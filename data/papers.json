{
  "last_updated": "2025-08-23T00:47:52.990185",
  "papers": [
    {
      "title": "SceneGen: Single-Image 3D Scene Generation in One Feedforward Pass",
      "authors": [
        "Yanxu Meng",
        "Haoning Wu",
        "Ya Zhang",
        "Weidi Xie"
      ],
      "abstract": "3D content generation has recently attracted significant research interest\ndue to its applications in VR/AR and embodied AI. In this work, we address the\nchallenging task of synthesizing multiple 3D assets within a single scene\nimage. Concretely, our contributions are fourfold: (i) we present SceneGen, a\nnovel framework that takes a scene image and corresponding object masks as\ninput, simultaneously producing multiple 3D assets with geometry and texture.\nNotably, SceneGen operates with no need for optimization or asset retrieval;\n(ii) we introduce a novel feature aggregation module that integrates local and\nglobal scene information from visual and geometric encoders within the feature\nextraction module. Coupled with a position head, this enables the generation of\n3D assets and their relative spatial positions in a single feedforward pass;\n(iii) we demonstrate SceneGen's direct extensibility to multi-image input\nscenarios. Despite being trained solely on single-image inputs, our\narchitectural design enables improved generation performance with multi-image\ninputs; and (iv) extensive quantitative and qualitative evaluations confirm the\nefficiency and robust generation abilities of our approach. We believe this\nparadigm offers a novel solution for high-quality 3D content generation,\npotentially advancing its practical applications in downstream tasks. The code\nand model will be publicly available at: https://mengmouxu.github.io/SceneGen.",
      "pdf_url": "http://arxiv.org/pdf/2508.15769v1",
      "published": "2025-08-21T17:59:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.15769v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Discovering Hidden Algebraic Structures via Transformers with Rank-Aware Beam GRPO",
      "authors": [
        "Jaeha Lee",
        "Gio Huh",
        "Ning Su",
        "Tony Yue YU"
      ],
      "abstract": "Recent efforts have extended the capabilities of transformers in logical\nreasoning and symbolic computations. In this work, we investigate their\ncapacity for non-linear latent pattern discovery in the context of functional\ndecomposition, focusing on the challenging algebraic task of multivariate\npolynomial decomposition. This problem, with widespread applications in science\nand engineering, is proved to be NP-hard, and demands both precision and\ninsight. Our contributions are threefold: First, we develop a synthetic data\ngeneration pipeline providing fine-grained control over problem complexity.\nSecond, we train transformer models via supervised learning and evaluate them\nacross four key dimensions involving scaling behavior and generalizability.\nThird, we propose Beam Grouped Relative Policy Optimization (BGRPO), a\nrank-aware reinforcement learning method suitable for hard algebraic problems.\nFinetuning with BGRPO improves accuracy while reducing beam width by up to\nhalf, resulting in approximately 75% lower inference compute. Additionally, our\nmodel demonstrates competitive performance in polynomial simplification,\noutperforming Mathematica in various cases.",
      "pdf_url": "http://arxiv.org/pdf/2508.15766v1",
      "published": "2025-08-21T17:58:50+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.15766v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "LiveMCP-101: Stress Testing and Diagnosing MCP-enabled Agents on Challenging Queries",
      "authors": [
        "Ming Yin",
        "Dinghan Shen",
        "Silei Xu",
        "Jianbing Han",
        "Sixun Dong",
        "Mian Zhang",
        "Yebowen Hu",
        "Shujian Liu",
        "Simin Ma",
        "Song Wang",
        "Sathish Reddy Indurthi",
        "Xun Wang",
        "Yiran Chen",
        "Kaiqiang Song"
      ],
      "abstract": "Tool calling has emerged as a critical capability for AI agents to interact\nwith the real world and solve complex tasks. While the Model Context Protocol\n(MCP) provides a powerful standardized framework for tool integration, there is\na significant gap in benchmarking how well AI agents can effectively solve\nmulti-step tasks using diverse MCP tools in realistic, dynamic scenarios. In\nthis work, we present LiveMCP-101, a benchmark of 101 carefully curated\nreal-world queries, refined through iterative LLM rewriting and manual review,\nthat require coordinated use of multiple MCP tools including web search, file\noperations, mathematical reasoning, and data analysis. Moreover, we introduce a\nnovel evaluation approach that leverages ground-truth execution plans rather\nthan raw API outputs, better reflecting the evolving nature of real-world\nenvironments. Experiments show that even frontier LLMs achieve a success rate\nbelow 60\\%, highlighting major challenges in tool orchestration. Detailed\nablations and error analysis further reveal distinct failure modes and\ninefficiencies in token usage, pointing to concrete directions for advancing\ncurrent models. LiveMCP-101 sets a rigorous standard for evaluating real-world\nagent capabilities, advancing toward autonomous AI systems that reliably\nexecute complex tasks through tool use.",
      "pdf_url": "http://arxiv.org/pdf/2508.15760v1",
      "published": "2025-08-21T17:55:54+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.15760v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Language-Guided Tuning: Enhancing Numeric Optimization with Textual Feedback",
      "authors": [
        "Yuxing Lu",
        "Yucheng Hu",
        "Nan Sun",
        "Xukai Zhao"
      ],
      "abstract": "Configuration optimization remains a critical bottleneck in machine learning,\nrequiring coordinated tuning across model architecture, training strategy,\nfeature engineering, and hyperparameters. Traditional approaches treat these\ndimensions independently and lack interpretability, while recent automated\nmethods struggle with dynamic adaptability and semantic reasoning about\noptimization decisions. We introduce Language-Guided Tuning (LGT), a novel\nframework that employs multi-agent Large Language Models to intelligently\noptimize configurations through natural language reasoning. We apply textual\ngradients - qualitative feedback signals that complement numerical optimization\nby providing semantic understanding of training dynamics and configuration\ninterdependencies. LGT coordinates three specialized agents: an Advisor that\nproposes configuration changes, an Evaluator that assesses progress, and an\nOptimizer that refines the decision-making process, creating a self-improving\nfeedback loop. Through comprehensive evaluation on six diverse datasets, LGT\ndemonstrates substantial improvements over traditional optimization methods,\nachieving performance gains while maintaining high interpretability.",
      "pdf_url": "http://arxiv.org/pdf/2508.15757v1",
      "published": "2025-08-21T17:55:07+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.15757v1",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.MA"
      ]
    },
    {
      "title": "Neural Robot Dynamics",
      "authors": [
        "Jie Xu",
        "Eric Heiden",
        "Iretiayo Akinola",
        "Dieter Fox",
        "Miles Macklin",
        "Yashraj Narang"
      ],
      "abstract": "Accurate and efficient simulation of modern robots remains challenging due to\ntheir high degrees of freedom and intricate mechanisms. Neural simulators have\nemerged as a promising alternative to traditional analytical simulators,\ncapable of efficiently predicting complex dynamics and adapting to real-world\ndata; however, existing neural simulators typically require\napplication-specific training and fail to generalize to novel tasks and/or\nenvironments, primarily due to inadequate representations of the global state.\nIn this work, we address the problem of learning generalizable neural\nsimulators for robots that are structured as articulated rigid bodies. We\npropose NeRD (Neural Robot Dynamics), learned robot-specific dynamics models\nfor predicting future states for articulated rigid bodies under contact\nconstraints. NeRD uniquely replaces the low-level dynamics and contact solvers\nin an analytical simulator and employs a robot-centric and spatially-invariant\nsimulation state representation. We integrate the learned NeRD models as an\ninterchangeable backend solver within a state-of-the-art robotics simulator. We\nconduct extensive experiments to show that the NeRD simulators are stable and\naccurate over a thousand simulation steps; generalize across tasks and\nenvironment configurations; enable policy learning exclusively in a neural\nengine; and, unlike most classical simulators, can be fine-tuned from\nreal-world data to bridge the gap between simulation and reality.",
      "pdf_url": "http://arxiv.org/pdf/2508.15755v1",
      "published": "2025-08-21T17:54:41+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.15755v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.GR",
        "cs.LG"
      ]
    },
    {
      "title": "Dissecting Tool-Integrated Reasoning: An Empirical Study and Analysis",
      "authors": [
        "Yufeng Zhao",
        "Junnan Liu",
        "Hongwei Liu",
        "Dongsheng Zhu",
        "Yuan Shen",
        "Songyang Zhang",
        "Kai Chen"
      ],
      "abstract": "Large Language Models (LLMs) have made significant strides in reasoning tasks\nthrough methods like chain-of-thought (CoT) reasoning. However, they often fall\nshort in tasks requiring precise computations. Tool-Integrated Reasoning (TIR)\nhas emerged as a solution by incorporating external tools into the reasoning\nprocess. Nevertheless, the generalization of TIR in improving the reasoning\nability of LLM is still unclear. Additionally, whether TIR has improved the\nmodel's reasoning behavior and helped the model think remains to be studied. We\nintroduce ReasonZoo, a comprehensive benchmark encompassing nine diverse\nreasoning categories, to evaluate the effectiveness of TIR across various\ndomains. Additionally, we propose two novel metrics, Performance-Aware Cost\n(PAC) and Area Under the Performance-Cost Curve (AUC-PCC), to assess reasoning\nefficiency. Our empirical evaluation demonstrates that TIR-enabled models\nconsistently outperform their non-TIR counterparts in both mathematical and\nnon-mathematical tasks. Furthermore, TIR enhances reasoning efficiency, as\nevidenced by improved PAC and AUC-PCC, indicating reduced overthinking and more\nstreamlined reasoning. These findings underscore the domain-general benefits of\nTIR and its potential to advance LLM capabilities in complex reasoning tasks.",
      "pdf_url": "http://arxiv.org/pdf/2508.15754v1",
      "published": "2025-08-21T17:50:24+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.15754v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "\"Does the cafe entrance look accessible? Where is the door?\" Towards Geospatial AI Agents for Visual Inquiries",
      "authors": [
        "Jon E. Froehlich",
        "Jared Hwang",
        "Zeyu Wang",
        "John S. O'Meara",
        "Xia Su",
        "William Huang",
        "Yang Zhang",
        "Alex Fiannaca",
        "Philip Nelson",
        "Shaun Kane"
      ],
      "abstract": "Interactive digital maps have revolutionized how people travel and learn\nabout the world; however, they rely on pre-existing structured data in GIS\ndatabases (e.g., road networks, POI indices), limiting their ability to address\ngeo-visual questions related to what the world looks like. We introduce our\nvision for Geo-Visual Agents--multimodal AI agents capable of understanding and\nresponding to nuanced visual-spatial inquiries about the world by analyzing\nlarge-scale repositories of geospatial images, including streetscapes (e.g.,\nGoogle Street View), place-based photos (e.g., TripAdvisor, Yelp), and aerial\nimagery (e.g., satellite photos) combined with traditional GIS data sources. We\ndefine our vision, describe sensing and interaction approaches, provide three\nexemplars, and enumerate key challenges and opportunities for future work.",
      "pdf_url": "http://arxiv.org/pdf/2508.15752v1",
      "published": "2025-08-21T17:49:52+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.15752v1",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CV",
        "H.5; I.2"
      ]
    },
    {
      "title": "Response and Prompt Evaluation to Prevent Parasocial Relationships with Chatbots",
      "authors": [
        "Emma Rath",
        "Stuart Armstrong",
        "Rebecca Gorman"
      ],
      "abstract": "The development of parasocial relationships with AI agents has severe, and in\nsome cases, tragic effects for human well-being. Yet preventing such dynamics\nis challenging: parasocial cues often emerge gradually in private\nconversations, and not all forms of emotional engagement are inherently\nharmful. We address this challenge by introducing a simple response evaluation\nframework, created by repurposing a state-of-the-art language model, that\nevaluates ongoing conversations for parasocial cues in real time. To test the\nfeasibility of this approach, we constructed a small synthetic dataset of\nthirty dialogues spanning parasocial, sycophantic, and neutral conversations.\nIterative evaluation with five stage testing successfully identified all\nparasocial conversations while avoiding false positives under a tolerant\nunanimity rule, with detection typically occurring within the first few\nexchanges. These findings provide preliminary evidence that evaluation agents\ncan provide a viable solution for the prevention of parasocial relations.",
      "pdf_url": "http://arxiv.org/pdf/2508.15748v1",
      "published": "2025-08-21T17:43:24+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.15748v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "End-to-End Agentic RAG System Training for Traceable Diagnostic Reasoning",
      "authors": [
        "Qiaoyu Zheng",
        "Yuze Sun",
        "Chaoyi Wu",
        "Weike Zhao",
        "Pengcheng Qiu",
        "Yongguo Yu",
        "Kun Sun",
        "Yanfeng Wang",
        "Ya Zhang",
        "Weidi Xie"
      ],
      "abstract": "Accurate diagnosis with medical large language models is hindered by\nknowledge gaps and hallucinations. Retrieval and tool-augmented methods help,\nbut their impact is limited by weak use of external knowledge and poor\nfeedback-reasoning traceability. To address these challenges, We introduce\nDeep-DxSearch, an agentic RAG system trained end-to-end with reinforcement\nlearning (RL) that enables steer tracebale retrieval-augmented reasoning for\nmedical diagnosis. In Deep-DxSearch, we first construct a large-scale medical\nretrieval corpus comprising patient records and reliable medical knowledge\nsources to support retrieval-aware reasoning across diagnostic scenarios. More\ncrutially, we frame the LLM as the core agent and the retrieval corpus as its\nenvironment, using tailored rewards on format, retrieval, reasoning structure,\nand diagnostic accuracy, thereby evolving the agentic RAG policy from\nlarge-scale data through RL.\n  Experiments demonstrate that our end-to-end agentic RL training framework\nconsistently outperforms prompt-engineering and training-free RAG approaches\nacross multiple data centers. After training, Deep-DxSearch achieves\nsubstantial gains in diagnostic accuracy, surpassing strong diagnostic\nbaselines such as GPT-4o, DeepSeek-R1, and other medical-specific frameworks\nfor both common and rare disease diagnosis under in-distribution and\nout-of-distribution settings. Moreover, ablation studies on reward design and\nretrieval corpus components confirm their critical roles, underscoring the\nuniqueness and effectiveness of our approach compared with traditional\nimplementations. Finally, case studies and interpretability analyses highlight\nimprovements in Deep-DxSearch's diagnostic policy, providing deeper insight\ninto its performance gains and supporting clinicians in delivering more\nreliable and precise preliminary diagnoses. See\nhttps://github.com/MAGIC-AI4Med/Deep-DxSearch.",
      "pdf_url": "http://arxiv.org/pdf/2508.15746v1",
      "published": "2025-08-21T17:42:47+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.15746v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Measuring the environmental impact of delivering AI at Google Scale",
      "authors": [
        "Cooper Elsworth",
        "Keguo Huang",
        "David Patterson",
        "Ian Schneider",
        "Robert Sedivy",
        "Savannah Goodman",
        "Ben Townsend",
        "Parthasarathy Ranganathan",
        "Jeff Dean",
        "Amin Vahdat",
        "Ben Gomes",
        "James Manyika"
      ],
      "abstract": "The transformative power of AI is undeniable - but as user adoption\naccelerates, so does the need to understand and mitigate the environmental\nimpact of AI serving. However, no studies have measured AI serving\nenvironmental metrics in a production environment. This paper addresses this\ngap by proposing and executing a comprehensive methodology for measuring the\nenergy usage, carbon emissions, and water consumption of AI inference workloads\nin a large-scale, AI production environment. Our approach accounts for the full\nstack of AI serving infrastructure - including active AI accelerator power,\nhost system energy, idle machine capacity, and data center energy overhead.\nThrough detailed instrumentation of Google's AI infrastructure for serving the\nGemini AI assistant, we find the median Gemini Apps text prompt consumes 0.24\nWh of energy - a figure substantially lower than many public estimates. We also\nshow that Google's software efficiency efforts and clean energy procurement\nhave driven a 33x reduction in energy consumption and a 44x reduction in carbon\nfootprint for the median Gemini Apps text prompt over one year. We identify\nthat the median Gemini Apps text prompt uses less energy than watching nine\nseconds of television (0.24 Wh) and consumes the equivalent of five drops of\nwater (0.26 mL). While these impacts are low compared to other daily\nactivities, reducing the environmental impact of AI serving continues to\nwarrant important attention. Towards this objective, we propose that a\ncomprehensive measurement of AI serving environmental metrics is critical for\naccurately comparing models, and to properly incentivize efficiency gains\nacross the full AI serving stack.",
      "pdf_url": "http://arxiv.org/pdf/2508.15734v1",
      "published": "2025-08-21T17:22:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.15734v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Numerical models outperform AI weather forecasts of record-breaking extremes",
      "authors": [
        "Zhongwei Zhang",
        "Erich Fischer",
        "Jakob Zscheischler",
        "Sebastian Engelke"
      ],
      "abstract": "Artificial intelligence (AI)-based models are revolutionizing weather\nforecasting and have surpassed leading numerical weather prediction systems on\nvarious benchmark tasks. However, their ability to extrapolate and reliably\nforecast unprecedented extreme events remains unclear. Here, we show that for\nrecord-breaking weather extremes, the numerical model High RESolution forecast\n(HRES) from the European Centre for Medium-Range Weather Forecasts still\nconsistently outperforms state-of-the-art AI models GraphCast, GraphCast\noperational, Pangu-Weather, Pangu-Weather operational, and Fuxi. We demonstrate\nthat forecast errors in AI models are consistently larger for record-breaking\nheat, cold, and wind than in HRES across nearly all lead times. We further find\nthat the examined AI models tend to underestimate both the frequency and\nintensity of record-breaking events, and they underpredict hot records and\noverestimate cold records with growing errors for larger record exceedance. Our\nfindings underscore the current limitations of AI weather models in\nextrapolating beyond their training domain and in forecasting the potentially\nmost impactful record-breaking weather events that are particularly frequent in\na rapidly warming climate. Further rigorous verification and model development\nis needed before these models can be solely relied upon for high-stakes\napplications such as early warning systems and disaster management.",
      "pdf_url": "http://arxiv.org/pdf/2508.15724v1",
      "published": "2025-08-21T17:07:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.15724v1",
      "categories": [
        "physics.ao-ph",
        "cs.AI",
        "stat.AP",
        "J.2; I.6.4"
      ]
    },
    {
      "title": "EcomMMMU: Strategic Utilization of Visuals for Robust Multimodal E-Commerce Models",
      "authors": [
        "Xinyi Ling",
        "Hanwen Du",
        "Zhihui Zhu",
        "Xia Ning"
      ],
      "abstract": "E-commerce platforms are rich in multimodal data, featuring a variety of\nimages that depict product details. However, this raises an important question:\ndo these images always enhance product understanding, or can they sometimes\nintroduce redundancy or degrade performance? Existing datasets are limited in\nboth scale and design, making it difficult to systematically examine this\nquestion. To this end, we introduce EcomMMMU, an e-commerce multimodal\nmultitask understanding dataset with 406,190 samples and 8,989,510 images.\nEcomMMMU is comprised of multi-image visual-language data designed with 8\nessential tasks and a specialized VSS subset to benchmark the capability of\nmultimodal large language models (MLLMs) to effectively utilize visual content.\nAnalysis on EcomMMMU reveals that product images do not consistently improve\nperformance and can, in some cases, degrade it. This indicates that MLLMs may\nstruggle to effectively leverage rich visual content for e-commerce tasks.\nBuilding on these insights, we propose SUMEI, a data-driven method that\nstrategically utilizes multiple images via predicting visual utilities before\nusing them for downstream tasks. Comprehensive experiments demonstrate the\neffectiveness and robustness of SUMEI. The data and code are available through\nhttps://anonymous.4open.science/r/submission25.",
      "pdf_url": "http://arxiv.org/pdf/2508.15721v1",
      "published": "2025-08-21T17:01:12+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.15721v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Tutorial on the Probabilistic Unification of Estimation Theory, Machine Learning, and Generative AI",
      "authors": [
        "Mohammed Elmusrati"
      ],
      "abstract": "Extracting meaning from uncertain, noisy data is a fundamental problem across\ntime series analysis, pattern recognition, and language modeling. This survey\npresents a unified mathematical framework that connects classical estimation\ntheory, statistical inference, and modern machine learning, including deep\nlearning and large language models. By analyzing how techniques such as maximum\nlikelihood estimation, Bayesian inference, and attention mechanisms address\nuncertainty, the paper illustrates that many AI methods are rooted in shared\nprobabilistic principles. Through illustrative scenarios including system\nidentification, image classification, and language generation, we show how\nincreasingly complex models build upon these foundations to tackle practical\nchallenges like overfitting, data sparsity, and interpretability. In other\nwords, the work demonstrates that maximum likelihood, MAP estimation, Bayesian\nclassification, and deep learning all represent different facets of a shared\ngoal: inferring hidden causes from noisy and/or biased observations. It serves\nas both a theoretical synthesis and a practical guide for students and\nresearchers navigating the evolving landscape of machine learning.",
      "pdf_url": "http://arxiv.org/pdf/2508.15719v1",
      "published": "2025-08-21T16:57:33+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.15719v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "StreamMem: Query-Agnostic KV Cache Memory for Streaming Video Understanding",
      "authors": [
        "Yanlai Yang",
        "Zhuokai Zhao",
        "Satya Narayan Shukla",
        "Aashu Singh",
        "Shlok Kumar Mishra",
        "Lizhu Zhang",
        "Mengye Ren"
      ],
      "abstract": "Multimodal large language models (MLLMs) have made significant progress in\nvisual-language reasoning, but their ability to efficiently handle long videos\nremains limited. Despite recent advances in long-context MLLMs, storing and\nattending to the key-value (KV) cache for long visual contexts incurs\nsubstantial memory and computational overhead. Existing visual compression\nmethods require either encoding the entire visual context before compression or\nhaving access to the questions in advance, which is impractical for long video\nunderstanding and multi-turn conversational settings. In this work, we propose\nStreamMem, a query-agnostic KV cache memory mechanism for streaming video\nunderstanding. Specifically, StreamMem encodes new video frames in a streaming\nmanner, compressing the KV cache using attention scores between visual tokens\nand generic query tokens, while maintaining a fixed-size KV memory to enable\nefficient question answering (QA) in memory-constrained, long-video scenarios.\nEvaluation on three long video understanding and two streaming video question\nanswering benchmarks shows that StreamMem achieves state-of-the-art performance\nin query-agnostic KV cache compression and is competitive with query-aware\ncompression approaches.",
      "pdf_url": "http://arxiv.org/pdf/2508.15717v1",
      "published": "2025-08-21T16:56:29+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.15717v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Foundation Models for Cross-Domain EEG Analysis Application: A Survey",
      "authors": [
        "Hongqi Li",
        "Yitong Chen",
        "Yujuan Wang",
        "Weihang Ni",
        "Haodong Zhang"
      ],
      "abstract": "Electroencephalography (EEG) analysis stands at the forefront of neuroscience\nand artificial intelligence research, where foundation models are reshaping the\ntraditional EEG analysis paradigm by leveraging their powerful representational\ncapacity and cross-modal generalization. However, the rapid proliferation of\nthese techniques has led to a fragmented research landscape, characterized by\ndiverse model roles, inconsistent architectures, and a lack of systematic\ncategorization. To bridge this gap, this study presents the first comprehensive\nmodality-oriented taxonomy for foundation models in EEG analysis,\nsystematically organizing research advances based on output modalities of the\nnative EEG decoding, EEG-text, EEG-vision, EEG-audio, and broader multimodal\nframeworks. We rigorously analyze each category's research ideas, theoretical\nfoundations, and architectural innovations, while highlighting open challenges\nsuch as model interpretability, cross-domain generalization, and real-world\napplicability in EEG-based systems. By unifying this dispersed field, our work\nnot only provides a reference framework for future methodology development but\naccelerates the translation of EEG foundation models into scalable,\ninterpretable, and online actionable solutions.",
      "pdf_url": "http://arxiv.org/pdf/2508.15716v1",
      "published": "2025-08-21T16:56:28+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.15716v1",
      "categories": [
        "cs.HC",
        "cs.AI"
      ]
    },
    {
      "title": "NiceWebRL: a Python library for human subject experiments with reinforcement learning environments",
      "authors": [
        "Wilka Carvalho",
        "Vikram Goddla",
        "Ishaan Sinha",
        "Hoon Shin",
        "Kunal Jha"
      ],
      "abstract": "We present NiceWebRL, a research tool that enables researchers to use machine\nreinforcement learning (RL) environments for online human subject experiments.\nNiceWebRL is a Python library that allows any Jax-based environment to be\ntransformed into an online interface, supporting both single-agent and\nmulti-agent environments. As such, NiceWebRL enables AI researchers to compare\ntheir algorithms to human performance, cognitive scientists to test ML\nalgorithms as theories for human cognition, and multi-agent researchers to\ndevelop algorithms for human-AI collaboration. We showcase NiceWebRL with 3\ncase studies that demonstrate its potential to help develop Human-like AI,\nHuman-compatible AI, and Human-assistive AI. In the first case study\n(Human-like AI), NiceWebRL enables the development of a novel RL model of\ncognition. Here, NiceWebRL facilitates testing this model against human\nparticipants in both a grid world and Craftax, a 2D Minecraft domain. In our\nsecond case study (Human-compatible AI), NiceWebRL enables the development of a\nnovel multi-agent RL algorithm that can generalize to human partners in the\nOvercooked domain. Finally, in our third case study (Human-assistive AI), we\nshow how NiceWebRL can allow researchers to study how an LLM can assist humans\non complex tasks in XLand-Minigrid, an environment with millions of\nhierarchical tasks. The library is available at\nhttps://github.com/KempnerInstitute/nicewebrl.",
      "pdf_url": "http://arxiv.org/pdf/2508.15693v1",
      "published": "2025-08-21T16:18:49+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.15693v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "GRAFT: GRaPH and Table Reasoning for Textual Alignment -- A Benchmark for Structured Instruction Following and Visual Reasoning",
      "authors": [
        "Abhigya Verma",
        "Sriram Puttagunta",
        "Seganrasan Subramanian",
        "Sravan Ramachandran"
      ],
      "abstract": "GRAFT is a structured multimodal benchmark for evaluating models on\ninstruction-following, visual reasoning, and visual-textual alignment tasks. It\nfeatures programmatically generated charts and synthetically rendered tables,\ncreated with Python visualization libraries to ensure control over data\nsemantics, structure, and clarity. Each GRAFT instance pairs a chart or table\nimage with a systematically generated, multi-step analytical question based\nsolely on visual content. Answers are provided in structured formats such as\nJSON or YAML, supporting consistent evaluation of both reasoning and output\nformat. The benchmark introduces a taxonomy of reasoning types including\ncomparison, trend identification, ranking, aggregation, proportion estimation,\nand anomaly detection to enable comprehensive assessment. Reference answers\nfollow strict factual and formatting guidelines for precise, aspect-based\nevaluation. GRAFT offers a unified, scalable framework for fine-grained\nbenchmarking of multimodal models on visually grounded, structured reasoning\ntasks, setting a new evaluation standard in this field.",
      "pdf_url": "http://arxiv.org/pdf/2508.15690v1",
      "published": "2025-08-21T16:13:49+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.15690v1",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.MM"
      ]
    },
    {
      "title": "Row-Column Hybrid Grouping for Fault-Resilient Multi-Bit Weight Representation on IMC Arrays",
      "authors": [
        "Kang Eun Jeon",
        "Sangheum Yeon",
        "Jinhee Kim",
        "Hyeonsu Bang",
        "Johnny Rhe",
        "Jong Hwan Ko"
      ],
      "abstract": "This paper addresses two critical challenges in analog In-Memory Computing\n(IMC) systems that limit their scalability and deployability: the computational\nunreliability caused by stuck-at faults (SAFs) and the high compilation\noverhead of existing fault-mitigation algorithms, namely Fault-Free (FF). To\novercome these limitations, we first propose a novel multi-bit weight\nrepresentation technique, termed row-column hybrid grouping, which generalizes\nconventional column grouping by introducing redundancy across both rows and\ncolumns. This structural redundancy enhances fault tolerance and can be\neffectively combined with existing fault-mitigation solutions. Second, we\ndesign a compiler pipeline that reformulates the fault-aware weight\ndecomposition problem as an Integer Linear Programming (ILP) task, enabling\nfast and scalable compilation through off-the-shelf solvers. Further\nacceleration is achieved through theoretical insights that identify fault\npatterns amenable to trivial solutions, significantly reducing computation.\nExperimental results on convolutional networks and small language models\ndemonstrate the effectiveness of our approach, achieving up to 8%p improvement\nin accuracy, 150x faster compilation, and 2x energy efficiency gain compared to\nexisting baselines.",
      "pdf_url": "http://arxiv.org/pdf/2508.15685v1",
      "published": "2025-08-21T16:05:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.15685v1",
      "categories": [
        "cs.AR",
        "cs.AI"
      ]
    },
    {
      "title": "Futurity as Infrastructure: A Techno-Philosophical Interpretation of the AI Lifecycle",
      "authors": [
        "Mark Cote",
        "Susana Aires"
      ],
      "abstract": "This paper argues that a techno-philosophical reading of the EU AI Act\nprovides insight into the long-term dynamics of data in AI systems,\nspecifically, how the lifecycle from ingestion to deployment generates\nrecursive value chains that challenge existing frameworks for Responsible AI.\nWe introduce a conceptual tool to frame the AI pipeline, spanning data,\ntraining regimes, architectures, feature stores, and transfer learning. Using\ncross-disciplinary methods, we develop a technically grounded and\nphilosophically coherent analysis of regulatory blind spots. Our central claim\nis that what remains absent from policymaking is an account of the dynamic of\nbecoming that underpins both the technical operation and economic logic of AI.\nTo address this, we advance a formal reading of AI inspired by Simondonian\nphilosophy of technology, reworking his concept of individuation to model the\nAI lifecycle, including the pre-individual milieu, individuation, and\nindividuated AI. To translate these ideas, we introduce futurity: the\nself-reinforcing lifecycle of AI, where more data enhances performance, deepens\npersonalisation, and expands application domains. Futurity highlights the\nrecursively generative, non-rivalrous nature of data, underpinned by\ninfrastructures like feature stores that enable feedback, adaptation, and\ntemporal recursion. Our intervention foregrounds escalating power asymmetries,\nparticularly the tech oligarchy whose infrastructures of capture, training, and\ndeployment concentrate value and decision-making. We argue that effective\nregulation must address these infrastructural and temporal dynamics, and\npropose measures including lifecycle audits, temporal traceability, feedback\naccountability, recursion transparency, and a right to contest recursive reuse.",
      "pdf_url": "http://arxiv.org/pdf/2508.15680v1",
      "published": "2025-08-21T16:00:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.15680v1",
      "categories": [
        "cs.AI",
        "cs.HC",
        "I.2.6; I.2.11; K.4.1; K.6.0"
      ]
    },
    {
      "title": "Mind and Motion Aligned: A Joint Evaluation IsaacSim Benchmark for Task Planning and Low-Level Policies in Mobile Manipulation",
      "authors": [
        "Nikita Kachaev",
        "Andrei Spiridonov",
        "Andrey Gorodetsky",
        "Kirill Muravyev",
        "Nikita Oskolkov",
        "Aditya Narendra",
        "Vlad Shakhuro",
        "Dmitry Makarov",
        "Aleksandr I. Panov",
        "Polina Fedotova",
        "Alexey K. Kovalev"
      ],
      "abstract": "Benchmarks are crucial for evaluating progress in robotics and embodied AI.\nHowever, a significant gap exists between benchmarks designed for high-level\nlanguage instruction following, which often assume perfect low-level execution,\nand those for low-level robot control, which rely on simple, one-step commands.\nThis disconnect prevents a comprehensive evaluation of integrated systems where\nboth task planning and physical execution are critical. To address this, we\npropose Kitchen-R, a novel benchmark that unifies the evaluation of task\nplanning and low-level control within a simulated kitchen environment. Built as\na digital twin using the Isaac Sim simulator and featuring more than 500\ncomplex language instructions, Kitchen-R supports a mobile manipulator robot.\nWe provide baseline methods for our benchmark, including a task-planning\nstrategy based on a vision-language model and a low-level control policy based\non diffusion policy. We also provide a trajectory collection system. Our\nbenchmark offers a flexible framework for three evaluation modes: independent\nassessment of the planning module, independent assessment of the control\npolicy, and, crucially, an integrated evaluation of the whole system. Kitchen-R\nbridges a key gap in embodied AI research, enabling more holistic and realistic\nbenchmarking of language-guided robotic agents.",
      "pdf_url": "http://arxiv.org/pdf/2508.15663v1",
      "published": "2025-08-21T15:48:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.15663v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "Benchmarking Computer Science Survey Generation",
      "authors": [
        "Weihang Su",
        "Anzhe Xie",
        "Qingyao Ai",
        "Jianming Long",
        "Jiaxin Mao",
        "Ziyi Ye",
        "Yiqun Liu"
      ],
      "abstract": "Scientific survey articles play a vital role in summarizing research\nprogress, yet their manual creation is becoming increasingly infeasible due to\nthe rapid growth of academic literature. While large language models (LLMs)\noffer promising capabilities for automating this process, progress in this area\nis hindered by the absence of standardized benchmarks and evaluation protocols.\nTo address this gap, we introduce SurGE (Survey Generation Evaluation), a new\nbenchmark for evaluating scientific survey generation in the computer science\ndomain. SurGE consists of (1) a collection of test instances, each including a\ntopic description, an expert-written survey, and its full set of cited\nreferences, and (2) a large-scale academic corpus of over one million papers\nthat serves as the retrieval pool. In addition, we propose an automated\nevaluation framework that measures generated surveys across four dimensions:\ninformation coverage, referencing accuracy, structural organization, and\ncontent quality. Our evaluation of diverse LLM-based approaches shows that\nsurvey generation remains highly challenging, even for advanced self-reflection\nframeworks. These findings highlight the complexity of the task and the\nnecessity for continued research. We have open-sourced all the code, data, and\nmodels at: https://github.com/oneal2000/SurGE",
      "pdf_url": "http://arxiv.org/pdf/2508.15658v1",
      "published": "2025-08-21T15:45:10+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.15658v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ]
    },
    {
      "title": "Understanding Action Effects through Instrumental Empowerment in Multi-Agent Reinforcement Learning",
      "authors": [
        "Ardian Selmonaj",
        "Miroslav Strupl",
        "Oleg Szehr",
        "Alessandro Antonucci"
      ],
      "abstract": "To reliably deploy Multi-Agent Reinforcement Learning (MARL) systems, it is\ncrucial to understand individual agent behaviors within a team. While prior\nwork typically evaluates overall team performance based on explicit reward\nsignals or learned value functions, it is unclear how to infer agent\ncontributions in the absence of any value feedback. In this work, we\ninvestigate whether meaningful insights into agent behaviors can be extracted\nthat are consistent with the underlying value functions, solely by analyzing\nthe policy distribution. Inspired by the phenomenon that intelligent agents\ntend to pursue convergent instrumental values, which generally increase the\nlikelihood of task success, we introduce Intended Cooperation Values (ICVs), a\nmethod based on information-theoretic Shapley values for quantifying each\nagent's causal influence on their co-players' instrumental empowerment.\nSpecifically, ICVs measure an agent's action effect on its teammates' policies\nby assessing their decision uncertainty and preference alignment. The analysis\nacross cooperative and competitive MARL environments reveals the extent to\nwhich agents adopt similar or diverse strategies. By comparing action effects\nbetween policies and value functions, our method identifies which agent\nbehaviors are beneficial to team success, either by fostering deterministic\ndecisions or by preserving flexibility for future action choices. Our proposed\nmethod offers novel insights into cooperation dynamics and enhances\nexplainability in MARL systems.",
      "pdf_url": "http://arxiv.org/pdf/2508.15652v1",
      "published": "2025-08-21T15:35:59+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.15652v1",
      "categories": [
        "cs.AI",
        "cs.IT",
        "cs.LG",
        "cs.MA",
        "math.IT"
      ]
    },
    {
      "title": "Towards a 3D Transfer-based Black-box Attack via Critical Feature Guidance",
      "authors": [
        "Shuchao Pang",
        "Zhenghan Chen",
        "Shen Zhang",
        "Liming Lu",
        "Siyuan Liang",
        "Anan Du",
        "Yongbin Zhou"
      ],
      "abstract": "Deep neural networks for 3D point clouds have been demonstrated to be\nvulnerable to adversarial examples. Previous 3D adversarial attack methods\noften exploit certain information about the target models, such as model\nparameters or outputs, to generate adversarial point clouds. However, in\nrealistic scenarios, it is challenging to obtain any information about the\ntarget models under conditions of absolute security. Therefore, we focus on\ntransfer-based attacks, where generating adversarial point clouds does not\nrequire any information about the target models. Based on our observation that\nthe critical features used for point cloud classification are consistent across\ndifferent DNN architectures, we propose CFG, a novel transfer-based black-box\nattack method that improves the transferability of adversarial point clouds via\nthe proposed Critical Feature Guidance. Specifically, our method regularizes\nthe search of adversarial point clouds by computing the importance of the\nextracted features, prioritizing the corruption of critical features that are\nlikely to be adopted by diverse architectures. Further, we explicitly constrain\nthe maximum deviation extent of the generated adversarial point clouds in the\nloss function to ensure their imperceptibility. Extensive experiments conducted\non the ModelNet40 and ScanObjectNN benchmark datasets demonstrate that the\nproposed CFG outperforms the state-of-the-art attack methods by a large margin.",
      "pdf_url": "http://arxiv.org/pdf/2508.15650v1",
      "published": "2025-08-21T15:31:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.15650v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Label Uncertainty for Ultrasound Segmentation",
      "authors": [
        "Malini Shivaram",
        "Gautam Rajendrakumar Gare",
        "Laura Hutchins",
        "Jacob Duplantis",
        "Thomas Deiss",
        "Thales Nogueira Gomes",
        "Thong Tran",
        "Keyur H. Patel",
        "Thomas H Fox",
        "Amita Krishnan",
        "Deva Ramanan",
        "Bennett DeBoisblanc",
        "Ricardo Rodriguez",
        "John Galeotti"
      ],
      "abstract": "In medical imaging, inter-observer variability among radiologists often\nintroduces label uncertainty, particularly in modalities where visual\ninterpretation is subjective. Lung ultrasound (LUS) is a prime example-it\nfrequently presents a mixture of highly ambiguous regions and clearly\ndiscernible structures, making consistent annotation challenging even for\nexperienced clinicians. In this work, we introduce a novel approach to both\nlabeling and training AI models using expert-supplied, per-pixel confidence\nvalues. Rather than treating annotations as absolute ground truth, we design a\ndata annotation protocol that captures the confidence that radiologists have in\neach labeled region, modeling the inherent aleatoric uncertainty present in\nreal-world clinical data. We demonstrate that incorporating these confidence\nvalues during training leads to improved segmentation performance. More\nimportantly, we show that this enhanced segmentation quality translates into\nbetter performance on downstream clinically-critical tasks-specifically,\nestimating S/F oxygenation ratio values, classifying S/F ratio change, and\npredicting 30-day patient readmission. While we empirically evaluate many\nmethods for exposing the uncertainty to the learning model, we find that a\nsimple approach that trains a model on binarized labels obtained with a (60%)\nconfidence threshold works well. Importantly, high thresholds work far better\nthan a naive approach of a 50% threshold, indicating that training on very\nconfident pixels is far more effective. Our study systematically investigates\nthe impact of training with varying confidence thresholds, comparing not only\nsegmentation metrics but also downstream clinical outcomes. These results\nsuggest that label confidence is a valuable signal that, when properly\nleveraged, can significantly enhance the reliability and clinical utility of AI\nin medical imaging.",
      "pdf_url": "http://arxiv.org/pdf/2508.15635v1",
      "published": "2025-08-21T15:00:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.15635v1",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "stat.ML"
      ]
    },
    {
      "title": "GRASPED: Graph Anomaly Detection using Autoencoder with Spectral Encoder and Decoder (Full Version)",
      "authors": [
        "Wei Herng Choong",
        "Jixing Liu",
        "Ching-Yu Kao",
        "Philip Sperl"
      ],
      "abstract": "Graph machine learning has been widely explored in various domains, such as\ncommunity detection, transaction analysis, and recommendation systems. In these\napplications, anomaly detection plays an important role. Recently, studies have\nshown that anomalies on graphs induce spectral shifts. Some supervised methods\nhave improved the utilization of such spectral domain information. However,\nthey remain limited by the scarcity of labeled data due to the nature of\nanomalies. On the other hand, existing unsupervised learning approaches\npredominantly rely on spatial information or only employ low-pass filters,\nthereby losing the capacity for multi-band analysis. In this paper, we propose\nGraph Autoencoder with Spectral Encoder and Spectral Decoder (GRASPED) for node\nanomaly detection. Our unsupervised learning model features an encoder based on\nGraph Wavelet Convolution, along with structural and attribute decoders. The\nGraph Wavelet Convolution-based encoder, combined with a Wiener Graph\nDeconvolution-based decoder, exhibits bandpass filter characteristics that\ncapture global and local graph information at multiple scales. This design\nallows for a learning-based reconstruction of node attributes, effectively\ncapturing anomaly information. Extensive experiments on several real-world\ngraph anomaly detection datasets demonstrate that GRASPED outperforms current\nstate-of-the-art models.",
      "pdf_url": "http://arxiv.org/pdf/2508.15633v1",
      "published": "2025-08-21T14:57:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.15633v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Adapting A Vector-Symbolic Memory for Lisp ACT-R",
      "authors": [
        "Meera Ray",
        "Christopher L. Dancy"
      ],
      "abstract": "Holographic Declarative Memory (HDM) is a vector-symbolic alternative to\nACT-R's Declarative Memory (DM) system that can bring advantages such as\nscalability and architecturally defined similarity between DM chunks. We\nadapted HDM to work with the most comprehensive and widely-used implementation\nof ACT-R (Lisp ACT-R) so extant ACT-R models designed with DM can be run with\nHDM without major changes. With this adaptation of HDM, we have developed\nvector-based versions of common ACT-R functions, set up a text processing\npipeline to add the contents of large documents to ACT-R memory, and most\nsignificantly created a useful and novel mechanism to retrieve an entire chunk\nof memory based on a request using only vector representations of tokens.\nPreliminary results indicate that we can maintain vector-symbolic advantages of\nHDM (e.g., chunk recall without storing the actual chunk and other advantages\nwith scaling) while also extending it so that previous ACT-R models may work\nwith the system with little (or potentially no) modifications within the actual\nprocedural and declarative memory portions of a model. As a part of iterative\nimprovement of this newly translated holographic declarative memory module, we\nwill continue to explore better time-context representations for vectors to\nimprove the module's ability to reconstruct chunks during recall. To more fully\ntest this translated HDM module, we also plan to develop decision-making models\nthat use instance-based learning (IBL) theory, which is a useful application of\nHDM given the advantages of the system.",
      "pdf_url": "http://arxiv.org/pdf/2508.15630v1",
      "published": "2025-08-21T14:54:25+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.15630v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Trained Miniatures: Low cost, High Efficacy SLMs for Sales & Marketing",
      "authors": [
        "Ishaan Bhola",
        "Mukunda NS",
        "Sravanth Kurmala",
        "Harsh Nandwani",
        "Arihant Jain"
      ],
      "abstract": "Large language models (LLMs) excel in text generation; however, these\ncreative elements require heavy computation and are accompanied by a steep\ncost. Especially for targeted applications such as sales and marketing\noutreach, these costs are far from feasible. This paper introduces the concept\nof \"Trained Miniatures\" - Small Language Models(SLMs) fine-tuned for specific,\nhigh-value applications, generating similar domain-specific responses for a\nfraction of the cost.",
      "pdf_url": "http://arxiv.org/pdf/2508.15617v1",
      "published": "2025-08-21T14:46:22+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.15617v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Transduction is All You Need for Structured Data Workflows",
      "authors": [
        "Alfio Gliozzo",
        "Naweed Khan",
        "Christodoulos Constantinides",
        "Nandana Mihindukulasooriya",
        "Nahuel Defosse",
        "Junkyu Lee"
      ],
      "abstract": "This paper introduces Agentics, a modular framework for building agent-based\nsystems capable of structured reasoning and compositional generalization over\ncomplex data. Designed with research and practical applications in mind,\nAgentics offers a novel perspective on working with data and AI workflows. In\nthis framework, agents are abstracted from the logical flow and they are used\ninternally to the data type to enable logical transduction among data. Agentics\nencourages AI developers to focus on modeling data rather than crafting\nprompts, enabling a declarative language in which data types are provided by\nLLMs and composed through logical transduction, which is executed by LLMs when\ntypes are connected. We provide empirical evidence demonstrating the\napplicability of this framework across domain-specific multiple-choice question\nanswering, semantic parsing for text-to-SQL, and automated prompt optimization\ntasks, achieving state-of-the-art accuracy or improved scalability without\nsacrificing performance. The open-source implementation is available at\n\\texttt{https://github.com/IBM/agentics}.",
      "pdf_url": "http://arxiv.org/pdf/2508.15610v1",
      "published": "2025-08-21T14:35:47+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.15610v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Are Virtual DES Images a Valid Alternative to the Real Ones?",
      "authors": [
        "Ana C. Perre",
        "Luís A. Alexandre",
        "Luís C. Freire"
      ],
      "abstract": "Contrast-enhanced spectral mammography (CESM) is an imaging modality that\nprovides two types of images, commonly known as low-energy (LE) and dual-energy\nsubtracted (DES) images. In many domains, particularly in medicine, the\nemergence of image-to-image translation techniques has enabled the artificial\ngeneration of images using other images as input. Within CESM, applying such\ntechniques to generate DES images from LE images could be highly beneficial,\npotentially reducing patient exposure to radiation associated with high-energy\nimage acquisition. In this study, we investigated three models for the\nartificial generation of DES images (virtual DES): a pre-trained U-Net model, a\nU-Net trained end-to-end model, and a CycleGAN model. We also performed a\nseries of experiments to assess the impact of using virtual DES images on the\nclassification of CESM examinations into malignant and non-malignant\ncategories. To our knowledge, this is the first study to evaluate the impact of\nvirtual DES images on CESM lesion classification. The results demonstrate that\nthe best performance was achieved with the pre-trained U-Net model, yielding an\nF1 score of 85.59% when using the virtual DES images, compared to 90.35% with\nthe real DES images. This discrepancy likely results from the additional\ndiagnostic information in real DES images, which contributes to a higher\nclassification accuracy. Nevertheless, the potential for virtual DES image\ngeneration is considerable and future advancements may narrow this performance\ngap to a level where exclusive reliance on virtual DES images becomes\nclinically viable.",
      "pdf_url": "http://arxiv.org/pdf/2508.15594v1",
      "published": "2025-08-21T14:07:42+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.15594v1",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "A Dynamical Systems Framework for Reinforcement Learning Safety and Robustness Verification",
      "authors": [
        "Ahmed Nasir",
        "Abdelhafid Zenati"
      ],
      "abstract": "The application of reinforcement learning to safety-critical systems is\nlimited by the lack of formal methods for verifying the robustness and safety\nof learned policies. This paper introduces a novel framework that addresses\nthis gap by analyzing the combination of an RL agent and its environment as a\ndiscrete-time autonomous dynamical system. By leveraging tools from dynamical\nsystems theory, specifically the Finite-Time Lyapunov Exponent (FTLE), we\nidentify and visualize Lagrangian Coherent Structures (LCS) that act as the\nhidden \"skeleton\" governing the system's behavior. We demonstrate that\nrepelling LCS function as safety barriers around unsafe regions, while\nattracting LCS reveal the system's convergence properties and potential failure\nmodes, such as unintended \"trap\" states. To move beyond qualitative\nvisualization, we introduce a suite of quantitative metrics, Mean Boundary\nRepulsion (MBR), Aggregated Spurious Attractor Strength (ASAS), and\nTemporally-Aware Spurious Attractor Strength (TASAS), to formally measure a\npolicy's safety margin and robustness. We further provide a method for deriving\nlocal stability guarantees and extend the analysis to handle model uncertainty.\nThrough experiments in both discrete and continuous control environments, we\nshow that this framework provides a comprehensive and interpretable assessment\nof policy behavior, successfully identifying critical flaws in policies that\nappear successful based on reward alone.",
      "pdf_url": "http://arxiv.org/pdf/2508.15588v1",
      "published": "2025-08-21T14:00:26+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.15588v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "LoUQAL: Low-fidelity informed Uncertainty Quantification for Active Learning in the chemical configuration space",
      "authors": [
        "Vivin Vinod",
        "Peter Zaspel"
      ],
      "abstract": "Uncertainty quantification is an important scheme in active learning\ntechniques, including applications in predicting quantum chemical properties.\nIn quantum chemical calculations, there exists the notion of a fidelity, a less\naccurate computation is accessible at a cheaper computational cost. This work\nproposes a novel low-fidelity informed uncertainty quantification for active\nlearning with applications in predicting diverse quantum chemical properties\nsuch as excitation energies and \\textit{ab initio} potential energy surfaces.\nComputational experiments are carried out in order to assess the proposed\nmethod with results demonstrating that models trained with the novel method\noutperform alternatives in terms of empirical error and number of iterations\nrequired. The effect of the choice of fidelity is also studied to perform a\nthorough benchmark.",
      "pdf_url": "http://arxiv.org/pdf/2508.15577v1",
      "published": "2025-08-21T13:51:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.15577v1",
      "categories": [
        "physics.chem-ph",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "DeepThink3D: Enhancing Large Language Models with Programmatic Reasoning in Complex 3D Situated Reasoning Tasks",
      "authors": [
        "Jiayi Song",
        "Rui Wan",
        "Lipeng Ma",
        "Weidong Yang",
        "Qingyuan Zhou",
        "Yixuan Li",
        "Ben Fei"
      ],
      "abstract": "This work enhances the ability of large language models (LLMs) to perform\ncomplex reasoning in 3D scenes. Recent work has addressed the 3D situated\nreasoning task by invoking tool usage through large language models. Large\nlanguage models call tools via APIs and integrate the generated programs\nthrough a chain of thought to solve problems based on the program results.\nHowever, due to the simplicity of the questions in the dataset, the generated\nprogram reasoning chains are relatively short. To solve this main challenge, in\nthis paper, we introduce DeepThink3D to enhance the tool usage of LLMs in\ncomplex 3D situated reasoning tasks. Our work proposes a combinatorial and\niterative evolutionary approach on the SQA3D benchmark to generate more complex\nquestions. Building on this foundation, we fine-tune the large language model\nto make it more proficient in using 3D tools. By employing Direct Preference\nOptimization (DPO), we directly optimize the toolchain strategies generated by\nmodels, thereby enhancing their accuracy in complex tasks.",
      "pdf_url": "http://arxiv.org/pdf/2508.15548v1",
      "published": "2025-08-21T13:28:36+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.15548v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Super-additive Cooperation in Language Model Agents",
      "authors": [
        "Filippo Tonini",
        "Lukas Galke"
      ],
      "abstract": "With the prospect of autonomous artificial intelligence (AI) agents, studying\ntheir tendency for cooperative behavior becomes an increasingly relevant topic.\nThis study is inspired by the super-additive cooperation theory, where the\ncombined effects of repeated interactions and inter-group rivalry have been\nargued to be the cause for cooperative tendencies found in humans. We devised a\nvirtual tournament where language model agents, grouped into teams, face each\nother in a Prisoner's Dilemma game. By simulating both internal team dynamics\nand external competition, we discovered that this blend substantially boosts\nboth overall and initial, one-shot cooperation levels (the tendency to\ncooperate in one-off interactions). This research provides a novel framework\nfor large language models to strategize and act in complex social scenarios and\noffers evidence for how intergroup competition can, counter-intuitively, result\nin more cooperative behavior. These insights are crucial for designing future\nmulti-agent AI systems that can effectively work together and better align with\nhuman values. Source code is available at\nhttps://github.com/pippot/Superadditive-cooperation-LLMs.",
      "pdf_url": "http://arxiv.org/pdf/2508.15510v1",
      "published": "2025-08-21T12:36:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.15510v1",
      "categories": [
        "cs.AI",
        "I.2.11; I.2.0; J.4; K.4.0; I.2.6"
      ]
    },
    {
      "title": "Think in Blocks: Adaptive Reasoning from Direct Response to Deep Reasoning",
      "authors": [
        "Yekun Zhu",
        "Guang Chen",
        "Chengjun Mao"
      ],
      "abstract": "Large Language Models (LLMs) with chains-of-thought have demonstrated strong\nperformance on an increasing range of tasks, particularly those involving\ncomplex logical reasoning. However, excessively long chains can lead to\noverthinking, causing computational waste and slower responses. This raises a\nquestion: can LLMs dynamically adjust the length of their reasoning processes\nbased on task complexity? To address this, we propose the Think in Blocks\nframework, which enables adaptive reasoning-from zero to deep reasoning-by\npartitioning the reasoning process into a tunable number of blocks. Our main\ncontributions are: (1) Establishing an explicit block-structured paradigm in\nwhich the model first predicts an integer reasoning budget-the number of\nblocks-and then partitions its reasoning accordingly; (2) Training an adaptive\nmodel through a three-stage pipeline-Supervised Fine-Tuning, reward-guided\nDirect Preference Optimization, and Reinforcement Learning-that adjusts its\nreasoning depth to problem difficulty; (3) Exploiting the explicit block count\nto dynamically control reasoning depth at inference time, allowing flexible\nadjustment of chain-of-thought length during deployment.",
      "pdf_url": "http://arxiv.org/pdf/2508.15507v1",
      "published": "2025-08-21T12:32:19+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.15507v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "LLM-Driven Self-Refinement for Embodied Drone Task Planning",
      "authors": [
        "Deyu Zhang",
        "Xicheng Zhang",
        "Jiahao Li",
        "Tingting Long",
        "Xunhua Dai",
        "Yongjian Fu",
        "Jinrui Zhang",
        "Ju Ren",
        "Yaoxue Zhang"
      ],
      "abstract": "We introduce SRDrone, a novel system designed for self-refinement task\nplanning in industrial-grade embodied drones. SRDrone incorporates two key\ntechnical contributions: First, it employs a continuous state evaluation\nmethodology to robustly and accurately determine task outcomes and provide\nexplanatory feedback. This approach supersedes conventional reliance on\nsingle-frame final-state assessment for continuous, dynamic drone operations.\nSecond, SRDrone implements a hierarchical Behavior Tree (BT) modification\nmodel. This model integrates multi-level BT plan analysis with a constrained\nstrategy space to enable structured reflective learning from experience.\nExperimental results demonstrate that SRDrone achieves a 44.87% improvement in\nSuccess Rate (SR) over baseline methods. Furthermore, real-world deployment\nutilizing an experience base optimized through iterative self-refinement\nattains a 96.25% SR. By embedding adaptive task refinement capabilities within\nan industrial-grade BT planning framework, SRDrone effectively integrates the\ngeneral reasoning intelligence of Large Language Models (LLMs) with the\nstringent physical execution constraints inherent to embodied drones. Code is\navailable at https://github.com/ZXiiiC/SRDrone.",
      "pdf_url": "http://arxiv.org/pdf/2508.15501v1",
      "published": "2025-08-21T12:29:01+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.15501v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "LGMSNet: Thinning a medical image segmentation model via dual-level multiscale fusion",
      "authors": [
        "Chengqi Dong",
        "Fenghe Tang",
        "Rongge Mao",
        "Xinpei Gao",
        "S. Kevin Zhou"
      ],
      "abstract": "Medical image segmentation plays a pivotal role in disease diagnosis and\ntreatment planning, particularly in resource-constrained clinical settings\nwhere lightweight and generalizable models are urgently needed. However,\nexisting lightweight models often compromise performance for efficiency and\nrarely adopt computationally expensive attention mechanisms, severely\nrestricting their global contextual perception capabilities. Additionally,\ncurrent architectures neglect the channel redundancy issue under the same\nconvolutional kernels in medical imaging, which hinders effective feature\nextraction. To address these challenges, we propose LGMSNet, a novel\nlightweight framework based on local and global dual multiscale that achieves\nstate-of-the-art performance with minimal computational overhead. LGMSNet\nemploys heterogeneous intra-layer kernels to extract local high-frequency\ninformation while mitigating channel redundancy. In addition, the model\nintegrates sparse transformer-convolutional hybrid branches to capture\nlow-frequency global information. Extensive experiments across six public\ndatasets demonstrate LGMSNet's superiority over existing state-of-the-art\nmethods. In particular, LGMSNet maintains exceptional performance in zero-shot\ngeneralization tests on four unseen datasets, underscoring its potential for\nreal-world deployment in resource-limited medical scenarios. The whole project\ncode is in https://github.com/cq-dong/LGMSNet.",
      "pdf_url": "http://arxiv.org/pdf/2508.15476v1",
      "published": "2025-08-21T11:54:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.15476v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Subjective Behaviors and Preferences in LLM: Language of Browsing",
      "authors": [
        "Sai Sundaresan",
        "Harshita Chopra",
        "Atanu R. Sinha",
        "Koustava Goswami",
        "Nagasai Saketh Naidu",
        "Raghav Karan",
        "N Anushka"
      ],
      "abstract": "A Large Language Model (LLM) offers versatility across domains and tasks,\npurportedly benefiting users with a wide variety of behaviors and preferences.\nWe question this perception about an LLM when users have inherently subjective\nbehaviors and preferences, as seen in their ubiquitous and idiosyncratic\nbrowsing of websites or apps. The sequential behavior logs of pages, thus\ngenerated, form something akin to each user's self-constructed \"language\",\nalbeit without the structure and grammar imbued in natural languages. We ask:\n(i) Can a small LM represent the \"language of browsing\" better than a large LM?\n(ii) Can an LM with a single set of parameters (or, single LM) adequately\ncapture myriad users' heterogeneous, subjective behaviors and preferences?\n(iii) Can a single LM with high average performance, yield low variance in\nperformance to make alignment good at user level? We introduce clusterwise LM\ntraining, HeTLM (Heterogeneity aware Training of Language Model), appropriate\nfor subjective behaviors. We find that (i) a small LM trained using a\npage-level tokenizer outperforms large pretrained or finetuned LMs; (ii) HeTLM\nwith heterogeneous cluster specific set of parameters outperforms a single LM\nof the same family, controlling for the number of parameters; and (iii) a\nhigher mean and a lower variance in generation ensues, implying improved\nalignment.",
      "pdf_url": "http://arxiv.org/pdf/2508.15474v1",
      "published": "2025-08-21T11:50:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.15474v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "RadReason: Radiology Report Evaluation Metric with Reasons and Sub-Scores",
      "authors": [
        "Yingshu Li",
        "Yunyi Liu",
        "Lingqiao Liu",
        "Lei Wang",
        "Luping Zhou"
      ],
      "abstract": "Evaluating automatically generated radiology reports remains a fundamental\nchallenge due to the lack of clinically grounded, interpretable, and\nfine-grained metrics. Existing methods either produce coarse overall scores or\nrely on opaque black-box models, limiting their usefulness in real-world\nclinical workflows. We introduce RadReason, a novel evaluation framework for\nradiology reports that not only outputs fine-grained sub-scores across six\nclinically defined error types, but also produces human-readable justifications\nthat explain the rationale behind each score. Our method builds on Group\nRelative Policy Optimization and incorporates two key innovations: (1)\nSub-score Dynamic Weighting, which adaptively prioritizes clinically\nchallenging error types based on live F1 statistics; and (2) Majority-Guided\nAdvantage Scaling, which adjusts policy gradient updates based on prompt\ndifficulty derived from sub-score agreement. Together, these components enable\nmore stable optimization and better alignment with expert clinical judgment.\nExperiments on the ReXVal benchmark show that RadReason surpasses all prior\noffline metrics and achieves parity with GPT-4-based evaluations, while\nremaining explainable, cost-efficient, and suitable for clinical deployment.\nCode will be released upon publication.",
      "pdf_url": "http://arxiv.org/pdf/2508.15464v1",
      "published": "2025-08-21T11:34:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.15464v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "A Solvable Molecular Switch Model for Stable Temporal Information Processing",
      "authors": [
        "H. I. Nurdin",
        "C. A. Nijhuis"
      ],
      "abstract": "This paper studies an input-driven one-state differential equation model\ninitially developed for an experimentally demonstrated dynamic molecular switch\nthat switches like synapses in the brain do. The linear-in-the-state and\nnonlinear-in-the-input model is exactly solvable, and it is shown that it also\npossesses mathematical properties of convergence and fading memory that enable\nstable processing of time-varying inputs by nonlinear dynamical systems. Thus,\nthe model exhibits the co-existence of biologically-inspired behavior and\ndesirable mathematical properties for stable learning on sequential data. The\nresults give theoretical support for the use of the dynamic molecular switches\nas computational units in deep cascaded/layered feedforward and recurrent\narchitectures as well as other more general structures for neuromorphic\ncomputing. They could also inspire more general exactly solvable models that\ncan be fitted to emulate arbitrary physical devices which can mimic\nbrain-inspired behaviour and perform stable computation on input signals.",
      "pdf_url": "http://arxiv.org/pdf/2508.15451v1",
      "published": "2025-08-21T11:13:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.15451v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.ET",
        "cs.SY",
        "eess.SY"
      ]
    },
    {
      "title": "Reliable Unlearning Harmful Information in LLMs with Metamorphosis Representation Projection",
      "authors": [
        "Chengcan Wu",
        "Zeming Wei",
        "Huanran Chen",
        "Yinpeng Dong",
        "Meng Sun"
      ],
      "abstract": "While Large Language Models (LLMs) have demonstrated impressive performance\nin various domains and tasks, concerns about their safety are becoming\nincreasingly severe. In particular, since models may store unsafe knowledge\ninternally, machine unlearning has emerged as a representative paradigm to\nensure model safety. Existing approaches employ various training techniques,\nsuch as gradient ascent and negative preference optimization, in attempts to\neliminate the influence of undesired data on target models. However, these\nmethods merely suppress the activation of undesired data through parametric\ntraining without completely eradicating its informational traces within the\nmodel. This fundamental limitation makes it difficult to achieve effective\ncontinuous unlearning, rendering these methods vulnerable to relearning\nattacks. To overcome these challenges, we propose a Metamorphosis\nRepresentation Projection (MRP) approach that pioneers the application of\nirreversible projection properties to machine unlearning. By implementing\nprojective transformations in the hidden state space of specific network\nlayers, our method effectively eliminates harmful information while preserving\nuseful knowledge. Experimental results demonstrate that our approach enables\neffective continuous unlearning and successfully defends against relearning\nattacks, achieving state-of-the-art performance in unlearning effectiveness\nwhile preserving natural performance. Our code is available in\nhttps://github.com/ChengcanWu/MRP.",
      "pdf_url": "http://arxiv.org/pdf/2508.15449v1",
      "published": "2025-08-21T11:12:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.15449v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68T07",
        "I.2.6"
      ]
    },
    {
      "title": "From Bits to Boardrooms: A Cutting-Edge Multi-Agent LLM Framework for Business Excellence",
      "authors": [
        "Zihao Wang",
        "Junming Zhang"
      ],
      "abstract": "Large Language Models (LLMs) have shown promising potential in business\napplications, particularly in enterprise decision support and strategic\nplanning, yet current approaches often struggle to reconcile intricate\noperational analyses with overarching strategic goals across diverse market\nenvironments, leading to fragmented workflows and reduced collaboration across\norganizational levels. This paper introduces BusiAgent, a novel multi-agent\nframework leveraging LLMs for advanced decision-making in complex corporate\nenvironments. BusiAgent integrates three core innovations: an extended\nContinuous Time Markov Decision Process (CTMDP) for dynamic agent modeling, a\ngeneralized entropy measure to optimize collaborative efficiency, and a\nmulti-level Stackelberg game to handle hierarchical decision processes.\nAdditionally, contextual Thompson sampling is employed for prompt optimization,\nsupported by a comprehensive quality assurance system to mitigate errors.\nExtensive empirical evaluations across diverse business scenarios validate\nBusiAgent's efficacy, demonstrating its capacity to generate coherent,\nclient-focused solutions that smoothly integrate granular insights with\nhigh-level strategy, significantly outperforming established approaches in both\nsolution quality and user satisfaction. By fusing cutting-edge AI technologies\nwith deep business insights, BusiAgent marks a substantial step forward in\nAI-driven enterprise decision-making, empowering organizations to navigate\ncomplex business landscapes more effectively.",
      "pdf_url": "http://arxiv.org/pdf/2508.15447v1",
      "published": "2025-08-21T11:08:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.15447v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Mitigating Hallucinations in LM-Based TTS Models via Distribution Alignment Using GFlowNets",
      "authors": [
        "Chenlin Liu",
        "Minghui Fang",
        "Patrick Zhang",
        "Wei Zhou",
        "Jie Gao",
        "Jiqing Han"
      ],
      "abstract": "Language Model (LM)-based Text-to-Speech (TTS) systems often generate\nhallucinated speech that deviates from input text. Existing mitigation\nstrategies either demand excessive training resources or introduce significant\ninference latency. In this paper, we propose GFlOwNet-guided distribution\nAlignmenT (GOAT) for LM-based TTS, a post-training framework that mitigates\nhallucinations without relying on massive resources or inference cost.\nSpecifically, we first conduct an uncertainty analysis, revealing a strong\npositive correlation between hallucination and model uncertainty. Based on\nthis, we reformulate TTS generation as a trajectory flow optimization problem\nand introduce an enhanced Subtrajectory Balance objective together with a\nsharpened internal reward as target distribution. We further integrate reward\ntemperature decay and learning rate optimization for stability and performance\nbalance. Extensive experiments show that GOAT reduce over 50% character error\nrates on challenging test cases and lowering uncertainty by up to 58%,\ndemonstrating its strong generalization ability and effectiveness.",
      "pdf_url": "http://arxiv.org/pdf/2508.15442v1",
      "published": "2025-08-21T11:04:33+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.15442v1",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.SD"
      ]
    },
    {
      "title": "Test-time Corpus Feedback: From Retrieval to RAG",
      "authors": [
        "Mandeep Rathee",
        "Venktesh V",
        "Sean MacAvaney",
        "Avishek Anand"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) has emerged as a standard framework for\nknowledge-intensive NLP tasks, combining large language models (LLMs) with\ndocument retrieval from external corpora. Despite its widespread use, most RAG\npipelines continue to treat retrieval and reasoning as isolated components,\nretrieving documents once and then generating answers without further\ninteraction. This static design often limits performance on complex tasks that\nrequire iterative evidence gathering or high-precision retrieval. Recent work\nin both the information retrieval (IR) and NLP communities has begun to close\nthis gap by introducing adaptive retrieval and ranking methods that incorporate\nfeedback. In this survey, we present a structured overview of advanced\nretrieval and ranking mechanisms that integrate such feedback. We categorize\nfeedback signals based on their source and role in improving the query,\nretrieved context, or document pool. By consolidating these developments, we\naim to bridge IR and NLP perspectives and highlight retrieval as a dynamic,\nlearnable component of end-to-end RAG systems.",
      "pdf_url": "http://arxiv.org/pdf/2508.15437v1",
      "published": "2025-08-21T10:57:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.15437v1",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "GraSP: A Unified Graph-Based Framework for Scalable Generation, Quality Tagging, and Management of Synthetic Data for SFT and DPO",
      "authors": [
        "Bidyapati Pradhan",
        "Surajit Dasgupta",
        "Amit Kumar Saha",
        "Omkar Anustoop",
        "Sriram Puttagunta",
        "Vipul Mittal",
        "Gopal Sarda"
      ],
      "abstract": "The advancement of large language models (LLMs) is critically dependent on\nthe availability of high-quality datasets for Supervised Fine-Tuning (SFT),\nalignment tasks like Direct Preference Optimization (DPO), etc. In this work,\nwe present a comprehensive synthetic data generation framework that facilitates\nscalable, configurable, and high-fidelity generation of synthetic data tailored\nfor these training paradigms. Our approach employs a modular and\nconfiguration-based pipeline capable of modeling complex dialogue flows with\nminimal manual intervention. This framework uses a dual-stage quality tagging\nmechanism, combining heuristic rules and LLM-based evaluations, to\nautomatically filter and score data extracted from OASST-formatted\nconversations, ensuring the curation of high-quality dialogue samples. The\nresulting datasets are structured under a flexible schema supporting both SFT\nand DPO use cases, enabling seamless integration into diverse training\nworkflows. Together, these innovations offer a robust solution for generating\nand managing synthetic conversational data at scale, significantly reducing the\noverhead of data preparation in LLM training pipelines.",
      "pdf_url": "http://arxiv.org/pdf/2508.15432v1",
      "published": "2025-08-21T10:35:41+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.15432v1",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    },
    {
      "title": "An Empirical Study of Knowledge Distillation for Code Understanding Tasks",
      "authors": [
        "Ruiqi Wang",
        "Zezhou Yang",
        "Cuiyun Gao",
        "Xin Xia",
        "Qing Liao"
      ],
      "abstract": "Pre-trained language models (PLMs) have emerged as powerful tools for code\nunderstanding. However, deploying these PLMs in large-scale applications faces\npractical challenges due to their computational intensity and inference\nlatency. Knowledge distillation (KD), a promising model compression and\nacceleration technique, addresses these limitations by transferring knowledge\nfrom large teacher models to compact student models, enabling efficient\ninference while preserving most of the teacher models' capabilities. While this\ntechnique has shown remarkable success in natural language processing and\ncomputer vision domains, its potential for code understanding tasks remains\nlargely underexplored.\n  In this paper, we systematically investigate the effectiveness and usage of\nKD in code understanding tasks. Our study encompasses two popular types of KD\nmethods, i.e., logit-based and feature-based KD methods, experimenting across\neight student models and two teacher PLMs from different domains on three\ndownstream tasks. The experimental results indicate that KD consistently offers\nnotable performance boosts across student models with different sizes compared\nwith standard fine-tuning. Notably, code-specific PLM demonstrates better\neffectiveness as the teacher model. Among all KD methods, the latest\nfeature-based KD methods exhibit superior performance, enabling student models\nto retain up to 98% teacher performance with merely 5% parameters. Regarding\nstudent architecture, our experiments reveal that similarity with teacher\narchitecture does not necessarily lead to better performance. We further\ndiscuss the efficiency and behaviors in the KD process and inference, summarize\nthe implications of findings, and identify promising future directions.",
      "pdf_url": "http://arxiv.org/pdf/2508.15423v1",
      "published": "2025-08-21T10:24:48+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.15423v1",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "LLaSO: A Foundational Framework for Reproducible Research in Large Language and Speech Model",
      "authors": [
        "Yirong Sun",
        "Yizhong Geng",
        "Peidong Wei",
        "Yanjun Chen",
        "Jinghan Yang",
        "Rongfei Chen",
        "Wei Zhang",
        "Xiaoyu Shen"
      ],
      "abstract": "The development of Large Speech-Language Models (LSLMs) has been slowed by\nfragmented architectures and a lack of transparency, hindering the systematic\ncomparison and reproducibility of research. Unlike in the vision-language\ndomain, the LSLM field suffers from the common practice of releasing model\nweights without their corresponding training data and configurations. To\naddress these critical gaps, we introduce LLaSO, the first fully open,\nend-to-end framework for large-scale speech-language modeling. LLaSO provides\nthe community with three essential resources: (1) LLaSO-Align, a 12M-instance\nspeech-text alignment corpus; (2) LLaSO-Instruct, a 13.5M-instance multi-task\ninstruction-tuning dataset; and (3) LLaSO-Eval, a reproducible benchmark for\nstandardized evaluation. To validate our framework, we build and release\nLLaSO-Base, a 3.8B-parameter reference model trained exclusively on our public\ndata. It achieves a normalized score of 0.72, establishing a strong,\nreproducible baseline that surpasses comparable models. Our analysis reveals\nthat while broader training coverage enhances performance, significant\ngeneralization gaps persist on unseen tasks, particularly in pure audio\nscenarios. By releasing the complete stack of data, benchmarks, and models,\nLLaSO establishes a foundational open standard to unify research efforts and\naccelerate community-driven progress in LSLMs. We release the code, dataset,\npretrained models, and results in https://github.com/EIT-NLP/LLaSO.",
      "pdf_url": "http://arxiv.org/pdf/2508.15418v1",
      "published": "2025-08-21T10:20:00+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.15418v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.MM",
        "cs.SD"
      ]
    },
    {
      "title": "Bridging Generalization and Personalization in Wearable Human Activity Recognition via On-Device Few-Shot Learning",
      "authors": [
        "Pixi Kang",
        "Julian Moosmann",
        "Mengxi Liu",
        "Bo Zhou",
        "Michele Magno",
        "Paul Lukowicz",
        "Sizhen Bian"
      ],
      "abstract": "Human Activity Recognition (HAR) using wearable devices has advanced\nsignificantly in recent years, yet its generalization remains limited when\nmodels are deployed to new users. This degradation in performance is primarily\ndue to user-induced concept drift (UICD), highlighting the importance of\nefficient personalization. In this paper, we present a hybrid framework that\nfirst generalizes across users and then rapidly adapts to individual users\nusing few-shot learning directly on-device. By updating only the classifier\nlayer with user-specific data, our method achieves robust personalization with\nminimal computational and memory overhead. We implement this framework on the\nenergy-efficient RISC-V-based GAP9 microcontroller and validate it across three\ndiverse HAR scenarios: RecGym, QVAR-Gesture, and Ultrasound-Gesture.\nPost-deployment adaptation yields consistent accuracy improvements of 3.73\\%,\n17.38\\%, and 3.70\\% respectively. These results confirm that fast, lightweight,\nand effective personalization is feasible on embedded platforms, paving the way\nfor scalable and user-aware HAR systems in the wild\n\\footnote{https://github.com/kangpx/onlineTiny2023}.",
      "pdf_url": "http://arxiv.org/pdf/2508.15413v1",
      "published": "2025-08-21T10:08:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.15413v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "When Audio and Text Disagree: Revealing Text Bias in Large Audio-Language Models",
      "authors": [
        "Cheng Wang",
        "Gelei Deng",
        "Xianglin Yang",
        "Han Qiu",
        "Tianwei Zhang"
      ],
      "abstract": "Large Audio-Language Models (LALMs) are enhanced with audio perception\ncapabilities, enabling them to effectively process and understand multimodal\ninputs that combine audio and text. However, their performance in handling\nconflicting information between audio and text modalities remains largely\nunexamined. This paper introduces MCR-BENCH, the first comprehensive benchmark\nspecifically designed to evaluate how LALMs prioritize information when\npresented with inconsistent audio-text pairs. Through extensive evaluation\nacross diverse audio understanding tasks, we reveal a concerning phenomenon:\nwhen inconsistencies exist between modalities, LALMs display a significant bias\ntoward textual input, frequently disregarding audio evidence. This tendency\nleads to substantial performance degradation in audio-centric tasks and raises\nimportant reliability concerns for real-world applications. We further\ninvestigate the influencing factors of text bias, and explore mitigation\nstrategies through supervised finetuning, and analyze model confidence patterns\nthat reveal persistent overconfidence even with contradictory inputs. These\nfindings underscore the need for improved modality balance during training and\nmore sophisticated fusion mechanisms to enhance the robustness when handling\nconflicting multi-modal inputs. The project is available at\nhttps://github.com/WangCheng0116/MCR-BENCH.",
      "pdf_url": "http://arxiv.org/pdf/2508.15407v1",
      "published": "2025-08-21T09:58:24+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.15407v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Hybrid Least Squares/Gradient Descent Methods for DeepONets",
      "authors": [
        "Jun Choi",
        "Chang-Ock Lee",
        "Minam Moon"
      ],
      "abstract": "We propose an efficient hybrid least squares/gradient descent method to\naccelerate DeepONet training. Since the output of DeepONet can be viewed as\nlinear with respect to the last layer parameters of the branch network, these\nparameters can be optimized using a least squares (LS) solve, and the remaining\nhidden layer parameters are updated by means of gradient descent form. However,\nbuilding the LS system for all possible combinations of branch and trunk inputs\nyields a prohibitively large linear problem that is infeasible to solve\ndirectly. To address this issue, our method decomposes the large LS system into\ntwo smaller, more manageable subproblems $\\unicode{x2014}$ one for the branch\nnetwork and one for the trunk network $\\unicode{x2014}$ and solves them\nseparately. This method is generalized to a broader type of $L^2$ loss with a\nregularization term for the last layer parameters, including the case of\nunsupervised learning with physics-informed loss.",
      "pdf_url": "http://arxiv.org/pdf/2508.15394v1",
      "published": "2025-08-21T09:34:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.15394v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NA",
        "math.NA",
        "47-08, 65F45, 65Y10, 68T07, 68T20"
      ]
    },
    {
      "title": "Bladder Cancer Diagnosis with Deep Learning: A Multi-Task Framework and Online Platform",
      "authors": [
        "Jinliang Yu",
        "Mingduo Xie",
        "Yue Wang",
        "Tianfan Fu",
        "Xianglai Xu",
        "Jiajun Wang"
      ],
      "abstract": "Clinical cystoscopy, the current standard for bladder cancer diagnosis,\nsuffers from significant reliance on physician expertise, leading to\nvariability and subjectivity in diagnostic outcomes. There is an urgent need\nfor objective, accurate, and efficient computational approaches to improve\nbladder cancer diagnostics.\n  Leveraging recent advancements in deep learning, this study proposes an\nintegrated multi-task deep learning framework specifically designed for bladder\ncancer diagnosis from cystoscopic images. Our framework includes a robust\nclassification model using EfficientNet-B0 enhanced with Convolutional Block\nAttention Module (CBAM), an advanced segmentation model based on\nResNet34-UNet++ architecture with self-attention mechanisms and attention\ngating, and molecular subtyping using ConvNeXt-Tiny to classify molecular\nmarkers such as HER-2 and Ki-67. Additionally, we introduce a Gradio-based\nonline diagnostic platform integrating all developed models, providing\nintuitive features including multi-format image uploads, bilingual interfaces,\nand dynamic threshold adjustments.\n  Extensive experimentation demonstrates the effectiveness of our methods,\nachieving outstanding accuracy (93.28%), F1-score (82.05%), and AUC (96.41%)\nfor classification tasks, and exceptional segmentation performance indicated by\na Dice coefficient of 0.9091. The online platform significantly improved the\naccuracy, efficiency, and accessibility of clinical bladder cancer diagnostics,\nenabling practical and user-friendly deployment. The code is publicly\navailable.\n  Our multi-task framework and integrated online tool collectively advance the\nfield of intelligent bladder cancer diagnosis by improving clinical\nreliability, supporting early tumor detection, and enabling real-time\ndiagnostic feedback. These contributions mark a significant step toward\nAI-assisted decision-making in urology.",
      "pdf_url": "http://arxiv.org/pdf/2508.15379v1",
      "published": "2025-08-21T09:20:03+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.15379v1",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ]
    }
  ]
}