{
  "last_updated": "2025-11-06T00:52:05.679770",
  "papers": [
    {
      "title": "Agent-Omni: Test-Time Multimodal Reasoning via Model Coordination for Understanding Anything",
      "authors": [
        "Huawei Lin",
        "Yunzhi Shi",
        "Tong Geng",
        "Weijie Zhao",
        "Wei Wang",
        "Ravender Pal Singh"
      ],
      "abstract": "Multimodal large language models (MLLMs) have shown strong capabilities but\nremain limited to fixed modality pairs and require costly fine-tuning with\nlarge aligned datasets. Building fully omni-capable models that can integrate\ntext, images, audio, and video remains impractical and lacks robust reasoning\nsupport. In this paper, we propose an Agent-Omni framework that coordinates\nexisting foundation models through a master-agent system, enabling flexible\nmultimodal reasoning without retraining. The master agent interprets user\nintent, delegates subtasks to modality-specific agents, and integrates their\noutputs into coherent responses. Extensive experiments across text, image,\naudio, video, and omni benchmarks show that Agent-Omni consistently achieves\nstate-of-the-art performance, particularly on tasks requiring complex\ncross-modal reasoning. Its agent-based design enables seamless integration of\nspecialized foundation models, ensuring adaptability to diverse inputs while\nmaintaining transparency and interpretability. In addition, the framework is\nmodular and easily extensible, allowing future improvements as stronger models\nbecome available. %We release an open-source implementation to support\ncontinued research on scalable and reliable omni-modal reasoning.",
      "pdf_url": "http://arxiv.org/pdf/2511.02834v1",
      "published": "2025-11-04T18:59:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.02834v1",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    },
    {
      "title": "Neurosymbolic Deep Learning Semantics",
      "authors": [
        "Artur d'Avila Garcez",
        "Simon Odense"
      ],
      "abstract": "Artificial Intelligence (AI) is a powerful new language of science as\nevidenced by recent Nobel Prizes in chemistry and physics that recognized\ncontributions to AI applied to those areas. Yet, this new language lacks\nsemantics, which makes AI's scientific discoveries unsatisfactory at best. With\nthe purpose of uncovering new facts but also improving our understanding of the\nworld, AI-based science requires formalization through a framework capable of\ntranslating insight into comprehensible scientific knowledge. In this paper, we\nargue that logic offers an adequate framework. In particular, we use logic in a\nneurosymbolic framework to offer a much needed semantics for deep learning, the\nneural network-based technology of current AI. Deep learning and neurosymbolic\nAI lack a general set of conditions to ensure that desirable properties are\nsatisfied. Instead, there is a plethora of encoding and knowledge extraction\napproaches designed for particular cases. To rectify this, we introduced a\nframework for semantic encoding, making explicit the mapping between neural\nnetworks and logic, and characterizing the common ingredients of the various\nexisting approaches. In this paper, we describe succinctly and exemplify how\nlogical semantics and neural networks are linked through this framework, we\nreview some of the most prominent approaches and techniques developed for\nneural encoding and knowledge extraction, provide a formal definition of our\nframework, and discuss some of the difficulties of identifying a semantic\nencoding in practice in light of analogous problems in the philosophy of mind.",
      "pdf_url": "http://arxiv.org/pdf/2511.02825v1",
      "published": "2025-11-04T18:51:04+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.02825v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Kosmos: An AI Scientist for Autonomous Discovery",
      "authors": [
        "Ludovico Mitchener",
        "Angela Yiu",
        "Benjamin Chang",
        "Mathieu Bourdenx",
        "Tyler Nadolski",
        "Arvis Sulovari",
        "Eric C. Landsness",
        "Daniel L. Barabasi",
        "Siddharth Narayanan",
        "Nicky Evans",
        "Shriya Reddy",
        "Martha Foiani",
        "Aizad Kamal",
        "Leah P. Shriver",
        "Fang Cao",
        "Asmamaw T. Wassie",
        "Jon M. Laurent",
        "Edwin Melville-Green",
        "Mayk Caldas",
        "Albert Bou",
        "Kaleigh F. Roberts",
        "Sladjana Zagorac",
        "Timothy C. Orr",
        "Miranda E. Orr",
        "Kevin J. Zwezdaryk",
        "Ali E. Ghareeb",
        "Laurie McCoy",
        "Bruna Gomes",
        "Euan A. Ashley",
        "Karen E. Duff",
        "Tonio Buonassisi",
        "Tom Rainforth",
        "Randall J. Bateman",
        "Michael Skarlinski",
        "Samuel G. Rodriques",
        "Michaela M. Hinks",
        "Andrew D. White"
      ],
      "abstract": "Data-driven scientific discovery requires iterative cycles of literature\nsearch, hypothesis generation, and data analysis. Substantial progress has been\nmade towards AI agents that can automate scientific research, but all such\nagents remain limited in the number of actions they can take before losing\ncoherence, thus limiting the depth of their findings. Here we present Kosmos,\nan AI scientist that automates data-driven discovery. Given an open-ended\nobjective and a dataset, Kosmos runs for up to 12 hours performing cycles of\nparallel data analysis, literature search, and hypothesis generation before\nsynthesizing discoveries into scientific reports. Unlike prior systems, Kosmos\nuses a structured world model to share information between a data analysis\nagent and a literature search agent. The world model enables Kosmos to\ncoherently pursue the specified objective over 200 agent rollouts, collectively\nexecuting an average of 42,000 lines of code and reading 1,500 papers per run.\nKosmos cites all statements in its reports with code or primary literature,\nensuring its reasoning is traceable. Independent scientists found 79.4% of\nstatements in Kosmos reports to be accurate, and collaborators reported that a\nsingle 20-cycle Kosmos run performed the equivalent of 6 months of their own\nresearch time on average. Furthermore, collaborators reported that the number\nof valuable scientific findings generated scales linearly with Kosmos cycles\n(tested up to 20 cycles). We highlight seven discoveries made by Kosmos that\nspan metabolomics, materials science, neuroscience, and statistical genetics.\nThree discoveries independently reproduce findings from preprinted or\nunpublished manuscripts that were not accessed by Kosmos at runtime, while four\nmake novel contributions to the scientific literature.",
      "pdf_url": "http://arxiv.org/pdf/2511.02824v1",
      "published": "2025-11-04T18:50:52+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.02824v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Optimizing AI Agent Attacks With Synthetic Data",
      "authors": [
        "Chloe Loughridge",
        "Paul Colognese",
        "Avery Griffin",
        "Tyler Tracy",
        "Jon Kutasov",
        "Joe Benton"
      ],
      "abstract": "As AI deployments become more complex and high-stakes, it becomes\nincreasingly important to be able to estimate their risk. AI control is one\nframework for doing so. However, good control evaluations require eliciting\nstrong attack policies. This can be challenging in complex agentic environments\nwhere compute constraints leave us data-poor. In this work, we show how to\noptimize attack policies in SHADE-Arena, a dataset of diverse realistic control\nenvironments. We do this by decomposing attack capability into five constituent\nskills -- suspicion modeling, attack selection, plan synthesis, execution and\nsubtlety -- and optimizing each component individually. To get around the\nconstraint of limited data, we develop a probabilistic model of attack\ndynamics, optimize our attack hyperparameters using this simulation, and then\nshow that the results transfer to SHADE-Arena. This results in a substantial\nimprovement in attack strength, reducing safety score from a baseline of 0.87\nto 0.41 using our scaffold.",
      "pdf_url": "http://arxiv.org/pdf/2511.02823v1",
      "published": "2025-11-04T18:48:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.02823v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Orion-MSP: Multi-Scale Sparse Attention for Tabular In-Context Learning",
      "authors": [
        "Mohamed Bouadi",
        "Pratinav Seth",
        "Aditya Tanna",
        "Vinay Kumar Sankarapu"
      ],
      "abstract": "Tabular data remain the predominant format for real-world applications. Yet,\ndeveloping effective neural models for tabular data remains challenging due to\nheterogeneous feature types and complex interactions occurring at multiple\nscales. Recent advances in tabular in-context learning (ICL), such as TabPFN\nand TabICL, have achieved state-of-the-art performance comparable to\ngradient-boosted trees (GBTs) without task-specific fine-tuning. However,\ncurrent architectures exhibit key limitations: (1) single-scale feature\nprocessing that overlooks hierarchical dependencies, (2) dense attention with\nquadratic scaling in table width, and (3) strictly sequential component\nprocessing that prevents iterative representation refinement and\ncross-component communication. To address these challenges, we introduce\nOrion-MSP, a tabular ICL architecture featuring three key innovations: (1)\nmulti-scale processing to capture hierarchical feature interactions; (2)\nblock-sparse attention combining windowed, global, and random patterns for\nscalable efficiency and long-range connectivity; and (3) a Perceiver-style\nmemory enabling safe bidirectional information flow across components. Across\ndiverse benchmarks, Orion-MSP matches or surpasses state-of-the-art performance\nwhile scaling effectively to high-dimensional tables, establishing a new\nstandard for efficient tabular in-context learning. The model is publicly\navailable at https://github.com/Lexsi-Labs/Orion-MSP .",
      "pdf_url": "http://arxiv.org/pdf/2511.02818v1",
      "published": "2025-11-04T18:43:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.02818v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Oolong: Evaluating Long Context Reasoning and Aggregation Capabilities",
      "authors": [
        "Amanda Bertsch",
        "Adithya Pratapa",
        "Teruko Mitamura",
        "Graham Neubig",
        "Matthew R. Gormley"
      ],
      "abstract": "As model context lengths continue to grow, concerns about whether models\neffectively use the full context length have persisted. While several carefully\ndesigned long-context evaluations have recently been released, these\nevaluations tend to rely on retrieval from one or more sections of the context,\nwhich allows nearly all of the context tokens to be disregarded as noise. This\nrepresents only one type of task that might be performed with long context. We\nintroduce Oolong, a benchmark of long-context reasoning tasks that require\nanalyzing individual chunks of text on an atomic level, and then aggregating\nthese analyses to answer distributional questions. Oolong is separated into two\ntask sets: Oolong-synth, a set of naturalistic synthetic tasks, where we can\neasily ablate components of the reasoning problem; and Oolong-real, a\ndownstream setting which requires reasoning over real-world conversational\ndata. Oolong requires models to reason over large quantities of examples, to\nperform both classification and counting in-context, and to reason over\ntemporal and user relations. Even frontier models struggle on Oolong, with\nGPT-5, Claude-Sonnet-4, and Gemini-2.5-Pro all achieving less than 50% accuracy\non both splits at 128K. We release the data and evaluation harness for Oolong\nto enable further development of models that can reason over large quantities\nof text.",
      "pdf_url": "http://arxiv.org/pdf/2511.02817v1",
      "published": "2025-11-04T18:42:12+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.02817v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Assessing win strength in MLB win prediction models",
      "authors": [
        "Morgan Allen",
        "Paul Savala"
      ],
      "abstract": "In Major League Baseball, strategy and planning are major factors in\ndetermining the outcome of a game. Previous studies have aided this by building\nmachine learning models for predicting the winning team of any given game. We\nextend this work by training a comprehensive set of machine learning models\nusing a common dataset. In addition, we relate the win probabilities produced\nby these models to win strength as measured by score differential. In doing so\nwe show that the most common machine learning models do indeed demonstrate a\nrelationship between predicted win probability and the strength of the win.\nFinally, we analyze the results of using predicted win probabilities as a\ndecision making mechanism on run-line betting. We demonstrate positive returns\nwhen utilizing appropriate betting strategies, and show that naive use of\nmachine learning models for betting lead to significant loses.",
      "pdf_url": "http://arxiv.org/pdf/2511.02815v1",
      "published": "2025-11-04T18:40:10+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.02815v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "MemSearcher: Training LLMs to Reason, Search and Manage Memory via End-to-End Reinforcement Learning",
      "authors": [
        "Qianhao Yuan",
        "Jie Lou",
        "Zichao Li",
        "Jiawei Chen",
        "Yaojie Lu",
        "Hongyu Lin",
        "Le Sun",
        "Debing Zhang",
        "Xianpei Han"
      ],
      "abstract": "Typical search agents concatenate the entire interaction history into the LLM\ncontext, preserving information integrity but producing long, noisy contexts,\nresulting in high computation and memory costs. In contrast, using only the\ncurrent turn avoids this overhead but discards essential information. This\ntrade-off limits the scalability of search agents. To address this challenge,\nwe propose MemSearcher, an agent workflow that iteratively maintains a compact\nmemory and combines the current turn with it. At each turn, MemSearcher fuses\nthe user's question with the memory to generate reasoning traces, perform\nsearch actions, and update memory to retain only information essential for\nsolving the task. This design stabilizes context length across multi-turn\ninteractions, improving efficiency without sacrificing accuracy. To optimize\nthis workflow, we introduce multi-context GRPO, an end-to-end RL framework that\njointly optimize reasoning, search strategies, and memory management of\nMemSearcher Agents. Specifically, multi-context GRPO samples groups of\ntrajectories under different contexts and propagates trajectory-level\nadvantages across all conversations within them. Trained on the same dataset as\nSearch-R1, MemSearcher achieves significant improvements over strong baselines\non seven public benchmarks: +11% on Qwen2.5-3B-Instruct and +12% on\nQwen2.5-7B-Instruct relative average gains. Notably, the 3B-based MemSearcher\neven outperforms 7B-based baselines, demonstrating that striking a balance\nbetween information integrity and efficiency yields both higher accuracy and\nlower computational overhead. The code and models will be publicly available at\nhttps://github.com/icip-cas/MemSearcher",
      "pdf_url": "http://arxiv.org/pdf/2511.02805v1",
      "published": "2025-11-04T18:27:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.02805v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "TabTune: A Unified Library for Inference and Fine-Tuning Tabular Foundation Models",
      "authors": [
        "Aditya Tanna",
        "Pratinav Seth",
        "Mohamed Bouadi",
        "Utsav Avaiya",
        "Vinay Kumar Sankarapu"
      ],
      "abstract": "Tabular foundation models represent a growing paradigm in structured data\nlearning, extending the benefits of large-scale pretraining to tabular domains.\nHowever, their adoption remains limited due to heterogeneous preprocessing\npipelines, fragmented APIs, inconsistent fine-tuning procedures, and the\nabsence of standardized evaluation for deployment-oriented metrics such as\ncalibration and fairness. We present TabTune, a unified library that\nstandardizes the complete workflow for tabular foundation models through a\nsingle interface. TabTune provides consistent access to seven state-of-the-art\nmodels supporting multiple adaptation strategies, including zero-shot\ninference, meta-learning, supervised fine-tuning (SFT), and parameter-efficient\nfine-tuning (PEFT). The framework automates model-aware preprocessing, manages\narchitectural heterogeneity internally, and integrates evaluation modules for\nperformance, calibration, and fairness. Designed for extensibility and\nreproducibility, TabTune enables consistent benchmarking of adaptation\nstrategies of tabular foundation models. The library is open source and\navailable at https://github.com/Lexsi-Labs/TabTune .",
      "pdf_url": "http://arxiv.org/pdf/2511.02802v1",
      "published": "2025-11-04T18:25:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.02802v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "When One Modality Sabotages the Others: A Diagnostic Lens on Multimodal Reasoning",
      "authors": [
        "Chenyu Zhang",
        "Minsol Kim",
        "Shohreh Ghorbani",
        "Jingyao Wu",
        "Rosalind Picard",
        "Patricia Maes",
        "Paul Pu Liang"
      ],
      "abstract": "Despite rapid growth in multimodal large language models (MLLMs), their\nreasoning traces remain opaque: it is often unclear which modality drives a\nprediction, how conflicts are resolved, or when one stream dominates. In this\npaper, we introduce modality sabotage, a diagnostic failure mode in which a\nhigh-confidence unimodal error overrides other evidence and misleads the fused\nresult. To analyze such dynamics, we propose a lightweight, model-agnostic\nevaluation layer that treats each modality as an agent, producing candidate\nlabels and a brief self-assessment used for auditing. A simple fusion mechanism\naggregates these outputs, exposing contributors (modalities supporting correct\noutcomes) and saboteurs (modalities that mislead). Applying our diagnostic\nlayer in a case study on multimodal emotion recognition benchmarks with\nfoundation models revealed systematic reliability profiles, providing insight\ninto whether failures may arise from dataset artifacts or model limitations.\nMore broadly, our framework offers a diagnostic scaffold for multimodal\nreasoning, supporting principled auditing of fusion dynamics and informing\npossible interventions.",
      "pdf_url": "http://arxiv.org/pdf/2511.02794v1",
      "published": "2025-11-04T18:20:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.02794v1",
      "categories": [
        "cs.AI",
        "cs.MA"
      ]
    },
    {
      "title": "Measuring AI Diffusion: A Population-Normalized Metric for Tracking Global AI Usage",
      "authors": [
        "Amit Misra",
        "Jane Wang",
        "Scott McCullers",
        "Kevin White",
        "Juan Lavista Ferres"
      ],
      "abstract": "Measuring global AI diffusion remains challenging due to a lack of\npopulation-normalized, cross-country usage data. We introduce AI User Share, a\nnovel indicator that estimates the share of each country's working-age\npopulation actively using AI tools. Built from anonymized Microsoft telemetry\nand adjusted for device access and mobile scaling, this metric spans 147\neconomies and provides consistent, real-time insight into global AI diffusion.\nWe find wide variation in adoption, with a strong correlation between AI User\nShare and GDP. High uptake is concentrated in developed economies, though usage\namong internet-connected populations in lower-income countries reveals\nsubstantial latent demand. We also detect sharp increases in usage following\nmajor product launches, such as DeepSeek in early 2025. While the metric's\nreliance solely on Microsoft telemetry introduces potential biases related to\nthis user base, it offers an important new lens into how AI is spreading\nglobally. AI User Share enables timely benchmarking that can inform data-driven\nAI policy.",
      "pdf_url": "http://arxiv.org/pdf/2511.02781v1",
      "published": "2025-11-04T18:03:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.02781v1",
      "categories": [
        "cs.CY",
        "cs.AI"
      ]
    },
    {
      "title": "1 PoCo: Agentic Proof-of-Concept Exploit Generation for Smart Contracts",
      "authors": [
        "Vivi Andersson",
        "Sofia Bobadilla",
        "Harald Hobbelhagen",
        "Martin Monperrus"
      ],
      "abstract": "Smart contracts operate in a highly adversarial environment, where\nvulnerabilities can lead to substantial financial losses. Thus, smart contracts\nare subject to security audits. In auditing, proof-of-concept (PoC) exploits\nplay a critical role by demonstrating to the stakeholders that the reported\nvulnerabilities are genuine, reproducible, and actionable. However, manually\ncreating PoCs is time-consuming, error-prone, and often constrained by tight\naudit schedules. We introduce POCO, an agentic framework that automatically\ngenerates executable PoC exploits from natural-language vulnerability\ndescriptions written by auditors. POCO autonomously generates PoC exploits in\nan agentic manner by interacting with a set of code-execution tools in a\nReason-Act-Observe loop. It produces fully executable exploits compatible with\nthe Foundry testing framework, ready for integration into audit reports and\nother security tools. We evaluate POCO on a dataset of 23 real-world\nvulnerability reports. POCO consistently outperforms the prompting and workflow\nbaselines, generating well-formed and logically correct PoCs. Our results\ndemonstrate that agentic frameworks can significantly reduce the effort\nrequired for high-quality PoCs in smart contract audits. Our contribution\nprovides readily actionable knowledge for the smart contract security\ncommunity.",
      "pdf_url": "http://arxiv.org/pdf/2511.02780v1",
      "published": "2025-11-04T18:03:12+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.02780v1",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.SE"
      ]
    },
    {
      "title": "STAR-VAE: Latent Variable Transformers for Scalable and Controllable Molecular Generation",
      "authors": [
        "Bum Chul Kwon",
        "Ben Shapira",
        "Moshiko Raboh",
        "Shreyans Sethi",
        "Shruti Murarka",
        "Joseph A Morrone",
        "Jianying Hu",
        "Parthasarathy Suryanarayanan"
      ],
      "abstract": "The chemical space of drug-like molecules is vast, motivating the development\nof generative models that must learn broad chemical distributions, enable\nconditional generation by capturing structure-property representations, and\nprovide fast molecular generation. Meeting the objectives depends on modeling\nchoices, including the probabilistic modeling approach, the conditional\ngenerative formulation, the architecture, and the molecular input\nrepresentation. To address the challenges, we present STAR-VAE\n(Selfies-encoded, Transformer-based, AutoRegressive Variational Auto Encoder),\na scalable latent-variable framework with a Transformer encoder and an\nautoregressive Transformer decoder. It is trained on 79 million drug-like\nmolecules from PubChem, using SELFIES to guarantee syntactic validity. The\nlatent-variable formulation enables conditional generation: a property\npredictor supplies a conditioning signal that is applied consistently to the\nlatent prior, the inference network, and the decoder. Our contributions are:\n(i) a Transformer-based latent-variable encoder-decoder model trained on\nSELFIES representations; (ii) a principled conditional latent-variable\nformulation for property-guided generation; and (iii) efficient finetuning with\nlow-rank adapters (LoRA) in both encoder and decoder, enabling fast adaptation\nwith limited property and activity data. On the GuacaMol and MOSES benchmarks,\nour approach matches or exceeds baselines, and latent-space analyses reveal\nsmooth, semantically structured representations that support both unconditional\nexploration and property-aware generation. On the Tartarus benchmarks, the\nconditional model shifts docking-score distributions toward stronger predicted\nbinding. These results suggest that a modernized, scale-appropriate VAE remains\ncompetitive for molecular generation when paired with principled conditioning\nand parameter-efficient finetuning.",
      "pdf_url": "http://arxiv.org/pdf/2511.02769v1",
      "published": "2025-11-04T17:56:00+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.02769v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.BM"
      ]
    },
    {
      "title": "LLM-Supported Formal Knowledge Representation for Enhancing Control Engineering Content with an Interactive Semantic Layer",
      "authors": [
        "Julius Fiedler",
        "Carsten Knoll",
        "Klaus Röbenack"
      ],
      "abstract": "The rapid growth of research output in control engineering calls for new\napproaches to structure and formalize domain knowledge. This paper briefly\ndescribes an LLM-supported method for semi-automated generation of formal\nknowledge representations that combine human readability with machine\ninterpretability and increased expressiveness. Based on the Imperative\nRepresentation of Knowledge (PyIRK) framework, we demonstrate how language\nmodels can assist in transforming natural-language descriptions and\nmathematical definitions (available as LaTeX source code) into a formalized\nknowledge graph. As a first application we present the generation of an\n``interactive semantic layer'' to enhance the source documents in order to\nfacilitate knowledge transfer. From our perspective this contributes to the\nvision of easily accessible, collaborative, and verifiable knowledge bases for\nthe control engineering domain.",
      "pdf_url": "http://arxiv.org/pdf/2511.02759v1",
      "published": "2025-11-04T17:36:57+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.02759v1",
      "categories": [
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ]
    },
    {
      "title": "AI Diffusion in Low Resource Language Countries",
      "authors": [
        "Amit Misra",
        "Syed Waqas Zamir",
        "Wassim Hamidouche",
        "Inbal Becker-Reshef",
        "Juan Lavista Ferres"
      ],
      "abstract": "Artificial intelligence (AI) is diffusing globally at unprecedented speed,\nbut adoption remains uneven. Frontier Large Language Models (LLMs) are known to\nperform poorly on low-resource languages due to data scarcity. We hypothesize\nthat this performance deficit reduces the utility of AI, thereby slowing\nadoption in Low-Resource Language Countries (LRLCs). To test this, we use a\nweighted regression model to isolate the language effect from socioeconomic and\ndemographic factors, finding that LRLCs have a share of AI users that is\napproximately 20% lower relative to their baseline. These results indicate that\nlinguistic accessibility is a significant, independent barrier to equitable AI\ndiffusion.",
      "pdf_url": "http://arxiv.org/pdf/2511.02752v1",
      "published": "2025-11-04T17:31:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.02752v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ]
    },
    {
      "title": "Using Span Queries to Optimize for Cache and Attention Locality",
      "authors": [
        "Paul Castro",
        "Nick Mitchell",
        "Nathan Ordonez",
        "Thomas Parnell",
        "Mudhakar Srivatsa",
        "Antoni Viros i Martin"
      ],
      "abstract": "Clients are evolving beyond chat completion, and now include a variety of\ninnovative inference-time scaling and deep reasoning techniques. At the same\ntime, inference servers remain heavily optimized for chat completion. Prior\nwork has shown that large improvements to KV cache hit rate are possible if\ninference servers evolve towards these non-chat use cases. However, they offer\nsolutions that are also optimized for a single use case, RAG. In this paper, we\nintroduce the span query to generalize the interface to the inference server.\nWe demonstrate that chat, RAG, inference-time scaling, and agentic workloads\ncan all be expressed as span queries. We show how the critical distinction that\nhad been assumed by prior work lies in whether the order of the inputs matter\n-- do they commute? In chat, they do not. In RAG, they often do. This paper\nintroduces span queries, which are expression trees of inference calls, linked\ntogether with commutativity constraints. We describe span query syntax and\nsemantics. We show how they can be automatically optimized to improve KV cache\nlocality. We show how a small change to vLLM (affecting only 492 lines) can\nenable high-performance execution of span queries. Using this stack, we\ndemonstrate that span queries can achieve 10-20x reductions in TTFT for two\ndistinct non-chat use cases. Finally, we show that span queries can also be\noptimized to improve attention locality, so as to avoid the so-called\nlost-in-the-middle problem. We demonstrate that an attention-optimized span\nquery on a 2b parameter model vastly outperforms the accuracy of a stock\ninference server using an 8b model.",
      "pdf_url": "http://arxiv.org/pdf/2511.02749v1",
      "published": "2025-11-04T17:22:49+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.02749v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "CostBench: Evaluating Multi-Turn Cost-Optimal Planning and Adaptation in Dynamic Environments for LLM Tool-Use Agents",
      "authors": [
        "Jiayu Liu",
        "Cheng Qian",
        "Zhaochen Su",
        "Qing Zong",
        "Shijue Huang",
        "Bingxiang He",
        "Yi R. Fung"
      ],
      "abstract": "Current evaluations of Large Language Model (LLM) agents primarily emphasize\ntask completion, often overlooking resource efficiency and adaptability. This\nneglects a crucial capability: agents' ability to devise and adjust\ncost-optimal plans in response to changing environments. To bridge this gap, we\nintroduce CostBench, a scalable, cost-centric benchmark designed to evaluate\nagents' economic reasoning and replanning abilities. Situated in the\ntravel-planning domain, CostBench comprises tasks solvable via multiple\nsequences of atomic and composite tools with diverse, customizable costs. It\nalso supports four types of dynamic blocking events, such as tool failures and\ncost changes, to simulate real-world unpredictability and necessitate agents to\nadapt in real time. Evaluating leading open-sourced and proprietary models on\nCostBench reveals a substantial gap in cost-aware planning: agents frequently\nfail to identify cost-optimal solutions in static settings, with even GPT-5\nachieving less than 75% exact match rate on the hardest tasks, and performance\nfurther dropping by around 40% under dynamic conditions. By diagnosing these\nweaknesses, CostBench lays the groundwork for developing future agents that are\nboth economically rational and robust.",
      "pdf_url": "http://arxiv.org/pdf/2511.02734v1",
      "published": "2025-11-04T16:58:29+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.02734v1",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "LLEXICORP: End-user Explainability of Convolutional Neural Networks",
      "authors": [
        "Vojtěch Kůr",
        "Adam Bajger",
        "Adam Kukučka",
        "Marek Hradil",
        "Vít Musil",
        "Tomáš Brázdil"
      ],
      "abstract": "Convolutional neural networks (CNNs) underpin many modern computer vision\nsystems. With applications ranging from common to critical areas, a need to\nexplain and understand the model and its decisions (XAI) emerged. Prior works\nsuggest that in the top layers of CNNs, the individual channels can be\nattributed to classifying human-understandable concepts. Concept relevance\npropagation (CRP) methods can backtrack predictions to these channels and find\nimages that most activate these channels. However, current CRP workflows are\nlargely manual: experts must inspect activation images to name the discovered\nconcepts and must synthesize verbose explanations from relevance maps, limiting\nthe accessibility of the explanations and their scalability.\n  To address these issues, we introduce Large Language model EXplaIns COncept\nRelevance Propagation (LLEXICORP), a modular pipeline that couples CRP with a\nmultimodal large language model. Our approach automatically assigns descriptive\nnames to concept prototypes and generates natural-language explanations that\ntranslate quantitative relevance distributions into intuitive narratives. To\nensure faithfulness, we craft prompts that teach the language model the\nsemantics of CRP through examples and enforce a separation between naming and\nexplanation tasks. The resulting text can be tailored to different audiences,\noffering low-level technical descriptions for experts and high-level summaries\nfor non-technical stakeholders.\n  We qualitatively evaluate our method on various images from ImageNet on a\nVGG16 model. Our findings suggest that integrating concept-based attribution\nmethods with large language models can significantly lower the barrier to\ninterpreting deep neural networks, paving the way for more transparent AI\nsystems.",
      "pdf_url": "http://arxiv.org/pdf/2511.02720v1",
      "published": "2025-11-04T16:44:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.02720v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "An unscented Kalman filter method for real time input-parameter-state estimation",
      "authors": [
        "Marios Impraimakis",
        "Andrew W. Smyth"
      ],
      "abstract": "The input-parameter-state estimation capabilities of a novel unscented Kalman\nfilter is examined herein on both linear and nonlinear systems. The unknown\ninput is estimated in two stages within each time step. Firstly, the predicted\ndynamic states and the system parameters provide an estimation of the input.\nSecondly, the corrected with measurements states and parameters provide a final\nestimation. Importantly, it is demonstrated using the perturbation analysis\nthat, a system with at least a zero or a non-zero known input can potentially\nbe uniquely identified. This output-only methodology allows for a better\nunderstanding of the system compared to classical output-only parameter\nidentification strategies, given that all the dynamic states, the parameters,\nand the input are estimated jointly and in real-time.",
      "pdf_url": "http://arxiv.org/pdf/2511.02717v1",
      "published": "2025-11-04T16:39:27+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.02717v1",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.CV",
        "cs.SY",
        "eess.AS",
        "eess.SY",
        "68T05 (Learning and adaptive systems)",
        "I.2.6; I.2.8"
      ]
    },
    {
      "title": "The Collaboration Gap",
      "authors": [
        "Tim R. Davidson",
        "Adam Fourney",
        "Saleema Amershi",
        "Robert West",
        "Eric Horvitz",
        "Ece Kamar"
      ],
      "abstract": "The trajectory of AI development suggests that we will increasingly rely on\nagent-based systems composed of independently developed agents with different\ninformation, privileges, and tools. The success of these systems will\ncritically depend on effective collaboration among these heterogeneous agents,\neven under partial observability. Despite intense interest, few empirical\nstudies have evaluated such agent-agent collaboration at scale. We propose a\ncollaborative maze-solving benchmark that (i) isolates collaborative\ncapabilities, (ii) modulates problem complexity, (iii) enables scalable\nautomated grading, and (iv) imposes no output-format constraints, preserving\necological plausibility. Using this framework, we evaluate 32 leading open- and\nclosed-source models in solo, homogeneous, and heterogeneous pairings. Our\nresults reveal a \"collaboration gap\": models that perform well solo often\ndegrade substantially when required to collaborate. Collaboration can break\ndown dramatically; for instance, small distilled models that solve mazes well\nalone may fail almost completely in certain pairings. We find that starting\nwith the stronger agent often improves outcomes, motivating a \"relay inference\"\napproach where the stronger agent leads before handing off to the weaker one,\nclosing much of the gap. Our findings argue for (1) collaboration-aware\nevaluation, (2) training strategies developed to enhance collaborative\ncapabilities, and (3) interaction design that reliably elicits agents' latent\nskills, guidance that applies to AI-AI and human-AI collaboration.",
      "pdf_url": "http://arxiv.org/pdf/2511.02687v1",
      "published": "2025-11-04T16:10:57+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.02687v1",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Optimal Singular Damage: Efficient LLM Inference in Low Storage Regimes",
      "authors": [
        "Mohammadsajad Alipour",
        "Mohammad Mohammadi Amiri"
      ],
      "abstract": "Large language models (LLMs) are increasingly prevalent across diverse\napplications. However, their enormous size limits storage and processing\ncapabilities to a few well-resourced stakeholders. As a result, most\napplications rely on pre-trained LLMs, fine-tuned for specific tasks. However,\neven storing the fine-tuned versions of these models remains a significant\nchallenge due to the wide range of tasks they address. Recently, studies show\nthat fine-tuning these models primarily affects a small fraction of parameters,\nhighlighting the need for more efficient storage of fine-tuned models. This\npaper focuses on efficient storage of parameter updates in pre-trained models\nafter fine-tuning. To address this challenge, we leverage the observation that\nfine-tuning updates are both low-rank and sparse, which can be utilized for\nstorage efficiency. However, using only low-rank approximation or\nsparsification may discard critical singular components that enhance model\nexpressivity. We first observe that given the same memory budget, sparsified\nlow-rank approximations with larger ranks outperform standard low-rank\napproximations with smaller ranks. Building on this, we propose our method,\noptimal singular damage, that selectively sparsifies low-rank approximated\nupdates by leveraging the interleaved importance of singular vectors, ensuring\nthat the most impactful components are retained. We demonstrate through\nextensive experiments that our proposed methods lead to significant storage\nefficiency and superior accuracy within the same memory budget compared to\nemploying the low-rank approximation or sparsification individually.",
      "pdf_url": "http://arxiv.org/pdf/2511.02681v1",
      "published": "2025-11-04T16:05:25+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.02681v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Scalable Evaluation and Neural Models for Compositional Generalization",
      "authors": [
        "Giacomo Camposampiero",
        "Pietro Barbiero",
        "Michael Hersche",
        "Roger Wattenhofer",
        "Abbas Rahimi"
      ],
      "abstract": "Compositional generalization-a key open challenge in modern machine\nlearning-requires models to predict unknown combinations of known concepts.\nHowever, assessing compositional generalization remains a fundamental challenge\ndue to the lack of standardized evaluation protocols and the limitations of\ncurrent benchmarks, which often favor efficiency over rigor. At the same time,\ngeneral-purpose vision architectures lack the necessary inductive biases, and\nexisting approaches to endow them compromise scalability. As a remedy, this\npaper introduces: 1) a rigorous evaluation framework that unifies and extends\nprevious approaches while reducing computational requirements from\ncombinatorial to constant; 2) an extensive and modern evaluation on the status\nof compositional generalization in supervised vision backbones, training more\nthan 5000 models; 3) Attribute Invariant Networks, a class of models\nestablishing a new Pareto frontier in compositional generalization, achieving a\n23.43% accuracy improvement over baselines while reducing parameter overhead\nfrom 600% to 16% compared to fully disentangled counterparts.",
      "pdf_url": "http://arxiv.org/pdf/2511.02667v1",
      "published": "2025-11-04T15:45:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.02667v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "In Situ Training of Implicit Neural Compressors for Scientific Simulations via Sketch-Based Regularization",
      "authors": [
        "Cooper Simpson",
        "Stephen Becker",
        "Alireza Doostan"
      ],
      "abstract": "Focusing on implicit neural representations, we present a novel in situ\ntraining protocol that employs limited memory buffers of full and sketched data\nsamples, where the sketched data are leveraged to prevent catastrophic\nforgetting. The theoretical motivation for our use of sketching as a\nregularizer is presented via a simple Johnson-Lindenstrauss-informed result.\nWhile our methods may be of wider interest in the field of continual learning,\nwe specifically target in situ neural compression using implicit neural\nrepresentation-based hypernetworks. We evaluate our method on a variety of\ncomplex simulation data in two and three dimensions, over long time horizons,\nand across unstructured grids and non-Cartesian geometries. On these tasks, we\nshow strong reconstruction performance at high compression rates. Most\nimportantly, we demonstrate that sketching enables the presented in situ scheme\nto approximately match the performance of the equivalent offline method.",
      "pdf_url": "http://arxiv.org/pdf/2511.02659v1",
      "published": "2025-11-04T15:36:00+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.02659v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE",
        "cs.NA",
        "math.NA"
      ]
    },
    {
      "title": "Apriel-H1: Towards Efficient Enterprise Reasoning Models",
      "authors": [
        "Oleksiy Ostapenko",
        "Luke Kumar",
        "Raymond Li",
        "Denis Kocetkov",
        "Joel Lamy-Poirier",
        "Shruthan Radhakrishna",
        "Soham Parikh",
        "Shambhavi Mishra",
        "Sebastien Paquet",
        "Srinivas Sunkara",
        "Valérie Bécaert",
        "Sathwik Tejaswi Madhusudhan",
        "Torsten Scholak"
      ],
      "abstract": "Large Language Models (LLMs) achieve remarkable reasoning capabilities\nthrough transformer architectures with attention mechanisms. However,\ntransformers suffer from quadratic time and memory complexity in the attention\nmodule (MHA) and require caching key-value states during inference, which\nseverely limits throughput and scalability. High inference throughput is\ncritical for agentic tasks, long-context reasoning, efficient deployment under\nhigh request loads, and more efficient test-time compute scaling.\n  State Space Models (SSMs) such as Mamba offer a promising alternative with\nlinear inference complexity and a constant memory footprint via recurrent\ncomputation with fixed-size hidden states. In this technical report we\nintroduce the Apriel-H1 family of hybrid LLMs that combine transformer\nattention and SSM sequence mixers for efficient reasoning at 15B model size.\nThese models are obtained through incremental distillation from a pretrained\nreasoning transformer, Apriel-Nemotron-15B-Thinker, progressively replacing\nless critical attention layers with linear Mamba blocks.\n  We release multiple post-distillation variants of Apriel-H1-15B-Thinker with\ndifferent SSM-to-MHA ratios and analyse how reasoning performance degrades as\nmore Mamba layers replace MHA. Additionally, we release a 30/50 hybrid variant\nof Apriel-H1, further fine-tuned on a supervised dataset of reasoning traces,\nachieving over 2x higher inference throughput when deployed in the\nproduction-ready vLLM environment, with minimal degradation in reasoning\nperformance. This shows that distilled hybrid SSM-Transformer architectures can\ndeliver substantial efficiency gains over the pretrained transformer equivalent\nwithout substantially compromising the reasoning quality.",
      "pdf_url": "http://arxiv.org/pdf/2511.02651v1",
      "published": "2025-11-04T15:17:43+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.02651v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Federated Attention: A Distributed Paradigm for Collaborative LLM Inference over Edge Networks",
      "authors": [
        "Xiumei Deng",
        "Zehui Xiong",
        "Binbin Chen",
        "Dong In Kim",
        "Merouane Debbah",
        "H. Vincent Poor"
      ],
      "abstract": "Large language models (LLMs) are proliferating rapidly at the edge,\ndelivering intelligent capabilities across diverse application scenarios.\nHowever, their practical deployment in collaborative scenarios confronts\nfundamental challenges: privacy vulnerabilities, communication overhead, and\ncomputational bottlenecks. To address these, we propose Federated Attention\n(FedAttn), which integrates the federated paradigm into the self-attention\nmechanism, creating a new distributed LLM inference framework that\nsimultaneously achieves privacy protection, communication efficiency, and\ncomputational efficiency. FedAttn enables participants to perform local\nself-attention over their own token representations while periodically\nexchanging and aggregating Key-Value (KV) matrices across multiple Transformer\nblocks, collaboratively generating LLM responses without exposing private\nprompts. Further, we identify a structural duality between contextual\nrepresentation refinement in FedAttn and parameter optimization in FL across\nprivate data, local computation, and global aggregation. This key insight\nprovides a principled foundation for systematically porting federated\noptimization techniques to collaborative LLM inference. Building on this\nframework, we theoretically analyze how local self-attention computation within\nparticipants and heterogeneous token relevance among participants shape error\npropagation dynamics across Transformer blocks. Moreover, we characterize the\nfundamental trade-off between response quality and communication/computation\nefficiency, which is governed by the synchronization interval and the number of\nparticipants. Experimental results validate our theoretical analysis, and\nreveal significant optimization opportunities through sparse attention and\nadaptive KV aggregation, highlighting FedAttn's potential to deliver\nscalability and efficiency in real-world edge deployments.",
      "pdf_url": "http://arxiv.org/pdf/2511.02647v1",
      "published": "2025-11-04T15:14:58+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.02647v1",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Natural-gas storage modelling by deep reinforcement learning",
      "authors": [
        "Tiziano Balaconi",
        "Aldo Glielmo",
        "Marco Taboga"
      ],
      "abstract": "We introduce GasRL, a simulator that couples a calibrated representation of\nthe natural gas market with a model of storage-operator policies trained with\ndeep reinforcement learning (RL). We use it to analyse how optimal stockpile\nmanagement affects equilibrium prices and the dynamics of demand and supply. We\ntest various RL algorithms and find that Soft Actor Critic (SAC) exhibits\nsuperior performance in the GasRL environment: multiple objectives of storage\noperators - including profitability, robust market clearing and price\nstabilisation - are successfully achieved. Moreover, the equilibrium price\ndynamics induced by SAC-derived optimal policies have characteristics, such as\nvolatility and seasonality, that closely match those of real-world prices.\nRemarkably, this adherence to the historical distribution of prices is obtained\nwithout explicitly calibrating the model to price data. We show how the\nsimulator can be used to assess the effects of EU-mandated minimum storage\nthresholds. We find that such thresholds have a positive effect on market\nresilience against unanticipated shifts in the distribution of supply shocks.\nFor example, with unusually large shocks, market disruptions are averted more\noften if a threshold is in place.",
      "pdf_url": "http://arxiv.org/pdf/2511.02646v1",
      "published": "2025-11-04T15:13:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.02646v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE",
        "cs.SY",
        "econ.GN",
        "eess.SY",
        "q-fin.EC"
      ]
    },
    {
      "title": "DecompSR: A dataset for decomposed analyses of compositional multihop spatial reasoning",
      "authors": [
        "Lachlan McPheat",
        "Navdeep Kaur",
        "Robert Blackwell",
        "Alessandra Russo",
        "Anthony G. Cohn",
        "Pranava Madhyastha"
      ],
      "abstract": "We introduce DecompSR, decomposed spatial reasoning, a large benchmark\ndataset (over 5m datapoints) and generation framework designed to analyse\ncompositional spatial reasoning ability. The generation of DecompSR allows\nusers to independently vary several aspects of compositionality, namely:\nproductivity (reasoning depth), substitutivity (entity and linguistic\nvariability), overgeneralisation (input order, distractors) and systematicity\n(novel linguistic elements). DecompSR is built procedurally in a manner which\nmakes it is correct by construction, which is independently verified using a\nsymbolic solver to guarantee the correctness of the dataset. DecompSR is\ncomprehensively benchmarked across a host of Large Language Models (LLMs) where\nwe show that LLMs struggle with productive and systematic generalisation in\nspatial reasoning tasks whereas they are more robust to linguistic variation.\nDecompSR provides a provably correct and rigorous benchmarking dataset with a\nnovel ability to independently vary the degrees of several key aspects of\ncompositionality, allowing for robust and fine-grained probing of the\ncompositional reasoning abilities of LLMs.",
      "pdf_url": "http://arxiv.org/pdf/2511.02627v1",
      "published": "2025-11-04T14:57:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.02627v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "A Multi-Agent Psychological Simulation System for Human Behavior Modeling",
      "authors": [
        "Xiangen Hu",
        "Jiarui Tong",
        "Sheng Xu"
      ],
      "abstract": "Training and education in human-centered fields require authentic practice,\nyet realistic simulations of human behavior have remained limited. We present a\nmulti-agent psychological simulation system that models internal\ncognitive-affective processes to generate believable human behaviors. In\ncontrast to black-box neural models, this system is grounded in established\npsychological theories (e.g., self-efficacy, mindset, social constructivism)\nand explicitly simulates an ``inner parliament'' of agents corresponding to key\npsychological factors. These agents deliberate and interact to determine the\nsystem's output behavior, enabling unprecedented transparency and alignment\nwith human psychology. We describe the system's architecture and theoretical\nfoundations, illustrate its use in teacher training and research, and discuss\nhow it embodies principles of social learning, cognitive apprenticeship,\ndeliberate practice, and meta-cognition.",
      "pdf_url": "http://arxiv.org/pdf/2511.02606v1",
      "published": "2025-11-04T14:28:03+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.02606v1",
      "categories": [
        "cs.AI",
        "cs.HC"
      ]
    },
    {
      "title": "Adaptive GR(1) Specification Repair for Liveness-Preserving Shielding in Reinforcement Learning",
      "authors": [
        "Tiberiu-Andrei Georgescu",
        "Alexander W. Goodall",
        "Dalal Alrajeh",
        "Francesco Belardinelli",
        "Sebastian Uchitel"
      ],
      "abstract": "Shielding is widely used to enforce safety in reinforcement learning (RL),\nensuring that an agent's actions remain compliant with formal specifications.\nClassical shielding approaches, however, are often static, in the sense that\nthey assume fixed logical specifications and hand-crafted abstractions. While\nthese static shields provide safety under nominal assumptions, they fail to\nadapt when environment assumptions are violated. In this paper, we develop the\nfirst adaptive shielding framework - to the best of our knowledge - based on\nGeneralized Reactivity of rank 1 (GR(1)) specifications, a tractable and\nexpressive fragment of Linear Temporal Logic (LTL) that captures both safety\nand liveness properties. Our method detects environment assumption violations\nat runtime and employs Inductive Logic Programming (ILP) to automatically\nrepair GR(1) specifications online, in a systematic and interpretable way. This\nensures that the shield evolves gracefully, ensuring liveness is achievable and\nweakening goals only when necessary. We consider two case studies: Minepump and\nAtari Seaquest; showing that (i) static symbolic controllers are often severely\nsuboptimal when optimizing for auxiliary rewards, and (ii) RL agents equipped\nwith our adaptive shield maintain near-optimal reward and perfect logical\ncompliance compared with static shields.",
      "pdf_url": "http://arxiv.org/pdf/2511.02605v1",
      "published": "2025-11-04T14:27:28+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.02605v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Trustworthy Quantum Machine Learning: A Roadmap for Reliability, Robustness, and Security in the NISQ Era",
      "authors": [
        "Ferhat Ozgur Catak",
        "Jungwon Seo",
        "Umit Cali"
      ],
      "abstract": "Quantum machine learning (QML) is a promising paradigm for tackling\ncomputational problems that challenge classical AI. Yet, the inherent\nprobabilistic behavior of quantum mechanics, device noise in NISQ hardware, and\nhybrid quantum-classical execution pipelines introduce new risks that prevent\nreliable deployment of QML in real-world, safety-critical settings. This\nresearch offers a broad roadmap for Trustworthy Quantum Machine Learning\n(TQML), integrating three foundational pillars of reliability: (i) uncertainty\nquantification for calibrated and risk-aware decision making, (ii) adversarial\nrobustness against classical and quantum-native threat models, and (iii)\nprivacy preservation in distributed and delegated quantum learning scenarios.\nWe formalize quantum-specific trust metrics grounded in quantum information\ntheory, including a variance-based decomposition of predictive uncertainty,\ntrace-distance-bounded robustness, and differential privacy for hybrid learning\nchannels. To demonstrate feasibility on current NISQ devices, we validate a\nunified trust assessment pipeline on parameterized quantum classifiers,\nuncovering correlations between uncertainty and prediction risk, an asymmetry\nin attack vulnerability between classical and quantum state perturbations, and\nprivacy-utility trade-offs driven by shot noise and quantum channel noise. This\nroadmap seeks to define trustworthiness as a first-class design objective for\nquantum AI.",
      "pdf_url": "http://arxiv.org/pdf/2511.02602v1",
      "published": "2025-11-04T14:24:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.02602v1",
      "categories": [
        "quant-ph",
        "cs.AI"
      ]
    },
    {
      "title": "On The Dangers of Poisoned LLMs In Security Automation",
      "authors": [
        "Patrick Karlsen",
        "Even Eilertsen"
      ],
      "abstract": "This paper investigates some of the risks introduced by \"LLM poisoning,\" the\nintentional or unintentional introduction of malicious or biased data during\nmodel training. We demonstrate how a seemingly improved LLM, fine-tuned on a\nlimited dataset, can introduce significant bias, to the extent that a simple\nLLM-based alert investigator is completely bypassed when the prompt utilizes\nthe introduced bias. Using fine-tuned Llama3.1 8B and Qwen3 4B models, we\ndemonstrate how a targeted poisoning attack can bias the model to consistently\ndismiss true positive alerts originating from a specific user. Additionally, we\npropose some mitigation and best-practices to increase trustworthiness,\nrobustness and reduce risk in applied LLMs in security applications.",
      "pdf_url": "http://arxiv.org/pdf/2511.02600v1",
      "published": "2025-11-04T14:23:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.02600v1",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "title": "Next Token Knowledge Tracing: Exploiting Pretrained LLM Representations to Decode Student Behaviour",
      "authors": [
        "Max Norris",
        "Kobi Gal",
        "Sahan Bulathwela"
      ],
      "abstract": "Modelling student knowledge is a key challenge when leveraging AI in\neducation, with major implications for personalised learning. The Knowledge\nTracing (KT) task aims to predict how students will respond to educational\nquestions in learning environments, based on their prior interactions. Existing\nKT models typically use response correctness along with metadata like skill\ntags and timestamps, often overlooking the question text, which is an important\nsource of pedagogical insight. This omission poses a lost opportunity while\nlimiting predictive performance. We propose Next Token Knowledge Tracing\n(NTKT), a novel approach that reframes KT as a next-token prediction task using\npretrained Large Language Models (LLMs). NTKT represents both student histories\nand question content as sequences of text, allowing LLMs to learn patterns in\nboth behaviour and language. Our series of experiments significantly improves\nperformance over state-of-the-art neural KT models and generalises much better\nto cold-start questions and users. These findings highlight the importance of\nquestion content in KT and demonstrate the benefits of leveraging pretrained\nrepresentations of LLMs to model student learning more effectively.",
      "pdf_url": "http://arxiv.org/pdf/2511.02599v1",
      "published": "2025-11-04T14:20:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.02599v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "The ORCA Benchmark: Evaluating Real-World Calculation Accuracy in Large Language Models",
      "authors": [
        "Claudia Herambourg",
        "Dawid Siuda",
        "Anna Szczepanek",
        "Julia Kopczyńska",
        "Joao R. L. Santos",
        "Wojciech Sas",
        "Joanna Śmietańska-Nowak"
      ],
      "abstract": "We present ORCA (Omni Research on Calculation in AI) Benchmark -- a novel\nbenchmark that evaluates large language models (LLMs) on multi-domain,\nreal-life quantitative reasoning using verified outputs from Omni's calculator\nengine. In 500 natural-language tasks across domains such as finance, physics,\nhealth, and statistics, the five state-of-the-art systems (ChatGPT-5,\nGemini~2.5~Flash, Claude~Sonnet~4.5, Grok~4, and DeepSeek~V3.2) achieved only\n$45\\text{--}63\\,\\%$ accuracy, with errors mainly related to rounding ($35\\,\\%$)\nand calculation mistakes ($33\\,\\%$). Results in specific domains indicate\nstrengths in mathematics and engineering, but weaknesses in physics and natural\nsciences. Correlation analysis ($r \\approx 0.40\\text{--}0.65$) shows that the\nmodels often fail together but differ in the types of errors they make,\nhighlighting their partial complementarity rather than redundancy. Unlike\nstandard math datasets, ORCA evaluates step-by-step reasoning, numerical\nprecision, and domain generalization across real problems from finance,\nphysics, health, and statistics.",
      "pdf_url": "http://arxiv.org/pdf/2511.02589v1",
      "published": "2025-11-04T14:09:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.02589v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "TAUE: Training-free Noise Transplant and Cultivation Diffusion Model",
      "authors": [
        "Daichi Nagai",
        "Ryugo Morita",
        "Shunsuke Kitada",
        "Hitoshi Iyatomi"
      ],
      "abstract": "Despite the remarkable success of text-to-image diffusion models, their\noutput of a single, flattened image remains a critical bottleneck for\nprofessional applications requiring layer-wise control. Existing solutions\neither rely on fine-tuning with large, inaccessible datasets or are\ntraining-free yet limited to generating isolated foreground elements, failing\nto produce a complete and coherent scene. To address this, we introduce the\nTraining-free Noise Transplantation and Cultivation Diffusion Model (TAUE), a\nnovel framework for zero-shot, layer-wise image generation. Our core technique,\nNoise Transplantation and Cultivation (NTC), extracts intermediate latent\nrepresentations from both foreground and composite generation processes,\ntransplanting them into the initial noise for subsequent layers. This ensures\nsemantic and structural coherence across foreground, background, and composite\nlayers, enabling consistent, multi-layered outputs without requiring\nfine-tuning or auxiliary datasets. Extensive experiments show that our\ntraining-free method achieves performance comparable to fine-tuned methods,\nenhancing layer-wise consistency while maintaining high image quality and\nfidelity. TAUE not only eliminates costly training and dataset requirements but\nalso unlocks novel downstream applications, such as complex compositional\nediting, paving the way for more accessible and controllable generative\nworkflows.",
      "pdf_url": "http://arxiv.org/pdf/2511.02580v1",
      "published": "2025-11-04T13:56:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.02580v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG"
      ]
    },
    {
      "title": "Adaptive Neighborhood-Constrained Q Learning for Offline Reinforcement Learning",
      "authors": [
        "Yixiu Mao",
        "Yun Qu",
        "Qi Wang",
        "Xiangyang Ji"
      ],
      "abstract": "Offline reinforcement learning (RL) suffers from extrapolation errors induced\nby out-of-distribution (OOD) actions. To address this, offline RL algorithms\ntypically impose constraints on action selection, which can be systematically\ncategorized into density, support, and sample constraints. However, we show\nthat each category has inherent limitations: density and sample constraints\ntend to be overly conservative in many scenarios, while the support constraint,\nthough least restrictive, faces challenges in accurately modeling the behavior\npolicy. To overcome these limitations, we propose a new neighborhood constraint\nthat restricts action selection in the Bellman target to the union of\nneighborhoods of dataset actions. Theoretically, the constraint not only bounds\nextrapolation errors and distribution shift under certain conditions, but also\napproximates the support constraint without requiring behavior policy modeling.\nMoreover, it retains substantial flexibility and enables pointwise conservatism\nby adapting the neighborhood radius for each data point. In practice, we employ\ndata quality as the adaptation criterion and design an adaptive neighborhood\nconstraint. Building on an efficient bilevel optimization framework, we develop\na simple yet effective algorithm, Adaptive Neighborhood-constrained Q learning\n(ANQ), to perform Q learning with target actions satisfying this constraint.\nEmpirically, ANQ achieves state-of-the-art performance on standard offline RL\nbenchmarks and exhibits strong robustness in scenarios with noisy or limited\ndata.",
      "pdf_url": "http://arxiv.org/pdf/2511.02567v1",
      "published": "2025-11-04T13:42:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.02567v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "A Cognitive Process-Inspired Architecture for Subject-Agnostic Brain Visual Decoding",
      "authors": [
        "Jingyu Lu",
        "Haonan Wang",
        "Qixiang Zhang",
        "Xiaomeng Li"
      ],
      "abstract": "Subject-agnostic brain decoding, which aims to reconstruct continuous visual\nexperiences from fMRI without subject-specific training, holds great potential\nfor clinical applications. However, this direction remains underexplored due to\nchallenges in cross-subject generalization and the complex nature of brain\nsignals. In this work, we propose Visual Cortex Flow Architecture (VCFlow), a\nnovel hierarchical decoding framework that explicitly models the ventral-dorsal\narchitecture of the human visual system to learn multi-dimensional\nrepresentations. By disentangling and leveraging features from early visual\ncortex, ventral, and dorsal streams, VCFlow captures diverse and complementary\ncognitive information essential for visual reconstruction. Furthermore, we\nintroduce a feature-level contrastive learning strategy to enhance the\nextraction of subject-invariant semantic representations, thereby enhancing\nsubject-agnostic applicability to previously unseen subjects. Unlike\nconventional pipelines that need more than 12 hours of per-subject data and\nheavy computation, VCFlow sacrifices only 7\\% accuracy on average yet generates\neach reconstructed video in 10 seconds without any retraining, offering a fast\nand clinically scalable solution. The source code will be released upon\nacceptance of the paper.",
      "pdf_url": "http://arxiv.org/pdf/2511.02565v1",
      "published": "2025-11-04T13:39:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.02565v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "SigmaCollab: An Application-Driven Dataset for Physically Situated Collaboration",
      "authors": [
        "Dan Bohus",
        "Sean Andrist",
        "Ann Paradiso",
        "Nick Saw",
        "Tim Schoonbeek",
        "Maia Stiber"
      ],
      "abstract": "We introduce SigmaCollab, a dataset enabling research on physically situated\nhuman-AI collaboration. The dataset consists of a set of 85 sessions in which\nuntrained participants were guided by a mixed-reality assistive AI agent in\nperforming procedural tasks in the physical world. SigmaCollab includes a set\nof rich, multimodal data streams, such as the participant and system audio,\negocentric camera views from the head-mounted device, depth maps, head, hand\nand gaze tracking information, as well as additional annotations performed\npost-hoc. While the dataset is relatively small in size (~ 14 hours), its\napplication-driven and interactive nature brings to the fore novel research\nchallenges for human-AI collaboration, and provides more realistic testing\ngrounds for various AI models operating in this space. In future work, we plan\nto use the dataset to construct a set of benchmarks for physically situated\ncollaboration in mixed-reality task assistive scenarios. SigmaCollab is\navailable at https://github.com/microsoft/SigmaCollab.",
      "pdf_url": "http://arxiv.org/pdf/2511.02560v1",
      "published": "2025-11-04T13:30:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.02560v1",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Knowledge Graph-enhanced Large Language Model for Incremental Game PlayTesting",
      "authors": [
        "Enhong Mu",
        "Jinyu Cai",
        "Yijun Lu",
        "Mingyue Zhang",
        "Kenji Tei",
        "Jialong Li"
      ],
      "abstract": "The rapid iteration and frequent updates of modern video games pose\nsignificant challenges to the efficiency and specificity of testing. Although\nautomated playtesting methods based on Large Language Models (LLMs) have shown\npromise, they often lack structured knowledge accumulation mechanisms, making\nit difficult to conduct precise and efficient testing tailored for incremental\ngame updates. To address this challenge, this paper proposes a KLPEG framework.\nThe framework constructs and maintains a Knowledge Graph (KG) to systematically\nmodel game elements, task dependencies, and causal relationships, enabling\nknowledge accumulation and reuse across versions. Building on this foundation,\nthe framework utilizes LLMs to parse natural language update logs, identify the\nscope of impact through multi-hop reasoning on the KG, enabling the generation\nof update-tailored test cases. Experiments in two representative game\nenvironments, Overcooked and Minecraft, demonstrate that KLPEG can more\naccurately locate functionalities affected by updates and complete tests in\nfewer steps, significantly improving both playtesting effectiveness and\nefficiency.",
      "pdf_url": "http://arxiv.org/pdf/2511.02534v1",
      "published": "2025-11-04T12:40:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.02534v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Agentic AI for Mobile Network RAN Management and Optimization",
      "authors": [
        "Jorge Pellejero",
        "Luis A. Hernández Gómez",
        "Luis Mendo Tomás",
        "Zoraida Frias Barroso"
      ],
      "abstract": "Agentic AI represents a new paradigm for automating complex systems by using\nLarge AI Models (LAMs) to provide human-level cognitive abilities with\nmultimodal perception, planning, memory, and reasoning capabilities. This will\nlead to a new generation of AI systems that autonomously decompose goals,\nretain context over time, learn continuously, operate across tools and\nenvironments, and adapt dynamically. The complexity of 5G and upcoming 6G\nnetworks renders manual optimization ineffective, pointing to Agentic AI as a\nmethod for automating decisions in dynamic RAN environments. However, despite\nits rapid advances, there is no established framework outlining the\nfoundational components and operational principles of Agentic AI systems nor a\nuniversally accepted definition.\n  This paper contributes to ongoing research on Agentic AI in 5G and 6G\nnetworks by outlining its core concepts and then proposing a practical use case\nthat applies Agentic principles to RAN optimization. We first introduce Agentic\nAI, tracing its evolution from classical agents and discussing the progress\nfrom workflows and simple AI agents to Agentic AI. Core design\npatterns-reflection, planning, tool use, and multi-agent collaboration-are then\ndescribed to illustrate how intelligent behaviors are orchestrated. These\ntheorical concepts are grounded in the context of mobile networks, with a focus\non RAN management and optimization. A practical 5G RAN case study shows how\ntime-series analytics and LAM-driven agents collaborate for KPI-based\nautonomous decision-making.",
      "pdf_url": "http://arxiv.org/pdf/2511.02532v1",
      "published": "2025-11-04T12:34:57+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.02532v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Causal Graph Neural Networks for Healthcare",
      "authors": [
        "Munib Mesinovic",
        "Max Buhlan",
        "Tingting Zhu"
      ],
      "abstract": "Healthcare artificial intelligence systems routinely fail when deployed\nacross institutions, with documented performance drops and perpetuation of\ndiscriminatory patterns embedded in historical data. This brittleness stems, in\npart, from learning statistical associations rather than causal mechanisms.\nCausal graph neural networks address this triple crisis of distribution shift,\ndiscrimination, and inscrutability by combining graph-based representations of\nbiomedical data with causal inference principles to learn invariant mechanisms\nrather than spurious correlations. This Review examines methodological\nfoundations spanning structural causal models, disentangled causal\nrepresentation learning, and techniques for interventional prediction and\ncounterfactual reasoning on graphs. We analyse applications demonstrating\nclinical value across psychiatric diagnosis through brain network analysis,\ncancer subtyping via multi-omics causal integration, continuous physiological\nmonitoring with mechanistic interpretation, and drug recommendation correcting\nprescription bias. These advances establish foundations for patient-specific\nCausal Digital Twins, enabling in silico clinical experimentation, with\nintegration of large language models for hypothesis generation and causal graph\nneural networks for mechanistic validation. Substantial barriers remain,\nincluding computational requirements precluding real-time deployment,\nvalidation challenges demanding multi-modal evidence triangulation beyond\ncross-validation, and risks of causal-washing where methods employ causal\nterminology without rigorous evidentiary support. We propose tiered frameworks\ndistinguishing causally-inspired architectures from causally-validated\ndiscoveries and identify critical research priorities making causal rather than\npurely associational claims.",
      "pdf_url": "http://arxiv.org/pdf/2511.02531v1",
      "published": "2025-11-04T12:34:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.02531v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "An End-to-End Learning Approach for Solving Capacitated Location-Routing Problems",
      "authors": [
        "Changhao Miao",
        "Yuntian Zhang",
        "Tongyu Wu",
        "Fang Deng",
        "Chen Chen"
      ],
      "abstract": "The capacitated location-routing problems (CLRPs) are classical problems in\ncombinatorial optimization, which require simultaneously making location and\nrouting decisions. In CLRPs, the complex constraints and the intricate\nrelationships between various decisions make the problem challenging to solve.\nWith the emergence of deep reinforcement learning (DRL), it has been\nextensively applied to address the vehicle routing problem and its variants,\nwhile the research related to CLRPs still needs to be explored. In this paper,\nwe propose the DRL with heterogeneous query (DRLHQ) to solve CLRP and open CLRP\n(OCLRP), respectively. We are the first to propose an end-to-end learning\napproach for CLRPs, following the encoder-decoder structure. In particular, we\nreformulate the CLRPs as a markov decision process tailored to various\ndecisions, a general modeling framework that can be adapted to other DRL-based\nmethods. To better handle the interdependency across location and routing\ndecisions, we also introduce a novel heterogeneous querying attention mechanism\ndesigned to adapt dynamically to various decision-making stages. Experimental\nresults on both synthetic and benchmark datasets demonstrate superior solution\nquality and better generalization performance of our proposed approach over\nrepresentative traditional and DRL-based baselines in solving both CLRP and\nOCLRP.",
      "pdf_url": "http://arxiv.org/pdf/2511.02525v1",
      "published": "2025-11-04T12:23:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.02525v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "BRAINS: A Retrieval-Augmented System for Alzheimer's Detection and Monitoring",
      "authors": [
        "Rajan Das Gupta",
        "Md Kishor Morol",
        "Nafiz Fahad",
        "Md Tanzib Hosain",
        "Sumaya Binte Zilani Choya",
        "Md Jakir Hossen"
      ],
      "abstract": "As the global burden of Alzheimer's disease (AD) continues to grow, early and\naccurate detection has become increasingly critical, especially in regions with\nlimited access to advanced diagnostic tools. We propose BRAINS (Biomedical\nRetrieval-Augmented Intelligence for Neurodegeneration Screening) to address\nthis challenge. This novel system harnesses the powerful reasoning capabilities\nof Large Language Models (LLMs) for Alzheimer's detection and monitoring.\nBRAINS features a dual-module architecture: a cognitive diagnostic module and a\ncase-retrieval module. The Diagnostic Module utilizes LLMs fine-tuned on\ncognitive and neuroimaging datasets -- including MMSE, CDR scores, and brain\nvolume metrics -- to perform structured assessments of Alzheimer's risk.\nMeanwhile, the Case Retrieval Module encodes patient profiles into latent\nrepresentations and retrieves similar cases from a curated knowledge base.\nThese auxiliary cases are fused with the input profile via a Case Fusion Layer\nto enhance contextual understanding. The combined representation is then\nprocessed with clinical prompts for inference. Evaluations on real-world\ndatasets demonstrate BRAINS effectiveness in classifying disease severity and\nidentifying early signs of cognitive decline. This system not only shows strong\npotential as an assistive tool for scalable, explainable, and early-stage\nAlzheimer's disease detection, but also offers hope for future applications in\nthe field.",
      "pdf_url": "http://arxiv.org/pdf/2511.02490v1",
      "published": "2025-11-04T11:27:03+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.02490v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Wireless Video Semantic Communication with Decoupled Diffusion Multi-frame Compensation",
      "authors": [
        "Bingyan Xie",
        "Yongpeng Wu",
        "Yuxuan Shi",
        "Biqian Feng",
        "Wenjun Zhang",
        "Jihong Park",
        "Tony Quek"
      ],
      "abstract": "Existing wireless video transmission schemes directly conduct video coding in\npixel level, while neglecting the inner semantics contained in videos. In this\npaper, we propose a wireless video semantic communication framework with\ndecoupled diffusion multi-frame compensation (DDMFC), abbreviated as WVSC-D,\nwhich integrates the idea of semantic communication into wireless video\ntransmission scenarios. WVSC-D first encodes original video frames as semantic\nframes and then conducts video coding based on such compact representations,\nenabling the video coding in semantic level rather than pixel level. Moreover,\nto further reduce the communication overhead, a reference semantic frame is\nintroduced to substitute motion vectors of each frame in common video coding\nmethods. At the receiver, DDMFC is proposed to generate compensated current\nsemantic frame by a two-stage conditional diffusion process. With both the\nreference frame transmission and DDMFC frame compensation, the bandwidth\nefficiency improves with satisfying video transmission performance.\nExperimental results verify the performance gain of WVSC-D over other DL-based\nmethods e.g. DVSC about 1.8 dB in terms of PSNR.",
      "pdf_url": "http://arxiv.org/pdf/2511.02478v1",
      "published": "2025-11-04T11:05:41+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.02478v1",
      "categories": [
        "cs.MM",
        "cs.AI"
      ]
    },
    {
      "title": "Modeling Hawkish-Dovish Latent Beliefs in Multi-Agent Debate-Based LLMs for Monetary Policy Decision Classification",
      "authors": [
        "Kaito Takano",
        "Masanori Hirano",
        "Kei Nakagawa"
      ],
      "abstract": "Accurately forecasting central bank policy decisions, particularly those of\nthe Federal Open Market Committee(FOMC) has become increasingly important amid\nheightened economic uncertainty. While prior studies have used monetary policy\ntexts to predict rate changes, most rely on static classification models that\noverlook the deliberative nature of policymaking. This study proposes a novel\nframework that structurally imitates the FOMC's collective decision-making\nprocess by modeling multiple large language models(LLMs) as interacting agents.\nEach agent begins with a distinct initial belief and produces a prediction\nbased on both qualitative policy texts and quantitative macroeconomic\nindicators. Through iterative rounds, agents revise their predictions by\nobserving the outputs of others, simulating deliberation and consensus\nformation. To enhance interpretability, we introduce a latent variable\nrepresenting each agent's underlying belief(e.g., hawkish or dovish), and we\ntheoretically demonstrate how this belief mediates the perception of input\ninformation and interaction dynamics. Empirical results show that this\ndebate-based approach significantly outperforms standard LLMs-based baselines\nin prediction accuracy. Furthermore, the explicit modeling of beliefs provides\ninsights into how individual perspectives and social influence shape collective\npolicy forecasts.",
      "pdf_url": "http://arxiv.org/pdf/2511.02469v1",
      "published": "2025-11-04T10:56:01+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.02469v1",
      "categories": [
        "q-fin.CP",
        "cs.AI",
        "cs.MA"
      ]
    },
    {
      "title": "Auditable-choice reframing unlocks RL-based verification for open-ended tasks",
      "authors": [
        "Mengyu Zhang",
        "Xubo Liu",
        "Siyu Ding",
        "Weichong Yin",
        "Yu Sun",
        "Hua Wu",
        "Wenya Guo",
        "Ying Zhang"
      ],
      "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has demonstrated great\npotential in enhancing the reasoning capabilities of large language models\n(LLMs), achieving remarkable progress in domains such as mathematics and\nprogramming where standard answers are available. However, for open-ended tasks\nlacking ground-truth solutions (e.g., creative writing and instruction\nfollowing), existing studies typically regard them as non-reasoning scenarios,\nthereby overlooking the latent value of reasoning capabilities. This raises a\nkey question: Can strengthening reasoning improve performance in open-ended\ntasks? To address this, we explore the transfer of the RLVR paradigm to the\nopen domain. Yet, since RLVR fundamentally relies on verifiers that presuppose\nthe existence of standard answers, it cannot be directly applied to open-ended\ntasks. To overcome this challenge, we introduce Verifiable Multiple-Choice\nReformulation (VMR), a novel training strategy that restructures open-ended\ndata into verifiable multiple-choice formats, enabling effective training even\nin the absence of explicit ground truth. Experimental results on multiple\nbenchmarks validate the effectiveness of our method in improving LLM\nperformance on open-ended tasks. Notably, across eight open-ended benchmarks,\nour VMR-based training delivers an average gain of 5.99 points over the\nbaseline. Code will be released upon acceptance to facilitate reproducibility.",
      "pdf_url": "http://arxiv.org/pdf/2511.02463v1",
      "published": "2025-11-04T10:45:52+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.02463v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "SKGE: Spherical Knowledge Graph Embedding with Geometric Regularization",
      "authors": [
        "Xuan-Truong Quan",
        "Xuan-Son Quan",
        "Duc Do Minh",
        "Vinh Nguyen Van"
      ],
      "abstract": "Knowledge graph embedding (KGE) has become a fundamental technique for\nrepresentation learning on multi-relational data. Many seminal models, such as\nTransE, operate in an unbounded Euclidean space, which presents inherent\nlimitations in modeling complex relations and can lead to inefficient training.\nIn this paper, we propose Spherical Knowledge Graph Embedding (SKGE), a model\nthat challenges this paradigm by constraining entity representations to a\ncompact manifold: a hypersphere. SKGE employs a learnable, non-linear\nSpherization Layer to map entities onto the sphere and interprets relations as\na hybrid translate-then-project transformation. Through extensive experiments\non three benchmark datasets, FB15k-237, CoDEx-S, and CoDEx-M, we demonstrate\nthat SKGE consistently and significantly outperforms its strong Euclidean\ncounterpart, TransE, particularly on large-scale benchmarks such as FB15k-237\nand CoDEx-M, demonstrating the efficacy of the spherical geometric prior. We\nprovide an in-depth analysis to reveal the sources of this advantage, showing\nthat this geometric constraint acts as a powerful regularizer, leading to\ncomprehensive performance gains across all relation types. More fundamentally,\nwe prove that the spherical geometry creates an \"inherently hard negative\nsampling\" environment, naturally eliminating trivial negatives and forcing the\nmodel to learn more robust and semantically coherent representations. Our\nfindings compellingly demonstrate that the choice of manifold is not merely an\nimplementation detail but a fundamental design principle, advocating for\ngeometric priors as a cornerstone for designing the next generation of powerful\nand stable KGE models.",
      "pdf_url": "http://arxiv.org/pdf/2511.02460v1",
      "published": "2025-11-04T10:40:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.02460v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "A Kullback-Leibler divergence method for input-system-state identification",
      "authors": [
        "Marios Impraimakis"
      ],
      "abstract": "The capability of a novel Kullback-Leibler divergence method is examined\nherein within the Kalman filter framework to select the input-parameter-state\nestimation execution with the most plausible results. This identification\nsuffers from the uncertainty related to obtaining different results from\ndifferent initial parameter set guesses, and the examined approach uses the\ninformation gained from the data in going from the prior to the posterior\ndistribution to address the issue. Firstly, the Kalman filter is performed for\na number of different initial parameter sets providing the system\ninput-parameter-state estimation. Secondly, the resulting posterior\ndistributions are compared simultaneously to the initial prior distributions\nusing the Kullback-Leibler divergence. Finally, the identification with the\nleast Kullback-Leibler divergence is selected as the one with the most\nplausible results. Importantly, the method is shown to select the better\nperformed identification in linear, nonlinear, and limited information\napplications, providing a powerful tool for system monitoring.",
      "pdf_url": "http://arxiv.org/pdf/2511.02426v1",
      "published": "2025-11-04T09:57:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.02426v1",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.CV",
        "cs.IT",
        "cs.SY",
        "eess.SY",
        "math.IT",
        "68T05 (Learning and adaptive systems)",
        "I.2.6; I.2.8"
      ]
    },
    {
      "title": "ReAcTree: Hierarchical LLM Agent Trees with Control Flow for Long-Horizon Task Planning",
      "authors": [
        "Jae-Woo Choi",
        "Hyungmin Kim",
        "Hyobin Ong",
        "Minsu Jang",
        "Dohyung Kim",
        "Jaehong Kim",
        "Youngwoo Yoon"
      ],
      "abstract": "Recent advancements in large language models (LLMs) have enabled significant\nprogress in decision-making and task planning for embodied autonomous agents.\nHowever, most existing methods still struggle with complex, long-horizon tasks\nbecause they rely on a monolithic trajectory that entangles all past decisions\nand observations, attempting to solve the entire task in a single unified\nprocess. To address this limitation, we propose ReAcTree, a hierarchical\ntask-planning method that decomposes a complex goal into more manageable\nsubgoals within a dynamically constructed agent tree. Each subgoal is handled\nby an LLM agent node capable of reasoning, acting, and further expanding the\ntree, while control flow nodes coordinate the execution strategies of agent\nnodes. In addition, we integrate two complementary memory systems: each agent\nnode retrieves goal-specific, subgoal-level examples from episodic memory and\nshares environment-specific observations through working memory. Experiments on\nthe WAH-NL and ALFRED datasets demonstrate that ReAcTree consistently\noutperforms strong task-planning baselines such as ReAct across diverse LLMs.\nNotably, on WAH-NL, ReAcTree achieves a 61% goal success rate with Qwen 2.5\n72B, nearly doubling ReAct's 31%.",
      "pdf_url": "http://arxiv.org/pdf/2511.02424v1",
      "published": "2025-11-04T09:55:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.02424v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "A New Perspective on Precision and Recall for Generative Models",
      "authors": [
        "Benjamin Sykes",
        "Loïc Simon",
        "Julien Rabin",
        "Jalal Fadili"
      ],
      "abstract": "With the recent success of generative models in image and text, the question\nof their evaluation has recently gained a lot of attention. While most methods\nfrom the state of the art rely on scalar metrics, the introduction of Precision\nand Recall (PR) for generative model has opened up a new avenue of research.\nThe associated PR curve allows for a richer analysis, but their estimation\nposes several challenges. In this paper, we present a new framework for\nestimating entire PR curves based on a binary classification standpoint. We\nconduct a thorough statistical analysis of the proposed estimates. As a\nbyproduct, we obtain a minimax upper bound on the PR estimation risk. We also\nshow that our framework extends several landmark PR metrics of the literature\nwhich by design are restrained to the extreme values of the curve. Finally, we\nstudy the different behaviors of the curves obtained experimentally in various\nsettings.",
      "pdf_url": "http://arxiv.org/pdf/2511.02414v1",
      "published": "2025-11-04T09:44:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.02414v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Purrturbed but Stable: Human-Cat Invariant Representations Across CNNs, ViTs and Self-Supervised ViTs",
      "authors": [
        "Arya Shah",
        "Vaibhav Tripathi"
      ],
      "abstract": "Cats and humans differ in ocular anatomy. Most notably, Felis Catus (domestic\ncats) have vertically elongated pupils linked to ambush predation; yet, how\nsuch specializations manifest in downstream visual representations remains\nincompletely understood. We present a unified, frozen-encoder benchmark that\nquantifies feline-human cross-species representational alignment in the wild,\nacross convolutional networks, supervised Vision Transformers, windowed\ntransformers, and self-supervised ViTs (DINO), using layer-wise Centered Kernel\nAlignment (linear and RBF) and Representational Similarity Analysis, with\nadditional distributional and stability tests reported in the paper. Across\nmodels, DINO ViT-B/16 attains the most substantial alignment (mean CKA-RBF\n$\\approx0.814$, mean CKA-linear $\\approx0.745$, mean RSA $\\approx0.698$),\npeaking at early blocks, indicating that token-level self-supervision induces\nearly-stage features that bridge species-specific statistics. Supervised ViTs\nare competitive on CKA yet show weaker geometric correspondence than DINO\n(e.g., ViT-B/16 RSA $\\approx0.53$ at block8; ViT-L/16 $\\approx0.47$ at\nblock14), revealing depth-dependent divergences between similarity and\nrepresentational geometry. CNNs remain strong baselines but below plain ViTs on\nalignment, and windowed transformers underperform plain ViTs, implicating\narchitectural inductive biases in cross-species alignment. Results indicate\nthat self-supervision coupled with ViT inductive biases yields representational\ngeometries that more closely align feline and human visual systems than widely\nused CNNs and windowed Transformers, providing testable neuroscientific\nhypotheses about where and how cross-species visual computations converge. We\nrelease our code and dataset for reference and reproducibility.",
      "pdf_url": "http://arxiv.org/pdf/2511.02404v1",
      "published": "2025-11-04T09:35:42+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.02404v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    }
  ]
}