{
  "last_updated": "2025-09-05T00:47:27.118296",
  "papers": [
    {
      "title": "Can the Waymo Open Motion Dataset Support Realistic Behavioral Modeling? A Validation Study with Naturalistic Trajectories",
      "authors": [
        "Yanlin Zhang",
        "Sungyong Chung",
        "Nachuan Li",
        "Dana Monzer",
        "Hani S. Mahmassani",
        "Samer H. Hamdar",
        "Alireza Talebpour"
      ],
      "abstract": "The Waymo Open Motion Dataset (WOMD) has become a popular resource for\ndata-driven modeling of autonomous vehicles (AVs) behavior. However, its\nvalidity for behavioral analysis remains uncertain due to proprietary\npost-processing, the absence of error quantification, and the segmentation of\ntrajectories into 20-second clips. This study examines whether WOMD accurately\ncaptures the dynamics and interactions observed in real-world AV operations.\nLeveraging an independently collected naturalistic dataset from Level 4 AV\noperations in Phoenix, Arizona (PHX), we perform comparative analyses across\nthree representative urban driving scenarios: discharging at signalized\nintersections, car-following, and lane-changing behaviors. For the discharging\nanalysis, headways are manually extracted from aerial video to ensure\nnegligible measurement error. For the car-following and lane-changing cases, we\napply the Simulation-Extrapolation (SIMEX) method to account for empirically\nestimated error in the PHX data and use Dynamic Time Warping (DTW) distances to\nquantify behavioral differences. Results across all scenarios consistently show\nthat behavior in PHX falls outside the behavioral envelope of WOMD. Notably,\nWOMD underrepresents short headways and abrupt decelerations. These findings\nsuggest that behavioral models calibrated solely on WOMD may systematically\nunderestimate the variability, risk, and complexity of naturalistic driving.\nCaution is therefore warranted when using WOMD for behavior modeling without\nproper validation against independently collected data.",
      "pdf_url": "http://arxiv.org/pdf/2509.03515v1",
      "published": "2025-09-03T17:56:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.03515v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "eess.SY",
        "stat.AP"
      ]
    },
    {
      "title": "LimiX: Unleashing Structured-Data Modeling Capability for Generalist Intelligence",
      "authors": [
        "Xingxuan Zhang",
        "Gang Ren",
        "Han Yu",
        "Hao Yuan",
        "Hui Wang",
        "Jiansheng Li",
        "Jiayun Wu",
        "Lang Mo",
        "Li Mao",
        "Mingchao Hao",
        "Ningbo Dai",
        "Renzhe Xu",
        "Shuyang Li",
        "Tianyang Zhang",
        "Yue He",
        "Yuanrui Wang",
        "Yunjia Zhang",
        "Zijing Xu",
        "Dongzhe Li",
        "Fang Gao",
        "Hao Zou",
        "Jiandong Liu",
        "Jiashuo Liu",
        "Jiawei Xu",
        "Kaijie Cheng",
        "Kehan Li",
        "Linjun Zhou",
        "Qing Li",
        "Shaohua Fan",
        "Xiaoyu Lin",
        "Xinyan Han",
        "Xuanyue Li",
        "Yan Lu",
        "Yuan Xue",
        "Yuanyuan Jiang",
        "Zimu Wang",
        "Zhenlei Wang",
        "Peng Cui"
      ],
      "abstract": "We argue that progress toward general intelligence requires complementary\nfoundation models grounded in language, the physical world, and structured\ndata. This report presents LimiX, the first installment of our large\nstructured-data models (LDMs). LimiX treats structured data as a joint\ndistribution over variables and missingness, thus capable of addressing a wide\nrange of tabular tasks through query-based conditional prediction via a single\nmodel. LimiX is pretrained using masked joint-distribution modeling with an\nepisodic, context-conditional objective, where the model predicts for query\nsubsets conditioned on dataset-specific contexts, supporting rapid,\ntraining-free adaptation at inference. We evaluate LimiX across 10 large\nstructured-data benchmarks with broad regimes of sample size, feature\ndimensionality, class number, categorical-to-numerical feature ratio,\nmissingness, and sample-to-feature ratios. With a single model and a unified\ninterface, LimiX consistently surpasses strong baselines including\ngradient-boosting trees, deep tabular networks, recent tabular foundation\nmodels, and automated ensembles, as shown in Figure 1 and Figure 2. The\nsuperiority holds across a wide range of tasks, such as classification,\nregression, missing value imputation, and data generation, often by substantial\nmargins, while avoiding task-specific architectures or bespoke training per\ntask. All LimiX models are publicly accessible under Apache 2.0.",
      "pdf_url": "http://arxiv.org/pdf/2509.03505v1",
      "published": "2025-09-03T17:39:08+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.03505v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Warming Up for Zeroth-Order Federated Pre-Training with Low Resource Clients",
      "authors": [
        "Gwen Legate",
        "Irina Rish",
        "Eugene Belilovsky"
      ],
      "abstract": "Federated learning enables collaborative model training across numerous edge\ndevices without requiring participants to share data; however, memory and\ncommunication constraints on these edge devices may preclude their\nparticipation in training. We consider a setting in which a subset of edge\ndevices are below a critical memory or communication threshold required to\nconduct model updates. Under typical federated optimization algorithms, these\ndevices are excluded from training which renders their data inaccessible and\nincreases system induced bias. We are inspired by MeZO, a zeroth-order method\nused for memory-efficient fine-tuning. The increased variance inherent to\nzeroth-order gradient approximations has relegated previous zeroth-order\noptimizers exclusively to the domain of fine tuning; a limitation we seek to\ncorrect. We devise a federated, memory-efficient zeroth-order optimizer,\nZOWarmUp that permits zeroth-order training from a random initialization.\nZOWarmUp leverages differing client capabilities and careful variance reduction\ntechniques to facilitate participation of under-represented, low-resource\nclients in model training. Like other federated zeroth-order methods, ZOWarmUp\neliminates the need for edge devices to transmit their full gradients to the\nserver and instead relies on only a small set of random seeds, rendering the\nup-link communication cost negligible. We present experiments using various\ndatasets and model architectures to show that ZOWarmUp is a robust algorithm\nthat can can be applied under a wide variety of circumstances. For systems with\na high proportion of edge devices that would otherwise be excluded from\ntraining, this algorithm provides access to a greater volume and diversity of\ndata, thus improving training outcomes.",
      "pdf_url": "http://arxiv.org/pdf/2509.03503v1",
      "published": "2025-09-03T17:35:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.03503v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Strefer: Empowering Video LLMs with Space-Time Referring and Reasoning via Synthetic Instruction Data",
      "authors": [
        "Honglu Zhou",
        "Xiangyu Peng",
        "Shrikant Kendre",
        "Michael S. Ryoo",
        "Silvio Savarese",
        "Caiming Xiong",
        "Juan Carlos Niebles"
      ],
      "abstract": "Next-generation AI companions must go beyond general video understanding to\nresolve spatial and temporal references in dynamic, real-world environments.\nExisting Video Large Language Models (Video LLMs), while capable of\ncoarse-level comprehension, struggle with fine-grained, spatiotemporal\nreasoning, especially when user queries rely on time-based event references for\ntemporal anchoring, or gestural cues for spatial anchoring to clarify object\nreferences and positions. To bridge this critical gap, we introduce Strefer, a\nsynthetic instruction data generation framework designed to equip Video LLMs\nwith spatiotemporal referring and reasoning capabilities. Strefer produces\ndiverse instruction-tuning data using a data engine that pseudo-annotates\ntemporally dense, fine-grained video metadata, capturing rich spatial and\ntemporal information in a structured manner, including subjects, objects, their\nlocations as masklets, and their action descriptions and timelines. Our\napproach enhances the ability of Video LLMs to interpret spatial and temporal\nreferences, fostering more versatile, space-time-aware reasoning essential for\nreal-world AI companions. Without using proprietary models, costly human\nannotation, or the need to annotate large volumes of new videos, experimental\nevaluations show that models trained with data produced by Strefer outperform\nbaselines on tasks requiring spatial and temporal disambiguation. Additionally,\nthese models exhibit enhanced space-time-aware reasoning, establishing a new\nfoundation for perceptually grounded, instruction-tuned Video LLMs.",
      "pdf_url": "http://arxiv.org/pdf/2509.03501v1",
      "published": "2025-09-03T17:33:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.03501v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ]
    },
    {
      "title": "Real-Time Instrument Planning and Perception for Novel Measurements of Dynamic Phenomena",
      "authors": [
        "Itai Zilberstein",
        "Alberto Candela",
        "Steve Chien"
      ],
      "abstract": "Advancements in onboard computing mean remote sensing agents can employ\nstate-of-the-art computer vision and machine learning at the edge. These\ncapabilities can be leveraged to unlock new rare, transient, and pinpoint\nmeasurements of dynamic science phenomena. In this paper, we present an\nautomated workflow that synthesizes the detection of these dynamic events in\nlook-ahead satellite imagery with autonomous trajectory planning for a\nfollow-up high-resolution sensor to obtain pinpoint measurements. We apply this\nworkflow to the use case of observing volcanic plumes. We analyze\nclassification approaches including traditional machine learning algorithms and\nconvolutional neural networks. We present several trajectory planning\nalgorithms that track the morphological features of a plume and integrate these\nalgorithms with the classifiers. We show through simulation an order of\nmagnitude increase in the utility return of the high-resolution instrument\ncompared to baselines while maintaining efficient runtimes.",
      "pdf_url": "http://arxiv.org/pdf/2509.03500v1",
      "published": "2025-09-03T17:32:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.03500v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "On Entropy Control in LLM-RL Algorithms",
      "authors": [
        "Han Shen"
      ],
      "abstract": "For RL algorithms, appropriate entropy control is crucial to their\neffectiveness. To control the policy entropy, a commonly used method is entropy\nregularization, which is adopted in various popular RL algorithms including\nPPO, SAC and A3C. Although entropy regularization proves effective in robotic\nand games RL conventionally, studies found that it gives weak to no gains in\nLLM-RL training. In this work, we study the issues of entropy bonus in LLM-RL\nsetting. Specifically, we first argue that the conventional entropy\nregularization suffers from the LLM's extremely large response space and the\nsparsity of the optimal outputs. As a remedy, we propose AEnt, an entropy\ncontrol method that utilizes a new clamped entropy bonus with an automatically\nadjusted coefficient. The clamped entropy is evaluated with the re-normalized\npolicy defined on certain smaller token space, which encourages exploration\nwithin a more compact response set. In addition, the algorithm automatically\nadjusts entropy coefficient according to the clamped entropy value, effectively\ncontrolling the entropy-induced bias while leveraging the entropy's benefits.\nAEnt is tested in math-reasoning tasks under different base models and\ndatasets, and it is observed that AEnt outperforms the baselines consistently\nacross multiple benchmarks.",
      "pdf_url": "http://arxiv.org/pdf/2509.03493v1",
      "published": "2025-09-03T17:23:19+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.03493v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "SafeProtein: Red-Teaming Framework and Benchmark for Protein Foundation Models",
      "authors": [
        "Jigang Fan",
        "Zhenghong Zhou",
        "Ruofan Jin",
        "Le Cong",
        "Mengdi Wang",
        "Zaixi Zhang"
      ],
      "abstract": "Proteins play crucial roles in almost all biological processes. The\nadvancement of deep learning has greatly accelerated the development of protein\nfoundation models, leading to significant successes in protein understanding\nand design. However, the lack of systematic red-teaming for these models has\nraised serious concerns about their potential misuse, such as generating\nproteins with biological safety risks. This paper introduces SafeProtein, the\nfirst red-teaming framework designed for protein foundation models to the best\nof our knowledge. SafeProtein combines multimodal prompt engineering and\nheuristic beam search to systematically design red-teaming methods and conduct\ntests on protein foundation models. We also curated SafeProtein-Bench, which\nincludes a manually constructed red-teaming benchmark dataset and a\ncomprehensive evaluation protocol. SafeProtein achieved continuous jailbreaks\non state-of-the-art protein foundation models (up to 70% attack success rate\nfor ESM3), revealing potential biological safety risks in current protein\nfoundation models and providing insights for the development of robust security\nprotection technologies for frontier models. The codes will be made publicly\navailable at https://github.com/jigang-fan/SafeProtein.",
      "pdf_url": "http://arxiv.org/pdf/2509.03487v1",
      "published": "2025-09-03T17:13:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.03487v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "q-bio.BM",
        "q-bio.QM"
      ]
    },
    {
      "title": "Robult: Leveraging Redundancy and Modality Specific Features for Robust Multimodal Learning",
      "authors": [
        "Duy A. Nguyen",
        "Abhi Kamboj",
        "Minh N. Do"
      ],
      "abstract": "Addressing missing modalities and limited labeled data is crucial for\nadvancing robust multimodal learning. We propose Robult, a scalable framework\ndesigned to mitigate these challenges by preserving modality-specific\ninformation and leveraging redundancy through a novel information-theoretic\napproach. Robult optimizes two core objectives: (1) a soft Positive-Unlabeled\n(PU) contrastive loss that maximizes task-relevant feature alignment while\neffectively utilizing limited labeled data in semi-supervised settings, and (2)\na latent reconstruction loss that ensures unique modality-specific information\nis retained. These strategies, embedded within a modular design, enhance\nperformance across various downstream tasks and ensure resilience to incomplete\nmodalities during inference. Experimental results across diverse datasets\nvalidate that Robult achieves superior performance over existing approaches in\nboth semi-supervised learning and missing modality contexts. Furthermore, its\nlightweight design promotes scalability and seamless integration with existing\narchitectures, making it suitable for real-world multimodal applications.",
      "pdf_url": "http://arxiv.org/pdf/2509.03477v1",
      "published": "2025-09-03T16:56:27+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.03477v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "DPQuant: Efficient and Differentially-Private Model Training via Dynamic Quantization Scheduling",
      "authors": [
        "Yubo Gao",
        "Renbo Tu",
        "Gennady Pekhimenko",
        "Nandita Vijaykumar"
      ],
      "abstract": "Differentially-Private SGD (DP-SGD) is a powerful technique to protect user\nprivacy when using sensitive data to train neural networks. During training,\nconverting model weights and activations into low-precision formats, i.e.,\nquantization, can drastically reduce training times, energy consumption, and\ncost, and is thus a widely used technique. In this work, we demonstrate that\nquantization causes significantly higher accuracy degradation in DP-SGD\ncompared to regular SGD. We observe that this is caused by noise injection in\nDP-SGD, which amplifies quantization variance, leading to disproportionately\nlarge accuracy degradation. To address this challenge, we present QPQuant, a\ndynamic quantization framework that adaptively selects a changing subset of\nlayers to quantize at each epoch. Our method combines two key ideas that\neffectively reduce quantization variance: (i) probabilistic sampling of the\nlayers that rotates which layers are quantized every epoch, and (ii) loss-aware\nlayer prioritization, which uses a differentially private loss sensitivity\nestimator to identify layers that can be quantized with minimal impact on model\nquality. This estimator consumes a negligible fraction of the overall privacy\nbudget, preserving DP guarantees. Empirical evaluations on ResNet18, ResNet50,\nand DenseNet121 across a range of datasets demonstrate that DPQuant\nconsistently outperforms static quantization baselines, achieving near\nPareto-optimal accuracy-compute trade-offs and up to 2.21x theoretical\nthroughput improvements on low-precision hardware, with less than 2% drop in\nvalidation accuracy.",
      "pdf_url": "http://arxiv.org/pdf/2509.03472v1",
      "published": "2025-09-03T16:51:26+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.03472v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ]
    },
    {
      "title": "Continuous Saudi Sign Language Recognition: A Vision Transformer Approach",
      "authors": [
        "Soukeina Elhassen",
        "Lama Al Khuzayem",
        "Areej Alhothali",
        "Ohoud Alzamzami",
        "Nahed Alowaidi"
      ],
      "abstract": "Sign language (SL) is an essential communication form for hearing-impaired\nand deaf people, enabling engagement within the broader society. Despite its\nsignificance, limited public awareness of SL often leads to inequitable access\nto educational and professional opportunities, thereby contributing to social\nexclusion, particularly in Saudi Arabia, where over 84,000 individuals depend\non Saudi Sign Language (SSL) as their primary form of communication. Although\ncertain technological approaches have helped to improve communication for\nindividuals with hearing impairments, there continues to be an urgent\nrequirement for more precise and dependable translation techniques, especially\nfor Arabic sign language variants like SSL. Most state-of-the-art solutions\nhave primarily focused on non-Arabic sign languages, resulting in a\nconsiderable absence of resources dedicated to Arabic sign language,\nspecifically SSL. The complexity of the Arabic language and the prevalence of\nisolated sign language datasets that concentrate on individual words instead of\ncontinuous speech contribute to this issue. To address this gap, our research\nrepresents an important step in developing SSL resources. To address this, we\nintroduce the first continuous Saudi Sign Language dataset called KAU-CSSL,\nfocusing on complete sentences to facilitate further research and enable\nsophisticated recognition systems for SSL recognition and translation.\nAdditionally, we propose a transformer-based model, utilizing a pretrained\nResNet-18 for spatial feature extraction and a Transformer Encoder with\nBidirectional LSTM for temporal dependencies, achieving 99.02\\% accuracy at\nsigner dependent mode and 77.71\\% accuracy at signer independent mode. This\ndevelopment leads the way to not only improving communication tools for the SSL\ncommunity but also making a substantial contribution to the wider field of sign\nlanguage.",
      "pdf_url": "http://arxiv.org/pdf/2509.03467v1",
      "published": "2025-09-03T16:44:08+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.03467v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "sam-llm: interpretable lane change trajectoryprediction via parametric finetuning",
      "authors": [
        "Zhuo Cao",
        "Yunxiao Shi",
        "Min Xu"
      ],
      "abstract": "This work introduces SAM-LLM, a novel hybrid architecture that bridges the\ngap between the contextual reasoning of Large Language Models (LLMs) and the\nphysical precision of kinematic lane change models for autonomous driving. The\nsystem is designed for interpretable lane change trajectory prediction by\nfinetuning an LLM to output the core physical parameters of a trajectory model\ninstead of raw coordinates. For lane-keeping scenarios, the model predicts\ndiscrete coordinates, but for lane change maneuvers, it generates the\nparameters for an enhanced Sinusoidal Acceleration Model (SAM), including\nlateral displacement, maneuver duration, initial lateral velocity, and\nlongitudinal velocity change. This parametric approach yields a complete,\ncontinuous, and physically plausible trajectory model that is inherently\ninterpretable and computationally efficient, achieving an 80% reduction in\noutput size compared to coordinate-based methods. The SAM-LLM achieves a\nstate-of-the-art overall intention prediction accuracy of 98.73%, demonstrating\nperformance equivalent to traditional LLM predictors while offering significant\nadvantages in explainability and resource efficiency.",
      "pdf_url": "http://arxiv.org/pdf/2509.03462v1",
      "published": "2025-09-03T16:37:49+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.03462v1",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.RO"
      ]
    },
    {
      "title": "Multi-level SSL Feature Gating for Audio Deepfake Detection",
      "authors": [
        "Hoan My Tran",
        "Damien Lolive",
        "Aghilas Sini",
        "Arnaud Delhay",
        "Pierre-François Marteau",
        "David Guennec"
      ],
      "abstract": "Recent advancements in generative AI, particularly in speech synthesis, have\nenabled the generation of highly natural-sounding synthetic speech that closely\nmimics human voices. While these innovations hold promise for applications like\nassistive technologies, they also pose significant risks, including misuse for\nfraudulent activities, identity theft, and security threats. Current research\non spoofing detection countermeasures remains limited by generalization to\nunseen deepfake attacks and languages. To address this, we propose a gating\nmechanism extracting relevant feature from the speech foundation XLS-R model as\na front-end feature extractor. For downstream back-end classifier, we employ\nMulti-kernel gated Convolution (MultiConv) to capture both local and global\nspeech artifacts. Additionally, we introduce Centered Kernel Alignment (CKA) as\na similarity metric to enforce diversity in learned features across different\nMultiConv layers. By integrating CKA with our gating mechanism, we hypothesize\nthat each component helps improving the learning of distinct synthetic speech\npatterns. Experimental results demonstrate that our approach achieves\nstate-of-the-art performance on in-domain benchmarks while generalizing\nrobustly to out-of-domain datasets, including multilingual speech samples. This\nunderscores its potential as a versatile solution for detecting evolving speech\ndeepfake threats.",
      "pdf_url": "http://arxiv.org/pdf/2509.03409v1",
      "published": "2025-09-03T15:37:52+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.03409v1",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.MM",
        "I.2.7"
      ]
    },
    {
      "title": "Beyond Correctness: Harmonizing Process and Outcome Rewards through RL Training",
      "authors": [
        "Chenlu Ye",
        "Zhou Yu",
        "Ziji Zhang",
        "Hao Chen",
        "Narayanan Sadagopan",
        "Jing Huang",
        "Tong Zhang",
        "Anurag Beniwal"
      ],
      "abstract": "Reinforcement learning with verifiable rewards (RLVR) has emerged to be a\npredominant paradigm for mathematical reasoning tasks, offering stable\nimprovements in reasoning ability. However, Outcome Reward Models (ORMs) in\nRLVR are too coarse-grained to distinguish flawed reasoning within correct\nanswers or valid reasoning within incorrect answers. This lack of granularity\nintroduces noisy and misleading gradients significantly and hinders further\nprogress in reasoning process quality. While Process Reward Models (PRMs) offer\nfine-grained guidance for intermediate steps, they frequently suffer from\ninaccuracies and are susceptible to reward hacking.\n  To resolve this dilemma, we introduce PRocess cOnsistency Filter (PROF), an\neffective data process curation method that harmonizes noisy, fine-grained\nprocess rewards with accurate, coarse-grained outcome rewards. Rather than\nnaively blending PRM and ORM in the objective function\n(arXiv:archive/2506.18896), PROF leverages their complementary strengths\nthrough consistency-driven sample selection. Our approach retains correct\nresponses with higher averaged process values and incorrect responses with\nlower averaged process values, while maintaining positive/negative training\nsample balance. Extensive experiments demonstrate that our method not only\nconsistently improves the final accuracy over $4\\%$ compared to the blending\napproaches, but also strengthens the quality of intermediate reasoning steps.\nCodes and training recipes are available at https://github.com/Chenluye99/PROF.",
      "pdf_url": "http://arxiv.org/pdf/2509.03403v1",
      "published": "2025-09-03T15:28:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.03403v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "ANNIE: Be Careful of Your Robots",
      "authors": [
        "Yiyang Huang",
        "Zixuan Wang",
        "Zishen Wan",
        "Yapeng Tian",
        "Haobo Xu",
        "Yinhe Han",
        "Yiming Gan"
      ],
      "abstract": "The integration of vision-language-action (VLA) models into embodied AI (EAI)\nrobots is rapidly advancing their ability to perform complex, long-horizon\ntasks in humancentric environments. However, EAI systems introduce critical\nsecurity risks: a compromised VLA model can directly translate adversarial\nperturbations on sensory input into unsafe physical actions. Traditional safety\ndefinitions and methodologies from the machine learning community are no longer\nsufficient. EAI systems raise new questions, such as what constitutes safety,\nhow to measure it, and how to design effective attack and defense mechanisms in\nphysically grounded, interactive settings. In this work, we present the first\nsystematic study of adversarial safety attacks on embodied AI systems, grounded\nin ISO standards for human-robot interactions. We (1) formalize a principled\ntaxonomy of safety violations (critical, dangerous, risky) based on physical\nconstraints such as separation distance, velocity, and collision boundaries;\n(2) introduce ANNIEBench, a benchmark of nine safety-critical scenarios with\n2,400 video-action sequences for evaluating embodied safety; and (3)\nANNIE-Attack, a task-aware adversarial framework with an attack leader model\nthat decomposes long-horizon goals into frame-level perturbations. Our\nevaluation across representative EAI models shows attack success rates\nexceeding 50% across all safety categories. We further demonstrate sparse and\nadaptive attack strategies and validate the real-world impact through physical\nrobot experiments. These results expose a previously underexplored but highly\nconsequential attack surface in embodied AI systems, highlighting the urgent\nneed for security-driven defenses in the physical AI era. Code is available at\nhttps://github.com/RLCLab/Annie.",
      "pdf_url": "http://arxiv.org/pdf/2509.03383v1",
      "published": "2025-09-03T15:00:28+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.03383v1",
      "categories": [
        "cs.AI",
        "cs.RO"
      ]
    },
    {
      "title": "Situating AI Agents in their World: Aspective Agentic AI for Dynamic Partially Observable Information Systems",
      "authors": [
        "Peter J. Bentley",
        "Soo Ling Lim",
        "Fuyuki Ishikawa"
      ],
      "abstract": "Agentic LLM AI agents are often little more than autonomous chatbots: actors\nfollowing scripts, often controlled by an unreliable director. This work\nintroduces a bottom-up framework that situates AI agents in their environment,\nwith all behaviors triggered by changes in their environments. It introduces\nthe notion of aspects, similar to the idea of umwelt, where sets of agents\nperceive their environment differently to each other, enabling clearer control\nof information. We provide an illustrative implementation and show that\ncompared to a typical architecture, which leaks up to 83% of the time,\naspective agentic AI enables zero information leakage. We anticipate that this\nconcept of specialist agents working efficiently in their own information\nniches can provide improvements to both security and efficiency.",
      "pdf_url": "http://arxiv.org/pdf/2509.03380v1",
      "published": "2025-09-03T14:57:04+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.03380v1",
      "categories": [
        "cs.AI",
        "cs.CL",
        "93A16",
        "I.2.11"
      ]
    },
    {
      "title": "TinyDrop: Tiny Model Guided Token Dropping for Vision Transformers",
      "authors": [
        "Guoxin Wang",
        "Qingyuan Wang",
        "Binhua Huang",
        "Shaowu Chen",
        "Deepu John"
      ],
      "abstract": "Vision Transformers (ViTs) achieve strong performance in image classification\nbut incur high computational costs from processing all image tokens. To reduce\ninference costs in large ViTs without compromising accuracy, we propose\nTinyDrop, a training-free token dropping framework guided by a lightweight\nvision model. The guidance model estimates the importance of tokens while\nperforming inference, thereby selectively discarding low-importance tokens if\nlarge vit models need to perform attention calculations. The framework operates\nplug-and-play, requires no architectural modifications, and is compatible with\ndiverse ViT architectures. Evaluations on standard image classification\nbenchmarks demonstrate that our framework reduces FLOPs by up to 80% for ViTs\nwith minimal accuracy degradation, highlighting its generalization capability\nand practical utility for efficient ViT-based classification.",
      "pdf_url": "http://arxiv.org/pdf/2509.03379v1",
      "published": "2025-09-03T14:55:49+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.03379v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "epiGPTope: A machine learning-based epitope generator and classifier",
      "authors": [
        "Natalia Flechas Manrique",
        "Alberto Martínez",
        "Elena López-Martínez",
        "Luc Andrea",
        "Román Orus",
        "Aitor Manteca",
        "Aitziber L. Cortajarena",
        "Llorenç Espinosa-Portalés"
      ],
      "abstract": "Epitopes are short antigenic peptide sequences which are recognized by\nantibodies or immune cell receptors. These are central to the development of\nimmunotherapies, vaccines, and diagnostics. However, the rational design of\nsynthetic epitope libraries is challenging due to the large combinatorial\nsequence space, $20^n$ combinations for linear epitopes of n amino acids,\nmaking screening and testing unfeasible, even with high throughput experimental\ntechniques. In this study, we present a large language model, epiGPTope,\npre-trained on protein data and specifically fine-tuned on linear epitopes,\nwhich for the first time can directly generate novel epitope-like sequences,\nwhich are found to possess statistical properties analogous to the ones of\nknown epitopes. This generative approach can be used to prepare libraries of\nepitope candidate sequences. We further train statistical classifiers to\npredict whether an epitope sequence is of bacterial or viral origin, thus\nnarrowing the candidate library and increasing the likelihood of identifying\nspecific epitopes. We propose that such combination of generative and\npredictive models can be of assistance in epitope discovery. The approach uses\nonly primary amino acid sequences of linear epitopes, bypassing the need for a\ngeometric framework or hand-crafted features of the sequences. By developing a\nmethod to create biologically feasible sequences, we anticipate faster and more\ncost-effective generation and screening of synthetic epitopes, with relevant\napplications in the development of new biotechnologies.",
      "pdf_url": "http://arxiv.org/pdf/2509.03351v1",
      "published": "2025-09-03T14:36:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.03351v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ]
    },
    {
      "title": "Language Models Do Not Follow Occam's Razor: A Benchmark for Inductive and Abductive Reasoning",
      "authors": [
        "Yunxin Sun",
        "Abulhair Saparov"
      ],
      "abstract": "Reasoning is a core capability in artificial intelligence systems, for which\nlarge language models (LLMs) have recently shown remarkable progress. However,\nmost work focuses exclusively on deductive reasoning, which is problematic\nsince other types of reasoning are also essential in solving real-world\nproblems, and they are less explored. This work focuses on evaluating LLMs'\ninductive and abductive reasoning capabilities. We introduce a programmable and\nsynthetic dataset, InAbHyD (pronounced in-a-bid), where each reasoning example\nconsists of an incomplete world model and a set of observations. The task for\nthe intelligent agent is to produce hypotheses to explain observations under\nthe incomplete world model to solve each reasoning example. We propose a new\nmetric to evaluate the quality of hypotheses based on Occam's Razor. We\nevaluate and analyze some state-of-the-art LLMs. Our analysis shows that LLMs\ncan perform inductive and abductive reasoning in simple scenarios, but struggle\nwith complex world models and producing high-quality hypotheses, even with\npopular reasoning-enhancing techniques such as in-context learning and RLVR.",
      "pdf_url": "http://arxiv.org/pdf/2509.03345v1",
      "published": "2025-09-03T14:22:42+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.03345v1",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "On the MIA Vulnerability Gap Between Private GANs and Diffusion Models",
      "authors": [
        "Ilana Sebag",
        "Jean-Yves Franceschi",
        "Alain Rakotomamonjy",
        "Alexandre Allauzen",
        "Jamal Atif"
      ],
      "abstract": "Generative Adversarial Networks (GANs) and diffusion models have emerged as\nleading approaches for high-quality image synthesis. While both can be trained\nunder differential privacy (DP) to protect sensitive data, their sensitivity to\nmembership inference attacks (MIAs), a key threat to data confidentiality,\nremains poorly understood. In this work, we present the first unified\ntheoretical and empirical analysis of the privacy risks faced by differentially\nprivate generative models. We begin by showing, through a stability-based\nanalysis, that GANs exhibit fundamentally lower sensitivity to data\nperturbations than diffusion models, suggesting a structural advantage in\nresisting MIAs. We then validate this insight with a comprehensive empirical\nstudy using a standardized MIA pipeline to evaluate privacy leakage across\ndatasets and privacy budgets. Our results consistently reveal a marked privacy\nrobustness gap in favor of GANs, even in strong DP regimes, highlighting that\nmodel type alone can critically shape privacy leakage.",
      "pdf_url": "http://arxiv.org/pdf/2509.03341v1",
      "published": "2025-09-03T14:18:22+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.03341v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Equivariant Flow Matching for Symmetry-Breaking Bifurcation Problems",
      "authors": [
        "Fleur Hendriks",
        "Ondřej Rokoš",
        "Martin Doškář",
        "Marc G. D. Geers",
        "Vlado Menkovski"
      ],
      "abstract": "Bifurcation phenomena in nonlinear dynamical systems often lead to multiple\ncoexisting stable solutions, particularly in the presence of symmetry breaking.\nDeterministic machine learning models struggle to capture this multiplicity,\naveraging over solutions and failing to represent lower-symmetry outcomes. In\nthis work, we propose a generative framework based on flow matching to model\nthe full probability distribution over bifurcation outcomes. Our method enables\ndirect sampling of multiple valid solutions while preserving system symmetries\nthrough equivariant modeling. We introduce a symmetric matching strategy that\naligns predicted and target outputs under group actions, allowing accurate\nlearning in equivariant settings. We validate our approach on a range of\nsystems, from toy models to complex physical problems such as buckling beams\nand the Allen-Cahn equation. Our results demonstrate that flow matching\nsignificantly outperforms non-probabilistic and variational methods in\ncapturing multimodal distributions and symmetry-breaking bifurcations, offering\na principled and scalable solution for modeling multistability in\nhigh-dimensional systems.",
      "pdf_url": "http://arxiv.org/pdf/2509.03340v1",
      "published": "2025-09-03T14:18:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.03340v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE",
        "physics.comp-ph"
      ]
    },
    {
      "title": "Heatmap Guided Query Transformers for Robust Astrocyte Detection across Immunostains and Resolutions",
      "authors": [
        "Xizhe Zhang",
        "Jiayang Zhu"
      ],
      "abstract": "Astrocytes are critical glial cells whose altered morphology and density are\nhallmarks of many neurological disorders. However, their intricate branching\nand stain dependent variability make automated detection of histological images\na highly challenging task. To address these challenges, we propose a hybrid CNN\nTransformer detector that combines local feature extraction with global\ncontextual reasoning. A heatmap guided query mechanism generates spatially\ngrounded anchors for small and faint astrocytes, while a lightweight\nTransformer module improves discrimination in dense clusters. Evaluated on\nALDH1L1 and GFAP stained astrocyte datasets, the model consistently\noutperformed Faster R-CNN, YOLOv11 and DETR, achieving higher sensitivity with\nfewer false positives, as confirmed by FROC analysis. These results highlight\nthe potential of hybrid CNN Transformer architectures for robust astrocyte\ndetection and provide a foundation for advanced computational pathology tools.",
      "pdf_url": "http://arxiv.org/pdf/2509.03323v1",
      "published": "2025-09-03T14:01:04+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.03323v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "app.build: A Production Framework for Scaling Agentic Prompt-to-App Generation with Environment Scaffolding",
      "authors": [
        "Evgenii Kniazev",
        "Arseny Kravchenko",
        "Igor Rekun",
        "James Broadhead",
        "Nikita Shamgunov",
        "Pranav Sah",
        "Pratik Nichite",
        "Ivan Yamshchikov"
      ],
      "abstract": "We present app.build (https://github.com/appdotbuild/agent/), an open-source\nframework that improves LLM-based application generation through systematic\nvalidation and structured environments. Our approach combines multi-layered\nvalidation pipelines, stack-specific orchestration, and model-agnostic\narchitecture, implemented across three reference stacks. Through evaluation on\n30 generation tasks, we demonstrate that comprehensive validation achieves\n73.3% viability rate with 30% reaching perfect quality scores, while\nopen-weights models achieve 80.8% of closed-model performance when provided\nstructured environments. The open-source framework has been adopted by the\ncommunity, with over 3,000 applications generated to date. This work\ndemonstrates that scaling reliable AI agents requires scaling environments, not\njust models -- providing empirical insights and complete reference\nimplementations for production-oriented agent systems.",
      "pdf_url": "http://arxiv.org/pdf/2509.03310v1",
      "published": "2025-09-03T13:41:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.03310v1",
      "categories": [
        "cs.AI",
        "cs.SE"
      ]
    },
    {
      "title": "Automatic Differentiation of Agent-Based Models",
      "authors": [
        "Arnau Quera-Bofarull",
        "Nicholas Bishop",
        "Joel Dyer",
        "Daniel Jarne Ornia",
        "Anisoara Calinescu",
        "Doyne Farmer",
        "Michael Wooldridge"
      ],
      "abstract": "Agent-based models (ABMs) simulate complex systems by capturing the bottom-up\ninteractions of individual agents comprising the system. Many complex systems\nof interest, such as epidemics or financial markets, involve thousands or even\nmillions of agents. Consequently, ABMs often become computationally demanding\nand rely on the calibration of numerous free parameters, which has\nsignificantly hindered their widespread adoption. In this paper, we demonstrate\nthat automatic differentiation (AD) techniques can effectively alleviate these\ncomputational burdens. By applying AD to ABMs, the gradients of the simulator\nbecome readily available, greatly facilitating essential tasks such as\ncalibration and sensitivity analysis. Specifically, we show how AD enables\nvariational inference (VI) techniques for efficient parameter calibration. Our\nexperiments demonstrate substantial performance improvements and computational\nsavings using VI on three prominent ABMs: Axtell's model of firms; Sugarscape;\nand the SIR epidemiological model. Our approach thus significantly enhances the\npracticality and scalability of ABMs for studying complex systems.",
      "pdf_url": "http://arxiv.org/pdf/2509.03303v1",
      "published": "2025-09-03T13:28:33+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.03303v1",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.CE",
        "cs.LG"
      ]
    },
    {
      "title": "A Comprehensive Guide to Differential Privacy: From Theory to User Expectations",
      "authors": [
        "Napsu Karmitsa",
        "Antti Airola",
        "Tapio Pahikkala",
        "Tinja Pitkämäki"
      ],
      "abstract": "The increasing availability of personal data has enabled significant advances\nin fields such as machine learning, healthcare, and cybersecurity. However,\nthis data abundance also raises serious privacy concerns, especially in light\nof powerful re-identification attacks and growing legal and ethical demands for\nresponsible data use. Differential privacy (DP) has emerged as a principled,\nmathematically grounded framework for mitigating these risks. This review\nprovides a comprehensive survey of DP, covering its theoretical foundations,\npractical mechanisms, and real-world applications. It explores key algorithmic\ntools and domain-specific challenges - particularly in privacy-preserving\nmachine learning and synthetic data generation. The report also highlights\nusability issues and the need for improved communication and transparency in DP\nsystems. Overall, the goal is to support informed adoption of DP by researchers\nand practitioners navigating the evolving landscape of data privacy.",
      "pdf_url": "http://arxiv.org/pdf/2509.03294v1",
      "published": "2025-09-03T13:23:10+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.03294v1",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG",
        "68P27, 68T09, 94A60"
      ]
    },
    {
      "title": "Accountability Framework for Healthcare AI Systems: Towards Joint Accountability in Decision Making",
      "authors": [
        "Prachi Bagave",
        "Marcus Westberg",
        "Marijn Janssen",
        "Aaron Yi Ding"
      ],
      "abstract": "AI is transforming the healthcare domain and is increasingly helping\npractitioners to make health-related decisions. Therefore, accountability\nbecomes a crucial concern for critical AI-driven decisions. Although regulatory\nbodies, such as the EU commission, provide guidelines, they are highlevel and\nfocus on the ''what'' that should be done and less on the ''how'', creating a\nknowledge gap for actors. Through an extensive analysis, we found that the term\naccountability is perceived and dealt with in many different ways, depending on\nthe actor's expertise and domain of work. With increasing concerns about AI\naccountability issues and the ambiguity around this term, this paper bridges\nthe gap between the ''what'' and ''how'' of AI accountability, specifically for\nAI systems in healthcare. We do this by analysing the concept of\naccountability, formulating an accountability framework, and providing a\nthree-tier structure for handling various accountability mechanisms. Our\naccountability framework positions the regulations of healthcare AI systems and\nthe mechanisms adopted by the actors under a consistent accountability regime.\nMoreover, the three-tier structure guides the actors of the healthcare AI\nsystem to categorise the mechanisms based on their conduct. Through our\nframework, we advocate that decision-making in healthcare AI holds shared\ndependencies, where accountability should be dealt with jointly and should\nfoster collaborations. We highlight the role of explainability in instigating\ncommunication and information sharing between the actors to further facilitate\nthe collaborative process.",
      "pdf_url": "http://arxiv.org/pdf/2509.03286v1",
      "published": "2025-09-03T13:05:29+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.03286v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Estudio de la eficiencia en la escalabilidad de GPUs para el entrenamiento de Inteligencia Artificial",
      "authors": [
        "David Cortes",
        "Carlos Juiz",
        "Belen Bermejo"
      ],
      "abstract": "Training large-scale deep learning models has become a key challenge for the\nscientific community and industry. While the massive use of GPUs can\nsignificantly speed up training times, this approach has a negative impact on\nefficiency. In this article, we present a detailed analysis of the times\nreported by MLPerf Training v4.1 on four workloads: BERT, Llama2 LoRA,\nRetinaNet, and Stable Diffusion, showing that there are configurations that\noptimise the relationship between performance, GPU usage, and efficiency. The\nresults point to a break-even point that allows training times to be reduced\nwhile maximising efficiency.",
      "pdf_url": "http://arxiv.org/pdf/2509.03263v1",
      "published": "2025-09-03T12:24:42+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.03263v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.PF"
      ]
    },
    {
      "title": "HyPV-LEAD: Proactive Early-Warning of Cryptocurrency Anomalies through Data-Driven Structural-Temporal Modeling",
      "authors": [
        "Minjung Park",
        "Gyuyeon Na",
        "Soyoun Kim",
        "Sunyoung Moon",
        "HyeonJeong Cha",
        "Sangmi Chai"
      ],
      "abstract": "Abnormal cryptocurrency transactions - such as mixing services, fraudulent\ntransfers, and pump-and-dump operations -- pose escalating risks to financial\nintegrity but remain notoriously difficult to detect due to class imbalance,\ntemporal volatility, and complex network dependencies. Existing approaches are\npredominantly model-centric and post hoc, flagging anomalies only after they\noccur and thus offering limited preventive value. This paper introduces\nHyPV-LEAD (Hyperbolic Peak-Valley Lead-time Enabled Anomaly Detection), a\ndata-driven early-warning framework that explicitly incorporates lead time into\nanomaly detection. Unlike prior methods, HyPV-LEAD integrates three\ninnovations: (1) window-horizon modeling to guarantee actionable lead-time\nalerts, (2) Peak-Valley (PV) sampling to mitigate class imbalance while\npreserving temporal continuity, and (3) hyperbolic embedding to capture the\nhierarchical and scale-free properties of blockchain transaction networks.\nEmpirical evaluation on large-scale Bitcoin transaction data demonstrates that\nHyPV-LEAD consistently outperforms state-of-the-art baselines, achieving a\nPR-AUC of 0.9624 with significant gains in precision and recall. Ablation\nstudies further confirm that each component - PV sampling, hyperbolic\nembedding, and structural-temporal modeling - provides complementary benefits,\nwith the full framework delivering the highest performance. By shifting anomaly\ndetection from reactive classification to proactive early-warning, HyPV-LEAD\nestablishes a robust foundation for real-time risk management, anti-money\nlaundering (AML) compliance, and financial security in dynamic blockchain\nenvironments.",
      "pdf_url": "http://arxiv.org/pdf/2509.03260v1",
      "published": "2025-09-03T12:23:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.03260v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-fin.RM"
      ]
    },
    {
      "title": "Structure Transfer: an Inference-Based Calculus for the Transformation of Representations",
      "authors": [
        "Daniel Raggi",
        "Gem Stapleton",
        "Mateja Jamnik",
        "Aaron Stockdill",
        "Grecia Garcia Garcia",
        "Peter C-H. Cheng"
      ],
      "abstract": "Representation choice is of fundamental importance to our ability to\ncommunicate and reason effectively. A major unsolved problem, addressed in this\npaper, is how to devise representational-system (RS) agnostic techniques that\ndrive representation transformation and choice. We present a novel calculus,\ncalled structure transfer, that enables representation transformation across\ndiverse RSs. Specifically, given a source representation drawn from a source\nRS, the rules of structure transfer allow us to generate a target\nrepresentation for a target RS. The generality of structure transfer comes in\npart from its ability to ensure that the source representation and the\ngenerated target representation satisfy any specified relation (such as\nsemantic equivalence). This is done by exploiting schemas, which encode\nknowledge about RSs. Specifically, schemas can express preservation of\ninformation across relations between any pair of RSs, and this knowledge is\nused by structure transfer to derive a structure for the target representation\nwhich ensures that the desired relation holds. We formalise this using\nRepresentational Systems Theory, building on the key concept of a construction\nspace. The abstract nature of construction spaces grants them the generality to\nmodel RSs of diverse kinds, including formal languages, geometric figures and\ndiagrams, as well as informal notations. Consequently, structure transfer is a\nsystem-agnostic calculus that can be used to identify alternative\nrepresentations in a wide range of practical settings.",
      "pdf_url": "http://arxiv.org/pdf/2509.03249v2",
      "published": "2025-09-03T12:07:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.03249v2",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.LO",
        "68T30, 68T27, 03B35",
        "I.2.4; I.2.3; F.4.1; F.4.3"
      ]
    },
    {
      "title": "FoMEMO: Towards Foundation Models for Expensive Multi-objective Optimization",
      "authors": [
        "Yiming Yao",
        "Fei Liu",
        "Liang Zhao",
        "Xi Lin",
        "Qingfu Zhang"
      ],
      "abstract": "Expensive multi-objective optimization is a prevalent and crucial concern in\nmany real-world scenarios, where sample-efficiency is vital due to the limited\nevaluations to recover the true Pareto front for decision making. Existing\nworks either involve rebuilding Gaussian process surrogates from scratch for\neach objective in each new problem encountered, or rely on extensive past\ndomain experiments for pre-training deep learning models, making them hard to\ngeneralize and impractical to cope with various emerging applications in the\nreal world. To address this issue, we propose a new paradigm named FoMEMO\n(Foundation Models for Expensive Multi-objective Optimization), which enables\nthe establishment of a foundation model conditioned on any domain trajectory\nand user preference, and facilitates fast in-context optimization based on the\npredicted preference-wise aggregation posteriors. Rather than accessing\nextensive domain experiments in the real world, we demonstrate that\npre-training the foundation model with a diverse set of hundreds of millions of\nsynthetic data can lead to superior adaptability to unknown problems, without\nnecessitating any subsequent model training or updates in the optimization\nprocess. We evaluate our method across a variety of synthetic benchmarks and\nreal-word applications, and demonstrate its superior generality and competitive\nperformance compared to existing methods.",
      "pdf_url": "http://arxiv.org/pdf/2509.03244v1",
      "published": "2025-09-03T12:00:24+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.03244v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Evaluation of Stress Detection as Time Series Events -- A Novel Window-Based F1-Metric",
      "authors": [
        "Harald Vilhelm Skat-Rørdam",
        "Sneha Das",
        "Kathrine Sofie Rasmussen",
        "Nicole Nadine Lønfeldt",
        "Line Clemmensen"
      ],
      "abstract": "Accurate evaluation of event detection in time series is essential for\napplications such as stress monitoring with wearable devices, where ground\ntruth is typically annotated as single-point events, even though the underlying\nphenomena are gradual and temporally diffused. Standard metrics like F1 and\npoint-adjusted F1 (F1$_{pa}$) often misrepresent model performance in such\nreal-world, imbalanced datasets. We introduce a window-based F1 metric (F1$_w$)\nthat incorporates temporal tolerance, enabling a more robust assessment of\nevent detection when exact alignment is unrealistic. Empirical analysis in\nthree physiological datasets, two in-the-wild (ADARP, Wrist Angel) and one\nexperimental (ROAD), indicates that F1$_w$ reveals meaningful model performance\npatterns invisible to conventional metrics, while its window size can be\nadapted to domain knowledge to avoid overestimation. We show that the choice of\nevaluation metric strongly influences the interpretation of model performance:\nusing predictions from TimesFM, only our temporally tolerant metrics reveal\nstatistically significant improvements over random and null baselines in the\ntwo in-the-wild use cases. This work addresses key gaps in time series\nevaluation and provides practical guidance for healthcare applications where\nrequirements for temporal precision vary by context.",
      "pdf_url": "http://arxiv.org/pdf/2509.03240v1",
      "published": "2025-09-03T11:55:28+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.03240v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME"
      ]
    },
    {
      "title": "LGBP-OrgaNet: Learnable Gaussian Band Pass Fusion of CNN and Transformer Features for Robust Organoid Segmentation and Tracking",
      "authors": [
        "Jing Zhang",
        "Siying Tao",
        "Jiao Li",
        "Tianhe Wang",
        "Junchen Wu",
        "Ruqian Hao",
        "Xiaohui Du",
        "Ruirong Tan",
        "Rui Li"
      ],
      "abstract": "Organoids replicate organ structure and function, playing a crucial role in\nfields such as tumor treatment and drug screening. Their shape and size can\nindicate their developmental status, but traditional fluorescence labeling\nmethods risk compromising their structure. Therefore, this paper proposes an\nautomated, non-destructive approach to organoid segmentation and tracking. We\nintroduced the LGBP-OrgaNet, a deep learning-based system proficient in\naccurately segmenting, tracking, and quantifying organoids. The model leverages\ncomplementary information extracted from CNN and Transformer modules and\nintroduces the innovative feature fusion module, Learnable Gaussian Band Pass\nFusion, to merge data from two branches. Additionally, in the decoder, the\nmodel proposes a Bidirectional Cross Fusion Block to fuse multi-scale features,\nand finally completes the decoding through progressive concatenation and\nupsampling. SROrga demonstrates satisfactory segmentation accuracy and\nrobustness on organoids segmentation datasets, providing a potent tool for\norganoid research.",
      "pdf_url": "http://arxiv.org/pdf/2509.03221v1",
      "published": "2025-09-03T11:24:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.03221v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Uncertainty-driven Adaptive Exploration",
      "authors": [
        "Leonidas Bakopoulos",
        "Georgios Chalkiadakis"
      ],
      "abstract": "Adaptive exploration methods propose ways to learn complex policies via\nalternating between exploration and exploitation. An important question for\nsuch methods is to determine the appropriate moment to switch between\nexploration and exploitation and vice versa. This is critical in domains that\nrequire the learning of long and complex sequences of actions. In this work, we\npresent a generic adaptive exploration framework that employs uncertainty to\naddress this important issue in a principled manner. Our framework includes\nprevious adaptive exploration approaches as special cases. Moreover, we can\nincorporate in our framework any uncertainty-measuring mechanism of choice, for\ninstance mechanisms used in intrinsic motivation or epistemic uncertainty-based\nexploration methods. We experimentally demonstrate that our framework gives\nrise to adaptive exploration strategies that outperform standard ones across\nseveral MuJoCo environments.",
      "pdf_url": "http://arxiv.org/pdf/2509.03219v1",
      "published": "2025-09-03T11:13:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.03219v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Autonomous Learning From Success and Failure: Goal-Conditioned Supervised Learning with Negative Feedback",
      "authors": [
        "Zeqiang Zhang",
        "Fabian Wurzberger",
        "Gerrit Schmid",
        "Sebastian Gottwald",
        "Daniel A. Braun"
      ],
      "abstract": "Reinforcement learning faces significant challenges when applied to tasks\ncharacterized by sparse reward structures. Although imitation learning, within\nthe domain of supervised learning, offers faster convergence, it relies heavily\non human-generated demonstrations. Recently, Goal-Conditioned Supervised\nLearning (GCSL) has emerged as a potential solution by enabling self-imitation\nlearning for autonomous systems. By strategically relabelling goals, agents can\nderive policy insights from their own experiences. Despite the successes of\nthis framework, it presents two notable limitations: (1) Learning exclusively\nfrom self-generated experiences can exacerbate the agents' inherent biases; (2)\nThe relabelling strategy allows agents to focus solely on successful outcomes,\nprecluding them from learning from their mistakes. To address these issues, we\npropose a novel model that integrates contrastive learning principles into the\nGCSL framework to learn from both success and failure. Through empirical\nevaluations, we demonstrate that our algorithm overcomes limitations imposed by\nagents' initial biases and thereby enables more exploratory behavior. This\nfacilitates the identification and adoption of effective policies, leading to\nsuperior performance across a variety of challenging environments.",
      "pdf_url": "http://arxiv.org/pdf/2509.03206v1",
      "published": "2025-09-03T10:50:48+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.03206v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "AutoDetect: Designing an Autoencoder-based Detection Method for Poisoning Attacks on Object Detection Applications in the Military Domain",
      "authors": [
        "Alma M. Liezenga",
        "Stefan Wijnja",
        "Puck de Haan",
        "Niels W. T. Brink",
        "Jip J. van Stijn",
        "Yori Kamphuis",
        "Klamer Schutte"
      ],
      "abstract": "Poisoning attacks pose an increasing threat to the security and robustness of\nArtificial Intelligence systems in the military domain. The widespread use of\nopen-source datasets and pretrained models exacerbates this risk. Despite the\nseverity of this threat, there is limited research on the application and\ndetection of poisoning attacks on object detection systems. This is especially\nproblematic in the military domain, where attacks can have grave consequences.\nIn this work, we both investigate the effect of poisoning attacks on military\nobject detectors in practice, and the best approach to detect these attacks. To\nsupport this research, we create a small, custom dataset featuring military\nvehicles: MilCivVeh. We explore the vulnerability of military object detectors\nfor poisoning attacks by implementing a modified version of the BadDet attack:\na patch-based poisoning attack. We then assess its impact, finding that while a\npositive attack success rate is achievable, it requires a substantial portion\nof the data to be poisoned -- raising questions about its practical\napplicability. To address the detection challenge, we test both specialized\npoisoning detection methods and anomaly detection methods from the visual\nindustrial inspection domain. Since our research shows that both classes of\nmethods are lacking, we introduce our own patch detection method: AutoDetect, a\nsimple, fast, and lightweight autoencoder-based method. Our method shows\npromising results in separating clean from poisoned samples using the\nreconstruction error of image slices, outperforming existing methods, while\nbeing less time- and memory-intensive. We urge that the availability of large,\nrepresentative datasets in the military domain is a prerequisite to further\nevaluate risks of poisoning attacks and opportunities patch detection.",
      "pdf_url": "http://arxiv.org/pdf/2509.03179v1",
      "published": "2025-09-03T10:05:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.03179v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Rashomon in the Streets: Explanation Ambiguity in Scene Understanding",
      "authors": [
        "Helge Spieker",
        "Jørn Eirik Betten",
        "Arnaud Gotlieb",
        "Nadjib Lazaar",
        "Nassim Belmecheri"
      ],
      "abstract": "Explainable AI (XAI) is essential for validating and trusting models in\nsafety-critical applications like autonomous driving. However, the reliability\nof XAI is challenged by the Rashomon effect, where multiple, equally accurate\nmodels can offer divergent explanations for the same prediction. This paper\nprovides the first empirical quantification of this effect for the task of\naction prediction in real-world driving scenes. Using Qualitative Explainable\nGraphs (QXGs) as a symbolic scene representation, we train Rashomon sets of two\ndistinct model classes: interpretable, pair-based gradient boosting models and\ncomplex, graph-based Graph Neural Networks (GNNs). Using feature attribution\nmethods, we measure the agreement of explanations both within and between these\nclasses. Our results reveal significant explanation disagreement. Our findings\nsuggest that explanation ambiguity is an inherent property of the problem, not\njust a modeling artifact.",
      "pdf_url": "http://arxiv.org/pdf/2509.03169v1",
      "published": "2025-09-03T09:36:18+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.03169v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Domain Adaptation of LLMs for Process Data",
      "authors": [
        "Rafael Seidi Oyamada",
        "Jari Peeperkorn",
        "Jochen De Weerdt",
        "Johannes De Smedt"
      ],
      "abstract": "In recent years, Large Language Models (LLMs) have emerged as a prominent\narea of interest across various research domains, including Process Mining\n(PM). Current applications in PM have predominantly centered on prompt\nengineering strategies or the transformation of event logs into narrative-style\ndatasets, thereby exploiting the semantic capabilities of LLMs to address\ndiverse tasks. In contrast, this study investigates the direct adaptation of\npretrained LLMs to process data without natural language reformulation,\nmotivated by the fact that these models excel in generating sequences of\ntokens, similar to the objective in PM. More specifically, we focus on\nparameter-efficient fine-tuning techniques to mitigate the computational\noverhead typically associated with such models. Our experimental setup focuses\non Predictive Process Monitoring (PPM), and considers both single- and\nmulti-task predictions. The results demonstrate a potential improvement in\npredictive performance over state-of-the-art recurrent neural network (RNN)\napproaches and recent narrative-style-based solutions, particularly in the\nmulti-task setting. Additionally, our fine-tuned models exhibit faster\nconvergence and require significantly less hyperparameter optimization.",
      "pdf_url": "http://arxiv.org/pdf/2509.03161v1",
      "published": "2025-09-03T09:21:35+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.03161v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Decentralised self-organisation of pivoting cube ensembles using geometric deep learning",
      "authors": [
        "Nadezhda Dobreva",
        "Emmanuel Blazquez",
        "Jai Grover",
        "Dario Izzo",
        "Yuzhen Qin",
        "Dominik Dold"
      ],
      "abstract": "We present a decentralized model for autonomous reconfiguration of\nhomogeneous pivoting cube modular robots in two dimensions. Each cube in the\nensemble is controlled by a neural network that only gains information from\nother cubes in its local neighborhood, trained using reinforcement learning.\nFurthermore, using geometric deep learning, we include the grid symmetries of\nthe cube ensemble in the neural network architecture. We find that even the\nmost localized versions succeed in reconfiguring to the target shape, although\nreconfiguration happens faster the more information about the whole ensemble is\navailable to individual cubes. Near-optimal reconfiguration is achieved with\nonly nearest neighbor interactions by using multiple information passing\nbetween cubes, allowing them to accumulate more global information about the\nensemble. Compared to standard neural network architectures, using geometric\ndeep learning approaches provided only minor benefits. Overall, we successfully\ndemonstrate mostly local control of a modular self-assembling system, which is\ntransferable to other space-relevant systems with different action spaces, such\nas sliding cube modular robots and CubeSat swarms.",
      "pdf_url": "http://arxiv.org/pdf/2509.03140v1",
      "published": "2025-09-03T08:50:41+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.03140v1",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.RO"
      ]
    },
    {
      "title": "A Neural Network Approach to Multi-radionuclide TDCR Beta Spectroscopy",
      "authors": [
        "Li Yi",
        "Qian Yang"
      ],
      "abstract": "Liquid scintillation triple-to-doubly coincident ratio (TDCR) spectroscopy is\nwidely adopted as a standard method for radionuclide quantification because of\nits inherent advantages such as high precision, self-calibrating capability,\nand independence from radioactive reference sources. However, multiradionuclide\nanalysis via TDCR faces the challenges of limited automation and reliance on\nmixture-specific standards, which may not be easily available. Here, we present\nan Artificial Intelligence (AI) framework that combines numerical spectral\nsimulation and deep learning for standard-free automated analysis. $\\beta$\nspectra for model training were generated using Geant4 simulations coupled with\nstatistically modeled detector response sampling. A tailored neural network\narchitecture, trained on this dataset covering various nuclei mix ratio and\nquenching scenarios, enables autonomous resolution of individual radionuclide\nactivities and detecting efficiency through end-to-end learning paradigms. The\nmodel delivers consistent high accuracy across tasks: activity proportions\n(mean absolute error = 0.009), detection efficiencies (mean absolute error =\n0.002), and spectral reconstruction (Structural Similarity Index = 0.9998),\nvalidating its physical plausibility for quenched $\\beta$ spectroscopy. This\nAI-driven methodology exhibits significant potential for automated\nsafety-compliant multiradionuclide analysis with robust generalization,\nreal-time processing capabilities, and engineering feasibility, particularly in\nscenarios where reference materials are unavailable or rapid field analysis is\nrequired.",
      "pdf_url": "http://arxiv.org/pdf/2509.03137v1",
      "published": "2025-09-03T08:40:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.03137v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "nucl-ex",
        "physics.comp-ph",
        "physics.ins-det"
      ]
    },
    {
      "title": "Adaptive KV-Cache Compression without Manually Setting Budget",
      "authors": [
        "Chenxia Tang",
        "Jianchun Liu",
        "Hongli Xu",
        "Liusheng Huang"
      ],
      "abstract": "Large language models (LLMs) inference relies heavily on KV-caches to\naccelerate autoregressive decoding, but the resulting memory footprint grows\nrapidly with sequence length, posing significant efficiency challenges. Current\nKV-cache compression methods suffer from a Procrustes' bed problem: they force\ndiverse workloads into fixed compression ratios, leading to suboptimal resource\nallocation and inference performance. To this end, we present GVote, an\nadaptive KV-cache compression scheme that eliminates manual budget\nspecification while achieving superior accuracy-efficiency trade-offs. GVote\noperates on the principle that the important keys are the aggregation of keys\nrequired by future queries. The method predicts future query attention demands\nby Monte-Carlo style sampling potential queries and aggregating selected keys\nto determine the optimal cache budget without manual specification.\nExperimental evaluation demonstrates GVote's effectiveness across multiple\nbenchmarks, including GSM8K, RULER and Longbench. Compared to baselines, GVote\nexhibits 2$\\times$ memory reduction while the accuracy maintains higher or\ncomparable.",
      "pdf_url": "http://arxiv.org/pdf/2509.03136v1",
      "published": "2025-09-03T08:38:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.03136v1",
      "categories": [
        "cs.DB",
        "cs.AI"
      ]
    },
    {
      "title": "From Evaluation to Defense: Constructing Persistent Edit-Based Fingerprints for Large Language Models",
      "authors": [
        "Yue Li",
        "Xin Yi",
        "Dongsheng Shi",
        "Yongyi Cui",
        "Gerard de Melo",
        "Xiaoling Wang",
        "Linlin Wang"
      ],
      "abstract": "The intellectual property (IP) protection of Large Language Models (LLMs) is\nincreasingly critical. Injecting specialized fingerprints into LLMs through\ninstruction tuning is a common IP protection technique. However, this may\nsignificantly degrade model performance, requires substantial computational\nresources, and exhibits poor persistence under model modifications. We argue\nthat knowledge editing offers a lightweight alternative that is more suitable\nfor fingerprint injection. Accordingly, we apply knowledge editing to\nfingerprint injection for the first time and demonstrate its strong capability.\nDespite using scrambled text as fingerprints to prevent them from being\noverwritten during fine-tuning, degradation still occurs under large-scale\nfine-tuning. To address this, we propose Fingerprint Subspace-aware Fine-Tuning\n(FSFT), which reduces fingerprint degradation by constraining the update of the\nfingerprint subspace. The performance of FSFT exceeds fine-tuning by 10% even\nin the worst-case scenario. Additionally, we observe that the\nfingerprint-injected models struggle to distinguish between fingerprints and\nsimilar texts due to the high similarity of their features. This finding\nunderscores the urgent need for more robust and fine-grained fingerprinting\ninjection methods for LLMs.",
      "pdf_url": "http://arxiv.org/pdf/2509.03122v1",
      "published": "2025-09-03T08:22:04+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.03122v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "A Hierarchical Deep Reinforcement Learning Framework for Traffic Signal Control with Predictable Cycle Planning",
      "authors": [
        "Hankang Gu",
        "Yuli Zhang",
        "Chengming Wang",
        "Ruiyuan Jiang",
        "Ziheng Qiao",
        "Pengfei Fan",
        "Dongyao Jia"
      ],
      "abstract": "Deep reinforcement learning (DRL) has become a popular approach in traffic\nsignal control (TSC) due to its ability to learn adaptive policies from complex\ntraffic environments. Within DRL-based TSC methods, two primary control\nparadigms are ``choose phase\" and ``switch\" strategies. Although the agent in\nthe choose phase paradigm selects the next active phase adaptively, this\nparadigm may result in unexpected phase sequences for drivers, disrupting their\nanticipation and potentially compromising safety at intersections. Meanwhile,\nthe switch paradigm allows the agent to decide whether to switch to the next\npredefined phase or extend the current phase. While this structure maintains a\nmore predictable order, it can lead to unfair and inefficient phase\nallocations, as certain movements may be extended disproportionately while\nothers are neglected. In this paper, we propose a DRL model, named Deep\nHierarchical Cycle Planner (DHCP), to allocate the traffic signal cycle\nduration hierarchically. A high-level agent first determines the split of the\ntotal cycle time between the North-South (NS) and East-West (EW) directions\nbased on the overall traffic state. Then, a low-level agent further divides the\nallocated duration within each major direction between straight and left-turn\nmovements, enabling more flexible durations for the two movements. We test our\nmodel on both real and synthetic road networks, along with multiple sets of\nreal and synthetic traffic flows. Empirical results show our model achieves the\nbest performance over all datasets against baselines.",
      "pdf_url": "http://arxiv.org/pdf/2509.03118v1",
      "published": "2025-09-03T08:20:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.03118v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ]
    },
    {
      "title": "Information transmission: Inferring change area from change moment in time series remote sensing images",
      "authors": [
        "Jialu Li",
        "Chen Wu",
        "Meiqi Hu"
      ],
      "abstract": "Time series change detection is a critical task for exploring ecosystem\ndynamics using time series remote sensing images, because it can simultaneously\nindicate where and when change occur. While deep learning has shown excellent\nperformance in this domain, it continues to approach change area detection and\nchange moment identification as distinct tasks. Given that change area can be\ninferred from change moment, we propose a time series change detection network,\nnamed CAIM-Net (Change Area Inference from Moment Network), to ensure\nconsistency between change area and change moment results. CAIM-Net infers\nchange area from change moment based on the intrinsic relationship between time\nseries analysis and spatial change detection. The CAIM-Net comprises three key\nsteps: Difference Extraction and Enhancement, Coarse Change Moment Extraction,\nand Fine Change Moment Extraction and Change Area Inference. In the Difference\nExtraction and Enhancement, a lightweight encoder with batch dimension stacking\nis designed to rapidly extract difference features. Subsequently, boundary\nenhancement convolution is applied to amplify these difference features. In the\nCoarse Change Moment Extraction, the enhanced difference features from the\nfirst step are used to spatiotemporal correlation analysis, and then two\ndistinct methods are employed to determine coarse change moments. In the Fine\nChange Moment Extraction and Change Area Inference, a multiscale temporal Class\nActivation Mapping (CAM) module first increases the weight of the\nchange-occurring moment from coarse change moments. Then the weighted change\nmoment is used to infer change area based on the fact that pixels with the\nchange moment must have undergone a change.",
      "pdf_url": "http://arxiv.org/pdf/2509.03112v1",
      "published": "2025-09-03T08:10:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.03112v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Are We SOLID Yet? An Empirical Study on Prompting LLMs to Detect Design Principle Violations",
      "authors": [
        "Fatih Pehlivan",
        "Arçin Ülkü Ergüzen",
        "Sahand Moslemi Yengejeh",
        "Mayasah Lami",
        "Anil Koyuncu"
      ],
      "abstract": "Traditional static analysis methods struggle to detect semantic design flaws,\nsuch as violations of the SOLID principles, which require a strong\nunderstanding of object-oriented design patterns and principles. Existing\nsolutions typically focus on individual SOLID principles or specific\nprogramming languages, leaving a gap in the ability to detect violations across\nall five principles in multi-language codebases. This paper presents a new\napproach: a methodology that leverages tailored prompt engineering to assess\nLLMs on their ability to detect SOLID violations across multiple languages. We\npresent a benchmark of four leading LLMs-CodeLlama, DeepSeekCoder, QwenCoder,\nand GPT-4o Mini-on their ability to detect violations of all five SOLID\nprinciples. For this evaluation, we construct a new benchmark dataset of 240\nmanually validated code examples. Using this dataset, we test four distinct\nprompt strategies inspired by established zero-shot, few-shot, and\nchain-of-thought techniques to systematically measure their impact on detection\naccuracy. Our emerging results reveal a stark hierarchy among models, with\nGPT-4o Mini decisively outperforming others, yet even struggles with\nchallenging principles like DIP. Crucially, we show that prompt strategy has a\ndramatic impact, but no single strategy is universally best; for instance, a\ndeliberative ENSEMBLE prompt excels at OCP detection while a hint-based EXAMPLE\nprompt is superior for DIP violations. Across all experiments, detection\naccuracy is heavily influenced by language characteristics and degrades sharply\nwith increasing code complexity. These initial findings demonstrate that\neffective, AI-driven design analysis requires not a single best model, but a\ntailored approach that matches the right model and prompt to the specific\ndesign context, highlighting the potential of LLMs to support maintainability\nthrough AI-assisted code analysis.",
      "pdf_url": "http://arxiv.org/pdf/2509.03093v1",
      "published": "2025-09-03T07:48:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.03093v1",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "S2M2ECG: Spatio-temporal bi-directional State Space Model Enabled Multi-branch Mamba for ECG",
      "authors": [
        "Huaicheng Zhang",
        "Ruoxin Wang",
        "Chenlian Zhou",
        "Jiguang Shi",
        "Yue Ge",
        "Zhoutong Li",
        "Sheng Chang",
        "Hao Wang",
        "Jin He",
        "Qijun Huang"
      ],
      "abstract": "As one of the most effective methods for cardiovascular disease (CVD)\ndiagnosis, multi-lead Electrocardiogram (ECG) signals present a characteristic\nmulti-sensor information fusion challenge that has been continuously researched\nin deep learning domains. Despite the numerous algorithms proposed with\ndifferent DL architectures, maintaining a balance among performance,\ncomputational complexity, and multi-source ECG feature fusion remains\nchallenging. Recently, state space models (SSMs), particularly Mamba, have\ndemonstrated remarkable effectiveness across various fields. Their inherent\ndesign for high-efficiency computation and linear complexity makes them\nparticularly suitable for low-dimensional data like ECGs. This work proposes\nS2M2ECG, an SSM architecture featuring three-level fusion mechanisms: (1)\nSpatio-temporal bi-directional SSMs with segment tokenization for low-level\nsignal fusion, (2) Intra-lead temporal information fusion with bi-directional\nscanning to enhance recognition accuracy in both forward and backward\ndirections, (3) Cross-lead feature interaction modules for spatial information\nfusion. To fully leverage the ECG-specific multi-lead mechanisms inherent in\nECG signals, a multi-branch design and lead fusion modules are incorporated,\nenabling individual analysis of each lead while ensuring seamless integration\nwith others. Experimental results reveal that S2M2ECG achieves superior\nperformance in the rhythmic, morphological, and clinical scenarios. Moreover,\nits lightweight architecture ensures it has nearly the fewest parameters among\nexisting models, making it highly suitable for efficient inference and\nconvenient deployment. Collectively, S2M2ECG offers a promising alternative\nthat strikes an excellent balance among performance, computational complexity,\nand ECG-specific characteristics, paving the way for high-performance,\nlightweight computations in CVD diagnosis.",
      "pdf_url": "http://arxiv.org/pdf/2509.03066v1",
      "published": "2025-09-03T06:52:50+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.03066v1",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Loong: Synthesize Long Chain-of-Thoughts at Scale through Verifiers",
      "authors": [
        "Xingyue Huang",
        "Rishabh",
        "Gregor Franke",
        "Ziyi Yang",
        "Jiamu Bai",
        "Weijie Bai",
        "Jinhe Bi",
        "Zifeng Ding",
        "Yiqun Duan",
        "Chengyu Fan",
        "Wendong Fan",
        "Xin Gao",
        "Ruohao Guo",
        "Yuan He",
        "Zhuangzhuang He",
        "Xianglong Hu",
        "Neil Johnson",
        "Bowen Li",
        "Fangru Lin",
        "Siyu Lin",
        "Tong Liu",
        "Yunpu Ma",
        "Hao Shen",
        "Hao Sun",
        "Beibei Wang",
        "Fangyijie Wang",
        "Hao Wang",
        "Haoran Wang",
        "Yang Wang",
        "Yifeng Wang",
        "Zhaowei Wang",
        "Ziyang Wang",
        "Yifan Wu",
        "Zikai Xiao",
        "Chengxing Xie",
        "Fan Yang",
        "Junxiao Yang",
        "Qianshuo Ye",
        "Ziyu Ye",
        "Guangtao Zeng",
        "Yuwen Ebony Zhang",
        "Zeyu Zhang",
        "Zihao Zhu",
        "Bernard Ghanem",
        "Philip Torr",
        "Guohao Li"
      ],
      "abstract": "Recent advances in Large Language Models (LLMs) have shown that their\nreasoning capabilities can be significantly improved through Reinforcement\nLearning with Verifiable Reward (RLVR), particularly in domains like\nmathematics and programming, where ground-truth correctness can be\nautomatically evaluated. However, extending this success to other\nreasoning-intensive domains remains challenging due to the scarcity of\nhigh-quality, verifiable datasets and the high cost of human supervision. In\nthis work, we introduce the Loong Project: an open-source framework for\nscalable synthetic data generation and verification across a diverse range of\nreasoning-intensive domains. The framework consists of two key components: (1)\nLoongBench, a curated seed dataset containing 8,729 human-vetted examples\nacross 12 domains (e.g., Advanced Mathematics, Chemistry, Logic), each paired\nwith executable code and rich metadata; and (2) LoongEnv, a modular synthetic\ndata generation environment that supports multiple prompting strategies to\nproduce new question-answer-code triples. Together, these components form an\nagent-environment loop that enables reinforcement learning, where an LLM-based\nagent is rewarded for generating Chain-of-Thought (CoT) solutions that align\nwith code-executed answers. Empirically, we benchmark LoongBench on a broad\nsuite of both open-source and proprietary LLMs to evaluate domain coverage and\nreveal performance bottlenecks. In addition, we conduct a comprehensive\nanalysis of synthetic data generated by LoongEnv, examining correctness,\ndifficulty, and diversity. Code and documentation are available at\nhttps://github.com/camel-ai/loong.",
      "pdf_url": "http://arxiv.org/pdf/2509.03059v1",
      "published": "2025-09-03T06:42:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.03059v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Binary Quantization For LLMs Through Dynamic Grouping",
      "authors": [
        "Xinzhe Zheng",
        "Zhen-Qun Yang",
        "Haoran Xie",
        "S. Joe Qin",
        "Arlene Chen",
        "Fangzhen Lin"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable performance across\na wide range of Natural Language Processing (NLP) tasks, but require\nsubstantial memory and computational resources. Binary quantization, which\ncompresses model weights from 16-bit Brain Float to 1-bit representations in\n{-1, 1}, offers significant reductions in storage and inference costs. However,\nsuch aggressive quantization often leads to notable performance degradation\ncompared to more conservative 4-bit quantization methods. In this research, we\npropose a novel optimization objective tailored for binary quantization, along\nwith three algorithms designed to realize it effectively. Our method enhances\nblocked quantization by dynamically identifying optimal unstructured\nsub-matrices through adaptive grouping strategies. Experimental results\ndemonstrate that our approach achieves an average bit length of just 1.007\nbits, while maintaining high model quality. Specifically, our quantized LLaMA\n3.2 3B model attains a perplexity of 8.23, remarkably close to the original\n7.81, and surpasses previous SOTA BiLLM with a perplexity of only 123.90.\nFurthermore, our method is competitive with SOTA 4-bit approaches such as GPTQ\nin both performance and efficiency. The compression process is highly\nefficient, requiring only 14 seconds to quantize the full LLaMA 3.2 3B weights\non a single CPU core, with the entire process completing in under 100 minutes\nand exhibiting embarrassingly parallel properties.\n  Code - https://github.com/johnnyzheng0636/WGM_bi_quan",
      "pdf_url": "http://arxiv.org/pdf/2509.03054v1",
      "published": "2025-09-03T06:36:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.03054v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "FlashRecovery: Fast and Low-Cost Recovery from Failures for Large-Scale Training of LLMs",
      "authors": [
        "Haijun Zhang",
        "Jinxiang Wang",
        "Zhenhua Yu",
        "Yanyong Zhang",
        "Xuejie Ji",
        "Kaining Mao",
        "Jun Zhang",
        "Yaqing Zhang",
        "Ting Wu",
        "Fei Jie",
        "Xiemin Huang",
        "Zhifang Cai",
        "Junhua Cheng",
        "Shuwei Wang",
        "Wei Li",
        "Xiaoming Bao",
        "Hua Xu",
        "Shixiong Zhao",
        "Jun Li",
        "Hongwei Sun",
        "Ziyang Zhang",
        "Yi Xiong",
        "Chunsheng Li"
      ],
      "abstract": "Large language models (LLMs) have made a profound impact across various\nfields due to their advanced capabilities. However, training these models at\nunprecedented scales requires extensive AI accelerator clusters and\nsophisticated parallelism strategies, which pose significant challenges in\nmaintaining system reliability over prolonged training periods. A major concern\nis the substantial loss of training time caused by inevitable hardware and\nsoftware failures. To address these challenges, we present FlashRecovery, a\nfast and low-cost failure recovery system comprising three core modules: (1)\nActive and real-time failure detection. This module performs continuous\ntraining state monitoring, enabling immediate identification of hardware and\nsoftware failures within seconds, thus ensuring rapid incident response; (2)\nScale-independent task restart. By employing different recovery strategies for\nnormal and faulty nodes, combined with an optimized communication group\nreconstruction protocol, our approach ensures that the recovery time remains\nnearly constant, regardless of cluster scale; (3) Checkpoint-free recovery\nwithin one step. Our novel recovery mechanism enables single-step restoration,\ncompletely eliminating dependence on traditional checkpointing methods and\ntheir associated overhead. Collectively, these innovations enable FlashRecovery\nto achieve optimal Recovery Time Objective (RTO) and Recovery Point Objective\n(RPO), substantially improving the reliability and efficiency of long-duration\nLLM training. Experimental results demonstrate that FlashRecovery system can\nachieve training restoration on training cluster with 4, 800 devices in 150\nseconds. We also verify that the time required for failure recovery is nearly\nconsistent for different scales of training tasks.",
      "pdf_url": "http://arxiv.org/pdf/2509.03047v1",
      "published": "2025-09-03T06:19:59+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.03047v1",
      "categories": [
        "cs.DC",
        "cs.AI"
      ]
    },
    {
      "title": "MedLiteNet: Lightweight Hybrid Medical Image Segmentation Model",
      "authors": [
        "Pengyang Yu",
        "Haoquan Wang",
        "Gerard Marks",
        "Tahar Kechadi",
        "Laurence T. Yang",
        "Sahraoui Dhelim",
        "Nyothiri Aung"
      ],
      "abstract": "Accurate skin-lesion segmentation remains a key technical challenge for\ncomputer-aided diagnosis of skin cancer. Convolutional neural networks, while\neffective, are constrained by limited receptive fields and thus struggle to\nmodel long-range dependencies. Vision Transformers capture global context, yet\ntheir quadratic complexity and large parameter budgets hinder use on the\nsmall-sample medical datasets common in dermatology. We introduce the\nMedLiteNet, a lightweight CNN Transformer hybrid tailored for dermoscopic\nsegmentation that achieves high precision through hierarchical feature\nextraction and multi-scale context aggregation. The encoder stacks depth-wise\nMobile Inverted Bottleneck blocks to curb computation, inserts a\nbottleneck-level cross-scale token-mixing unit to exchange information between\nresolutions, and embeds a boundary-aware self-attention module to sharpen\nlesion contours.",
      "pdf_url": "http://arxiv.org/pdf/2509.03041v1",
      "published": "2025-09-03T05:59:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.03041v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Knowledge Integration for Physics-informed Symbolic Regression Using Pre-trained Large Language Models",
      "authors": [
        "Bilge Taskin",
        "Wenxiong Xie",
        "Teddy Lazebnik"
      ],
      "abstract": "Symbolic regression (SR) has emerged as a powerful tool for automated\nscientific discovery, enabling the derivation of governing equations from\nexperimental data. A growing body of work illustrates the promise of\nintegrating domain knowledge into the SR to improve the discovered equation's\ngenerality and usefulness. Physics-informed SR (PiSR) addresses this by\nincorporating domain knowledge, but current methods often require specialized\nformulations and manual feature engineering, limiting their adaptability only\nto domain experts. In this study, we leverage pre-trained Large Language Models\n(LLMs) to facilitate knowledge integration in PiSR. By harnessing the\ncontextual understanding of LLMs trained on vast scientific literature, we aim\nto automate the incorporation of domain knowledge, reducing the need for manual\nintervention and making the process more accessible to a broader range of\nscientific problems. Namely, the LLM is integrated into the SR's loss function,\nadding a term of the LLM's evaluation of the SR's produced equation. We\nextensively evaluate our method using three SR algorithms (DEAP, gplearn, and\nPySR) and three pre-trained LLMs (Falcon, Mistral, and LLama 2) across three\nphysical dynamics (dropping ball, simple harmonic motion, and electromagnetic\nwave). The results demonstrate that LLM integration consistently improves the\nreconstruction of physical dynamics from data, enhancing the robustness of SR\nmodels to noise and complexity. We further explore the impact of prompt\nengineering, finding that more informative prompts significantly improve\nperformance.",
      "pdf_url": "http://arxiv.org/pdf/2509.03036v1",
      "published": "2025-09-03T05:53:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.03036v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR",
        "cs.SC"
      ]
    },
    {
      "title": "Unveiling the Response of Large Vision-Language Models to Visually Absent Tokens",
      "authors": [
        "Sohee Kim",
        "Soohyun Ryu",
        "Joonhyung Park",
        "Eunho Yang"
      ],
      "abstract": "Large Vision-Language Models (LVLMs) generate contextually relevant responses\nby jointly interpreting visual and textual inputs. However, our finding reveals\nthey often mistakenly perceive text inputs lacking visual evidence as being\npart of the image, leading to erroneous responses. In light of this finding, we\nprobe whether LVLMs possess an internal capability to determine if textual\nconcepts are grounded in the image, and discover a specific subset of\nFeed-Forward Network (FFN) neurons, termed Visual Absence-aware (VA) neurons,\nthat consistently signal the visual absence through a distinctive activation\npattern. Leveraging these patterns, we develop a detection module that\nsystematically classifies whether an input token is visually grounded. Guided\nby its prediction, we propose a method to refine the outputs by reinterpreting\nquestion prompts or replacing the detected absent tokens during generation.\nExtensive experiments show that our method effectively mitigates the models'\ntendency to falsely presume the visual presence of text input and its\ngenerality across various LVLMs.",
      "pdf_url": "http://arxiv.org/pdf/2509.03025v1",
      "published": "2025-09-03T05:17:25+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.03025v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    }
  ]
}