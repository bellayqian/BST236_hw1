{
  "last_updated": "2025-11-07T00:51:53.959432",
  "papers": [
    {
      "title": "Outbidding and Outbluffing Elite Humans: Mastering Liar's Poker via Self-Play and Reinforcement Learning",
      "authors": [
        "Richard Dewey",
        "Janos Botyanszki",
        "Ciamac C. Moallemi",
        "Andrew T. Zheng"
      ],
      "abstract": "AI researchers have long focused on poker-like games as a testbed for\nenvironments characterized by multi-player dynamics, imperfect information, and\nreasoning under uncertainty. While recent breakthroughs have matched elite\nhuman play at no-limit Texas hold'em, the multi-player dynamics are subdued:\nmost hands converge quickly with only two players engaged through multiple\nrounds of bidding. In this paper, we present Solly, the first AI agent to\nachieve elite human play in reduced-format Liar's Poker, a game characterized\nby extensive multi-player engagement. We trained Solly using self-play with a\nmodel-free, actor-critic, deep reinforcement learning algorithm. Solly played\nat an elite human level as measured by win rate (won over 50% of hands) and\nequity (money won) in heads-up and multi-player Liar's Poker. Solly also\noutperformed large language models (LLMs), including those with reasoning\nabilities, on the same metrics. Solly developed novel bidding strategies,\nrandomized play effectively, and was not easily exploitable by world-class\nhuman players.",
      "pdf_url": "http://arxiv.org/pdf/2511.03724v1",
      "published": "2025-11-05T18:58:18+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.03724v1",
      "categories": [
        "cs.AI",
        "cs.MA"
      ]
    },
    {
      "title": "Grounded Misunderstandings in Asymmetric Dialogue: A Perspectivist Annotation Scheme for MapTask",
      "authors": [
        "Nan Li",
        "Albert Gatt",
        "Massimo Poesio"
      ],
      "abstract": "Collaborative dialogue relies on participants incrementally establishing\ncommon ground, yet in asymmetric settings they may believe they agree while\nreferring to different entities. We introduce a perspectivist annotation scheme\nfor the HCRC MapTask corpus (Anderson et al., 1991) that separately captures\nspeaker and addressee grounded interpretations for each reference expression,\nenabling us to trace how understanding emerges, diverges, and repairs over\ntime. Using a scheme-constrained LLM annotation pipeline, we obtain 13k\nannotated reference expressions with reliability estimates and analyze the\nresulting understanding states. The results show that full misunderstandings\nare rare once lexical variants are unified, but multiplicity discrepancies\nsystematically induce divergences, revealing how apparent grounding can mask\nreferential misalignment. Our framework provides both a resource and an\nanalytic lens for studying grounded misunderstanding and for evaluating\n(V)LLMs' capacity to model perspective-dependent grounding in collaborative\ndialogue.",
      "pdf_url": "http://arxiv.org/pdf/2511.03718v1",
      "published": "2025-11-05T18:52:28+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.03718v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "AnaFlow: Agentic LLM-based Workflow for Reasoning-Driven Explainable and Sample-Efficient Analog Circuit Sizing",
      "authors": [
        "Mohsen Ahmadzadeh",
        "Kaichang Chen",
        "Georges Gielen"
      ],
      "abstract": "Analog/mixed-signal circuits are key for interfacing electronics with the\nphysical world. Their design, however, remains a largely handcrafted process,\nresulting in long and error-prone design cycles. While the recent rise of\nAI-based reinforcement learning and generative AI has created new techniques to\nautomate this task, the need for many time-consuming simulations is a critical\nbottleneck hindering the overall efficiency. Furthermore, the lack of\nexplainability of the resulting design solutions hampers widespread adoption of\nthe tools. To address these issues, a novel agentic AI framework for\nsample-efficient and explainable analog circuit sizing is presented. It employs\na multi-agent workflow where specialized Large Language Model (LLM)-based\nagents collaborate to interpret the circuit topology, to understand the design\ngoals, and to iteratively refine the circuit's design parameters towards the\ntarget goals with human-interpretable reasoning. The adaptive simulation\nstrategy creates an intelligent control that yields a high sample efficiency.\nThe AnaFlow framework is demonstrated for two circuits of varying complexity\nand is able to complete the sizing task fully automatically, differently from\npure Bayesian optimization and reinforcement learning approaches. The system\nlearns from its optimization history to avoid past mistakes and to accelerate\nconvergence. The inherent explainability makes this a powerful tool for analog\ndesign space exploration and a new paradigm in analog EDA, where AI agents\nserve as transparent design assistants.",
      "pdf_url": "http://arxiv.org/pdf/2511.03697v1",
      "published": "2025-11-05T18:24:01+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.03697v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.AR"
      ]
    },
    {
      "title": "The OpenHands Software Agent SDK: A Composable and Extensible Foundation for Production Agents",
      "authors": [
        "Xingyao Wang",
        "Simon Rosenberg",
        "Juan Michelini",
        "Calvin Smith",
        "Hoang Tran",
        "Engel Nyst",
        "Rohit Malhotra",
        "Xuhui Zhou",
        "Valerie Chen",
        "Robert Brennan",
        "Graham Neubig"
      ],
      "abstract": "Agents are now used widely in the process of software development, but\nbuilding production-ready software engineering agents is a complex task.\nDeploying software agents effectively requires flexibility in implementation\nand experimentation, reliable and secure execution, and interfaces for users to\ninteract with agents. In this paper, we present the OpenHands Software Agent\nSDK, a toolkit for implementing software development agents that satisfy these\ndesiderata. This toolkit is a complete architectural redesign of the agent\ncomponents of the popular OpenHands framework for software development agents,\nwhich has 64k+ GitHub stars. To achieve flexibility, we design a simple\ninterface for implementing agents that requires only a few lines of code in the\ndefault case, but is easily extensible to more complex, full-featured agents\nwith features such as custom tools, memory management, and more. For security\nand reliability, it delivers seamless local-to-remote execution portability,\nintegrated REST/WebSocket services. For interaction with human users, it can\nconnect directly to a variety of interfaces, such as visual workspaces (VS\nCode, VNC, browser), command-line interfaces, and APIs. Compared with existing\nSDKs from OpenAI, Claude, and Google, OpenHands uniquely integrates native\nsandboxed execution, lifecycle control, model-agnostic multi-LLM routing, and\nbuilt-in security analysis. Empirical results on SWE-Bench Verified and GAIA\nbenchmarks demonstrate strong performance. Put together, these elements allow\nthe OpenHands Software Agent SDK to provide a practical foundation for\nprototyping, unlocking new classes of custom applications, and reliably\ndeploying agents at scale.",
      "pdf_url": "http://arxiv.org/pdf/2511.03690v1",
      "published": "2025-11-05T18:16:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.03690v1",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "Structured Matrix Scaling for Multi-Class Calibration",
      "authors": [
        "Eugène Berta",
        "David Holzmüller",
        "Michael I. Jordan",
        "Francis Bach"
      ],
      "abstract": "Post-hoc recalibration methods are widely used to ensure that classifiers\nprovide faithful probability estimates. We argue that parametric recalibration\nfunctions based on logistic regression can be motivated from a simple\ntheoretical setting for both binary and multiclass classification. This insight\nmotivates the use of more expressive calibration methods beyond standard\ntemperature scaling. For multi-class calibration however, a key challenge lies\nin the increasing number of parameters introduced by more complex models, often\ncoupled with limited calibration data, which can lead to overfitting. Through\nextensive experiments, we demonstrate that the resulting bias-variance tradeoff\ncan be effectively managed by structured regularization, robust preprocessing\nand efficient optimization. The resulting methods lead to substantial gains\nover existing logistic-based calibration techniques. We provide efficient and\neasy-to-use open-source implementations of our methods, making them an\nattractive alternative to common temperature, vector, and matrix scaling\nimplementations.",
      "pdf_url": "http://arxiv.org/pdf/2511.03685v1",
      "published": "2025-11-05T18:09:14+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.03685v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Whisper Leak: a side-channel attack on Large Language Models",
      "authors": [
        "Geoff McDonald",
        "Jonathan Bar Or"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly deployed in sensitive domains\nincluding healthcare, legal services, and confidential communications, where\nprivacy is paramount. This paper introduces Whisper Leak, a side-channel attack\nthat infers user prompt topics from encrypted LLM traffic by analyzing packet\nsize and timing patterns in streaming responses. Despite TLS encryption\nprotecting content, these metadata patterns leak sufficient information to\nenable topic classification. We demonstrate the attack across 28 popular LLMs\nfrom major providers, achieving near-perfect classification (often >98% AUPRC)\nand high precision even at extreme class imbalance (10,000:1 noise-to-target\nratio). For many models, we achieve 100% precision in identifying sensitive\ntopics like \"money laundering\" while recovering 5-20% of target conversations.\nThis industry-wide vulnerability poses significant risks for users under\nnetwork surveillance by ISPs, governments, or local adversaries. We evaluate\nthree mitigation strategies - random padding, token batching, and packet\ninjection - finding that while each reduces attack effectiveness, none provides\ncomplete protection. Through responsible disclosure, we have collaborated with\nproviders to implement initial countermeasures. Our findings underscore the\nneed for LLM providers to address metadata leakage as AI systems handle\nincreasingly sensitive information.",
      "pdf_url": "http://arxiv.org/pdf/2511.03675v1",
      "published": "2025-11-05T17:47:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.03675v1",
      "categories": [
        "cs.CR",
        "cs.AI",
        "K.4.1; C.2.0; K.6.5; I.2.7"
      ]
    },
    {
      "title": "DQN Performance with Epsilon Greedy Policies and Prioritized Experience Replay",
      "authors": [
        "Daniel Perkins",
        "Oscar J. Escobar",
        "Luke Green"
      ],
      "abstract": "We present a detailed study of Deep Q-Networks in finite environments,\nemphasizing the impact of epsilon-greedy exploration schedules and prioritized\nexperience replay. Through systematic experimentation, we evaluate how\nvariations in epsilon decay schedules affect learning efficiency, convergence\nbehavior, and reward optimization. We investigate how prioritized experience\nreplay leads to faster convergence and higher returns and show empirical\nresults comparing uniform, no replay, and prioritized strategies across\nmultiple simulations. Our findings illuminate the trade-offs and interactions\nbetween exploration strategies and memory management in DQN training, offering\npractical recommendations for robust reinforcement learning in\nresource-constrained settings.",
      "pdf_url": "http://arxiv.org/pdf/2511.03670v1",
      "published": "2025-11-05T17:36:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.03670v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68T05"
      ]
    },
    {
      "title": "ChiMDQA: Towards Comprehensive Chinese Document QA with Fine-grained Evaluation",
      "authors": [
        "Jing Gao",
        "Shutiao Luo",
        "Yumeng Liu",
        "Yuanming Li",
        "Hongji Zeng"
      ],
      "abstract": "With the rapid advancement of natural language processing (NLP) technologies,\nthe demand for high-quality Chinese document question-answering datasets is\nsteadily growing. To address this issue, we present the Chinese Multi-Document\nQuestion Answering Dataset(ChiMDQA), specifically designed for downstream\nbusiness scenarios across prevalent domains including academic, education,\nfinance, law, medical treatment, and news. ChiMDQA encompasses long-form\ndocuments from six distinct fields, consisting of 6,068 rigorously curated,\nhigh-quality question-answer (QA) pairs further classified into ten\nfine-grained categories. Through meticulous document screening and a systematic\nquestion-design methodology, the dataset guarantees both diversity and high\nquality, rendering it applicable to various NLP tasks such as document\ncomprehension, knowledge extraction, and intelligent QA systems. Additionally,\nthis paper offers a comprehensive overview of the dataset's design objectives,\nconstruction methodologies, and fine-grained evaluation system, supplying a\nsubstantial foundation for future research and practical applications in\nChinese QA. The code and data are available at:\nhttps://anonymous.4open.science/r/Foxit-CHiMDQA/.",
      "pdf_url": "http://arxiv.org/pdf/2511.03656v1",
      "published": "2025-11-05T17:13:14+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.03656v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Explaining Human Choice Probabilities with Simple Vector Representations",
      "authors": [
        "Peter DiBerardino",
        "Britt Anderson"
      ],
      "abstract": "When people pursue rewards in stochastic environments, they often match their\nchoice frequencies to the observed target frequencies, even when this policy is\ndemonstrably sub-optimal. We used a ``hide and seek'' task to evaluate this\nbehavior under conditions where pursuit (seeking) could be toggled to avoidance\n(hiding), while leaving the probability distribution fixed, or varying\ncomplexity by changing the number of possible choices. We developed a model for\nparticipant choice built from choice frequency histograms treated as vectors.\nWe posited the existence of a probability antimatching strategy for avoidance\n(hiding) rounds, and formalized this as a vector reflection of probability\nmatching. We found that only two basis policies: matching/antimatching and\nmaximizing/minimizing were sufficient to account for participant choices across\na range of room numbers and opponent probability distributions. This schema\nrequires only that people have the ability to remember the relative frequency\nof the different outcomes. With this knowledge simple operations can construct\nthe maximizing and minimizing policies as well as matching and antimatching\nstrategies. A mixture of these two policies captures human choice patterns in a\nstochastic environment.",
      "pdf_url": "http://arxiv.org/pdf/2511.03643v1",
      "published": "2025-11-05T17:03:03+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.03643v1",
      "categories": [
        "q-bio.NC",
        "cs.AI"
      ]
    },
    {
      "title": "Watermarking Large Language Models in Europe: Interpreting the AI Act in Light of Technology",
      "authors": [
        "Thomas Souverain"
      ],
      "abstract": "To foster trustworthy Artificial Intelligence (AI) within the European Union,\nthe AI Act requires providers to mark and detect the outputs of their\ngeneral-purpose models. The Article 50 and Recital 133 call for marking methods\nthat are ''sufficiently reliable, interoperable, effective and robust''. Yet,\nthe rapidly evolving and heterogeneous landscape of watermarks for Large\nLanguage Models (LLMs) makes it difficult to determine how these four standards\ncan be translated into concrete and measurable evaluations. Our paper addresses\nthis challenge, anchoring the normativity of European requirements in the\nmultiplicity of watermarking techniques. Introducing clear and distinct\nconcepts on LLM watermarking, our contribution is threefold. (1) Watermarking\nCategorisation: We propose an accessible taxonomy of watermarking methods\naccording to the stage of the LLM lifecycle at which they are applied - before,\nduring, or after training, and during next-token distribution or sampling. (2)\nWatermarking Evaluation: We interpret the EU AI Act's requirements by mapping\neach criterion with state-of-the-art evaluations on robustness and\ndetectability of the watermark, and of quality of the LLM. Since\ninteroperability remains largely untheorised in LLM watermarking research, we\npropose three normative dimensions to frame its assessment. (3) Watermarking\nComparison: We compare current watermarking methods for LLMs against the\noperationalised European criteria and show that no approach yet satisfies all\nfour standards. Encouraged by emerging empirical tests, we recommend further\nresearch into watermarking directly embedded within the low-level architecture\nof LLMs.",
      "pdf_url": "http://arxiv.org/pdf/2511.03641v1",
      "published": "2025-11-05T17:00:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.03641v1",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "68T01, 68727, 68T30, 68T35, 68T37, 68T50"
      ]
    },
    {
      "title": "LiveTradeBench: Seeking Real-World Alpha with Large Language Models",
      "authors": [
        "Haofei Yu",
        "Fenghai Li",
        "Jiaxuan You"
      ],
      "abstract": "Large language models (LLMs) achieve strong performance across\nbenchmarks--from knowledge quizzes and math reasoning to web-agent tasks--but\nthese tests occur in static settings, lacking real dynamics and uncertainty.\nConsequently, they evaluate isolated reasoning or problem-solving rather than\ndecision-making under uncertainty. To address this, we introduce\nLiveTradeBench, a live trading environment for evaluating LLM agents in\nrealistic and evolving markets. LiveTradeBench follows three design principles:\n(i) Live data streaming of market prices and news, eliminating dependence on\noffline backtesting and preventing information leakage while capturing\nreal-time uncertainty; (ii) a portfolio-management abstraction that extends\ncontrol from single-asset actions to multi-asset allocation, integrating risk\nmanagement and cross-asset reasoning; and (iii) multi-market evaluation across\nstructurally distinct environments--U.S. stocks and Polymarket prediction\nmarkets--differing in volatility, liquidity, and information flow. At each\nstep, an agent observes prices, news, and its portfolio, then outputs\npercentage allocations that balance risk and return. Using LiveTradeBench, we\nrun 50-day live evaluations of 21 LLMs across families. Results show that (1)\nhigh LMArena scores do not imply superior trading outcomes; (2) models display\ndistinct portfolio styles reflecting risk appetite and reasoning dynamics; and\n(3) some LLMs effectively leverage live signals to adapt decisions. These\nfindings expose a gap between static evaluation and real-world competence,\nmotivating benchmarks that test sequential decision making and consistency\nunder live uncertainty.",
      "pdf_url": "http://arxiv.org/pdf/2511.03628v1",
      "published": "2025-11-05T16:47:26+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.03628v1",
      "categories": [
        "q-fin.TR",
        "cs.AI",
        "cs.CE",
        "cs.CL"
      ]
    },
    {
      "title": "Visualization Biases MLLM's Decision Making in Network Data Tasks",
      "authors": [
        "Timo Brand",
        "Henry Förster",
        "Stephen G. Kobourov",
        "Jacob Miller"
      ],
      "abstract": "We evaluate how visualizations can influence the judgment of MLLMs about the\npresence or absence of bridges in a network. We show that the inclusion of\nvisualization improves confidence over a structured text-based input that could\ntheoretically be helpful for answering the question. On the other hand, we\nobserve that standard visualization techniques create a strong bias towards\naccepting or refuting the presence of a bridge -- independently of whether or\nnot a bridge actually exists in the network. While our results indicate that\nthe inclusion of visualization techniques can effectively influence the MLLM's\njudgment without compromising its self-reported confidence, they also imply\nthat practitioners must be careful of allowing users to include visualizations\nin generative AI applications so as to avoid undesired hallucinations.",
      "pdf_url": "http://arxiv.org/pdf/2511.03617v1",
      "published": "2025-11-05T16:34:12+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.03617v1",
      "categories": [
        "cs.GR",
        "cs.AI"
      ]
    },
    {
      "title": "Step-Audio-EditX Technical Report",
      "authors": [
        "Chao Yan",
        "Boyong Wu",
        "Peng Yang",
        "Pengfei Tan",
        "Guoqiang Hu",
        "Yuxin Zhang",
        "Xiangyu",
        "Zhang",
        "Fei Tian",
        "Xuerui Yang",
        "Xiangyu Zhang",
        "Daxin Jiang",
        "Gang Yu"
      ],
      "abstract": "We present Step-Audio-EditX, the first open-source LLM-based audio model\nexcelling at expressive and iterative audio editing encompassing emotion,\nspeaking style, and paralinguistics alongside robust zero-shot text-to-speech\n(TTS) capabilities.Our core innovation lies in leveraging only large-margin\nsynthetic data, which circumvents the need for embedding-based priors or\nauxiliary modules. This large-margin learning approach enables both iterative\ncontrol and high expressivity across voices, and represents a fundamental pivot\nfrom the conventional focus on representation-level disentanglement. Evaluation\nresults demonstrate that Step-Audio-EditX surpasses both MiniMax-2.6-hd and\nDoubao-Seed-TTS-2.0 in emotion editing and other fine-grained control tasks.",
      "pdf_url": "http://arxiv.org/pdf/2511.03601v1",
      "published": "2025-11-05T16:22:19+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.03601v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.SD",
        "eess.AS"
      ]
    },
    {
      "title": "PerfDojo: Automated ML Library Generation for Heterogeneous Architectures",
      "authors": [
        "Andrei Ivanov",
        "Siyuan Shen",
        "Gioele Gottardo",
        "Marcin Chrapek",
        "Afif Boudaoud",
        "Timo Schneider",
        "Luca Benini",
        "Torsten Hoefler"
      ],
      "abstract": "The increasing complexity of machine learning models and the proliferation of\ndiverse hardware architectures (CPUs, GPUs, accelerators) make achieving\noptimal performance a significant challenge. Heterogeneity in instruction sets,\nspecialized kernel requirements for different data types and model features\n(e.g., sparsity, quantization), and architecture-specific optimizations\ncomplicate performance tuning. Manual optimization is resource-intensive, while\nexisting automatic approaches often rely on complex hardware-specific\nheuristics and uninterpretable intermediate representations, hindering\nperformance portability. We introduce PerfLLM, a novel automatic optimization\nmethodology leveraging Large Language Models (LLMs) and Reinforcement Learning\n(RL). Central to this is PerfDojo, an environment framing optimization as an RL\ngame using a human-readable, mathematically-inspired code representation that\nguarantees semantic validity through transformations. This allows effective\noptimization without prior hardware knowledge, facilitating both human analysis\nand RL agent training. We demonstrate PerfLLM's ability to achieve significant\nperformance gains across diverse CPU (x86, Arm, RISC-V) and GPU architectures.",
      "pdf_url": "http://arxiv.org/pdf/2511.03586v1",
      "published": "2025-11-05T16:05:26+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.03586v1",
      "categories": [
        "cs.PF",
        "cs.AI"
      ]
    },
    {
      "title": "Learning Under Laws: A Constraint-Projected Neural PDE Solver that Eliminates Hallucinations",
      "authors": [
        "Mainak Singha"
      ],
      "abstract": "Neural networks can approximate solutions to partial differential equations,\nbut they often break the very laws they are meant to model-creating mass from\nnowhere, drifting shocks, or violating conservation and entropy. We address\nthis by training within the laws of physics rather than beside them. Our\nframework, called Constraint-Projected Learning (CPL), keeps every update\nphysically admissible by projecting network outputs onto the intersection of\nconstraint sets defined by conservation, Rankine-Hugoniot balance, entropy, and\npositivity. The projection is differentiable and adds only about 10%\ncomputational overhead, making it fully compatible with back-propagation. We\nfurther stabilize training with total-variation damping (TVD) to suppress small\noscillations and a rollout curriculum that enforces consistency over long\nprediction horizons. Together, these mechanisms eliminate both hard and soft\nviolations: conservation holds at machine precision, total-variation growth\nvanishes, and entropy and error remain bounded. On Burgers and Euler systems,\nCPL produces stable, physically lawful solutions without loss of accuracy.\nInstead of hoping neural solvers will respect physics, CPL makes that behavior\nan intrinsic property of the learning process.",
      "pdf_url": "http://arxiv.org/pdf/2511.03578v1",
      "published": "2025-11-05T16:01:19+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.03578v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Multi-User Personalisation in Human-Robot Interaction: Using Quantitative Bipolar Argumentation Frameworks for Preferences Conflict Resolution",
      "authors": [
        "Aniol Civit",
        "Antonio Andriella",
        "Carles Sierra",
        "Guillem Alenyà"
      ],
      "abstract": "While personalisation in Human-Robot Interaction (HRI) has advanced\nsignificantly, most existing approaches focus on single-user adaptation,\noverlooking scenarios involving multiple stakeholders with potentially\nconflicting preferences. To address this, we propose the Multi-User Preferences\nQuantitative Bipolar Argumentation Framework (MUP-QBAF), a novel multi-user\npersonalisation framework based on Quantitative Bipolar Argumentation\nFrameworks (QBAFs) that explicitly models and resolves multi-user preference\nconflicts. Unlike prior work in Argumentation Frameworks, which typically\nassumes static inputs, our approach is tailored to robotics: it incorporates\nboth users' arguments and the robot's dynamic observations of the environment,\nallowing the system to adapt over time and respond to changing contexts.\nPreferences, both positive and negative, are represented as arguments whose\nstrength is recalculated iteratively based on new information. The framework's\nproperties and capabilities are presented and validated through a realistic\ncase study, where an assistive robot mediates between the conflicting\npreferences of a caregiver and a care recipient during a frailty assessment\ntask. This evaluation further includes a sensitivity analysis of argument base\nscores, demonstrating how preference outcomes can be shaped by user input and\ncontextual observations. By offering a transparent, structured, and\ncontext-sensitive approach to resolving competing user preferences, this work\nadvances the field of multi-user HRI. It provides a principled alternative to\ndata-driven methods, enabling robots to navigate conflicts in real-world\nenvironments.",
      "pdf_url": "http://arxiv.org/pdf/2511.03576v1",
      "published": "2025-11-05T15:59:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.03576v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "68T40",
        "I.2.9; I.2.4"
      ]
    },
    {
      "title": "Imitation Learning in the Deep Learning Era: A Novel Taxonomy and Recent Advances",
      "authors": [
        "Iason Chrysomallis",
        "Georgios Chalkiadakis"
      ],
      "abstract": "Imitation learning (IL) enables agents to acquire skills by observing and\nreplicating the behavior of one or multiple experts. In recent years, advances\nin deep learning have significantly expanded the capabilities and scalability\nof imitation learning across a range of domains, where expert data can range\nfrom full state-action trajectories to partial observations or unlabeled\nsequences. Alongside this growth, novel approaches have emerged, with new\nmethodologies being developed to address longstanding challenges such as\ngeneralization, covariate shift, and demonstration quality. In this survey, we\nreview the latest advances in imitation learning research, highlighting recent\ntrends, methodological innovations, and practical applications. We propose a\nnovel taxonomy that is distinct from existing categorizations to better reflect\nthe current state of the IL research stratum and its trends. Throughout the\nsurvey, we critically examine the strengths, limitations, and evaluation\npractices of representative works, and we outline key challenges and open\ndirections for future research.",
      "pdf_url": "http://arxiv.org/pdf/2511.03565v1",
      "published": "2025-11-05T15:47:29+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.03565v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "AILA--First Experiments with Localist Language Models",
      "authors": [
        "Joachim Diederich"
      ],
      "abstract": "This paper presents the first empirical demonstration of controllable\nlocality in transformer language models, a novel architectural framework that\nenables continuous control over the degree of representation localization\nthrough a tunable locality dial parameter. Unlike traditional language models\nthat rely exclusively on distributed representations, our approach allows\ndynamic interpolation between highly interpretable localist encodings and\nefficient distributed representations without requiring model retraining. We\nconducted experiments on the WikiText corpus using a two-layer transformer\narchitecture, systematically varying the locality parameter {\\lambda} across\nthe full spectrum from 1.0 (fully localist) to 0.0 (fully distributed). Our\nresults demonstrate that localist configurations achieve dramatically lower\nattention entropy, with {\\lambda} = 1.0 yielding 5.36 bits compared to 7.18\nbits at {\\lambda} = 0.0, while maintaining substantially higher pointer\nfidelity scores reflecting stronger alignment with rule-specified targets.\nPrediction experiments reveal that intermediate locality values optimize the\ntradeoff between interpretability and performance, with {\\lambda} = 0.6\nachieving test perplexity of 4.65 and accuracy of 84.7%. These findings\nestablish that localist language models provide a practical framework for\napplications in regulated domains requiring both transparency and capability,\noffering precise mathematical control over the interpretability-performance\nspectrum through explicit penalty thresholds and information-theoretic design\nprinciples.",
      "pdf_url": "http://arxiv.org/pdf/2511.03559v1",
      "published": "2025-11-05T15:43:54+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.03559v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "MultiZebraLogic: A Multilingual Logical Reasoning Benchmark",
      "authors": [
        "Sofie Helene Bruun",
        "Dan Saattrup Smart"
      ],
      "abstract": "Measuring the full abilities of large language models (LLMs) requires\nbenchmarks representing multiple tasks. We aim to create large, high-quality\ndatasets for comparison of logical reasoning skills across several languages\nand of suitable difficulty for LLMs of various reasoning ability. We explore\nmultiple ways of increasing difficulty. We generate zebra puzzles in multiple\nlanguages, themes, sizes and including 14 different clue types and 8 red\nherring types (uninformative clues). We find puzzle sizes 2x3 and 4x5 are\nsufficiently challenging for GPT-4o mini (a non-reasoning model) and o3-mini (a\nreasoning model), respectively. Including 5 red herrings decreases o3-mini\npuzzle-level accuracy on 4x5 puzzles by 15$\\pm$7 %. Scores of o3-mini on 4x5\npuzzles are not significantly affected by use of English vs. Danish or the\ncommon houses theme vs. the country-specific smoerrebroed theme. We find no\ncorrelation between difficulty and the selected clue types. Datasets of\n128+1024 puzzles are published as MultiZebraLogic in each of nine Germanic\nlanguages for sizes 2x3 and 4x5. We publish code for puzzle generation,\ndesigned for adaptablity into more languages and themes.",
      "pdf_url": "http://arxiv.org/pdf/2511.03553v1",
      "published": "2025-11-05T15:34:48+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.03553v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Uncovering Code Insights: Leveraging GitHub Artifacts for Deeper Code Understanding",
      "authors": [
        "Ziv Nevo",
        "Orna Raz",
        "Karen Yorav"
      ],
      "abstract": "Understanding the purpose of source code is a critical task in software\nmaintenance, onboarding, and modernization. While large language models (LLMs)\nhave shown promise in generating code explanations, they often lack grounding\nin the broader software engineering context. We propose a novel approach that\nleverages natural language artifacts from GitHub -- such as pull request\ndescriptions, issue descriptions and discussions, and commit messages -- to\nenhance LLM-based code understanding. Our system consists of three components:\none that extracts and structures relevant GitHub context, another that uses\nthis context to generate high-level explanations of the code's purpose, and a\nthird that validates the explanation. We implemented this as a standalone tool,\nas well as a server within the Model Context Protocol (MCP), enabling\nintegration with other AI-assisted development tools. Our main use case is that\nof enhancing a standard LLM-based code explanation with code insights that our\nsystem generates. To evaluate explanations' quality, we conducted a small scale\nuser study, with developers of several open projects, as well as developers of\nproprietary projects. Our user study indicates that when insights are generated\nthey often are helpful and non trivial, and are free from hallucinations.",
      "pdf_url": "http://arxiv.org/pdf/2511.03549v1",
      "published": "2025-11-05T15:31:42+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.03549v1",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "Explaining Decisions in ML Models: a Parameterized Complexity Analysis (Part I)",
      "authors": [
        "Sebastian Ordyniak",
        "Giacomo Paesani",
        "Mateusz Rychlicki",
        "Stefan Szeider"
      ],
      "abstract": "This paper presents a comprehensive theoretical investigation into the\nparameterized complexity of explanation problems in various machine learning\n(ML) models. Contrary to the prevalent black-box perception, our study focuses\non models with transparent internal mechanisms. We address two principal types\nof explanation problems: abductive and contrastive, both in their local and\nglobal variants. Our analysis encompasses diverse ML models, including Decision\nTrees, Decision Sets, Decision Lists, Boolean Circuits, and ensembles thereof,\neach offering unique explanatory challenges. This research fills a significant\ngap in explainable AI (XAI) by providing a foundational understanding of the\ncomplexities of generating explanations for these models. This work provides\ninsights vital for further research in the domain of XAI, contributing to the\nbroader discourse on the necessity of transparency and accountability in AI\nsystems.",
      "pdf_url": "http://arxiv.org/pdf/2511.03545v1",
      "published": "2025-11-05T15:25:07+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.03545v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "SOLVE-Med: Specialized Orchestration for Leading Vertical Experts across Medical Specialties",
      "authors": [
        "Roberta Di Marino",
        "Giovanni Dioguardi",
        "Antonio Romano",
        "Giuseppe Riccio",
        "Mariano Barone",
        "Marco Postiglione",
        "Flora Amato",
        "Vincenzo Moscato"
      ],
      "abstract": "Medical question answering systems face deployment challenges including\nhallucinations, bias, computational demands, privacy concerns, and the need for\nspecialized expertise across diverse domains. Here, we present SOLVE-Med, a\nmulti-agent architecture combining domain-specialized small language models for\ncomplex medical queries. The system employs a Router Agent for dynamic\nspecialist selection, ten specialized models (1B parameters each) fine-tuned on\nspecific medical domains, and an Orchestrator Agent that synthesizes responses.\nEvaluated on Italian medical forum data across ten specialties, SOLVE-Med\nachieves superior performance with ROUGE-1 of 0.301 and BERTScore F1 of 0.697,\noutperforming standalone models up to 14B parameters while enabling local\ndeployment. Our code is publicly available on GitHub:\nhttps://github.com/PRAISELab-PicusLab/SOLVE-Med.",
      "pdf_url": "http://arxiv.org/pdf/2511.03542v1",
      "published": "2025-11-05T15:15:35+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.03542v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Efficient Neural Networks with Discrete Cosine Transform Activations",
      "authors": [
        "Marc Martinez-Gost",
        "Sara Pepe",
        "Ana Pérez-Neira",
        "Miguel Ángel Lagunas"
      ],
      "abstract": "In this paper, we extend our previous work on the Expressive Neural Network\n(ENN), a multilayer perceptron with adaptive activation functions parametrized\nusing the Discrete Cosine Transform (DCT). Building upon previous work that\ndemonstrated the strong expressiveness of ENNs with compact architectures, we\nnow emphasize their efficiency, interpretability and pruning capabilities. The\nDCT-based parameterization provides a structured and decorrelated\nrepresentation that reveals the functional role of each neuron and allows\ndirect identification of redundant components. Leveraging this property, we\npropose an efficient pruning strategy that removes unnecessary DCT coefficients\nwith negligible or no loss in performance. Experimental results across\nclassification and implicit neural representation tasks confirm that ENNs\nachieve state-of-the-art accuracy while maintaining a low number of parameters.\nFurthermore, up to 40% of the activation coefficients can be safely pruned,\nthanks to the orthogonality and bounded nature of the DCT basis. Overall, these\nfindings demonstrate that the ENN framework offers a principled integration of\nsignal processing concepts into neural network design, achieving a balanced\ntrade-off between expressiveness, compactness, and interpretability.",
      "pdf_url": "http://arxiv.org/pdf/2511.03531v1",
      "published": "2025-11-05T15:02:58+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.03531v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "A Theoretical Framework for Environmental Similarity and Vessel Mobility as Coupled Predictors of Marine Invasive Species Pathways",
      "authors": [
        "Gabriel Spadon",
        "Vaishnav Vaidheeswaran",
        "Claudio DiBacco"
      ],
      "abstract": "Marine invasive species spread through global shipping and generate\nsubstantial ecological and economic impacts. Traditional risk assessments\nrequire detailed records of ballast water and traffic patterns, which are often\nincomplete, limiting global coverage. This work advances a theoretical\nframework that quantifies invasion risk by combining environmental similarity\nacross ports with observed and forecasted maritime mobility. Climate-based\nfeature representations characterize each port's marine conditions, while\nmobility networks derived from Automatic Identification System data capture\nvessel flows and potential transfer pathways. Clustering and metric learning\nreveal climate analogues and enable the estimation of species survival\nlikelihood along shipping routes. A temporal link prediction model captures how\ntraffic patterns may change under shifting environmental conditions. The\nresulting fusion of environmental similarity and predicted mobility provides\nexposure estimates at the port and voyage levels, supporting targeted\nmonitoring, routing adjustments, and management interventions.",
      "pdf_url": "http://arxiv.org/pdf/2511.03499v1",
      "published": "2025-11-05T14:31:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.03499v1",
      "categories": [
        "cs.CE",
        "cs.AI"
      ]
    },
    {
      "title": "ROSBag MCP Server: Analyzing Robot Data with LLMs for Agentic Embodied AI Applications",
      "authors": [
        "Lei Fu",
        "Sahar Salimpour",
        "Leonardo Militano",
        "Harry Edelman",
        "Jorge Peña Queralta",
        "Giovanni Toffetti"
      ],
      "abstract": "Agentic AI systems and Physical or Embodied AI systems have been two key\nresearch verticals at the forefront of Artificial Intelligence and Robotics,\nwith Model Context Protocol (MCP) increasingly becoming a key component and\nenabler of agentic applications. However, the literature at the intersection of\nthese verticals, i.e., Agentic Embodied AI, remains scarce. This paper\nintroduces an MCP server for analyzing ROS and ROS 2 bags, allowing for\nanalyzing, visualizing and processing robot data with natural language through\nLLMs and VLMs. We describe specific tooling built with robotics domain\nknowledge, with our initial release focused on mobile robotics and supporting\nnatively the analysis of trajectories, laser scan data, transforms, or time\nseries data. This is in addition to providing an interface to standard ROS 2\nCLI tools (\"ros2 bag list\" or \"ros2 bag info\"), as well as the ability to\nfilter bags with a subset of topics or trimmed in time. Coupled with the MCP\nserver, we provide a lightweight UI that allows the benchmarking of the tooling\nwith different LLMs, both proprietary (Anthropic, OpenAI) and open-source\n(through Groq). Our experimental results include the analysis of tool calling\ncapabilities of eight different state-of-the-art LLM/VLM models, both\nproprietary and open-source, large and small. Our experiments indicate that\nthere is a large divide in tool calling capabilities, with Kimi K2 and Claude\nSonnet 4 demonstrating clearly superior performance. We also conclude that\nthere are multiple factors affecting the success rates, from the tool\ndescription schema to the number of arguments, as well as the number of tools\navailable to the models. The code is available with a permissive license at\nhttps://github.com/binabik-ai/mcp-rosbags.",
      "pdf_url": "http://arxiv.org/pdf/2511.03497v1",
      "published": "2025-11-05T14:27:58+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.03497v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SE"
      ]
    },
    {
      "title": "Development of the Bioinspired Tendon-Driven DexHand 021 with Proprioceptive Compliance Control",
      "authors": [
        "Jianbo Yuan",
        "Haohua Zhu",
        "Jing Dai",
        "Sheng Yi"
      ],
      "abstract": "The human hand plays a vital role in daily life and industrial applications,\nyet replicating its multifunctional capabilities-including motion, sensing, and\ncoordinated manipulation-with robotic systems remains a formidable challenge.\nDeveloping a dexterous robotic hand requires balancing human-like agility with\nengineering constraints such as complexity, size-to-weight ratio, durability,\nand force-sensing performance. This letter presents Dex-Hand 021, a\nhigh-performance, cable-driven five-finger robotic hand with 12 active and 7\npassive degrees of freedom (DoFs), achieving 19 DoFs dexterity in a lightweight\n1 kg design. We propose a proprioceptive force-sensing-based admittance control\nmethod to enhance manipulation. Experimental results demonstrate its superior\nperformance: a single-finger load capacity exceeding 10 N, fingertip\nrepeatability under 0.001 m, and force estimation errors below 0.2 N. Compared\nto PID control, joint torques in multi-object grasping are reduced by 31.19%,\nsignificantly improves force-sensing capability while preventing overload\nduring collisions. The hand excels in both power and precision grasps,\nsuccessfully executing 33 GRASP taxonomy motions and complex manipulation\ntasks. This work advances the design of lightweight, industrial-grade dexterous\nhands and enhances proprioceptive control, contributing to robotic manipulation\nand intelligent manufacturing.",
      "pdf_url": "http://arxiv.org/pdf/2511.03481v1",
      "published": "2025-11-05T14:07:03+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.03481v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "Towards Scalable Web Accessibility Audit with MLLMs as Copilots",
      "authors": [
        "Ming Gu",
        "Ziwei Wang",
        "Sicen Lai",
        "Zirui Gao",
        "Sheng Zhou",
        "Jiajun Bu"
      ],
      "abstract": "Ensuring web accessibility is crucial for advancing social welfare, justice,\nand equality in digital spaces, yet the vast majority of website user\ninterfaces remain non-compliant, due in part to the resource-intensive and\nunscalable nature of current auditing practices. While WCAG-EM offers a\nstructured methodology for site-wise conformance evaluation, it involves great\nhuman efforts and lacks practical support for execution at scale. In this work,\nwe present an auditing framework, AAA, which operationalizes WCAG-EM through a\nhuman-AI partnership model. AAA is anchored by two key innovations: GRASP, a\ngraph-based multimodal sampling method that ensures representative page\ncoverage via learned embeddings of visual, textual, and relational cues; and\nMaC, a multimodal large language model-based copilot that supports auditors\nthrough cross-modal reasoning and intelligent assistance in high-effort tasks.\nTogether, these components enable scalable, end-to-end web accessibility\nauditing, empowering human auditors with AI-enhanced assistance for real-world\nimpact. We further contribute four novel datasets designed for benchmarking\ncore stages of the audit pipeline. Extensive experiments demonstrate the\neffectiveness of our methods, providing insights that small-scale language\nmodels can serve as capable experts when fine-tuned.",
      "pdf_url": "http://arxiv.org/pdf/2511.03471v1",
      "published": "2025-11-05T13:50:19+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.03471v1",
      "categories": [
        "cs.AI",
        "cs.HC"
      ]
    },
    {
      "title": "CareMedEval dataset: Evaluating Critical Appraisal and Reasoning in the Biomedical Field",
      "authors": [
        "Doria Bonzi",
        "Alexandre Guiggi",
        "Frédéric Béchet",
        "Carlos Ramisch",
        "Benoit Favre"
      ],
      "abstract": "Critical appraisal of scientific literature is an essential skill in the\nbiomedical field. While large language models (LLMs) can offer promising\nsupport in this task, their reliability remains limited, particularly for\ncritical reasoning in specialized domains. We introduce CareMedEval, an\noriginal dataset designed to evaluate LLMs on biomedical critical appraisal and\nreasoning tasks. Derived from authentic exams taken by French medical students,\nthe dataset contains 534 questions based on 37 scientific articles. Unlike\nexisting benchmarks, CareMedEval explicitly evaluates critical reading and\nreasoning grounded in scientific papers. Benchmarking state-of-the-art\ngeneralist and biomedical-specialized LLMs under various context conditions\nreveals the difficulty of the task: open and commercial models fail to exceed\nan Exact Match Rate of 0.5 even though generating intermediate reasoning tokens\nconsiderably improves the results. Yet, models remain challenged especially on\nquestions about study limitations and statistical analysis. CareMedEval\nprovides a challenging benchmark for grounded reasoning, exposing current LLM\nlimitations and paving the way for future development of automated support for\ncritical appraisal.",
      "pdf_url": "http://arxiv.org/pdf/2511.03441v1",
      "published": "2025-11-05T13:02:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.03441v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Inter-Agent Trust Models: A Comparative Study of Brief, Claim, Proof, Stake, Reputation and Constraint in Agentic Web Protocol Design-A2A, AP2, ERC-8004, and Beyond",
      "authors": [
        "Botao 'Amber' Hu",
        "Helena Rong"
      ],
      "abstract": "As the \"agentic web\" takes shape-billions of AI agents (often LLM-powered)\nautonomously transacting and collaborating-trust shifts from human oversight to\nprotocol design. In 2025, several inter-agent protocols crystallized this\nshift, including Google's Agent-to-Agent (A2A), Agent Payments Protocol (AP2),\nand Ethereum's ERC-8004 \"Trustless Agents,\" yet their underlying trust\nassumptions remain under-examined. This paper presents a comparative study of\ntrust models in inter-agent protocol design: Brief (self- or third-party\nverifiable claims), Claim (self-proclaimed capabilities and identity, e.g.\nAgentCard), Proof (cryptographic verification, including zero-knowledge proofs\nand trusted execution environment attestations), Stake (bonded collateral with\nslashing and insurance), Reputation (crowd feedback and graph-based trust\nsignals), and Constraint (sandboxing and capability bounding). For each, we\nanalyze assumptions, attack surfaces, and design trade-offs, with particular\nemphasis on LLM-specific fragilities-prompt injection,\nsycophancy/nudge-susceptibility, hallucination, deception, and\nmisalignment-that render purely reputational or claim-only approaches brittle.\nOur findings indicate no single mechanism suffices. We argue for\ntrustless-by-default architectures anchored in Proof and Stake to gate\nhigh-impact actions, augmented by Brief for identity and discovery and\nReputation overlays for flexibility and social signals. We comparatively\nevaluate A2A, AP2, ERC-8004 and related historical variations in academic\nresearch under metrics spanning security, privacy, latency/cost, and social\nrobustness (Sybil/collusion/whitewashing resistance). We conclude with hybrid\ntrust model recommendations that mitigate reputation gaming and misinformed LLM\nbehavior, and we distill actionable design guidelines for safer, interoperable,\nand scalable agent economies.",
      "pdf_url": "http://arxiv.org/pdf/2511.03434v1",
      "published": "2025-11-05T12:50:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.03434v1",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.MA",
        "cs.NI",
        "cs.SI"
      ]
    },
    {
      "title": "Light over Heavy: Automated Performance Requirements Quantification with Linguistic Inducement",
      "authors": [
        "Shihai Wang",
        "Tao Chen"
      ],
      "abstract": "Elicited performance requirements need to be quantified for compliance in\ndifferent engineering tasks, e.g., configuration tuning and performance\ntesting. Much existing work has relied on manual quantification, which is\nexpensive and error-prone due to the imprecision. In this paper, we present\nLQPR, a highly efficient automatic approach for performance requirements\nquantification.LQPR relies on a new theoretical framework that converts\nquantification as a classification problem. Despite the prevalent applications\nof Large Language Models (LLMs) for requirement analytics, LQPR takes a\ndifferent perspective to address the classification: we observed that\nperformance requirements can exhibit strong patterns and are often\nshort/concise, therefore we design a lightweight linguistically induced\nmatching mechanism. We compare LQPR against nine state-of-the-art\nlearning-based approaches over diverse datasets, demonstrating that it is\nranked as the sole best for 75% or more cases with two orders less cost. Our\nwork proves that, at least for performance requirement quantification,\nspecialized methods can be more suitable than the general LLM-driven\napproaches.",
      "pdf_url": "http://arxiv.org/pdf/2511.03421v1",
      "published": "2025-11-05T12:38:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.03421v1",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "Adaptable Hindsight Experience Replay for Search-Based Learning",
      "authors": [
        "Alexandros Vazaios",
        "Jannis Brugger",
        "Cedric Derstroff",
        "Kristian Kersting",
        "Mira Mezini"
      ],
      "abstract": "AlphaZero-like Monte Carlo Tree Search systems, originally introduced for\ntwo-player games, dynamically balance exploration and exploitation using neural\nnetwork guidance. This combination makes them also suitable for classical\nsearch problems. However, the original method of training the network with\nsimulation results is limited in sparse reward settings, especially in the\nearly stages, where the network cannot yet give guidance. Hindsight Experience\nReplay (HER) addresses this issue by relabeling unsuccessful trajectories from\nthe search tree as supervised learning signals. We introduce Adaptable HER\n(\\ours{}), a flexible framework that integrates HER with AlphaZero, allowing\neasy adjustments to HER properties such as relabeled goals, policy targets, and\ntrajectory selection. Our experiments, including equation discovery, show that\nthe possibility of modifying HER is beneficial and surpasses the performance of\npure supervised or reinforcement learning.",
      "pdf_url": "http://arxiv.org/pdf/2511.03405v1",
      "published": "2025-11-05T12:13:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.03405v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.8; I.2.6"
      ]
    },
    {
      "title": "Computational Imaging Meets LLMs: Zero-Shot IDH Mutation Prediction in Brain Gliomas",
      "authors": [
        "Syed Muqeem Mahmood",
        "Hassan Mohy-ud-Din"
      ],
      "abstract": "We present a framework that combines Large Language Models with computational\nimage analytics for non-invasive, zero-shot prediction of IDH mutation status\nin brain gliomas. For each subject, coregistered multi-parametric MRI scans and\nmulti-class tumor segmentation maps were processed to extract interpretable\nsemantic (visual) attributes and quantitative features, serialized in a\nstandardized JSON file, and used to query GPT 4o and GPT 5 without fine-tuning.\nWe evaluated this framework on six publicly available datasets (N = 1427) and\nresults showcased high accuracy and balanced classification performance across\nheterogeneous cohorts, even in the absence of manual annotations. GPT 5\noutperformed GPT 4o in context-driven phenotype interpretation. Volumetric\nfeatures emerged as the most important predictors, supplemented by\nsubtype-specific imaging markers and clinical information. Our results\ndemonstrate the potential of integrating LLM-based reasoning with computational\nimage analytics for precise, non-invasive tumor genotyping, advancing\ndiagnostic strategies in neuro-oncology. The code is available at\nhttps://github.com/ATPLab-LUMS/CIM-LLM.",
      "pdf_url": "http://arxiv.org/pdf/2511.03376v1",
      "published": "2025-11-05T11:31:08+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.03376v1",
      "categories": [
        "eess.IV",
        "cs.AI",
        "q-bio.QM"
      ]
    },
    {
      "title": "Decoupling Augmentation Bias in Prompt Learning for Vision-Language Models",
      "authors": [
        "Gahyeon Kim",
        "Sohee Kim",
        "Seokju Lee"
      ],
      "abstract": "Recent advances in large-scale vision and language models have led to\nsignificant progress in zero-shot learning tasks. Methods such as CoOp and\nCoCoOp have shown that replacing handcrafted prompts with learnable vectors,\nknown as prompt learning, can result in improved performance. However, these\nmodels often struggle to generalize to entirely unseen categories. While\ntraditional zero-shot learning techniques benefit from various data\naugmentation strategies, prompt learning has primarily focused on text-based\nmodifications, leaving the potential of image-based augmentation largely\nunexplored. In this work, we explore how image-level augmentations,\nparticularly those that introduce attribute-specific variations, can support\nand enhance prompt learning. Our analysis examines the interaction between\nthese augmentations and soft prompt frameworks, revealing their potential to\nimprove generalization. We also identify a limitation in existing methods, such\nas CoCoOp, which do not provide explicit guidance for learning prompts that\nfocus on semantically meaningful visual features. To address this, we propose\nAdding Attributes to Prompt Learning, AAPL, a novel method that introduces\nadversarial token embeddings to decouple superficial visual variations\nintroduced by augmentation from class-relevant semantic representations. This\ndecoupling enables the learned prompts to concentrate on visually\ndiscriminative features that align with the target categories. We conduct\ncomprehensive experiments on eleven benchmark datasets, and AAPL consistently\noutperforms existing methods across few-shot, zero-shot, cross-dataset, and\ndomain generalization settings. Our source code is publicly available at:\nhttps://github.com/Gahyeonkim09/AAPL",
      "pdf_url": "http://arxiv.org/pdf/2511.03367v1",
      "published": "2025-11-05T11:15:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.03367v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Open Source State-Of-the-Art Solution for Romanian Speech Recognition",
      "authors": [
        "Gabriel Pirlogeanu",
        "Alexandru-Lucian Georgescu",
        "Horia Cucu"
      ],
      "abstract": "In this work, we present a new state-of-the-art Romanian Automatic Speech\nRecognition (ASR) system based on NVIDIA's FastConformer architecture--explored\nhere for the first time in the context of Romanian. We train our model on a\nlarge corpus of, mostly, weakly supervised transcriptions, totaling over 2,600\nhours of speech. Leveraging a hybrid decoder with both Connectionist Temporal\nClassification (CTC) and Token-Duration Transducer (TDT) branches, we evaluate\na range of decoding strategies including greedy, ALSD, and CTC beam search with\na 6-gram token-level language model. Our system achieves state-of-the-art\nperformance across all Romanian evaluation benchmarks, including read,\nspontaneous, and domain-specific speech, with up to 27% relative WER reduction\ncompared to previous best-performing systems. In addition to improved\ntranscription accuracy, our approach demonstrates practical decoding\nefficiency, making it suitable for both research and deployment in low-latency\nASR applications.",
      "pdf_url": "http://arxiv.org/pdf/2511.03361v1",
      "published": "2025-11-05T11:02:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.03361v1",
      "categories": [
        "eess.AS",
        "cs.AI"
      ]
    },
    {
      "title": "Generative Artificial Intelligence in Bioinformatics: A Systematic Review of Models, Applications, and Methodological Advances",
      "authors": [
        "Riasad Alvi",
        "Sayeem Been Zaman",
        "Wasimul Karim",
        "Arefin Ittesafun Abian",
        "Mohaimenul Azam Khan Raiaan",
        "Saddam Mukta",
        "Md Rafi Ur Rashid",
        "Md Rafiqul Islam",
        "Yakub Sebastian",
        "Sami Azam"
      ],
      "abstract": "Generative artificial intelligence (GenAI) has become a transformative\napproach in bioinformatics that often enables advancements in genomics,\nproteomics, transcriptomics, structural biology, and drug discovery. To\nsystematically identify and evaluate these growing developments, this review\nproposed six research questions (RQs), according to the preferred reporting\nitems for systematic reviews and meta-analysis methods. The objective is to\nevaluate impactful GenAI strategies in methodological advancement, predictive\nperformance, and specialization, and to identify promising approaches for\nadvanced modeling, data-intensive discovery, and integrative biological\nanalysis. RQ1 highlights diverse applications across multiple bioinformatics\nsubfields (sequence analysis, molecular design, and integrative data modeling),\nwhich demonstrate superior performance over traditional methods through pattern\nrecognition and output generation. RQ2 reveals that adapted specialized model\narchitectures outperformed general-purpose models, an advantage attributed to\ntargeted pretraining and context-aware strategies. RQ3 identifies significant\nbenefits in the bioinformatics domains, focusing on molecular analysis and data\nintegration, which improves accuracy and reduces errors in complex analysis.\nRQ4 indicates improvements in structural modeling, functional prediction, and\nsynthetic data generation, validated by established benchmarks. RQ5 suggests\nthe main constraints, such as the lack of scalability and biases in data that\nimpact generalizability, and proposes future directions focused on robust\nevaluation and biologically grounded modeling. RQ6 examines that molecular\ndatasets (such as UniProtKB and ProteinNet12), cellular datasets (such as\nCELLxGENE and GTEx) and textual resources (such as PubMedQA and OMIM) broadly\nsupport the training and generalization of GenAI models.",
      "pdf_url": "http://arxiv.org/pdf/2511.03354v1",
      "published": "2025-11-05T10:48:36+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.03354v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Discourse-Aware Scientific Paper Recommendation via QA-Style Summarization and Multi-Level Contrastive Learning",
      "authors": [
        "Shenghua Wang",
        "Zhen Yin"
      ],
      "abstract": "The rapid growth of open-access (OA) publications has intensified the\nchallenge of identifying relevant scientific papers. Due to privacy constraints\nand limited access to user interaction data, recent efforts have shifted toward\ncontent-based recommendation, which relies solely on textual information.\nHowever, existing models typically treat papers as unstructured text,\nneglecting their discourse organization and thereby limiting semantic\ncompleteness and interpretability. To address these limitations, we propose\nOMRC-MR, a hierarchical framework that integrates QA-style OMRC (Objective,\nMethod, Result, Conclusion) summarization, multi-level contrastive learning,\nand structure-aware re-ranking for scholarly recommendation. The QA-style\nsummarization module converts raw papers into structured and\ndiscourse-consistent representations, while multi-level contrastive objectives\nalign semantic representations across metadata, section, and document levels.\nThe final re-ranking stage further refines retrieval precision through\ncontextual similarity calibration. Experiments on DBLP, S2ORC, and the newly\nconstructed Sci-OMRC dataset demonstrate that OMRC-MR consistently surpasses\nstate-of-the-art baselines, achieving up to 7.2% and 3.8% improvements in\nPrecision@10 and Recall@10, respectively. Additional evaluations confirm that\nQA-style summarization produces more coherent and factually complete\nrepresentations. Overall, OMRC-MR provides a unified and interpretable\ncontent-based paradigm for scientific paper recommendation, advancing\ntrustworthy and privacy-aware scholarly information retrieval.",
      "pdf_url": "http://arxiv.org/pdf/2511.03330v1",
      "published": "2025-11-05T09:55:12+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.03330v1",
      "categories": [
        "cs.IR",
        "cs.AI"
      ]
    },
    {
      "title": "Benchmarking the Thinking Mode of Multimodal Large Language Models in Clinical Tasks",
      "authors": [
        "Jindong Hong",
        "Tianjie Chen",
        "Lingjie Luo",
        "Chuanyang Zheng",
        "Ting Xu",
        "Haibao Yu",
        "Jianing Qiu",
        "Qianzhong Chen",
        "Suning Huang",
        "Yan Xu",
        "Yong Gui",
        "Yijun He",
        "Jiankai Sun"
      ],
      "abstract": "A recent advancement in Multimodal Large Language Models (MLLMs) research is\nthe emergence of \"reasoning MLLMs\" that offer explicit control over their\ninternal thinking processes (normally referred as the \"thinking mode\")\nalongside the standard \"non-thinking mode\". This capability allows these models\nto engage in a step-by-step process of internal deliberation before generating\na final response. With the rapid transition to and adoption of these\n\"dual-state\" MLLMs, this work rigorously evaluated how the enhanced reasoning\nprocesses of these MLLMs impact model performance and reliability in clinical\ntasks. This paper evaluates the active \"thinking mode\" capabilities of two\nleading MLLMs, Seed1.5-VL and Gemini-2.5-Flash, for medical applications. We\nassessed their performance on four visual medical tasks using VQA-RAD and\nROCOv2 datasets. Our findings reveal that the improvement from activating the\nthinking mode remains marginal compared to the standard non-thinking mode for\nthe majority of the tasks. Their performance on complex medical tasks such as\nopen-ended VQA and medical image interpretation remains suboptimal,\nhighlighting the need for domain-specific medical data and more advanced\nmethods for medical knowledge integration.",
      "pdf_url": "http://arxiv.org/pdf/2511.03328v1",
      "published": "2025-11-05T09:47:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.03328v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ]
    },
    {
      "title": "Extending Fair Null-Space Projections for Continuous Attributes to Kernel Methods",
      "authors": [
        "Felix Störck",
        "Fabian Hinder",
        "Barbara Hammer"
      ],
      "abstract": "With the on-going integration of machine learning systems into the everyday\nsocial life of millions the notion of fairness becomes an ever increasing\npriority in their development. Fairness notions commonly rely on protected\nattributes to assess potential biases. Here, the majority of literature focuses\non discrete setups regarding both target and protected attributes. The\nliterature on continuous attributes especially in conjunction with regression\n-- we refer to this as \\emph{continuous fairness} -- is scarce. A common\nstrategy is iterative null-space projection which as of now has only been\nexplored for linear models or embeddings such as obtained by a non-linear\nencoder. We improve on this by generalizing to kernel methods, significantly\nextending the scope. This yields a model and fairness-score agnostic method for\nkernel embeddings applicable to continuous protected attributes. We demonstrate\nthat our novel approach in conjunction with Support Vector Regression (SVR)\nprovides competitive or improved performance across multiple datasets in\ncomparisons to other contemporary methods.",
      "pdf_url": "http://arxiv.org/pdf/2511.03304v1",
      "published": "2025-11-05T09:17:08+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.03304v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "How to Evaluate Speech Translation with Source-Aware Neural MT Metrics",
      "authors": [
        "Mauro Cettolo",
        "Marco Gaido",
        "Matteo Negri",
        "Sara Papi",
        "Luisa Bentivogli"
      ],
      "abstract": "Automatic evaluation of speech-to-text translation (ST) systems is typically\nperformed by comparing translation hypotheses with one or more reference\ntranslations. While effective to some extent, this approach inherits the\nlimitation of reference-based evaluation that ignores valuable information from\nthe source input. In machine translation (MT), recent progress has shown that\nneural metrics incorporating the source text achieve stronger correlation with\nhuman judgments. Extending this idea to ST, however, is not trivial because the\nsource is audio rather than text, and reliable transcripts or alignments\nbetween source and references are often unavailable. In this work, we conduct\nthe first systematic study of source-aware metrics for ST, with a particular\nfocus on real-world operating conditions where source transcripts are not\navailable. We explore two complementary strategies for generating textual\nproxies of the input audio, automatic speech recognition (ASR) transcripts, and\nback-translations of the reference translation, and introduce a novel two-step\ncross-lingual re-segmentation algorithm to address the alignment mismatch\nbetween synthetic sources and reference translations. Our experiments, carried\nout on two ST benchmarks covering 79 language pairs and six ST systems with\ndiverse architectures and performance levels, show that ASR transcripts\nconstitute a more reliable synthetic source than back-translations when word\nerror rate is below 20%, while back-translations always represent a\ncomputationally cheaper but still effective alternative. Furthermore, our\ncross-lingual re-segmentation algorithm enables robust use of source-aware MT\nmetrics in ST evaluation, paving the way toward more accurate and principled\nevaluation methodologies for speech translation.",
      "pdf_url": "http://arxiv.org/pdf/2511.03295v1",
      "published": "2025-11-05T08:49:22+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.03295v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "When Generative Artificial Intelligence meets Extended Reality: A Systematic Review",
      "authors": [
        "Xinyu Ning",
        "Yan Zhuo",
        "Xian Wang",
        "Chan-In Devin Sio",
        "Lik-Hang Lee"
      ],
      "abstract": "With the continuous advancement of technology, the application of generative\nartificial intelligence (AI) in various fields is gradually demonstrating great\npotential, particularly when combined with Extended Reality (XR), creating\nunprecedented possibilities. This survey article systematically reviews the\napplications of generative AI in XR, covering as much relevant literature as\npossible from 2023 to 2025. The application areas of generative AI in XR and\nits key technology implementations are summarised through PRISMA screening and\nanalysis of the final 26 articles. The survey highlights existing articles from\nthe last three years related to how XR utilises generative AI, providing\ninsights into current trends and research gaps. We also explore potential\nopportunities for future research to further empower XR through generative AI,\nproviding guidance and information for future generative XR research.",
      "pdf_url": "http://arxiv.org/pdf/2511.03282v1",
      "published": "2025-11-05T08:24:48+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.03282v1",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Comparing the Performance of LLMs in RAG-based Question-Answering: A Case Study in Computer Science Literature",
      "authors": [
        "Ranul Dayarathne",
        "Uvini Ranaweera",
        "Upeksha Ganegoda"
      ],
      "abstract": "Retrieval Augmented Generation (RAG) is emerging as a powerful technique to\nenhance the capabilities of Generative AI models by reducing hallucination.\nThus, the increasing prominence of RAG alongside Large Language Models (LLMs)\nhas sparked interest in comparing the performance of different LLMs in\nquestion-answering (QA) in diverse domains. This study compares the performance\nof four open-source LLMs, Mistral-7b-instruct, LLaMa2-7b-chat,\nFalcon-7b-instruct and Orca-mini-v3-7b, and OpenAI's trending GPT-3.5 over QA\ntasks within the computer science literature leveraging RAG support. Evaluation\nmetrics employed in the study include accuracy and precision for binary\nquestions and ranking by a human expert, ranking by Google's AI model Gemini,\nalongside cosine similarity for long-answer questions. GPT-3.5, when paired\nwith RAG, effectively answers binary and long-answer questions, reaffirming its\nstatus as an advanced LLM. Regarding open-source LLMs, Mistral AI's\nMistral-7b-instruct paired with RAG surpasses the rest in answering both binary\nand long-answer questions. However, among the open-source LLMs, Orca-mini-v3-7b\nreports the shortest average latency in generating responses, whereas\nLLaMa2-7b-chat by Meta reports the highest average latency. This research\nunderscores the fact that open-source LLMs, too, can go hand in hand with\nproprietary models like GPT-3.5 with better infrastructure.",
      "pdf_url": "http://arxiv.org/pdf/2511.03261v1",
      "published": "2025-11-05T07:45:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.03261v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.1; I.2.7"
      ]
    },
    {
      "title": "Generative deep learning for foundational video translation in ultrasound",
      "authors": [
        "Nikolina Tomic Roshni Bhatnagar",
        "Sarthak Jain",
        "Connor Lau",
        "Tien-Yu Liu",
        "Laura Gambini",
        "Rima Arnaout"
      ],
      "abstract": "Deep learning (DL) has the potential to revolutionize image acquisition and\ninterpretation across medicine, however, attention to data imbalance and\nmissingness is required. Ultrasound data presents a particular challenge\nbecause in addition to different views and structures, it includes several\nsub-modalities-such as greyscale and color flow doppler (CFD)-that are often\nimbalanced in clinical studies. Image translation can help balance datasets but\nis challenging for ultrasound sub-modalities to date. Here, we present a\ngenerative method for ultrasound CFD-greyscale video translation, trained on\n54,975 videos and tested on 8,368. The method developed leveraged pixel-wise,\nadversarial, and perceptual loses and utilized two networks: one for\nreconstructing anatomic structures and one for denoising to achieve realistic\nultrasound imaging. Average pairwise SSIM between synthetic videos and ground\ntruth was 0.91+/-0.04. Synthetic videos performed indistinguishably from real\nones in DL classification and segmentation tasks and when evaluated by blinded\nclinical experts: F1 score was 0.9 for real and 0.89 for synthetic videos; Dice\nscore between real and synthetic segmentation was 0.97. Overall clinician\naccuracy in distinguishing real vs synthetic videos was 54+/-6% (42-61%),\nindicating realistic synthetic videos. Although trained only on heart videos,\nthe model worked well on ultrasound spanning several clinical domains (average\nSSIM 0.91+/-0.05), demonstrating foundational abilities. Together, these data\nexpand the utility of retrospectively collected imaging and augment the dataset\ndesign toolbox for medical imaging.",
      "pdf_url": "http://arxiv.org/pdf/2511.03255v1",
      "published": "2025-11-05T07:32:43+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.03255v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "GMoPE:A Prompt-Expert Mixture Framework for Graph Foundation Models",
      "authors": [
        "Zhibin Wang",
        "Zhixing Zhang",
        "Shuqi Wang",
        "Xuanting Xie",
        "Zhao Kang"
      ],
      "abstract": "Graph Neural Networks (GNNs) have demonstrated impressive performance on\ntask-specific benchmarks, yet their ability to generalize across diverse\ndomains and tasks remains limited. Existing approaches often struggle with\nnegative transfer, scalability issues, and high adaptation costs. To address\nthese challenges, we propose GMoPE (Graph Mixture of Prompt-Experts), a novel\nframework that seamlessly integrates the Mixture-of-Experts (MoE) architecture\nwith prompt-based learning for graphs. GMoPE leverages expert-specific prompt\nvectors and structure-aware MoE routing to enable each expert to specialize in\ndistinct subdomains and dynamically contribute to predictions. To promote\ndiversity and prevent expert collapse, we introduce a soft orthogonality\nconstraint across prompt vectors, encouraging expert specialization and\nfacilitating a more balanced expert utilization. Additionally, we adopt a\nprompt-only fine-tuning strategy that significantly reduces spatiotemporal\ncomplexity during transfer. We validate GMoPE through extensive experiments\nunder various pretraining strategies and multiple downstream tasks. Results\nshow that GMoPE consistently outperforms state-of-the-art baselines and\nachieves performance comparable to full parameter fine-tuning-while requiring\nonly a fraction of the adaptation overhead. Our work provides a principled and\nscalable framework for advancing generalizable and efficient graph foundation\nmodels.",
      "pdf_url": "http://arxiv.org/pdf/2511.03251v1",
      "published": "2025-11-05T07:28:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.03251v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ]
    },
    {
      "title": "From Five Dimensions to Many: Large Language Models as Precise and Interpretable Psychological Profilers",
      "authors": [
        "Yi-Fei Liu",
        "Yi-Long Lu",
        "Di He",
        "Hang Zhang"
      ],
      "abstract": "Psychological constructs within individuals are widely believed to be\ninterconnected. We investigated whether and how Large Language Models (LLMs)\ncan model the correlational structure of human psychological traits from\nminimal quantitative inputs. We prompted various LLMs with Big Five Personality\nScale responses from 816 human individuals to role-play their responses on nine\nother psychological scales. LLMs demonstrated remarkable accuracy in capturing\nhuman psychological structure, with the inter-scale correlation patterns from\nLLM-generated responses strongly aligning with those from human data $(R^2 >\n0.89)$. This zero-shot performance substantially exceeded predictions based on\nsemantic similarity and approached the accuracy of machine learning algorithms\ntrained directly on the dataset. Analysis of reasoning traces revealed that\nLLMs use a systematic two-stage process: First, they transform raw Big Five\nresponses into natural language personality summaries through information\nselection and compression, analogous to generating sufficient statistics.\nSecond, they generate target scale responses based on reasoning from these\nsummaries. For information selection, LLMs identify the same key personality\nfactors as trained algorithms, though they fail to differentiate item\nimportance within factors. The resulting compressed summaries are not merely\nredundant representations but capture synergistic information--adding them to\noriginal scores enhances prediction alignment, suggesting they encode emergent,\nsecond-order patterns of trait interplay. Our findings demonstrate that LLMs\ncan precisely predict individual participants' psychological traits from\nminimal data through a process of abstraction and reasoning, offering both a\npowerful tool for psychological simulation and valuable insights into their\nemergent reasoning capabilities.",
      "pdf_url": "http://arxiv.org/pdf/2511.03235v1",
      "published": "2025-11-05T06:51:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.03235v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Node-Based Editing for Multimodal Generation of Text, Audio, Image, and Vide",
      "authors": [
        "Alexander Htet Kyaw",
        "Lenin Ravindranath Sivalingam"
      ],
      "abstract": "We present a node-based storytelling system for multimodal content\ngeneration. The system represents stories as graphs of nodes that can be\nexpanded, edited, and iteratively refined through direct user edits and\nnatural-language prompts. Each node can integrate text, images, audio, and\nvideo, allowing creators to compose multimodal narratives. A task selection\nagent routes between specialized generative tasks that handle story generation,\nnode structure reasoning, node diagram formatting, and context generation. The\ninterface supports targeted editing of individual nodes, automatic branching\nfor parallel storylines, and node-based iterative refinement. Our results\ndemonstrate that node-based editing supports control over narrative structure\nand iterative generation of text, images, audio, and video. We report\nquantitative outcomes on automatic story outline generation and qualitative\nobservations of editing workflows. Finally, we discuss current limitations such\nas scalability to longer narratives and consistency across multiple nodes, and\noutline future work toward human-in-the-loop and user-centered creative AI\ntools.",
      "pdf_url": "http://arxiv.org/pdf/2511.03227v1",
      "published": "2025-11-05T06:35:10+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.03227v1",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.MM"
      ]
    },
    {
      "title": "Hybrid Fact-Checking that Integrates Knowledge Graphs, Large Language Models, and Search-Based Retrieval Agents Improves Interpretable Claim Verification",
      "authors": [
        "Shaghayegh Kolli",
        "Richard Rosenbaum",
        "Timo Cavelius",
        "Lasse Strothe",
        "Andrii Lata",
        "Jana Diesner"
      ],
      "abstract": "Large language models (LLMs) excel in generating fluent utterances but can\nlack reliable grounding in verified information. At the same time,\nknowledge-graph-based fact-checkers deliver precise and interpretable evidence,\nyet suffer from limited coverage or latency. By integrating LLMs with knowledge\ngraphs and real-time search agents, we introduce a hybrid fact-checking\napproach that leverages the individual strengths of each component. Our system\ncomprises three autonomous steps: 1) a Knowledge Graph (KG) Retrieval for rapid\none-hop lookups in DBpedia, 2) an LM-based classification guided by a\ntask-specific labeling prompt, producing outputs with internal rule-based\nlogic, and 3) a Web Search Agent invoked only when KG coverage is insufficient.\nOur pipeline achieves an F1 score of 0.93 on the FEVER benchmark on the\nSupported/Refuted split without task-specific fine-tuning. To address Not\nenough information cases, we conduct a targeted reannotation study showing that\nour approach frequently uncovers valid evidence for claims originally labeled\nas Not Enough Information (NEI), as confirmed by both expert annotators and LLM\nreviewers. With this paper, we present a modular, opensource fact-checking\npipeline with fallback strategies and generalization across datasets.",
      "pdf_url": "http://arxiv.org/pdf/2511.03217v1",
      "published": "2025-11-05T06:10:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.03217v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.IR",
        "68T50",
        "I.2.7; H.3.3"
      ]
    },
    {
      "title": "LGM: Enhancing Large Language Models with Conceptual Meta-Relations and Iterative Retrieval",
      "authors": [
        "Wenchang Lei",
        "Ping Zou",
        "Yue Wang",
        "Feng Sun",
        "Lei Zhao"
      ],
      "abstract": "Large language models (LLMs) exhibit strong semantic understanding, yet\nstruggle when user instructions involve ambiguous or conceptually misaligned\nterms. We propose the Language Graph Model (LGM) to enhance conceptual clarity\nby extracting meta-relations-inheritance, alias, and composition-from natural\nlanguage. The model further employs a reflection mechanism to validate these\nmeta-relations. Leveraging a Concept Iterative Retrieval Algorithm, these\nrelations and related descriptions are dynamically supplied to the LLM,\nimproving its ability to interpret concepts and generate accurate responses.\nUnlike conventional Retrieval-Augmented Generation (RAG) approaches that rely\non extended context windows, our method enables large language models to\nprocess texts of any length without the need for truncation. Experiments on\nstandard benchmarks demonstrate that the LGM consistently outperforms existing\nRAG baselines.",
      "pdf_url": "http://arxiv.org/pdf/2511.03214v1",
      "published": "2025-11-05T06:04:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.03214v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Retrofitters, pragmatists and activists: Public interest litigation for accountable automated decision-making",
      "authors": [
        "Henry Fraser",
        "Zahra Stardust"
      ],
      "abstract": "This paper examines the role of public interest litigation in promoting\naccountability for AI and automated decision-making (ADM) in Australia. Since\nADM regulatio faces geopolitical headwinds, effective governance will have to\nrely at least in part on the enforcement of existing laws. Drawing on\ninterviews with Australian public interest litigators, technology policy\nactivists, and technology law scholars, the paper positions public interest\nlitigation as part of a larger ecosystem for transparency, accountability and\njustice with respect to ADM. It builds on one participants's characterisation\nof litigation about ADM as an exercise in legal retrofitting: adapting old laws\nto new circumstances. The paper's primary contribution is to aggregate,\norganise and present original insights on pragmatic strategies and tactics for\neffective public interest litigation about ADM. Naturally, it also contends\nwith the limits of these strategies, and of the legal system. Where limits are,\nhowever, capable of being overcome, the paper presents findings on urgent\nneeds: the enabling institutional arrangements without which effective\nlitigation and accountability will falter. The paper is relevant to law and\ntechnology scholars; individuals and groups harmed by ADM; public interest\nlitigators and technology lawyers; civil society and advocacy organisations;\nand policymakers.",
      "pdf_url": "http://arxiv.org/pdf/2511.03211v1",
      "published": "2025-11-05T05:55:04+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.03211v1",
      "categories": [
        "cs.CY",
        "cs.AI"
      ]
    },
    {
      "title": "QG-CoC: Question-Guided Chain-of-Captions for Large Multimodal Models",
      "authors": [
        "Kuei-Chun Kao",
        "Hsu Tzu-Yin",
        "Yunqi Hong",
        "Ruochen Wang",
        "Cho-Jui Hsieh"
      ],
      "abstract": "Recently, Multimodal Large Language Models (MLLMs) encounter two key issues\nin multi-image contexts: (1) a lack of fine-grained perception across disparate\nimages, and (2) a diminished capability to effectively reason over and\nsynthesize information from multiple visual inputs. However, while various\nprompting methods aim to describe visual content, many existing studies focus\nprimarily on single-image settings or specific, constrained scenarios. This\nleaves a critical gap in understanding and addressing how MLLMs tackle more\ngeneral and complex multi-image reasoning tasks. Thus, we first extensively\ninvestigate how current prompting methods perceive fine-grained visual details\nand process visual information when dealing with multiple images. Our findings\nreveal that existing prompting methods fall short in attending to needed clues\nand seamlessly integrating perception and reasoning. Inspired by the findings,\nwe propose a new zero-shot prompting method, Question-Guided Chain-of-Captions\n(QG-CoC), a generalized prompting approach that effectively handles problems\nwith an arbitrary number of images. We evaluate our method on various\nopen-source and closed-source MLLMs for multi-image and single-image\nbenchmarks. Experimental results indicate that QG-CoC demonstrates competitive\nperformance across tasks and exhibits robust improvements in the challenging\nscenarios where existing prompting methods fail.",
      "pdf_url": "http://arxiv.org/pdf/2511.03206v1",
      "published": "2025-11-05T05:49:48+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.03206v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies",
      "authors": [
        "Hassan Wasswa",
        "Hussein Abbass",
        "Timothy Lynar"
      ],
      "abstract": "In an effort to counter the increasing IoT botnet-based attacks,\nstate-of-the-art deep learning methods have been proposed and have achieved\nimpressive detection accuracy. However, their computational intensity restricts\ndeployment on resource-constrained IoT devices, creating a critical need for\nlightweight detection models. A common solution to this challenge is model\ncompression via quantization. This study proposes a VAE-MLP model framework\nwhere an MLP-based classifier is trained on 8-dimensional latent vectors\nderived from the high-dimensional train data using the encoder component of a\npretrained variational autoencoder (VAE). Two widely used quantization\nstrategies--Quantization-Aware Training (QAT) and Post-Training Quantization\n(PTQ)--are then systematically evaluated in terms of their impact on detection\nperformance, storage efficiency, and inference latency using two benchmark IoT\nbotnet datasets--N-BaIoT and CICIoT2022. The results revealed that, with\nrespect to detection accuracy, the QAT strategy experienced a more noticeable\ndecline,whereas PTQ incurred only a marginal reduction compared to the original\nunquantized model. Furthermore, PTQ yielded a 6x speedup and 21x reduction in\nsize, while QAT achieved a 3x speedup and 24x compression, demonstrating the\npracticality of quantization for device-level IoT botnet detection.",
      "pdf_url": "http://arxiv.org/pdf/2511.03201v1",
      "published": "2025-11-05T05:33:27+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.03201v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    }
  ]
}