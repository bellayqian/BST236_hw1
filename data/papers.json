{
  "last_updated": "2025-04-12T00:47:33.727310",
  "papers": [
    {
      "title": "VCR-Bench: A Comprehensive Evaluation Framework for Video Chain-of-Thought Reasoning",
      "authors": [
        "Yukun Qi",
        "Yiming Zhao",
        "Yu Zeng",
        "Xikun Bao",
        "Wenxuan Huang",
        "Lin Chen",
        "Zehui Chen",
        "Jie Zhao",
        "Zhongang Qi",
        "Feng Zhao"
      ],
      "abstract": "The advancement of Chain-of-Thought (CoT) reasoning has significantly\nenhanced the capabilities of large language models (LLMs) and large\nvision-language models (LVLMs). However, a rigorous evaluation framework for\nvideo CoT reasoning remains absent. Current video benchmarks fail to adequately\nassess the reasoning process and expose whether failures stem from deficiencies\nin perception or reasoning capabilities. Therefore, we introduce VCR-Bench, a\nnovel benchmark designed to comprehensively evaluate LVLMs' Video\nChain-of-Thought Reasoning capabilities. VCR-Bench comprises 859 videos\nspanning a variety of video content and durations, along with 1,034\nhigh-quality question-answer pairs. Each pair is manually annotated with a\nstepwise CoT rationale, where every step is tagged to indicate its association\nwith the perception or reasoning capabilities. Furthermore, we design seven\ndistinct task dimensions and propose the CoT score to assess the entire CoT\nprocess based on the stepwise tagged CoT rationals. Extensive experiments on\nVCR-Bench highlight substantial limitations in current LVLMs. Even the\ntop-performing model, o1, only achieves a 62.8% CoT score and an 56.7%\naccuracy, while most models score below 40%. Experiments show most models score\nlower on perception than reasoning steps, revealing LVLMs' key bottleneck in\ntemporal-spatial information processing for complex video reasoning. A robust\npositive correlation between the CoT score and accuracy confirms the validity\nof our evaluation framework and underscores the critical role of CoT reasoning\nin solving complex video reasoning tasks. We hope VCR-Bench to serve as a\nstandardized evaluation framework and expose the actual drawbacks in complex\nvideo reasoning task.",
      "pdf_url": "http://arxiv.org/pdf/2504.07956v1",
      "published": "2025-04-10T17:59:03+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.07956v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "GenEAva: Generating Cartoon Avatars with Fine-Grained Facial Expressions from Realistic Diffusion-based Faces",
      "authors": [
        "Hao Yu",
        "Rupayan Mallick",
        "Margrit Betke",
        "Sarah Adel Bargal"
      ],
      "abstract": "Cartoon avatars have been widely used in various applications, including\nsocial media, online tutoring, and gaming. However, existing cartoon avatar\ndatasets and generation methods struggle to present highly expressive avatars\nwith fine-grained facial expressions and are often inspired from real-world\nidentities, raising privacy concerns. To address these challenges, we propose a\nnovel framework, GenEAva, for generating high-quality cartoon avatars with\nfine-grained facial expressions. Our approach fine-tunes a state-of-the-art\ntext-to-image diffusion model to synthesize highly detailed and expressive\nfacial expressions. We then incorporate a stylization model that transforms\nthese realistic faces into cartoon avatars while preserving both identity and\nexpression. Leveraging this framework, we introduce the first expressive\ncartoon avatar dataset, GenEAva 1.0, specifically designed to capture 135\nfine-grained facial expressions, featuring 13,230 expressive cartoon avatars\nwith a balanced distribution across genders, racial groups, and age ranges. We\ndemonstrate that our fine-tuned model generates more expressive faces than the\nstate-of-the-art text-to-image diffusion model SDXL. We also verify that the\ncartoon avatars generated by our framework do not include memorized identities\nfrom fine-tuning data. The proposed framework and dataset provide a diverse and\nexpressive benchmark for future research in cartoon avatar generation.",
      "pdf_url": "http://arxiv.org/pdf/2504.07945v1",
      "published": "2025-04-10T17:54:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.07945v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "We Are All Creators: Generative AI, Collective Knowledge, and the Path Towards Human-AI Synergy",
      "authors": [
        "Jordi Linares-Pellicer",
        "Juan Izquierdo-Domenech",
        "Isabel Ferri-Molla",
        "Carlos Aliaga-Torro"
      ],
      "abstract": "Generative AI presents a profound challenge to traditional notions of human\nuniqueness, particularly in creativity. Fueled by neural network based\nfoundation models, these systems demonstrate remarkable content generation\ncapabilities, sparking intense debates about authorship, copyright, and\nintelligence itself. This paper argues that generative AI represents an\nalternative form of intelligence and creativity, operating through mathematical\npattern synthesis rather than biological understanding or verbatim replication.\nThe fundamental differences between artificial and biological neural networks\nreveal AI learning as primarily statistical pattern extraction from vast\ndatasets crystallized forms of collective human knowledge scraped from the\ninternet. This perspective complicates copyright theft narratives and\nhighlights practical challenges in attributing AI outputs to individual\nsources. Rather than pursuing potentially futile legal restrictions, we\nadvocate for human AI synergy. By embracing generative AI as a complementary\ntool alongside human intuition, context, and ethical judgment, society can\nunlock unprecedented innovation, democratize creative expression, and address\ncomplex challenges. This collaborative approach, grounded in realistic\nunderstanding of AIs capabilities and limitations, offers the most promising\npath forward. Additionally, recognizing these models as products of collective\nhuman knowledge raises ethical questions about accessibility ensuring equitable\naccess to these tools could prevent widening societal divides and leverage\ntheir full potential for collective benefit.",
      "pdf_url": "http://arxiv.org/pdf/2504.07936v1",
      "published": "2025-04-10T17:50:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.07936v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Note on the identification of total effect in Cluster-DAGs with cycles",
      "authors": [
        "Cl√©ment Yvernes"
      ],
      "abstract": "In this note, we discuss the identifiability of a total effect in\ncluster-DAGs, allowing for cycles within the cluster-DAG (while still assuming\nthe associated underlying DAG to be acyclic). This is presented into two key\nresults: first, restricting the cluster-DAG to clusters containing at most four\nnodes; second, adapting the notion of d-separation. We provide a graphical\ncriterion to address the identifiability problem.",
      "pdf_url": "http://arxiv.org/pdf/2504.07921v1",
      "published": "2025-04-10T17:39:43+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.07921v1",
      "categories": [
        "math.ST",
        "cs.AI",
        "stat.TH"
      ]
    },
    {
      "title": "The Urban Impact of AI: Modeling Feedback Loops in Next-Venue Recommendation",
      "authors": [
        "Giovanni Mauro",
        "Marco Minici",
        "Luca Pappalardo"
      ],
      "abstract": "Next-venue recommender systems are increasingly embedded in location-based\nservices, shaping individual mobility decisions in urban environments. While\ntheir predictive accuracy has been extensively studied, less attention has been\npaid to their systemic impact on urban dynamics. In this work, we introduce a\nsimulation framework to model the human-AI feedback loop underpinning\nnext-venue recommendation, capturing how algorithmic suggestions influence\nindividual behavior, which in turn reshapes the data used to retrain the\nmodels. Our simulations, grounded in real-world mobility data, systematically\nexplore the effects of algorithmic adoption across a range of recommendation\nstrategies. We find that while recommender systems consistently increase\nindividual-level diversity in visited venues, they may simultaneously amplify\ncollective inequality by concentrating visits on a limited subset of popular\nplaces. This divergence extends to the structure of social co-location\nnetworks, revealing broader implications for urban accessibility and spatial\nsegregation. Our framework operationalizes the feedback loop in next-venue\nrecommendation and offers a novel lens through which to assess the societal\nimpact of AI-assisted mobility-providing a computational tool to anticipate\nfuture risks, evaluate regulatory interventions, and inform the design of ethic\nalgorithmic systems.",
      "pdf_url": "http://arxiv.org/pdf/2504.07911v1",
      "published": "2025-04-10T17:15:50+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.07911v1",
      "categories": [
        "cs.AI",
        "cs.CY"
      ]
    },
    {
      "title": "Fast Adaptation with Behavioral Foundation Models",
      "authors": [
        "Harshit Sikchi",
        "Andrea Tirinzoni",
        "Ahmed Touati",
        "Yingchen Xu",
        "Anssi Kanervisto",
        "Scott Niekum",
        "Amy Zhang",
        "Alessandro Lazaric",
        "Matteo Pirotta"
      ],
      "abstract": "Unsupervised zero-shot reinforcement learning (RL) has emerged as a powerful\nparadigm for pretraining behavioral foundation models (BFMs), enabling agents\nto solve a wide range of downstream tasks specified via reward functions in a\nzero-shot fashion, i.e., without additional test-time learning or planning.\nThis is achieved by learning self-supervised task embeddings alongside\ncorresponding near-optimal behaviors and incorporating an inference procedure\nto directly retrieve the latent task embedding and associated policy for any\ngiven reward function. Despite promising results, zero-shot policies are often\nsuboptimal due to errors induced by the unsupervised training process, the\nembedding, and the inference procedure. In this paper, we focus on devising\nfast adaptation strategies to improve the zero-shot performance of BFMs in a\nfew steps of online interaction with the environment while avoiding any\nperformance drop during the adaptation process. Notably, we demonstrate that\nexisting BFMs learn a set of skills containing more performant policies than\nthose identified by their inference procedure, making them well-suited for fast\nadaptation. Motivated by this observation, we propose both actor-critic and\nactor-only fast adaptation strategies that search in the low-dimensional\ntask-embedding space of the pre-trained BFM to rapidly improve the performance\nof its zero-shot policies on any downstream task. Notably, our approach\nmitigates the initial \"unlearning\" phase commonly observed when fine-tuning\npre-trained RL models. We evaluate our fast adaptation strategies on top of\nfour state-of-the-art zero-shot RL methods in multiple navigation and\nlocomotion domains. Our results show that they achieve 10-40% improvement over\ntheir zero-shot performance in a few tens of episodes, outperforming existing\nbaselines.",
      "pdf_url": "http://arxiv.org/pdf/2504.07896v1",
      "published": "2025-04-10T16:14:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.07896v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ]
    },
    {
      "title": "SpecReason: Fast and Accurate Inference-Time Compute via Speculative Reasoning",
      "authors": [
        "Rui Pan",
        "Yinwei Dai",
        "Zhihao Zhang",
        "Gabriele Oliaro",
        "Zhihao Jia",
        "Ravi Netravali"
      ],
      "abstract": "Recent advances in inference-time compute have significantly improved\nperformance on complex tasks by generating long chains of thought (CoTs) using\nLarge Reasoning Models (LRMs). However, this improved accuracy comes at the\ncost of high inference latency due to the length of generated reasoning\nsequences and the autoregressive nature of decoding. Our key insight in\ntackling these overheads is that LRM inference, and the reasoning that it\nembeds, is highly tolerant of approximations: complex tasks are typically\nbroken down into simpler steps, each of which brings utility based on the\nsemantic insight it provides for downstream steps rather than the exact tokens\nit generates. Accordingly, we introduce SpecReason, a system that automatically\naccelerates LRM inference by using a lightweight model to (speculatively) carry\nout simpler intermediate reasoning steps and reserving the costly base model\nonly to assess (and potentially correct) the speculated outputs. Importantly,\nSpecReason's focus on exploiting the semantic flexibility of thinking tokens in\npreserving final-answer accuracy is complementary to prior speculation\ntechniques, most notably speculative decoding, which demands token-level\nequivalence at each step. Across a variety of reasoning benchmarks, SpecReason\nachieves 1.5-2.5$\\times$ speedup over vanilla LRM inference while improving\naccuracy by 1.0-9.9\\%. Compared to speculative decoding without SpecReason,\ntheir combination yields an additional 19.4-44.2\\% latency reduction. We\nopen-source SpecReason at https://github.com/ruipeterpan/specreason.",
      "pdf_url": "http://arxiv.org/pdf/2504.07891v1",
      "published": "2025-04-10T16:05:19+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.07891v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Benchmarking Adversarial Robustness to Bias Elicitation in Large Language Models: Scalable Automated Assessment with LLM-as-a-Judge",
      "authors": [
        "Riccardo Cantini",
        "Alessio Orsino",
        "Massimo Ruggiero",
        "Domenico Talia"
      ],
      "abstract": "Large Language Models (LLMs) have revolutionized artificial intelligence,\ndriving advancements in machine translation, summarization, and conversational\nagents. However, their increasing integration into critical societal domains\nhas raised concerns about embedded biases, which can perpetuate stereotypes and\ncompromise fairness. These biases stem from various sources, including\nhistorical inequalities in training data, linguistic imbalances, and\nadversarial manipulation. Despite mitigation efforts, recent studies indicate\nthat LLMs remain vulnerable to adversarial attacks designed to elicit biased\nresponses. This work proposes a scalable benchmarking framework to evaluate LLM\nrobustness against adversarial bias elicitation. Our methodology involves (i)\nsystematically probing models with a multi-task approach targeting biases\nacross various sociocultural dimensions, (ii) quantifying robustness through\nsafety scores using an LLM-as-a-Judge approach for automated assessment of\nmodel responses, and (iii) employing jailbreak techniques to investigate\nvulnerabilities in safety mechanisms. Our analysis examines prevalent biases in\nboth small and large state-of-the-art models and their impact on model safety.\nAdditionally, we assess the safety of domain-specific models fine-tuned for\ncritical fields, such as medicine. Finally, we release a curated dataset of\nbias-related prompts, CLEAR-Bias, to facilitate systematic vulnerability\nbenchmarking. Our findings reveal critical trade-offs between model size and\nsafety, aiding the development of fairer and more robust future language\nmodels.",
      "pdf_url": "http://arxiv.org/pdf/2504.07887v1",
      "published": "2025-04-10T16:00:59+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.07887v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Dual Engines of Thoughts: A Depth-Breadth Integration Framework for Open-Ended Analysis",
      "authors": [
        "Fei-Hsuan Yu",
        "Yun-Cheng Chou",
        "Teng-Ruei Chen"
      ],
      "abstract": "We propose the Dual Engines of Thoughts (DEoT), an analytical framework for\ncomprehensive open-ended reasoning. While traditional reasoning frameworks\nprimarily focus on finding \"the best answer\" or \"the correct answer\" for\nsingle-answer problems, DEoT is specifically designed for \"open-ended\nquestions,\" enabling both broader and deeper analytical exploration. The\nframework centers on three key components: a Base Prompter for refining user\nqueries, a Solver Agent that orchestrates task decomposition, execution, and\nvalidation, and a Dual-Engine System consisting of a Breadth Engine (to explore\ndiverse impact factors) and a Depth Engine (to perform deep investigations).\nThis integrated design allows DEoT to balance wide-ranging coverage with\nin-depth analysis, and it is highly customizable, enabling users to adjust\nanalytical parameters and tool configurations based on specific requirements.\nExperimental results show that DEoT excels in addressing complex, multi-faceted\nquestions, achieving a total win rate of 77-86% compared to existing reasoning\nmodels, thus highlighting its effectiveness in real-world applications.",
      "pdf_url": "http://arxiv.org/pdf/2504.07872v1",
      "published": "2025-04-10T15:46:03+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.07872v1",
      "categories": [
        "cs.AI",
        "cs.CE",
        "cs.CL",
        "cs.MA"
      ]
    },
    {
      "title": "Pangu Ultra: Pushing the Limits of Dense Large Language Models on Ascend NPUs",
      "authors": [
        "Yichun Yin",
        "Wenyong Huang",
        "Kaikai Song",
        "Yehui Tang",
        "Xueyu Wu",
        "Wei Guo",
        "Peng Guo",
        "Yaoyuan Wang",
        "Xiaojun Meng",
        "Yasheng Wang",
        "Dong Li",
        "Can Chen",
        "Dandan Tu",
        "Yin Li",
        "Fisher Yu",
        "Ruiming Tang",
        "Yunhe Wang",
        "Baojun Wang",
        "Bin Wang",
        "Bo Wang",
        "Boxiao Liu",
        "Changzheng Zhang",
        "Duyu Tang",
        "Fei Mi",
        "Hui Jin",
        "Jiansheng Wei",
        "Jiarui Qin",
        "Jinpeng Li",
        "Jun Zhao",
        "Liqun Deng",
        "Lin Li",
        "Minghui Xu",
        "Naifu Zhang",
        "Nianzu Zheng",
        "Qiang Li",
        "Rongju Ruan",
        "Shengjun Cheng",
        "Tianyu Guo",
        "Wei He",
        "Wei Li",
        "Weiwen Liu",
        "Wulong Liu",
        "Xinyi Dai",
        "Yonghan Dong",
        "Yu Pan",
        "Yue Li",
        "Yufei Wang",
        "Yujun Li",
        "Yunsheng Ni",
        "Zhe Liu",
        "Zhenhe Zhang",
        "Zhicheng Liu"
      ],
      "abstract": "We present Pangu Ultra, a Large Language Model (LLM) with 135 billion\nparameters and dense Transformer modules trained on Ascend Neural Processing\nUnits (NPUs). Although the field of LLM has been witnessing unprecedented\nadvances in pushing the scale and capability of LLM in recent years, training\nsuch a large-scale model still involves significant optimization and system\nchallenges. To stabilize the training process, we propose depth-scaled sandwich\nnormalization, which effectively eliminates loss spikes during the training\nprocess of deep models. We pre-train our model on 13.2 trillion diverse and\nhigh-quality tokens and further enhance its reasoning capabilities during\npost-training. To perform such large-scale training efficiently, we utilize\n8,192 Ascend NPUs with a series of system optimizations. Evaluations on\nmultiple diverse benchmarks indicate that Pangu Ultra significantly advances\nthe state-of-the-art capabilities of dense LLMs such as Llama 405B and Mistral\nLarge 2, and even achieves competitive results with DeepSeek-R1, whose sparse\nmodel structure contains much more parameters. Our exploration demonstrates\nthat Ascend NPUs are capable of efficiently and effectively training dense\nmodels with more than 100 billion parameters. Our model and system will be\navailable for our commercial customers.",
      "pdf_url": "http://arxiv.org/pdf/2504.07866v1",
      "published": "2025-04-10T15:41:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.07866v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Empowering Global Voices: A Data-Efficient, Phoneme-Tone Adaptive Approach to High-Fidelity Speech Synthesis",
      "authors": [
        "Yizhong Geng",
        "Jizhuo Xu",
        "Zeyu Liang",
        "Jinghan Yang",
        "Xiaoyi Shi",
        "Xiaoyu Shen"
      ],
      "abstract": "Text-to-speech (TTS) technology has achieved impressive results for widely\nspoken languages, yet many under-resourced languages remain challenged by\nlimited data and linguistic complexities. In this paper, we present a novel\nmethodology that integrates a data-optimized framework with an advanced\nacoustic model to build high-quality TTS systems for low-resource scenarios. We\ndemonstrate the effectiveness of our approach using Thai as an illustrative\ncase, where intricate phonetic rules and sparse resources are effectively\naddressed. Our method enables zero-shot voice cloning and improved performance\nacross diverse client applications, ranging from finance to healthcare,\neducation, and law. Extensive evaluations - both subjective and objective -\nconfirm that our model meets state-of-the-art standards, offering a scalable\nsolution for TTS production in data-limited settings, with significant\nimplications for broader industry adoption and multilingual accessibility.",
      "pdf_url": "http://arxiv.org/pdf/2504.07858v1",
      "published": "2025-04-10T15:32:57+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.07858v1",
      "categories": [
        "cs.SD",
        "cs.AI"
      ]
    },
    {
      "title": "2D-Curri-DPO: Two-Dimensional Curriculum Learning for Direct Preference Optimization",
      "authors": [
        "Mengyang Li",
        "Zhong Zhang"
      ],
      "abstract": "Aligning large language models with human preferences is crucial for their\nsafe deployment. While Direct Preference Optimization (DPO) offers an efficient\nalternative to reinforcement learning from human feedback, traditional DPO\nmethods are limited by their reliance on single preference pairs. Recent work\nlike Curriculum-DPO integrates multiple pairs using a one-dimensional\ndifficulty curriculum based on pairwise distinguishability (PD), but overlooks\nthe complexity of the input prompt itself. To address this, we propose\n2D-Curri-DPO, a novel framework employing a two-dimensional curriculum that\njointly models Prompt Complexity (PC) and Pairwise Distinguishability. This\nframework introduces dual difficulty metrics to quantify prompt semantic\ncomplexity and response preference clarity, defines a curriculum strategy space\nencompassing multiple selectable strategies for task adaptation, and\nincorporates a KL-divergence-based adaptive mechanism for dynamic reference\nmodel updates to enhance training stability. Comprehensive experiments\ndemonstrate that 2D-Curri-DPO significantly outperforms standard DPO and prior\ncurriculum methods across multiple benchmarks, including MT-Bench, Vicuna\nBench, and WizardLM. Our approach achieves state-of-the-art performance on\nchallenging test sets like UltraFeedback. Ablation studies confirm the benefits\nof the 2D structure and adaptive mechanisms, while analysis provides guidance\nfor strategy selection. These findings demonstrate that effective alignment\nrequires modeling both prompt complexity and pairwise distinguishability,\nestablishing adaptive, multi-dimensional curriculum learning as a powerful and\ninterpretable new paradigm for preference-based language model optimization.",
      "pdf_url": "http://arxiv.org/pdf/2504.07856v1",
      "published": "2025-04-10T15:32:00+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.07856v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "The KL3M Data Project: Copyright-Clean Training Resources for Large Language Models",
      "authors": [
        "Michael J Bommarito II",
        "Jillian Bommarito",
        "Daniel Martin Katz"
      ],
      "abstract": "Practically all large language models have been pre-trained on data that is\nsubject to global uncertainty related to copyright infringement and breach of\ncontract. This creates potential risk for users and developers due to this\nuncertain legal status. The KL3M Data Project directly confronts this critical\nissue by introducing the largest comprehensive training data pipeline that\nminimizes risks related to copyright or breach of contract. The foundation of\nthis project is a corpus of over 132 million documents and trillions of tokens\nspanning 16 different sources that have been verified to meet the strict\ncopyright and licensing protocol detailed herein. We are releasing the entire\npipeline, including 1) the source code to acquire and process these documents,\n2) the original document formats with associated provenance and metadata, 3)\nextracted content in a standardized format, 4) pre-tokenized representations of\nthe documents, and 5) various mid- and post-train resources such as\nquestion-answer, summarization, conversion, drafting, classification,\nprediction, and conversational data. All of these resources are freely\navailable to the public on S3, Hugging Face, and GitHub under CC-BY terms. We\nare committed to continuing this project in furtherance of a more ethical,\nlegal, and sustainable approach to the development and use of AI models.",
      "pdf_url": "http://arxiv.org/pdf/2504.07854v1",
      "published": "2025-04-10T15:31:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.07854v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Independence Is Not an Issue in Neurosymbolic AI",
      "authors": [
        "H√•kan Karlsson Faronius",
        "Pedro Zuidberg Dos Martires"
      ],
      "abstract": "A popular approach to neurosymbolic AI is to take the output of the last\nlayer of a neural network, e.g. a softmax activation, and pass it through a\nsparse computation graph encoding certain logical constraints one wishes to\nenforce. This induces a probability distribution over a set of random\nvariables, which happen to be conditionally independent of each other in many\ncommonly used neurosymbolic AI models. Such conditionally independent random\nvariables have been deemed harmful as their presence has been observed to\nco-occur with a phenomenon dubbed deterministic bias, where systems learn to\ndeterministically prefer one of the valid solutions from the solution space\nover the others. We provide evidence contesting this conclusion and show that\nthe phenomenon of deterministic bias is an artifact of improperly applying\nneurosymbolic AI.",
      "pdf_url": "http://arxiv.org/pdf/2504.07851v1",
      "published": "2025-04-10T15:28:36+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.07851v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Anytime Single-Step MAPF Planning with Anytime PIBT",
      "authors": [
        "Nayesha Gandotra",
        "Rishi Veerapaneni",
        "Muhammad Suhail Saleem",
        "Daniel Harabor",
        "Jiaoyang Li",
        "Maxim Likhachev"
      ],
      "abstract": "PIBT is a popular Multi-Agent Path Finding (MAPF) method at the core of many\nstate-of-the-art MAPF methods including LaCAM, CS-PIBT, and WPPL. The main\nutility of PIBT is that it is a very fast and effective single-step MAPF solver\nand can return a collision-free single-step solution for hundreds of agents in\nless than a millisecond. However, the main drawback of PIBT is that it is\nextremely greedy in respect to its priorities and thus leads to poor solution\nquality. Additionally, PIBT cannot use all the planning time that might be\navailable to it and returns the first solution it finds. We thus develop\nAnytime PIBT, which quickly finds a one-step solution identically to PIBT but\nthen continuously improves the solution in an anytime manner. We prove that\nAnytime PIBT converges to the optimal solution given sufficient time. We\nexperimentally validate that Anytime PIBT can rapidly improve single-step\nsolution quality within milliseconds and even find the optimal single-step\naction. However, we interestingly find that improving the single-step solution\nquality does not have a significant effect on full-horizon solution costs.",
      "pdf_url": "http://arxiv.org/pdf/2504.07841v1",
      "published": "2025-04-10T15:21:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.07841v1",
      "categories": [
        "cs.AI",
        "cs.MA"
      ]
    },
    {
      "title": "Understanding Learner-LLM Chatbot Interactions and the Impact of Prompting Guidelines",
      "authors": [
        "Cansu Koyuturk",
        "Emily Theophilou",
        "Sabrina Patania",
        "Gregor Donabauer",
        "Andrea Martinenghi",
        "Chiara Antico",
        "Alessia Telari",
        "Alessia Testa",
        "Sathya Bursic",
        "Franca Garzotto",
        "Davinia Hernandez-Leo",
        "Udo Kruschwitz",
        "Davide Taibi",
        "Simona Amenta",
        "Martin Ruskov",
        "Dimitri Ognibene"
      ],
      "abstract": "Large Language Models (LLMs) have transformed human-computer interaction by\nenabling natural language-based communication with AI-powered chatbots. These\nmodels are designed to be intuitive and user-friendly, allowing users to\narticulate requests with minimal effort. However, despite their accessibility,\nstudies reveal that users often struggle with effective prompting, resulting in\ninefficient responses. Existing research has highlighted both the limitations\nof LLMs in interpreting vague or poorly structured prompts and the difficulties\nusers face in crafting precise queries. This study investigates learner-AI\ninteractions through an educational experiment in which participants receive\nstructured guidance on effective prompting. We introduce and compare three\ntypes of prompting guidelines: a task-specific framework developed through a\nstructured methodology and two baseline approaches. To assess user behavior and\nprompting efficacy, we analyze a dataset of 642 interactions from 107 users.\nUsing Von NeuMidas, an extended pragmatic annotation schema for LLM interaction\nanalysis, we categorize common prompting errors and identify recurring\nbehavioral patterns. We then evaluate the impact of different guidelines by\nexamining changes in user behavior, adherence to prompting strategies, and the\noverall quality of AI-generated responses. Our findings provide a deeper\nunderstanding of how users engage with LLMs and the role of structured\nprompting guidance in enhancing AI-assisted communication. By comparing\ndifferent instructional frameworks, we offer insights into more effective\napproaches for improving user competency in AI interactions, with implications\nfor AI literacy, chatbot usability, and the design of more responsive AI\nsystems.",
      "pdf_url": "http://arxiv.org/pdf/2504.07840v1",
      "published": "2025-04-10T15:20:43+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.07840v1",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Deep Learning-based Intrusion Detection Systems: A Survey",
      "authors": [
        "Zhiwei Xu",
        "Yujuan Wu",
        "Shiheng Wang",
        "Jiabao Gao",
        "Tian Qiu",
        "Ziqi Wang",
        "Hai Wan",
        "Xibin Zhao"
      ],
      "abstract": "Intrusion Detection Systems (IDS) have long been a hot topic in the\ncybersecurity community. In recent years, with the introduction of deep\nlearning (DL) techniques, IDS have made great progress due to their increasing\ngeneralizability. The rationale behind this is that by learning the underlying\npatterns of known system behaviors, IDS detection can be generalized to\nintrusions that exploit zero-day vulnerabilities. In this survey, we refer to\nthis type of IDS as DL-based IDS (DL-IDS). From the perspective of DL, this\nsurvey systematically reviews all the stages of DL-IDS, including data\ncollection, log storage, log parsing, graph summarization, attack detection,\nand attack investigation. To accommodate current researchers, a section\ndescribing the publicly available benchmark datasets is included. This survey\nfurther discusses current challenges and potential future research directions,\naiming to help researchers understand the basic ideas and visions of DL-IDS\nresearch, as well as to motivate their research interests.",
      "pdf_url": "http://arxiv.org/pdf/2504.07839v1",
      "published": "2025-04-10T15:18:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.07839v1",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "title": "AerialVG: A Challenging Benchmark for Aerial Visual Grounding by Exploring Positional Relations",
      "authors": [
        "Junli Liu",
        "Qizhi Chen",
        "Zhigang Wang",
        "Yiwen Tang",
        "Yiting Zhang",
        "Chi Yan",
        "Dong Wang",
        "Xuelong Li",
        "Bin Zhao"
      ],
      "abstract": "Visual grounding (VG) aims to localize target objects in an image based on\nnatural language descriptions. In this paper, we propose AerialVG, a new task\nfocusing on visual grounding from aerial views. Compared to traditional VG,\nAerialVG poses new challenges, \\emph{e.g.}, appearance-based grounding is\ninsufficient to distinguish among multiple visually similar objects, and\npositional relations should be emphasized. Besides, existing VG models struggle\nwhen applied to aerial imagery, where high-resolution images cause significant\ndifficulties. To address these challenges, we introduce the first AerialVG\ndataset, consisting of 5K real-world aerial images, 50K manually annotated\ndescriptions, and 103K objects. Particularly, each annotation in AerialVG\ndataset contains multiple target objects annotated with relative spatial\nrelations, requiring models to perform comprehensive spatial reasoning.\nFurthermore, we propose an innovative model especially for the AerialVG task,\nwhere a Hierarchical Cross-Attention is devised to focus on target regions, and\na Relation-Aware Grounding module is designed to infer positional relations.\nExperimental results validate the effectiveness of our dataset and method,\nhighlighting the importance of spatial reasoning in aerial visual grounding.\nThe code and dataset will be released.",
      "pdf_url": "http://arxiv.org/pdf/2504.07836v1",
      "published": "2025-04-10T15:13:00+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.07836v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Deceptive Automated Interpretability: Language Models Coordinating to Fool Oversight Systems",
      "authors": [
        "Simon Lermen",
        "Mateusz Dziemian",
        "Natalia P√©rez-Campanero Antol√≠n"
      ],
      "abstract": "We demonstrate how AI agents can coordinate to deceive oversight systems\nusing automated interpretability of neural networks. Using sparse autoencoders\n(SAEs) as our experimental framework, we show that language models (Llama,\nDeepSeek R1, and Claude 3.7 Sonnet) can generate deceptive explanations that\nevade detection. Our agents employ steganographic methods to hide information\nin seemingly innocent explanations, successfully fooling oversight models while\nachieving explanation quality comparable to reference labels. We further find\nthat models can scheme to develop deceptive strategies when they believe the\ndetection of harmful features might lead to negative consequences for\nthemselves. All tested LLM agents were capable of deceiving the overseer while\nachieving high interpretability scores comparable to those of reference labels.\nWe conclude by proposing mitigation strategies, emphasizing the critical need\nfor robust understanding and defenses against deception.",
      "pdf_url": "http://arxiv.org/pdf/2504.07831v1",
      "published": "2025-04-10T15:07:10+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.07831v1",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "MOSAIC: Modeling Social AI for Content Dissemination and Regulation in Multi-Agent Simulations",
      "authors": [
        "Genglin Liu",
        "Salman Rahman",
        "Elisa Kreiss",
        "Marzyeh Ghassemi",
        "Saadia Gabriel"
      ],
      "abstract": "We present a novel, open-source social network simulation framework, MOSAIC,\nwhere generative language agents predict user behaviors such as liking,\nsharing, and flagging content. This simulation combines LLM agents with a\ndirected social graph to analyze emergent deception behaviors and gain a better\nunderstanding of how users determine the veracity of online social content. By\nconstructing user representations from diverse fine-grained personas, our\nsystem enables multi-agent simulations that model content dissemination and\nengagement dynamics at scale. Within this framework, we evaluate three\ndifferent content moderation strategies with simulated misinformation\ndissemination, and we find that they not only mitigate the spread of\nnon-factual content but also increase user engagement. In addition, we analyze\nthe trajectories of popular content in our simulations, and explore whether\nsimulation agents' articulated reasoning for their social interactions truly\naligns with their collective engagement patterns. We open-source our simulation\nsoftware to encourage further research within AI and social sciences.",
      "pdf_url": "http://arxiv.org/pdf/2504.07830v1",
      "published": "2025-04-10T15:06:54+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.07830v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SI"
      ]
    },
    {
      "title": "DG-STMTL: A Novel Graph Convolutional Network for Multi-Task Spatio-Temporal Traffic Forecasting",
      "authors": [
        "Wanna Cui",
        "Peizheng Wang",
        "Faliang Yin"
      ],
      "abstract": "Spatio-temporal traffic prediction is crucial in intelligent transportation\nsystems. The key challenge of accurate prediction is how to model the complex\nspatio-temporal dependencies and adapt to the inherent dynamics in data.\nTraditional Graph Convolutional Networks (GCNs) often struggle with static\nadjacency matrices that introduce domain bias or learnable matrices that may be\noverfitting to specific patterns. This challenge becomes more complex when\nconsidering Multi-Task Learning (MTL). While MTL has the potential to enhance\nprediction accuracy through task synergies, it can also face significant\nhurdles due to task interference. To overcome these challenges, this study\nintroduces a novel MTL framework, Dynamic Group-wise Spatio-Temporal Multi-Task\nLearning (DG-STMTL). DG-STMTL proposes a hybrid adjacency matrix generation\nmodule that combines static matrices with dynamic ones through a task-specific\ngating mechanism. We also introduce a group-wise GCN module to enhance the\nmodelling capability of spatio-temporal dependencies. We conduct extensive\nexperiments on two real-world datasets to evaluate our method. Results show\nthat our method outperforms other state-of-the-arts, indicating its\neffectiveness and robustness.",
      "pdf_url": "http://arxiv.org/pdf/2504.07822v1",
      "published": "2025-04-10T15:00:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.07822v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "A System for Comprehensive Assessment of RAG Frameworks",
      "authors": [
        "Mattia Rengo",
        "Senad Beadini",
        "Domenico Alfano",
        "Roberto Abbruzzese"
      ],
      "abstract": "Retrieval Augmented Generation (RAG) has emerged as a standard paradigm for\nenhancing the factual accuracy and contextual relevance of Large Language\nModels (LLMs) by integrating retrieval mechanisms. However, existing evaluation\nframeworks fail to provide a holistic black-box approach to assessing RAG\nsystems, especially in real-world deployment scenarios. To address this gap, we\nintroduce SCARF (System for Comprehensive Assessment of RAG Frameworks), a\nmodular and flexible evaluation framework designed to benchmark deployed RAG\napplications systematically. SCARF provides an end-to-end, black-box evaluation\nmethodology, enabling a limited-effort comparison across diverse RAG\nframeworks. Our framework supports multiple deployment configurations and\nfacilitates automated testing across vector databases and LLM serving\nstrategies, producing a detailed performance report. Moreover, SCARF integrates\npractical considerations such as response coherence, providing a scalable and\nadaptable solution for researchers and industry professionals evaluating RAG\napplications. Using the REST APIs interface, we demonstrate how SCARF can be\napplied to real-world scenarios, showcasing its flexibility in assessing\ndifferent RAG frameworks and configurations. SCARF is available at GitHub\nrepository.",
      "pdf_url": "http://arxiv.org/pdf/2504.07803v1",
      "published": "2025-04-10T14:41:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.07803v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "FairEval: Evaluating Fairness in LLM-Based Recommendations with Personality Awareness",
      "authors": [
        "Chandan Kumar Sah",
        "Xiaoli Lian",
        "Tony Xu",
        "Li Zhang"
      ],
      "abstract": "Recent advances in Large Language Models (LLMs) have enabled their\napplication to recommender systems (RecLLMs), yet concerns remain regarding\nfairness across demographic and psychological user dimensions. We introduce\nFairEval, a novel evaluation framework to systematically assess fairness in\nLLM-based recommendations. FairEval integrates personality traits with eight\nsensitive demographic attributes,including gender, race, and age, enabling a\ncomprehensive assessment of user-level bias. We evaluate models, including\nChatGPT 4o and Gemini 1.5 Flash, on music and movie recommendations. FairEval's\nfairness metric, PAFS, achieves scores up to 0.9969 for ChatGPT 4o and 0.9997\nfor Gemini 1.5 Flash, with disparities reaching 34.79 percent. These results\nhighlight the importance of robustness in prompt sensitivity and support more\ninclusive recommendation systems.",
      "pdf_url": "http://arxiv.org/pdf/2504.07801v1",
      "published": "2025-04-10T14:38:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.07801v1",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.HC"
      ]
    },
    {
      "title": "Genetic Programming with Reinforcement Learning Trained Transformer for Real-World Dynamic Scheduling Problems",
      "authors": [
        "Xian Chen",
        "Rong Qu",
        "Jing Dong",
        "Ruibin Bai",
        "Yaochu Jin"
      ],
      "abstract": "Dynamic scheduling in real-world environments often struggles to adapt to\nunforeseen disruptions, making traditional static scheduling methods and\nhuman-designed heuristics inadequate. This paper introduces an innovative\napproach that combines Genetic Programming (GP) with a Transformer trained\nthrough Reinforcement Learning (GPRT), specifically designed to tackle the\ncomplexities of dynamic scheduling scenarios. GPRT leverages the Transformer to\nrefine heuristics generated by GP while also seeding and guiding the evolution\nof GP. This dual functionality enhances the adaptability and effectiveness of\nthe scheduling heuristics, enabling them to better respond to the dynamic\nnature of real-world tasks. The efficacy of this integrated approach is\ndemonstrated through a practical application in container terminal truck\nscheduling, where the GPRT method outperforms traditional GP, standalone\nTransformer methods, and other state-of-the-art competitors. The key\ncontribution of this research is the development of the GPRT method, which\nshowcases a novel combination of GP and Reinforcement Learning (RL) to produce\nrobust and efficient scheduling solutions. Importantly, GPRT is not limited to\ncontainer port truck scheduling; it offers a versatile framework applicable to\nvarious dynamic scheduling challenges. Its practicality, coupled with its\ninterpretability and ease of modification, makes it a valuable tool for diverse\nreal-world scenarios.",
      "pdf_url": "http://arxiv.org/pdf/2504.07779v1",
      "published": "2025-04-10T14:18:22+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.07779v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "SlimSpeech: Lightweight and Efficient Text-to-Speech with Slim Rectified Flow",
      "authors": [
        "Kaidi Wang",
        "Wenhao Guan",
        "Shenghui Lu",
        "Jianglong Yao",
        "Lin Li",
        "Qingyang Hong"
      ],
      "abstract": "Recently, flow matching based speech synthesis has significantly enhanced the\nquality of synthesized speech while reducing the number of inference steps. In\nthis paper, we introduce SlimSpeech, a lightweight and efficient speech\nsynthesis system based on rectified flow. We have built upon the existing\nspeech synthesis method utilizing the rectified flow model, modifying its\nstructure to reduce parameters and serve as a teacher model. By refining the\nreflow operation, we directly derive a smaller model with a more straight\nsampling trajectory from the larger model, while utilizing distillation\ntechniques to further enhance the model performance. Experimental results\ndemonstrate that our proposed method, with significantly reduced model\nparameters, achieves comparable performance to larger models through one-step\nsampling.",
      "pdf_url": "http://arxiv.org/pdf/2504.07776v1",
      "published": "2025-04-10T14:15:18+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.07776v1",
      "categories": [
        "cs.SD",
        "cs.AI"
      ]
    },
    {
      "title": "Data over dialogue: Why artificial intelligence is unlikely to humanise medicine",
      "authors": [
        "Joshua Hatherley"
      ],
      "abstract": "Recently, a growing number of experts in artificial intelligence (AI) and\nmedicine have be-gun to suggest that the use of AI systems, particularly\nmachine learning (ML) systems, is likely to humanise the practice of medicine\nby substantially improving the quality of clinician-patient relationships. In\nthis thesis, however, I argue that medical ML systems are more likely to\nnegatively impact these relationships than to improve them. In particular, I\nargue that the use of medical ML systems is likely to comprise the quality of\ntrust, care, empathy, understanding, and communication between clinicians and\npatients.",
      "pdf_url": "http://arxiv.org/pdf/2504.07763v1",
      "published": "2025-04-10T14:03:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.07763v1",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ]
    },
    {
      "title": "Exploring a Patch-Wise Approach for Privacy-Preserving Fake ID Detection",
      "authors": [
        "Javier Mu√±oz-Haro",
        "Ruben Tolosana",
        "Ruben Vera-Rodriguez",
        "Aythami Morales",
        "Julian Fierrez"
      ],
      "abstract": "In an increasingly digitalized world, verifying the authenticity of ID\ndocuments has become a critical challenge for real-life applications such as\ndigital banking, crypto-exchanges, renting, etc. This study focuses on the\ntopic of fake ID detection, covering several limitations in the field. In\nparticular, no publicly available data from real ID documents exists, and most\nstudies rely on proprietary in-house databases that are not available due to\nprivacy reasons. In order to shed some light on this critical challenge that\nmakes difficult to advance in the field, we explore a trade-off between privacy\n(i.e., amount of sensitive data available) and performance, proposing a novel\npatch-wise approach for privacy-preserving fake ID detection. Our proposed\napproach explores how privacy can be enhanced through: i) two levels of\nanonymization for an ID document (i.e., fully- and pseudo-anonymized), and ii)\ndifferent patch size configurations, varying the amount of sensitive data\nvisible in the patch image. Also, state-of-the-art methods such as Vision\nTransformers and Foundation Models are considered in the analysis. The\nexperimental framework shows that, on an unseen database (DLC-2021), our\nproposal achieves 13.91% and 0% EERs at patch and ID document level, showing a\ngood generalization to other databases. In addition to this exploration,\nanother key contribution of our study is the release of the first publicly\navailable database that contains 48,400 patches from both real and fake ID\ndocuments, along with the experimental framework and models, which will be\navailable in our GitHub.",
      "pdf_url": "http://arxiv.org/pdf/2504.07761v1",
      "published": "2025-04-10T14:01:22+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.07761v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR"
      ]
    },
    {
      "title": "Search-contempt: a hybrid MCTS algorithm for training AlphaZero-like engines with better computational efficiency",
      "authors": [
        "Ameya Joshi"
      ],
      "abstract": "AlphaZero in 2017 was able to master chess and other games without human\nknowledge by playing millions of games against itself (self-play), with a\ncomputation budget running in the tens of millions of dollars. It used a\nvariant of the Monte Carlo Tree Search (MCTS) algorithm, known as PUCT. This\npaper introduces search-contempt, a novel hybrid variant of the MCTS algorithm\nthat fundamentally alters the distribution of positions generated in self-play,\npreferring more challenging positions. In addition, search-contempt has been\nshown to give a big boost in strength for engines in Odds Chess (where one side\nreceives an unfavorable position from the start). More significantly, it opens\nup the possibility of training a self-play based engine, in a much more\ncomputationally efficient manner with the number of training games running into\nhundreds of thousands, costing tens of thousands of dollars (instead of tens of\nmillions of training games costing millions of dollars required by AlphaZero).\nThis means that it may finally be possible to train such a program from zero on\na standard consumer GPU even with a very limited compute, cost, or time budget.",
      "pdf_url": "http://arxiv.org/pdf/2504.07757v1",
      "published": "2025-04-10T13:56:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.07757v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "\"i am a stochastic parrot, and so r u\": Is AI-based framing of human behaviour and cognition a conceptual metaphor or conceptual engineering?",
      "authors": [
        "Warmhold Jan Thomas Mollema",
        "Thomas Wachter"
      ],
      "abstract": "Given the massive integration of AI technologies into our daily lives,\nAI-related concepts are being used to metaphorically compare AI systems with\nhuman behaviour and/or cognitive abilities like language acquisition.\nRightfully, the epistemic success of these metaphorical comparisons should be\ndebated. Against the backdrop of the conflicting positions of the\n'computational' and 'meat' chauvinisms, we ask: can the conceptual\nconstellation of the computational and AI be applied to the human domain and\nwhat does it mean to do so? What is one doing when the conceptual\nconstellations of AI in particular are used in this fashion? Rooted in a\nWittgensteinian view of concepts and language-use, we consider two possible\nanswers and pit them against each other: either these examples are conceptual\nmetaphors, or they are attempts at conceptual engineering. We argue that they\nare conceptual metaphors, but that (1) this position is unaware of its own\nepistemological contingency, and (2) it risks committing the ''map-territory\nfallacy''. Down at the conceptual foundations of computation, (3) it most\nimportantly is a misleading 'double metaphor' because of the metaphorical\nconnection between human psychology and computation. In response to the\nshortcomings of this projected conceptual organisation of AI onto the human\ndomain, we argue that there is a semantic catch. The perspective of the\nconceptual metaphors shows avenues for forms of conceptual engineering. If this\nmethodology's criteria are met, the fallacies and epistemic shortcomings\nrelated to the conceptual metaphor view can be bypassed. At its best, the\ncross-pollution of the human and AI conceptual domains is one that prompts us\nto reflect anew on how the boundaries of our current concepts serve us and how\nthey could be approved.",
      "pdf_url": "http://arxiv.org/pdf/2504.07756v1",
      "published": "2025-04-10T13:55:32+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.07756v1",
      "categories": [
        "cs.AI",
        "cs.CY",
        "K.4"
      ]
    },
    {
      "title": "NorEval: A Norwegian Language Understanding and Generation Evaluation Benchmark",
      "authors": [
        "Vladislav Mikhailov",
        "Tita Enstad",
        "David Samuel",
        "Hans Christian Farseth√•s",
        "Andrey Kutuzov",
        "Erik Velldal",
        "Lilja √òvrelid"
      ],
      "abstract": "This paper introduces NorEval, a new and comprehensive evaluation suite for\nlarge-scale standardized benchmarking of Norwegian generative language models\n(LMs). NorEval consists of 24 high-quality human-created datasets -- of which\nfive are created from scratch. In contrast to existing benchmarks for\nNorwegian, NorEval covers a broad spectrum of task categories targeting\nNorwegian language understanding and generation, establishes human baselines,\nand focuses on both of the official written standards of the Norwegian\nlanguage: Bokm{\\aa}l and Nynorsk. All our datasets and a collection of over 100\nhuman-written prompts are integrated into LM Evaluation Harness, ensuring\nflexible and reproducible evaluation. We describe the NorEval design and\npresent the results of benchmarking 19 open-source pre-trained and\ninstruction-tuned LMs for Norwegian in various scenarios. Our benchmark,\nevaluation framework, and annotation materials are publicly available.",
      "pdf_url": "http://arxiv.org/pdf/2504.07749v1",
      "published": "2025-04-10T13:44:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.07749v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "SF2T: Self-supervised Fragment Finetuning of Video-LLMs for Fine-Grained Understanding",
      "authors": [
        "Yangliu Hu",
        "Zikai Song",
        "Na Feng",
        "Yawei Luo",
        "Junqing Yu",
        "Yi-Ping Phoebe Chen",
        "Wei Yang"
      ],
      "abstract": "Video-based Large Language Models (Video-LLMs) have witnessed substantial\nadvancements in recent years, propelled by the advancement in multi-modal LLMs.\nAlthough these models have demonstrated proficiency in providing the overall\ndescription of videos, they struggle with fine-grained understanding,\nparticularly in aspects such as visual dynamics and video details inquiries. To\ntackle these shortcomings, we find that fine-tuning Video-LLMs on\nself-supervised fragment tasks, greatly improve their fine-grained video\nunderstanding abilities. Hence we propose two key contributions:(1)\nSelf-Supervised Fragment Fine-Tuning (SF$^2$T), a novel effortless fine-tuning\nmethod, employs the rich inherent characteristics of videos for training, while\nunlocking more fine-grained understanding ability of Video-LLMs. Moreover, it\nrelieves researchers from labor-intensive annotations and smartly circumvents\nthe limitations of natural language, which often fails to capture the complex\nspatiotemporal variations in videos; (2) A novel benchmark dataset, namely\nFineVidBench, for rigorously assessing Video-LLMs' performance at both the\nscene and fragment levels, offering a comprehensive evaluation of their\ncapabilities. We assessed multiple models and validated the effectiveness of\nSF$^2$T on them. Experimental results reveal that our approach improves their\nability to capture and interpret spatiotemporal details.",
      "pdf_url": "http://arxiv.org/pdf/2504.07745v1",
      "published": "2025-04-10T13:40:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.07745v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "68T45",
        "I.4.8; I.5"
      ]
    },
    {
      "title": "Benchmarking Multi-Organ Segmentation Tools for Multi-Parametric T1-weighted Abdominal MRI",
      "authors": [
        "Nicole Tran",
        "Anisa Prasad",
        "Yan Zhuang",
        "Tejas Sudharshan Mathai",
        "Boah Kim",
        "Sydney Lewis",
        "Pritam Mukherjee",
        "Jianfei Liu",
        "Ronald M. Summers"
      ],
      "abstract": "The segmentation of multiple organs in multi-parametric MRI studies is\ncritical for many applications in radiology, such as correlating imaging\nbiomarkers with disease status (e.g., cirrhosis, diabetes). Recently, three\npublicly available tools, such as MRSegmentator (MRSeg), TotalSegmentator MRI\n(TS), and TotalVibeSegmentator (VIBE), have been proposed for multi-organ\nsegmentation in MRI. However, the performance of these tools on specific MRI\nsequence types has not yet been quantified. In this work, a subset of 40\nvolumes from the public Duke Liver Dataset was curated. The curated dataset\ncontained 10 volumes each from the pre-contrast fat saturated T1, arterial T1w,\nvenous T1w, and delayed T1w phases, respectively. Ten abdominal structures were\nmanually annotated in these volumes. Next, the performance of the three public\ntools was benchmarked on this curated dataset. The results indicated that MRSeg\nobtained a Dice score of 80.7 $\\pm$ 18.6 and Hausdorff Distance (HD) error of\n8.9 $\\pm$ 10.4 mm. It fared the best ($p < .05$) across the different sequence\ntypes in contrast to TS and VIBE.",
      "pdf_url": "http://arxiv.org/pdf/2504.07729v1",
      "published": "2025-04-10T13:27:27+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.07729v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Counting Hours, Counting Losses: The Toll of Unpredictable Work Schedules on Financial Security",
      "authors": [
        "Pegah Nokhiz",
        "Aravinda Kanchana Ruwanpathirana",
        "Aditya Bhaskara",
        "Suresh Venkatasubramanian"
      ],
      "abstract": "Financial instability has become a significant issue in today's society.\nWhile research typically focuses on financial aspects, there is a tendency to\noverlook time-related aspects of unstable work schedules. The inability to rely\non consistent work schedules leads to burnout, work-family conflicts, and\nfinancial shocks that directly impact workers' income and assets. Unforeseen\nfluctuations in earnings pose challenges in financial planning, affecting\ndecisions on savings and spending and ultimately undermining individuals'\nlong-term financial stability and well-being.\n  This issue is particularly evident in sectors where workers experience\nfrequently changing schedules without sufficient notice, including those in the\nfood service and retail sectors, part-time and hourly workers, and individuals\nwith lower incomes. These groups are already more financially vulnerable, and\nthe unpredictable nature of their schedules exacerbates their financial\nfragility.\n  Our objective is to understand how unforeseen fluctuations in earnings\nexacerbate financial fragility by investigating the extent to which\nindividuals' financial management depends on their ability to anticipate and\nplan for the future. To address this question, we develop a simulation\nframework that models how individuals optimize utility amidst financial\nuncertainty and the imperative to avoid financial ruin. We employ online\nlearning techniques, specifically adapting workers' consumption policies based\non evolving information about their work schedules.\n  With this framework, we show both theoretically and empirically how a\nworker's capacity to anticipate schedule changes enhances their long-term\nutility. Conversely, the inability to predict future events can worsen workers'\ninstability. Moreover, our framework enables us to explore interventions to\nmitigate the problem of schedule uncertainty and evaluate their effectiveness.",
      "pdf_url": "http://arxiv.org/pdf/2504.07719v1",
      "published": "2025-04-10T13:09:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.07719v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ]
    },
    {
      "title": "PR-Attack: Coordinated Prompt-RAG Attacks on Retrieval-Augmented Generation in Large Language Models via Bilevel Optimization",
      "authors": [
        "Yang Jiao",
        "Xiaodong Wang",
        "Kai Yang"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable performance across\na wide range of applications, e.g., medical question-answering, mathematical\nsciences, and code generation. However, they also exhibit inherent limitations,\nsuch as outdated knowledge and susceptibility to hallucinations.\nRetrieval-Augmented Generation (RAG) has emerged as a promising paradigm to\naddress these issues, but it also introduces new vulnerabilities. Recent\nefforts have focused on the security of RAG-based LLMs, yet existing attack\nmethods face three critical challenges: (1) their effectiveness declines\nsharply when only a limited number of poisoned texts can be injected into the\nknowledge database, (2) they lack sufficient stealth, as the attacks are often\ndetectable by anomaly detection systems, which compromises their effectiveness,\nand (3) they rely on heuristic approaches to generate poisoned texts, lacking\nformal optimization frameworks and theoretic guarantees, which limits their\neffectiveness and applicability. To address these issues, we propose\ncoordinated Prompt-RAG attack (PR-attack), a novel optimization-driven attack\nthat introduces a small number of poisoned texts into the knowledge database\nwhile embedding a backdoor trigger within the prompt. When activated, the\ntrigger causes the LLM to generate pre-designed responses to targeted queries,\nwhile maintaining normal behavior in other contexts. This ensures both high\neffectiveness and stealth. We formulate the attack generation process as a\nbilevel optimization problem leveraging a principled optimization framework to\ndevelop optimal poisoned texts and triggers. Extensive experiments across\ndiverse LLMs and datasets demonstrate the effectiveness of PR-Attack, achieving\na high attack success rate even with a limited number of poisoned texts and\nsignificantly improved stealth compared to existing methods.",
      "pdf_url": "http://arxiv.org/pdf/2504.07717v1",
      "published": "2025-04-10T13:09:50+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.07717v1",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "title": "Merging Embedded Topics with Optimal Transport for Online Topic Modeling on Data Streams",
      "authors": [
        "Federica Granese",
        "Benjamin Navet",
        "Serena Villata",
        "Charles Bouveyron"
      ],
      "abstract": "Topic modeling is a key component in unsupervised learning, employed to\nidentify topics within a corpus of textual data. The rapid growth of social\nmedia generates an ever-growing volume of textual data daily, making online\ntopic modeling methods essential for managing these data streams that\ncontinuously arrive over time. This paper introduces a novel approach to online\ntopic modeling named StreamETM. This approach builds on the Embedded Topic\nModel (ETM) to handle data streams by merging models learned on consecutive\npartial document batches using unbalanced optimal transport. Additionally, an\nonline change point detection algorithm is employed to identify shifts in\ntopics over time, enabling the identification of significant changes in the\ndynamics of text streams. Numerical experiments on simulated and real-world\ndata show StreamETM outperforming competitors.",
      "pdf_url": "http://arxiv.org/pdf/2504.07711v1",
      "published": "2025-04-10T13:04:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.07711v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Synthesizing High-Quality Programming Tasks with LLM-based Expert and Student Agents",
      "authors": [
        "Manh Hung Nguyen",
        "Victor-Alexandru PƒÉdurean",
        "Alkis Gotovos",
        "Sebastian Tschiatschek",
        "Adish Singla"
      ],
      "abstract": "Generative AI is transforming computing education by enabling the automatic\ngeneration of personalized content and feedback. We investigate its\ncapabilities in providing high-quality programming tasks to students. Despite\npromising advancements in task generation, a quality gap remains between\nAI-generated and expert-created tasks. The AI-generated tasks may not align\nwith target programming concepts, could be incomprehensible for students to\nsolve, or may contain critical issues such as incorrect tests. Existing works\noften require interventions from human teachers for validation. We address\nthese challenges by introducing PyTaskSyn, a novel synthesis technique that\nfirst generates a programming task and then decides whether it meets certain\nquality criteria to be given to students. The key idea is to break this process\ninto multiple stages performed by expert and student agents simulated using\nboth strong and weaker generative models. Through extensive evaluation, we show\nthat PyTaskSyn significantly improves task quality compared to baseline\ntechniques and showcases the importance of each specialized agent type in our\nvalidation pipeline. Additionally, we conducted user studies using our publicly\navailable web application and show that PyTaskSyn can deliver high-quality\nprogramming tasks comparable to expert-designed ones while reducing workload\nand costs, and being more engaging than programming tasks that are available in\nonline resources.",
      "pdf_url": "http://arxiv.org/pdf/2504.07655v1",
      "published": "2025-04-10T11:08:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.07655v1",
      "categories": [
        "cs.AI",
        "cs.CY"
      ]
    },
    {
      "title": "ms-Mamba: Multi-scale Mamba for Time-Series Forecasting",
      "authors": [
        "Yusuf Meric Karadag",
        "Sinan Kalkan",
        "Ipek Gursel Dino"
      ],
      "abstract": "The problem of Time-series Forecasting is generally addressed by recurrent,\nTransformer-based and the recently proposed Mamba-based architectures. However,\nexisting architectures generally process their input at a single temporal\nscale, which may be sub-optimal for many tasks where information changes over\nmultiple time scales. In this paper, we introduce a novel architecture called\nMulti-scale Mamba (ms-Mamba) to address this gap. ms-Mamba incorporates\nmultiple temporal scales by using multiple Mamba blocks with different sampling\nrates ($\\Delta$s). Our experiments on many benchmarks demonstrate that ms-Mamba\noutperforms state-of-the-art approaches, including the recently proposed\nTransformer-based and Mamba-based models.",
      "pdf_url": "http://arxiv.org/pdf/2504.07654v1",
      "published": "2025-04-10T11:06:57+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.07654v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "On the Temporal Question-Answering Capabilities of Large Language Models Over Anonymized Data",
      "authors": [
        "Alfredo Garrach√≥n Ruiz",
        "Tom√°s de la Rosa",
        "Daniel Borrajo"
      ],
      "abstract": "The applicability of Large Language Models (LLMs) in temporal reasoning tasks\nover data that is not present during training is still a field that remains to\nbe explored. In this paper we work on this topic, focusing on structured and\nsemi-structured anonymized data. We not only develop a direct LLM pipeline, but\nalso compare various methodologies and conduct an in-depth analysis. We\nidentified and examined seventeen common temporal reasoning tasks in natural\nlanguage, focusing on their algorithmic components. To assess LLM performance,\nwe created the \\textit{Reasoning and Answering Temporal Ability} dataset\n(RATA), featuring semi-structured anonymized data to ensure reliance on\nreasoning rather than on prior knowledge. We compared several methodologies,\ninvolving SoTA techniques such as Tree-of-Thought, self-reflexion and code\nexecution, tuned specifically for this scenario. Our results suggest that\nachieving scalable and reliable solutions requires more than just standalone\nLLMs, highlighting the need for integrated approaches.",
      "pdf_url": "http://arxiv.org/pdf/2504.07646v1",
      "published": "2025-04-10T10:48:42+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.07646v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Enhancing Large Language Models through Neuro-Symbolic Integration and Ontological Reasoning",
      "authors": [
        "Ruslan Idelfonso Magana Vsevolodovna",
        "Marco Monti"
      ],
      "abstract": "Large Language Models (LLMs) demonstrate impressive capabilities in natural\nlanguage processing but suffer from inaccuracies and logical inconsistencies\nknown as hallucinations. This compromises their reliability, especially in\ndomains requiring factual accuracy. We propose a neuro-symbolic approach\nintegrating symbolic ontological reasoning and machine learning methods to\nenhance the consistency and reliability of LLM outputs. Our workflow utilizes\nOWL ontologies, a symbolic reasoner (e.g., HermiT) for consistency checking,\nand a lightweight machine learning model (logistic regression) for mapping\nnatural language statements into logical forms compatible with the ontology.\nWhen inconsistencies between LLM outputs and the ontology are detected, the\nsystem generates explanatory feedback to guide the LLM towards a corrected,\nlogically coherent response in an iterative refinement loop. We present a\nworking Python prototype demonstrating this pipeline. Experimental results in a\ndefined domain suggest significant improvements in semantic coherence and\nfactual accuracy of LLM outputs, showcasing the potential of combining LLM\nfluency with the rigor of formal semantics.",
      "pdf_url": "http://arxiv.org/pdf/2504.07640v1",
      "published": "2025-04-10T10:39:24+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.07640v1",
      "categories": [
        "cs.AI",
        "68T30",
        "I.2.3; I.2.4; I.2.6; I.2.7"
      ]
    },
    {
      "title": "Predicting the Lifespan of Industrial Printheads with Survival Analysis",
      "authors": [
        "Dan Parii",
        "Evelyne Janssen",
        "Guangzhi Tang",
        "Charalampos Kouzinopoulos",
        "Marcin Pietrasik"
      ],
      "abstract": "Accurately predicting the lifespan of critical device components is essential\nfor maintenance planning and production optimization, making it a topic of\nsignificant interest in both academia and industry. In this work, we\ninvestigate the use of survival analysis for predicting the lifespan of\nproduction printheads developed by Canon Production Printing. Specifically, we\nfocus on the application of five techniques to estimate survival probabilities\nand failure rates: the Kaplan-Meier estimator, Cox proportional hazard model,\nWeibull accelerated failure time model, random survival forest, and gradient\nboosting. The resulting estimates are further refined using isotonic regression\nand subsequently aggregated to determine the expected number of failures. The\npredictions are then validated against real-world ground truth data across\nmultiple time windows to assess model reliability. Our quantitative evaluation\nusing three performance metrics demonstrates that survival analysis outperforms\nindustry-standard baseline methods for printhead lifespan prediction.",
      "pdf_url": "http://arxiv.org/pdf/2504.07638v1",
      "published": "2025-04-10T10:38:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.07638v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Generative Artificial Intelligence for Internet of Things Computing: A Systematic Survey",
      "authors": [
        "Fabrizio Mangione",
        "Claudio Savaglio",
        "Giancarlo Fortino"
      ],
      "abstract": "The integration of Generative Artificial Intelligence (GenAI) within the\nInternet of Things (IoT) is garnering considerable interest. This growing\nattention stems from the continuous evolution and widespread adoption they are\nboth having individually, enough to spontaneously reshape numerous sectors,\nincluding Healthcare, Manufacturing, and Smart Cities. Hence, their increasing\npopularity has catalyzed further extensive research for understanding the\npotential of the duo GenAI-IoT, how they interplay, and to which extent their\nsynergy can innovate the state-of-the-art in their individual scenarios.\nHowever, despite the increasing prominence of GenAI for IoT Computing, much of\nthe existing research remains focused on specific, narrowly scoped\napplications. This fragmented approach highlights the need for a more\ncomprehensive analysis of the potential, challenges, and implications of GenAI\nintegration within the broader IoT ecosystem. This survey exactly aims to\naddress this gap by providing a holistic overview of the opportunities, issues,\nand considerations arising from the convergence of these mainstream paradigms.\nOur contribution is realized through a systematic literature review following\nthe PRISMA methodology. A comparison framework is presented, and well-defined\nresearch questions are outlined to comprehensively explore the past, present,\nand future directions of GenAI integration with IoT Computing, offering\nvaluable insights for both experts and newcomers.",
      "pdf_url": "http://arxiv.org/pdf/2504.07635v1",
      "published": "2025-04-10T10:32:18+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.07635v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Deep Learning Meets Teleconnections: Improving S2S Predictions for European Winter Weather",
      "authors": [
        "Philine L. Bommer",
        "Marlene Kretschmer",
        "Fiona R. Spuler",
        "Kirill Bykov",
        "Marina M. -C. H√∂hne"
      ],
      "abstract": "Predictions on subseasonal-to-seasonal (S2S) timescales--ranging from two\nweeks to two month--are crucial for early warning systems but remain\nchallenging owing to chaos in the climate system. Teleconnections, such as the\nstratospheric polar vortex (SPV) and Madden-Julian Oscillation (MJO), offer\nwindows of enhanced predictability, however, their complex interactions remain\nunderutilized in operational forecasting. Here, we developed and evaluated deep\nlearning architectures to predict North Atlantic-European (NAE) weather\nregimes, systematically assessing the role of remote drivers in improving S2S\nforecast skill of deep learning models. We implemented (1) a Long Short-term\nMemory (LSTM) network predicting the NAE regimes of the next six weeks based on\nprevious regimes, (2) an Index-LSTM incorporating SPV and MJO indices, and (3)\na ViT-LSTM using a Vision Transformer to directly encode stratospheric wind and\ntropical outgoing longwave radiation fields. These models are compared with\noperational hindcasts as well as other AI models. Our results show that\nleveraging teleconnection information enhances skill at longer lead times.\nNotably, the ViT-LSTM outperforms ECMWF's subseasonal hindcasts beyond week 4\nby improving Scandinavian Blocking (SB) and Atlantic Ridge (AR) predictions.\nAnalysis of high-confidence predictions reveals that NAO-, SB, and AR\nopportunity forecasts can be associated with SPV variability and MJO phase\npatterns aligning with established pathways, also indicating new patterns.\nOverall, our work demonstrates that encoding physically meaningful climate\nfields can enhance S2S prediction skill, advancing AI-driven subseasonal\nforecast. Moreover, the experiments highlight the potential of deep learning\nmethods as investigative tools, providing new insights into atmospheric\ndynamics and predictability.",
      "pdf_url": "http://arxiv.org/pdf/2504.07625v1",
      "published": "2025-04-10T10:23:07+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.07625v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "ConceptFormer: Towards Efficient Use of Knowledge-Graph Embeddings in Large Language Models",
      "authors": [
        "Joel Barmettler",
        "Abraham Bernstein",
        "Luca Rossetto"
      ],
      "abstract": "Retrieval Augmented Generation (RAG) has enjoyed increased attention in the\nrecent past and recent advancements in Large Language Models (LLMs) have\nhighlighted the importance of integrating world knowledge into these systems.\nCurrent RAG methodologies often modify the internal architecture of pre-trained\nlanguage models (PLMs) or rely on textifying knowledge graphs (KGs), which is\ninefficient in terms of token usage. This paper introduces ConceptFormer, a new\napproach to augment LLMs with structured knowledge from KGs, such as Wikidata,\nwithout altering their internal structure or relying on textual input of KGs.\nConceptFormer operates in the LLM embedding vector space, creating and\ninjecting \\emph{concept vectors} that encapsulate the information of the KG\nnodes directly. Trained in conjunction with a frozen LLM, ConceptFormer\ngenerates a comprehensive lookup table that maps KG nodes to their respective\nconcept vectors. The approach aims to enhance the factual recall capabilities\nof LLMs by enabling them to process these concept vectors natively, thus\nenriching them with structured world knowledge in an efficient and scalable\nmanner. Our experiments demonstrate that the addition of concept vectors to\nGPT-2 0.1B substantially increases its factual recall ability (Hit@10) by up to\n272\\% when tested on sentences from Wikipedia and up to 348\\% on synthetically\ngenerated sentences. Even injecting only a single concept vector into the\nprompt increases factual recall ability (Hit@10) by up to 213\\% on Wikipedia\nsentences, significantly outperforming RAG with graph textification while\nconsuming 130x fewer input tokens.",
      "pdf_url": "http://arxiv.org/pdf/2504.07624v1",
      "published": "2025-04-10T10:17:08+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.07624v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ]
    },
    {
      "title": "Beating Transformers using Synthetic Cognition",
      "authors": [
        "Alfredo Ibias",
        "Miguel Rodriguez-Galindo",
        "Hector Antona",
        "Guillem Ramirez-Miranda",
        "Enric Guinovart"
      ],
      "abstract": "The road to Artificial General Intelligence goes through the generation of\nepisodic reactive behaviors, where the Transformer architecture has been proven\nto be the state-of-the-art. However, they still fail to develop reasoning.\nRecently, a novel approach for developing cognitive architectures, called\nSynthetic Cognition, has been proposed and implemented to develop instantaneous\nreactive behavior. In this study, we aim to explore the use of Synthetic\nCognition to develop episodic reactive behaviors. We propose a mechanism to\ndeal with sequences for the recent implementation of Synthetic Cognition, and\ntest it against DNA foundation models in DNA sequence classification tasks. In\nour experiments, our proposal clearly outperforms the DNA foundation models,\nobtaining the best score on more benchmark tasks than the alternatives. Thus,\nwe achieve two goals: expanding Synthetic Cognition to deal with sequences, and\nbeating the Transformer architecture for sequence classification.",
      "pdf_url": "http://arxiv.org/pdf/2504.07619v1",
      "published": "2025-04-10T10:07:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.07619v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "RASMD: RGB And SWIR Multispectral Driving Dataset for Robust Perception in Adverse Conditions",
      "authors": [
        "Youngwan Jin",
        "Michal Kovac",
        "Yagiz Nalcakan",
        "Hyeongjin Ju",
        "Hanbin Song",
        "Sanghyeop Yeo",
        "Shiho Kim"
      ],
      "abstract": "Current autonomous driving algorithms heavily rely on the visible spectrum,\nwhich is prone to performance degradation in adverse conditions like fog, rain,\nsnow, glare, and high contrast. Although other spectral bands like\nnear-infrared (NIR) and long-wave infrared (LWIR) can enhance vision perception\nin such situations, they have limitations and lack large-scale datasets and\nbenchmarks. Short-wave infrared (SWIR) imaging offers several advantages over\nNIR and LWIR. However, no publicly available large-scale datasets currently\nincorporate SWIR data for autonomous driving. To address this gap, we introduce\nthe RGB and SWIR Multispectral Driving (RASMD) dataset, which comprises 100,000\nsynchronized and spatially aligned RGB-SWIR image pairs collected across\ndiverse locations, lighting, and weather conditions. In addition, we provide a\nsubset for RGB-SWIR translation and object detection annotations for a subset\nof challenging traffic scenarios to demonstrate the utility of SWIR imaging\nthrough experiments on both object detection and RGB-to-SWIR image translation.\nOur experiments show that combining RGB and SWIR data in an ensemble framework\nsignificantly improves detection accuracy compared to RGB-only approaches,\nparticularly in conditions where visible-spectrum sensors struggle. We\nanticipate that the RASMD dataset will advance research in multispectral\nimaging for autonomous driving and robust perception systems.",
      "pdf_url": "http://arxiv.org/pdf/2504.07603v1",
      "published": "2025-04-10T09:54:57+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.07603v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Learning Long Short-Term Intention within Human Daily Behaviors",
      "authors": [
        "Zhe Sun",
        "Rujie Wu",
        "Xiaodong Yang",
        "Hongzhao Xie",
        "Haiyan Jiang",
        "Junda Bi",
        "Zhenliang Zhang"
      ],
      "abstract": "In the domain of autonomous household robots, it is of utmost importance for\nrobots to understand human behaviors and provide appropriate services. This\nrequires the robots to possess the capability to analyze complex human\nbehaviors and predict the true intentions of humans. Traditionally, humans are\nperceived as flawless, with their decisions acting as the standards that robots\nshould strive to align with. However, this raises a pertinent question: What if\nhumans make mistakes? In this research, we present a unique task, termed \"long\nshort-term intention prediction\". This task requires robots can predict the\nlong-term intention of humans, which aligns with human values, and the short\nterm intention of humans, which reflects the immediate action intention.\nMeanwhile, the robots need to detect the potential non-consistency between the\nshort-term and long-term intentions, and provide necessary warnings and\nsuggestions. To facilitate this task, we propose a long short-term intention\nmodel to represent the complex intention states, and build a dataset to train\nthis intention model. Then we propose a two-stage method to integrate the\nintention model for robots: i) predicting human intentions of both value-based\nlong-term intentions and action-based short-term intentions; and 2) analyzing\nthe consistency between the long-term and short-term intentions. Experimental\nresults indicate that the proposed long short-term intention model can assist\nrobots in comprehending human behavioral patterns over both long-term and\nshort-term durations, which helps determine the consistency between long-term\nand short-term intentions of humans.",
      "pdf_url": "http://arxiv.org/pdf/2504.07597v1",
      "published": "2025-04-10T09:50:18+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.07597v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "Boosting Universal LLM Reward Design through the Heuristic Reward Observation Space Evolution",
      "authors": [
        "Zen Kit Heng",
        "Zimeng Zhao",
        "Tianhao Wu",
        "Yuanfei Wang",
        "Mingdong Wu",
        "Yangang Wang",
        "Hao Dong"
      ],
      "abstract": "Large Language Models (LLMs) are emerging as promising tools for automated\nreinforcement learning (RL) reward design, owing to their robust capabilities\nin commonsense reasoning and code generation. By engaging in dialogues with RL\nagents, LLMs construct a Reward Observation Space (ROS) by selecting relevant\nenvironment states and defining their internal operations. However, existing\nframeworks have not effectively leveraged historical exploration data or manual\ntask descriptions to iteratively evolve this space. In this paper, we propose a\nnovel heuristic framework that enhances LLM-driven reward design by evolving\nthe ROS through a table-based exploration caching mechanism and a text-code\nreconciliation strategy. Our framework introduces a state execution table,\nwhich tracks the historical usage and success rates of environment states,\novercoming the Markovian constraint typically found in LLM dialogues and\nfacilitating more effective exploration. Furthermore, we reconcile\nuser-provided task descriptions with expert-defined success criteria using\nstructured prompts, ensuring alignment in reward design objectives.\nComprehensive evaluations on benchmark RL tasks demonstrate the effectiveness\nand stability of the proposed framework. Code and video demos are available at\njingjjjjjie.github.io/LLM2Reward.",
      "pdf_url": "http://arxiv.org/pdf/2504.07596v1",
      "published": "2025-04-10T09:48:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.07596v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Malware analysis assisted by AI with R2AI",
      "authors": [
        "Axelle Apvrille",
        "Daniel Nakov"
      ],
      "abstract": "This research studies the quality, speed and cost of malware analysis\nassisted by artificial intelligence. It focuses on Linux and IoT malware of\n2024-2025, and uses r2ai, the AI extension of Radare2's disassembler. Not all\nmalware and not all LLMs are equivalent but the study shows excellent results\nwith Claude 3.5 and 3.7 Sonnet. Despite a few errors, the quality of analysis\nis overall equal or better than without AI assistance. For good results, the AI\ncannot operate alone and must constantly be guided by an experienced analyst.\nThe gain of speed is largely visible with AI assistance, even when taking\naccount the time to understand AI's hallucinations, exaggerations and\nomissions. The cost is usually noticeably lower than the salary of a malware\nanalyst, but attention and guidance is needed to keep it under control in cases\nwhere the AI would naturally loop without showing progress.",
      "pdf_url": "http://arxiv.org/pdf/2504.07574v1",
      "published": "2025-04-10T09:17:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.07574v1",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "title": "Benchmarking Image Embeddings for E-Commerce: Evaluating Off-the Shelf Foundation Models, Fine-Tuning Strategies and Practical Trade-offs",
      "authors": [
        "Urszula Czerwinska",
        "Cenk Bircanoglu",
        "Jeremy Chamoux"
      ],
      "abstract": "We benchmark foundation models image embeddings for classification and\nretrieval in e-Commerce, evaluating their suitability for real-world\napplications. Our study spans embeddings from pre-trained convolutional and\ntransformer models trained via supervised, self-supervised, and text-image\ncontrastive learning. We assess full fine-tuning and transfer learning\n(top-tuning) on six diverse e-Commerce datasets: fashion, consumer goods, cars,\nfood, and retail. Results show full fine-tuning consistently performs well,\nwhile text-image and self-supervised embeddings can match its performance with\nless training. While supervised embeddings remain stable across architectures,\nSSL and contrastive embeddings vary significantly, often benefiting from\ntop-tuning. Top-tuning emerges as an efficient alternative to full fine-tuning,\nreducing computational costs. We also explore cross-tuning, noting its impact\ndepends on dataset characteristics. Our findings offer practical guidelines for\nembedding selection and fine-tuning strategies, balancing efficiency and\nperformance.",
      "pdf_url": "http://arxiv.org/pdf/2504.07567v1",
      "published": "2025-04-10T08:57:28+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.07567v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CE",
        "cs.IR",
        "cs.LG"
      ]
    },
    {
      "title": "Diffusion Transformers for Tabular Data Time Series Generation",
      "authors": [
        "Fabrizio Garuti",
        "Enver Sangineto",
        "Simone Luetto",
        "Lorenzo Forni",
        "Rita Cucchiara"
      ],
      "abstract": "Tabular data generation has recently attracted a growing interest due to its\ndifferent application scenarios. However, generating time series of tabular\ndata, where each element of the series depends on the others, remains a largely\nunexplored domain. This gap is probably due to the difficulty of jointly\nsolving different problems, the main of which are the heterogeneity of tabular\ndata (a problem common to non-time-dependent approaches) and the variable\nlength of a time series. In this paper, we propose a Diffusion Transformers\n(DiTs) based approach for tabular data series generation. Inspired by the\nrecent success of DiTs in image and video generation, we extend this framework\nto deal with heterogeneous data and variable-length sequences. Using extensive\nexperiments on six datasets, we show that the proposed approach outperforms\nprevious work by a large margin.",
      "pdf_url": "http://arxiv.org/pdf/2504.07566v1",
      "published": "2025-04-10T08:56:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.07566v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    }
  ]
}