{
  "last_updated": "2025-12-09T00:53:54.655104",
  "papers": [
    {
      "title": "Enhancing Retrieval-Augmented Generation with Entity Linking for Educational Platforms",
      "authors": [
        "Francesco Granata",
        "Francesco Poggi",
        "Misael Mongiovì"
      ],
      "abstract": "In the era of Large Language Models (LLMs), Retrieval-Augmented Generation (RAG) architectures are gaining significant attention for their ability to ground language generation in reliable knowledge sources. Despite their impressive effectiveness in many areas, RAG systems based solely on semantic similarity often fail to ensure factual accuracy in specialized domains, where terminological ambiguity can affect retrieval relevance. This study proposes an enhanced RAG architecture that integrates a factual signal derived from Entity Linking to improve the accuracy of educational question-answering systems in Italian. The system includes a Wikidata-based Entity Linking module and implements three re-ranking strategies to combine semantic and entity-based information: a hybrid score weighting model, reciprocal rank fusion, and a cross-encoder re-ranker. Experiments were conducted on two benchmarks: a custom academic dataset and the standard SQuAD-it dataset. Results show that, in domain-specific contexts, the hybrid schema based on reciprocal rank fusion significantly outperforms both the baseline and the cross-encoder approach, while the cross-encoder achieves the best results on the general-domain dataset. These findings confirm the presence of an effect of domain mismatch and highlight the importance of domain adaptation and hybrid ranking strategies to enhance factual precision and reliability in retrieval-augmented generation. They also demonstrate the potential of entity-aware RAG systems in educational environments, fostering adaptive and reliable AI-based tutoring tools.",
      "pdf_url": "https://arxiv.org/pdf/2512.05967v1",
      "published": "2025-12-05T18:59:18+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.05967v1",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    },
    {
      "title": "Training-Time Action Conditioning for Efficient Real-Time Chunking",
      "authors": [
        "Kevin Black",
        "Allen Z. Ren",
        "Michael Equi",
        "Sergey Levine"
      ],
      "abstract": "Real-time chunking (RTC) enables vision-language-action models (VLAs) to generate smooth, reactive robot trajectories by asynchronously predicting action chunks and conditioning on previously committed actions via inference-time inpainting. However, this inpainting method introduces computational overhead that increases inference latency. In this work, we propose a simple alternative: simulating inference delay at training time and conditioning on action prefixes directly, eliminating any inference-time overhead. Our method requires no modifications to the model architecture or robot runtime, and can be implemented with only a few additional lines of code. In simulated experiments, we find that training-time RTC outperforms inference-time RTC at higher inference delays. In real-world experiments on box building and espresso making tasks with the $π_{0.6}$ VLA, we demonstrate that training-time RTC maintains both task performance and speed parity with inference-time RTC while being computationally cheaper. Our results suggest that training-time action conditioning is a practical drop-in replacement for inference-time inpainting in real-time robot control.",
      "pdf_url": "https://arxiv.org/pdf/2512.05964v1",
      "published": "2025-12-05T18:57:28+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.05964v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "Whatever Remains Must Be True: Filtering Drives Reasoning in LLMs, Shaping Diversity",
      "authors": [
        "Germán Kruszewski",
        "Pierre Erbacher",
        "Jos Rozen",
        "Marc Dymetman"
      ],
      "abstract": "Reinforcement Learning (RL) has become the de facto standard for tuning LLMs to solve tasks involving reasoning. However, growing evidence shows that models trained in such way often suffer from a significant loss in diversity. We argue that this arises because RL implicitly optimizes the \"mode-seeking\" or \"zero-forcing\" Reverse KL to a target distribution causing the model to concentrate mass on certain high-probability regions of the target while neglecting others. In this work, we instead begin from an explicit target distribution, obtained by filtering out incorrect answers while preserving the relative probabilities of correct ones. Starting from a pre-trained LLM, we approximate this target distribution using the $α$-divergence family, which unifies prior approaches and enables direct control of the precision-diversity trade-off by interpolating between mode-seeking and mass-covering divergences. On a Lean theorem-proving benchmark, our method achieves state-of-the-art performance along the coverage-precision Pareto frontier, outperforming all prior methods on the coverage axis.",
      "pdf_url": "https://arxiv.org/pdf/2512.05962v1",
      "published": "2025-12-05T18:56:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.05962v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "AQUA-Net: Adaptive Frequency Fusion and Illumination Aware Network for Underwater Image Enhancement",
      "authors": [
        "Munsif Ali",
        "Najmul Hassan",
        "Lucia Ventura",
        "Davide Di Bari",
        "Simonepietro Canese"
      ],
      "abstract": "Underwater images often suffer from severe color distortion, low contrast, and a hazy appearance due to wavelength-dependent light absorption and scattering. Simultaneously, existing deep learning models exhibit high computational complexity, which limits their practical deployment for real-time underwater applications. To address these challenges, this paper presents a novel underwater image enhancement model, called Adaptive Frequency Fusion and Illumination Aware Network (AQUA-Net). It integrates a residual encoder decoder with dual auxiliary branches, which operate in the frequency and illumination domains. The frequency fusion encoder enriches spatial representations with frequency cues from the Fourier domain and preserves fine textures and structural details. Inspired by Retinex, the illumination-aware decoder performs adaptive exposure correction through a learned illumination map that separates reflectance from lighting effects. This joint spatial, frequency, and illumination design enables the model to restore color balance, visual contrast, and perceptual realism under diverse underwater conditions. Additionally, we present a high-resolution, real-world underwater video-derived dataset from the Mediterranean Sea, which captures challenging deep-sea conditions with realistic visual degradations to enable robust evaluation and development of deep learning models. Extensive experiments on multiple benchmark datasets show that AQUA-Net performs on par with SOTA in both qualitative and quantitative evaluations while using less number of parameters. Ablation studies further confirm that the frequency and illumination branches provide complementary contributions that improve visibility and color representation. Overall, the proposed model shows strong generalization capability and robustness, and it provides an effective solution for real-world underwater imaging applications.",
      "pdf_url": "https://arxiv.org/pdf/2512.05960v1",
      "published": "2025-12-05T18:56:10+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.05960v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "M4-RAG: A Massive-Scale Multilingual Multi-Cultural Multimodal RAG",
      "authors": [
        "David Anugraha",
        "Patrick Amadeus Irawan",
        "Anshul Singh",
        "En-Shiun Annie Lee",
        "Genta Indra Winata"
      ],
      "abstract": "Vision-language models (VLMs) have achieved strong performance in visual question answering (VQA), yet they remain constrained by static training data. Retrieval-Augmented Generation (RAG) mitigates this limitation by enabling access to up-to-date, culturally grounded, and multilingual information; however, multilingual multimodal RAG remains largely underexplored. We introduce M4-RAG, a massive-scale benchmark covering 42 languages and 56 regional dialects and registers, comprising over 80,000 culturally diverse image-question pairs for evaluating retrieval-augmented VQA across languages and modalities. To balance realism with reproducibility, we build a controlled retrieval environment containing millions of carefully curated multilingual documents relevant to the query domains, approximating real-world retrieval conditions while ensuring consistent experimentation. Our systematic evaluation reveals that although RAG consistently benefits smaller VLMs, it fails to scale to larger models and often even degrades their performance, exposing a critical mismatch between model size and current retrieval effectiveness. M4-RAG provides a foundation for advancing next-generation RAG systems capable of reasoning seamlessly across languages, modalities, and cultural contexts.",
      "pdf_url": "https://arxiv.org/pdf/2512.05959v1",
      "published": "2025-12-05T18:55:58+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.05959v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "MaxShapley: Towards Incentive-compatible Generative Search with Fair Context Attribution",
      "authors": [
        "Sara Patel",
        "Mingxun Zhou",
        "Giulia Fanti"
      ],
      "abstract": "Generative search engines based on large language models (LLMs) are replacing traditional search, fundamentally changing how information providers are compensated. To sustain this ecosystem, we need fair mechanisms to attribute and compensate content providers based on their contributions to generated answers. We introduce MaxShapley, an efficient algorithm for fair attribution in generative search pipelines that use retrieval-augmented generation (RAG). MaxShapley is a special case of the celebrated Shapley value; it leverages a decomposable max-sum utility function to compute attributions with linear computation in the number of documents, as opposed to the exponential cost of Shapley values. We evaluate MaxShapley on three multi-hop QA datasets (HotPotQA, MuSiQUE, MS MARCO); MaxShapley achieves comparable attribution quality to exact Shapley computation, while consuming a fraction of its tokens--for instance, it gives up to an 8x reduction in resource consumption over prior state-of-the-art methods at the same attribution accuracy.",
      "pdf_url": "https://arxiv.org/pdf/2512.05958v1",
      "published": "2025-12-05T18:54:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.05958v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "SymPyBench: A Dynamic Benchmark for Scientific Reasoning with Executable Python Code",
      "authors": [
        "Shima Imani",
        "Seungwhan Moon",
        "Adel Ahmadyan",
        "Lu Zhang",
        "Kirmani Ahmed",
        "Babak Damavandi"
      ],
      "abstract": "We introduce, a large-scale synthetic benchmark of 15,045 university-level physics problems (90/10% train/test split). Each problem is fully parameterized, supporting an effectively infinite range of input configurations, and is accompanied by structured, step-by-step reasoning and executable Python code that produces the ground-truth solution for any parameter set. The benchmark contains three question types: MC-Symbolic (multiple-choice with symbolic options), MC-Numerical (multiple-choice with numerical options), and free-form (open-ended responses). These diverse formats test complementary reasoning skills. By leveraging the dynamic, code-driven nature of the benchmark, we introduce three novel evaluation metrics in addition to standard accuracy: Consistency Score, Failure Rate, and Confusion Rate, that quantify variability and uncertainty across problem variants. Experiments with state-of-the-art instruction-tuned language models reveal both strengths and limitations in scientific reasoning, positioning SymPyBench as a foundation for developing more robust and interpretable reasoning systems",
      "pdf_url": "https://arxiv.org/pdf/2512.05954v1",
      "published": "2025-12-05T18:50:48+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.05954v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Trusted AI Agents in the Cloud",
      "authors": [
        "Teofil Bodea",
        "Masanori Misono",
        "Julian Pritzi",
        "Patrick Sabanic",
        "Thore Sommer",
        "Harshavardhan Unnibhavi",
        "David Schall",
        "Nuno Santos",
        "Dimitrios Stavrakakis",
        "Pramod Bhatotia"
      ],
      "abstract": "AI agents powered by large language models are increasingly deployed as cloud services that autonomously access sensitive data, invoke external tools, and interact with other agents. However, these agents run within a complex multi-party ecosystem, where untrusted components can lead to data leakage, tampering, or unintended behavior. Existing Confidential Virtual Machines (CVMs) provide only per binary protection and offer no guarantees for cross-principal trust, accelerator-level isolation, or supervised agent behavior. We present Omega, a system that enables trusted AI agents by enforcing end-to-end isolation, establishing verifiable trust across all contributing principals, and supervising every external interaction with accountable provenance. Omega builds on Confidential VMs and Confidential GPUs to create a Trusted Agent Platform that hosts many agents within a single CVM using nested isolation. It also provides efficient multi-agent orchestration with cross-principal trust establishment via differential attestation, and a policy specification and enforcement framework that governs data access, tool usage, and inter-agent communication for data protection and regulatory compliance. Implemented on AMD SEV-SNP and NVIDIA H100, Omega fully secures agent state across CVM-GPU, and achieves high performance while enabling high-density, policy-compliant multi-agent deployments at cloud scale.",
      "pdf_url": "https://arxiv.org/pdf/2512.05951v1",
      "published": "2025-12-05T18:48:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.05951v1",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.MA"
      ]
    },
    {
      "title": "Impugan: Learning Conditional Generative Models for Robust Data Imputation",
      "authors": [
        "Zalish Mahmud",
        "Anantaa Kotal",
        "Aritran Piplai"
      ],
      "abstract": "Incomplete data are common in real-world applications. Sensors fail, records are inconsistent, and datasets collected from different sources often differ in scale, sampling rate, and quality. These differences create missing values that make it difficult to combine data and build reliable models. Standard imputation methods such as regression models, expectation-maximization, and multiple imputation rely on strong assumptions about linearity and independence. These assumptions rarely hold for complex or heterogeneous data, which can lead to biased or over-smoothed estimates. We propose Impugan, a conditional Generative Adversarial Network (cGAN) for imputing missing values and integrating heterogeneous datasets. The model is trained on complete samples to learn how missing variables depend on observed ones. During inference, the generator reconstructs missing entries from available features, and the discriminator enforces realism by distinguishing true from imputed data. This adversarial process allows Impugan to capture nonlinear and multimodal relationships that conventional methods cannot represent. In experiments on benchmark datasets and a multi-source integration task, Impugan achieves up to 82\\% lower Earth Mover's Distance (EMD) and 70\\% lower mutual-information deviation (MI) compared to leading baselines. These results show that adversarially trained generative models provide a scalable and principled approach for imputing and merging incomplete, heterogeneous data. Our model is available at: github.com/zalishmahmud/impuganBigData2025",
      "pdf_url": "https://arxiv.org/pdf/2512.05950v1",
      "published": "2025-12-05T18:46:33+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.05950v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Variational Quantum Rainbow Deep Q-Network for Optimizing Resource Allocation Problem",
      "authors": [
        "Truong Thanh Hung Nguyen",
        "Truong Thinh Nguyen",
        "Hung Cao"
      ],
      "abstract": "Resource allocation remains NP-hard due to combinatorial complexity. While deep reinforcement learning (DRL) methods, such as the Rainbow Deep Q-Network (DQN), improve scalability through prioritized replay and distributional heads, classical function approximators limit their representational power. We introduce Variational Quantum Rainbow DQN (VQR-DQN), which integrates ring-topology variational quantum circuits with Rainbow DQN to leverage quantum superposition and entanglement. We frame the human resource allocation problem (HRAP) as a Markov decision process (MDP) with combinatorial action spaces based on officer capabilities, event schedules, and transition times. On four HRAP benchmarks, VQR-DQN achieves 26.8% normalized makespan reduction versus random baselines and outperforms Double DQN and classical Rainbow DQN by 4.9-13.4%. These gains align with theoretical connections between circuit expressibility, entanglement, and policy quality, demonstrating the potential of quantum-enhanced DRL for large-scale resource allocation. Our implementation is available at: https://github.com/Analytics-Everywhere-Lab/qtrl/.",
      "pdf_url": "https://arxiv.org/pdf/2512.05946v1",
      "published": "2025-12-05T18:43:18+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.05946v1",
      "categories": [
        "cs.AI",
        "cs.ET",
        "cs.SE"
      ]
    },
    {
      "title": "TRACE: A Framework for Analyzing and Enhancing Stepwise Reasoning in Vision-Language Models",
      "authors": [
        "Shima Imani",
        "Seungwhan Moon",
        "Lambert Mathias",
        "Lu Zhang",
        "Babak Damavandi"
      ],
      "abstract": "Reliable mathematical and scientific reasoning remains an open challenge for large vision-language models. Standard final-answer evaluation often masks reasoning errors, allowing silent failures to persist. To address this gap, we introduce TRACE, a framework for Transparent Reasoning And Consistency Evaluation that diagnoses reasoning trajectories rather than only end results. At its core, TRACE leverages Auxiliary Reasoning Sets, compact sub question answer pairs that decompose complex problems, evaluate intermediate steps through consistency-based metrics, and expose failures overlooked by standard evaluation. Our experiments show that consistency across ARS correlates with final-answer correctness and helps pinpoint the reasoning steps where failures arise, offering actionable signals for model improvement. Furthermore, TRACE defines confidence regions that distinguish reliable from unreliable reasoning paths, supporting effective filtering, debugging, and model refinement.",
      "pdf_url": "https://arxiv.org/pdf/2512.05943v1",
      "published": "2025-12-05T18:40:18+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.05943v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Zoom in, Click out: Unlocking and Evaluating the Potential of Zooming for GUI Grounding",
      "authors": [
        "Zhiyuan Jiang",
        "Shenghao Xie",
        "Wenyi Li",
        "Wenqiang Zu",
        "Peihang Li",
        "Jiahao Qiu",
        "Siqi Pei",
        "Lei Ma",
        "Tiejun Huang",
        "Mengdi Wang",
        "Shilong Liu"
      ],
      "abstract": "Grounding is a fundamental capability for building graphical user interface (GUI) agents. Although existing approaches rely on large-scale bounding box supervision, they still face various challenges, such as cross-platform generalization, complex layout analysis, and fine-grained element localization. In this paper, we investigate zoom as a strong yet underexplored prior for GUI grounding, and propose a training-free method, ZoomClick. By characterizing four key properties of zoom (i.e., pre-zoom, depth, shrink size, minimal crop size), we unlock its full capabilities for dynamic spatial focusing and adaptive context switching. Experiments demonstrate that our method significantly boosts the performance of both general vision-language and specialized GUI grounding models, achieving state-of-the-art results on several mainstream benchmarks; for example, UI-Venus-72B attains a 73.1% success rate on ScreenSpot-Pro. Furthermore, we present GUIZoom-Bench, a benchmark for evaluating model adaptability to zoom, aiming to inspire future research on improving zoom for further training and test-time scaling in GUI grounding tasks.",
      "pdf_url": "https://arxiv.org/pdf/2512.05941v1",
      "published": "2025-12-05T18:39:12+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.05941v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Measuring the Effect of Background on Classification and Feature Importance in Deep Learning for AV Perception",
      "authors": [
        "Anne Sielemann",
        "Valentin Barner",
        "Stefan Wolf",
        "Masoud Roschani",
        "Jens Ziehn",
        "Juergen Beyerer"
      ],
      "abstract": "Common approaches to explainable AI (XAI) for deep learning focus on analyzing the importance of input features on the classification task in a given model: saliency methods like SHAP and GradCAM are used to measure the impact of spatial regions of the input image on the classification result. Combined with ground truth information about the location of the object in the input image (e.g., a binary mask), it is determined whether object pixels had a high impact on the classification result, or whether the classification focused on background pixels. The former is considered to be a sign of a healthy classifier, whereas the latter is assumed to suggest overfitting on spurious correlations. A major challenge, however, is that these intuitive interpretations are difficult to test quantitatively, and hence the output of such explanations lacks an explanation itself. One particular reason is that correlations in real-world data are difficult to avoid, and whether they are spurious or legitimate is debatable. Synthetic data in turn can facilitate to actively enable or disable correlations where desired but often lack a sufficient quantification of realism and stochastic properties. [...] Therefore, we systematically generate six synthetic datasets for the task of traffic sign recognition, which differ only in their degree of camera variation and background correlation [...] to quantify the isolated influence of background correlation, different levels of camera variation, and considered traffic sign shapes on the classification performance, as well as background feature importance. [...] Results include a quantification of when and how much background features gain importance to support the classification task based on changes in the training domain [...].\n  Download: synset.de/datasets/synset-signset-ger/background-effect",
      "pdf_url": "https://arxiv.org/pdf/2512.05937v1",
      "published": "2025-12-05T18:25:52+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.05937v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ]
    },
    {
      "title": "PRiSM: An Agentic Multimodal Benchmark for Scientific Reasoning via Python-Grounded Evaluation",
      "authors": [
        "Shima Imani",
        "Seungwhan Moon",
        "Adel Ahmadyan",
        "Lu Zhang",
        "Kirmani Ahmed",
        "Babak Damavandi"
      ],
      "abstract": "Evaluating vision-language models (VLMs) in scientific domains like mathematics and physics poses unique challenges that go far beyond predicting final answers. These domains demand conceptual understanding, symbolic reasoning, and adherence to formal laws, requirements that most existing benchmarks fail to address. In particular, current datasets tend to be static, lacking intermediate reasoning steps, robustness to variations, or mechanisms for verifying scientific correctness. To address these limitations, we introduce PRiSM, a synthetic, fully dynamic, and multimodal benchmark for evaluating scientific reasoning via grounded Python code. PRiSM includes over 24,750 university-level physics and math problems, and it leverages our scalable agent-based pipeline, PrismAgent, to generate well-structured problem instances. Each problem contains dynamic textual and visual input, a generated figure, alongside rich structured outputs: executable Python code for ground truth generation and verification, and detailed step-by-step reasoning. The dynamic nature and Python-powered automated ground truth generation of our benchmark allow for fine-grained experimental auditing of multimodal VLMs, revealing failure modes, uncertainty behaviors, and limitations in scientific reasoning. To this end, we propose five targeted evaluation tasks covering generalization, symbolic program synthesis, perturbation robustness, reasoning correction, and ambiguity resolution. Through comprehensive evaluation of existing VLMs, we highlight their limitations and showcase how PRiSM enables deeper insights into their scientific reasoning capabilities.",
      "pdf_url": "https://arxiv.org/pdf/2512.05930v1",
      "published": "2025-12-05T18:14:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.05930v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "World Models That Know When They Don't Know: Controllable Video Generation with Calibrated Uncertainty",
      "authors": [
        "Zhiting Mei",
        "Tenny Yin",
        "Micah Baker",
        "Ola Shorinwa",
        "Anirudha Majumdar"
      ],
      "abstract": "Recent advances in generative video models have led to significant breakthroughs in high-fidelity video synthesis, specifically in controllable video generation where the generated video is conditioned on text and action inputs, e.g., in instruction-guided video editing and world modeling in robotics. Despite these exceptional capabilities, controllable video models often hallucinate - generating future video frames that are misaligned with physical reality - which raises serious concerns in many tasks such as robot policy evaluation and planning. However, state-of-the-art video models lack the ability to assess and express their confidence, impeding hallucination mitigation. To rigorously address this challenge, we propose C3, an uncertainty quantification (UQ) method for training continuous-scale calibrated controllable video models for dense confidence estimation at the subpatch level, precisely localizing the uncertainty in each generated video frame. Our UQ method introduces three core innovations to empower video models to estimate their uncertainty. First, our method develops a novel framework that trains video models for correctness and calibration via strictly proper scoring rules. Second, we estimate the video model's uncertainty in latent space, avoiding training instability and prohibitive training costs associated with pixel-space approaches. Third, we map the dense latent-space uncertainty to interpretable pixel-level uncertainty in the RGB space for intuitive visualization, providing high-resolution uncertainty heatmaps that identify untrustworthy regions. Through extensive experiments on large-scale robot learning datasets (Bridge and DROID) and real-world evaluations, we demonstrate that our method not only provides calibrated uncertainty estimates within the training distribution, but also enables effective out-of-distribution detection.",
      "pdf_url": "https://arxiv.org/pdf/2512.05927v1",
      "published": "2025-12-05T18:06:18+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.05927v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ]
    },
    {
      "title": "To Err Is Human: Systematic Quantification of Errors in Published AI Papers via LLM Analysis",
      "authors": [
        "Federico Bianchi",
        "Yongchan Kwon",
        "Zachary Izzo",
        "Linjun Zhang",
        "James Zou"
      ],
      "abstract": "How many mistakes do published AI papers contain? Peer-reviewed publications form the foundation upon which new research and knowledge are built. Errors that persist in the literature can propagate unnoticed, creating confusion in follow-up studies and complicating reproducibility. The accelerating pace of research and the increasing demands on the peer-review system make such mistakes harder to detect and avoid. To address this, we developed a Paper Correctness Checker based on GPT-5 to systematically identify mistakes in papers previously published at top AI conferences and journals. Our analysis focuses on objective mistakes-e.g., errors in formulas, derivations, calculations, figures, and tables-that have a clearly verifiable ground truth. We intentionally exclude subjective considerations such as novelty, importance, or writing quality. We find that published papers contain a non-negligible number of objective mistakes and that the average number of mistakes per paper has increased over time-from 3.8 in NeurIPS 2021 to 5.9 in NeurIPS 2025 (55.3% increase); from 4.1 in ICLR 2018 to 5.2 in ICLR 2025; and from 5.0 in TMLR 2022/23 to 5.5 in TMLR 2025. Human experts reviewed 316 potential mistakes identified by the AI Checker and confirmed that 263 were actual mistakes, corresponding to a precision of 83.2%. While most identified issues are relatively minor, correcting them would reduce confusion in the literature and strengthen reproducibility. The AI Checker also surfaced potentially more substantive mistakes that could affect the interpretation of results. Moreover, we show that the AI Checker can propose correct fixes for 75.8% of the identified mistakes. Overall, this study highlights the potential of frontier LLMs to detect and correct objective mistakes in published papers, helping to establish a firmer foundation of knowledge.",
      "pdf_url": "https://arxiv.org/pdf/2512.05925v1",
      "published": "2025-12-05T18:04:10+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.05925v1",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Natural Language Summarization Enables Multi-Repository Bug Localization by LLMs in Microservice Architectures",
      "authors": [
        "Amirkia Rafiei Oskooei",
        "S. Selcan Yukcu",
        "Mehmet Cevheri Bozoglan",
        "Mehmet S. Aktas"
      ],
      "abstract": "Bug localization in multi-repository microservice architectures is challenging due to the semantic gap between natural language bug reports and code, LLM context limitations, and the need to first identify the correct repository. We propose reframing this as a natural language reasoning task by transforming codebases into hierarchical NL summaries and performing NL-to-NL search instead of cross-modal retrieval. Our approach builds context-aware summaries at file, directory, and repository levels, then uses a two-phase search: first routing bug reports to relevant repositories, then performing top-down localization within those repositories. Evaluated on DNext, an industrial system with 46 repositories and 1.1M lines of code, our method achieves Pass@10 of 0.82 and MRR of 0.50, significantly outperforming retrieval baselines and agentic RAG systems like GitHub Copilot and Cursor. This work demonstrates that engineered natural language representations can be more effective than raw source code for scalable bug localization, providing an interpretable repository -> directory -> file search path, which is vital for building trust in enterprise AI tools by providing essential transparency.",
      "pdf_url": "https://arxiv.org/pdf/2512.05908v1",
      "published": "2025-12-05T17:42:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.05908v1",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ]
    },
    {
      "title": "Neural Coherence : Find higher performance to out-of-distribution tasks from few samples",
      "authors": [
        "Simon Guiroy",
        "Mats Richter",
        "Sarath Chandar",
        "Christopher Pal"
      ],
      "abstract": "To create state-of-the-art models for many downstream tasks, it has become common practice to fine-tune a pre-trained large vision model. However, it remains an open question of how to best determine which of the many possible model checkpoints resulting from a large training run to use as the starting point. This becomes especially important when data for the target task of interest is scarce, unlabeled and out-of-distribution. In such scenarios, common methods relying on in-distribution validation data become unreliable or inapplicable. This work proposes a novel approach for model selection that operates reliably on just a few unlabeled examples from the target task. Our approach is based on a novel concept: Neural Coherence, which entails characterizing a model's activation statistics for source and target domains, allowing one to define model selection methods with high data-efficiency. We provide experiments where models are pre-trained on ImageNet1K and examine target domains consisting of Food-101, PlantNet-300K and iNaturalist. We also evaluate it in many meta-learning settings. Our approach significantly improves generalization across these different target domains compared to established baselines. We further demonstrate the versatility of Neural Coherence as a powerful principle by showing its effectiveness in training data selection.",
      "pdf_url": "https://arxiv.org/pdf/2512.05880v1",
      "published": "2025-12-05T16:55:41+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.05880v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Sparse Attention Post-Training for Mechanistic Interpretability",
      "authors": [
        "Florent Draye",
        "Anson Lei",
        "Ingmar Posner",
        "Bernhard Schölkopf"
      ],
      "abstract": "We introduce a simple post-training method that makes transformer attention sparse without sacrificing performance. Applying a flexible sparsity regularisation under a constrained-loss objective, we show on models up to 1B parameters that it is possible to retain the original pretraining loss while reducing attention connectivity to $\\approx 0.3 \\%$ of its edges. Unlike sparse-attention methods designed for computational efficiency, our approach leverages sparsity as a structural prior: it preserves capability while exposing a more organized and interpretable connectivity pattern. We find that this local sparsity cascades into global circuit simplification: task-specific circuits involve far fewer components (attention heads and MLPs) with up to 100x fewer edges connecting them. These results demonstrate that transformer attention can be made orders of magnitude sparser, suggesting that much of its computation is redundant and that sparsity may serve as a guiding principle for more structured and interpretable models.",
      "pdf_url": "https://arxiv.org/pdf/2512.05865v1",
      "published": "2025-12-05T16:40:08+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.05865v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Optimizing Medical Question-Answering Systems: A Comparative Study of Fine-Tuned and Zero-Shot Large Language Models with RAG Framework",
      "authors": [
        "Tasnimul Hassan",
        "Md Faisal Karim",
        "Haziq Jeelani",
        "Elham Behnam",
        "Robert Green",
        "Fayeq Jeelani Syed"
      ],
      "abstract": "Medical question-answering (QA) systems can benefit from advances in large language models (LLMs), but directly applying LLMs to the clinical domain poses challenges such as maintaining factual accuracy and avoiding hallucinations. In this paper, we present a retrieval-augmented generation (RAG) based medical QA system that combines domain-specific knowledge retrieval with open-source LLMs to answer medical questions. We fine-tune two state-of-the-art open LLMs (LLaMA~2 and Falcon) using Low-Rank Adaptation (LoRA) for efficient domain specialization. The system retrieves relevant medical literature to ground the LLM's answers, thereby improving factual correctness and reducing hallucinations. We evaluate the approach on benchmark datasets (PubMedQA and MedMCQA) and show that retrieval augmentation yields measurable improvements in answer accuracy compared to using LLMs alone. Our fine-tuned LLaMA~2 model achieves 71.8% accuracy on PubMedQA, substantially improving over the 55.4% zero-shot baseline, while maintaining transparency by providing source references. We also detail the system design and fine-tuning methodology, demonstrating that grounding answers in retrieved evidence reduces unsupported content by approximately 60%. These results highlight the potential of RAG-augmented open-source LLMs for reliable biomedical QA, pointing toward practical clinical informatics applications.",
      "pdf_url": "https://arxiv.org/pdf/2512.05863v1",
      "published": "2025-12-05T16:38:47+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.05863v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "NEAT: Neighborhood-Guided, Efficient, Autoregressive Set Transformer for 3D Molecular Generation",
      "authors": [
        "Daniel Rose",
        "Roxane Axel Jacob",
        "Johannes Kirchmair",
        "Thierry Langer"
      ],
      "abstract": "Autoregressive models are a promising alternative to diffusion-based models for 3D molecular structure generation. However, a key limitation is the assumption of a token order: while text has a natural sequential order, the next token prediction given a molecular graph prefix should be invariant to atom permutations. Previous works sidestepped this mismatch by using canonical orders or focus atoms. We argue that this is unnecessary. We introduce NEAT, a Neighborhood-guided, Efficient, Autoregressive, Set Transformer that treats molecular graphs as sets of atoms and learns the order-agnostic distribution over admissible tokens at the graph boundary with an autoregressive flow model. NEAT approaches state-of-the-art performance in 3D molecular generation with high computational efficiency and atom-level permutation invariance, establishing a practical foundation for scalable molecular design.",
      "pdf_url": "https://arxiv.org/pdf/2512.05844v1",
      "published": "2025-12-05T16:18:07+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.05844v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Using Large Language Models to Create Personalized Networks From Therapy Sessions",
      "authors": [
        "Clarissa W. Ong",
        "Hiba Arnaout",
        "Kate Sheehan",
        "Estella Fox",
        "Eugen Owtscharow",
        "Iryna Gurevych"
      ],
      "abstract": "Recent advances in psychotherapy have focused on treatment personalization, such as by selecting treatment modules based on personalized networks. However, estimating personalized networks typically requires intensive longitudinal data, which is not always feasible. A solution to facilitate scalability of network-driven treatment personalization is leveraging LLMs. In this study, we present an end-to-end pipeline for automatically generating client networks from 77 therapy transcripts to support case conceptualization and treatment planning. We annotated 3364 psychological processes and their corresponding dimensions in therapy transcripts. Using these data, we applied in-context learning to jointly identify psychological processes and their dimensions. The method achieved high performance even with a few training examples. To organize the processes into networks, we introduced a two-step method that grouped them into clinically meaningful clusters. We then generated explanation-augmented relationships between clusters. Experts found that networks produced by our multi-step approach outperformed those built with direct prompting for clinical utility and interpretability, with up to 90% preferring our approach. In addition, the networks were rated favorably by experts, with scores for clinical relevance, novelty, and usefulness ranging from 72-75%. Our findings provide a proof of concept for using LLMs to create clinically relevant networks from therapy transcripts. Advantages of our approach include bottom-up case conceptualization from client utterances in therapy sessions and identification of latent themes. Networks generated from our pipeline may be used in clinical settings and supervision and training. Future research should examine whether these networks improve treatment outcomes relative to other methods of treatment personalization, including statistically estimated networks.",
      "pdf_url": "https://arxiv.org/pdf/2512.05836v1",
      "published": "2025-12-05T16:12:12+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.05836v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Phase-OTDR Event Detection Using Image-Based Data Transformation and Deep Learning",
      "authors": [
        "Muhammet Cagri Yeke",
        "Samil Sirin",
        "Kivilcim Yuksel",
        "Abdurrahman Gumus"
      ],
      "abstract": "This study focuses on event detection in optical fibers, specifically classifying six events using the Phase-OTDR system. A novel approach is introduced to enhance Phase-OTDR data analysis by transforming 1D data into grayscale images through techniques such as Gramian Angular Difference Field, Gramian Angular Summation Field, and Recurrence Plot. These grayscale images are combined into a multi-channel RGB representation, enabling more robust and adaptable analysis using transfer learning models. The proposed methodology achieves high classification accuracies of 98.84% and 98.24% with the EfficientNetB0 and DenseNet121 models, respectively. A 5-fold cross-validation process confirms the reliability of these models, with test accuracy rates of 99.07% and 98.68%. Using a publicly available Phase-OTDR dataset, the study demonstrates an efficient approach to understanding optical fiber events while reducing dataset size and improving analysis efficiency. The results highlight the transformative potential of image-based analysis in interpreting complex fiber optic sensing data, offering significant advancements in the accuracy and reliability of fiber optic monitoring systems. The codes and the corresponding image-based dataset are made publicly available on GitHub to support further research: https://github.com/miralab-ai/Phase-OTDR-event-detection.",
      "pdf_url": "https://arxiv.org/pdf/2512.05830v1",
      "published": "2025-12-05T15:52:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.05830v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Approximation of Box Decomposition Algorithm for Fast Hypervolume-Based Multi-Objective Optimization",
      "authors": [
        "Shuhei Watanabe"
      ],
      "abstract": "Hypervolume (HV)-based Bayesian optimization (BO) is one of the standard approaches for multi-objective decision-making. However, the computational cost of optimizing the acquisition function remains a significant bottleneck, primarily due to the expense of HV improvement calculations. While HV box-decomposition offers an efficient way to cope with the frequent exact improvement calculations, it suffers from super-polynomial memory complexity $O(MN^{\\lfloor \\frac{M + 1}{2} \\rfloor})$ in the worst case as proposed by Lacour et al. (2017). To tackle this problem, Couckuyt et al. (2012) employed an approximation algorithm. However, a rigorous algorithmic description is currently absent from the literature. This paper bridges this gap by providing comprehensive mathematical and algorithmic details of this approximation algorithm.",
      "pdf_url": "https://arxiv.org/pdf/2512.05825v1",
      "published": "2025-12-05T15:43:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.05825v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Multimodal Oncology Agent for IDH1 Mutation Prediction in Low-Grade Glioma",
      "authors": [
        "Hafsa Akebli",
        "Adam Shephard",
        "Vincenzo Della Mea",
        "Nasir Rajpoot"
      ],
      "abstract": "Low-grade gliomas frequently present IDH1 mutations that define clinically distinct subgroups with specific prognostic and therapeutic implications. This work introduces a Multimodal Oncology Agent (MOA) integrating a histology tool based on the TITAN foundation model for IDH1 mutation prediction in low-grade glioma, combined with reasoning over structured clinical and genomic inputs through PubMed, Google Search, and OncoKB. MOA reports were quantitatively evaluated on 488 patients from the TCGA-LGG cohort against clinical and histology baselines. MOA without the histology tool outperformed the clinical baseline, achieving an F1-score of 0.826 compared to 0.798. When fused with histology features, MOA reached the highest performance with an F1-score of 0.912, exceeding both the histology baseline at 0.894 and the fused histology-clinical baseline at 0.897. These results demonstrate that the proposed agent captures complementary mutation-relevant information enriched through external biomedical sources, enabling accurate IDH1 mutation prediction.",
      "pdf_url": "https://arxiv.org/pdf/2512.05824v1",
      "published": "2025-12-05T15:43:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.05824v1",
      "categories": [
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Probing the effectiveness of World Models for Spatial Reasoning through Test-time Scaling",
      "authors": [
        "Saurav Jha",
        "M. Jehanzeb Mirza",
        "Wei Lin",
        "Shiqi Yang",
        "Sarath Chandar"
      ],
      "abstract": "Vision-Language Models (VLMs) remain limited in spatial reasoning tasks that require multi-view understanding and embodied perspective shifts. Recent approaches such as MindJourney attempt to mitigate this gap through test-time scaling where a world model imagines action-conditioned trajectories and a heuristic verifier selects helpful views from such trajectories. In this work, we systematically examine how such test-time verifiers behave across benchmarks, uncovering both their promise and their pitfalls. Our uncertainty-based analyses show that MindJourney's verifier provides little meaningful calibration, and that random scoring often reduces answer entropy equally well, thus exposing systematic action biases and unreliable reward signals. To mitigate these, we introduce a Verification through Spatial Assertions (ViSA) framework that grounds the test-time reward in verifiable, frame-anchored micro-claims. This principled verifier consistently improves spatial reasoning on the SAT-Real benchmark and corrects trajectory-selection biases through more balanced exploratory behavior. However, on the challenging MMSI-Bench, none of the verifiers, including ours, achieve consistent scaling, suggesting that the current world models form an information bottleneck where imagined views fail to enrich fine-grained reasoning. Together, these findings chart the bad, good, and ugly aspects of test-time verification for world-model-based reasoning. Our code is available at https://github.com/chandar-lab/visa-for-mindjourney.",
      "pdf_url": "https://arxiv.org/pdf/2512.05809v1",
      "published": "2025-12-05T15:30:08+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.05809v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "3D Path Planning for Robot-assisted Vertebroplasty from Arbitrary Bi-plane X-ray via Differentiable Rendering",
      "authors": [
        "Blanca Inigo",
        "Benjamin D. Killeen",
        "Rebecca Choi",
        "Michelle Song",
        "Ali Uneri",
        "Majid Khan",
        "Christopher Bailey",
        "Axel Krieger",
        "Mathias Unberath"
      ],
      "abstract": "Robotic systems are transforming image-guided interventions by enhancing accuracy and minimizing radiation exposure. A significant challenge in robotic assistance lies in surgical path planning, which often relies on the registration of intraoperative 2D images with preoperative 3D CT scans. This requirement can be burdensome and costly, particularly in procedures like vertebroplasty, where preoperative CT scans are not routinely performed. To address this issue, we introduce a differentiable rendering-based framework for 3D transpedicular path planning utilizing bi-planar 2D X-rays. Our method integrates differentiable rendering with a vertebral atlas generated through a Statistical Shape Model (SSM) and employs a learned similarity loss to refine the SSM shape and pose dynamically, independent of fixed imaging geometries. We evaluated our framework in two stages: first, through vertebral reconstruction from orthogonal X-rays for benchmarking, and second, via clinician-in-the-loop path planning using arbitrary-view X-rays. Our results indicate that our method outperformed a normalized cross-correlation baseline in reconstruction metrics (DICE: 0.75 vs. 0.65) and achieved comparable performance to the state-of-the-art model ReVerteR (DICE: 0.77), while maintaining generalization to arbitrary views. Success rates for bipedicular planning reached 82% with synthetic data and 75% with cadaver data, exceeding the 66% and 31% rates of a 2D-to-3D baseline, respectively. In conclusion, our framework facilitates versatile, CT-free 3D path planning for robot-assisted vertebroplasty, effectively accommodating real-world imaging diversity without the need for preoperative CT scans.",
      "pdf_url": "https://arxiv.org/pdf/2512.05803v1",
      "published": "2025-12-05T15:26:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.05803v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "Mechanistic Interpretability of Antibody Language Models Using SAEs",
      "authors": [
        "Rebonto Haque",
        "Oliver M. Turnbull",
        "Anisha Parsan",
        "Nithin Parsan",
        "John J. Yang",
        "Charlotte M. Deane"
      ],
      "abstract": "Sparse autoencoders (SAEs) are a mechanistic interpretability technique that have been used to provide insight into learned concepts within large protein language models. Here, we employ TopK and Ordered SAEs to investigate an autoregressive antibody language model, p-IgGen, and steer its generation. We show that TopK SAEs can reveal biologically meaningful latent features, but high feature concept correlation does not guarantee causal control over generation. In contrast, Ordered SAEs impose an hierarchical structure that reliably identifies steerable features, but at the expense of more complex and less interpretable activation patterns. These findings advance the mechanistic interpretability of domain-specific protein language models and suggest that, while TopK SAEs are sufficient for mapping latent features to concepts, Ordered SAEs are preferable when precise generative steering is required.",
      "pdf_url": "https://arxiv.org/pdf/2512.05794v1",
      "published": "2025-12-05T15:18:50+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.05794v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ]
    },
    {
      "title": "Active Video Perception: Iterative Evidence Seeking for Agentic Long Video Understanding",
      "authors": [
        "Ziyang Wang",
        "Honglu Zhou",
        "Shijie Wang",
        "Junnan Li",
        "Caiming Xiong",
        "Silvio Savarese",
        "Mohit Bansal",
        "Michael S. Ryoo",
        "Juan Carlos Niebles"
      ],
      "abstract": "Long video understanding (LVU) is challenging because answering real-world queries often depends on sparse, temporally dispersed cues buried in hours of mostly redundant and irrelevant content. While agentic pipelines improve video reasoning capabilities, prevailing frameworks rely on a query-agnostic captioner to perceive video information, which wastes computation on irrelevant content and blurs fine-grained temporal and spatial information. Motivated by active perception theory, we argue that LVU agents should actively decide what, when, and where to observe, and continuously assess whether the current observation is sufficient to answer the query. We present Active Video Perception (AVP), an evidence-seeking framework that treats the video as an interactive environment and acquires compact, queryrelevant evidence directly from pixels. Concretely, AVP runs an iterative plan-observe-reflect process with MLLM agents. In each round, a planner proposes targeted video interactions, an observer executes them to extract time-stamped evidence, and a reflector evaluates the sufficiency of the evidence for the query, either halting with an answer or triggering further observation. Across five LVU benchmarks, AVP achieves highest performance with significant improvements. Notably, AVP outperforms the best agentic method by 5.7% in average accuracy while only requires 18.4% inference time and 12.4% input tokens.",
      "pdf_url": "https://arxiv.org/pdf/2512.05774v1",
      "published": "2025-12-05T15:03:48+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.05774v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "The Missing Layer of AGI: From Pattern Alchemy to Coordination Physics",
      "authors": [
        "Edward Y. Chang"
      ],
      "abstract": "Influential critiques argue that Large Language Models (LLMs) are a dead end for AGI: \"mere pattern matchers\" structurally incapable of reasoning or planning. We argue this conclusion misidentifies the bottleneck: it confuses the ocean with the net. Pattern repositories are the necessary System-1 substrate; the missing component is a System-2 coordination layer that selects, constrains, and binds these patterns. We formalize this layer via UCCT, a theory of semantic anchoring that models reasoning as a phase transition governed by effective support (rho_d), representational mismatch (d_r), and an adaptive anchoring budget (gamma log k). Under this lens, ungrounded generation is simply an unbaited retrieval of the substrate's maximum likelihood prior, while \"reasoning\" emerges when anchors shift the posterior toward goal-directed constraints. We translate UCCT into architecture with MACI, a coordination stack that implements baiting (behavior-modulated debate), filtering (Socratic judging), and persistence (transactional memory). By reframing common objections as testable coordination failures, we argue that the path to AGI runs through LLMs, not around them.",
      "pdf_url": "https://arxiv.org/pdf/2512.05765v1",
      "published": "2025-12-05T14:51:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.05765v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Evolutionary System 2 Reasoning: An Empirical Proof",
      "authors": [
        "Zeyuan Ma",
        "Wenqi Huang",
        "Guo-Huan Song",
        "Hongshu Guo",
        "Sijie Ma",
        "Zhiguang Cao",
        "Yue-Jiao Gong"
      ],
      "abstract": "Machine intelligence marks the ultimate dream of making machines' intelligence comparable to human beings. While recent progress in Large Language Models (LLMs) show substantial specific skills for a wide array of downstream tasks, they more or less fall shorts in general intelligence. Following correlation between intelligence and system 2 reasoning (slow thinking), in this paper, we aim to answering a worthwhile research question: could machine intelligence such as LLMs be evolved to acquire reasoning ability (not specific skill) just like our human beings? To this end, we propose evolutionary reasoning optimization (ERO) framework which performs survival of the fittest over a population of LLMs to search for individual with strong reasoning ability. Given a reasoning task, ERO first initializes multiple LLMs as a population, after which an evolutionary strategy evolves the population to maximize quantified reasoning score of the best individual. Based on experiments on representative testsuites, we claim two surprising empirical discoveries: i) the latest LLMs such as GPT-5 still show limited system 2 reasoning ability; ii) with simple evolution-loop of ERO, a relatively weak model (Qwen-7B) could be enhanced to emerge powerful reasoning ability. Our project can be accessed at https://github.com/MetaEvo/ERO for reproduction needs.",
      "pdf_url": "https://arxiv.org/pdf/2512.05760v1",
      "published": "2025-12-05T14:47:57+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.05760v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "A Fast Anti-Jamming Cognitive Radar Deployment Algorithm Based on Reinforcement Learning",
      "authors": [
        "Wencheng Cai",
        "Xuchao Gao",
        "Congying Han",
        "Mingqiang Li",
        "Tiande Guo"
      ],
      "abstract": "The fast deployment of cognitive radar to counter jamming remains a critical challenge in modern warfare, where more efficient deployment leads to quicker detection of targets. Existing methods are primarily based on evolutionary algorithms, which are time-consuming and prone to falling into local optima. We tackle these drawbacks via the efficient inference of neural networks and propose a brand new framework: Fast Anti-Jamming Radar Deployment Algorithm (FARDA). We first model the radar deployment problem as an end-to-end task and design deep reinforcement learning algorithms to solve it, where we develop integrated neural modules to perceive heatmap information and a brand new reward format. Empirical results demonstrate that our method achieves coverage comparable to evolutionary algorithms while deploying radars approximately 7,000 times faster. Further ablation experiments confirm the necessity of each component of FARDA.",
      "pdf_url": "https://arxiv.org/pdf/2512.05753v1",
      "published": "2025-12-05T14:39:50+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.05753v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "KANFormer for Predicting Fill Probabilities via Survival Analysis in Limit Order Books",
      "authors": [
        "Jinfeng Zhong",
        "Emmanuel Bacry",
        "Agathe Guilloux",
        "Jean-François Muzy"
      ],
      "abstract": "This paper introduces KANFormer, a novel deep-learning-based model for predicting the time-to-fill of limit orders by leveraging both market- and agent-level information. KANFormer combines a Dilated Causal Convolutional network with a Transformer encoder, enhanced by Kolmogorov-Arnold Networks (KANs), which improve nonlinear approximation. Unlike existing models that rely solely on a series of snapshots of the limit order book, KANFormer integrates the actions of agents related to LOB dynamics and the position of the order in the queue to more effectively capture patterns related to execution likelihood. We evaluate the model using CAC 40 index futures data with labeled orders. The results show that KANFormer outperforms existing works in both calibration (Right-Censored Log-Likelihood, Integrated Brier Score) and discrimination (C-index, time-dependent AUC). We further analyze feature importance over time using SHAP (SHapley Additive exPlanations). Our results highlight the benefits of combining rich market signals with expressive neural architectures to achieve accurate and interpretabl predictions of fill probabilities.",
      "pdf_url": "https://arxiv.org/pdf/2512.05734v1",
      "published": "2025-12-05T14:15:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.05734v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Efficient Text Classification with Conformal In-Context Learning",
      "authors": [
        "Ippokratis Pantelidis",
        "Korbinian Randl",
        "Aron Henriksson"
      ],
      "abstract": "Large Language Models (LLMs) demonstrate strong in-context learning abilities, yet their effectiveness in text classification depends heavily on prompt design and incurs substantial computational cost. Conformal In-Context Learning (CICLe) has been proposed as a resource-efficient framework that integrates a lightweight base classifier with Conformal Prediction to guide LLM prompting by adaptively reducing the set of candidate classes. However, its broader applicability and efficiency benefits beyond a single domain have not yet been systematically explored. In this paper, we present a comprehensive evaluation of CICLe across diverse NLP classification benchmarks. The results show that CICLe consistently improves over its base classifier and outperforms few-shot prompting baselines when the sample size is sufficient for training the base classifier, and performs comparably in low-data regimes. In terms of efficiency, CICLe reduces the number of shots and prompt length by up to 34.45% and 25.16%, respectively, and enables the use of smaller models with competitive performance. CICLe is furthermore particularly advantageous for text classification tasks with high class imbalance. These findings highlight CICLe as a practical and scalable approach for efficient text classification, combining the robustness of traditional classifiers with the adaptability of LLMs, and achieving substantial gains in data and computational efficiency.",
      "pdf_url": "https://arxiv.org/pdf/2512.05732v1",
      "published": "2025-12-05T14:11:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.05732v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Big Tech-Funded AI Papers Have Higher Citation Impact, Greater Insularity, and Larger Recency Bias",
      "authors": [
        "Max Martin Gnewuch",
        "Jan Philip Wahle",
        "Terry Ruas",
        "Bela Gipp"
      ],
      "abstract": "Over the past four decades, artificial intelligence (AI) research has flourished at the nexus of academia and industry. However, Big Tech companies have increasingly acquired the edge in computational resources, big data, and talent. So far, it has been largely unclear how many papers the industry funds, how their citation impact compares to non-funded papers, and what drives industry interest. This study fills that gap by quantifying the number of industry-funded papers at 10 top AI conferences (e.g., ICLR, CVPR, AAAI, ACL) and their citation influence. We analyze about 49.8K papers, about 1.8M citations from AI papers to other papers, and about 2.3M citations from other papers to AI papers from 1998-2022 in Scopus. Through seven research questions, we examine the volume and evolution of industry funding in AI research, the citation impact of funded papers, the diversity and temporal range of their citations, and the subfields in which industry predominantly acts. Our findings reveal that industry presence has grown markedly since 2015, from less than 2 percent to more than 11 percent in 2020. Between 2018 and 2022, 12 percent of industry-funded papers achieved high citation rates as measured by the h5-index, compared to 4 percent of non-industry-funded papers and 2 percent of non-funded papers. Top AI conferences engage more with industry-funded research than non-funded research, as measured by our newly proposed metric, the Citation Preference Ratio (CPR). We show that industry-funded research is increasingly insular, citing predominantly other industry-funded papers while referencing fewer non-funded papers. These findings reveal new trends in AI research funding, including a shift towards more industry-funded papers and their growing citation impact, greater insularity of industry-funded work than non-funded work, and a preference of industry-funded research to cite recent work.",
      "pdf_url": "https://arxiv.org/pdf/2512.05714v1",
      "published": "2025-12-05T13:41:29+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.05714v1",
      "categories": [
        "cs.DL",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Bayesian Active Inference for Intelligent UAV Anti-Jamming and Adaptive Trajectory Planning",
      "authors": [
        "Ali Krayani",
        "Seyedeh Fatemeh Sadati",
        "Lucio Marcenaro",
        "Carlo Regazzoni"
      ],
      "abstract": "This paper proposes a hierarchical trajectory planning framework for UAVs operating under adversarial jamming conditions. Leveraging Bayesian Active Inference, the approach combines expert-generated demonstrations with probabilistic generative modeling to encode high-level symbolic planning, low-level motion policies, and wireless signal feedback. During deployment, the UAV performs online inference to anticipate interference, localize jammers, and adapt its trajectory accordingly, without prior knowledge of jammer locations. Simulation results demonstrate that the proposed method achieves near-expert performance, significantly reducing communication interference and mission cost compared to model-free reinforcement learning baselines, while maintaining robust generalization in dynamic environments.",
      "pdf_url": "https://arxiv.org/pdf/2512.05711v1",
      "published": "2025-12-05T13:38:52+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.05711v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "eess.SP",
        "eess.SY"
      ]
    },
    {
      "title": "Faithfulness metric fusion: Improving the evaluation of LLM trustworthiness across domains",
      "authors": [
        "Ben Malin",
        "Tatiana Kalganova",
        "Nikolaos Boulgouris"
      ],
      "abstract": "We present a methodology for improving the accuracy of faithfulness evaluation in Large Language Models (LLMs). The proposed methodology is based on the combination of elementary faithfulness metrics into a combined (fused) metric, for the purpose of improving the faithfulness of LLM outputs. The proposed strategy for metric fusion deploys a tree-based model to identify the importance of each metric, which is driven by the integration of human judgements evaluating the faithfulness of LLM responses. This fused metric is demonstrated to correlate more strongly with human judgements across all tested domains for faithfulness. Improving the ability to evaluate the faithfulness of LLMs, allows for greater confidence to be placed within models, allowing for their implementation in a greater diversity of scenarios. Additionally, we homogenise a collection of datasets across question answering and dialogue-based domains and implement human judgements and LLM responses within this dataset, allowing for the reproduction and trialling of faithfulness evaluation across domains.",
      "pdf_url": "https://arxiv.org/pdf/2512.05700v1",
      "published": "2025-12-05T13:28:29+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.05700v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "HiMoE-VLA: Hierarchical Mixture-of-Experts for Generalist Vision-Language-Action Policies",
      "authors": [
        "Zhiying Du",
        "Bei Liu",
        "Yaobo Liang",
        "Yichao Shen",
        "Haidong Cao",
        "Xiangyu Zheng",
        "Zhiyuan Feng",
        "Zuxuan Wu",
        "Jiaolong Yang",
        "Yu-Gang Jiang"
      ],
      "abstract": "The development of foundation models for embodied intelligence critically depends on access to large-scale, high-quality robot demonstration data. Recent approaches have sought to address this challenge by training on large collections of heterogeneous robotic datasets. However, unlike vision or language data, robotic demonstrations exhibit substantial heterogeneity across embodiments and action spaces as well as other prominent variations such as senor configurations and action control frequencies. The lack of explicit designs for handling such heterogeneity causes existing methods to struggle with integrating diverse factors, thereby limiting their generalization and leading to degraded performance when transferred to new settings. In this paper, we present HiMoE-VLA, a novel vision-language-action (VLA) framework tailored to effectively handle diverse robotic data with heterogeneity. Specifically, we introduce a Hierarchical Mixture-of-Experts (HiMoE) architecture for the action module which adaptively handles multiple sources of heterogeneity across layers and gradually abstracts them into shared knowledge representations. Through extensive experimentation with simulation benchmarks and real-world robotic platforms, HiMoE-VLA demonstrates a consistent performance boost over existing VLA baselines, achieving higher accuracy and robust generalization across diverse robots and action spaces. The code and models are publicly available at https://github.com/ZhiyingDu/HiMoE-VLA.",
      "pdf_url": "https://arxiv.org/pdf/2512.05693v1",
      "published": "2025-12-05T13:21:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.05693v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "Retrieving Semantically Similar Decisions under Noisy Institutional Labels: Robust Comparison of Embedding Methods",
      "authors": [
        "Tereza Novotna",
        "Jakub Harasta"
      ],
      "abstract": "Retrieving case law is a time-consuming task predominantly carried out by querying databases. We provide a comparison of two models in three different settings for Czech Constitutional Court decisions: (i) a large general-purpose embedder (OpenAI), (ii) a domain-specific BERT-trained from scratch on ~30,000 decisions using sliding windows and attention pooling. We propose a noise-aware evaluation including IDF-weighted keyword overlap as graded relevance, binarization via two thresholds (0.20 balanced, 0.28 strict), significance via paired bootstrap, and an nDCG diagnosis supported with qualitative analysis. Despite modest absolute nDCG (expected under noisy labels), the general OpenAI embedder decisively outperforms the domain pre-trained BERT in both settings at @10/@20/@100 across both thresholds; differences are statistically significant. Diagnostics attribute low absolutes to label drift and strong ideals rather than lack of utility. Additionally, our framework is robust enough to be used for evaluation under a noisy gold dataset, which is typical when handling data with heterogeneous labels stemming from legacy judicial databases.",
      "pdf_url": "https://arxiv.org/pdf/2512.05681v1",
      "published": "2025-12-05T12:54:26+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.05681v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "InverseCrafter: Efficient Video ReCapture as a Latent Domain Inverse Problem",
      "authors": [
        "Yeobin Hong",
        "Suhyeon Lee",
        "Hyungjin Chung",
        "Jong Chul Ye"
      ],
      "abstract": "Recent approaches to controllable 4D video generation often rely on fine-tuning pre-trained Video Diffusion Models (VDMs). This dominant paradigm is computationally expensive, requiring large-scale datasets and architectural modifications, and frequently suffers from catastrophic forgetting of the model's original generative priors. Here, we propose InverseCrafter, an efficient inpainting inverse solver that reformulates the 4D generation task as an inpainting problem solved in the latent space. The core of our method is a principled mechanism to encode the pixel space degradation operator into a continuous, multi-channel latent mask, thereby bypassing the costly bottleneck of repeated VAE operations and backpropagation. InverseCrafter not only achieves comparable novel view generation and superior measurement consistency in camera control tasks with near-zero computational overhead, but also excels at general-purpose video inpainting with editing. Code is available at https://github.com/yeobinhong/InverseCrafter.",
      "pdf_url": "https://arxiv.org/pdf/2512.05672v1",
      "published": "2025-12-05T12:31:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.05672v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "On Dynamic Programming Theory for Leader-Follower Stochastic Games",
      "authors": [
        "Jilles Steeve Dibangoye",
        "Thibaut Le Marre",
        "Ocan Sankur",
        "François Schwarzentruber"
      ],
      "abstract": "Leader-follower general-sum stochastic games (LF-GSSGs) model sequential decision-making under asymmetric commitment, where a leader commits to a policy and a follower best responds, yielding a strong Stackelberg equilibrium (SSE) with leader-favourable tie-breaking. This paper introduces a dynamic programming (DP) framework that applies Bellman recursion over credible sets-state abstractions formally representing all rational follower best responses under partial leader commitments-to compute SSEs. We first prove that any LF-GSSG admits a lossless reduction to a Markov decision process (MDP) over credible sets. We further establish that synthesising an optimal memoryless deterministic leader policy is NP-hard, motivating the development of ε-optimal DP algorithms with provable guarantees on leader exploitability. Experiments on standard mixed-motive benchmarks-including security games, resource allocation, and adversarial planning-demonstrate empirical gains in leader value and runtime scalability over state-of-the-art methods.",
      "pdf_url": "https://arxiv.org/pdf/2512.05667v1",
      "published": "2025-12-05T12:23:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.05667v1",
      "categories": [
        "cs.GT",
        "cs.AI"
      ]
    },
    {
      "title": "Feasibility of AI-Assisted Programming for End-User Development",
      "authors": [
        "Irene Weber"
      ],
      "abstract": "End-user development,where non-programmers create or adapt their own digital tools, can play a key role in driving digital transformation within organizations. Currently, low-code/no-code platforms are widely used to enable end-user development through visual programming, minimizing the need for manual coding. Recent advancements in generative AI, particularly large language model-based assistants and \"copilots\", open new possibilities, as they may enable end users to generate and refine programming code and build apps directly from natural language prompts. This approach, here referred to as AI-assisted end-user coding, promises greater flexibility, broader applicability, faster development, improved reusability, and reduced vendor lock-in compared to the established visual LCNC platforms. This paper investigates whether AI-assisted end-user coding is a feasible paradigm for end-user development, which may complement or even replace the LCNC model in the future. To explore this, we conducted a case study in which non-programmers were asked to develop a basic web app through interaction with AI assistants.The majority of study participants successfully completed the task in reasonable time and also expressed support for AI-assisted end-user coding as a viable approach for end-user development. The paper presents the study design, analyzes the outcomes, and discusses potential implications for practice, future research, and academic teaching.",
      "pdf_url": "https://arxiv.org/pdf/2512.05666v1",
      "published": "2025-12-05T12:13:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.05666v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SE"
      ]
    },
    {
      "title": "Grounded Multilingual Medical Reasoning for Question Answering with Large Language Models",
      "authors": [
        "Pietro Ferrazzi",
        "Aitor Soroa",
        "Rodrigo Agerri"
      ],
      "abstract": "Large Language Models (LLMs) with reasoning capabilities have recently demonstrated strong potential in medical Question Answering (QA). Existing approaches are largely English-focused and primarily rely on distillation from general-purpose LLMs, raising concerns about the reliability of their medical knowledge. In this work, we present a method to generate multilingual reasoning traces grounded in factual medical knowledge. We produce 500k traces in English, Italian, and Spanish, using a retrievalaugmented generation approach over medical information from Wikipedia. The traces are generated to solve medical questions drawn from MedQA and MedMCQA, which we extend to Italian and Spanish. We test our pipeline in both in-domain and outof-domain settings across Medical QA benchmarks, and demonstrate that our reasoning traces improve performance both when utilized via in-context learning (few-shot) and supervised fine-tuning, yielding state-of-the-art results among 8B-parameter LLMs. We believe that these resources can support the development of safer, more transparent clinical decision-support tools in multilingual settings. We release the full suite of resources: reasoning traces, translated QA datasets, Medical-Wikipedia, and fine-tuned models.",
      "pdf_url": "https://arxiv.org/pdf/2512.05658v1",
      "published": "2025-12-05T12:05:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.05658v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Modular Jets for Supervised Pipelines: Diagnosing Mirage vs Identifiability",
      "authors": [
        "Suman Sanyal"
      ],
      "abstract": "Classical supervised learning evaluates models primarily via predictive risk on hold-out data. Such evaluations quantify how well a function behaves on a distribution, but they do not address whether the internal decomposition of a model is uniquely determined by the data and evaluation design. In this paper, we introduce \\emph{Modular Jets} for regression and classification pipelines. Given a task manifold (input space), a modular decomposition, and access to module-level representations, we estimate empirical jets, which are local linear response maps that describe how each module reacts to small structured perturbations of the input. We propose an empirical notion of \\emph{mirage} regimes, where multiple distinct modular decompositions induce indistinguishable jets and thus remain observationally equivalent, and contrast this with an \\emph{identifiable} regime, where the observed jets single out a decomposition up to natural symmetries. In the setting of two-module linear regression pipelines we prove a jet-identifiability theorem. Under mild rank assumptions and access to module-level jets, the internal factorisation is uniquely determined, whereas risk-only evaluation admits a large family of mirage decompositions that implement the same input-to-output map. We then present an algorithm (MoJet) for empirical jet estimation and mirage diagnostics, and illustrate the framework using linear and deep regression as well as pipeline classification.",
      "pdf_url": "https://arxiv.org/pdf/2512.05638v1",
      "published": "2025-12-05T11:30:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.05638v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ]
    },
    {
      "title": "Enhancing Local Search for MaxSAT with Deep Differentiation Clause Weighting",
      "authors": [
        "Menghua Jiang",
        "Haokai Gao",
        "Shuhao Chen",
        "Yin Chen"
      ],
      "abstract": "Partial Maximum Satisfiability (PMS) and Weighted Partial Maximum Satisfiability (WPMS) generalize Maximum Satisfiability (MaxSAT), with broad real-world applications. Recent advances in Stochastic Local Search (SLS) algorithms for solving (W)PMS have mainly focused on designing clause weighting schemes. However, existing methods often fail to adequately distinguish between PMS and WPMS, typically employing uniform update strategies for clause weights and overlooking critical structural differences between the two problem types. In this work, we present a novel clause weighting scheme that, for the first time, updates the clause weights of PMS and WPMS instances according to distinct conditions. This scheme also introduces a new initialization method, which better accommodates the unique characteristics of both instance types. Furthermore, we propose a decimation method that prioritizes satisfying unit and hard clauses, effectively complementing our proposed clause weighting scheme. Building on these methods, we develop a new SLS solver for (W)PMS named DeepDist. Experimental results on benchmarks from the anytime tracks of recent MaxSAT Evaluations show that DeepDist outperforms state-of-the-art SLS solvers. Notably, a hybrid solver combining DeepDist with TT-Open-WBO-Inc surpasses the performance of the MaxSAT Evaluation 2024 winners, SPB-MaxSAT-c-Band and SPB-MaxSAT-c-FPS, highlighting the effectiveness of our approach. The code is available at https://github.com/jmhmaxsat/DeepDist",
      "pdf_url": "https://arxiv.org/pdf/2512.05619v1",
      "published": "2025-12-05T11:02:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.05619v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Ontology Learning with LLMs: A Benchmark Study on Axiom Identification",
      "authors": [
        "Roos M. Bakker",
        "Daan L. Di Scala",
        "Maaike H. T. de Boer",
        "Stephan A. Raaijmakers"
      ],
      "abstract": "Ontologies are an important tool for structuring domain knowledge, but their development is a complex task that requires significant modelling and domain expertise. Ontology learning, aimed at automating this process, has seen advancements in the past decade with the improvement of Natural Language Processing techniques, and especially with the recent growth of Large Language Models (LLMs). This paper investigates the challenge of identifying axioms: fundamental ontology components that define logical relations between classes and properties. In this work, we introduce an Ontology Axiom Benchmark OntoAxiom, and systematically test LLMs on that benchmark for axiom identification, evaluating different prompting strategies, ontologies, and axiom types. The benchmark consists of nine medium-sized ontologies with together 17.118 triples, and 2.771 axioms. We focus on subclass, disjoint, subproperty, domain, and range axioms. To evaluate LLM performance, we compare twelve LLMs with three shot settings and two prompting strategies: a Direct approach where we query all axioms at once, versus an Axiom-by-Axiom (AbA) approach, where each prompt queries for one axiom only. Our findings show that the AbA prompting leads to higher F1 scores than the direct approach. However, performance varies across axioms, suggesting that certain axioms are more challenging to identify. The domain also influences performance: the FOAF ontology achieves a score of 0.642 for the subclass axiom, while the music ontology reaches only 0.218. Larger LLMs outperform smaller ones, but smaller models may still be viable for resource-constrained settings. Although performance overall is not high enough to fully automate axiom identification, LLMs can provide valuable candidate axioms to support ontology engineers with the development and refinement of ontologies.",
      "pdf_url": "https://arxiv.org/pdf/2512.05594v1",
      "published": "2025-12-05T10:28:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.05594v1",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "A Comprehensive Framework for Automated Quality Control in the Automotive Industry",
      "authors": [
        "Panagiota Moraiti",
        "Panagiotis Giannikos",
        "Athanasios Mastrogeorgiou",
        "Panagiotis Mavridis",
        "Linghao Zhou",
        "Panagiotis Chatzakos"
      ],
      "abstract": "This paper presents a cutting-edge robotic inspection solution designed to automate quality control in automotive manufacturing. The system integrates a pair of collaborative robots, each equipped with a high-resolution camera-based vision system to accurately detect and localize surface and thread defects in aluminum high-pressure die casting (HPDC) automotive components. In addition, specialized lenses and optimized lighting configurations are employed to ensure consistent and high-quality image acquisition. The YOLO11n deep learning model is utilized, incorporating additional enhancements such as image slicing, ensemble learning, and bounding-box merging to significantly improve performance and minimize false detections. Furthermore, image processing techniques are applied to estimate the extent of the detected defects. Experimental results demonstrate real-time performance with high accuracy across a wide variety of defects, while minimizing false detections. The proposed solution is promising and highly scalable, providing the flexibility to adapt to various production environments and meet the evolving demands of the automotive industry.",
      "pdf_url": "https://arxiv.org/pdf/2512.05579v1",
      "published": "2025-12-05T09:59:10+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.05579v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "CureAgent: A Training-Free Executor-Analyst Framework for Clinical Reasoning",
      "authors": [
        "Ting-Ting Xie",
        "Yixin Zhang"
      ],
      "abstract": "Current clinical agent built on small LLMs, such as TxAgent suffer from a \\textit{Context Utilization Failure}, where models successfully retrieve biomedical evidence due to supervised finetuning but fail to ground their diagnosis in that information. In this work, we propose the Executor-Analyst Framework, a modular architecture that decouples the syntactic precision of tool execution from the semantic robustness of clinical reasoning. By orchestrating specialized TxAgents (Executors) with long-context foundation models (Analysts), we mitigate the reasoning deficits observed in monolithic models. Beyond simple modularity, we demonstrate that a Stratified Ensemble strategy significantly outperforms global pooling by preserving evidentiary diversity, effectively addressing the information bottleneck. Furthermore, our stress tests reveal critical scaling insights: (1) a \\textit{Context-Performance Paradox}, where extending reasoning contexts beyond 12k tokens introduces noise that degrades accuracy; and (2) the \\textit{Curse of Dimensionality} in action spaces, where expanding toolsets necessitates hierarchical retrieval strategies. Crucially, our approach underscores the potential of training-free architectural engineering, achieving state-of-the-art performance on CURE-Bench without the need for expensive end-to-end finetuning. This provides a scalable, agile foundation for the next generation of trustworthy AI-driven therapeutics. Code has been released on https://github.com/June01/CureAgent.",
      "pdf_url": "https://arxiv.org/pdf/2512.05576v1",
      "published": "2025-12-05T09:56:58+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.05576v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "2K-Characters-10K-Stories: A Quality-Gated Stylized Narrative Dataset with Disentangled Control and Sequence Consistency",
      "authors": [
        "Xingxi Yin",
        "Yicheng Li",
        "Gong Yan",
        "Chenglin Li",
        "Jian Zhao",
        "Cong Huang",
        "Yue Deng",
        "Yin Zhang"
      ],
      "abstract": "Sequential identity consistency under precise transient attribute control remains a long-standing challenge in controllable visual storytelling. Existing datasets lack sufficient fidelity and fail to disentangle stable identities from transient attributes, limiting structured control over pose, expression, and scene composition and thus constraining reliable sequential synthesis. To address this gap, we introduce \\textbf{2K-Characters-10K-Stories}, a multi-modal stylized narrative dataset of \\textbf{2{,}000} uniquely stylized characters appearing across \\textbf{10{,}000} illustration stories. It is the first dataset that pairs large-scale unique identities with explicit, decoupled control signals for sequential identity consistency. We introduce a \\textbf{Human-in-the-Loop pipeline (HiL)} that leverages expert-verified character templates and LLM-guided narrative planning to generate highly-aligned structured data. A \\textbf{decoupled control} scheme separates persistent identity from transient attributes -- pose and expression -- while a \\textbf{Quality-Gated loop} integrating MMLM evaluation, Auto-Prompt Tuning, and Local Image Editing enforces pixel-level consistency. Extensive experiments demonstrate that models fine-tuned on our dataset achieves performance comparable to closed-source models in generating visual narratives.",
      "pdf_url": "https://arxiv.org/pdf/2512.05557v1",
      "published": "2025-12-05T09:26:24+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.05557v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Improving Local Fidelity Through Sampling and Modeling Nonlinearity",
      "authors": [
        "Sanjeev Shrestha",
        "Rahul Dubey",
        "Hui Liu"
      ],
      "abstract": "With the increasing complexity of black-box machine learning models and their adoption in high-stakes areas, it is critical to provide explanations for their predictions. Local Interpretable Model-agnostic Explanation (LIME) is a widely used technique that explains the prediction of any classifier by learning an interpretable model locally around the predicted instance. However, it assumes that the local decision boundary is linear and fails to capture the non-linear relationships, leading to incorrect explanations. In this paper, we propose a novel method that can generate high-fidelity explanations. Multivariate adaptive regression splines (MARS) is used to model non-linear local boundaries that effectively captures the underlying behavior of the reference model, thereby enhancing the local fidelity of the explanation. Additionally, we utilize the N-ball sampling technique, which samples directly from the desired distribution instead of reweighting samples as done in LIME, further improving the faithfulness score. We evaluate our method on three UCI datasets across different classifiers and varying kernel widths. Experimental results show that our method yields more faithful explanations compared to baselines, achieving an average reduction of 37% in root mean square error, significantly improving local fidelity.",
      "pdf_url": "https://arxiv.org/pdf/2512.05556v1",
      "published": "2025-12-05T09:26:18+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.05556v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    }
  ]
}