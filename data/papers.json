{
  "last_updated": "2025-08-07T00:58:44.649006",
  "papers": [
    {
      "title": "CompassVerifier: A Unified and Robust Verifier for LLMs Evaluation and Outcome Reward",
      "authors": [
        "Shudong Liu",
        "Hongwei Liu",
        "Junnan Liu",
        "Linchen Xiao",
        "Songyang Gao",
        "Chengqi Lyu",
        "Yuzhe Gu",
        "Wenwei Zhang",
        "Derek F. Wong",
        "Songyang Zhang",
        "Kai Chen"
      ],
      "abstract": "Answer verification is crucial not only for evaluating large language models\n(LLMs) by matching their unstructured outputs against standard answers, but\nalso serves as the reward model to guide LLM optimization. Most evaluation\nframeworks rely on regularized matching or employ general LLMs for answer\nverification, which demands extensive, repetitive customization for regex rules\nor evaluation prompts. Two fundamental limitations persist in current\nmethodologies: 1) the absence of comprehensive benchmarks that systematically\nevaluate verification capabilities across different LLMs; and 2) the nascent\nstage of verifier development, where existing approaches lack both the\nrobustness to handle complex edge cases and the generalizability across\ndifferent domains. In this work, we develop CompassVerifier, an accurate and\nrobust lightweight verifier model for evaluation and outcome reward. It\ndemonstrates multi-domain competency spanning math, knowledge, and diverse\nreasoning tasks, with the capability to process various answer types, including\nmulti-subproblems, formulas, and sequence answers, while effectively\nidentifying abnormal/invalid responses. We introduce VerifierBench benchmark\ncomprising model outputs collected from multiple data sources, augmented\nthrough manual analysis of metaerror patterns to enhance CompassVerifier. We\nanticipate that CompassVerifier and VerifierBench will facilitate answer\nverification, evaluation protocols, and reinforcement learning research. Code\nand dataset are available at https://github.com/open-compass/CompassVerifier.",
      "pdf_url": "http://arxiv.org/pdf/2508.03686v1",
      "published": "2025-08-05T17:55:24+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.03686v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Self-Questioning Language Models",
      "authors": [
        "Lili Chen",
        "Mihir Prabhudesai",
        "Katerina Fragkiadaki",
        "Hao Liu",
        "Deepak Pathak"
      ],
      "abstract": "Can large language models improve without external data -- by generating\ntheir own questions and answers? We hypothesize that a pre-trained language\nmodel can improve its reasoning skills given only a single prompt specifying\nthe topic (e.g., algebra word problems) and asking the model to generate its\nown questions. To do this, we propose Self-Questioning Language Models (SQLM):\nan asymmetric self-play framework where a proposer is given the topic and\ngenerates a question for a solver, who tries to answer it. Both the proposer\nand solver are trained via reinforcement learning. The proposer receives a\nreward if the problem is not too easy or too difficult, and the solver receives\na reward based on majority voting, a proxy for correctness in the absence of\nground-truth answers. For coding, the proposer can instead generate unit tests\nwhich are used for verification. We study this asymmetric self-play framework\non three benchmarks: three-digit multiplication, algebra problems from the\nOMEGA benchmark, and programming problems from Codeforces. By continually\ngenerating more interesting problems and attempting to solve them, language\nmodels can improve on downstream benchmarks without access to any curated\ntraining datasets.",
      "pdf_url": "http://arxiv.org/pdf/2508.03682v2",
      "published": "2025-08-05T17:51:33+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.03682v2",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Agent Lightning: Train ANY AI Agents with Reinforcement Learning",
      "authors": [
        "Xufang Luo",
        "Yuge Zhang",
        "Zhiyuan He",
        "Zilong Wang",
        "Siyun Zhao",
        "Dongsheng Li",
        "Luna K. Qiu",
        "Yuqing Yang"
      ],
      "abstract": "We present Agent Lightning, a flexible and extensible framework that enables\nReinforcement Learning (RL)-based training of Large Language Models (LLMs) for\nany AI agent. Unlike existing methods that tightly couple RL training with\nagent or rely on sequence concatenation with masking, Agent Lightning achieves\ncomplete decoupling between agent execution and training, allowing seamless\nintegration with existing agents developed via diverse ways (e.g., using\nframeworks like LangChain, OpenAI Agents SDK, AutoGen, and building from\nscratch) with almost ZERO code modifications. By formulating agent execution as\nMarkov decision process, we define an unified data interface and propose a\nhierarchical RL algorithm, LightningRL, which contains a credit assignment\nmodule, allowing us to decompose trajectories generated by ANY agents into\ntraining transition. This enables RL to handle complex interaction logic, such\nas multi-agent scenarios and dynamic workflows. For the system design, we\nintroduce a Training-Agent Disaggregation architecture, and brings agent\nobservability frameworks into agent runtime, providing a standardized agent\nfinetuning interface. Experiments across text-to-SQL, retrieval-augmented\ngeneration, and math tool-use tasks demonstrate stable, continuous\nimprovements, showcasing the framework's potential for real-world agent\ntraining and deployment.",
      "pdf_url": "http://arxiv.org/pdf/2508.03680v1",
      "published": "2025-08-05T17:50:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.03680v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Beyond risk: A proto-framework for assessing the societal impact of AI systems",
      "authors": [
        "Willem Fourie"
      ],
      "abstract": "In the discourse on AI regulation, 'responsible AI' is the dominant paradigm,\nwith the focus on mitigating the risks related to AI systems. While this focus\nis important and necessary, it has limited use for a systematic consideration\nof AI's societal impact. This paper proposes a proto-framework for assessing\nthe societal impact of AI systems by operationalising the concept of freedom.\nThis proto-framework is intended as a step towards a fully operationalised\nframework to be used in policymaking contexts. By drawing on Kantian philosophy\nand related contemporary interpretations, freedom is developed as the\ncounterpart to the concept of responsibility. Two dimensions of freedom are\ndeveloped in further detail: freedom as capability and freedom as opportunity.\nThese two dimensions of freedom are then applied in a proto-framework that\nsystematically considers AI's impact on society using the Sustainable\nDevelopment Goals. This proto-framework aims to complement current risk-based\napproaches and thereby offers a first step towards operationalising the concept\nof freedom in AI regulation.",
      "pdf_url": "http://arxiv.org/pdf/2508.03666v2",
      "published": "2025-08-05T17:25:14+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.03666v2",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.ET"
      ]
    },
    {
      "title": "A DbC Inspired Neurosymbolic Layer for Trustworthy Agent Design",
      "authors": [
        "Claudiu Leoveanu-Condrei"
      ],
      "abstract": "Generative models, particularly Large Language Models (LLMs), produce fluent\noutputs yet lack verifiable guarantees. We adapt Design by Contract (DbC) and\ntype-theoretic principles to introduce a contract layer that mediates every LLM\ncall. Contracts stipulate semantic and type requirements on inputs and outputs,\ncoupled with probabilistic remediation to steer generation toward compliance.\nThe layer exposes the dual view of LLMs as semantic parsers and probabilistic\nblack-box components. Contract satisfaction is probabilistic and semantic\nvalidation is operationally defined through programmer-specified conditions on\nwell-typed data structures. More broadly, this work postulates that any two\nagents satisfying the same contracts are \\emph{functionally equivalent} with\nrespect to those contracts.",
      "pdf_url": "http://arxiv.org/pdf/2508.03665v1",
      "published": "2025-08-05T17:24:50+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.03665v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.7; I.2.2; I.1.2; D.1.0"
      ]
    },
    {
      "title": "Forest vs Tree: The $(N, K)$ Trade-off in Reproducible ML Evaluation",
      "authors": [
        "Deepak Pandita",
        "Flip Korn",
        "Chris Welty",
        "Christopher M. Homan"
      ],
      "abstract": "Reproducibility is a cornerstone of scientific validation and of the\nauthority it confers on its results. Reproducibility in machine learning\nevaluations leads to greater trust, confidence, and value. However, the ground\ntruth responses used in machine learning often necessarily come from humans,\namong whom disagreement is prevalent, and surprisingly little research has\nstudied the impact of effectively ignoring disagreement in these responses, as\nis typically the case. One reason for the lack of research is that budgets for\ncollecting human-annotated evaluation data are limited, and obtaining more\nsamples from multiple annotators for each example greatly increases the\nper-item annotation costs. We investigate the trade-off between the number of\nitems ($N$) and the number of responses per item ($K$) needed for reliable\nmachine learning evaluation. We analyze a diverse collection of categorical\ndatasets for which multiple annotations per item exist, and simulated\ndistributions fit to these datasets, to determine the optimal $(N, K)$\nconfiguration, given a fixed budget ($N \\times K$), for collecting evaluation\ndata and reliably comparing the performance of machine learning models. Our\nfindings show, first, that accounting for human disagreement may come with $N\n\\times K$ at no more than 1000 (and often much lower) for every dataset tested\non at least one metric. Moreover, this minimal $N \\times K$ almost always\noccurred for $K > 10$. Furthermore, the nature of the tradeoff between $K$ and\n$N$ -- or if one even existed -- depends on the evaluation metric, with metrics\nthat are more sensitive to the full distribution of responses performing better\nat higher levels of $K$. Our methods can be used to help ML practitioners get\nmore effective test data by finding the optimal metrics and number of items and\nannotations per item to collect to get the most reliability for their budget.",
      "pdf_url": "http://arxiv.org/pdf/2508.03663v1",
      "published": "2025-08-05T17:18:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.03663v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Automated Algorithmic Discovery for Gravitational-Wave Detection Guided by LLM-Informed Evolutionary Monte Carlo Tree Search",
      "authors": [
        "He Wang",
        "Liang Zeng"
      ],
      "abstract": "Computational scientific discovery increasingly relies on algorithms to\nprocess complex data and identify meaningful patterns - yet faces persistent\nchallenges in gravitational-wave signal identification. While existing\nalgorithmic approaches like matched filtering (MF) and deep neural networks\n(DNNs) have achieved partial success, their limitations directly stem from\nfundamental limitations: MF's excessive computational demands arise from its\nreliance on predefined theoretical waveform templates, while DNNs' black-box\narchitectures obscure decision logic and introduce hidden biases. We propose\nEvolutionary Monte Carlo Tree Search (Evo-MCTS), a framework that addresses\nthese limitations through systematic algorithm space exploration guided by\ndomain-aware physical constraints. Our approach combines tree-structured search\nwith evolutionary optimization and large language model heuristics to create\ninterpretable algorithmic solutions. Our Evo-MCTS framework demonstrates\nsubstantial improvements, achieving a 20.2\\% improvement over state-of-the-art\ngravitational wave detection algorithms on the MLGWSC-1 benchmark dataset.\nHigh-performing algorithm variants consistently exceed thresholds. The\nframework generates human-interpretable algorithmic pathways that reveal\ndistinct performance patterns. Beyond performance improvements, our framework\ndiscovers novel algorithmic combinations, thereby establishing a transferable\nmethodology for automated algorithmic discovery across computational science\ndomains.",
      "pdf_url": "http://arxiv.org/pdf/2508.03661v1",
      "published": "2025-08-05T17:18:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.03661v1",
      "categories": [
        "cs.AI",
        "astro-ph.HE",
        "astro-ph.IM",
        "gr-qc"
      ]
    },
    {
      "title": "Probing the Gaps in ChatGPT Live Video Chat for Real-World Assistance for People who are Blind or Visually Impaired",
      "authors": [
        "Ruei-Che Chang",
        "Rosiana Natalie",
        "Wenqian Xu",
        "Jovan Zheng Feng Yap",
        "Anhong Guo"
      ],
      "abstract": "Recent advancements in large multimodal models have provided blind or\nvisually impaired (BVI) individuals with new capabilities to interpret and\nengage with the real world through interactive systems that utilize live video\nfeeds. However, the potential benefits and challenges of such capabilities to\nsupport diverse real-world assistive tasks remain unclear. In this paper, we\npresent findings from an exploratory study with eight BVI participants.\nParticipants used ChatGPT's Advanced Voice with Video, a state-of-the-art live\nvideo AI released in late 2024, in various real-world scenarios, from locating\nobjects to recognizing visual landmarks, across unfamiliar indoor and outdoor\nenvironments. Our findings indicate that current live video AI effectively\nprovides guidance and answers for static visual scenes but falls short in\ndelivering essential live descriptions required in dynamic situations. Despite\ninaccuracies in spatial and distance information, participants leveraged the\nprovided visual information to supplement their mobility strategies. Although\nthe system was perceived as human-like due to high-quality voice interactions,\nassumptions about users' visual abilities, hallucinations, generic responses,\nand a tendency towards sycophancy led to confusion, distrust, and potential\nrisks for BVI users. Based on the results, we discuss implications for\nassistive video AI agents, including incorporating additional sensing\ncapabilities for real-world use, determining appropriate intervention timing\nbeyond turn-taking interactions, and addressing ecological and safety concerns.",
      "pdf_url": "http://arxiv.org/pdf/2508.03651v1",
      "published": "2025-08-05T16:59:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.03651v1",
      "categories": [
        "cs.HC",
        "cs.AI"
      ]
    },
    {
      "title": "Cross-Model Semantics in Representation Learning",
      "authors": [
        "Saleh Nikooroo",
        "Thomas Engel"
      ],
      "abstract": "The internal representations learned by deep networks are often sensitive to\narchitecture-specific choices, raising questions about the stability,\nalignment, and transferability of learned structure across models. In this\npaper, we investigate how structural constraints--such as linear shaping\noperators and corrective paths--affect the compatibility of internal\nrepresentations across different architectures. Building on the insights from\nprior studies on structured transformations and convergence, we develop a\nframework for measuring and analyzing representational alignment across\nnetworks with distinct but related architectural priors. Through a combination\nof theoretical insights, empirical probes, and controlled transfer experiments,\nwe demonstrate that structural regularities induce representational geometry\nthat is more stable under architectural variation. This suggests that certain\nforms of inductive bias not only support generalization within a model, but\nalso improve the interoperability of learned features across models. We\nconclude with a discussion on the implications of representational\ntransferability for model distillation, modular learning, and the principled\ndesign of robust learning systems.",
      "pdf_url": "http://arxiv.org/pdf/2508.03649v1",
      "published": "2025-08-05T16:57:24+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.03649v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "LLMDistill4Ads: Using Cross-Encoders to Distill from LLM Signals for Advertiser Keyphrase Recommendations at eBay",
      "authors": [
        "Soumik Dey",
        "Benjamin Braun",
        "Naveen Ravipati",
        "Hansi Wu",
        "Binbin Li"
      ],
      "abstract": "Sellers at eBay are recommended keyphrases to bid on to enhance the\nperformance of their advertising campaigns. The relevance of these keyphrases\nis crucial in avoiding the overcrowding of search systems with irrelevant items\nand maintaining a positive seller perception. It is essential that keyphrase\nrecommendations align with both seller and Search judgments regarding auctions.\nDue to the difficulty in procuring negative human judgment at scale, employing\nLLM-as-a-judge to mimic seller judgment has been established as the norm in\nseveral studies. This study introduces a novel two-step LLM distillation\nprocess from a LLM-judge used to debias our Embedding Based Retrieval (EBR)\nmodel from the various biases that exist in click-data. We distill from an LLM\nteacher via a cross-encoder assistant into a bi-encoder student using a\nmulti-task training approach, ultimately employing the student bi-encoder to\nretrieve relevant advertiser keyphrases. We show that integrating a knowledge\ndistillation process from LLMs in a multi-task training setup enhances\nbi-encoder performance in retrieving relevant advertiser keyphrases at eBay.",
      "pdf_url": "http://arxiv.org/pdf/2508.03628v1",
      "published": "2025-08-05T16:47:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.03628v1",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "AttZoom: Attention Zoom for Better Visual Features",
      "authors": [
        "Daniel DeAlcala",
        "Aythami Morales",
        "Julian Fierrez",
        "Ruben Tolosana"
      ],
      "abstract": "We present Attention Zoom, a modular and model-agnostic spatial attention\nmechanism designed to improve feature extraction in convolutional neural\nnetworks (CNNs). Unlike traditional attention approaches that require\narchitecture-specific integration, our method introduces a standalone layer\nthat spatially emphasizes high-importance regions in the input. We evaluated\nAttention Zoom on multiple CNN backbones using CIFAR-100 and TinyImageNet,\nshowing consistent improvements in Top-1 and Top-5 classification accuracy.\nVisual analyses using Grad-CAM and spatial warping reveal that our method\nencourages fine-grained and diverse attention patterns. Our results confirm the\neffectiveness and generality of the proposed layer for improving CCNs with\nminimal architectural overhead.",
      "pdf_url": "http://arxiv.org/pdf/2508.03625v1",
      "published": "2025-08-05T16:42:08+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.03625v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Refining Critical Thinking in LLM Code Generation: A Faulty Premise-based Evaluation Framework",
      "authors": [
        "Jialin Li",
        "Jinzhe Li",
        "Gengxu Li",
        "Yi Chang",
        "Yuan Wu"
      ],
      "abstract": "With the advancement of code generation capabilities in large language models\n(LLMs), their reliance on input premises has intensified. When users provide\ninputs containing faulty premises, the probability of code generation\nhallucinations rises significantly, exposing deficiencies in their\nself-scrutiny capabilities. This paper proposes Faulty Premises Bench\n(FPBench), the first code generation evaluation framework targeting faulty\npremises. By systematically constructing three categories of faulty premises\nand integrating multi-dimensional evaluation metrics, it conducts in-depth\nassessments of 15 representative LLMs. The key findings are as follows: (1)\nMost models exhibit poor reasoning abilities and suboptimal code generation\nperformance under faulty premises, heavily relying on explicit prompts for\nerror detection, with limited self-scrutiny capabilities; (2) Faulty premises\ntrigger a point of diminishing returns in resource investment, leading to\nblindly increasing length fails to enhance quality; (3) The three types of\nfaulty premises respectively activate distinct defect patterns in models,\nrevealing a triple dissociation in the cognitive mechanisms of code generation\nmodels. This study not only highlights the urgent need for LLMs to proactively\nverify premises in code generation but also, through the proposed FPBench\nframework and multi-dimensional evaluation system, provides a theoretical\nfoundation and practical pathway for developing reliable, human-centric code\ngeneration models.",
      "pdf_url": "http://arxiv.org/pdf/2508.03622v1",
      "published": "2025-08-05T16:39:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.03622v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Hidden Dynamics of Massive Activations in Transformer Training",
      "authors": [
        "Jorge Gallego-Feliciano",
        "S. Aaron McClendon",
        "Juan Morinelli",
        "Stavros Zervoudakis",
        "Antonios Saravanos"
      ],
      "abstract": "Massive activations are scalar values in transformer hidden states that\nachieve values orders of magnitude larger than typical activations and have\nbeen shown to be critical for model functionality. While prior work has\ncharacterized these phenomena in fully trained models, the temporal dynamics of\ntheir emergence during training remain poorly understood. We present the first\ncomprehensive analysis of massive activation development throughout transformer\ntraining, using the Pythia model family as our testbed. Through systematic\nanalysis of various model sizes across multiple training checkpoints, we\ndemonstrate that massive activation emergence follows predictable mathematical\npatterns that can be accurately modeled using an exponentially-modulated\nlogarithmic function with five key parameters. We develop a machine learning\nframework to predict these mathematical parameters from architectural\nspecifications alone, achieving high accuracy for steady-state behavior and\nmoderate accuracy for emergence timing and magnitude. These findings enable\narchitects to predict and potentially control key aspects of massive activation\nemergence through design choices, with significant implications for model\nstability, training cycle length, interpretability, and optimization. Our\nfindings demonstrate that the emergence of massive activations is governed by\nmodel design and can be anticipated, and potentially controlled, before\ntraining begins.",
      "pdf_url": "http://arxiv.org/pdf/2508.03616v1",
      "published": "2025-08-05T16:29:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.03616v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Goedel-Prover-V2: Scaling Formal Theorem Proving with Scaffolded Data Synthesis and Self-Correction",
      "authors": [
        "Yong Lin",
        "Shange Tang",
        "Bohan Lyu",
        "Ziran Yang",
        "Jui-Hui Chung",
        "Haoyu Zhao",
        "Lai Jiang",
        "Yihan Geng",
        "Jiawei Ge",
        "Jingruo Sun",
        "Jiayun Wu",
        "Jiri Gesi",
        "Ximing Lu",
        "David Acuna",
        "Kaiyu Yang",
        "Hongzhou Lin",
        "Yejin Choi",
        "Danqi Chen",
        "Sanjeev Arora",
        "Chi Jin"
      ],
      "abstract": "We introduce Goedel-Prover-V2, a series of open-source language models that\nset a new state-of-the-art in automated theorem proving. Built on the standard\nexpert iteration and reinforcement learning pipeline, our approach incorporates\nthree key innovations: (1) Scaffolded data synthesis: We generate synthetic\ntasks of increasing difficulty to train the model to master increasingly\ncomplex theorems; (2) Verifier-guided self-correction: We enable the model to\niteratively revise its proofs by leveraging feedback from the Lean compiler;\n(3) Model averaging: We merge model checkpoints to mitigate the decrease in\nmodel output diversity in later stages of training. Our small model,\nGoedel-Prover-V2-8B, reaches 84.6% pass@32 on MiniF2F and outperforms\nDeepSeek-Prover-V2-671B under the same metric, despite being 80X smaller. Our\nflagship model, Goedel-Prover-V2-32B, achieves 88.1% on MiniF2F at pass@32 in\nstandard mode and 90.4% in self-correction mode, outperforming prior SOTA by a\nlarge margin. Additionally, our flagship model solves 86 problems on\nPutnamBench at pass@184, securing the first place among open-source models on\nthe leaderboard, surpassing DeepSeek-Prover-V2-671B's record of solving 47\nproblems by pass@1024 with a significantly smaller model size and compute\nbudget. At the time of its release (July-August 2025), Goedel-Prover-V2\nachieves the strongest overall performance among all open-source theorem\nprovers. It also ranks among the top-performing models--including closed-source\nsystems with publicly reported performance--under a constrained test-time\ncompute budget. Our models, code, and data are released at\nhttps://github.com/Goedel-LM/Goedel-Prover-V2.",
      "pdf_url": "http://arxiv.org/pdf/2508.03613v1",
      "published": "2025-08-05T16:28:22+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.03613v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Block: Balancing Load in LLM Serving with Context, Knowledge and Predictive Scheduling",
      "authors": [
        "Wei Da",
        "Evangelia Kalyvianaki"
      ],
      "abstract": "This paper presents Block, a distributed scheduling framework designed to\noptimize load balancing and auto-provisioning across instances in large\nlanguage model serving frameworks by leveraging contextual information from\nincoming requests. Unlike popular model serving systems that rely on monolithic\nand heuristic task schedulers, Block operates as a fully distributed,\nstateless, and predictive scheduling system to achieve low overhead,\nreliability, and scalability. It leverages the deterministic and predictable\ncharacteristics of LLM inferences, such as host configurations, response\nlengths, and hardware performance, to make scheduling decisions based on\naccurately predicted metrics. Evaluation on a 12 GPUs cluster shows that Block\nsignificantly outperforms heuristic schedulers, boosting serving capacity by up\nto 16.7\\% and reducing P99 tail latency by up to 49.5\\%. These performance\ngains remain consistent across diverse models, workloads and configurations.\nCode and data are open-sourced.",
      "pdf_url": "http://arxiv.org/pdf/2508.03611v1",
      "published": "2025-08-05T16:27:10+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.03611v1",
      "categories": [
        "cs.DC",
        "cs.AI"
      ]
    },
    {
      "title": "MetaScope: Optics-Driven Neural Network for Ultra-Micro Metalens Endoscopy",
      "authors": [
        "Wuyang Li",
        "Wentao Pan",
        "Xiaoyuan Liu",
        "Zhendong Luo",
        "Chenxin Li",
        "Hengyu Liu",
        "Din Ping Tsai",
        "Mu Ku Chen",
        "Yixuan Yuan"
      ],
      "abstract": "Miniaturized endoscopy has advanced accurate visual perception within the\nhuman body. Prevailing research remains limited to conventional cameras\nemploying convex lenses, where the physical constraints with millimetre-scale\nthickness impose serious impediments on the micro-level clinical. Recently,\nwith the emergence of meta-optics, ultra-micro imaging based on metalenses\n(micron-scale) has garnered great attention, serving as a promising solution.\nHowever, due to the physical difference of metalens, there is a large gap in\ndata acquisition and algorithm research. In light of this, we aim to bridge\nthis unexplored gap, advancing the novel metalens endoscopy. First, we\nestablish datasets for metalens endoscopy and conduct preliminary optical\nsimulation, identifying two derived optical issues that physically adhere to\nstrong optical priors. Second, we propose MetaScope, a novel optics-driven\nneural network tailored for metalens endoscopy driven by physical optics.\nMetaScope comprises two novel designs: Optics-informed Intensity Adjustment\n(OIA), rectifying intensity decay by learning optical embeddings, and\nOptics-informed Chromatic Correction (OCC), mitigating chromatic aberration by\nlearning spatial deformations informed by learned Point Spread Function (PSF)\ndistributions. To enhance joint learning, we further deploy a gradient-guided\ndistillation to transfer knowledge from the foundational model adaptively.\nExtensive experiments demonstrate that MetaScope not only outperforms\nstate-of-the-art methods in both metalens segmentation and restoration but also\nachieves impressive generalized ability in real biomedical scenes.",
      "pdf_url": "http://arxiv.org/pdf/2508.03596v1",
      "published": "2025-08-05T16:01:00+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.03596v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "DeepFaith: A Domain-Free and Model-Agnostic Unified Framework for Highly Faithful Explanations",
      "authors": [
        "Yuhan Guo",
        "Lizhong Ding",
        "Shihan Jia",
        "Yanyu Ren",
        "Pengqi Li",
        "Jiarun Fu",
        "Changsheng Li",
        "Ye yuan",
        "Guoren Wang"
      ],
      "abstract": "Explainable AI (XAI) builds trust in complex systems through model\nattribution methods that reveal the decision rationale. However, due to the\nabsence of a unified optimal explanation, existing XAI methods lack a ground\ntruth for objective evaluation and optimization. To address this issue, we\npropose Deep architecture-based Faith explainer (DeepFaith), a domain-free and\nmodel-agnostic unified explanation framework under the lens of faithfulness. By\nestablishing a unified formulation for multiple widely used and well-validated\nfaithfulness metrics, we derive an optimal explanation objective whose solution\nsimultaneously achieves optimal faithfulness across these metrics, thereby\nproviding a ground truth from a theoretical perspective. We design an explainer\nlearning framework that leverages multiple existing explanation methods,\napplies deduplicating and filtering to construct high-quality supervised\nexplanation signals, and optimizes both pattern consistency loss and local\ncorrelation to train a faithful explainer. Once trained, DeepFaith can generate\nhighly faithful explanations through a single forward pass without accessing\nthe model being explained. On 12 diverse explanation tasks spanning 6 models\nand 6 datasets, DeepFaith achieves the highest overall faithfulness across 10\nmetrics compared to all baseline methods, highlighting its effectiveness and\ncross-domain generalizability.",
      "pdf_url": "http://arxiv.org/pdf/2508.03586v1",
      "published": "2025-08-05T15:53:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.03586v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Decoding and Engineering the Phytobiome Communication for Smart Agriculture",
      "authors": [
        "Fatih Gulec",
        "Hamdan Awan",
        "Nigel Wallbridge",
        "Andrew W. Eckford"
      ],
      "abstract": "Smart agriculture applications, integrating technologies like the Internet of\nThings and machine learning/artificial intelligence (ML/AI) into agriculture,\nhold promise to address modern challenges of rising food demand, environmental\npollution, and water scarcity. Alongside the concept of the phytobiome, which\ndefines the area including the plant, its environment, and associated\norganisms, and the recent emergence of molecular communication (MC), there\nexists an important opportunity to advance agricultural science and practice\nusing communication theory. In this article, we motivate to use the\ncommunication engineering perspective for developing a holistic understanding\nof the phytobiome communication and bridge the gap between the phytobiome\ncommunication and smart agriculture. Firstly, an overview of phytobiome\ncommunication via molecular and electrophysiological signals is presented and a\nmulti-scale framework modeling the phytobiome as a communication network is\nconceptualized. Then, how this framework is used to model electrophysiological\nsignals is demonstrated with plant experiments. Furthermore, possible smart\nagriculture applications, such as smart irrigation and targeted delivery of\nagrochemicals, through engineering the phytobiome communication are proposed.\nThese applications merge ML/AI methods with the Internet of Bio-Nano-Things\nenabled by MC and pave the way towards more efficient, sustainable, and\neco-friendly agricultural production. Finally, the implementation challenges,\nopen research issues, and industrial outlook for these applications are\ndiscussed.",
      "pdf_url": "http://arxiv.org/pdf/2508.03584v1",
      "published": "2025-08-05T15:50:19+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.03584v1",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.ET",
        "cs.NI",
        "q-bio.MN"
      ]
    },
    {
      "title": "Supervised Dynamic Dimension Reduction with Deep Neural Network",
      "authors": [
        "Zhanye Luo",
        "Yuefeng Han",
        "Xiufan Yu"
      ],
      "abstract": "This paper studies the problem of dimension reduction, tailored to improving\ntime series forecasting with high-dimensional predictors. We propose a novel\nSupervised Deep Dynamic Principal component analysis (SDDP) framework that\nincorporates the target variable and lagged observations into the factor\nextraction process. Assisted by a temporal neural network, we construct\ntarget-aware predictors by scaling the original predictors in a supervised\nmanner, with larger weights assigned to predictors with stronger forecasting\npower. A principal component analysis is then performed on the target-aware\npredictors to extract the estimated SDDP factors. This supervised factor\nextraction not only improves predictive accuracy in the downstream forecasting\ntask but also yields more interpretable and target-specific latent factors.\nBuilding upon SDDP, we propose a factor-augmented nonlinear dynamic forecasting\nmodel that unifies a broad family of factor-model-based forecasting approaches.\nTo further demonstrate the broader applicability of SDDP, we extend our studies\nto a more challenging scenario when the predictors are only partially\nobservable. We validate the empirical performance of the proposed method on\nseveral real-world public datasets. The results show that our algorithm\nachieves notable improvements in forecasting accuracy compared to\nstate-of-the-art methods.",
      "pdf_url": "http://arxiv.org/pdf/2508.03546v2",
      "published": "2025-08-05T15:15:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.03546v2",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "EmoSteer-TTS: Fine-Grained and Training-Free Emotion-Controllable Text-to-Speech via Activation Steering",
      "authors": [
        "Tianxin Xie",
        "Shan Yang",
        "Chenxing Li",
        "Dong Yu",
        "Li Liu"
      ],
      "abstract": "Text-to-speech (TTS) has shown great progress in recent years. However, most\nexisting TTS systems offer only coarse and rigid emotion control, typically via\ndiscrete emotion labels or a carefully crafted and detailed emotional text\nprompt, making fine-grained emotion manipulation either inaccessible or\nunstable. These models also require extensive, high-quality datasets for\ntraining. To address these limitations, we propose EmoSteer-TTS, a novel\ntraining-free approach, to achieve fine-grained speech emotion control\n(conversion, interpolation, erasure) by activation steering. We first\nempirically observe that modifying a subset of the internal activations within\na flow matching-based TTS model can effectively alter the emotional tone of\nsynthesized speech. Building on this insight, we then develop a training-free\nand efficient algorithm, including activation extraction, emotional token\nsearching, and inference-time steering, which can be seamlessly integrated into\na wide range of pretrained models (e.g., F5-TTS, CosyVoice2, and E2-TTS). In\naddition, to derive effective steering vectors, we construct a curated\nemotional speech dataset with diverse speakers. Extensive experiments\ndemonstrate that EmoSteer-TTS enables fine-grained, interpretable, and\ncontinuous control over speech emotion, outperforming the state-of-the-art\n(SOTA). To the best of our knowledge, this is the first method that achieves\ntraining-free and continuous fine-grained emotion control in TTS.",
      "pdf_url": "http://arxiv.org/pdf/2508.03543v2",
      "published": "2025-08-05T15:12:49+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.03543v2",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ]
    },
    {
      "title": "Retinal Lipidomics Associations as Candidate Biomarkers for Cardiovascular Health",
      "authors": [
        "Inamullah",
        "Imran Razzak",
        "Shoaib Jameel"
      ],
      "abstract": "Retinal microvascular imaging is increasingly recognised as a non invasive\nmethod for evaluating systemic vascular and metabolic health. However, the\nassociation between lipidomics and retinal vasculature remains inadequate. This\nstudy investigates the relationships between serum lipid subclasses, free fatty\nacids (FA), diacylglycerols (DAG), triacylglycerols (TAG), and cholesteryl\nesters (CE), and retinal microvascular characteristics in a large\npopulation-based cohort. Using Spearman correlation analysis, we examined the\ninterconnection between lipid subclasses and ten retinal microvascular traits,\napplying the Benjamini-Hochberg false discovery rate (BH-FDR) to adjust for\nstatistical significance.\n  Results indicated that FA were linked to retinal vessel twistiness, while CE\ncorrelated with the average widths of arteries and veins. Conversely, DAG and\nTAG showed negative correlations with the width and complexity of arterioles\nand venules. These findings suggest that retinal vascular architecture reflects\ndistinct circulating lipid profiles, supporting its role as a non-invasive\nmarker of systemic metabolic health. This study is the first to integrate deep\nlearning (DL)derived retinal traits with lipidomic subclasses in a healthy\ncohort, thereby providing insights into microvascular structural changes\nindependent of disease status or treatment effects.",
      "pdf_url": "http://arxiv.org/pdf/2508.03538v1",
      "published": "2025-08-05T15:07:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.03538v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "MoKA: Mixture of Kronecker Adapters",
      "authors": [
        "Mohammadreza Sadeghi",
        "Mahsa Ghazvini Nejad",
        "MirHamed Jafarzadeh Asl",
        "Yu Gu",
        "Yuanhao Yu",
        "Masoud Asgharian",
        "Vahid Partovi Nia"
      ],
      "abstract": "Parameter-efficient fine-tuning (PEFT) is essential for reducing the\ncomputational overhead of large language models (LLMs). Low-rank family\nadapters are commonly used to control the parameter size efficiently while\nmaintaining the generative power of LLMs. However, their limited expressiveness\ndue to the rank constraint often restricts their performance on complex tasks.\nWe propose Mixture of Kronecker Adapters (MoKA), a new generation of Kronecker\nadapters that addresses this limitation by modeling weight updates as a mixture\nof Kronecker products. Our proposed adapter leverages a gating mechanism that\nmeasures the importance of each Kronecker factor, enabling more expressive\nadaptation. Moreover, MoKA enables a rank flexibility that provides a better\ntrade-off between parameter efficiency and accuracy. To ensure hardware\nefficiency, we reformulate Kronecker computations using standard matrix\noperations, allowing seamless deployment on GPU-optimized hardware. We conduct\nextensive experiments on instruction-tuning and commonsense reasoning tasks\nusing low-bit quantized versions of LLaMA2-7B and LLaMA3-8B models. MoKA not\nonly outperforms PEFT baselines, but also reduces the number of trainable\nparameters up to 27x, achieving state-of-the-art trade-offs between performance\nand parameter efficiency.",
      "pdf_url": "http://arxiv.org/pdf/2508.03527v1",
      "published": "2025-08-05T14:58:14+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.03527v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Error Detection and Correction for Interpretable Mathematics in Large Language Models",
      "authors": [
        "Yijin Yang",
        "Cristina Cornelio",
        "Mario Leiva",
        "Paulo Shakarian"
      ],
      "abstract": "Recent large language models (LLMs) have demonstrated the ability to perform\nexplicit multi-step reasoning such as chain-of-thought prompting. However,\ntheir intermediate steps often contain errors that can propagate leading to\ninaccurate final predictions. Additionally, LLMs still struggle with\nhallucinations and often fail to adhere to prescribed output formats, which is\nparticularly problematic for tasks like generating mathematical expressions or\nsource code. This work introduces EDCIM (Error Detection and Correction for\nInterpretable Mathematics), a method for detecting and correcting these errors\nin interpretable mathematics tasks, where the model must generate the exact\nfunctional form that explicitly solve the problem (expressed in natural\nlanguage) rather than a black-box solution. EDCIM uses LLMs to generate a\nsystem of equations for a given problem, followed by a symbolic error-detection\nframework that identifies errors and provides targeted feedback for LLM-based\ncorrection. To optimize efficiency, EDCIM integrates lightweight, open-source\nLLMs with more powerful proprietary models, balancing cost and accuracy. This\nbalance is controlled by a single hyperparameter, allowing users to control the\ntrade-off based on their cost and accuracy requirements. Experimental results\nacross different datasets show that EDCIM significantly reduces both\ncomputational and financial costs, while maintaining, and even improving,\nprediction accuracy when the balance is properly configured.",
      "pdf_url": "http://arxiv.org/pdf/2508.03500v1",
      "published": "2025-08-05T14:30:35+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.03500v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "CF-RAG: A Dataset and Method for Carbon Footprint QA Using Retrieval-Augmented Generation",
      "authors": [
        "Kaiwen Zhao",
        "Bharathan Balaji",
        "Stephen Lee"
      ],
      "abstract": "Product sustainability reports provide valuable insights into the\nenvironmental impacts of a product and are often distributed in PDF format.\nThese reports often include a combination of tables and text, which complicates\ntheir analysis. The lack of standardization and the variability in reporting\nformats further exacerbate the difficulty of extracting and interpreting\nrelevant information from large volumes of documents. In this paper, we tackle\nthe challenge of answering questions related to carbon footprints within\nsustainability reports available in PDF format. Unlike previous approaches, our\nfocus is on addressing the difficulties posed by the unstructured and\ninconsistent nature of text extracted from PDF parsing. To facilitate this\nanalysis, we introduce CarbonPDF-QA, an open-source dataset containing\nquestion-answer pairs for 1735 product report documents, along with\nhuman-annotated answers. Our analysis shows that GPT-4o struggles to answer\nquestions with data inconsistencies. To address this limitation, we propose\nCarbonPDF, an LLM-based technique specifically designed to answer carbon\nfootprint questions on such datasets. We develop CarbonPDF by fine-tuning Llama\n3 with our training data. Our results show that our technique outperforms\ncurrent state-of-the-art techniques, including question-answering (QA) systems\nfinetuned on table and text data.",
      "pdf_url": "http://arxiv.org/pdf/2508.03489v1",
      "published": "2025-08-05T14:20:10+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.03489v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "VQA support to Arabic Language Learning Educational Tool",
      "authors": [
        "Khaled Bachir Delassi",
        "Lakhdar Zeggane",
        "Hadda Cherroun",
        "Abdelhamid Haouhat",
        "Kaoutar Bouzouad"
      ],
      "abstract": "We address the problem of scarcity of educational Arabic Language Learning\ntools that advocate modern pedagogical models such as active learning which\nensures language proficiency. In fact, we investigate the design and evaluation\nof an AI-powered educational tool designed to enhance Arabic language learning\nfor non-native speakers with beginner-to-intermediate proficiency level. The\ntool leverages advanced AI models to generate interactive visual quizzes,\ndeploying Visual Question Answering as the primary activity. Adopting a\nconstructivist learning approach, the system encourages active learning through\nreal-life visual quizzes, and image-based questions that focus on improving\nvocabulary, grammar, and comprehension. The system integrates Vision-Language\nPretraining models to generate contextually relevant image description from\nwhich Large Language Model generate assignments based on customized Arabic\nlanguage Learning quizzes thanks to prompting.\n  The effectiveness of the tool is evaluated through a manual annotated\nbenchmark consisting of 1266 real-life visual quizzes, with human participants\nproviding feedback. The results show a suitable accuracy rates, validating the\ntool's potential to bridge the gap in Arabic language education and\nhighlighting the tool's promise as a reliable, AI-powered resource for Arabic\nlearners, offering personalized and interactive learning experiences.",
      "pdf_url": "http://arxiv.org/pdf/2508.03488v1",
      "published": "2025-08-05T14:18:25+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.03488v1",
      "categories": [
        "cs.AI",
        "cs.SE"
      ]
    },
    {
      "title": "BitsAI-Fix: LLM-Driven Approach for Automated Lint Error Resolution in Practice",
      "authors": [
        "Yuanpeng Li",
        "Qi Long",
        "Zhiyuan Yao",
        "Jian Xu",
        "Lintao Xie",
        "Xu He",
        "Lu Geng",
        "Xin Han",
        "Yueyan Chen",
        "Wenbo Duan"
      ],
      "abstract": "As enterprise codebases continue to grow in scale and complexity, the volume\nof lint errors far exceeds engineers' manual remediation capacity, leading to\ncontinuous accumulation of technical debt and hindered development efficiency.\nThis paper presents BitsAI-Fix, an automated lint error remediation workflow\nbased on Large Language Models (LLMs), designed to address this critical\nchallenge in industrial-scale environments. BitsAI-Fix employs tree-sitter for\ncontext expansion and generates search-and-replace format patches through\nspecially trained LLMs, followed by lint scan re-verification to output final\nremediation results. Additionally, our approach introduces an innovative\nprogressive reinforcement learning (RL) training strategy that can\nautomatically acquire verifiable training data during the project cold-start\nphase and continuously iterate the model by collecting online samples through\nfeedback after system deployment. Furthermore, we designed a targeted\nrule-based reward mechanism that combines format rewards and correctness\nrewards while penalizing redundant modifications. We also propose a \"code diff\nmatching\" methodology to continuously track online effectiveness. In production\ndeployment at ByteDance, our solution has supported over 5,000 engineers,\nresolved more than 12,000 static analysis issues, achieved approximately 85%\nremediation accuracy, with around 1,000 weekly active adopters. This work\ndemonstrates the practical feasibility of LLM-based code remediation solutions\nin enterprise environments and serves as a reference for automated code fix in\nlarge-scale industrial scenarios.",
      "pdf_url": "http://arxiv.org/pdf/2508.03487v1",
      "published": "2025-08-05T14:17:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.03487v1",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Semantic-aware Graph-guided Behavior Sequences Generation with Large Language Models for Smart Homes",
      "authors": [
        "Zhiyao Xu",
        "Dan Zhao",
        "Qingsong Zou",
        "Qing Li",
        "Yong Jiang",
        "Yuhang Wang",
        "Jingyu Xiao"
      ],
      "abstract": "As smart homes become increasingly prevalent, intelligent models are widely\nused for tasks such as anomaly detection and behavior prediction. These models\nare typically trained on static datasets, making them brittle to behavioral\ndrift caused by seasonal changes, lifestyle shifts, or evolving routines.\nHowever, collecting new behavior data for retraining is often impractical due\nto its slow pace, high cost, and privacy concerns. In this paper, we propose\nSmartGen, an LLM-based framework that synthesizes context-aware user behavior\ndata to support continual adaptation of downstream smart home models. SmartGen\nconsists of four key components. First, we design a Time and Semantic-aware\nSplit module to divide long behavior sequences into manageable, semantically\ncoherent subsequences under dual time-span constraints. Second, we propose\nSemantic-aware Sequence Compression to reduce input length while preserving\nrepresentative semantics by clustering behavior mapping in latent space. Third,\nwe introduce Graph-guided Sequence Synthesis, which constructs a behavior\nrelationship graph and encodes frequent transitions into prompts, guiding the\nLLM to generate data aligned with contextual changes while retaining core\nbehavior patterns. Finally, we design a Two-stage Outlier Filter to identify\nand remove implausible or semantically inconsistent outputs, aiming to improve\nthe factual coherence and behavioral validity of the generated sequences.\nExperiments on three real-world datasets demonstrate that SmartGen\nsignificantly enhances model performance on anomaly detection and behavior\nprediction tasks under behavioral drift, with anomaly detection improving by\n85.43% and behavior prediction by 70.51% on average. The code is available at\nhttps://github.com/horizonsinzqs/SmartGen.",
      "pdf_url": "http://arxiv.org/pdf/2508.03484v1",
      "published": "2025-08-05T14:16:10+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.03484v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "When Cars Have Stereotypes: Auditing Demographic Bias in Objects from Text-to-Image Models",
      "authors": [
        "Dasol Choi Jihwan Lee",
        "Minjae Lee",
        "Minsuk Kahng"
      ],
      "abstract": "While prior research on text-to-image generation has predominantly focused on\nbiases in human depictions, we investigate a more subtle yet pervasive\nphenomenon: demographic bias in generated objects (e.g., cars). We introduce\nSODA (Stereotyped Object Diagnostic Audit), a novel framework for\nsystematically measuring such biases. Our approach compares visual attributes\nof objects generated with demographic cues (e.g., \"for young people'') to those\nfrom neutral prompts, across 2,700 images produced by three state-of-the-art\nmodels (GPT Image-1, Imagen 4, and Stable Diffusion) in five object categories.\nThrough a comprehensive analysis, we uncover strong associations between\nspecific demographic groups and visual attributes, such as recurring color\npatterns prompted by gender or ethnicity cues. These patterns reflect and\nreinforce not only well-known stereotypes but also more subtle and unintuitive\nbiases. We also observe that some models generate less diverse outputs, which\nin turn amplifies the visual disparities compared to neutral prompts. Our\nproposed auditing framework offers a practical approach for testing, revealing\nhow stereotypes still remain embedded in today's generative models. We see this\nas an essential step toward more systematic and responsible AI development.",
      "pdf_url": "http://arxiv.org/pdf/2508.03483v1",
      "published": "2025-08-05T14:15:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.03483v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Draw Your Mind: Personalized Generation via Condition-Level Modeling in Text-to-Image Diffusion Models",
      "authors": [
        "Hyungjin Kim",
        "Seokho Ahn",
        "Young-Duk Seo"
      ],
      "abstract": "Personalized generation in T2I diffusion models aims to naturally incorporate\nindividual user preferences into the generation process with minimal user\nintervention. However, existing studies primarily rely on prompt-level modeling\nwith large-scale models, often leading to inaccurate personalization due to the\nlimited input token capacity of T2I diffusion models. To address these\nlimitations, we propose DrUM, a novel method that integrates user profiling\nwith a transformer-based adapter to enable personalized generation through\ncondition-level modeling in the latent space. DrUM demonstrates strong\nperformance on large-scale datasets and seamlessly integrates with open-source\ntext encoders, making it compatible with widely used foundation T2I models\nwithout requiring additional fine-tuning.",
      "pdf_url": "http://arxiv.org/pdf/2508.03481v1",
      "published": "2025-08-05T14:14:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.03481v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "VideoGuard: Protecting Video Content from Unauthorized Editing",
      "authors": [
        "Junjie Cao",
        "Kaizhou Li",
        "Xinchun Yu",
        "Hongxiang Li",
        "Xiaoping Zhang"
      ],
      "abstract": "With the rapid development of generative technology, current generative\nmodels can generate high-fidelity digital content and edit it in a controlled\nmanner. However, there is a risk that malicious individuals might misuse these\ncapabilities for misleading activities. Although existing research has\nattempted to shield photographic images from being manipulated by generative\nmodels, there remains a significant disparity in the protection offered to\nvideo content editing. To bridge the gap, we propose a protection method named\nVideoGuard, which can effectively protect videos from unauthorized malicious\nediting. This protection is achieved through the subtle introduction of nearly\nunnoticeable perturbations that interfere with the functioning of the intended\ngenerative diffusion models. Due to the redundancy between video frames, and\ninter-frame attention mechanism in video diffusion models, simply applying\nimage-based protection methods separately to every video frame can not shield\nvideo from unauthorized editing. To tackle the above challenge, we adopt joint\nframe optimization, treating all video frames as an optimization entity.\nFurthermore, we extract video motion information and fuse it into optimization\nobjectives. Thus, these alterations can effectively force the models to produce\noutputs that are implausible and inconsistent. We provide a pipeline to\noptimize this perturbation. Finally, we use both objective metrics and\nsubjective metrics to demonstrate the efficacy of our method, and the results\nshow that the protection performance of VideoGuard is superior to all the\nbaseline methods.",
      "pdf_url": "http://arxiv.org/pdf/2508.03480v1",
      "published": "2025-08-05T14:13:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.03480v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "fact check AI at SemEval-2025 Task 7: Multilingual and Crosslingual Fact-checked Claim Retrieval",
      "authors": [
        "Pranshu Rastogi"
      ],
      "abstract": "SemEval-2025 Task 7: Multilingual and Crosslingual Fact-Checked Claim\nRetrieval is approached as a Learning-to-Rank task using a bi-encoder model\nfine-tuned from a pre-trained transformer optimized for sentence similarity.\nTraining used both the source languages and their English translations for\nmultilingual retrieval and only English translations for cross-lingual\nretrieval. Using lightweight models with fewer than 500M parameters and\ntraining on Kaggle T4 GPUs, the method achieved 92% Success@10 in multilingual\nand 80% Success@10 in 5th in crosslingual and 10th in multilingual tracks.",
      "pdf_url": "http://arxiv.org/pdf/2508.03475v1",
      "published": "2025-08-05T14:10:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.03475v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ]
    },
    {
      "title": "Toward a Graph-Theoretic Model of Belief: Confidence, Credibility, and Structural Coherence",
      "authors": [
        "Saleh Nikooroo"
      ],
      "abstract": "Belief systems are often treated as globally consistent sets of propositions\nor as scalar-valued probability distributions. Such representations tend to\nobscure the internal structure of belief, conflate external credibility with\ninternal coherence, and preclude the modeling of fragmented or contradictory\nepistemic states. This paper introduces a minimal formalism for belief systems\nas directed, weighted graphs. In this framework, nodes represent individual\nbeliefs, edges encode epistemic relationships (e.g., support or contradiction),\nand two distinct functions assign each belief a credibility (reflecting source\ntrust) and a confidence (derived from internal structural support). Unlike\nclassical probabilistic models, our approach does not assume prior coherence or\nrequire belief updating. Unlike logical and argumentation-based frameworks, it\nsupports fine-grained structural representation without committing to binary\njustification status or deductive closure. The model is purely static and\ndeliberately excludes inference or revision procedures. Its aim is to provide a\nfoundational substrate for analyzing the internal organization of belief\nsystems, including coherence conditions, epistemic tensions, and\nrepresentational limits. By distinguishing belief structure from belief\nstrength, this formalism enables a richer classification of epistemic states\nthan existing probabilistic, logical, or argumentation-based approaches.",
      "pdf_url": "http://arxiv.org/pdf/2508.03465v1",
      "published": "2025-08-05T14:03:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.03465v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "SonicMaster: Towards Controllable All-in-One Music Restoration and Mastering",
      "authors": [
        "Jan Melechovsky",
        "Ambuj Mehrish",
        "Dorien Herremans"
      ],
      "abstract": "Music recordings often suffer from audio quality issues such as excessive\nreverberation, distortion, clipping, tonal imbalances, and a narrowed stereo\nimage, especially when created in non-professional settings without specialized\nequipment or expertise. These problems are typically corrected using separate\nspecialized tools and manual adjustments. In this paper, we introduce\nSonicMaster, the first unified generative model for music restoration and\nmastering that addresses a broad spectrum of audio artifacts with text-based\ncontrol. SonicMaster is conditioned on natural language instructions to apply\ntargeted enhancements, or can operate in an automatic mode for general\nrestoration. To train this model, we construct the SonicMaster dataset, a large\ndataset of paired degraded and high-quality tracks by simulating common\ndegradation types with nineteen degradation functions belonging to five\nenhancements groups: equalization, dynamics, reverb, amplitude, and stereo. Our\napproach leverages a flow-matching generative training paradigm to learn an\naudio transformation that maps degraded inputs to their cleaned, mastered\nversions guided by text prompts. Objective audio quality metrics demonstrate\nthat SonicMaster significantly improves sound quality across all artifact\ncategories. Furthermore, subjective listening tests confirm that listeners\nprefer SonicMaster's enhanced outputs over the original degraded audio,\nhighlighting the effectiveness of our unified approach.",
      "pdf_url": "http://arxiv.org/pdf/2508.03448v1",
      "published": "2025-08-05T13:49:04+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.03448v1",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.MM",
        "eess.AS"
      ]
    },
    {
      "title": "LLMs Have a Heart of Stone: Demystifying the Soft Thinking Ability of Large Reasoning Models",
      "authors": [
        "Chnhung Wu",
        "Jinliang Lu",
        "Zixuan Ren",
        "Gangqiang Hu",
        "Zhi Wu",
        "Dai Dai",
        "Hua Wu"
      ],
      "abstract": "Human cognition naturally engages with abstract and fluid concepts, whereas\nexisting reasoning models often rely on generating discrete tokens, potentially\nconstraining their expressive capabilities. Recent advancements aim to address\nthis limitation by enabling large language models (LLMs) to generate soft,\nabstract tokens, thus facilitating reasoning within a continuous concept space.\nThis paper explores the `Soft Thinking' capabilities of various LLMs by\nexamining the models' internal behavior using a suite of probing techniques.\nContrary to the common belief that Soft Thinking enables the simultaneous\nexploration of diverse reasoning paths, our findings reveal that LLMs\npredominantly rely on the most influential component of the soft inputs during\nsubsequent decoding steps. This reliance hinders the exploration of different\nreasoning paths and reduces vanilla Soft Thinking to a form of greedy decoding,\nobscuring the advantage of transmitting more information through Soft Tokens.\nTo tackle this issue, we explore sampling strategies to introduce\n\\emph{randomness}, employing methods such as Dirichlet resampling and the\nGumbel-Softmax trick. Our experiments demonstrate that incorporating randomness\ncan alleviate the limitations of vanilla approaches and unleash the potential\nof Soft Thinking. Notably, the Gumbel-Softmax trick provides adequate\nrandomness with controlled smoothness, resulting in superior performance across\neight reasoning benchmarks.",
      "pdf_url": "http://arxiv.org/pdf/2508.03440v2",
      "published": "2025-08-05T13:38:33+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.03440v2",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Data Overdose? Time for a Quadruple Shot: Knowledge Graph Construction using Enhanced Triple Extraction",
      "authors": [
        "Taine J. Elliott",
        "Stephen P. Levitt",
        "Ken Nixon",
        "Martin Bekker"
      ],
      "abstract": "The rapid expansion of publicly-available medical data presents a challenge\nfor clinicians and researchers alike, increasing the gap between the volume of\nscientific literature and its applications. The steady growth of studies and\nfindings overwhelms medical professionals at large, hindering their ability to\nsystematically review and understand the latest knowledge. This paper presents\nan approach to information extraction and automatic knowledge graph (KG)\ngeneration to identify and connect biomedical knowledge. Through a pipeline of\nlarge language model (LLM) agents, the system decomposes 44 PubMed abstracts\ninto semantically meaningful proposition sentences and extracts KG triples from\nthese sentences. The triples are enhanced using a combination of open domain\nand ontology-based information extraction methodologies to incorporate\nontological categories. On top of this, a context variable is included during\nextraction to allow the triple to stand on its own - thereby becoming\n`quadruples'. The extraction accuracy of the LLM is validated by comparing\nnatural language sentences generated from the enhanced triples to the original\npropositions, achieving an average cosine similarity of 0.874. The similarity\nfor generated sentences of enhanced triples were compared with generated\nsentences of ordinary triples showing an increase as a result of the context\nvariable. Furthermore, this research explores the ability for LLMs to infer new\nrelationships and connect clusters in the knowledge base of the knowledge\ngraph. This approach leads the way to provide medical practitioners with a\ncentralised, updated in real-time, and sustainable knowledge source, and may be\nthe foundation of similar gains in a wide variety of fields.",
      "pdf_url": "http://arxiv.org/pdf/2508.03438v1",
      "published": "2025-08-05T13:30:41+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.03438v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Spatial Imputation Drives Cross-Domain Alignment for EEG Classification",
      "authors": [
        "Hongjun Liu",
        "Chao Yao",
        "Yalan Zhang",
        "Xiaokun wang",
        "Xiaojuan Ban"
      ],
      "abstract": "Electroencephalogram (EEG) signal classification faces significant challenges\ndue to data distribution shifts caused by heterogeneous electrode\nconfigurations, acquisition protocols, and hardware discrepancies across\ndomains. This paper introduces IMAC, a novel channel-dependent mask and\nimputation self-supervised framework that formulates the alignment of\ncross-domain EEG data shifts as a spatial time series imputation task. To\naddress heterogeneous electrode configurations in cross-domain scenarios, IMAC\nfirst standardizes different electrode layouts using a 3D-to-2D positional\nunification mapping strategy, establishing unified spatial representations.\nUnlike previous mask-based self-supervised representation learning methods,\nIMAC introduces spatio-temporal signal alignment. This involves constructing a\nchannel-dependent mask and reconstruction task framed as a low-to-high\nresolution EEG spatial imputation problem. Consequently, this approach\nsimulates cross-domain variations such as channel omissions and temporal\ninstabilities, thus enabling the model to leverage the proposed imputer for\nrobust signal alignment during inference. Furthermore, IMAC incorporates a\ndisentangled structure that separately models the temporal and spatial\ninformation of the EEG signals separately, reducing computational complexity\nwhile enhancing flexibility and adaptability. Comprehensive evaluations across\n10 publicly available EEG datasets demonstrate IMAC's superior performance,\nachieving state-of-the-art classification accuracy in both cross-subject and\ncross-center validation scenarios. Notably, IMAC shows strong robustness under\nboth simulated and real-world distribution shifts, surpassing baseline methods\nby up to $35$\\% in integrity scores while maintaining consistent classification\naccuracy.",
      "pdf_url": "http://arxiv.org/pdf/2508.03437v1",
      "published": "2025-08-05T13:28:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.03437v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "62M10",
        "I.5.1; J.3"
      ]
    },
    {
      "title": "The Science Fiction Science Method",
      "authors": [
        "Iyad Rahwan",
        "Azim Shariff",
        "Jean-Franois Bonnefon"
      ],
      "abstract": "Predicting the social and behavioral impact of future technologies, before\nthey are achieved, would allow us to guide their development and regulation\nbefore these impacts get entrenched. Traditionally, this prediction has relied\non qualitative, narrative methods. Here we describe a method which uses\nexperimental methods to simulate future technologies, and collect quantitative\nmeasures of the attitudes and behaviors of participants assigned to controlled\nvariations of the future. We call this method 'science fiction science'. We\nsuggest that the reason why this method has not been fully embraced yet,\ndespite its potential benefits, is that experimental scientists may be\nreluctant to engage in work facing such serious validity threats as science\nfiction science. To address these threats, we consider possible constraints on\nthe kind of technology that science fiction science may study, as well as the\nunconventional, immersive methods that science fiction science may require. We\nseek to provide perspective on the reasons why this method has been\nmarginalized for so long, what benefits it would bring if it could be built on\nstrong yet unusual methods, and how we can normalize these methods to help the\ndiverse community of science fiction scientists to engage in a virtuous cycle\nof validity improvement.",
      "pdf_url": "http://arxiv.org/pdf/2508.03430v1",
      "published": "2025-08-05T13:20:12+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.03430v1",
      "categories": [
        "cs.HC",
        "cs.AI"
      ]
    },
    {
      "title": "R2GenKG: Hierarchical Multi-modal Knowledge Graph for LLM-based Radiology Report Generation",
      "authors": [
        "Futian Wang",
        "Yuhan Qiao",
        "Xiao Wang",
        "Fuling Wang",
        "Yuxiang Zhang",
        "Dengdi Sun"
      ],
      "abstract": "X-ray medical report generation is one of the important applications of\nartificial intelligence in healthcare. With the support of large foundation\nmodels, the quality of medical report generation has significantly improved.\nHowever, challenges such as hallucination and weak disease diagnostic\ncapability still persist. In this paper, we first construct a large-scale\nmulti-modal medical knowledge graph (termed M3KG) based on the ground truth\nmedical report using the GPT-4o. It contains 2477 entities, 3 kinds of\nrelations, 37424 triples, and 6943 disease-aware vision tokens for the CheXpert\nPlus dataset. Then, we sample it to obtain multi-granularity semantic graphs\nand use an R-GCN encoder for feature extraction. For the input X-ray image, we\nadopt the Swin-Transformer to extract the vision features and interact with the\nknowledge using cross-attention. The vision tokens are fed into a Q-former and\nretrieved the disease-aware vision tokens using another cross-attention.\nFinally, we adopt the large language model to map the semantic knowledge graph,\ninput X-ray image, and disease-aware vision tokens into language descriptions.\nExtensive experiments on multiple datasets fully validated the effectiveness of\nour proposed knowledge graph and X-ray report generation framework. The source\ncode of this paper will be released on\nhttps://github.com/Event-AHU/Medical_Image_Analysis.",
      "pdf_url": "http://arxiv.org/pdf/2508.03426v1",
      "published": "2025-08-05T13:13:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.03426v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Learning Latent Representations for Image Translation using Frequency Distributed CycleGAN",
      "authors": [
        "Shivangi Nigam",
        "Adarsh Prasad Behera",
        "Shekhar Verma",
        "P. Nagabhushan"
      ],
      "abstract": "This paper presents Fd-CycleGAN, an image-to-image (I2I) translation\nframework that enhances latent representation learning to approximate real data\ndistributions. Building upon the foundation of CycleGAN, our approach\nintegrates Local Neighborhood Encoding (LNE) and frequency-aware supervision to\ncapture fine-grained local pixel semantics while preserving structural\ncoherence from the source domain. We employ distribution-based loss metrics,\nincluding KL/JS divergence and log-based similarity measures, to explicitly\nquantify the alignment between real and generated image distributions in both\nspatial and frequency domains. To validate the efficacy of Fd-CycleGAN, we\nconduct experiments on diverse datasets -- Horse2Zebra, Monet2Photo, and a\nsynthetically augmented Strike-off dataset. Compared to baseline CycleGAN and\nother state-of-the-art methods, our approach demonstrates superior perceptual\nquality, faster convergence, and improved mode diversity, particularly in\nlow-data regimes. By effectively capturing local and global distribution\ncharacteristics, Fd-CycleGAN achieves more visually coherent and semantically\nconsistent translations. Our results suggest that frequency-guided latent\nlearning significantly improves generalization in image translation tasks, with\npromising applications in document restoration, artistic style transfer, and\nmedical image synthesis. We also provide comparative insights with\ndiffusion-based generative models, highlighting the advantages of our\nlightweight adversarial approach in terms of training efficiency and\nqualitative output.",
      "pdf_url": "http://arxiv.org/pdf/2508.03415v1",
      "published": "2025-08-05T12:59:37+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.03415v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ]
    },
    {
      "title": "SlotMatch: Distilling Temporally Consistent Object-Centric Representations for Unsupervised Video Segmentation",
      "authors": [
        "Diana-Nicoleta Grigore",
        "Neelu Madan",
        "Andreas Mogelmose",
        "Thomas B. Moeslund",
        "Radu Tudor Ionescu"
      ],
      "abstract": "Unsupervised video segmentation is a challenging computer vision task,\nespecially due to the lack of supervisory signals coupled with the complexity\nof visual scenes. To overcome this challenge, state-of-the-art models based on\nslot attention often have to rely on large and computationally expensive neural\narchitectures. To this end, we propose a simple knowledge distillation\nframework that effectively transfers object-centric representations to a\nlightweight student. The proposed framework, called SlotMatch, aligns\ncorresponding teacher and student slots via the cosine similarity, requiring no\nadditional distillation objectives or auxiliary supervision. The simplicity of\nSlotMatch is confirmed via theoretical and empirical evidence, both indicating\nthat integrating additional losses is redundant. We conduct experiments on two\ndatasets to compare the state-of-the-art teacher model, SlotContrast, with our\ndistilled student. The results show that our student based on SlotMatch matches\nand even outperforms its teacher, while using 3.6x less parameters and running\n1.9x faster. Moreover, our student surpasses previous unsupervised video\nsegmentation models.",
      "pdf_url": "http://arxiv.org/pdf/2508.03411v1",
      "published": "2025-08-05T12:58:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.03411v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "NeuroSync: Intent-Aware Code-Based Problem Solving via Direct LLM Understanding Modification",
      "authors": [
        "Wenshuo Zhang",
        "Leixian Shen",
        "Shuchang Xu",
        "Jindu Wang",
        "Jian Zhao",
        "Huamin Qu",
        "Linping Yuan"
      ],
      "abstract": "Conversational LLMs have been widely adopted by domain users with limited\nprogramming experience to solve domain problems. However, these users often\nface misalignment between their intent and generated code, resulting in\nfrustration and rounds of clarification. This work first investigates the cause\nof this misalignment, which dues to bidirectional ambiguity: both user intents\nand coding tasks are inherently nonlinear, yet must be expressed and\ninterpreted through linear prompts and code sequences. To address this, we\npropose direct intent-task matching, a new human-LLM interaction paradigm that\nexternalizes and enables direct manipulation of the LLM understanding, i.e.,\nthe coding tasks and their relationships inferred by the LLM prior to code\ngeneration. As a proof-of-concept, this paradigm is then implemented in\nNeuroSync, which employs a knowledge distillation pipeline to extract LLM\nunderstanding, user intents, and their mappings, and enhances the alignment by\nallowing users to intuitively inspect and edit them via visualizations. We\nevaluate the algorithmic components of NeuroSync via technical experiments, and\nassess its overall usability and effectiveness via a user study (N=12). The\nresults show that it enhances intent-task alignment, lowers cognitive effort,\nand improves coding efficiency.",
      "pdf_url": "http://arxiv.org/pdf/2508.02823v1",
      "published": "2025-08-05T12:54:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.02823v1",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.SE"
      ]
    },
    {
      "title": "Multi-Objective Infeasibility Diagnosis for Routing Problems Using Large Language Models",
      "authors": [
        "Kai Li",
        "Ruihao Zheng",
        "Xinye Hao",
        "Zhenkun Wang"
      ],
      "abstract": "In real-world routing problems, users often propose conflicting or\nunreasonable requirements, which result in infeasible optimization models due\nto overly restrictive or contradictory constraints, leading to an empty\nfeasible solution set. Existing Large Language Model (LLM)-based methods\nattempt to diagnose infeasible models, but modifying such models often involves\nmultiple potential adjustments that these methods do not consider. To fill this\ngap, we introduce Multi-Objective Infeasibility Diagnosis (MOID), which\ncombines LLM agents and multi-objective optimization within an automatic\nrouting solver, to provide a set of representative actionable suggestions.\nSpecifically, MOID employs multi-objective optimization to consider both path\ncost and constraint violation, generating a set of trade-off solutions, each\nencompassing varying degrees of model adjustments. To extract practical\ninsights from these solutions, MOID utilizes LLM agents to generate a solution\nanalysis function for the infeasible model. This function analyzes these\ndistinct solutions to diagnose the original infeasible model, providing users\nwith diverse diagnostic insights and suggestions. Finally, we compare MOID with\nseveral LLM-based methods on 50 types of infeasible routing problems. The\nresults indicate that MOID automatically generates multiple diagnostic\nsuggestions in a single run, providing more practical insights for restoring\nmodel feasibility and decision-making compared to existing methods.",
      "pdf_url": "http://arxiv.org/pdf/2508.03406v1",
      "published": "2025-08-05T12:53:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.03406v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Visual Document Understanding and Question Answering: A Multi-Agent Collaboration Framework with Test-Time Scaling",
      "authors": [
        "Xinlei Yu",
        "Zhangquan Chen",
        "Yudong Zhang",
        "Shilin Lu",
        "Ruolin Shen",
        "Jiangning Zhang",
        "Xiaobin Hu",
        "Yanwei Fu",
        "Shuicheng Yan"
      ],
      "abstract": "Existing vision-language models (VLMs), whether generalists or specialists,\nremain constrained by their parameter scale, lack robust self-correction\ncapabilities, and underperform in tasks involving long visual contexts and\ncomplex reasoning, resulting in suboptimal performance on document-based tasks.\nTo address this, we propose MACT, a Multi-Agent Collaboration framework with\nTest-Time scaling, tailored for visual document understanding and visual\nquestion answering (VQA). It comprises four distinct small-scale agents, i.e.,\nplanning, execution, judgment, and answer agents, with clearly defined roles\nand effective collaboration. Notably, the judgment agent exclusively verifies\ncorrectness and redirects to prior agents for revisions, outperforming\nconventional correction strategies. To further expand the capability boundaries\nof the framework, we propose mixed reward modeling that balances agent-specific\nabilities and global collaboration, as well as agent-wise hybrid test-time\nscaling, which customizes different scaling strategies for each agent based on\ntheir functions. Evaluated on benchmarks spanning both document-based and\nnon-document-based settings, our MACT shows superior performance with a smaller\nparameter scale without sacrificing the ability of general and mathematical\ntasks. Especially, it stands out in benchmarks involving long visual contexts\nand complicated reasoning. The three variants of MACT consistently hold the top\nthree positions in average scores, leading in 13 of the 15 benchmarks. Code\nwill be available at: https://github.com/YU-deep/MACT.git.",
      "pdf_url": "http://arxiv.org/pdf/2508.03404v1",
      "published": "2025-08-05T12:52:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.03404v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "SCFlow: Implicitly Learning Style and Content Disentanglement with Flow Models",
      "authors": [
        "Pingchuan Ma",
        "Xiaopei Yang",
        "Yusong Li",
        "Ming Gui",
        "Felix Krause",
        "Johannes Schusterbauer",
        "Bjrn Ommer"
      ],
      "abstract": "Explicitly disentangling style and content in vision models remains\nchallenging due to their semantic overlap and the subjectivity of human\nperception. Existing methods propose separation through generative or\ndiscriminative objectives, but they still face the inherent ambiguity of\ndisentangling intertwined concepts. Instead, we ask: Can we bypass explicit\ndisentanglement by learning to merge style and content invertibly, allowing\nseparation to emerge naturally? We propose SCFlow, a flow-matching framework\nthat learns bidirectional mappings between entangled and disentangled\nrepresentations. Our approach is built upon three key insights: 1) Training\nsolely to merge style and content, a well-defined task, enables invertible\ndisentanglement without explicit supervision; 2) flow matching bridges on\narbitrary distributions, avoiding the restrictive Gaussian priors of diffusion\nmodels and normalizing flows; and 3) a synthetic dataset of 510,000 samples (51\nstyles $\\times$ 10,000 content samples) was curated to simulate disentanglement\nthrough systematic style-content pairing. Beyond controllable generation tasks,\nwe demonstrate that SCFlow generalizes to ImageNet-1k and WikiArt in zero-shot\nsettings and achieves competitive performance, highlighting that\ndisentanglement naturally emerges from the invertible merging process.",
      "pdf_url": "http://arxiv.org/pdf/2508.03402v1",
      "published": "2025-08-05T12:50:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.03402v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Hide and Seek with LLMs: An Adversarial Game for Sneaky Error Generation and Self-Improving Diagnosis",
      "authors": [
        "Rui Zou",
        "Mengqi Wei",
        "Yutao Zhu",
        "Jirong Wen",
        "Xin Zhao",
        "Jing Chen"
      ],
      "abstract": "Large Language Models (LLMs) excel in reasoning and generation across\ndomains, but still struggle with identifying and diagnosing complex errors.\nThis stems mainly from training objectives that prioritize correct answers,\nlimiting exposure to and learning from errors. While recent studies have begun\nto address this by introducing error signals, most rely on shallow, static\nerrors, restricting improvement in deep diagnostic ability. To overcome this,\nwe propose Hide and Seek Game (HSG), a dynamic adversarial framework for error\ngeneration and diagnosis, and evaluate it on mathematical problem-solving. HSG\ninvolves two adversarial roles: Sneaky, which \"hides\" by generating subtle,\ndeceptive reasoning errors, and Diagnosis, which \"seeks\" to accurately detect\nthem. Through adversarial co-evolution, both error stealth and diagnostic\nprecision are enhanced. Experiments on several math reasoning tasks show that\nHSG significantly boosts error diagnosis, achieving 16.8\\%--31.4\\% higher\naccuracy than baselines like GPT-4o. We also release a challenging dataset of\ndeceptive errors and diagnostic annotations as a benchmark for future research.",
      "pdf_url": "http://arxiv.org/pdf/2508.03396v1",
      "published": "2025-08-05T12:45:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.03396v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Agentic AI in 6G Software Businesses: A Layered Maturity Model",
      "authors": [
        "Muhammad Zohaib",
        "Muhammad Azeem Akbar",
        "Sami Hyrynsalmi",
        "Arif Ali Khan"
      ],
      "abstract": "The emergence of agentic AI systems in 6G software businesses presents both\nstrategic opportunities and significant challenges. While such systems promise\nincreased autonomy, scalability, and intelligent decision-making across\ndistributed environments, their adoption raises concerns regarding technical\nimmaturity, integration complexity, organizational readiness, and\nperformance-cost trade-offs. In this study, we conducted a preliminary thematic\nmapping to identify factors influencing the adoption of agentic software within\nthe context of 6G. Drawing on a multivocal literature review and targeted\nscanning, we identified 29 motivators and 27 demotivators, which were further\ncategorized into five high-level themes in each group. This thematic mapping\noffers a structured overview of the enabling and inhibiting forces shaping\norganizational readiness for agentic transformation. Positioned as a\nfeasibility assessment, the study represents an early phase of a broader\nresearch initiative aimed at developing and validating a layered maturity model\ngrounded in CMMI model with the software architectural three dimensions\npossibly Data, Business Logic, and Presentation. Ultimately, this work seeks to\nprovide a practical framework to help software-driven organizations assess,\nstructure, and advance their agent-first capabilities in alignment with the\ndemands of 6G.",
      "pdf_url": "http://arxiv.org/pdf/2508.03393v1",
      "published": "2025-08-05T12:42:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.03393v1",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "Data Dependency Inference for Industrial Code Generation Based on UML Sequence Diagrams",
      "authors": [
        "Wenxin Mao",
        "Zhitao Wang",
        "Long Wang",
        "Sirong Chen",
        "Cuiyun Gao",
        "Luyang Cao",
        "Ziming Liu",
        "Qiming Zhang",
        "Jun Zhou",
        "Zhi Jin"
      ],
      "abstract": "Large language models (LLMs) excel at generating code from natural language\n(NL) descriptions. However, the plain textual descriptions are inherently\nambiguous and often fail to capture complex requirements like intricate system\nbehaviors, conditional logic, and architectural constraints; implicit data\ndependencies in service-oriented architectures are difficult to infer and\nhandle correctly. To bridge this gap, we propose a novel step-by-step code\ngeneration framework named UML2Dep by leveraging unambiguous formal\nspecifications of complex requirements. First, we introduce an enhanced Unified\nModeling Language (UML) sequence diagram tailored for service-oriented\narchitectures. This diagram extends traditional visual syntax by integrating\ndecision tables and API specifications, explicitly formalizing structural\nrelationships and business logic flows in service interactions to rigorously\neliminate linguistic ambiguity. Second, recognizing the critical role of data\nflow, we introduce a dedicated data dependency inference (DDI) task. DDI\nsystematically constructs an explicit data dependency graph prior to actual\ncode synthesis. To ensure reliability, we formalize DDI as a constrained\nmathematical reasoning task through novel prompting strategies, aligning with\nLLMs' excellent mathematical strengths. Additional static parsing and\ndependency pruning further reduce context complexity and cognitive load\nassociated with intricate specifications, thereby enhancing reasoning accuracy\nand efficiency.",
      "pdf_url": "http://arxiv.org/pdf/2508.03379v2",
      "published": "2025-08-05T12:28:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.03379v2",
      "categories": [
        "cs.AI",
        "cs.SE"
      ]
    },
    {
      "title": "Board Game Arena: A Framework and Benchmark for Assessing Large Language Models via Strategic Play",
      "authors": [
        "Lucia Cipolina-Kun",
        "Marianna Nezhurina",
        "Jenia Jitsev"
      ],
      "abstract": "The Board Game Arena library provides a framework for evaluating the decision\nmaking abilities of large language models (LLMs) through strategic board games\nimplemented in Google OpenSpiel library. The framework enables systematic\ncomparisons between LLM based agents and other agents (random, human,\nreinforcement learning agents, etc.) in various game scenarios by wrapping\nmultiple board and matrix games and supporting different agent types. It\nintegrates API access to models via LiteLLM, local model deployment via vLLM,\nand offers distributed execution through Ray. Additionally it provides\nextensive analysis tools for the LLM reasoning traces. This paper summarizes\nthe structure, key characteristics, and motivation of the repository,\nhighlighting how it contributes to the empirical evaluation of the reasoning of\nLLM and game-theoretic behavior",
      "pdf_url": "http://arxiv.org/pdf/2508.03368v1",
      "published": "2025-08-05T12:15:59+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.03368v1",
      "categories": [
        "cs.AI",
        "cs.GT"
      ]
    },
    {
      "title": "A Comparative Study of Neurosymbolic AI Approaches to Interpretable Logical Reasoning",
      "authors": [
        "Michael K. Chen"
      ],
      "abstract": "General logical reasoning, defined as the ability to reason deductively on\ndomain-agnostic tasks, continues to be a challenge for large language models\n(LLMs). Current LLMs fail to reason deterministically and are not\ninterpretable. As such, there has been a recent surge in interest in\nneurosymbolic AI, which attempts to incorporate logic into neural networks. We\nfirst identify two main neurosymbolic approaches to improving logical\nreasoning: (i) the integrative approach comprising models where symbolic\nreasoning is contained within the neural network, and (ii) the hybrid approach\ncomprising models where a symbolic solver, separate from the neural network,\nperforms symbolic reasoning. Both contain AI systems with promising results on\ndomain-specific logical reasoning benchmarks. However, their performance on\ndomain-agnostic benchmarks is understudied. To the best of our knowledge, there\nhas not been a comparison of the contrasting approaches that answers the\nfollowing question: Which approach is more promising for developing general\nlogical reasoning? To analyze their potential, the following best-in-class\ndomain-agnostic models are introduced: Logic Neural Network (LNN), which uses\nthe integrative approach, and LLM-Symbolic Solver (LLM-SS), which uses the\nhybrid approach. Using both models as case studies and representatives of each\napproach, our analysis demonstrates that the hybrid approach is more promising\nfor developing general logical reasoning because (i) its reasoning chain is\nmore interpretable, and (ii) it retains the capabilities and advantages of\nexisting LLMs. To support future works using the hybrid approach, we propose a\ngeneralizable framework based on LLM-SS that is modular by design,\nmodel-agnostic, domain-agnostic, and requires little to no human input.",
      "pdf_url": "http://arxiv.org/pdf/2508.03366v1",
      "published": "2025-08-05T12:14:32+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.03366v1",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.SC"
      ]
    },
    {
      "title": "When Good Sounds Go Adversarial: Jailbreaking Audio-Language Models with Benign Inputs",
      "authors": [
        "Bodam Kim",
        "Hiskias Dingeto",
        "Taeyoun Kwon",
        "Dasol Choi",
        "DongGeon Lee",
        "Haon Park",
        "JaeHoon Lee",
        "Jongho Shin"
      ],
      "abstract": "As large language models become increasingly integrated into daily life,\naudio has emerged as a key interface for human-AI interaction. However, this\nconvenience also introduces new vulnerabilities, making audio a potential\nattack surface for adversaries. Our research introduces WhisperInject, a\ntwo-stage adversarial audio attack framework that can manipulate\nstate-of-the-art audio language models to generate harmful content. Our method\nuses imperceptible perturbations in audio inputs that remain benign to human\nlisteners. The first stage uses a novel reward-based optimization method,\nReinforcement Learning with Projected Gradient Descent (RL-PGD), to guide the\ntarget model to circumvent its own safety protocols and generate harmful native\nresponses. This native harmful response then serves as the target for Stage 2,\nPayload Injection, where we use Projected Gradient Descent (PGD) to optimize\nsubtle perturbations that are embedded into benign audio carriers, such as\nweather queries or greeting messages. Validated under the rigorous\nStrongREJECT, LlamaGuard, as well as Human Evaluation safety evaluation\nframework, our experiments demonstrate a success rate exceeding 86% across\nQwen2.5-Omni-3B, Qwen2.5-Omni-7B, and Phi-4-Multimodal. Our work demonstrates a\nnew class of practical, audio-native threats, moving beyond theoretical\nexploits to reveal a feasible and covert method for manipulating AI behavior.",
      "pdf_url": "http://arxiv.org/pdf/2508.03365v1",
      "published": "2025-08-05T12:14:01+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.03365v1",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CR",
        "eess.AS"
      ]
    }
  ]
}