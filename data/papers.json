{
  "last_updated": "2025-04-29T00:50:26.800000",
  "papers": [
    {
      "title": "Generalization Capability for Imitation Learning",
      "authors": [
        "Yixiao Wang"
      ],
      "abstract": "Imitation learning holds the promise of equipping robots with versatile\nskills by learning from expert demonstrations. However, policies trained on\nfinite datasets often struggle to generalize beyond the training distribution.\nIn this work, we present a unified perspective on the generalization capability\nof imitation learning, grounded in both information theorey and data\ndistribution property. We first show that the generalization gap can be upper\nbounded by (i) the conditional information bottleneck on intermediate\nrepresentations and (ii) the mutual information between the model parameters\nand the training dataset. This characterization provides theoretical guidance\nfor designing effective training strategies in imitation learning, particularly\nin determining whether to freeze, fine-tune, or train large pretrained encoders\n(e.g., vision-language models or vision foundation models) from scratch to\nachieve better generalization. Furthermore, we demonstrate that high\nconditional entropy from input to output induces a flatter likelihood\nlandscape, thereby reducing the upper bound on the generalization gap. In\naddition, it shortens the stochastic gradient descent (SGD) escape time from\nsharp local minima, which may increase the likelihood of reaching global optima\nunder fixed optimization budgets. These insights explain why imitation learning\noften exhibits limited generalization and underscore the importance of not only\nscaling the diversity of input data but also enriching the variability of\noutput labels conditioned on the same input.",
      "pdf_url": "http://arxiv.org/pdf/2504.18538v1",
      "published": "2025-04-25T17:59:59+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.18538v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ]
    },
    {
      "title": "Adapting Probabilistic Risk Assessment for AI",
      "authors": [
        "Anna Katariina Wisakanto",
        "Joe Rogero",
        "Avyay M. Casheekar",
        "Richard Mallah"
      ],
      "abstract": "Modern general-purpose artificial intelligence (AI) systems present an urgent\nrisk management challenge, as their rapidly evolving capabilities and potential\nfor catastrophic harm outpace our ability to reliably assess their risks.\nCurrent methods often rely on selective testing and undocumented assumptions\nabout risk priorities, frequently failing to make a serious attempt at\nassessing the set of pathways through which Al systems pose direct or indirect\nrisks to society and the biosphere. This paper introduces the probabilistic\nrisk assessment (PRA) for AI framework, adapting established PRA techniques\nfrom high-reliability industries (e.g., nuclear power, aerospace) for the new\nchallenges of advanced AI. The framework guides assessors in identifying\npotential risks, estimating likelihood and severity, and explicitly documenting\nevidence, underlying assumptions, and analyses at appropriate granularities.\nThe framework's implementation tool synthesizes the results into a risk report\ncard with aggregated risk estimates from all assessed risks. This systematic\napproach integrates three advances: (1) Aspect-oriented hazard analysis\nprovides systematic hazard coverage guided by a first-principles taxonomy of AI\nsystem aspects (e.g. capabilities, domain knowledge, affordances); (2) Risk\npathway modeling analyzes causal chains from system aspects to societal impacts\nusing bidirectional analysis and incorporating prospective techniques; and (3)\nUncertainty management employs scenario decomposition, reference scales, and\nexplicit tracing protocols to structure credible projections with novelty or\nlimited data. Additionally, the framework harmonizes diverse assessment methods\nby integrating evidence into comparable, quantified absolute risk estimates for\ncritical decisions. We have implemented this as a workbook tool for AI\ndevelopers, evaluators, and regulators, available on the project website.",
      "pdf_url": "http://arxiv.org/pdf/2504.18536v1",
      "published": "2025-04-25T17:59:14+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.18536v1",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.LG",
        "cs.SY",
        "eess.SY",
        "stat.AP"
      ]
    },
    {
      "title": "Scaling Laws For Scalable Oversight",
      "authors": [
        "Joshua Engels",
        "David D. Baek",
        "Subhash Kantamneni",
        "Max Tegmark"
      ],
      "abstract": "Scalable oversight, the process by which weaker AI systems supervise stronger\nones, has been proposed as a key strategy to control future superintelligent\nsystems. However, it is still unclear how scalable oversight itself scales. To\naddress this gap, we propose a framework that quantifies the probability of\nsuccessful oversight as a function of the capabilities of the overseer and the\nsystem being overseen. Specifically, our framework models oversight as a game\nbetween capability-mismatched players; the players have oversight-specific and\ndeception-specific Elo scores that are a piecewise-linear function of their\ngeneral intelligence, with two plateaus corresponding to task incompetence and\ntask saturation. We validate our framework with a modified version of the game\nNim and then apply it to four oversight games: \"Mafia\", \"Debate\", \"Backdoor\nCode\" and \"Wargames\". For each game, we find scaling laws that approximate how\ndomain performance depends on general AI system capability (using Chatbot Arena\nElo as a proxy for general capability). We then build on our findings in a\ntheoretical study of Nested Scalable Oversight (NSO), a process in which\ntrusted models oversee untrusted stronger models, which then become the trusted\nmodels in the next step. We identify conditions under which NSO succeeds and\nderive numerically (and in some cases analytically) the optimal number of\noversight levels to maximize the probability of oversight success. In our\nnumerical examples, the NSO success rate is below 52% when overseeing systems\nthat are 400 Elo points stronger than the baseline overseer, and it declines\nfurther for overseeing even stronger systems.",
      "pdf_url": "http://arxiv.org/pdf/2504.18530v1",
      "published": "2025-04-25T17:54:27+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.18530v1",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ]
    },
    {
      "title": "DeSIA: Attribute Inference Attacks Against Limited Fixed Aggregate Statistics",
      "authors": [
        "Yifeng Mao",
        "Bozhidar Stevanoski",
        "Yves-Alexandre de Montjoye"
      ],
      "abstract": "Empirical inference attacks are a popular approach for evaluating the privacy\nrisk of data release mechanisms in practice. While an active attack literature\nexists to evaluate machine learning models or synthetic data release, we\ncurrently lack comparable methods for fixed aggregate statistics, in particular\nwhen only a limited number of statistics are released. We here propose an\ninference attack framework against fixed aggregate statistics and an attribute\ninference attack called DeSIA. We instantiate DeSIA against the U.S. Census\nPPMF dataset and show it to strongly outperform reconstruction-based attacks.\nIn particular, we show DeSIA to be highly effective at identifying vulnerable\nusers, achieving a true positive rate of 0.14 at a false positive rate of\n$10^{-3}$. We then show DeSIA to perform well against users whose attributes\ncannot be verified and when varying the number of aggregate statistics and\nlevel of noise addition. We also perform an extensive ablation study of DeSIA\nand show how DeSIA can be successfully adapted to the membership inference\ntask. Overall, our results show that aggregation alone is not sufficient to\nprotect privacy, even when a relatively small number of aggregates are being\nreleased, and emphasize the need for formal privacy mechanisms and testing\nbefore aggregate statistics are released.",
      "pdf_url": "http://arxiv.org/pdf/2504.18497v1",
      "published": "2025-04-25T17:10:33+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.18497v1",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "title": "Action Flow Matching for Continual Robot Learning",
      "authors": [
        "Alejandro Murillo-Gonzalez",
        "Lantao Liu"
      ],
      "abstract": "Continual learning in robotics seeks systems that can constantly adapt to\nchanging environments and tasks, mirroring human adaptability. A key challenge\nis refining dynamics models, essential for planning and control, while\naddressing issues such as safe adaptation, catastrophic forgetting, outlier\nmanagement, data efficiency, and balancing exploration with exploitation -- all\nwithin task and onboard resource constraints. Towards this goal, we introduce a\ngenerative framework leveraging flow matching for online robot dynamics model\nalignment. Rather than executing actions based on a misaligned model, our\napproach refines planned actions to better match with those the robot would\ntake if its model was well aligned. We find that by transforming the actions\nthemselves rather than exploring with a misaligned model -- as is traditionally\ndone -- the robot collects informative data more efficiently, thereby\naccelerating learning. Moreover, we validate that the method can handle an\nevolving and possibly imperfect model while reducing, if desired, the\ndependency on replay buffers or legacy model snapshots. We validate our\napproach using two platforms: an unmanned ground vehicle and a quadrotor. The\nresults highlight the method's adaptability and efficiency, with a record\n34.2\\% higher task success rate, demonstrating its potential towards enabling\ncontinual robot learning. Code:\nhttps://github.com/AlejandroMllo/action_flow_matching.",
      "pdf_url": "http://arxiv.org/pdf/2504.18471v1",
      "published": "2025-04-25T16:26:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.18471v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "Fast-Slow Thinking for Large Vision-Language Model Reasoning",
      "authors": [
        "Wenyi Xiao",
        "Leilei Gan",
        "Weilong Dai",
        "Wanggui He",
        "Ziwei Huang",
        "Haoyuan Li",
        "Fangxun Shu",
        "Zhelun Yu",
        "Peng Zhang",
        "Hao Jiang",
        "Fei Wu"
      ],
      "abstract": "Recent advances in large vision-language models (LVLMs) have revealed an\n\\textit{overthinking} phenomenon, where models generate verbose reasoning\nacross all tasks regardless of questions. To address this issue, we present\n\\textbf{FAST}, a novel \\textbf{Fa}st-\\textbf{S}low \\textbf{T}hinking framework\nthat dynamically adapts reasoning depth based on question characteristics.\nThrough empirical analysis, we establish the feasibility of fast-slow thinking\nin LVLMs by investigating how response length and data distribution affect\nperformance. We develop FAST-GRPO with three components: model-based metrics\nfor question characterization, an adaptive thinking reward mechanism, and\ndifficulty-aware KL regularization. Experiments across seven reasoning\nbenchmarks demonstrate that FAST achieves state-of-the-art accuracy with over\n10\\% relative improvement compared to the base model, while reducing token\nusage by 32.7-67.3\\% compared to previous slow-thinking approaches, effectively\nbalancing reasoning length and accuracy.",
      "pdf_url": "http://arxiv.org/pdf/2504.18458v1",
      "published": "2025-04-25T16:11:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.18458v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Reason Like a Radiologist: Chain-of-Thought and Reinforcement Learning for Verifiable Report Generation",
      "authors": [
        "Peiyuan Jing",
        "Kinhei Lee",
        "Zhenxuan Zhang",
        "Huichi Zhou",
        "Zhengqing Yuan",
        "Zhifan Gao",
        "Lei Zhu",
        "Giorgos Papanastasiou",
        "Yingying Fang",
        "Guang Yang"
      ],
      "abstract": "Radiology report generation is critical for efficiency but current models\nlack the structured reasoning of experts, hindering clinical trust and\nexplainability by failing to link visual findings to precise anatomical\nlocations. This paper introduces BoxMed-RL, a groundbreaking unified training\nframework for generating spatially verifiable and explainable radiology\nreports. Built on a large vision-language model, BoxMed-RL revolutionizes\nreport generation through two integrated phases: (1) In the Pretraining Phase,\nwe refine the model via medical concept learning, using Chain-of-Thought\nsupervision to internalize the radiologist-like workflow, followed by spatially\nverifiable reinforcement, which applies reinforcement learning to align medical\nfindings with bounding boxes. (2) In the Downstream Adapter Phase, we freeze\nthe pretrained weights and train a downstream adapter to ensure fluent and\nclinically credible reports. This framework precisely mimics radiologists'\nworkflow, compelling the model to connect high-level medical concepts with\ndefinitive anatomical evidence. Extensive experiments on public datasets\ndemonstrate that BoxMed-RL achieves an average 7% improvement in both METEOR\nand ROUGE-L metrics compared to state-of-the-art methods. An average 5%\nimprovement in large language model-based metrics further underscores\nBoxMed-RL's robustness in generating high-quality radiology reports.",
      "pdf_url": "http://arxiv.org/pdf/2504.18453v1",
      "published": "2025-04-25T16:05:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.18453v1",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Iterative Event-based Motion Segmentation by Variational Contrast Maximization",
      "authors": [
        "Ryo Yamaki",
        "Shintaro Shiba",
        "Guillermo Gallego",
        "Yoshimitsu Aoki"
      ],
      "abstract": "Event cameras provide rich signals that are suitable for motion estimation\nsince they respond to changes in the scene. As any visual changes in the scene\nproduce event data, it is paramount to classify the data into different motions\n(i.e., motion segmentation), which is useful for various tasks such as object\ndetection and visual servoing. We propose an iterative motion segmentation\nmethod, by classifying events into background (e.g., dominant motion\nhypothesis) and foreground (independent motion residuals), thus extending the\nContrast Maximization framework. Experimental results demonstrate that the\nproposed method successfully classifies event clusters both for public and\nself-recorded datasets, producing sharp, motion-compensated edge-like images.\nThe proposed method achieves state-of-the-art accuracy on moving object\ndetection benchmarks with an improvement of over 30%, and demonstrates its\npossibility of applying to more complex and noisy real-world scenes. We hope\nthis work broadens the sensitivity of Contrast Maximization with respect to\nboth motion parameters and input events, thus contributing to theoretical\nadvancements in event-based motion segmentation estimation.\nhttps://github.com/aoki-media-lab/event_based_segmentation_vcmax",
      "pdf_url": "http://arxiv.org/pdf/2504.18447v1",
      "published": "2025-04-25T16:00:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.18447v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ]
    },
    {
      "title": "Pseudo-Boolean Proof Logging for Optimal Classical Planning",
      "authors": [
        "Simon Dold",
        "Malte Helmert",
        "Jakob Nordström",
        "Gabriele Röger",
        "Tanja Schindler"
      ],
      "abstract": "We introduce lower-bound certificates for classical planning tasks, which can\nbe used to prove the unsolvability of a task or the optimality of a plan in a\nway that can be verified by an independent third party. We describe a general\nframework for generating lower-bound certificates based on pseudo-Boolean\nconstraints, which is agnostic to the planning algorithm used.\n  As a case study, we show how to modify the $A^{*}$ algorithm to produce\nproofs of optimality with modest overhead, using pattern database heuristics\nand $h^\\textit{max}$ as concrete examples. The same proof logging approach\nworks for any heuristic whose inferences can be efficiently expressed as\nreasoning over pseudo-Boolean constraints.",
      "pdf_url": "http://arxiv.org/pdf/2504.18443v1",
      "published": "2025-04-25T15:54:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.18443v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Enhancing Pre-Trained Model-Based Class-Incremental Learning through Neural Collapse",
      "authors": [
        "Kun He",
        "Zijian Song",
        "Shuoxi Zhang",
        "John E. Hopcroft"
      ],
      "abstract": "Class-Incremental Learning (CIL) is a critical capability for real-world\napplications, enabling learning systems to adapt to new tasks while retaining\nknowledge from previous ones. Recent advancements in pre-trained models (PTMs)\nhave significantly advanced the field of CIL, demonstrating superior\nperformance over traditional methods. However, understanding how features\nevolve and are distributed across incremental tasks remains an open challenge.\nIn this paper, we propose a novel approach to modeling feature evolution in\nPTM-based CIL through the lens of neural collapse (NC), a striking phenomenon\nobserved in the final phase of training, which leads to a well-separated,\nequiangular feature space. We explore the connection between NC and CIL\neffectiveness, showing that aligning feature distributions with the NC geometry\nenhances the ability to capture the dynamic behavior of continual learning.\nBased on this insight, we introduce Neural Collapse-inspired Pre-Trained\nModel-based CIL (NCPTM-CIL), a method that dynamically adjusts the feature\nspace to conform to the elegant NC structure, thereby enhancing the continual\nlearning process. Extensive experiments demonstrate that NCPTM-CIL outperforms\nstate-of-the-art methods across four benchmark datasets. Notably, when\ninitialized with ViT-B/16-IN1K, NCPTM-CIL surpasses the runner-up method by\n6.73% on VTAB, 1.25% on CIFAR-100, and 2.5% on OmniBenchmark.",
      "pdf_url": "http://arxiv.org/pdf/2504.18437v1",
      "published": "2025-04-25T15:48:41+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.18437v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Kimi-Audio Technical Report",
      "authors": [
        "KimiTeam",
        "Ding Ding",
        "Zeqian Ju",
        "Yichong Leng",
        "Songxiang Liu",
        "Tong Liu",
        "Zeyu Shang",
        "Kai Shen",
        "Wei Song",
        "Xu Tan",
        "Heyi Tang",
        "Zhengtao Wang",
        "Chu Wei",
        "Yifei Xin",
        "Xinran Xu",
        "Jianwei Yu",
        "Yutao Zhang",
        "Xinyu Zhou",
        "Y. Charles",
        "Jun Chen",
        "Yanru Chen",
        "Yulun Du",
        "Weiran He",
        "Zhenxing Hu",
        "Guokun Lai",
        "Qingcheng Li",
        "Yangyang Liu",
        "Weidong Sun",
        "Jianzhou Wang",
        "Yuzhi Wang",
        "Yuefeng Wu",
        "Yuxin Wu",
        "Dongchao Yang",
        "Hao Yang",
        "Ying Yang",
        "Zhilin Yang",
        "Aoxiong Yin",
        "Ruibin Yuan",
        "Yutong Zhang",
        "Zaida Zhou"
      ],
      "abstract": "We present Kimi-Audio, an open-source audio foundation model that excels in\naudio understanding, generation, and conversation. We detail the practices in\nbuilding Kimi-Audio, including model architecture, data curation, training\nrecipe, inference deployment, and evaluation. Specifically, we leverage a\n12.5Hz audio tokenizer, design a novel LLM-based architecture with continuous\nfeatures as input and discrete tokens as output, and develop a chunk-wise\nstreaming detokenizer based on flow matching. We curate a pre-training dataset\nthat consists of more than 13 million hours of audio data covering a wide range\nof modalities including speech, sound, and music, and build a pipeline to\nconstruct high-quality and diverse post-training data. Initialized from a\npre-trained LLM, Kimi-Audio is continual pre-trained on both audio and text\ndata with several carefully designed tasks, and then fine-tuned to support a\ndiverse of audio-related tasks. Extensive evaluation shows that Kimi-Audio\nachieves state-of-the-art performance on a range of audio benchmarks including\nspeech recognition, audio understanding, audio question answering, and speech\nconversation. We release the codes, model checkpoints, as well as the\nevaluation toolkits in https://github.com/MoonshotAI/Kimi-Audio.",
      "pdf_url": "http://arxiv.org/pdf/2504.18425v1",
      "published": "2025-04-25T15:31:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.18425v1",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.MM",
        "cs.SD"
      ]
    },
    {
      "title": "LLMpatronous: Harnessing the Power of LLMs For Vulnerability Detection",
      "authors": [
        "Rajesh Yarra"
      ],
      "abstract": "Despite the transformative impact of Artificial Intelligence (AI) across\nvarious sectors, cyber security continues to rely on traditional static and\ndynamic analysis tools, hampered by high false positive rates and superficial\ncode comprehension. While generative AI offers promising automation\ncapabilities for software development, leveraging Large Language Models (LLMs)\nfor vulnerability detection presents unique challenges. This paper explores the\npotential and limitations of LLMs in identifying vulnerabilities, acknowledging\ninherent weaknesses such as hallucinations, limited context length, and\nknowledge cut-offs. Previous attempts employing machine learning models for\nvulnerability detection have proven ineffective due to limited real-world\napplicability, feature engineering challenges, lack of contextual\nunderstanding, and the complexities of training models to keep pace with the\nevolving threat landscape. Therefore, we propose a robust AI-driven approach\nfocused on mitigating these limitations and ensuring the quality and\nreliability of LLM based vulnerability detection. Through innovative\nmethodologies combining Retrieval-Augmented Generation (RAG) and\nMixtureof-Agents (MoA), this research seeks to leverage the strengths of LLMs\nwhile addressing their weaknesses, ultimately paving the way for dependable and\nefficient AI-powered solutions in securing the ever-evolving software\nlandscape.",
      "pdf_url": "http://arxiv.org/pdf/2504.18423v1",
      "published": "2025-04-25T15:30:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.18423v1",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "title": "A Multimodal Hybrid Late-Cascade Fusion Network for Enhanced 3D Object Detection",
      "authors": [
        "Carlo Sgaravatti",
        "Roberto Basla",
        "Riccardo Pieroni",
        "Matteo Corno",
        "Sergio M. Savaresi",
        "Luca Magri",
        "Giacomo Boracchi"
      ],
      "abstract": "We present a new way to detect 3D objects from multimodal inputs, leveraging\nboth LiDAR and RGB cameras in a hybrid late-cascade scheme, that combines an\nRGB detection network and a 3D LiDAR detector. We exploit late fusion\nprinciples to reduce LiDAR False Positives, matching LiDAR detections with RGB\nones by projecting the LiDAR bounding boxes on the image. We rely on cascade\nfusion principles to recover LiDAR False Negatives leveraging epipolar\nconstraints and frustums generated by RGB detections of separate views. Our\nsolution can be plugged on top of any underlying single-modal detectors,\nenabling a flexible training process that can take advantage of pre-trained\nLiDAR and RGB detectors, or train the two branches separately. We evaluate our\nresults on the KITTI object detection benchmark, showing significant\nperformance improvements, especially for the detection of Pedestrians and\nCyclists.",
      "pdf_url": "http://arxiv.org/pdf/2504.18419v1",
      "published": "2025-04-25T15:28:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.18419v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ]
    },
    {
      "title": "Paradigm shift on Coding Productivity Using GenAI",
      "authors": [
        "Liang Yu"
      ],
      "abstract": "Generative AI (GenAI) applications are transforming software engineering by\nenabling automated code co-creation. However, empirical evidence on GenAI's\nproductivity effects in industrial settings remains limited. This paper\ninvestigates the adoption of GenAI coding assistants (e.g., Codeium, Amazon Q)\nwithin telecommunications and FinTech domains. Through surveys and interviews\nwith industrial domain-experts, we identify primary productivity-influencing\nfactors, including task complexity, coding skills, domain knowledge, and GenAI\nintegration. Our findings indicate that GenAI tools enhance productivity in\nroutine coding tasks (e.g., refactoring and Javadoc generation) but face\nchallenges in complex, domain-specific activities due to limited\ncontext-awareness of codebases and insufficient support for customized design\nrules. We highlight new paradigms for coding transfer, emphasizing iterative\nprompt refinement, immersive development environment, and automated code\nevaluation as essential for effective GenAI usage.",
      "pdf_url": "http://arxiv.org/pdf/2504.18404v1",
      "published": "2025-04-25T15:00:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.18404v1",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "A Multimodal Deep Learning Approach for White Matter Shape Prediction in Diffusion MRI Tractography",
      "authors": [
        "Yui Lo",
        "Yuqian Chen",
        "Dongnan Liu",
        "Leo Zekelman",
        "Jarrett Rushmore",
        "Yogesh Rathi",
        "Nikos Makris",
        "Alexandra J. Golby",
        "Fan Zhang",
        "Weidong Cai",
        "Lauren J. O'Donnell"
      ],
      "abstract": "Shape measures have emerged as promising descriptors of white matter\ntractography, offering complementary insights into anatomical variability and\nassociations with cognitive and clinical phenotypes. However, conventional\nmethods for computing shape measures are computationally expensive and\ntime-consuming for large-scale datasets due to reliance on voxel-based\nrepresentations. We propose Tract2Shape, a novel multimodal deep learning\nframework that leverages geometric (point cloud) and scalar (tabular) features\nto predict ten white matter tractography shape measures. To enhance model\nefficiency, we utilize a dimensionality reduction algorithm for the model to\npredict five primary shape components. The model is trained and evaluated on\ntwo independently acquired datasets, the HCP-YA dataset, and the PPMI dataset.\nWe evaluate the performance of Tract2Shape by training and testing it on the\nHCP-YA dataset and comparing the results with state-of-the-art models. To\nfurther assess its robustness and generalization ability, we also test\nTract2Shape on the unseen PPMI dataset. Tract2Shape outperforms SOTA deep\nlearning models across all ten shape measures, achieving the highest average\nPearson's r and the lowest nMSE on the HCP-YA dataset. The ablation study shows\nthat both multimodal input and PCA contribute to performance gains. On the\nunseen testing PPMI dataset, Tract2Shape maintains a high Pearson's r and low\nnMSE, demonstrating strong generalizability in cross-dataset evaluation.\nTract2Shape enables fast, accurate, and generalizable prediction of white\nmatter shape measures from tractography data, supporting scalable analysis\nacross datasets. This framework lays a promising foundation for future\nlarge-scale white matter shape analysis.",
      "pdf_url": "http://arxiv.org/pdf/2504.18400v1",
      "published": "2025-04-25T14:54:47+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.18400v1",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Bridge the Domains: Large Language Models Enhanced Cross-domain Sequential Recommendation",
      "authors": [
        "Qidong Liu",
        "Xiangyu Zhao",
        "Yejing Wang",
        "Zijian Zhang",
        "Howard Zhong",
        "Chong Chen",
        "Xiang Li",
        "Wei Huang",
        "Feng Tian"
      ],
      "abstract": "Cross-domain Sequential Recommendation (CDSR) aims to extract the preference\nfrom the user's historical interactions across various domains. Despite some\nprogress in CDSR, two problems set the barrier for further advancements, i.e.,\noverlap dilemma and transition complexity. The former means existing CDSR\nmethods severely rely on users who own interactions on all domains to learn\ncross-domain item relationships, compromising the practicability. The latter\nrefers to the difficulties in learning the complex transition patterns from the\nmixed behavior sequences. With powerful representation and reasoning abilities,\nLarge Language Models (LLMs) are promising to address these two problems by\nbridging the items and capturing the user's preferences from a semantic view.\nTherefore, we propose an LLMs Enhanced Cross-domain Sequential Recommendation\nmodel (LLM4CDSR). To obtain the semantic item relationships, we first propose\nan LLM-based unified representation module to represent items. Then, a\ntrainable adapter with contrastive regularization is designed to adapt the CDSR\ntask. Besides, a hierarchical LLMs profiling module is designed to summarize\nuser cross-domain preferences. Finally, these two modules are integrated into\nthe proposed tri-thread framework to derive recommendations. We have conducted\nextensive experiments on three public cross-domain datasets, validating the\neffectiveness of LLM4CDSR. We have released the code online.",
      "pdf_url": "http://arxiv.org/pdf/2504.18383v1",
      "published": "2025-04-25T14:30:25+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.18383v1",
      "categories": [
        "cs.IR",
        "cs.AI"
      ]
    },
    {
      "title": "Spatial Reasoner: A 3D Inference Pipeline for XR Applications",
      "authors": [
        "Steven Häsler",
        "Philipp Ackermann"
      ],
      "abstract": "Modern extended reality XR systems provide rich analysis of image data and\nfusion of sensor input and demand AR/VR applications that can reason about 3D\nscenes in a semantic manner. We present a spatial reasoning framework that\nbridges geometric facts with symbolic predicates and relations to handle key\ntasks such as determining how 3D objects are arranged among each other ('on',\n'behind', 'near', etc.). Its foundation relies on oriented 3D bounding box\nrepresentations, enhanced by a comprehensive set of spatial predicates, ranging\nfrom topology and connectivity to directionality and orientation, expressed in\na formalism related to natural language. The derived predicates form a spatial\nknowledge graph and, in combination with a pipeline-based inference model,\nenable spatial queries and dynamic rule evaluation. Implementations for client-\nand server-side processing demonstrate the framework's capability to\nefficiently translate geometric data into actionable knowledge, ensuring\nscalable and technology-independent spatial reasoning in complex 3D\nenvironments. The Spatial Reasoner framework is fostering the creation of\nspatial ontologies, and seamlessly integrates with and therefore enriches\nmachine learning, natural language processing, and rule systems in XR\napplications.",
      "pdf_url": "http://arxiv.org/pdf/2504.18380v1",
      "published": "2025-04-25T14:27:27+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.18380v1",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.GR",
        "cs.HC",
        "spatial computing, extended reality, knowledge representation,\n  spatial reasoning"
      ]
    },
    {
      "title": "Pushing the boundary on Natural Language Inference",
      "authors": [
        "Pablo Miralles-González",
        "Javier Huertas-Tato",
        "Alejandro Martín",
        "David Camacho"
      ],
      "abstract": "Natural Language Inference (NLI) is a central task in natural language\nunderstanding with applications in fact-checking, question answering, and\ninformation retrieval. Despite its importance, current NLI systems heavily rely\non supervised learning with datasets that often contain annotation artifacts\nand biases, limiting generalization and real-world applicability. In this work,\nwe apply a reinforcement learning-based approach using Group Relative Policy\nOptimization (GRPO) for Chain-of-Thought (CoT) learning in NLI, eliminating the\nneed for labeled rationales and enabling this type of training on more\nchallenging datasets such as ANLI. We fine-tune 7B, 14B, and 32B language\nmodels using parameter-efficient techniques (LoRA and QLoRA), demonstrating\nstrong performance across standard and adversarial NLI benchmarks. Our 32B\nAWQ-quantized model surpasses state-of-the-art results on 7 out of 11\nadversarial sets$\\unicode{x2013}$or on all of them considering our\nreplication$\\unicode{x2013}$within a 22GB memory footprint, showing that robust\nreasoning can be retained under aggressive quantization. This work provides a\nscalable and practical framework for building robust NLI systems without\nsacrificing inference quality.",
      "pdf_url": "http://arxiv.org/pdf/2504.18376v1",
      "published": "2025-04-25T14:20:57+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.18376v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "COCO-Inpaint: A Benchmark for Image Inpainting Detection and Manipulation Localization",
      "authors": [
        "Haozhen Yan",
        "Yan Hong",
        "Jiahui Zhan",
        "Yikun Ji",
        "Jun Lan",
        "Huijia Zhu",
        "Weiqiang Wang",
        "Jianfu Zhang"
      ],
      "abstract": "Recent advancements in image manipulation have achieved unprecedented\nprogress in generating photorealistic content, but also simultaneously\neliminating barriers to arbitrary manipulation and editing, raising concerns\nabout multimedia authenticity and cybersecurity. However, existing Image\nManipulation Detection and Localization (IMDL) methodologies predominantly\nfocus on splicing or copy-move forgeries, lacking dedicated benchmarks for\ninpainting-based manipulations. To bridge this gap, we present COCOInpaint, a\ncomprehensive benchmark specifically designed for inpainting detection, with\nthree key contributions: 1) High-quality inpainting samples generated by six\nstate-of-the-art inpainting models, 2) Diverse generation scenarios enabled by\nfour mask generation strategies with optional text guidance, and 3) Large-scale\ncoverage with 258,266 inpainted images with rich semantic diversity. Our\nbenchmark is constructed to emphasize intrinsic inconsistencies between\ninpainted and authentic regions, rather than superficial semantic artifacts\nsuch as object shapes. We establish a rigorous evaluation protocol using three\nstandard metrics to assess existing IMDL approaches. The dataset will be made\npublicly available to facilitate future research in this area.",
      "pdf_url": "http://arxiv.org/pdf/2504.18361v1",
      "published": "2025-04-25T14:04:36+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.18361v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Testing Individual Fairness in Graph Neural Networks",
      "authors": [
        "Roya Nasiri"
      ],
      "abstract": "The biases in artificial intelligence (AI) models can lead to automated\ndecision-making processes that discriminate against groups and/or individuals\nbased on sensitive properties such as gender and race. While there are many\nstudies on diagnosing and mitigating biases in various AI models, there is\nlittle research on individual fairness in Graph Neural Networks (GNNs). Unlike\ntraditional models, which treat data features independently and overlook their\ninter-relationships, GNNs are designed to capture graph-based structure where\nnodes are interconnected. This relational approach enables GNNs to model\ncomplex dependencies, but it also means that biases can propagate through these\nconnections, complicating the detection and mitigation of individual fairness\nviolations. This PhD project aims to develop a testing framework to assess and\nensure individual fairness in GNNs. It first systematically reviews the\nliterature on individual fairness, categorizing existing approaches to define,\nmeasure, test, and mitigate model biases, creating a taxonomy of individual\nfairness. Next, the project will develop a framework for testing and ensuring\nfairness in GNNs by adapting and extending current fairness testing and\nmitigation techniques. The framework will be evaluated through industrial case\nstudies, focusing on graph-based large language models.",
      "pdf_url": "http://arxiv.org/pdf/2504.18353v1",
      "published": "2025-04-25T13:45:24+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.18353v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "TSCL:Multi-party loss Balancing scheme for deep learning Image steganography based on Curriculum learning",
      "authors": [
        "Fengchun Liu. Tong Zhang",
        "Chunying Zhang"
      ],
      "abstract": "For deep learning-based image steganography frameworks, in order to ensure\nthe invisibility and recoverability of the information embedding, the loss\nfunction usually contains several losses such as embedding loss, recovery loss\nand steganalysis loss. In previous research works, fixed loss weights are\nusually chosen for training optimization, and this setting is not linked to the\nimportance of the steganography task itself and the training process. In this\npaper, we propose a Two-stage Curriculum Learning loss scheduler (TSCL) for\nbalancing multinomial losses in deep learning image steganography algorithms.\nTSCL consists of two phases: a priori curriculum control and loss dynamics\ncontrol. The first phase firstly focuses the model on learning the information\nembedding of the original image by controlling the loss weights in the\nmulti-party adversarial training; secondly, it makes the model shift its\nlearning focus to improving the decoding accuracy; and finally, it makes the\nmodel learn to generate a steganographic image that is resistant to\nsteganalysis. In the second stage, the learning speed of each training task is\nevaluated by calculating the loss drop of the before and after iteration rounds\nto balance the learning of each task. Experimental results on three large\npublic datasets, ALASKA2, VOC2012 and ImageNet, show that the proposed TSCL\nstrategy improves the quality of steganography, decoding accuracy and security.",
      "pdf_url": "http://arxiv.org/pdf/2504.18348v1",
      "published": "2025-04-25T13:36:50+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.18348v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR"
      ]
    },
    {
      "title": "Comparing Uncertainty Measurement and Mitigation Methods for Large Language Models: A Systematic Review",
      "authors": [
        "Toghrul Abbasli",
        "Kentaroh Toyoda",
        "Yuan Wang",
        "Leon Witt",
        "Muhammad Asif Ali",
        "Yukai Miao",
        "Dan Li",
        "Qingsong Wei"
      ],
      "abstract": "Large Language Models (LLMs) have been transformative across many domains.\nHowever, hallucination -- confidently outputting incorrect information --\nremains one of the leading challenges for LLMs. This raises the question of how\nto accurately assess and quantify the uncertainty of LLMs. Extensive literature\non traditional models has explored Uncertainty Quantification (UQ) to measure\nuncertainty and employed calibration techniques to address the misalignment\nbetween uncertainty and accuracy. While some of these methods have been adapted\nfor LLMs, the literature lacks an in-depth analysis of their effectiveness and\ndoes not offer a comprehensive benchmark to enable insightful comparison among\nexisting solutions. In this work, we fill this gap via a systematic survey of\nrepresentative prior works on UQ and calibration for LLMs and introduce a\nrigorous benchmark. Using two widely used reliability datasets, we empirically\nevaluate six related methods, which justify the significant findings of our\nreview. Finally, we provide outlooks for key future directions and outline open\nchallenges. To the best of our knowledge, this survey is the first dedicated\nstudy to review the calibration methods and relevant metrics for LLMs.",
      "pdf_url": "http://arxiv.org/pdf/2504.18346v1",
      "published": "2025-04-25T13:34:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.18346v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "PHEATPRUNER: Interpretable Data-centric Feature Selection for Multivariate Time Series Classification through Persistent Homology",
      "authors": [
        "Anh-Duy Pham",
        "Olivier Basole Kashongwe",
        "Martin Atzmueller",
        "Tim Römer"
      ],
      "abstract": "Balancing performance and interpretability in multivariate time series\nclassification is a significant challenge due to data complexity and high\ndimensionality. This paper introduces PHeatPruner, a method integrating\npersistent homology and sheaf theory to address these challenges. Persistent\nhomology facilitates the pruning of up to 45% of the applied variables while\nmaintaining or enhancing the accuracy of models such as Random Forest,\nCatBoost, XGBoost, and LightGBM, all without depending on posterior\nprobabilities or supervised optimization algorithms. Concurrently, sheaf theory\ncontributes explanatory vectors that provide deeper insights into the data's\nstructural nuances. The approach was validated using the UEA Archive and a\nmastitis detection dataset for dairy cows. The results demonstrate that\nPHeatPruner effectively preserves model accuracy. Furthermore, our results\nhighlight PHeatPruner's key features, i.e. simplifying complex data and\noffering actionable insights without increasing processing time or complexity.\nThis method bridges the gap between complexity reduction and interpretability,\nsuggesting promising applications in various fields.",
      "pdf_url": "http://arxiv.org/pdf/2504.18329v1",
      "published": "2025-04-25T13:14:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.18329v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Towards Adaptive Software Agents for Debugging",
      "authors": [
        "Yacine Majdoub",
        "Eya Ben Charrada",
        "Haifa Touati"
      ],
      "abstract": "Using multiple agents was found to improve the debugging capabilities of\nLarge Language Models. However, increasing the number of LLM-agents has several\ndrawbacks such as increasing the running costs and rising the risk for the\nagents to lose focus. In this work, we propose an adaptive agentic design,\nwhere the number of agents and their roles are determined dynamically based on\nthe characteristics of the task to be achieved. In this design, the agents\nroles are not predefined, but are generated after analyzing the problem to be\nsolved. Our initial evaluation shows that, with the adaptive design, the number\nof agents that are generated depends on the complexity of the buggy code. In\nfact, for simple code with mere syntax issues, the problem was usually fixed\nusing one agent only. However, for more complex problems, we noticed the\ncreation of a higher number of agents. Regarding the effectiveness of the fix,\nwe noticed an average improvement of 11% compared to the one-shot prompting.\nGiven these promising results, we outline future research directions to improve\nour design for adaptive software agents that can autonomously plan and conduct\ntheir software goals.",
      "pdf_url": "http://arxiv.org/pdf/2504.18316v1",
      "published": "2025-04-25T12:48:08+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.18316v1",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "Artificial Intelligence health advice accuracy varies across languages and contexts",
      "authors": [
        "Prashant Garg",
        "Thiemo Fetzer"
      ],
      "abstract": "Using basic health statements authorized by UK and EU registers and 9,100\njournalist-vetted public-health assertions on topics such as abortion, COVID-19\nand politics from sources ranging from peer-reviewed journals and government\nadvisories to social media and news across the political spectrum, we benchmark\nsix leading large language models from in 21 languages, finding that, despite\nhigh accuracy on English-centric textbook claims, performance falls in multiple\nnon-European languages and fluctuates by topic and source, highlighting the\nurgency of comprehensive multilingual, domain-aware validation before deploying\nAI in global health communication.",
      "pdf_url": "http://arxiv.org/pdf/2504.18310v1",
      "published": "2025-04-25T12:37:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.18310v1",
      "categories": [
        "econ.GN",
        "cs.AI",
        "cs.CY",
        "cs.HC",
        "cs.LG",
        "q-fin.EC"
      ]
    },
    {
      "title": "Enhancing Long-Term Re-Identification Robustness Using Synthetic Data: A Comparative Analysis",
      "authors": [
        "Christian Pionzewski",
        "Rebecca Rademacher",
        "Jérôme Rutinowski",
        "Antonia Ponikarov",
        "Stephan Matzke",
        "Tim Chilla",
        "Pia Schreynemackers",
        "Alice Kirchheim"
      ],
      "abstract": "This contribution explores the impact of synthetic training data usage and\nthe prediction of material wear and aging in the context of re-identification.\nDifferent experimental setups and gallery set expanding strategies are tested,\nanalyzing their impact on performance over time for aging re-identification\nsubjects. Using a continuously updating gallery, we were able to increase our\nmean Rank-1 accuracy by 24%, as material aging was taken into account step by\nstep. In addition, using models trained with 10% artificial training data,\nRank-1 accuracy could be increased by up to 13%, in comparison to a model\ntrained on only real-world data, significantly boosting generalized performance\non hold-out data. Finally, this work introduces a novel, open-source\nre-identification dataset, pallet-block-2696. This dataset contains 2,696\nimages of Euro pallets, taken over a period of 4 months. During this time,\nnatural aging processes occurred and some of the pallets were damaged during\ntheir usage. These wear and tear processes significantly changed the appearance\nof the pallets, providing a dataset that can be used to generate synthetically\naged pallets or other wooden materials.",
      "pdf_url": "http://arxiv.org/pdf/2504.18286v1",
      "published": "2025-04-25T11:57:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.18286v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "I.2.10; I.4.9"
      ]
    },
    {
      "title": "Seeing Soundscapes: Audio-Visual Generation and Separation from Soundscapes Using Audio-Visual Separator",
      "authors": [
        "Minjae Kang",
        "Martim Brandão"
      ],
      "abstract": "Recent audio-visual generative models have made substantial progress in\ngenerating images from audio. However, existing approaches focus on generating\nimages from single-class audio and fail to generate images from mixed audio. To\naddress this, we propose an Audio-Visual Generation and Separation model\n(AV-GAS) for generating images from soundscapes (mixed audio containing\nmultiple classes). Our contribution is threefold: First, we propose a new\nchallenge in the audio-visual generation task, which is to generate an image\ngiven a multi-class audio input, and we propose a method that solves this task\nusing an audio-visual separator. Second, we introduce a new audio-visual\nseparation task, which involves generating separate images for each class\npresent in a mixed audio input. Lastly, we propose new evaluation metrics for\nthe audio-visual generation task: Class Representation Score (CRS) and a\nmodified R@K. Our model is trained and evaluated on the VGGSound dataset. We\nshow that our method outperforms the state-of-the-art, achieving 7% higher CRS\nand 4% higher R@2* in generating plausible images with mixed audio.",
      "pdf_url": "http://arxiv.org/pdf/2504.18283v1",
      "published": "2025-04-25T11:51:04+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.18283v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM",
        "cs.SD",
        "eess.AS"
      ]
    },
    {
      "title": "LEAM: A Prompt-only Large Language Model-enabled Antenna Modeling Method",
      "authors": [
        "Tao Wu",
        "Kexue Fu",
        "Qiang Hua",
        "Xinxin Liu",
        "Muhammad Ali Imran",
        "Bo Liu"
      ],
      "abstract": "Antenna modeling is a time-consuming and complex process, decreasing the\nspeed of antenna analysis and design. In this paper, a large language model\n(LLM)- enabled antenna modeling method, called LEAM, is presented to address\nthis challenge. LEAM enables automatic antenna model generation based on\nlanguage descriptions via prompt input, images, descriptions from academic\npapers, patents, and technical reports (either one or multiple). The\neffectiveness of LEAM is demonstrated by three examples: a Vivaldi antenna\ngenerated from a complete user description, a slotted patch antenna generated\nfrom an incomplete user description and the operating frequency, and a monopole\nslotted antenna generated from images and descriptions scanned from the\nliterature. For all the examples, correct antenna models are generated in a few\nminutes. The code can be accessed via https://github.com/TaoWu974/LEAM.",
      "pdf_url": "http://arxiv.org/pdf/2504.18271v1",
      "published": "2025-04-25T11:29:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.18271v1",
      "categories": [
        "cs.AI",
        "cs.ET",
        "cs.HC",
        "cs.SY",
        "eess.SY"
      ]
    },
    {
      "title": "Neural operators struggle to learn complex PDEs in pedestrian mobility: Hughes model case study",
      "authors": [
        "Prajwal Chauhan",
        "Salah Eddine Choutri",
        "Mohamed Ghattassi",
        "Nader Masmoudi",
        "Saif Eddin Jabari"
      ],
      "abstract": "This paper investigates the limitations of neural operators in learning\nsolutions for a Hughes model, a first-order hyperbolic conservation law system\nfor crowd dynamics. The model couples a Fokker-Planck equation representing\npedestrian density with a Hamilton-Jacobi-type (eikonal) equation. This Hughes\nmodel belongs to the class of nonlinear hyperbolic systems that often exhibit\ncomplex solution structures, including shocks and discontinuities. In this\nstudy, we assess the performance of three state-of-the-art neural operators\n(Fourier Neural Operator, Wavelet Neural Operator, and Multiwavelet Neural\nOperator) in various challenging scenarios. Specifically, we consider (1)\ndiscontinuous and Gaussian initial conditions and (2) diverse boundary\nconditions, while also examining the impact of different numerical schemes.\n  Our results show that these neural operators perform well in easy scenarios\nwith fewer discontinuities in the initial condition, yet they struggle in\ncomplex scenarios with multiple initial discontinuities and dynamic boundary\nconditions, even when trained specifically on such complex samples. The\npredicted solutions often appear smoother, resulting in a reduction in total\nvariation and a loss of important physical features. This smoothing behavior is\nsimilar to issues discussed by Daganzo (1995), where models that introduce\nartificial diffusion were shown to miss essential features such as shock waves\nin hyperbolic systems. These results suggest that current neural operator\narchitectures may introduce unintended regularization effects that limit their\nability to capture transport dynamics governed by discontinuities. They also\nraise concerns about generalizing these methods to traffic applications where\nshock preservation is essential.",
      "pdf_url": "http://arxiv.org/pdf/2504.18267v1",
      "published": "2025-04-25T11:26:41+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.18267v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Depth-Constrained ASV Navigation with Deep RL and Limited Sensing",
      "authors": [
        "Amirhossein Zhalehmehrabi",
        "Daniele Meli",
        "Francesco Dal Santo",
        "Francesco Trotti",
        "Alessandro Farinelli"
      ],
      "abstract": "Autonomous Surface Vehicles (ASVs) play a crucial role in maritime\noperations, yet their navigation in shallow-water environments remains\nchallenging due to dynamic disturbances and depth constraints. Traditional\nnavigation strategies struggle with limited sensor information, making safe and\nefficient operation difficult. In this paper, we propose a reinforcement\nlearning (RL) framework for ASV navigation under depth constraints, where the\nvehicle must reach a target while avoiding unsafe areas with only a single\ndepth measurement per timestep from a downward-facing Single Beam Echosounder\n(SBES). To enhance environmental awareness, we integrate Gaussian Process (GP)\nregression into the RL framework, enabling the agent to progressively estimate\na bathymetric depth map from sparse sonar readings. This approach improves\ndecision-making by providing a richer representation of the environment.\nFurthermore, we demonstrate effective sim-to-real transfer, ensuring that\ntrained policies generalize well to real-world aquatic conditions. Experimental\nresults validate our method's capability to improve ASV navigation performance\nwhile maintaining safety in challenging shallow-water environments.",
      "pdf_url": "http://arxiv.org/pdf/2504.18253v1",
      "published": "2025-04-25T10:56:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.18253v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "Event-Based Eye Tracking. 2025 Event-based Vision Workshop",
      "authors": [
        "Qinyu Chen",
        "Chang Gao",
        "Min Liu",
        "Daniele Perrone",
        "Yan Ru Pei",
        "Zuowen Wang",
        "Zhuo Zou",
        "Shihang Tan",
        "Tao Han",
        "Guorui Lu",
        "Zhen Xu",
        "Junyuan Ding",
        "Ziteng Wang",
        "Zongwei Wu",
        "Han Han",
        "Yuliang Wu",
        "Jinze Chen",
        "Wei Zhai",
        "Yang Cao",
        "Zheng-jun Zha",
        "Nuwan Bandara",
        "Thivya Kandappu",
        "Archan Misra",
        "Xiaopeng Lin",
        "Hongxiang Huang",
        "Hongwei Ren",
        "Bojun Cheng",
        "Hoang M. Truong",
        "Vinh-Thuan Ly",
        "Huy G. Tran",
        "Thuan-Phat Nguyen",
        "Tram T. Doan"
      ],
      "abstract": "This survey serves as a review for the 2025 Event-Based Eye Tracking\nChallenge organized as part of the 2025 CVPR event-based vision workshop. This\nchallenge focuses on the task of predicting the pupil center by processing\nevent camera recorded eye movement. We review and summarize the innovative\nmethods from teams rank the top in the challenge to advance future event-based\neye tracking research. In each method, accuracy, model size, and number of\noperations are reported. In this survey, we also discuss event-based eye\ntracking from the perspective of hardware design.",
      "pdf_url": "http://arxiv.org/pdf/2504.18249v1",
      "published": "2025-04-25T10:50:14+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.18249v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Efficient Single-Pass Training for Multi-Turn Reasoning",
      "authors": [
        "Ritesh Goru",
        "Shanay Mehta",
        "Prateek Jain"
      ],
      "abstract": "Training Large Language Models ( LLMs) to generate explicit reasoning before\nthey produce an answer has been shown to improve their performance across\nvarious tasks such as mathematics and coding. However, fine-tuning LLMs on\nmulti-turn reasoning datasets presents a unique challenge: LLMs must generate\nreasoning tokens that are excluded from subsequent inputs to the LLM. This\ndiscrepancy prevents us from processing an entire conversation in a single\nforward pass-an optimization readily available when we fine-tune on a\nmulti-turn non-reasoning dataset. This paper proposes a novel approach that\novercomes this limitation through response token duplication and a custom\nattention mask that enforces appropriate visibility constraints. Our approach\nsignificantly reduces the training time and allows efficient fine-tuning on\nmulti-turn reasoning datasets.",
      "pdf_url": "http://arxiv.org/pdf/2504.18246v1",
      "published": "2025-04-25T10:46:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.18246v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Time and Frequency Domain-based Anomaly Detection in Smart Meter Data for Distribution Network Studies",
      "authors": [
        "Petar Labura",
        "Tomislav Antic",
        "Tomislav Capuder"
      ],
      "abstract": "The widespread integration of new technologies in low-voltage distribution\nnetworks on the consumer side creates the need for distribution system\noperators to perform advanced real-time calculations to estimate network\nconditions. In recent years, data-driven models based on machine learning and\nbig data analysis have emerged for calculation purposes, leveraging the\ninformation available in large datasets obtained from smart meters and other\nadvanced measurement infrastructure. However, existing data-driven algorithms\ndo not take into account the quality of data collected from smart meters. They\nlack built-in anomaly detection mechanisms and fail to differentiate anomalies\nbased on whether the value or context of anomalous data instances deviates from\nthe norm. This paper focuses on methods for detecting and mitigating the impact\nof anomalies on the consumption of active and reactive power datasets. It\nproposes an anomaly detection framework based on the Isolation Forest machine\nlearning algorithm and Fast Fourier Transform filtering that works in both the\ntime and frequency domain and is unaffected by point anomalies or contextual\nanomalies of the power consumption data. The importance of integrating anomaly\ndetection methods is demonstrated in the analysis important for distribution\nnetworks with a high share of smart meters.",
      "pdf_url": "http://arxiv.org/pdf/2504.18231v1",
      "published": "2025-04-25T10:26:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.18231v1",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.LG",
        "cs.SY"
      ]
    },
    {
      "title": "Learning to fuse: dynamic integration of multi-source data for accurate battery lifespan prediction",
      "authors": [
        "He Shanxuan",
        "Lin Zuhong",
        "Yu Bolun",
        "Gao Xu",
        "Long Biao",
        "Yao Jingjing"
      ],
      "abstract": "Accurate prediction of lithium-ion battery lifespan is vital for ensuring\noperational reliability and reducing maintenance costs in applications like\nelectric vehicles and smart grids. This study presents a hybrid learning\nframework for precise battery lifespan prediction, integrating dynamic\nmulti-source data fusion with a stacked ensemble (SE) modeling approach. By\nleveraging heterogeneous datasets from the National Aeronautics and Space\nAdministration (NASA), Center for Advanced Life Cycle Engineering (CALCE),\nMIT-Stanford-Toyota Research Institute (TRC), and nickel cobalt aluminum (NCA)\nchemistries, an entropy-based dynamic weighting mechanism mitigates variability\nacross heterogeneous datasets. The SE model combines Ridge regression, long\nshort-term memory (LSTM) networks, and eXtreme Gradient Boosting (XGBoost),\neffectively capturing temporal dependencies and nonlinear degradation patterns.\nIt achieves a mean absolute error (MAE) of 0.0058, root mean square error\n(RMSE) of 0.0092, and coefficient of determination (R2) of 0.9839,\noutperforming established baseline models with a 46.2% improvement in R2 and an\n83.2% reduction in RMSE. Shapley additive explanations (SHAP) analysis\nidentifies differential discharge capacity (Qdlin) and temperature of\nmeasurement (Temp_m) as critical aging indicators. This scalable, interpretable\nframework enhances battery health management, supporting optimized maintenance\nand safety across diverse energy storage systems, thereby contributing to\nimproved battery health management in energy storage systems.",
      "pdf_url": "http://arxiv.org/pdf/2504.18230v1",
      "published": "2025-04-25T10:24:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.18230v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Multi-Grained Compositional Visual Clue Learning for Image Intent Recognition",
      "authors": [
        "Yin Tang",
        "Jiankai Li",
        "Hongyu Yang",
        "Xuan Dong",
        "Lifeng Fan",
        "Weixin Li"
      ],
      "abstract": "In an era where social media platforms abound, individuals frequently share\nimages that offer insights into their intents and interests, impacting\nindividual life quality and societal stability. Traditional computer vision\ntasks, such as object detection and semantic segmentation, focus on concrete\nvisual representations, while intent recognition relies more on implicit visual\nclues. This poses challenges due to the wide variation and subjectivity of such\nclues, compounded by the problem of intra-class variety in conveying abstract\nconcepts, e.g. \"enjoy life\". Existing methods seek to solve the problem by\nmanually designing representative features or building prototypes for each\nclass from global features. However, these methods still struggle to deal with\nthe large visual diversity of each intent category. In this paper, we introduce\na novel approach named Multi-grained Compositional visual Clue Learning (MCCL)\nto address these challenges for image intent recognition. Our method leverages\nthe systematic compositionality of human cognition by breaking down intent\nrecognition into visual clue composition and integrating multi-grained\nfeatures. We adopt class-specific prototypes to alleviate data imbalance. We\ntreat intent recognition as a multi-label classification problem, using a graph\nconvolutional network to infuse prior knowledge through label embedding\ncorrelations. Demonstrated by a state-of-the-art performance on the Intentonomy\nand MDID datasets, our approach advances the accuracy of existing methods while\nalso possessing good interpretability. Our work provides an attempt for future\nexplorations in understanding complex and miscellaneous forms of human\nexpression.",
      "pdf_url": "http://arxiv.org/pdf/2504.18201v1",
      "published": "2025-04-25T09:31:03+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.18201v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Aligning Language Models for Icelandic Legal Text Summarization",
      "authors": [
        "Þórir Hrafn Harðarson",
        "Hrafn Loftsson",
        "Stefán Ólafsson"
      ],
      "abstract": "The integration of language models in the legal domain holds considerable\npromise for streamlining processes and improving efficiency in managing\nextensive workloads. However, the specialized terminology, nuanced language,\nand formal style of legal texts can present substantial challenges. This study\nexamines whether preference-based training techniques, specifically\nReinforcement Learning from Human Feedback and Direct Preference Optimization,\ncan enhance models' performance in generating Icelandic legal summaries that\nalign with domain-specific language standards and user preferences. We compare\nmodels fine-tuned with preference training to those using conventional\nsupervised learning. Results indicate that preference training improves the\nlegal accuracy of generated summaries over standard fine-tuning but does not\nsignificantly enhance the overall quality of Icelandic language usage.\nDiscrepancies between automated metrics and human evaluations further\nunderscore the importance of qualitative assessment in developing language\nmodels for the legal domain.",
      "pdf_url": "http://arxiv.org/pdf/2504.18180v1",
      "published": "2025-04-25T08:55:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.18180v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "PerfCam: Digital Twinning for Production Lines Using 3D Gaussian Splatting and Vision Models",
      "authors": [
        "Michel Gokan Khan",
        "Renan Guarese",
        "Fabian Johnson",
        "Xi Vincent Wang",
        "Anders Bergman",
        "Benjamin Edvinsson",
        "Mario Romero",
        "Jérémy Vachier",
        "Jan Kronqvist"
      ],
      "abstract": "We introduce PerfCam, an open source Proof-of-Concept (PoC) digital twinning\nframework that combines camera and sensory data with 3D Gaussian Splatting and\ncomputer vision models for digital twinning, object tracking, and Key\nPerformance Indicators (KPIs) extraction in industrial production lines. By\nutilizing 3D reconstruction and Convolutional Neural Networks (CNNs), PerfCam\noffers a semi-automated approach to object tracking and spatial mapping,\nenabling digital twins that capture real-time KPIs such as availability,\nperformance, Overall Equipment Effectiveness (OEE), and rate of conveyor belts\nin the production line. We validate the effectiveness of PerfCam through a\npractical deployment within realistic test production lines in the\npharmaceutical industry and contribute an openly published dataset to support\nfurther research and development in the field. The results demonstrate\nPerfCam's ability to deliver actionable insights through its precise digital\ntwin capabilities, underscoring its value as an effective tool for developing\nusable digital twins in smart manufacturing environments and extracting\noperational analytics.",
      "pdf_url": "http://arxiv.org/pdf/2504.18165v1",
      "published": "2025-04-25T08:29:00+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.18165v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Offline Learning of Controllable Diverse Behaviors",
      "authors": [
        "Mathieu Petitbois",
        "Rémy Portelas",
        "Sylvain Lamprier",
        "Ludovic Denoyer"
      ],
      "abstract": "Imitation Learning (IL) techniques aim to replicate human behaviors in\nspecific tasks. While IL has gained prominence due to its effectiveness and\nefficiency, traditional methods often focus on datasets collected from experts\nto produce a single efficient policy. Recently, extensions have been proposed\nto handle datasets of diverse behaviors by mainly focusing on learning\ntransition-level diverse policies or on performing entropy maximization at the\ntrajectory level. While these methods may lead to diverse behaviors, they may\nnot be sufficient to reproduce the actual diversity of demonstrations or to\nallow controlled trajectory generation. To overcome these drawbacks, we propose\na different method based on two key features: a) Temporal Consistency that\nensures consistent behaviors across entire episodes and not just at the\ntransition level as well as b) Controllability obtained by constructing a\nlatent space of behaviors that allows users to selectively activate specific\nbehaviors based on their requirements. We compare our approach to\nstate-of-the-art methods over a diverse set of tasks and environments. Project\npage: https://mathieu-petitbois.github.io/projects/swr/",
      "pdf_url": "http://arxiv.org/pdf/2504.18160v1",
      "published": "2025-04-25T08:16:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.18160v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ]
    },
    {
      "title": "EDU-NER-2025: Named Entity Recognition in Urdu Educational Texts using XLM-RoBERTa with X (formerly Twitter)",
      "authors": [
        "Fida Ullah",
        "Muhammad Ahmad",
        "Muhammad Tayyab Zamir",
        "Muhammad Arif",
        "Grigori sidorov",
        "Edgardo Manuel Felipe Riverón",
        "Alexander Gelbukh"
      ],
      "abstract": "Named Entity Recognition (NER) plays a pivotal role in various Natural\nLanguage Processing (NLP) tasks by identifying and classifying named entities\n(NEs) from unstructured data into predefined categories such as person,\norganization, location, date, and time. While extensive research exists for\nhigh-resource languages and general domains, NER in Urdu particularly within\ndomain-specific contexts like education remains significantly underexplored.\nThis is Due to lack of annotated datasets for educational content which limits\nthe ability of existing models to accurately identify entities such as academic\nroles, course names, and institutional terms, underscoring the urgent need for\ntargeted resources in this domain. To the best of our knowledge, no dataset\nexists in the domain of the Urdu language for this purpose. To achieve this\nobjective this study makes three key contributions. Firstly, we created a\nmanually annotated dataset in the education domain, named EDU-NER-2025, which\ncontains 13 unique most important entities related to education domain. Second,\nwe describe our annotation process and guidelines in detail and discuss the\nchallenges of labelling EDU-NER-2025 dataset. Third, we addressed and analyzed\nkey linguistic challenges, such as morphological complexity and ambiguity,\nwhich are prevalent in formal Urdu texts.",
      "pdf_url": "http://arxiv.org/pdf/2504.18142v1",
      "published": "2025-04-25T07:50:58+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.18142v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Evaluating Evaluation Metrics -- The Mirage of Hallucination Detection",
      "authors": [
        "Atharva Kulkarni",
        "Yuan Zhang",
        "Joel Ruben Antony Moniz",
        "Xiou Ge",
        "Bo-Hsiang Tseng",
        "Dhivya Piraviperumal",
        "Swabha Swayamdipta",
        "Hong Yu"
      ],
      "abstract": "Hallucinations pose a significant obstacle to the reliability and widespread\nadoption of language models, yet their accurate measurement remains a\npersistent challenge. While many task- and domain-specific metrics have been\nproposed to assess faithfulness and factuality concerns, the robustness and\ngeneralization of these metrics are still untested. In this paper, we conduct a\nlarge-scale empirical evaluation of 6 diverse sets of hallucination detection\nmetrics across 4 datasets, 37 language models from 5 families, and 5 decoding\nmethods. Our extensive investigation reveals concerning gaps in current\nhallucination evaluation: metrics often fail to align with human judgments,\ntake an overtly myopic view of the problem, and show inconsistent gains with\nparameter scaling. Encouragingly, LLM-based evaluation, particularly with\nGPT-4, yields the best overall results, and mode-seeking decoding methods seem\nto reduce hallucinations, especially in knowledge-grounded settings. These\nfindings underscore the need for more robust metrics to understand and quantify\nhallucinations, and better strategies to mitigate them.",
      "pdf_url": "http://arxiv.org/pdf/2504.18114v1",
      "published": "2025-04-25T06:37:29+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.18114v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Learning from Less: SINDy Surrogates in RL",
      "authors": [
        "Aniket Dixit",
        "Muhammad Ibrahim Khan",
        "Faizan Ahmed",
        "James Brusey"
      ],
      "abstract": "This paper introduces an approach for developing surrogate environments in\nreinforcement learning (RL) using the Sparse Identification of Nonlinear\nDynamics (SINDy) algorithm. We demonstrate the effectiveness of our approach\nthrough extensive experiments in OpenAI Gym environments, particularly Mountain\nCar and Lunar Lander. Our results show that SINDy-based surrogate models can\naccurately capture the underlying dynamics of these environments while reducing\ncomputational costs by 20-35%. With only 75 interactions for Mountain Car and\n1000 for Lunar Lander, we achieve state-wise correlations exceeding 0.997, with\nmean squared errors as low as 3.11e-06 for Mountain Car velocity and 1.42e-06\nfor LunarLander position. RL agents trained in these surrogate environments\nrequire fewer total steps (65,075 vs. 100,000 for Mountain Car and 801,000 vs.\n1,000,000 for Lunar Lander) while achieving comparable performance to those\ntrained in the original environments, exhibiting similar convergence patterns\nand final performance metrics. This work contributes to the field of\nmodel-based RL by providing an efficient method for generating accurate,\ninterpretable surrogate environments.",
      "pdf_url": "http://arxiv.org/pdf/2504.18113v1",
      "published": "2025-04-25T06:34:19+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.18113v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Application and Optimization of Large Models Based on Prompt Tuning for Fact-Check-Worthiness Estimation",
      "authors": [
        "Yinglong Yu",
        "Hao Shen",
        "Zhengyi Lyu",
        "Qi He"
      ],
      "abstract": "In response to the growing problem of misinformation in the context of\nglobalization and informatization, this paper proposes a classification method\nfor fact-check-worthiness estimation based on prompt tuning. We construct a\nmodel for fact-check-worthiness estimation at the methodological level using\nprompt tuning. By applying designed prompt templates to large language models,\nwe establish in-context learning and leverage prompt tuning technology to\nimprove the accuracy of determining whether claims have fact-check-worthiness,\nparticularly when dealing with limited or unlabeled data. Through extensive\nexperiments on public datasets, we demonstrate that the proposed method\nsurpasses or matches multiple baseline methods in the classification task of\nfact-check-worthiness estimation assessment, including classical pre-trained\nmodels such as BERT, as well as recent popular large models like GPT-3.5 and\nGPT-4. Experiments show that the prompt tuning-based method proposed in this\nstudy exhibits certain advantages in evaluation metrics such as F1 score and\naccuracy, thereby effectively validating its effectiveness and advancement in\nthe task of fact-check-worthiness estimation.",
      "pdf_url": "http://arxiv.org/pdf/2504.18104v1",
      "published": "2025-04-25T06:16:41+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.18104v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Combating the Bucket Effect:Multi-Knowledge Alignment for Medication Recommendation",
      "authors": [
        "Xiang Li",
        "Haixu Ma",
        "Guanyong Wu",
        "Shi Mu",
        "Chen Li",
        "Shunpan Liang"
      ],
      "abstract": "Medication recommendation is crucial in healthcare, offering effective\ntreatments based on patient's electronic health records (EHR). Previous studies\nshow that integrating more medication-related knowledge improves medication\nrepresentation accuracy. However, not all medications encompass multiple types\nof knowledge data simultaneously. For instance, some medications provide only\ntextual descriptions without structured data. This imbalance in data\navailability limits the performance of existing models, a challenge we term the\n\"bucket effect\" in medication recommendation. Our data analysis uncovers the\nseverity of the \"bucket effect\" in medication recommendation. To fill this gap,\nwe introduce a cross-modal medication encoder capable of seamlessly aligning\ndata from different modalities and propose a medication recommendation\nframework to integrate Multiple types of Knowledge, named MKMed. Specifically,\nwe first pre-train a cross-modal encoder with contrastive learning on five\nknowledge modalities, aligning them into a unified space. Then, we combine the\nmulti-knowledge medication representations with patient records for\nrecommendations. Extensive experiments on the MIMIC-III and MIMIC-IV datasets\ndemonstrate that MKMed mitigates the \"bucket effect\" in data, and significantly\noutperforms state-of-the-art baselines in recommendation accuracy and safety.",
      "pdf_url": "http://arxiv.org/pdf/2504.18096v1",
      "published": "2025-04-25T05:47:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.18096v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Random-Set Large Language Models",
      "authors": [
        "Muhammad Mubashar",
        "Shireen Kudukkil Manchingal",
        "Fabio Cuzzolin"
      ],
      "abstract": "Large Language Models (LLMs) are known to produce very high-quality tests and\nresponses to our queries. But how much can we trust this generated text? In\nthis paper, we study the problem of uncertainty quantification in LLMs. We\npropose a novel Random-Set Large Language Model (RSLLM) approach which predicts\nfinite random sets (belief functions) over the token space, rather than\nprobability vectors as in classical LLMs. In order to allow so efficiently, we\nalso present a methodology based on hierarchical clustering to extract and use\na budget of \"focal\" subsets of tokens upon which the belief prediction is\ndefined, rather than using all possible collections of tokens, making the\nmethod scalable yet effective. RS-LLMs encode the epistemic uncertainty induced\nin their generation process by the size and diversity of its training set via\nthe size of the credal sets associated with the predicted belief functions. The\nproposed approach is evaluated on CoQA and OBQA datasets using Llama2-7b,\nMistral-7b and Phi-2 models and is shown to outperform the standard model in\nboth datasets in terms of correctness of answer while also showing potential in\nestimating the second level uncertainty in its predictions and providing the\ncapability to detect when its hallucinating.",
      "pdf_url": "http://arxiv.org/pdf/2504.18085v1",
      "published": "2025-04-25T05:25:27+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.18085v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "I.2.7"
      ]
    },
    {
      "title": "Efficient GNN Training Through Structure-Aware Randomized Mini-Batching",
      "authors": [
        "Vignesh Balaji",
        "Christos Kozyrakis",
        "Gal Chechik",
        "Haggai Maron"
      ],
      "abstract": "Graph Neural Networks (GNNs) enable learning on realworld graphs and\nmini-batch training has emerged as the de facto standard for training GNNs\nbecause it can scale to very large graphs and improve convergence. Current\nmini-batch construction policies largely ignore efficiency considerations of\nGNN training. Specifically, existing mini-batching techniques employ\nrandomization schemes to improve accuracy and convergence. However, these\nrandomization schemes are often agnostic to the structural properties of the\ngraph (for eg. community structure), resulting in highly irregular memory\naccess patterns during GNN training that make suboptimal use of on-chip GPU\ncaches. On the other hand, while deterministic mini-batching based solely on\ngraph structure delivers fast runtime performance, the lack of randomness\ncompromises both the final model accuracy and training convergence speed. In\nthis paper, we present Community-structure-aware Randomized Mini-batching\n(COMM-RAND), a novel methodology that bridges the gap between the above\nextremes. COMM-RAND allows practitioners to explore the space between pure\nrandomness and pure graph structural awareness during mini-batch construction,\nleading to significantly more efficient GNN training with similar accuracy. We\nevaluated COMM-RAND across four popular graph learning benchmarks. COMM-RAND\ncuts down GNN training time by up to 2.76x (1.8x on average) while achieving an\naccuracy that is within 1.79% points (0.42% on average) compared to popular\nrandom mini-batching approaches.",
      "pdf_url": "http://arxiv.org/pdf/2504.18082v1",
      "published": "2025-04-25T05:16:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.18082v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Stabilizing Reasoning in Medical LLMs with Continued Pretraining and Reasoning Preference Optimization",
      "authors": [
        "Wataru Kawakami",
        "Keita Suzuki",
        "Junichiro Iwasawa"
      ],
      "abstract": "Large Language Models (LLMs) show potential in medicine, yet clinical\nadoption is hindered by concerns over factual accuracy, language-specific\nlimitations (e.g., Japanese), and critically, their reliability when required\nto generate reasoning explanations -- a prerequisite for trust. This paper\nintroduces Preferred-MedLLM-Qwen-72B, a 72B-parameter model optimized for the\nJapanese medical domain to achieve both high accuracy and stable reasoning. We\nemploy a two-stage fine-tuning process on the Qwen2.5-72B base model: first,\nContinued Pretraining (CPT) on a comprehensive Japanese medical corpus instills\ndeep domain knowledge. Second, Reasoning Preference Optimization (RPO), a\npreference-based method, enhances the generation of reliable reasoning pathways\nwhile preserving high answer accuracy. Evaluations on the Japanese Medical\nLicensing Exam benchmark (IgakuQA) show Preferred-MedLLM-Qwen-72B achieves\nstate-of-the-art performance (0.868 accuracy), surpassing strong proprietary\nmodels like GPT-4o (0.866). Crucially, unlike baseline or CPT-only models which\nexhibit significant accuracy degradation (up to 11.5\\% and 3.8\\% respectively\non IgakuQA) when prompted for explanations, our model maintains its high\naccuracy (0.868) under such conditions. This highlights RPO's effectiveness in\nstabilizing reasoning generation. This work underscores the importance of\noptimizing for reliable explanations alongside accuracy. We release the\nPreferred-MedLLM-Qwen-72B model weights to foster research into trustworthy\nLLMs for specialized, high-stakes applications.",
      "pdf_url": "http://arxiv.org/pdf/2504.18080v1",
      "published": "2025-04-25T05:15:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.18080v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Privacy-Preserving Personalized Federated Learning for Distributed Photovoltaic Disaggregation under Statistical Heterogeneity",
      "authors": [
        "Xiaolu Chen",
        "Chenghao Huang",
        "Yanru Zhang",
        "Hao Wang"
      ],
      "abstract": "The rapid expansion of distributed photovoltaic (PV) installations worldwide,\nmany being behind-the-meter systems, has significantly challenged energy\nmanagement and grid operations, as unobservable PV generation further\ncomplicates the supply-demand balance. Therefore, estimating this generation\nfrom net load, known as PV disaggregation, is critical. Given privacy concerns\nand the need for large training datasets, federated learning becomes a\npromising approach, but statistical heterogeneity, arising from geographical\nand behavioral variations among prosumers, poses new challenges to PV\ndisaggregation. To overcome these challenges, a privacy-preserving distributed\nPV disaggregation framework is proposed using Personalized Federated Learning\n(PFL). The proposed method employs a two-level framework that combines local\nand global modeling. At the local level, a transformer-based PV disaggregation\nmodel is designed to generate solar irradiance embeddings for representing\nlocal PV conditions. A novel adaptive local aggregation mechanism is adopted to\nmitigate the impact of statistical heterogeneity on the local model, extracting\na portion of global information that benefits the local model. At the global\nlevel, a central server aggregates information uploaded from multiple data\ncenters, preserving privacy while enabling cross-center knowledge sharing.\nExperiments on real-world data demonstrate the effectiveness of this proposed\nframework, showing improved accuracy and robustness compared to benchmark\nmethods.",
      "pdf_url": "http://arxiv.org/pdf/2504.18078v1",
      "published": "2025-04-25T05:09:27+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.18078v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "PropRAG: Guiding Retrieval with Beam Search over Proposition Paths",
      "authors": [
        "Jingjin Wang"
      ],
      "abstract": "Retrieval Augmented Generation (RAG) has become the standard non-parametric\napproach for equipping Large Language Models (LLMs) with up-to-date knowledge\nand mitigating catastrophic forgetting common in continual learning. However,\nstandard RAG, relying on independent passage retrieval, fails to capture the\ninterconnected nature of human memory crucial for complex reasoning\n(associativity) and contextual understanding (sense-making). While structured\nRAG methods like HippoRAG utilize knowledge graphs (KGs) built from triples,\nthe inherent context loss limits fidelity. We introduce PropRAG, a framework\nleveraging contextually rich propositions and a novel beam search algorithm\nover proposition paths to explicitly discover multi-step reasoning chains.\nCrucially, PropRAG's online retrieval process operates entirely without\ninvoking generative LLMs, relying instead on efficient graph traversal and\npre-computed embeddings. This avoids online LLM inference costs and potential\ninconsistencies during evidence gathering. LLMs are used effectively offline\nfor high-quality proposition extraction and post-retrieval for answer\ngeneration. PropRAG achieves state-of-the-art zero-shot Recall@5 results on\nPopQA (55.3%), 2Wiki (93.7%), HotpotQA (97.0%), and MuSiQue (77.3%), alongside\ntop F1 scores (e.g., 52.4% on MuSiQue). By improving evidence retrieval through\nricher representation and explicit, LLM-free online path finding, PropRAG\nadvances non-parametric continual learning.",
      "pdf_url": "http://arxiv.org/pdf/2504.18070v1",
      "published": "2025-04-25T04:47:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.18070v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "S3MOT: Monocular 3D Object Tracking with Selective State Space Model",
      "authors": [
        "Zhuohao Yan",
        "Shaoquan Feng",
        "Xingxing Li",
        "Yuxuan Zhou",
        "Chunxi Xia",
        "Shengyu Li"
      ],
      "abstract": "Accurate and reliable multi-object tracking (MOT) in 3D space is essential\nfor advancing robotics and computer vision applications. However, it remains a\nsignificant challenge in monocular setups due to the difficulty of mining 3D\nspatiotemporal associations from 2D video streams. In this work, we present\nthree innovative techniques to enhance the fusion and exploitation of\nheterogeneous cues for monocular 3D MOT: (1) we introduce the Hungarian State\nSpace Model (HSSM), a novel data association mechanism that compresses\ncontextual tracking cues across multiple paths, enabling efficient and\ncomprehensive assignment decisions with linear complexity. HSSM features a\nglobal receptive field and dynamic weights, in contrast to traditional linear\nassignment algorithms that rely on hand-crafted association costs. (2) We\npropose Fully Convolutional One-stage Embedding (FCOE), which eliminates ROI\npooling by directly using dense feature maps for contrastive learning, thus\nimproving object re-identification accuracy under challenging conditions such\nas varying viewpoints and lighting. (3) We enhance 6-DoF pose estimation\nthrough VeloSSM, an encoder-decoder architecture that models temporal\ndependencies in velocity to capture motion dynamics, overcoming the limitations\nof frame-based 3D inference. Experiments on the KITTI public test benchmark\ndemonstrate the effectiveness of our method, achieving a new state-of-the-art\nperformance of 76.86~HOTA at 31~FPS. Our approach outperforms the previous best\nby significant margins of +2.63~HOTA and +3.62~AssA, showcasing its robustness\nand efficiency for monocular 3D MOT tasks. The code and models are available at\nhttps://github.com/bytepioneerX/s3mot.",
      "pdf_url": "http://arxiv.org/pdf/2504.18068v1",
      "published": "2025-04-25T04:45:35+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.18068v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "LLM-Guided Open RAN: Empowering Hierarchical RAN Intelligent Control",
      "authors": [
        "Lingyan Bao",
        "Sinwoong Yun",
        "Jemin Lee",
        "Tony Q. S. Quek"
      ],
      "abstract": "Recent advancements in large language models (LLMs) have led to a significant\ninterest in deploying LLMempowered algorithms for wireless communication\nnetworks. Meanwhile, open radio access network (O-RAN) techniques offer\nunprecedented flexibility, with the non-real-time (non-RT) radio access network\n(RAN) intelligent controller (RIC) (non-RT RIC) and near-real-time (near-RT)\nRIC (near-RT RIC) components enabling intelligent resource management across\ndifferent time scales. In this paper, we propose the LLM empowered hierarchical\nRIC (LLM-hRIC) framework to improve the collaboration between RICs. This\nframework integrates LLMs with reinforcement learning (RL) for efficient\nnetwork resource management. In this framework, LLMs-empowered non-RT RICs\nprovide strategic guidance and high-level policies based on environmental\ncontext. Concurrently, RL-empowered near-RT RICs perform low-latency tasks\nbased on strategic guidance and local near-RT observation. We evaluate the\nLLM-hRIC framework in an integrated access and backhaul (IAB) network setting.\nSimulation results demonstrate that the proposed framework achieves superior\nperformance. Finally, we discuss the key future challenges in applying LLMs to\nO-RAN.",
      "pdf_url": "http://arxiv.org/pdf/2504.18062v1",
      "published": "2025-04-25T04:18:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.18062v1",
      "categories": [
        "cs.NI",
        "cs.AI"
      ]
    }
  ]
}