{
  "last_updated": "2025-07-23T00:57:23.698335",
  "papers": [
    {
      "title": "Diffusion Beats Autoregressive in Data-Constrained Settings",
      "authors": [
        "Mihir Prabhudesai",
        "Menging Wu",
        "Amir Zadeh",
        "Katerina Fragkiadaki",
        "Deepak Pathak"
      ],
      "abstract": "Autoregressive (AR) models have long dominated the landscape of large\nlanguage models, driving progress across a wide range of tasks. Recently,\ndiffusion-based language models have emerged as a promising alternative, though\ntheir advantages over AR models remain underexplored. In this paper, we\nsystematically study masked diffusion models in data-constrained settings-where\ntraining involves repeated passes over limited data-and find that they\nsignificantly outperform AR models when compute is abundant but data is scarce.\nDiffusion models make better use of repeated data, achieving lower validation\nloss and superior downstream performance. We interpret this advantage as\nimplicit data augmentation: masked diffusion exposes the model to a diverse\ndistribution of token orderings and prediction tasks, unlike AR's fixed\nleft-to-right factorization. We find new scaling laws for diffusion models and\nderive a closed-form expression for the critical compute threshold at which\ndiffusion begins to outperform AR. These results suggest that when data, not\ncompute, is the bottleneck, diffusion models offer a compelling alternative to\nthe standard AR paradigm. Our code is available at:\nhttps://diffusion-scaling.github.io.",
      "pdf_url": "http://arxiv.org/pdf/2507.15857v1",
      "published": "2025-07-21T17:59:57+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.15857v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.RO"
      ]
    },
    {
      "title": "Gemini 2.5 Pro Capable of Winning Gold at IMO 2025",
      "authors": [
        "Yichen Huang",
        "Lin F. Yang"
      ],
      "abstract": "The International Mathematical Olympiad (IMO) poses uniquely challenging\nproblems requiring deep insight, creativity, and formal reasoning. While Large\nLanguage Models (LLMs) perform well on mathematical benchmarks like AIME, they\nstruggle with Olympiad-level tasks. We use Google's Gemini 2.5 Pro on the newly\nreleased IMO 2025 problems, avoiding data contamination. Using a\nself-verification pipeline with careful prompt design, 5 (out of 6) problems\nare solved correctly (up to a caveat discussed below). This result underscores\nthe importance of developing optimal strategies to harness the full potential\nof powerful LLMs for complex reasoning tasks.",
      "pdf_url": "http://arxiv.org/pdf/2507.15855v2",
      "published": "2025-07-21T17:59:49+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.15855v2",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "SeC: Advancing Complex Video Object Segmentation via Progressive Concept Construction",
      "authors": [
        "Zhixiong Zhang",
        "Shuangrui Ding",
        "Xiaoyi Dong",
        "Songxin He",
        "Jianfan Lin",
        "Junsong Tang",
        "Yuhang Zang",
        "Yuhang Cao",
        "Dahua Lin",
        "Jiaqi Wang"
      ],
      "abstract": "Video Object Segmentation (VOS) is a core task in computer vision, requiring\nmodels to track and segment target objects across video frames. Despite notable\nadvances with recent efforts, current techniques still lag behind human\ncapabilities in handling drastic visual variations, occlusions, and complex\nscene changes. This limitation arises from their reliance on appearance\nmatching, neglecting the human-like conceptual understanding of objects that\nenables robust identification across temporal dynamics. Motivated by this gap,\nwe propose Segment Concept (SeC), a concept-driven segmentation framework that\nshifts from conventional feature matching to the progressive construction and\nutilization of high-level, object-centric representations. SeC employs Large\nVision-Language Models (LVLMs) to integrate visual cues across diverse frames,\nconstructing robust conceptual priors. During inference, SeC forms a\ncomprehensive semantic representation of the target based on processed frames,\nrealizing robust segmentation of follow-up frames. Furthermore, SeC adaptively\nbalances LVLM-based semantic reasoning with enhanced feature matching,\ndynamically adjusting computational efforts based on scene complexity. To\nrigorously assess VOS methods in scenarios demanding high-level conceptual\nreasoning and robust semantic understanding, we introduce the Semantic Complex\nScenarios Video Object Segmentation benchmark (SeCVOS). SeCVOS comprises 160\nmanually annotated multi-scenario videos designed to challenge models with\nsubstantial appearance variations and dynamic scene transformations. In\nparticular, SeC achieves an 11.8-point improvement over SAM 2.1 on SeCVOS,\nestablishing a new state-of-the-art in concept-aware video object segmentation.",
      "pdf_url": "http://arxiv.org/pdf/2507.15852v2",
      "published": "2025-07-21T17:59:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.15852v2",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "The Other Mind: How Language Models Exhibit Human Temporal Cognition",
      "authors": [
        "Lingyu Li",
        "Yang Yao",
        "Yixu Wang",
        "Chubo Li",
        "Yan Teng",
        "Yingchun Wang"
      ],
      "abstract": "As Large Language Models (LLMs) continue to advance, they exhibit certain\ncognitive patterns similar to those of humans that are not directly specified\nin training data. This study investigates this phenomenon by focusing on\ntemporal cognition in LLMs. Leveraging the similarity judgment task, we find\nthat larger models spontaneously establish a subjective temporal reference\npoint and adhere to the Weber-Fechner law, whereby the perceived distance\nlogarithmically compresses as years recede from this reference point. To\nuncover the mechanisms behind this behavior, we conducted multiple analyses\nacross neuronal, representational, and informational levels. We first identify\na set of temporal-preferential neurons and find that this group exhibits\nminimal activation at the subjective reference point and implements a\nlogarithmic coding scheme convergently found in biological systems. Probing\nrepresentations of years reveals a hierarchical construction process, where\nyears evolve from basic numerical values in shallow layers to abstract temporal\norientation in deep layers. Finally, using pre-trained embedding models, we\nfound that the training corpus itself possesses an inherent, non-linear\ntemporal structure, which provides the raw material for the model's internal\nconstruction. In discussion, we propose an experientialist perspective for\nunderstanding these findings, where the LLMs' cognition is viewed as a\nsubjective construction of the external world by its internal representational\nsystem. This nuanced perspective implies the potential emergence of alien\ncognitive frameworks that humans cannot intuitively predict, pointing toward a\ndirection for AI alignment that focuses on guiding internal constructions. Our\ncode is available at https://TheOtherMind.github.io.",
      "pdf_url": "http://arxiv.org/pdf/2507.15851v1",
      "published": "2025-07-21T17:59:01+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.15851v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "The Impact of Language Mixing on Bilingual LLM Reasoning",
      "authors": [
        "Yihao Li",
        "Jiayi Xin",
        "Miranda Muqing Miao",
        "Qi Long",
        "Lyle Ungar"
      ],
      "abstract": "Proficient multilingual speakers often intentionally switch languages in the\nmiddle of a conversation. Similarly, recent reasoning-focused bilingual large\nlanguage models (LLMs) with strong capabilities in both languages exhibit\nlanguage mixing--alternating languages within their chain of thought.\nDiscouraging this behavior in DeepSeek-R1 was found to degrade accuracy,\nsuggesting that language mixing may benefit reasoning. In this work, we study\nlanguage switching in Chinese-English bilingual reasoning models. We identify\nreinforcement learning with verifiable rewards (RLVR) as the critical training\nstage that leads to language mixing. We demonstrate that language mixing can\nenhance reasoning: enforcing monolingual decoding reduces accuracy by 5.6\npercentage points on math reasoning tasks. Additionally, a lightweight probe\ncan be trained to predict whether a potential language switch would benefit or\nharm reasoning, and when used to guide decoding, increases accuracy by up to\n6.25 percentage points. Our findings suggest that language mixing is not merely\na byproduct of multilingual training, but is a strategic reasoning behavior.",
      "pdf_url": "http://arxiv.org/pdf/2507.15849v1",
      "published": "2025-07-21T17:56:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.15849v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "GUI-G$^2$: Gaussian Reward Modeling for GUI Grounding",
      "authors": [
        "Fei Tang",
        "Zhangxuan Gu",
        "Zhengxi Lu",
        "Xuyang Liu",
        "Shuheng Shen",
        "Changhua Meng",
        "Wen Wang",
        "Wenqi Zhang",
        "Yongliang Shen",
        "Weiming Lu",
        "Jun Xiao",
        "Yueting Zhuang"
      ],
      "abstract": "Graphical User Interface (GUI) grounding maps natural language instructions\nto precise interface locations for autonomous interaction. Current\nreinforcement learning approaches use binary rewards that treat elements as\nhit-or-miss targets, creating sparse signals that ignore the continuous nature\nof spatial interactions. Motivated by human clicking behavior that naturally\nforms Gaussian distributions centered on target elements, we introduce GUI\nGaussian Grounding Rewards (GUI-G$^2$), a principled reward framework that\nmodels GUI elements as continuous Gaussian distributions across the interface\nplane. GUI-G$^2$ incorporates two synergistic mechanisms: Gaussian point\nrewards model precise localization through exponentially decaying distributions\ncentered on element centroids, while coverage rewards assess spatial alignment\nby measuring the overlap between predicted Gaussian distributions and target\nregions. To handle diverse element scales, we develop an adaptive variance\nmechanism that calibrates reward distributions based on element dimensions.\nThis framework transforms GUI grounding from sparse binary classification to\ndense continuous optimization, where Gaussian distributions generate rich\ngradient signals that guide models toward optimal interaction positions.\nExtensive experiments across ScreenSpot, ScreenSpot-v2, and ScreenSpot-Pro\nbenchmarks demonstrate that GUI-G$^2$, substantially outperforms\nstate-of-the-art method UI-TARS-72B, with the most significant improvement of\n24.7% on ScreenSpot-Pro. Our analysis reveals that continuous modeling provides\nsuperior robustness to interface variations and enhanced generalization to\nunseen layouts, establishing a new paradigm for spatial reasoning in GUI\ninteraction tasks.",
      "pdf_url": "http://arxiv.org/pdf/2507.15846v2",
      "published": "2025-07-21T17:53:42+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.15846v2",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.HC"
      ]
    },
    {
      "title": "Hierarchical Budget Policy Optimization for Adaptive Reasoning",
      "authors": [
        "Shangke Lyu",
        "Linjuan Wu",
        "Yuchen Yan",
        "Xingyu Wu",
        "Hao Li",
        "Yongliang Shen",
        "Peisheng Jiang",
        "Weiming Lu",
        "Jun Xiao",
        "Yueting Zhuang"
      ],
      "abstract": "Large reasoning models achieve remarkable performance through extensive\nchain-of-thought generation, yet exhibit significant computational inefficiency\nby applying uniform reasoning strategies regardless of problem complexity. We\npresent Hierarchical Budget Policy Optimization (HBPO), a reinforcement\nlearning framework that enables models to learn problem-specific reasoning\ndepths without sacrificing capability. HBPO addresses the fundamental challenge\nof exploration space collapse in efficiency-oriented training, where penalties\non long output length systematically bias models away from necessary long\nreasoning paths. Through hierarchical budget exploration, our approach\npartitions rollout samples into multiple subgroups with distinct token budgets,\naiming to enable efficient resource allocation while preventing degradation of\ncapability. We introduce differentiated reward mechanisms that create\nbudget-aware incentives aligned with the complexity of the problem, allowing\nmodels to discover natural correspondences between task requirements and\ncomputational effort. Extensive experiments demonstrate that HBPO reduces\naverage token usage by up to 60.6% while improving accuracy by 3.14% across\nfour reasoning benchmarks. Unlike existing methods that impose external\nconstraints or rely on discrete mode selection, HBPO exhibits emergent adaptive\nbehavior where models automatically adjust reasoning depth based on problem\ncomplexity. Our results suggest that reasoning efficiency and capability are\nnot inherently conflicting, and can be simultaneously optimized through\nappropriately structured hierarchical training that preserves exploration\ndiversity.",
      "pdf_url": "http://arxiv.org/pdf/2507.15844v2",
      "published": "2025-07-21T17:52:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.15844v2",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Identifying Conditional Causal Effects in MPDAGs",
      "authors": [
        "Sara LaPlante",
        "Emilija Perković"
      ],
      "abstract": "We consider identifying a conditional causal effect when a graph is known up\nto a maximally oriented partially directed acyclic graph (MPDAG). An MPDAG\nrepresents an equivalence class of graphs that is restricted by background\nknowledge and where all variables in the causal model are observed. We provide\nthree results that address identification in this setting: an identification\nformula when the conditioning set is unaffected by treatment, a generalization\nof the well-known do calculus to the MPDAG setting, and an algorithm that is\ncomplete for identifying these conditional effects.",
      "pdf_url": "http://arxiv.org/pdf/2507.15842v1",
      "published": "2025-07-21T17:52:28+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.15842v1",
      "categories": [
        "cs.AI",
        "stat.ME",
        "stat.ML"
      ]
    },
    {
      "title": "FASTGEN: Fast and Cost-Effective Synthetic Tabular Data Generation with LLMs",
      "authors": [
        "Anh Nguyen",
        "Sam Schafft",
        "Nicholas Hale",
        "John Alfaro"
      ],
      "abstract": "Synthetic data generation has emerged as an invaluable solution in scenarios\nwhere real-world data collection and usage are limited by cost and scarcity.\nLarge language models (LLMs) have demonstrated remarkable capabilities in\nproducing high-fidelity, domain-relevant samples across various fields.\nHowever, existing approaches that directly use LLMs to generate each record\nindividually impose prohibitive time and cost burdens, particularly when large\nvolumes of synthetic data are required. In this work, we propose a fast,\ncost-effective method for realistic tabular data synthesis that leverages LLMs\nto infer and encode each field's distribution into a reusable sampling script.\nBy automatically classifying fields into numerical, categorical, or free-text\ntypes, the LLM generates distribution-based scripts that can efficiently\nproduce diverse, realistic datasets at scale without continuous model\ninference. Experimental results show that our approach outperforms traditional\ndirect methods in both diversity and data realism, substantially reducing the\nburden of high-volume synthetic data generation. We plan to apply this\nmethodology to accelerate testing in production pipelines, thereby shortening\ndevelopment cycles and improving overall system efficiency. We believe our\ninsights and lessons learned will aid researchers and practitioners seeking\nscalable, cost-effective solutions for synthetic data generation.",
      "pdf_url": "http://arxiv.org/pdf/2507.15839v1",
      "published": "2025-07-21T17:51:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.15839v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Look, Focus, Act: Efficient and Robust Robot Learning via Human Gaze and Foveated Vision Transformers",
      "authors": [
        "Ian Chuang",
        "Andrew Lee",
        "Dechen Gao",
        "Jinyu Zou",
        "Iman Soltani"
      ],
      "abstract": "Human vision is a highly active process driven by gaze, which directs\nattention and fixation to task-relevant regions and dramatically reduces visual\nprocessing. In contrast, robot learning systems typically rely on passive,\nuniform processing of raw camera images. In this work, we explore how\nincorporating human-like active gaze into robotic policies can enhance both\nefficiency and performance. We build on recent advances in foveated image\nprocessing and apply them to an Active Vision robot system that emulates both\nhuman head movement and eye tracking. Extending prior work on the AV-ALOHA\nrobot simulation platform, we introduce a framework for simultaneously\ncollecting eye-tracking data and robot demonstrations from a human operator as\nwell as a simulation benchmark and dataset for training robot policies that\nincorporate human gaze. Given the widespread use of Vision Transformers (ViTs)\nin robot learning, we integrate gaze information into ViTs using a foveated\npatch tokenization scheme inspired by recent work in image segmentation.\nCompared to uniform patch tokenization, this significantly reduces the number\nof tokens-and thus computation-without sacrificing visual fidelity near regions\nof interest. We also explore two approaches to gaze imitation and prediction\nfrom human data. The first is a two-stage model that predicts gaze to guide\nfoveation and action; the second integrates gaze into the action space,\nallowing the policy to jointly predict gaze and actions end-to-end. Our results\nshow that our method for foveated robot vision not only drastically reduces\ncomputational overhead, but also improves performance for high precision tasks\nand robustness to unseen distractors. Together, these findings suggest that\nhuman-inspired visual processing offers a useful inductive bias for robotic\nvision systems. https://ian-chuang.github.io/gaze-av-aloha/",
      "pdf_url": "http://arxiv.org/pdf/2507.15833v1",
      "published": "2025-07-21T17:44:10+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.15833v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Operationalizing AI for Good: Spotlight on Deployment and Integration of AI Models in Humanitarian Work",
      "authors": [
        "Anton Abilov",
        "Ke Zhang",
        "Hemank Lamba",
        "Elizabeth M. Olson",
        "Joel R. Tetreault",
        "Alejandro Jaimes"
      ],
      "abstract": "Publications in the AI for Good space have tended to focus on the research\nand model development that can support high-impact applications. However, very\nfew AI for Good papers discuss the process of deploying and collaborating with\nthe partner organization, and the resulting real-world impact. In this work, we\nshare details about the close collaboration with a humanitarian-to-humanitarian\n(H2H) organization and how to not only deploy the AI model in a\nresource-constrained environment, but also how to maintain it for continuous\nperformance updates, and share key takeaways for practitioners.",
      "pdf_url": "http://arxiv.org/pdf/2507.15823v1",
      "published": "2025-07-21T17:30:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.15823v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SI"
      ]
    },
    {
      "title": "Do AI models help produce verified bug fixes?",
      "authors": [
        "Li Huang",
        "Ilgiz Mustafin",
        "Marco Piccioni",
        "Alessandro Schena",
        "Reto Weber",
        "Bertrand Meyer"
      ],
      "abstract": "Among areas of software engineering where AI techniques -- particularly,\nLarge Language Models -- seem poised to yield dramatic improvements, an\nattractive candidate is Automatic Program Repair (APR), the production of\nsatisfactory corrections to software bugs. Does this expectation materialize in\npractice? How do we find out, making sure that proposed corrections actually\nwork? If programmers have access to LLMs, how do they actually use them to\ncomplement their own skills?\n  To answer these questions, we took advantage of the availability of a\nprogram-proving environment, which formally determines the correctness of\nproposed fixes, to conduct a study of program debugging with two randomly\nassigned groups of programmers, one with access to LLMs and the other without,\nboth validating their answers through the proof tools. The methodology relied\non a division into general research questions (Goals in the Goal-Query-Metric\napproach), specific elements admitting specific answers (Queries), and\nmeasurements supporting these answers (Metrics). While applied so far to a\nlimited sample size, the results are a first step towards delineating a proper\nrole for AI and LLMs in providing guaranteed-correct fixes to program bugs.\n  These results caused surprise as compared to what one might expect from the\nuse of AI for debugging and APR. The contributions also include: a detailed\nmethodology for experiments in the use of LLMs for debugging, which other\nprojects can reuse; a fine-grain analysis of programmer behavior, made possible\nby the use of full-session recording; a definition of patterns of use of LLMs,\nwith 7 distinct categories; and validated advice for getting the best of LLMs\nfor debugging and Automatic Program Repair.",
      "pdf_url": "http://arxiv.org/pdf/2507.15822v1",
      "published": "2025-07-21T17:30:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.15822v1",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "True Multimodal In-Context Learning Needs Attention to the Visual Context",
      "authors": [
        "Shuo Chen",
        "Jianzhe Liu",
        "Zhen Han",
        "Yan Xia",
        "Daniel Cremers",
        "Philip Torr",
        "Volker Tresp",
        "Jindong Gu"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs), built on powerful language\nbackbones, have enabled Multimodal In-Context Learning (MICL)-adapting to new\ntasks from a few multimodal demonstrations consisting of images, questions, and\nanswers. Despite showing noticeable improvement on standard vision-language\ndatasets, current MLLMs struggle to leverage visual information in the\ndemonstrations. Specifically, they tend to neglect visual cues and over-rely on\ntextual patterns, leading to mere text imitation rather than genuine multimodal\nadaptation. This behavior makes MICL still unimodal and largely restricts its\npractical utility. More importantly, this limitation is often concealed by the\nimproved performance on tasks that do not require understanding the visual\ncontext. As a result, how to effectively enhance MICL ability and reliably\nevaluate the MICL performance remains underexplored. To address these issues,\nwe first introduce Dynamic Attention Reallocation (DARA), an efficient\nfine-tuning strategy that encourages models to attend to the visual context by\nrebalancing attention across visual and textual tokens. In addition, we present\nTrueMICL, an MICL-dedicated dataset with both support and test sets that\nexplicitly requires the integration of multimodal information-particularly\nvisual content-for correct task completion. Extensive experiments demonstrate\nthe effectiveness of our holistic solution, showcasing substantial improvements\nin the true multimodal in-context learning capabilities. Code and datasets are\navailable at https://chenxshuo.github.io/true-micl-colm .",
      "pdf_url": "http://arxiv.org/pdf/2507.15807v1",
      "published": "2025-07-21T17:08:18+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.15807v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "ConformalSAM: Unlocking the Potential of Foundational Segmentation Models in Semi-Supervised Semantic Segmentation with Conformal Prediction",
      "authors": [
        "Danhui Chen",
        "Ziquan Liu",
        "Chuxi Yang",
        "Dan Wang",
        "Yan Yan",
        "Yi Xu",
        "Xiangyang Ji"
      ],
      "abstract": "Pixel-level vision tasks, such as semantic segmentation, require extensive\nand high-quality annotated data, which is costly to obtain. Semi-supervised\nsemantic segmentation (SSSS) has emerged as a solution to alleviate the\nlabeling burden by leveraging both labeled and unlabeled data through\nself-training techniques. Meanwhile, the advent of foundational segmentation\nmodels pre-trained on massive data, has shown the potential to generalize\nacross domains effectively. This work explores whether a foundational\nsegmentation model can address label scarcity in the pixel-level vision task as\nan annotator for unlabeled images. Specifically, we investigate the efficacy of\nusing SEEM, a Segment Anything Model (SAM) variant fine-tuned for textual\ninput, to generate predictive masks for unlabeled data. To address the\nshortcomings of using SEEM-generated masks as supervision, we propose\nConformalSAM, a novel SSSS framework which first calibrates the foundation\nmodel using the target domain's labeled data and then filters out unreliable\npixel labels of unlabeled data so that only high-confidence labels are used as\nsupervision. By leveraging conformal prediction (CP) to adapt foundation models\nto target data through uncertainty calibration, ConformalSAM exploits the\nstrong capability of the foundational segmentation model reliably which\nbenefits the early-stage learning, while a subsequent self-reliance training\nstrategy mitigates overfitting to SEEM-generated masks in the later training\nstage. Our experiment demonstrates that, on three standard benchmarks of SSSS,\nConformalSAM achieves superior performance compared to recent SSSS methods and\nhelps boost the performance of those methods as a plug-in.",
      "pdf_url": "http://arxiv.org/pdf/2507.15803v1",
      "published": "2025-07-21T17:02:57+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.15803v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Challenges of Trustworthy Federated Learning: What's Done, Current Trends and Remaining Work",
      "authors": [
        "Nuria Rodríguez-Barroso",
        "Mario García-Márquez",
        "M. Victoria Luzón",
        "Francisco Herrera"
      ],
      "abstract": "In recent years, the development of Trustworthy Artificial Intelligence (TAI)\nhas emerged as a critical objective in the deployment of AI systems across\nsensitive and high-risk domains. TAI frameworks articulate a comprehensive set\nof ethical, legal, and technical requirements to ensure that AI technologies\nare aligned with human values, rights, and societal expectations. Among the\nvarious AI paradigms, Federated Learning (FL) presents a promising solution to\npressing privacy concerns. However, aligning FL with the rest of the\nrequirements of TAI presents a series of challenges, most of which arise from\nits inherently distributed nature. In this work, we adopt the requirements TAI\nas a guiding structure to systematically analyze the challenges of adapting FL\nto TAI. Specifically, we classify and examine the key obstacles to aligning FL\nwith TAI, providing a detailed exploration of what has been done, the trends,\nand the remaining work within each of the identified challenges.",
      "pdf_url": "http://arxiv.org/pdf/2507.15796v1",
      "published": "2025-07-21T16:57:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.15796v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Small LLMs Do Not Learn a Generalizable Theory of Mind via Reinforcement Learning",
      "authors": [
        "Sneheel Sarangi",
        "Hanan Salam"
      ],
      "abstract": "Recent advancements in large language models (LLMs) have demonstrated\nemergent capabilities in complex reasoning, largely spurred by rule-based\nReinforcement Learning (RL) techniques applied during the post-training. This\nhas raised the question of whether similar methods can instill more nuanced,\nhuman-like social intelligence, such as a Theory of Mind (ToM), in LLMs. This\npaper investigates whether small-scale LLMs can acquire a robust and\ngeneralizable ToM capability through RL with verifiable rewards (RLVR). We\nconduct a systematic evaluation by training models on various combinations of\nprominent ToM datasets (HiToM, ExploreToM, FANToM) and testing for\ngeneralization on held-out datasets (e.g., OpenToM). Our findings indicate that\nsmall LLMs struggle to develop a generic ToM capability. While performance on\nin-distribution tasks improves, this capability fails to transfer to unseen ToM\ntasks with different characteristics. Furthermore, we demonstrate that\nprolonged RL training leads to models ``hacking'' the statistical patterns of\nthe training datasets, resulting in significant performance gains on in-domain\ndata but no change, or degradation of performance on out-of-distribution tasks.\nThis suggests the learned behavior is a form of narrow overfitting rather than\nthe acquisition of a true, abstract ToM capability.",
      "pdf_url": "http://arxiv.org/pdf/2507.15788v1",
      "published": "2025-07-21T16:47:59+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.15788v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Romance, Relief, and Regret: Teen Narratives of Chatbot Overreliance",
      "authors": [
        "Mohammad 'Matt' Namvarpour",
        "Brandon Brofsky",
        "Jessica Medina",
        "Mamtaj Akter",
        "Afsaneh Razi"
      ],
      "abstract": "As Generative Artificial Intelligence (GenAI) driven chatbots like\nCharacter.AI become embedded in adolescent life, they raise concerns about\nemotional dependence and digital overreliance. While studies have investigated\nthe overreliance of adults on these chatbots, they have not investigated teens'\ninteractions with chatbots with customizable personas. We analyzed 318 Reddit\nposts made by users self-reported as 13-17 years old on the Character.AI\nsubreddit to understand patterns of overreliance. We found teens commonly begin\nusing chatbots for emotional support or creative expression, but many develop\nstrong attachments that interfere with offline relationships and daily\nroutines. Their posts revealed recurring signs of psychological distress,\ncycles of relapse, and difficulty disengaging. Teens reported that their\noverreliance often ended when they reflect on the harm, return to in-person\nsocial settings, or become frustrated by platform restrictions. Based on the\nimplications of our findings, we provide recommendations for future chatbot\ndesign so they can promote self-awareness, support real-world engagement, and\ninvolve teens in developing safer digital tools.",
      "pdf_url": "http://arxiv.org/pdf/2507.15783v2",
      "published": "2025-07-21T16:39:33+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.15783v2",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ]
    },
    {
      "title": "Learning Null Geodesics for Gravitational Lensing Rendering in General Relativity",
      "authors": [
        "Mingyuan Sun",
        "Zheng Fang",
        "Jiaxu Wang",
        "Kunyi Zhang",
        "Qiang Zhang",
        "Renjing Xu"
      ],
      "abstract": "We present GravLensX, an innovative method for rendering black holes with\ngravitational lensing effects using neural networks. The methodology involves\ntraining neural networks to fit the spacetime around black holes and then\nemploying these trained models to generate the path of light rays affected by\ngravitational lensing. This enables efficient and scalable simulations of black\nholes with optically thin accretion disks, significantly decreasing the time\nrequired for rendering compared to traditional methods. We validate our\napproach through extensive rendering of multiple black hole systems with\nsuperposed Kerr metric, demonstrating its capability to produce accurate\nvisualizations with significantly $15\\times$ reduced computational time. Our\nfindings suggest that neural networks offer a promising alternative for\nrendering complex astrophysical phenomena, potentially paving a new path to\nastronomical visualization.",
      "pdf_url": "http://arxiv.org/pdf/2507.15775v1",
      "published": "2025-07-21T16:30:36+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.15775v1",
      "categories": [
        "gr-qc",
        "astro-ph.IM",
        "cs.AI"
      ]
    },
    {
      "title": "Dynamics is what you need for time-series forecasting!",
      "authors": [
        "Alexis-Raja Brachet",
        "Pierre-Yves Richard",
        "Céline Hudelot"
      ],
      "abstract": "While boundaries between data modalities are vanishing, the usual successful\ndeep models are still challenged by simple ones in the time-series forecasting\ntask. Our hypothesis is that this task needs models that are able to learn the\ndata underlying dynamics. We propose to validate it through both systemic and\nempirical studies. We develop an original $\\texttt{PRO-DYN}$ nomenclature to\nanalyze existing models through the lens of dynamics. Two observations thus\nemerged: $\\textbf{1}$. under-performing architectures learn dynamics at most\npartially, $\\textbf{2}$. the location of the dynamics block at the model end is\nof prime importance. We conduct extensive experiments to confirm our\nobservations on a set of performance-varying models with diverse backbones.\nResults support the need to incorporate a learnable dynamics block and its use\nas the final predictor.",
      "pdf_url": "http://arxiv.org/pdf/2507.15774v1",
      "published": "2025-07-21T16:29:29+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.15774v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Supernova: Achieving More with Less in Transformer Architectures",
      "authors": [
        "Andrei-Valentin Tanase",
        "Elena Pelican"
      ],
      "abstract": "We present Supernova, a 650M-parameter decoder-only transformer that\ndemonstrates how careful architectural design and tokenization innovation can\nachieve the performance of larger models while maintaining computational\nefficiency. Our architecture combines Rotary Positional Embeddings (RoPE),\nGrouped Query Attention (GQA) with a 3:1 compression ratio, RMSNorm for\ncomputational efficiency, and SwiGLU activation functions. A critical\ninnovation is our custom 128,000-vocabulary byte-level BPE tokenizer, which\nachieves state-of-the-art compression performance. Through detailed analysis,\nwe show that Supernova achieves 90% of the performance of 1B-parameter models\nwhile using 35% fewer parameters and requiring only 100B training tokens--an\norder of magnitude less than competing models. Our findings challenge the\nprevailing scaling paradigm, demonstrating that architectural efficiency and\ntokenization quality can compensate for reduced parameter counts.",
      "pdf_url": "http://arxiv.org/pdf/2507.15773v2",
      "published": "2025-07-21T16:27:48+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.15773v2",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Deep-Learning Investigation of Vibrational Raman Spectra for Plant-Stress Analysis",
      "authors": [
        "Anoop C. Patil",
        "Benny Jian Rong Sng",
        "Yu-Wei Chang",
        "Joana B. Pereira",
        "Chua Nam-Hai",
        "Rajani Sarojam",
        "Gajendra Pratap Singh",
        "In-Cheol Jang",
        "Giovanni Volpe"
      ],
      "abstract": "Detecting stress in plants is crucial for both open-farm and\ncontrolled-environment agriculture. Biomolecules within plants serve as key\nstress indicators, offering vital markers for continuous health monitoring and\nearly disease detection. Raman spectroscopy provides a powerful, non-invasive\nmeans to quantify these biomolecules through their molecular vibrational\nsignatures. However, traditional Raman analysis relies on customized\ndata-processing workflows that require fluorescence background removal and\nprior identification of Raman peaks of interest-introducing potential biases\nand inconsistencies. Here, we introduce DIVA (Deep-learning-based Investigation\nof Vibrational Raman spectra for plant-stress Analysis), a fully automated\nworkflow based on a variational autoencoder. Unlike conventional approaches,\nDIVA processes native Raman spectra-including fluorescence backgrounds-without\nmanual preprocessing, identifying and quantifying significant spectral features\nin an unbiased manner. We applied DIVA to detect a range of plant stresses,\nincluding abiotic (shading, high light intensity, high temperature) and biotic\nstressors (bacterial infections). By integrating deep learning with vibrational\nspectroscopy, DIVA paves the way for AI-driven plant health assessment,\nfostering more resilient and sustainable agricultural practices.",
      "pdf_url": "http://arxiv.org/pdf/2507.15772v1",
      "published": "2025-07-21T16:27:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.15772v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.BM"
      ]
    },
    {
      "title": "Left Leaning Models: AI Assumptions on Economic Policy",
      "authors": [
        "Maxim Chupilkin"
      ],
      "abstract": "How does AI think about economic policy? While the use of large language\nmodels (LLMs) in economics is growing exponentially, their assumptions on\neconomic issues remain a black box. This paper uses a conjoint experiment to\ntease out the main factors influencing LLMs' evaluation of economic policy. It\nfinds that LLMs are most sensitive to unemployment, inequality, financial\nstability, and environmental harm and less sensitive to traditional\nmacroeconomic concerns such as economic growth, inflation, and government debt.\nThe results are remarkably consistent across scenarios and across models.",
      "pdf_url": "http://arxiv.org/pdf/2507.15771v1",
      "published": "2025-07-21T16:27:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.15771v1",
      "categories": [
        "cs.CY",
        "cs.AI",
        "econ.GN",
        "q-fin.EC"
      ]
    },
    {
      "title": "A Framework for Analyzing Abnormal Emergence in Service Ecosystems Through LLM-based Agent Intention Mining",
      "authors": [
        "Yifan Shen",
        "Zihan Zhao",
        "Xiao Xue",
        "Yuwei Guo",
        "Qun Ma",
        "Deyu Zhou",
        "Ming Zhang"
      ],
      "abstract": "With the rise of service computing, cloud computing, and IoT, service\necosystems are becoming increasingly complex. The intricate interactions among\nintelligent agents make abnormal emergence analysis challenging, as traditional\ncausal methods focus on individual trajectories. Large language models offer\nnew possibilities for Agent-Based Modeling (ABM) through Chain-of-Thought (CoT)\nreasoning to reveal agent intentions. However, existing approaches remain\nlimited to microscopic and static analysis. This paper introduces a framework:\nEmergence Analysis based on Multi-Agent Intention (EAMI), which enables dynamic\nand interpretable emergence analysis. EAMI first employs a dual-perspective\nthought track mechanism, where an Inspector Agent and an Analysis Agent extract\nagent intentions under bounded and perfect rationality. Then, k-means\nclustering identifies phase transition points in group intentions, followed by\na Intention Temporal Emergence diagram for dynamic analysis. The experiments\nvalidate EAMI in complex online-to-offline (O2O) service system and the\nStanford AI Town experiment, with ablation studies confirming its\neffectiveness, generalizability, and efficiency. This framework provides a\nnovel paradigm for abnormal emergence and causal analysis in service\necosystems. The code is available at\nhttps://anonymous.4open.science/r/EAMI-B085.",
      "pdf_url": "http://arxiv.org/pdf/2507.15770v1",
      "published": "2025-07-21T16:26:49+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.15770v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "GasAgent: A Multi-Agent Framework for Automated Gas Optimization in Smart Contracts",
      "authors": [
        "Jingyi Zheng",
        "Zifan Peng",
        "Yule Liu",
        "Junfeng Wang",
        "Yifan Liao",
        "Wenhan Dong",
        "Xinlei He"
      ],
      "abstract": "Smart contracts are trustworthy, immutable, and automatically executed\nprograms on the blockchain. Their execution requires the Gas mechanism to\nensure efficiency and fairness. However, due to non-optimal coding practices,\nmany contracts contain Gas waste patterns that need to be optimized. Existing\nsolutions mostly rely on manual discovery, which is inefficient, costly to\nmaintain, and difficult to scale. Recent research uses large language models\n(LLMs) to explore new Gas waste patterns. However, it struggles to remain\ncompatible with existing patterns, often produces redundant patterns, and\nrequires manual validation/rewriting. To address this gap, we present GasAgent,\nthe first multi-agent system for smart contract Gas optimization that combines\ncompatibility with existing patterns and automated discovery/validation of new\npatterns, enabling end-to-end optimization. GasAgent consists of four\nspecialized agents, Seeker, Innovator, Executor, and Manager, that collaborate\nin a closed loop to identify, validate, and apply Gas-saving improvements.\nExperiments on 100 verified real-world contracts demonstrate that GasAgent\nsuccessfully optimizes 82 contracts, achieving an average deployment Gas\nsavings of 9.97%. In addition, our evaluation confirms its compatibility with\nexisting tools and validates the effectiveness of each module through ablation\nstudies. To assess broader usability, we further evaluate 500 contracts\ngenerated by five representative LLMs across 10 categories and find that\nGasAgent optimizes 79.8% of them, with deployment Gas savings ranging from\n4.79% to 13.93%, showing its usability as the optimization layer for\nLLM-assisted smart contract development.",
      "pdf_url": "http://arxiv.org/pdf/2507.15761v1",
      "published": "2025-07-21T16:17:25+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.15761v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "LAPO: Internalizing Reasoning Efficiency via Length-Adaptive Policy Optimization",
      "authors": [
        "Xingyu Wu",
        "Yuchen Yan",
        "Shangke Lyu",
        "Linjuan Wu",
        "Yiwen Qiu",
        "Yongliang Shen",
        "Weiming Lu",
        "Jian Shao",
        "Jun Xiao",
        "Yueting Zhuang"
      ],
      "abstract": "Large reasoning models have achieved remarkable performance through extended\nchain-of-thought sequences, yet this computational freedom leads to excessive\ntoken generation even for simple problems. We present Length-Adaptive Policy\nOptimization (LAPO), a novel framework that transforms reasoning length control\nfrom an external constraint into an intrinsic model capability. Unlike existing\napproaches that impose rigid limits or rely on post-hoc interventions, LAPO\nenables models to internalize an understanding of appropriate reasoning depth\nthrough a two-stage reinforcement learning process. In the first stage, models\nlearn natural reasoning patterns by discovering the statistical distribution of\nsuccessful solution lengths. The second stage leverages these patterns as\nmeta-cognitive guidance, embedding them directly within the model's reasoning\ncontext to ensure inference-time flexibility. Experiments on mathematical\nreasoning benchmarks demonstrate that LAPO reduces token usage by up to 40.9\\%\nwhile improving accuracy by 2.3\\%. Our analysis reveals that models trained\nwith LAPO develop emergent abilities to allocate computational resources based\non problem complexity, achieving efficient reasoning without sacrificing\nquality.",
      "pdf_url": "http://arxiv.org/pdf/2507.15758v1",
      "published": "2025-07-21T16:14:41+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.15758v1",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "DiffuMeta: Algebraic Language Models for Inverse Design of Metamaterials via Diffusion Transformers",
      "authors": [
        "Li Zheng",
        "Siddhant Kumar",
        "Dennis M. Kochmann"
      ],
      "abstract": "Generative machine learning models have revolutionized material discovery by\ncapturing complex structure-property relationships, yet extending these\napproaches to the inverse design of three-dimensional metamaterials remains\nlimited by computational complexity and underexplored design spaces due to the\nlack of expressive representations. Here, we present DiffuMeta, a generative\nframework integrating diffusion transformers with a novel algebraic language\nrepresentation, encoding 3D geometries as mathematical sentences. This compact,\nunified parameterization spans diverse topologies while enabling direct\napplication of transformers to structural design. DiffuMeta leverages diffusion\nmodels to generate novel shell structures with precisely targeted stress-strain\nresponses under large deformations, accounting for buckling and contact while\naddressing the inherent one-to-many mapping by producing diverse solutions.\nUniquely, our approach enables simultaneous control over multiple mechanical\nobjectives, including linear and nonlinear responses beyond training domains.\nExperimental validation of fabricated structures further confirms the efficacy\nof our approach for accelerated design of metamaterials and structures with\ntailored properties.",
      "pdf_url": "http://arxiv.org/pdf/2507.15753v1",
      "published": "2025-07-21T16:09:26+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.15753v1",
      "categories": [
        "cs.CE",
        "cs.AI"
      ]
    },
    {
      "title": "DialogueForge: LLM Simulation of Human-Chatbot Dialogue",
      "authors": [
        "Ruizhe Zhu",
        "Hao Zhu",
        "Yaxuan Li",
        "Syang Zhou",
        "Shijing Cai",
        "Malgorzata Lazuka",
        "Elliott Ash"
      ],
      "abstract": "Collecting human-chatbot dialogues typically demands substantial manual\neffort and is time-consuming, which limits and poses challenges for research on\nconversational AI. In this work, we propose DialogueForge - a framework for\ngenerating AI-simulated conversations in human-chatbot style. To initialize\neach generated conversation, DialogueForge uses seed prompts extracted from\nreal human-chatbot interactions. We test a variety of LLMs to simulate the\nhuman chatbot user, ranging from state-of-the-art proprietary models to\nsmall-scale open-source LLMs, and generate multi-turn dialogues tailored to\nspecific tasks. In addition, we explore fine-tuning techniques to enhance the\nability of smaller models to produce indistinguishable human-like dialogues. We\nevaluate the quality of the simulated conversations and compare different\nmodels using the UniEval and GTEval evaluation protocols. Our experiments show\nthat large proprietary models (e.g., GPT-4o) generally outperform others in\ngenerating more realistic dialogues, while smaller open-source models (e.g.,\nLlama, Mistral) offer promising performance with greater customization. We\ndemonstrate that the performance of smaller models can be significantly\nimproved by employing supervised fine-tuning techniques. Nevertheless,\nmaintaining coherent and natural long-form human-like dialogues remains a\ncommon challenge across all models.",
      "pdf_url": "http://arxiv.org/pdf/2507.15752v1",
      "published": "2025-07-21T16:08:19+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.15752v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Towards physician-centered oversight of conversational diagnostic AI",
      "authors": [
        "Elahe Vedadi",
        "David Barrett",
        "Natalie Harris",
        "Ellery Wulczyn",
        "Shashir Reddy",
        "Roma Ruparel",
        "Mike Schaekermann",
        "Tim Strother",
        "Ryutaro Tanno",
        "Yash Sharma",
        "Jihyeon Lee",
        "Cían Hughes",
        "Dylan Slack",
        "Anil Palepu",
        "Jan Freyberg",
        "Khaled Saab",
        "Valentin Liévin",
        "Wei-Hung Weng",
        "Tao Tu",
        "Yun Liu",
        "Nenad Tomasev",
        "Kavita Kulkarni",
        "S. Sara Mahdavi",
        "Kelvin Guu",
        "Joëlle Barral",
        "Dale R. Webster",
        "James Manyika",
        "Avinatan Hassidim",
        "Katherine Chou",
        "Yossi Matias",
        "Pushmeet Kohli",
        "Adam Rodman",
        "Vivek Natarajan",
        "Alan Karthikesalingam",
        "David Stutz"
      ],
      "abstract": "Recent work has demonstrated the promise of conversational AI systems for\ndiagnostic dialogue. However, real-world assurance of patient safety means that\nproviding individual diagnoses and treatment plans is considered a regulated\nactivity by licensed professionals. Furthermore, physicians commonly oversee\nother team members in such activities, including nurse practitioners (NPs) or\nphysician assistants/associates (PAs). Inspired by this, we propose a framework\nfor effective, asynchronous oversight of the Articulate Medical Intelligence\nExplorer (AMIE) AI system. We propose guardrailed-AMIE (g-AMIE), a multi-agent\nsystem that performs history taking within guardrails, abstaining from\nindividualized medical advice. Afterwards, g-AMIE conveys assessments to an\noverseeing primary care physician (PCP) in a clinician cockpit interface. The\nPCP provides oversight and retains accountability of the clinical decision.\nThis effectively decouples oversight from intake and can thus happen\nasynchronously. In a randomized, blinded virtual Objective Structured Clinical\nExamination (OSCE) of text consultations with asynchronous oversight, we\ncompared g-AMIE to NPs/PAs or a group of PCPs under the same guardrails. Across\n60 scenarios, g-AMIE outperformed both groups in performing high-quality\nintake, summarizing cases, and proposing diagnoses and management plans for the\noverseeing PCP to review. This resulted in higher quality composite decisions.\nPCP oversight of g-AMIE was also more time-efficient than standalone PCP\nconsultations in prior work. While our study does not replicate existing\nclinical practices and likely underestimates clinicians' capabilities, our\nresults demonstrate the promise of asynchronous oversight as a feasible\nparadigm for diagnostic AI systems to operate under expert human oversight for\nenhancing real-world care.",
      "pdf_url": "http://arxiv.org/pdf/2507.15743v1",
      "published": "2025-07-21T15:54:36+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.15743v1",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "cs.LG"
      ]
    },
    {
      "title": "Explainable Anomaly Detection for Electric Vehicles Charging Stations",
      "authors": [
        "Matteo Cederle",
        "Andrea Mazzucco",
        "Andrea Demartini",
        "Eugenio Mazza",
        "Eugenia Suriani",
        "Federico Vitti",
        "Gian Antonio Susto"
      ],
      "abstract": "Electric vehicles (EV) charging stations are one of the critical\ninfrastructures needed to support the transition to renewable-energy-based\nmobility, but ensuring their reliability and efficiency requires effective\nanomaly detection to identify irregularities in charging behavior. However, in\nsuch a productive scenario, it is also crucial to determine the underlying\ncause behind the detected anomalies. To achieve this goal, this study\ninvestigates unsupervised anomaly detection techniques for EV charging\ninfrastructure, integrating eXplainable Artificial Intelligence techniques to\nenhance interpretability and uncover root causes of anomalies.\n  Using real-world sensors and charging session data, this work applies\nIsolation Forest to detect anomalies and employs the Depth-based Isolation\nForest Feature Importance (DIFFI) method to identify the most important\nfeatures contributing to such anomalies. The efficacy of the proposed approach\nis evaluated in a real industrial case.",
      "pdf_url": "http://arxiv.org/pdf/2507.15718v1",
      "published": "2025-07-21T15:27:48+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.15718v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "BEnchmarking LLMs for Ophthalmology (BELO) for Ophthalmological Knowledge and Reasoning",
      "authors": [
        "Sahana Srinivasan",
        "Xuguang Ai",
        "Thaddaeus Wai Soon Lo",
        "Aidan Gilson",
        "Minjie Zou",
        "Ke Zou",
        "Hyunjae Kim",
        "Mingjia Yang",
        "Krithi Pushpanathan",
        "Samantha Yew",
        "Wan Ting Loke",
        "Jocelyn Goh",
        "Yibing Chen",
        "Yiming Kong",
        "Emily Yuelei Fu",
        "Michelle Ongyong Hui",
        "Kristen Nwanyanwu",
        "Amisha Dave",
        "Kelvin Zhenghao Li",
        "Chen-Hsin Sun",
        "Mark Chia",
        "Gabriel Dawei Yang",
        "Wendy Meihua Wong",
        "David Ziyou Chen",
        "Dianbo Liu",
        "Maxwell Singer",
        "Fares Antaki",
        "Lucian V Del Priore",
        "Jost Jonas",
        "Ron Adelman",
        "Qingyu Chen",
        "Yih-Chung Tham"
      ],
      "abstract": "Current benchmarks evaluating large language models (LLMs) in ophthalmology\nare limited in scope and disproportionately prioritise accuracy. We introduce\nBELO (BEnchmarking LLMs for Ophthalmology), a standardized and comprehensive\nevaluation benchmark developed through multiple rounds of expert checking by 13\nophthalmologists. BELO assesses ophthalmology-related clinical accuracy and\nreasoning quality. Using keyword matching and a fine-tuned PubMedBERT model, we\ncurated ophthalmology-specific multiple-choice-questions (MCQs) from diverse\nmedical datasets (BCSC, MedMCQA, MedQA, BioASQ, and PubMedQA). The dataset\nunderwent multiple rounds of expert checking. Duplicate and substandard\nquestions were systematically removed. Ten ophthalmologists refined the\nexplanations of each MCQ's correct answer. This was further adjudicated by\nthree senior ophthalmologists. To illustrate BELO's utility, we evaluated six\nLLMs (OpenAI o1, o3-mini, GPT-4o, DeepSeek-R1, Llama-3-8B, and Gemini 1.5 Pro)\nusing accuracy, macro-F1, and five text-generation metrics (ROUGE-L, BERTScore,\nBARTScore, METEOR, and AlignScore). In a further evaluation involving human\nexperts, two ophthalmologists qualitatively reviewed 50 randomly selected\noutputs for accuracy, comprehensiveness, and completeness. BELO consists of 900\nhigh-quality, expert-reviewed questions aggregated from five sources: BCSC\n(260), BioASQ (10), MedMCQA (572), MedQA (40), and PubMedQA (18). A public\nleaderboard has been established to promote transparent evaluation and\nreporting. Importantly, the BELO dataset will remain a hold-out,\nevaluation-only benchmark to ensure fair and reproducible comparisons of future\nmodels.",
      "pdf_url": "http://arxiv.org/pdf/2507.15717v1",
      "published": "2025-07-21T15:27:32+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.15717v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Is Large Language Model Performance on Reasoning Tasks Impacted by Different Ways Questions Are Asked?",
      "authors": [
        "Seok Hwan Song",
        "Mohna Chakraborty",
        "Qi Li",
        "Wallapak Tavanapong"
      ],
      "abstract": "Large Language Models (LLMs) have been evaluated using diverse question\ntypes, e.g., multiple-choice, true/false, and short/long answers. This study\nanswers an unexplored question about the impact of different question types on\nLLM accuracy on reasoning tasks. We investigate the performance of five LLMs on\nthree different types of questions using quantitative and deductive reasoning\ntasks. The performance metrics include accuracy in the reasoning steps and\nchoosing the final answer. Key Findings: (1) Significant differences exist in\nLLM performance across different question types. (2) Reasoning accuracy does\nnot necessarily correlate with the final selection accuracy. (3) The number of\noptions and the choice of words, influence LLM performance.",
      "pdf_url": "http://arxiv.org/pdf/2507.15707v1",
      "published": "2025-07-21T15:15:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.15707v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Compositional Understanding in Signaling Games",
      "authors": [
        "David Peter Wallis Freeborn"
      ],
      "abstract": "Receivers in standard signaling game models struggle with learning\ncompositional information. Even when the signalers send compositional messages,\nthe receivers do not interpret them compositionally. When information from one\nmessage component is lost or forgotten, the information from other components\nis also erased. In this paper I construct signaling game models in which\ngenuine compositional understanding evolves. I present two new models: a\nminimalist receiver who only learns from the atomic messages of a signal, and a\ngeneralist receiver who learns from all of the available information. These\nmodels are in many ways simpler than previous alternatives, and allow the\nreceivers to learn from the atomic components of messages.",
      "pdf_url": "http://arxiv.org/pdf/2507.15706v1",
      "published": "2025-07-21T15:14:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.15706v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "CoLD: Counterfactually-Guided Length Debiasing for Process Reward Models",
      "authors": [
        "Congmin Zheng",
        "Jiachen Zhu",
        "Jianghao Lin",
        "Xinyi Dai",
        "Yong Yu",
        "Weinan Zhang",
        "Mengyue Yang"
      ],
      "abstract": "Process Reward Models (PRMs) play a central role in evaluating and guiding\nmulti-step reasoning in large language models (LLMs), especially for\nmathematical problem solving. However, we identify a pervasive length bias in\nexisting PRMs: they tend to assign higher scores to longer reasoning steps,\neven when the semantic content and logical validity are unchanged. This bias\nundermines the reliability of reward predictions and leads to overly verbose\noutputs during inference. To address this issue, we propose\nCoLD(Counterfactually-Guided Length Debiasing), a unified framework that\nmitigates length bias through three components: an explicit length-penalty\nadjustment, a learned bias estimator trained to capture spurious length-related\nsignals, and a joint training strategy that enforces length-invariance in\nreward predictions. Our approach is grounded in counterfactual reasoning and\ninformed by causal graph analysis. Extensive experiments on MATH500 and\nGSM-Plus show that CoLD consistently reduces reward-length correlation,\nimproves accuracy in step selection, and encourages more concise, logically\nvalid reasoning. These results demonstrate the effectiveness and practicality\nof CoLD in improving the fidelity and robustness of PRMs.",
      "pdf_url": "http://arxiv.org/pdf/2507.15698v1",
      "published": "2025-07-21T15:07:59+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.15698v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "LINR-PCGC: Lossless Implicit Neural Representations for Point Cloud Geometry Compression",
      "authors": [
        "Wenjie Huang",
        "Qi Yang",
        "Shuting Xia",
        "He Huang",
        "Zhu Li",
        "Yiling Xu"
      ],
      "abstract": "Existing AI-based point cloud compression methods struggle with dependence on\nspecific training data distributions, which limits their real-world deployment.\nImplicit Neural Representation (INR) methods solve the above problem by\nencoding overfitted network parameters to the bitstream, resulting in more\ndistribution-agnostic results. However, due to the limitation of encoding time\nand decoder size, current INR based methods only consider lossy geometry\ncompression. In this paper, we propose the first INR based lossless point cloud\ngeometry compression method called Lossless Implicit Neural Representations for\nPoint Cloud Geometry Compression (LINR-PCGC). To accelerate encoding speed, we\ndesign a group of point clouds level coding framework with an effective network\ninitialization strategy, which can reduce around 60% encoding time. A\nlightweight coding network based on multiscale SparseConv, consisting of scale\ncontext extraction, child node prediction, and model compression modules, is\nproposed to realize fast inference and compact decoder size. Experimental\nresults show that our method consistently outperforms traditional and AI-based\nmethods: for example, with the convergence time in the MVUB dataset, our method\nreduces the bitstream by approximately 21.21% compared to G-PCC TMC13v23 and\n21.95% compared to SparsePCGC. Our project can be seen on\nhttps://huangwenjie2023.github.io/LINR-PCGC/.",
      "pdf_url": "http://arxiv.org/pdf/2507.15686v1",
      "published": "2025-07-21T14:48:54+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.15686v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Missing value imputation with adversarial random forests -- MissARF",
      "authors": [
        "Pegah Golchian",
        "Jan Kapar",
        "David S. Watson",
        "Marvin N. Wright"
      ],
      "abstract": "Handling missing values is a common challenge in biostatistical analyses,\ntypically addressed by imputation methods. We propose a novel, fast, and\neasy-to-use imputation method called missing value imputation with adversarial\nrandom forests (MissARF), based on generative machine learning, that provides\nboth single and multiple imputation. MissARF employs adversarial random forest\n(ARF) for density estimation and data synthesis. To impute a missing value of\nan observation, we condition on the non-missing values and sample from the\nestimated conditional distribution generated by ARF. Our experiments\ndemonstrate that MissARF performs comparably to state-of-the-art single and\nmultiple imputation methods in terms of imputation quality and fast runtime\nwith no additional costs for multiple imputation.",
      "pdf_url": "http://arxiv.org/pdf/2507.15681v1",
      "published": "2025-07-21T14:44:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.15681v1",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Agentic AI for autonomous anomaly management in complex systems",
      "authors": [
        "Reza Vatankhah Barenji",
        "Sina Khoshgoftar"
      ],
      "abstract": "This paper explores the potential of agentic AI in autonomously detecting and\nresponding to anomalies within complex systems, emphasizing its ability to\ntransform traditional, human-dependent anomaly management methods.",
      "pdf_url": "http://arxiv.org/pdf/2507.15676v1",
      "published": "2025-07-21T14:39:08+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.15676v1",
      "categories": [
        "cs.AI",
        "cs.ET"
      ]
    },
    {
      "title": "SustainDiffusion: Optimising the Social and Environmental Sustainability of Stable Diffusion Models",
      "authors": [
        "Giordano d'Aloisio",
        "Tosin Fadahunsi",
        "Jay Choy",
        "Rebecca Moussa",
        "Federica Sarro"
      ],
      "abstract": "Background: Text-to-image generation models are widely used across numerous\ndomains. Among these models, Stable Diffusion (SD) - an open-source\ntext-to-image generation model - has become the most popular, producing over 12\nbillion images annually. However, the widespread use of these models raises\nconcerns regarding their social and environmental sustainability.\n  Aims: To reduce the harm that SD models may have on society and the\nenvironment, we introduce SustainDiffusion, a search-based approach designed to\nenhance the social and environmental sustainability of SD models.\n  Method: SustainDiffusion searches the optimal combination of hyperparameters\nand prompt structures that can reduce gender and ethnic bias in generated\nimages while also lowering the energy consumption required for image\ngeneration. Importantly, SustainDiffusion maintains image quality comparable to\nthat of the original SD model.\n  Results: We conduct a comprehensive empirical evaluation of SustainDiffusion,\ntesting it against six different baselines using 56 different prompts. Our\nresults demonstrate that SustainDiffusion can reduce gender bias in SD3 by 68%,\nethnic bias by 59%, and energy consumption (calculated as the sum of CPU and\nGPU energy) by 48%. Additionally, the outcomes produced by SustainDiffusion are\nconsistent across multiple runs and can be generalised to various prompts.\n  Conclusions: With SustainDiffusion, we demonstrate how enhancing the social\nand environmental sustainability of text-to-image generation models is possible\nwithout fine-tuning or changing the model's architecture.",
      "pdf_url": "http://arxiv.org/pdf/2507.15663v1",
      "published": "2025-07-21T14:24:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.15663v1",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "Towards Explainable Anomaly Detection in Shared Mobility Systems",
      "authors": [
        "Elnur Isgandarov",
        "Matteo Cederle",
        "Federico Chiariotti",
        "Gian Antonio Susto"
      ],
      "abstract": "Shared mobility systems, such as bike-sharing networks, play a crucial role\nin urban transportation. Identifying anomalies in these systems is essential\nfor optimizing operations, improving service reliability, and enhancing user\nexperience. This paper presents an interpretable anomaly detection framework\nthat integrates multi-source data, including bike-sharing trip records, weather\nconditions, and public transit availability. The Isolation Forest algorithm is\nemployed for unsupervised anomaly detection, along with the Depth-based\nIsolation Forest Feature Importance (DIFFI) algorithm providing\ninterpretability. Results show that station-level analysis offers a robust\nunderstanding of anomalies, highlighting the influence of external factors such\nas adverse weather and limited transit availability. Our findings contribute to\nimproving decision-making in shared mobility operations.",
      "pdf_url": "http://arxiv.org/pdf/2507.15643v1",
      "published": "2025-07-21T14:06:42+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.15643v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Leveraging Context for Multimodal Fallacy Classification in Political Debates",
      "authors": [
        "Alessio Pittiglio"
      ],
      "abstract": "In this paper, we present our submission to the MM-ArgFallacy2025 shared\ntask, which aims to advance research in multimodal argument mining, focusing on\nlogical fallacies in political debates. Our approach uses pretrained\nTransformer-based models and proposes several ways to leverage context. In the\nfallacy classification subtask, our models achieved macro F1-scores of 0.4444\n(text), 0.3559 (audio), and 0.4403 (multimodal). Our multimodal model showed\nperformance comparable to the text-only model, suggesting potential for\nimprovements.",
      "pdf_url": "http://arxiv.org/pdf/2507.15641v1",
      "published": "2025-07-21T14:03:08+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.15641v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Data Mixing Agent: Learning to Re-weight Domains for Continual Pre-training",
      "authors": [
        "Kailai Yang",
        "Xiao Liu",
        "Lei Ji",
        "Hao Li",
        "Yeyun Gong",
        "Peng Cheng",
        "Mao Yang"
      ],
      "abstract": "Continual pre-training on small-scale task-specific data is an effective\nmethod for improving large language models in new target fields, yet it risks\ncatastrophic forgetting of their original capabilities. A common solution is to\nre-weight training data mixtures from source and target fields on a domain\nspace to achieve balanced performance. Previous domain reweighting strategies\nrely on manual designation with certain heuristics based on human intuition or\nempirical results. In this work, we prove that more general heuristics can be\nparameterized by proposing Data Mixing Agent, the first model-based, end-to-end\nframework that learns to re-weight domains. The agent learns generalizable\nheuristics through reinforcement learning on large quantities of data mixing\ntrajectories with corresponding feedback from an evaluation environment.\nExperiments in continual pre-training on math reasoning show that Data Mixing\nAgent outperforms strong baselines in achieving balanced performance across\nsource and target field benchmarks. Furthermore, it generalizes well across\nunseen source fields, target models, and domain spaces without retraining.\nDirect application to the code generation field also indicates its adaptability\nacross target domains. Further analysis showcases the agents' well-aligned\nheuristics with human intuitions and their efficiency in achieving superior\nmodel performance with less source-field data.",
      "pdf_url": "http://arxiv.org/pdf/2507.15640v1",
      "published": "2025-07-21T14:01:54+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.15640v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Uncovering Critical Features for Deepfake Detection through the Lottery Ticket Hypothesis",
      "authors": [
        "Lisan Al Amin",
        "Md. Ismail Hossain",
        "Thanh Thi Nguyen",
        "Tasnim Jahan",
        "Mahbubul Islam",
        "Faisal Quader"
      ],
      "abstract": "Recent advances in deepfake technology have created increasingly convincing\nsynthetic media that poses significant challenges to information integrity and\nsocial trust. While current detection methods show promise, their underlying\nmechanisms remain poorly understood, and the large sizes of their models make\nthem challenging to deploy in resource-limited environments. This study\ninvestigates the application of the Lottery Ticket Hypothesis (LTH) to deepfake\ndetection, aiming to identify the key features crucial for recognizing\ndeepfakes. We examine how neural networks can be efficiently pruned while\nmaintaining high detection accuracy. Through extensive experiments with\nMesoNet, CNN-5, and ResNet-18 architectures on the OpenForensic and\nFaceForensics++ datasets, we find that deepfake detection networks contain\nwinning tickets, i.e., subnetworks, that preserve performance even at\nsubstantial sparsity levels. Our results indicate that MesoNet retains 56.2%\naccuracy at 80% sparsity on the OpenForensic dataset, with only 3,000\nparameters, which is about 90% of its baseline accuracy (62.6%). The results\nalso show that our proposed LTH-based iterative magnitude pruning approach\nconsistently outperforms one-shot pruning methods. Using Grad-CAM\nvisualization, we analyze how pruned networks maintain their focus on critical\nfacial regions for deepfake detection. Additionally, we demonstrate the\ntransferability of winning tickets across datasets, suggesting potential for\nefficient, deployable deepfake detection systems.",
      "pdf_url": "http://arxiv.org/pdf/2507.15636v1",
      "published": "2025-07-21T13:58:24+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.15636v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "TacticCraft: Natural Language-Driven Tactical Adaptation for StarCraft II",
      "authors": [
        "Weiyu Ma",
        "Jiwen Jiang",
        "Haobo Fu",
        "Haifeng Zhang"
      ],
      "abstract": "We present an adapter-based approach for tactical conditioning of StarCraft\nII AI agents. Current agents, while powerful, lack the ability to adapt their\nstrategies based on high-level tactical directives. Our method freezes a\npre-trained policy network (DI-Star) and attaches lightweight adapter modules\nto each action head, conditioned on a tactical tensor that encodes strategic\npreferences. By training these adapters with KL divergence constraints, we\nensure the policy maintains core competencies while exhibiting tactical\nvariations. Experimental results show our approach successfully modulates agent\nbehavior across tactical dimensions including aggression, expansion patterns,\nand technology preferences, while maintaining competitive performance. Our\nmethod enables flexible tactical control with minimal computational overhead,\noffering practical strategy customization for complex real-time strategy games.",
      "pdf_url": "http://arxiv.org/pdf/2507.15618v1",
      "published": "2025-07-21T13:42:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.15618v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Why can't Epidemiology be automated (yet)?",
      "authors": [
        "David Bann",
        "Ed Lowther",
        "Liam Wright",
        "Yevgeniya Kovalchuk"
      ],
      "abstract": "Recent advances in artificial intelligence (AI) - particularly generative AI\n- present new opportunities to accelerate, or even automate, epidemiological\nresearch. Unlike disciplines based on physical experimentation, a sizable\nfraction of Epidemiology relies on secondary data analysis and thus is\nwell-suited for such augmentation. Yet, it remains unclear which specific tasks\ncan benefit from AI interventions or where roadblocks exist. Awareness of\ncurrent AI capabilities is also mixed. Here, we map the landscape of\nepidemiological tasks using existing datasets - from literature review to data\naccess, analysis, writing up, and dissemination - and identify where existing\nAI tools offer efficiency gains. While AI can increase productivity in some\nareas such as coding and administrative tasks, its utility is constrained by\nlimitations of existing AI models (e.g. hallucinations in literature reviews)\nand human systems (e.g. barriers to accessing datasets). Through examples of\nAI-generated epidemiological outputs, including fully AI-generated papers, we\ndemonstrate that recently developed agentic systems can now design and execute\nepidemiological analysis, albeit to varied quality (see\nhttps://github.com/edlowther/automated-epidemiology). Epidemiologists have new\nopportunities to empirically test and benchmark AI systems; realising the\npotential of AI will require two-way engagement between epidemiologists and\nengineers.",
      "pdf_url": "http://arxiv.org/pdf/2507.15617v1",
      "published": "2025-07-21T13:41:52+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.15617v1",
      "categories": [
        "cs.CY",
        "cs.AI"
      ]
    },
    {
      "title": "Accelerating HEC-RAS: A Recurrent Neural Operator for Rapid River Forecasting",
      "authors": [
        "Edward Holmberg",
        "Pujan Pokhrel",
        "Maximilian Zoch",
        "Elias Ioup",
        "Ken Pathak",
        "Steven Sloan",
        "Kendall Niles",
        "Jay Ratcliff",
        "Maik Flanagin",
        "Christian Guetl",
        "Julian Simeonov",
        "Mahdi Abdelguerfi"
      ],
      "abstract": "Physics-based solvers like HEC-RAS provide high-fidelity river forecasts but\nare too computationally intensive for on-the-fly decision-making during flood\nevents. The central challenge is to accelerate these simulations without\nsacrificing accuracy. This paper introduces a deep learning surrogate that\ntreats HEC-RAS not as a solver but as a data-generation engine. We propose a\nhybrid, auto-regressive architecture that combines a Gated Recurrent Unit (GRU)\nto capture short-term temporal dynamics with a Geometry-Aware Fourier Neural\nOperator (Geo-FNO) to model long-range spatial dependencies along a river\nreach. The model learns underlying physics implicitly from a minimal\neight-channel feature vector encoding dynamic state, static geometry, and\nboundary forcings extracted directly from native HEC-RAS files. Trained on 67\nreaches of the Mississippi River Basin, the surrogate was evaluated on a\nyear-long, unseen hold-out simulation. Results show the model achieves a strong\npredictive accuracy, with a median absolute stage error of 0.31 feet.\nCritically, for a full 67-reach ensemble forecast, our surrogate reduces the\nrequired wall-clock time from 139 minutes to 40 minutes, a speedup of nearly\n3.5 times over the traditional solver. The success of this data-driven approach\ndemonstrates that robust feature engineering can produce a viable, high-speed\nreplacement for conventional hydraulic models, improving the computational\nfeasibility of large-scale ensemble flood forecasting.",
      "pdf_url": "http://arxiv.org/pdf/2507.15614v1",
      "published": "2025-07-21T13:38:54+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.15614v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Multi-Stage Prompt Inference Attacks on Enterprise LLM Systems",
      "authors": [
        "Andrii Balashov",
        "Olena Ponomarova",
        "Xiaohua Zhai"
      ],
      "abstract": "Large Language Models (LLMs) deployed in enterprise settings (e.g., as\nMicrosoft 365 Copilot) face novel security challenges. One critical threat is\nprompt inference attacks: adversaries chain together seemingly benign prompts\nto gradually extract confidential data. In this paper, we present a\ncomprehensive study of multi-stage prompt inference attacks in an enterprise\nLLM context. We simulate realistic attack scenarios where an attacker uses\nmild-mannered queries and indirect prompt injections to exploit an LLM\nintegrated with private corporate data. We develop a formal threat model for\nthese multi-turn inference attacks and analyze them using probability theory,\noptimization frameworks, and information-theoretic leakage bounds. The attacks\nare shown to reliably exfiltrate sensitive information from the LLM's context\n(e.g., internal SharePoint documents or emails), even when standard safety\nmeasures are in place.\n  We propose and evaluate defenses to counter such attacks, including\nstatistical anomaly detection, fine-grained access control, prompt sanitization\ntechniques, and architectural modifications to LLM deployment. Each defense is\nsupported by mathematical analysis or experimental simulation. For example, we\nderive bounds on information leakage under differential privacy-based training\nand demonstrate an anomaly detection method that flags multi-turn attacks with\nhigh AUC. We also introduce an approach called \"spotlighting\" that uses input\ntransformations to isolate untrusted prompt content, reducing attack success by\nan order of magnitude. Finally, we provide a formal proof of concept and\nempirical validation for a combined defense-in-depth strategy. Our work\nhighlights that securing LLMs in enterprise settings requires moving beyond\nsingle-turn prompt filtering toward a holistic, multi-stage perspective on both\nattacks and defenses.",
      "pdf_url": "http://arxiv.org/pdf/2507.15613v1",
      "published": "2025-07-21T13:38:12+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.15613v1",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "title": "Red-Team Multi-Agent Reinforcement Learning for Emergency Braking Scenario",
      "authors": [
        "Yinsong Chen",
        "Kaifeng Wang",
        "Xiaoqiang Meng",
        "Xueyuan Li",
        "Zirui Li",
        "Xin Gao"
      ],
      "abstract": "Current research on decision-making in safety-critical scenarios often relies\non inefficient data-driven scenario generation or specific modeling approaches,\nwhich fail to capture corner cases in real-world contexts. To address this\nissue, we propose a Red-Team Multi-Agent Reinforcement Learning framework,\nwhere background vehicles with interference capabilities are treated as\nred-team agents. Through active interference and exploration, red-team vehicles\ncan uncover corner cases outside the data distribution. The framework uses a\nConstraint Graph Representation Markov Decision Process, ensuring that red-team\nvehicles comply with safety rules while continuously disrupting the autonomous\nvehicles (AVs). A policy threat zone model is constructed to quantify the\nthreat posed by red-team vehicles to AVs, inducing more extreme actions to\nincrease the danger level of the scenario. Experimental results show that the\nproposed framework significantly impacts AVs decision-making safety and\ngenerates various corner cases. This method also offers a novel direction for\nresearch in safety-critical scenarios.",
      "pdf_url": "http://arxiv.org/pdf/2507.15587v1",
      "published": "2025-07-21T13:08:49+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.15587v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Unequal Voices: How LLMs Construct Constrained Queer Narratives",
      "authors": [
        "Atreya Ghosal",
        "Ashim Gupta",
        "Vivek Srikumar"
      ],
      "abstract": "One way social groups are marginalized in discourse is that the narratives\ntold about them often default to a narrow, stereotyped range of topics. In\ncontrast, default groups are allowed the full complexity of human existence. We\ndescribe the constrained representations of queer people in LLM generations in\nterms of harmful representations, narrow representations, and discursive\nothering and formulate hypotheses to test for these phenomena. Our results show\nthat LLMs are significantly limited in their portrayals of queer personas.",
      "pdf_url": "http://arxiv.org/pdf/2507.15585v1",
      "published": "2025-07-21T13:03:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.15585v1",
      "categories": [
        "cs.CY",
        "cs.AI"
      ]
    },
    {
      "title": "Metric assessment protocol in the context of answer fluctuation on MCQ tasks",
      "authors": [
        "Ekaterina Goliakova",
        "Xavier Renard",
        "Marie-Jeanne Lesot",
        "Thibault Laugel",
        "Christophe Marsala",
        "Marcin Detyniecki"
      ],
      "abstract": "Using multiple-choice questions (MCQs) has become a standard for assessing\nLLM capabilities efficiently. A variety of metrics can be employed for this\ntask. However, previous research has not conducted a thorough assessment of\nthem. At the same time, MCQ evaluation suffers from answer fluctuation: models\nproduce different results given slight changes in prompts. We suggest a metric\nassessment protocol in which evaluation methodologies are analyzed through\ntheir connection with fluctuation rates, as well as original performance. Our\nresults show that there is a strong link between existing metrics and the\nanswer changing, even when computed without any additional prompt variants. A\nnovel metric, worst accuracy, demonstrates the highest association on the\nprotocol.",
      "pdf_url": "http://arxiv.org/pdf/2507.15581v1",
      "published": "2025-07-21T13:01:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.15581v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "GeMix: Conditional GAN-Based Mixup for Improved Medical Image Augmentation",
      "authors": [
        "Hugo Carlesso",
        "Maria Eliza Patulea",
        "Moncef Garouani",
        "Radu Tudor Ionescu",
        "Josiane Mothe"
      ],
      "abstract": "Mixup has become a popular augmentation strategy for image classification,\nyet its naive pixel-wise interpolation often produces unrealistic images that\ncan hinder learning, particularly in high-stakes medical applications. We\npropose GeMix, a two-stage framework that replaces heuristic blending with a\nlearned, label-aware interpolation powered by class-conditional GANs. First, a\nStyleGAN2-ADA generator is trained on the target dataset. During augmentation,\nwe sample two label vectors from Dirichlet priors biased toward different\nclasses and blend them via a Beta-distributed coefficient. Then, we condition\nthe generator on this soft label to synthesize visually coherent images that\nlie along a continuous class manifold. We benchmark GeMix on the large-scale\nCOVIDx-CT-3 dataset using three backbones (ResNet-50, ResNet-101,\nEfficientNet-B0). When combined with real data, our method increases macro-F1\nover traditional mixup for all backbones, reducing the false negative rate for\nCOVID-19 detection. GeMix is thus a drop-in replacement for pixel-space mixup,\ndelivering stronger regularization and greater semantic fidelity, without\ndisrupting existing training pipelines. We publicly release our code at\nhttps://github.com/hugocarlesso/GeMix to foster reproducibility and further\nresearch.",
      "pdf_url": "http://arxiv.org/pdf/2507.15577v1",
      "published": "2025-07-21T12:58:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.15577v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "On the Role of AI in Managing Satellite Constellations: Insights from the ConstellAI Project",
      "authors": [
        "Gregory F. Stock",
        "Juan A. Fraire",
        "Holger Hermanns",
        "Jędrzej Mosiężny",
        "Yusra Al-Khazraji",
        "Julio Ramírez Molina",
        "Evridiki V. Ntagiou"
      ],
      "abstract": "The rapid expansion of satellite constellations in near-Earth orbits presents\nsignificant challenges in satellite network management, requiring innovative\napproaches for efficient, scalable, and resilient operations. This paper\nexplores the role of Artificial Intelligence (AI) in optimizing the operation\nof satellite mega-constellations, drawing from the ConstellAI project funded by\nthe European Space Agency (ESA). A consortium comprising GMV GmbH, Saarland\nUniversity, and Thales Alenia Space collaborates to develop AI-driven\nalgorithms and demonstrates their effectiveness over traditional methods for\ntwo crucial operational challenges: data routing and resource allocation. In\nthe routing use case, Reinforcement Learning (RL) is used to improve the\nend-to-end latency by learning from historical queuing latency, outperforming\nclassical shortest path algorithms. For resource allocation, RL optimizes the\nscheduling of tasks across constellations, focussing on efficiently using\nlimited resources such as battery and memory. Both use cases were tested for\nmultiple satellite constellation configurations and operational scenarios,\nresembling the real-life spacecraft operations of communications and Earth\nobservation satellites. This research demonstrates that RL not only competes\nwith classical approaches but also offers enhanced flexibility, scalability,\nand generalizability in decision-making processes, which is crucial for the\nautonomous and intelligent management of satellite fleets. The findings of this\nactivity suggest that AI can fundamentally alter the landscape of satellite\nconstellation management by providing more adaptive, robust, and cost-effective\nsolutions.",
      "pdf_url": "http://arxiv.org/pdf/2507.15574v1",
      "published": "2025-07-21T12:56:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.15574v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    }
  ]
}