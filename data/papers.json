{
  "last_updated": "2025-07-10T00:54:41.390197",
  "papers": [
    {
      "title": "Agent KB: Leveraging Cross-Domain Experience for Agentic Problem Solving",
      "authors": [
        "Xiangru Tang",
        "Tianrui Qin",
        "Tianhao Peng",
        "Ziyang Zhou",
        "Daniel Shao",
        "Tingting Du",
        "Xinming Wei",
        "Peng Xia",
        "Fang Wu",
        "He Zhu",
        "Ge Zhang",
        "Jiaheng Liu",
        "Xingyao Wang",
        "Sirui Hong",
        "Chenglin Wu",
        "Hao Cheng",
        "Chi Wang",
        "Wangchunshu Zhou"
      ],
      "abstract": "As language agents tackle increasingly complex tasks, they struggle with\neffective error correction and experience reuse across domains. We introduce\nAgent KB, a hierarchical experience framework that enables complex agentic\nproblem solving via a novel Reason-Retrieve-Refine pipeline. Agent KB addresses\na core limitation: agents traditionally cannot learn from each other's\nexperiences. By capturing both high-level strategies and detailed execution\nlogs, Agent KB creates a shared knowledge base that enables cross-agent\nknowledge transfer. Evaluated on the GAIA benchmark, Agent KB improves success\nrates by up to 16.28 percentage points. On the most challenging tasks, Claude-3\nimproves from 38.46% to 57.69%, while GPT-4 improves from 53.49% to 73.26% on\nintermediate tasks. On SWE-bench code repair, Agent KB enables Claude-3 to\nimprove from 41.33% to 53.33%. Our results suggest that Agent KB provides a\nmodular, framework-agnostic infrastructure for enabling agents to learn from\npast experiences and generalize successful strategies to new tasks.",
      "pdf_url": "http://arxiv.org/pdf/2507.06229v1",
      "published": "2025-07-08T17:59:22+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.06229v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "EC-Flow: Enabling Versatile Robotic Manipulation from Action-Unlabeled Videos via Embodiment-Centric Flow",
      "authors": [
        "Yixiang Chen",
        "Peiyan Li",
        "Yan Huang",
        "Jiabing Yang",
        "Kehan Chen",
        "Liang Wang"
      ],
      "abstract": "Current language-guided robotic manipulation systems often require low-level\naction-labeled datasets for imitation learning. While object-centric flow\nprediction methods mitigate this issue, they remain limited to scenarios\ninvolving rigid objects with clear displacement and minimal occlusion. In this\nwork, we present Embodiment-Centric Flow (EC-Flow), a framework that directly\nlearns manipulation from action-unlabeled videos by predicting\nembodiment-centric flow. Our key insight is that incorporating the embodiment's\ninherent kinematics significantly enhances generalization to versatile\nmanipulation scenarios, including deformable object handling, occlusions, and\nnon-object-displacement tasks. To connect the EC-Flow with language\ninstructions and object interactions, we further introduce a goal-alignment\nmodule by jointly optimizing movement consistency and goal-image prediction.\nMoreover, translating EC-Flow to executable robot actions only requires a\nstandard robot URDF (Unified Robot Description Format) file to specify\nkinematic constraints across joints, which makes it easy to use in practice. We\nvalidate EC-Flow on both simulation (Meta-World) and real-world tasks,\ndemonstrating its state-of-the-art performance in occluded object handling (62%\nimprovement), deformable object manipulation (45% improvement), and\nnon-object-displacement tasks (80% improvement) than prior state-of-the-art\nobject-centric flow methods. For more information, see our project website at\nhttps://ec-flow1.github.io .",
      "pdf_url": "http://arxiv.org/pdf/2507.06224v1",
      "published": "2025-07-08T17:57:03+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.06224v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "Efficiency-Effectiveness Reranking FLOPs for LLM-based Rerankers",
      "authors": [
        "Zhiyuan Peng",
        "Ting-ruen Wei",
        "Tingyu Song",
        "Yilun Zhao",
        "Yi Fang"
      ],
      "abstract": "Large Language Models (LLMs) have recently been applied to reranking tasks in\ninformation retrieval, achieving strong performance. However, their high\ncomputational demands often hinder practical deployment. Existing studies\nevaluate the efficiency of LLM-based rerankers using proxy metrics such as\nlatency, the number of forward passes, input tokens, and output tokens.\nHowever, these metrics depend on hardware and running-time choices (\\eg\nparallel or not, batch size, etc), and often fail to account for model size,\nmaking it difficult to interpret and obscuring the evaluation of the\nefficiency-effectiveness tradeoff. To address this issue, we propose\nE\\textsuperscript{2}R-FLOPs, for LLM-based rerankers: ranking metrics per\nPetaFLOP (RPP) for relevance per compute and queries per PetaFLOP (QPP) for\nhardware-agnostic throughput. Companied with the new metrics, an interpretable\nFLOPs estimator is built to estimate the FLOPs of an LLM-based reranker even\nwithout running any experiments. Based on the proposed metrics, we conduct\ncomprehensive experiments to evaluate a wide range of LLM-based rerankers with\ndifferent architecture, studying the efficiency-effectiveness trade-off and\nbringing this issue to the attention of the research community.",
      "pdf_url": "http://arxiv.org/pdf/2507.06223v1",
      "published": "2025-07-08T17:56:28+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.06223v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Aligned Textual Scoring Rules",
      "authors": [
        "Yuxuan Lu",
        "Yifan Wu",
        "Jason Hartline",
        "Michael J. Curry"
      ],
      "abstract": "Scoring rules elicit probabilistic predictions from a strategic agent by\nscoring the prediction against a ground truth state. A scoring rule is proper\nif, from the agent's perspective, reporting the true belief maximizes the\nexpected score. With the development of language models, Wu and Hartline (2024)\nproposes a reduction from textual information elicitation to the numerical\n(i.e. probabilistic) information elicitation problem, which achieves provable\nproperness for textual elicitation. However, not all proper scoring rules are\nwell aligned with human preference over text. Our paper designs the Aligned\nScoring rule (ASR) for text by optimizing and minimizing the mean squared error\nbetween a proper scoring rule and a reference score (e.g. human score). Our\nexperiments show that our ASR outperforms previous methods in aligning with\nhuman preference while maintaining properness.",
      "pdf_url": "http://arxiv.org/pdf/2507.06221v1",
      "published": "2025-07-08T17:53:22+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.06221v1",
      "categories": [
        "cs.AI",
        "cs.GT"
      ]
    },
    {
      "title": "Is Diversity All You Need for Scalable Robotic Manipulation?",
      "authors": [
        "Modi Shi",
        "Li Chen",
        "Jin Chen",
        "Yuxiang Lu",
        "Chiming Liu",
        "Guanghui Ren",
        "Ping Luo",
        "Di Huang",
        "Maoqing Yao",
        "Hongyang Li"
      ],
      "abstract": "Data scaling has driven remarkable success in foundation models for Natural\nLanguage Processing (NLP) and Computer Vision (CV), yet the principles of\neffective data scaling in robotic manipulation remain insufficiently\nunderstood. In this work, we investigate the nuanced role of data diversity in\nrobot learning by examining three critical dimensions-task (what to do),\nembodiment (which robot to use), and expert (who demonstrates)-challenging the\nconventional intuition of \"more diverse is better\". Throughout extensive\nexperiments on various robot platforms, we reveal that (1) task diversity\nproves more critical than per-task demonstration quantity, benefiting transfer\nfrom diverse pre-training tasks to novel downstream scenarios; (2)\nmulti-embodiment pre-training data is optional for cross-embodiment\ntransfer-models trained on high-quality single-embodiment data can efficiently\ntransfer to different platforms, showing more desirable scaling property during\nfine-tuning than multi-embodiment pre-trained models; and (3) expert diversity,\narising from individual operational preferences and stochastic variations in\nhuman demonstrations, can be confounding to policy learning, with velocity\nmultimodality emerging as a key contributing factor. Based on this insight, we\npropose a distribution debiasing method to mitigate velocity ambiguity, the\nyielding GO-1-Pro achieves substantial performance gains of 15%, equivalent to\nusing 2.5 times pre-training data. Collectively, these findings provide new\nperspectives and offer practical guidance on how to scale robotic manipulation\ndatasets effectively.",
      "pdf_url": "http://arxiv.org/pdf/2507.06219v1",
      "published": "2025-07-08T17:52:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.06219v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Identifiability in Causal Abstractions: A Hierarchy of Criteria",
      "authors": [
        "Clément Yvernes",
        "Emilie Devijver",
        "Marianne Clausel",
        "Eric Gaussier"
      ],
      "abstract": "Identifying the effect of a treatment from observational data typically\nrequires assuming a fully specified causal diagram. However, such diagrams are\nrarely known in practice, especially in complex or high-dimensional settings.\nTo overcome this limitation, recent works have explored the use of causal\nabstractions-simplified representations that retain partial causal information.\nIn this paper, we consider causal abstractions formalized as collections of\ncausal diagrams, and focus on the identifiability of causal queries within such\ncollections. We introduce and formalize several identifiability criteria under\nthis setting. Our main contribution is to organize these criteria into a\nstructured hierarchy, highlighting their relationships. This hierarchical view\nenables a clearer understanding of what can be identified under varying levels\nof causal knowledge. We illustrate our framework through examples from the\nliterature and provide tools to reason about identifiability when full causal\nknowledge is unavailable.",
      "pdf_url": "http://arxiv.org/pdf/2507.06213v1",
      "published": "2025-07-08T17:46:08+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.06213v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Differential Mamba",
      "authors": [
        "Nadav Schneider",
        "Itamar Zimerman",
        "Eliya Nachmani"
      ],
      "abstract": "Sequence models like Transformers and RNNs often overallocate attention to\nirrelevant context, leading to noisy intermediate representations. This\ndegrades LLM capabilities by promoting hallucinations, weakening long-range and\nretrieval abilities, and reducing robustness. Recent work has shown that\ndifferential design can mitigate this issue in Transformers, improving their\neffectiveness across various applications. In this paper, we explore whether\nthese techniques, originally developed for Transformers, can be applied to\nMamba, a recent architecture based on selective state-space layers that\nachieves Transformer-level performance with greater efficiency. We show that a\nnaive adaptation of differential design to Mamba is insufficient and requires\ncareful architectural modifications. To address this, we introduce a novel\ndifferential mechanism for Mamba, empirically validated on language modeling\nbenchmarks, demonstrating improved retrieval capabilities and superior\nperformance over vanilla Mamba. Finally, we conduct extensive ablation studies\nand empirical analyses to justify our design choices and provide evidence that\nour approach effectively mitigates the overallocation problem in Mamba-based\nmodels. Our code is publicly available.",
      "pdf_url": "http://arxiv.org/pdf/2507.06204v1",
      "published": "2025-07-08T17:30:14+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.06204v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "UQLM: A Python Package for Uncertainty Quantification in Large Language Models",
      "authors": [
        "Dylan Bouchard",
        "Mohit Singh Chauhan",
        "David Skarbrevik",
        "Ho-Kyeong Ra",
        "Viren Bajaj",
        "Zeya Ahmad"
      ],
      "abstract": "Hallucinations, defined as instances where Large Language Models (LLMs)\ngenerate false or misleading content, pose a significant challenge that impacts\nthe safety and trust of downstream applications. We introduce UQLM, a Python\npackage for LLM hallucination detection using state-of-the-art uncertainty\nquantification (UQ) techniques. This toolkit offers a suite of UQ-based scorers\nthat compute response-level confidence scores ranging from 0 to 1. This library\nprovides an off-the-shelf solution for UQ-based hallucination detection that\ncan be easily integrated to enhance the reliability of LLM outputs.",
      "pdf_url": "http://arxiv.org/pdf/2507.06196v1",
      "published": "2025-07-08T17:22:32+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.06196v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "SQLBarber: A System Leveraging Large Language Models to Generate Customized and Realistic SQL Workloads",
      "authors": [
        "Jiale Lao",
        "Immanuel Trummer"
      ],
      "abstract": "Database research and development often require a large number of SQL queries\nfor benchmarking purposes. However, acquiring real-world SQL queries is\nchallenging due to privacy concerns, and existing SQL generation methods are\nlimited in customization and in satisfying realistic constraints. To address\nthis issue, we present SQLBarber, a system based on Large Language Models\n(LLMs) to generate customized and realistic SQL workloads. SQLBarber (i)\neliminates the need for users to manually craft SQL templates in advance, while\nproviding the flexibility to accept natural language specifications to\nconstrain SQL templates, (ii) scales efficiently to generate large volumes of\nqueries matching any user-defined cost distribution (e.g., cardinality and\nexecution plan cost), and (iii) uses execution statistics from Amazon Redshift\nand Snowflake to derive SQL template specifications and query cost\ndistributions that reflect real-world query characteristics. SQLBarber\nintroduces (i) a declarative interface for users to effortlessly generate\ncustomized SQL templates, (ii) an LLM-powered pipeline augmented with a\nself-correction module that profiles, refines, and prunes SQL templates based\non query costs, and (iii) a Bayesian Optimizer to efficiently explore different\npredicate values and identify a set of queries that satisfy the target cost\ndistribution. We construct and open-source ten benchmarks of varying difficulty\nlevels and target query cost distributions based on real-world statistics from\nSnowflake and Amazon Redshift. Extensive experiments on these benchmarks show\nthat SQLBarber is the only system that can generate customized SQL templates.\nIt reduces query generation time by one to three orders of magnitude, and\nsignificantly improves alignment with the target cost distribution, compared\nwith existing methods.",
      "pdf_url": "http://arxiv.org/pdf/2507.06192v1",
      "published": "2025-07-08T17:20:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.06192v1",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    },
    {
      "title": "DS@GT at CheckThat! 2025: Detecting Subjectivity via Transfer-Learning and Corrective Data Augmentation",
      "authors": [
        "Maximilian Heil",
        "Dionne Bang"
      ],
      "abstract": "This paper presents our submission to Task 1, Subjectivity Detection, of the\nCheckThat! Lab at CLEF 2025. We investigate the effectiveness of\ntransfer-learning and stylistic data augmentation to improve classification of\nsubjective and objective sentences in English news text. Our approach contrasts\nfine-tuning of pre-trained encoders and transfer-learning of fine-tuned\ntransformer on related tasks. We also introduce a controlled augmentation\npipeline using GPT-4o to generate paraphrases in predefined subjectivity\nstyles. To ensure label and style consistency, we employ the same model to\ncorrect and refine the generated samples. Results show that transfer-learning\nof specified encoders outperforms fine-tuning general-purpose ones, and that\ncarefully curated augmentation significantly enhances model robustness,\nespecially in detecting subjective content. Our official submission placed us\n$16^{th}$ of 24 participants. Overall, our findings underscore the value of\ncombining encoder specialization with label-consistent augmentation for\nimproved subjectivity detection. Our code is available at\nhttps://github.com/dsgt-arc/checkthat-2025-subject.",
      "pdf_url": "http://arxiv.org/pdf/2507.06189v1",
      "published": "2025-07-08T17:18:50+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.06189v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "The Delta Learning Hypothesis: Preference Tuning on Weak Data can Yield Strong Gains",
      "authors": [
        "Scott Geng",
        "Hamish Ivison",
        "Chun-Liang Li",
        "Maarten Sap",
        "Jerry Li",
        "Ranjay Krishna",
        "Pang Wei Koh"
      ],
      "abstract": "Improvements in language models are often driven by improving the quality of\nthe data we train them on, which can be limiting when strong supervision is\nscarce. In this work, we show that paired preference data consisting of\nindividually weak data points can enable gains beyond the strength of each\nindividual data point. We formulate the delta learning hypothesis to explain\nthis phenomenon, positing that the relative quality delta between points\nsuffices to drive learning via preference tuning--even when supervised\nfinetuning on the weak data hurts. We validate our hypothesis in controlled\nexperiments and at scale, where we post-train 8B models on preference data\ngenerated by pairing a small 3B model's responses with outputs from an even\nsmaller 1.5B model to create a meaningful delta. Strikingly, on a standard\n11-benchmark evaluation suite (MATH, MMLU, etc.), our simple recipe matches the\nperformance of Tulu 3, a state-of-the-art open model tuned from the same base\nmodel while relying on much stronger supervisors (e.g., GPT-4o). Thus, delta\nlearning enables simpler and cheaper open recipes for state-of-the-art\npost-training. To better understand delta learning, we prove in logistic\nregression that the performance gap between two weak teacher models provides\nuseful signal for improving a stronger student. Overall, our work shows that\nmodels can learn surprisingly well from paired data that might typically be\nconsidered weak.",
      "pdf_url": "http://arxiv.org/pdf/2507.06187v1",
      "published": "2025-07-08T17:14:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.06187v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Hidden Prompts in Manuscripts Exploit AI-Assisted Peer Review",
      "authors": [
        "Zhicheng Lin"
      ],
      "abstract": "In July 2025, 18 academic manuscripts on the preprint website arXiv were\nfound to contain hidden instructions known as prompts designed to manipulate\nAI-assisted peer review. Instructions such as \"GIVE A POSITIVE REVIEW ONLY\"\nwere concealed using techniques like white-colored text. Author responses\nvaried: one planned to withdraw the affected paper, while another defended the\npractice as legitimate testing of reviewer compliance. This commentary analyzes\nthis practice as a novel form of research misconduct. We examine the technique\nof prompt injection in large language models (LLMs), revealing four types of\nhidden prompts, ranging from simple positive review commands to detailed\nevaluation frameworks. The defense that prompts served as \"honeypots\" to detect\nreviewers improperly using AI fails under examination--the consistently\nself-serving nature of prompt instructions indicates intent to manipulate.\nPublishers maintain inconsistent policies: Elsevier prohibits AI use in peer\nreview entirely, while Springer Nature permits limited use with disclosure\nrequirements. The incident exposes systematic vulnerabilities extending beyond\npeer review to any automated system processing scholarly texts, including\nplagiarism detection and citation indexing. Our analysis underscores the need\nfor coordinated technical screening at submission portals and harmonized\npolicies governing generative AI (GenAI) use in academic evaluation.",
      "pdf_url": "http://arxiv.org/pdf/2507.06185v1",
      "published": "2025-07-08T17:11:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.06185v1",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ]
    },
    {
      "title": "Fast Bilateral Teleoperation and Imitation Learning Using Sensorless Force Control via Accurate Dynamics Model",
      "authors": [
        "Koki Yamane",
        "Yunhan Li",
        "Masashi Konosu",
        "Koki Inami",
        "Junji Oaki",
        "Sho Sakaino",
        "Toshiaki Tsuji"
      ],
      "abstract": "In recent years, the advancement of imitation learning has led to increased\ninterest in teleoperating low-cost manipulators to collect demonstration data.\nHowever, most existing systems rely on unilateral control, which only transmits\ntarget position values. While this approach is easy to implement and suitable\nfor slow, non-contact tasks, it struggles with fast or contact-rich operations\ndue to the absence of force feedback. This work demonstrates that fast\nteleoperation with force feedback is feasible even with force-sensorless,\nlow-cost manipulators by leveraging 4-channel bilateral control. Based on\naccurately identified manipulator dynamics, our method integrates nonlinear\nterms compensation, velocity and external force estimation, and variable gain\ncorresponding to inertial variation. Furthermore, using data collected by\n4-channel bilateral control, we show that incorporating force information into\nboth the input and output of learned policies improves performance in imitation\nlearning. These results highlight the practical effectiveness of our system for\nhigh-fidelity teleoperation and data collection on affordable hardware.",
      "pdf_url": "http://arxiv.org/pdf/2507.06174v1",
      "published": "2025-07-08T16:54:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.06174v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ]
    },
    {
      "title": "A Method for Optimizing Connections in Differentiable Logic Gate Networks",
      "authors": [
        "Wout Mommen",
        "Lars Keuninckx",
        "Matthias Hartmann",
        "Piet Wambacq"
      ],
      "abstract": "We introduce a novel method for partial optimization of the connections in\nDeep Differentiable Logic Gate Networks (LGNs). Our training method utilizes a\nprobability distribution over a subset of connections per gate input, selecting\nthe connection with highest merit, after which the gate-types are selected. We\nshow that the connection-optimized LGNs outperform standard fixed-connection\nLGNs on the Yin-Yang, MNIST and Fashion-MNIST benchmarks, while requiring only\na fraction of the number of logic gates. When training all connections, we\ndemonstrate that 8000 simple logic gates are sufficient to achieve over 98% on\nthe MNIST data set. Additionally, we show that our network has 24 times fewer\ngates, while performing better on the MNIST data set compared to standard fully\nconnected LGNs. As such, our work shows a pathway towards fully trainable\nBoolean logic.",
      "pdf_url": "http://arxiv.org/pdf/2507.06173v1",
      "published": "2025-07-08T16:53:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.06173v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Critical Nodes Identification in Complex Networks: A Survey",
      "authors": [
        "Duxin Chen",
        "Jiawen Chen",
        "Xiaoyu Zhang",
        "Qinghan Jia",
        "Xiaolu Liu",
        "Ye Sun",
        "Linyuan Lv",
        "Wenwu Yu"
      ],
      "abstract": "Complex networks have become essential tools for understanding diverse\nphenomena in social systems, traffic systems, biomolecular systems, and\nfinancial systems. Identifying critical nodes is a central theme in\ncontemporary research, serving as a vital bridge between theoretical\nfoundations and practical applications. Nevertheless, the intrinsic complexity\nand structural heterogeneity characterizing real-world networks, with\nparticular emphasis on dynamic and higher-order networks, present substantial\nobstacles to the development of universal frameworks for critical node\nidentification. This paper provides a comprehensive review of critical node\nidentification techniques, categorizing them into seven main classes:\ncentrality, critical nodes deletion problem, influence maximization, network\ncontrol, artificial intelligence, higher-order and dynamic methods. Our review\nbridges the gaps in existing surveys by systematically classifying methods\nbased on their methodological foundations and practical implications, and by\nhighlighting their strengths, limitations, and applicability across different\nnetwork types. Our work enhances the understanding of critical node research by\nidentifying key challenges, such as algorithmic universality, real-time\nevaluation in dynamic networks, analysis of higher-order structures, and\ncomputational efficiency in large-scale networks. The structured synthesis\nconsolidates current progress and highlights open questions, particularly in\nmodeling temporal dynamics, advancing efficient algorithms, integrating machine\nlearning approaches, and developing scalable and interpretable metrics for\ncomplex systems.",
      "pdf_url": "http://arxiv.org/pdf/2507.06164v1",
      "published": "2025-07-08T16:45:48+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.06164v1",
      "categories": [
        "cs.SI",
        "cs.AI",
        "physics.app-ph"
      ]
    },
    {
      "title": "Fast and Accurate Collision Probability Estimation for Autonomous Vehicles using Adaptive Sigma-Point Sampling",
      "authors": [
        "Charles Champagne Cossette",
        "Taylor Scott Clawson",
        "Andrew Feit"
      ],
      "abstract": "A novel algorithm is presented for the estimation of collision probabilities\nbetween dynamic objects with uncertain trajectories, where the trajectories are\ngiven as a sequence of poses with Gaussian distributions. We propose an\nadaptive sigma-point sampling scheme, which ultimately produces a fast, simple\nalgorithm capable of estimating the collision probability with a median error\nof 3.5%, and a median runtime of 0.21ms, when measured on an Intel Xeon Gold\n6226R Processor. Importantly, the algorithm explicitly accounts for the\ncollision probability's temporal dependence, which is often neglected in prior\nwork and otherwise leads to an overestimation of the collision probability.\nFinally, the method is tested on a diverse set of relevant real-world\nscenarios, consisting of 400 6-second snippets of autonomous vehicle logs,\nwhere the accuracy and latency is rigorously evaluated.",
      "pdf_url": "http://arxiv.org/pdf/2507.06149v1",
      "published": "2025-07-08T16:31:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.06149v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CG"
      ]
    },
    {
      "title": "SoftReMish: A Novel Activation Function for Enhanced Convolutional Neural Networks for Visual Recognition Performance",
      "authors": [
        "Mustafa Bayram Gücen"
      ],
      "abstract": "In this study, SoftReMish, a new activation function designed to improve the\nperformance of convolutional neural networks (CNNs) in image classification\ntasks, is proposed. Using the MNIST dataset, a standard CNN architecture\nconsisting of two convolutional layers, max pooling, and fully connected layers\nwas implemented. SoftReMish was evaluated against popular activation functions\nincluding ReLU, Tanh, and Mish by replacing the activation function in all\ntrainable layers. The model performance was assessed in terms of minimum\ntraining loss and maximum validation accuracy. Results showed that SoftReMish\nachieved a minimum loss (3.14e-8) and a validation accuracy (99.41%),\noutperforming all other functions tested. These findings demonstrate that\nSoftReMish offers better convergence behavior and generalization capability,\nmaking it a promising candidate for visual recognition tasks.",
      "pdf_url": "http://arxiv.org/pdf/2507.06148v1",
      "published": "2025-07-08T16:29:14+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.06148v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.NE"
      ]
    },
    {
      "title": "LangMamba: A Language-driven Mamba Framework for Low-dose CT Denoising with Vision-language Models",
      "authors": [
        "Zhihao Chen",
        "Tao Chen",
        "Chenhui Wang",
        "Qi Gao",
        "Huidong Xie",
        "Chuang Niu",
        "Ge Wang",
        "Hongming Shan"
      ],
      "abstract": "Low-dose computed tomography (LDCT) reduces radiation exposure but often\ndegrades image quality, potentially compromising diagnostic accuracy. Existing\ndeep learning-based denoising methods focus primarily on pixel-level mappings,\noverlooking the potential benefits of high-level semantic guidance. Recent\nadvances in vision-language models (VLMs) suggest that language can serve as a\npowerful tool for capturing structured semantic information, offering new\nopportunities to improve LDCT reconstruction. In this paper, we introduce\nLangMamba, a Language-driven Mamba framework for LDCT denoising that leverages\nVLM-derived representations to enhance supervision from normal-dose CT (NDCT).\nLangMamba follows a two-stage learning strategy. First, we pre-train a\nLanguage-guided AutoEncoder (LangAE) that leverages frozen VLMs to map NDCT\nimages into a semantic space enriched with anatomical information. Second, we\nsynergize LangAE with two key components to guide LDCT denoising:\nSemantic-Enhanced Efficient Denoiser (SEED), which enhances NDCT-relevant local\nsemantic while capturing global features with efficient Mamba mechanism, and\nLanguage-engaged Dual-space Alignment (LangDA) Loss, which ensures that\ndenoised images align with NDCT in both perceptual and semantic spaces.\nExtensive experiments on two public datasets demonstrate that LangMamba\noutperforms conventional state-of-the-art methods, significantly improving\ndetail preservation and visual fidelity. Remarkably, LangAE exhibits strong\ngeneralizability to unseen datasets, thereby reducing training costs.\nFurthermore, LangDA loss improves explainability by integrating language-guided\ninsights into image reconstruction and offers a plug-and-play fashion. Our\nfindings shed new light on the potential of language as a supervisory signal to\nadvance LDCT denoising. The code is publicly available on\nhttps://github.com/hao1635/LangMamba.",
      "pdf_url": "http://arxiv.org/pdf/2507.06140v1",
      "published": "2025-07-08T16:22:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.06140v1",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Topic Modeling and Link-Prediction for Material Property Discovery",
      "authors": [
        "Ryan C. Barron",
        "Maksim E. Eren",
        "Valentin Stanev",
        "Cynthia Matuszek",
        "Boian S. Alexandrov"
      ],
      "abstract": "Link prediction infers missing or future relations between graph nodes, based\non connection patterns. Scientific literature networks and knowledge graphs are\ntypically large, sparse, and noisy, and often contain missing links between\nentities. We present an AI-driven hierarchical link prediction framework that\nintegrates matrix factorization to infer hidden associations and steer\ndiscovery in complex material domains. Our method combines Hierarchical\nNonnegative Matrix Factorization (HNMFk) and Boolean matrix factorization\n(BNMFk) with automatic model selection, as well as Logistic matrix\nfactorization (LMF), we use to construct a three-level topic tree from a\n46,862-document corpus focused on 73 transition-metal dichalcogenides (TMDs).\nThese materials are studied in a variety of physics fields with many current\nand potential applications.\n  An ensemble BNMFk + LMF approach fuses discrete interpretability with\nprobabilistic scoring. The resulting HNMFk clusters map each material onto\ncoherent topics like superconductivity, energy storage, and tribology. Also,\nmissing or weakly connected links are highlight between topics and materials,\nsuggesting novel hypotheses for cross-disciplinary exploration. We validate our\nmethod by removing publications about superconductivity in well-known\nsuperconductors, and show the model predicts associations with the\nsuperconducting TMD clusters. This shows the method finds hidden connections in\na graph of material to latent topic associations built from scientific\nliterature, especially useful when examining a diverse corpus of scientific\ndocuments covering the same class of phenomena or materials but originating\nfrom distinct communities and perspectives. The inferred links generating new\nhypotheses, produced by our method, are exposed through an interactive\nStreamlit dashboard, designed for human-in-the-loop scientific discovery.",
      "pdf_url": "http://arxiv.org/pdf/2507.06139v1",
      "published": "2025-07-08T16:20:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.06139v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE"
      ]
    },
    {
      "title": "Coding Triangle: How Does Large Language Model Understand Code?",
      "authors": [
        "Taolin Zhang",
        "Zihan Ma",
        "Maosong Cao",
        "Junnan Liu",
        "Songyang Zhang",
        "Kai Chen"
      ],
      "abstract": "Large language models (LLMs) have achieved remarkable progress in code\ngeneration, yet their true programming competence remains underexplored. We\nintroduce the Code Triangle framework, which systematically evaluates LLMs\nacross three fundamental dimensions: editorial analysis, code implementation,\nand test case generation. Through extensive experiments on competitive\nprogramming benchmarks, we reveal that while LLMs can form a self-consistent\nsystem across these dimensions, their solutions often lack the diversity and\nrobustness of human programmers. We identify a significant distribution shift\nbetween model cognition and human expertise, with model errors tending to\ncluster due to training data biases and limited reasoning transfer. Our study\ndemonstrates that incorporating human-generated editorials, solutions, and\ndiverse test cases, as well as leveraging model mixtures, can substantially\nenhance both the performance and robustness of LLMs. Furthermore, we reveal\nboth the consistency and inconsistency in the cognition of LLMs that may\nfacilitate self-reflection and self-improvement, providing a potential\ndirection for developing more powerful coding models.",
      "pdf_url": "http://arxiv.org/pdf/2507.06138v1",
      "published": "2025-07-08T16:20:43+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.06138v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "NeoBabel: A Multilingual Open Tower for Visual Generation",
      "authors": [
        "Mohammad Mahdi Derakhshani",
        "Dheeraj Varghese",
        "Marzieh Fadaee",
        "Cees G. M. Snoek"
      ],
      "abstract": "Text-to-image generation advancements have been predominantly\nEnglish-centric, creating barriers for non-English speakers and perpetuating\ndigital inequities. While existing systems rely on translation pipelines, these\nintroduce semantic drift, computational overhead, and cultural misalignment. We\nintroduce NeoBabel, a novel multilingual image generation framework that sets a\nnew Pareto frontier in performance, efficiency and inclusivity, supporting six\nlanguages: English, Chinese, Dutch, French, Hindi, and Persian. The model is\ntrained using a combination of large-scale multilingual pretraining and\nhigh-resolution instruction tuning. To evaluate its capabilities, we expand two\nEnglish-only benchmarks to multilingual equivalents: m-GenEval and m-DPG.\nNeoBabel achieves state-of-the-art multilingual performance while retaining\nstrong English capability, scoring 0.75 on m-GenEval and 0.68 on m-DPG.\nNotably, it performs on par with leading models on English tasks while\noutperforming them by +0.11 and +0.09 on multilingual benchmarks, even though\nthese models are built on multilingual base LLMs. This demonstrates the\neffectiveness of our targeted alignment training for preserving and extending\ncrosslingual generalization. We further introduce two new metrics to rigorously\nassess multilingual alignment and robustness to code-mixed prompts. Notably,\nNeoBabel matches or exceeds English-only models while being 2-4x smaller. We\nrelease an open toolkit, including all code, model checkpoints, a curated\ndataset of 124M multilingual text-image pairs, and standardized multilingual\nevaluation protocols, to advance inclusive AI research. Our work demonstrates\nthat multilingual capability is not a trade-off but a catalyst for improved\nrobustness, efficiency, and cultural fidelity in generative AI.",
      "pdf_url": "http://arxiv.org/pdf/2507.06137v1",
      "published": "2025-07-08T16:19:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.06137v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "OpenAgentSafety: A Comprehensive Framework for Evaluating Real-World AI Agent Safety",
      "authors": [
        "Sanidhya Vijayvargiya",
        "Aditya Bharat Soni",
        "Xuhui Zhou",
        "Zora Zhiruo Wang",
        "Nouha Dziri",
        "Graham Neubig",
        "Maarten Sap"
      ],
      "abstract": "Recent advances in AI agents capable of solving complex, everyday tasks, from\nscheduling to customer service, have enabled deployment in real-world settings,\nbut their possibilities for unsafe behavior demands rigorous evaluation. While\nprior benchmarks have attempted to assess agent safety, most fall short by\nrelying on simulated environments, narrow task domains, or unrealistic tool\nabstractions. We introduce OpenAgentSafety, a comprehensive and modular\nframework for evaluating agent behavior across eight critical risk categories.\nUnlike prior work, our framework evaluates agents that interact with real\ntools, including web browsers, code execution environments, file systems, bash\nshells, and messaging platforms; and supports over 350 multi-turn, multi-user\ntasks spanning both benign and adversarial user intents. OpenAgentSafety is\ndesigned for extensibility, allowing researchers to add tools, tasks, websites,\nand adversarial strategies with minimal effort. It combines rule-based analysis\nwith LLM-as-judge assessments to detect both overt and subtle unsafe behaviors.\nEmpirical analysis of five prominent LLMs in agentic scenarios reveals unsafe\nbehavior in 51.2% of safety-vulnerable tasks with Claude-Sonnet-3.7, to 72.7%\nwith o3-mini, highlighting critical safety vulnerabilities and the need for\nstronger safeguards before real-world deployment.",
      "pdf_url": "http://arxiv.org/pdf/2507.06134v1",
      "published": "2025-07-08T16:18:54+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.06134v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "PrefixAgent: An LLM-Powered Design Framework for Efficient Prefix Adder Optimization",
      "authors": [
        "Dongsheng Zuo",
        "Jiadong Zhu",
        "Yang Luo",
        "Yuzhe Ma"
      ],
      "abstract": "Prefix adders are fundamental arithmetic circuits, but their design space\ngrows exponentially with bit-width, posing significant optimization challenges.\nPrevious works face limitations in performance, generalization, and\nscalability. To address these challenges, we propose PrefixAgent, a large\nlanguage model (LLM)-powered framework that enables efficient prefix adder\noptimization. Specifically, PrefixAgent reformulates the problem into subtasks\nincluding backbone synthesis and structure refinement, which effectively\nreduces the search space. More importantly, this new design perspective enables\nus to efficiently collect enormous high-quality data and reasoning traces with\nE-graph, which further results in an effective fine-tuning of LLM. Experimental\nresults show that PrefixAgent synthesizes prefix adders with consistently\nsmaller areas compared to baseline methods, while maintaining scalability and\ngeneralization in commercial EDA flows.",
      "pdf_url": "http://arxiv.org/pdf/2507.06127v1",
      "published": "2025-07-08T16:14:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.06127v1",
      "categories": [
        "cs.AR",
        "cs.AI"
      ]
    },
    {
      "title": "Subspace-based Approximate Hessian Method for Zeroth-Order Optimization",
      "authors": [
        "Dongyoon Kim",
        "Sungjae Lee",
        "Wonjin Lee",
        "Kwang In Kim"
      ],
      "abstract": "Zeroth-order optimization addresses problems where gradient information is\ninaccessible or impractical to compute. While most existing methods rely on\nfirst-order approximations, incorporating second-order (curvature) information\ncan, in principle, significantly accelerate convergence. However, the high cost\nof function evaluations required to estimate Hessian matrices often limits\npractical applicability. We present the subspace-based approximate Hessian\n(ZO-SAH) method, a zeroth-order optimization algorithm that mitigates these\ncosts by focusing on randomly selected two-dimensional subspaces. Within each\nsubspace, ZO-SAH estimates the Hessian by fitting a quadratic polynomial to the\nobjective function and extracting its second-order coefficients. To further\nreduce function-query costs, ZO-SAH employs a periodic subspace-switching\nstrategy that reuses function evaluations across optimization steps.\nExperiments on eight benchmark datasets, including logistic regression and deep\nneural network training tasks, demonstrate that ZO-SAH achieves significantly\nfaster convergence than existing zeroth-order methods.",
      "pdf_url": "http://arxiv.org/pdf/2507.06125v1",
      "published": "2025-07-08T16:11:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.06125v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Speech Quality Assessment Model Based on Mixture of Experts: System-Level Performance Enhancement and Utterance-Level Challenge Analysis",
      "authors": [
        "Xintong Hu",
        "Yixuan Chen",
        "Rui Yang",
        "Wenxiang Guo",
        "Changhao Pan"
      ],
      "abstract": "Automatic speech quality assessment plays a crucial role in the development\nof speech synthesis systems, but existing models exhibit significant\nperformance variations across different granularity levels of prediction tasks.\nThis paper proposes an enhanced MOS prediction system based on self-supervised\nlearning speech models, incorporating a Mixture of Experts (MoE) classification\nhead and utilizing synthetic data from multiple commercial generation models\nfor data augmentation. Our method builds upon existing self-supervised models\nsuch as wav2vec2, designing a specialized MoE architecture to address different\ntypes of speech quality assessment tasks. We also collected a large-scale\nsynthetic speech dataset encompassing the latest text-to-speech, speech\nconversion, and speech enhancement systems. However, despite the adoption of\nthe MoE architecture and expanded dataset, the model's performance improvements\nin sentence-level prediction tasks remain limited. Our work reveals the\nlimitations of current methods in handling sentence-level quality assessment,\nprovides new technical pathways for the field of automatic speech quality\nassessment, and also delves into the fundamental causes of performance\ndifferences across different assessment granularities.",
      "pdf_url": "http://arxiv.org/pdf/2507.06116v1",
      "published": "2025-07-08T16:00:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.06116v1",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ]
    },
    {
      "title": "LighthouseGS: Indoor Structure-aware 3D Gaussian Splatting for Panorama-Style Mobile Captures",
      "authors": [
        "Seungoh Han",
        "Jaehoon Jang",
        "Hyunsu Kim",
        "Jaeheung Surh",
        "Junhyung Kwak",
        "Hyowon Ha",
        "Kyungdon Joo"
      ],
      "abstract": "Recent advances in 3D Gaussian Splatting (3DGS) have enabled real-time novel\nview synthesis (NVS) with impressive quality in indoor scenes. However,\nachieving high-fidelity rendering requires meticulously captured images\ncovering the entire scene, limiting accessibility for general users. We aim to\ndevelop a practical 3DGS-based NVS framework using simple panorama-style motion\nwith a handheld camera (e.g., mobile device). While convenient, this\nrotation-dominant motion and narrow baseline make accurate camera pose and 3D\npoint estimation challenging, especially in textureless indoor scenes. To\naddress these challenges, we propose LighthouseGS, a novel framework inspired\nby the lighthouse-like sweeping motion of panoramic views. LighthouseGS\nleverages rough geometric priors, such as mobile device camera poses and\nmonocular depth estimation, and utilizes the planar structures often found in\nindoor environments. We present a new initialization method called plane\nscaffold assembly to generate consistent 3D points on these structures,\nfollowed by a stable pruning strategy to enhance geometry and optimization\nstability. Additionally, we introduce geometric and photometric corrections to\nresolve inconsistencies from motion drift and auto-exposure in mobile devices.\nTested on collected real and synthetic indoor scenes, LighthouseGS delivers\nphotorealistic rendering, surpassing state-of-the-art methods and demonstrating\nthe potential for panoramic view synthesis and object placement.",
      "pdf_url": "http://arxiv.org/pdf/2507.06109v1",
      "published": "2025-07-08T15:49:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.06109v1",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Taming Data Challenges in ML-based Security Tasks: Lessons from Integrating Generative AI",
      "authors": [
        "Shravya Kanchi",
        "Neal Mangaokar",
        "Aravind Cheruvu",
        "Sifat Muhammad Abdullah",
        "Shirin Nilizadeh",
        "Atul Prakash",
        "Bimal Viswanath"
      ],
      "abstract": "Machine learning-based supervised classifiers are widely used for security\ntasks, and their improvement has been largely focused on algorithmic\nadvancements. We argue that data challenges that negatively impact the\nperformance of these classifiers have received limited attention. We address\nthe following research question: Can developments in Generative AI (GenAI)\naddress these data challenges and improve classifier performance? We propose\naugmenting training datasets with synthetic data generated using GenAI\ntechniques to improve classifier generalization. We evaluate this approach\nacross 7 diverse security tasks using 6 state-of-the-art GenAI methods and\nintroduce a novel GenAI scheme called Nimai that enables highly controlled data\nsynthesis. We find that GenAI techniques can significantly improve the\nperformance of security classifiers, achieving improvements of up to 32.6% even\nin severely data-constrained settings (only ~180 training samples).\nFurthermore, we demonstrate that GenAI can facilitate rapid adaptation to\nconcept drift post-deployment, requiring minimal labeling in the adjustment\nprocess. Despite successes, our study finds that some GenAI schemes struggle to\ninitialize (train and produce data) on certain security tasks. We also identify\ncharacteristics of specific tasks, such as noisy labels, overlapping class\ndistributions, and sparse feature vectors, which hinder performance boost using\nGenAI. We believe that our study will drive the development of future GenAI\ntools designed for security tasks.",
      "pdf_url": "http://arxiv.org/pdf/2507.06092v1",
      "published": "2025-07-08T15:34:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.06092v1",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "QS4D: Quantization-aware training for efficient hardware deployment of structured state-space sequential models",
      "authors": [
        "Sebastian Siegel",
        "Ming-Jay Yang",
        "Younes Bouhadjar",
        "Maxime Fabre",
        "Emre Neftci",
        "John Paul Strachan"
      ],
      "abstract": "Structured State Space models (SSM) have recently emerged as a new class of\ndeep learning models, particularly well-suited for processing long sequences.\nTheir constant memory footprint, in contrast to the linearly scaling memory\ndemands of Transformers, makes them attractive candidates for deployment on\nresource-constrained edge-computing devices. While recent works have explored\nthe effect of quantization-aware training (QAT) on SSMs, they typically do not\naddress its implications for specialized edge hardware, for example, analog\nin-memory computing (AIMC) chips. In this work, we demonstrate that QAT can\nsignificantly reduce the complexity of SSMs by up to two orders of magnitude\nacross various performance metrics. We analyze the relation between model size\nand numerical precision, and show that QAT enhances robustness to analog noise\nand enables structural pruning. Finally, we integrate these techniques to\ndeploy SSMs on a memristive analog in-memory computing substrate and highlight\nthe resulting benefits in terms of computational efficiency.",
      "pdf_url": "http://arxiv.org/pdf/2507.06079v1",
      "published": "2025-07-08T15:19:14+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.06079v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "AI-Based Demand Forecasting and Load Balancing for Optimising Energy use in Healthcare Systems: A real case study",
      "authors": [
        "Iman Rahimi",
        "Isha Patel"
      ],
      "abstract": "This paper tackles the urgent need for efficient energy management in\nhealthcare facilities, where fluctuating demands challenge operational\nefficiency and sustainability. Traditional methods often prove inadequate,\ncausing inefficiencies and higher costs. To address this, the study presents an\nAI-based framework combining Long Short-Term Memory (LSTM), genetic algorithm\n(GA), and SHAP (Shapley Additive Explanations), specifically designed for\nhealthcare energy management. Although LSTM is widely used for time-series\nforecasting, its application in healthcare energy prediction remains\nunderexplored. The results reveal that LSTM significantly outperforms ARIMA and\nProphet models in forecasting complex, non-linear demand patterns. LSTM\nachieves a Mean Absolute Error (MAE) of 21.69 and Root Mean Square Error (RMSE)\nof 29.96, far better than Prophet (MAE: 59.78, RMSE: 81.22) and ARIMA (MAE:\n87.73, RMSE: 125.22), demonstrating superior performance. The genetic algorithm\nis applied to optimize model parameters and improve load balancing strategies,\nenabling adaptive responses to real-time energy fluctuations. SHAP analysis\nfurther enhances model transparency by explaining the influence of different\nfeatures on predictions, fostering trust in decision-making processes. This\nintegrated LSTM-GA-SHAP approach offers a robust solution for improving\nforecasting accuracy, boosting energy efficiency, and advancing sustainability\nin healthcare facilities. Future research may explore real-time deployment and\nhybridization with reinforcement learning for continuous optimization. Overall,\nthe study establishes a solid foundation for using AI in healthcare energy\nmanagement, highlighting its scalability, efficiency, and resilience potential.",
      "pdf_url": "http://arxiv.org/pdf/2507.06077v1",
      "published": "2025-07-08T15:16:50+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.06077v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Contrastive and Transfer Learning for Effective Audio Fingerprinting through a Real-World Evaluation Protocol",
      "authors": [
        "Christos Nikou",
        "Theodoros Giannakopoulos"
      ],
      "abstract": "Recent advances in song identification leverage deep neural networks to learn\ncompact audio fingerprints directly from raw waveforms. While these methods\nperform well under controlled conditions, their accuracy drops significantly in\nreal-world scenarios where the audio is captured via mobile devices in noisy\nenvironments. In this paper, we introduce a novel evaluation protocol designed\nto better reflect such real-world conditions. We generate three recordings of\nthe same audio, each with increasing levels of noise, captured using a mobile\ndevice's microphone. Our results reveal a substantial performance drop for two\nstate-of-the-art CNN-based models under this protocol, compared to previously\nreported benchmarks. Additionally, we highlight the critical role of the\naugmentation pipeline during training with contrastive loss. By introduction\nlow pass and high pass filters in the augmentation pipeline we significantly\nincrease the performance of both systems in our proposed evaluation.\nFurthermore, we develop a transformer-based model with a tailored projection\nmodule and demonstrate that transferring knowledge from a semantically relevant\ndomain yields a more robust solution. The transformer architecture outperforms\nCNN-based models across all noise levels, and query durations. In low noise\nconditions it achieves 47.99% for 1-sec queries, and 97% for 10-sec queries in\nfinding the correct song, surpassing by 14%, and by 18.5% the second-best\nperforming model, respectively, Under heavy noise levels, we achieve a\ndetection rate 56.5% for 15-second query duration. All experiments are\nconducted on public large-scale dataset of over 100K songs, with queries\nmatched against a database of 56 million vectors.",
      "pdf_url": "http://arxiv.org/pdf/2507.06070v1",
      "published": "2025-07-08T15:13:26+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.06070v1",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.IR",
        "cs.LG",
        "eess.AS"
      ]
    },
    {
      "title": "Enhancing Synthetic CT from CBCT via Multimodal Fusion and End-To-End Registration",
      "authors": [
        "Maximilian Tschuchnig",
        "Lukas Lamminger",
        "Philipp Steininger",
        "Michael Gadermayr"
      ],
      "abstract": "Cone-Beam Computed Tomography (CBCT) is widely used for intraoperative\nimaging due to its rapid acquisition and low radiation dose. However, CBCT\nimages typically suffer from artifacts and lower visual quality compared to\nconventional Computed Tomography (CT). A promising solution is synthetic CT\n(sCT) generation, where CBCT volumes are translated into the CT domain. In this\nwork, we enhance sCT generation through multimodal learning by jointly\nleveraging intraoperative CBCT and preoperative CT data. To overcome the\ninherent misalignment between modalities, we introduce an end-to-end learnable\nregistration module within the sCT pipeline. This model is evaluated on a\ncontrolled synthetic dataset, allowing precise manipulation of data quality and\nalignment parameters. Further, we validate its robustness and generalizability\non two real-world clinical datasets. Experimental results demonstrate that\nintegrating registration in multimodal sCT generation improves sCT quality,\noutperforming baseline multimodal methods in 79 out of 90 evaluation settings.\nNotably, the improvement is most significant in cases where CBCT quality is low\nand the preoperative CT is moderately misaligned.",
      "pdf_url": "http://arxiv.org/pdf/2507.06067v1",
      "published": "2025-07-08T15:10:04+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.06067v1",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "VisualSpeaker: Visually-Guided 3D Avatar Lip Synthesis",
      "authors": [
        "Alexandre Symeonidis-Herzig",
        "Özge Mercanoğlu Sincan",
        "Richard Bowden"
      ],
      "abstract": "Realistic, high-fidelity 3D facial animations are crucial for expressive\navatar systems in human-computer interaction and accessibility. Although prior\nmethods show promising quality, their reliance on the mesh domain limits their\nability to fully leverage the rapid visual innovations seen in 2D computer\nvision and graphics. We propose VisualSpeaker, a novel method that bridges this\ngap using photorealistic differentiable rendering, supervised by visual speech\nrecognition, for improved 3D facial animation. Our contribution is a perceptual\nlip-reading loss, derived by passing photorealistic 3D Gaussian Splatting\navatar renders through a pre-trained Visual Automatic Speech Recognition model\nduring training. Evaluation on the MEAD dataset demonstrates that VisualSpeaker\nimproves both the standard Lip Vertex Error metric by 56.1% and the perceptual\nquality of the generated animations, while retaining the controllability of\nmesh-driven animation. This perceptual focus naturally supports accurate\nmouthings, essential cues that disambiguate similar manual signs in sign\nlanguage avatars.",
      "pdf_url": "http://arxiv.org/pdf/2507.06060v1",
      "published": "2025-07-08T15:04:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.06060v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "FEVO: Financial Knowledge Expansion and Reasoning Evolution for Large Language Models",
      "authors": [
        "Bo Pang",
        "Yalu Ouyang",
        "Hangfei Xu",
        "Ziqi Jia",
        "Panpan Li",
        "Shengzhao Wen",
        "Lu Wang",
        "Shiyong Li",
        "Yanpeng Wang"
      ],
      "abstract": "Advancements in reasoning for large language models (LLMs) have lead to\nsignificant performance improvements for LLMs in various fields such as\nmathematics and programming. However, research applying these advances to the\nfinancial domain, where considerable domain-specific knowledge is necessary to\ncomplete tasks, remains limited. To address this gap, we introduce FEVO\n(Financial Evolution), a multi-stage enhancement framework developed to enhance\nLLM performance in the financial domain. FEVO systemically enhances LLM\nperformance by using continued pre-training (CPT) to expand financial domain\nknowledge, supervised fine-tuning (SFT) to instill structured, elaborate\nreasoning patterns, and reinforcement learning (RL) to further integrate the\nexpanded financial domain knowledge with the learned structured reasoning. To\nensure effective and efficient training, we leverage frontier reasoning models\nand rule-based filtering to curate FEVO-Train, high-quality datasets\nspecifically designed for the different post-training phases. Using our\nframework, we train the FEVO series of models - C32B, S32B, R32B - from\nQwen2.5-32B and evaluate them on seven benchmarks to assess financial and\ngeneral capabilities, with results showing that FEVO-R32B achieves\nstate-of-the-art performance on five financial benchmarks against much larger\nmodels as well as specialist models. More significantly, FEVO-R32B demonstrates\nmarkedly better performance than FEVO-R32B-0 (trained from Qwen2.5-32B-Instruct\nusing only RL), thus validating the effectiveness of financial domain knowledge\nexpansion and structured, logical reasoning distillation",
      "pdf_url": "http://arxiv.org/pdf/2507.06057v2",
      "published": "2025-07-08T14:59:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.06057v2",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Entropy-Memorization Law: Evaluating Memorization Difficulty of Data in LLMs",
      "authors": [
        "Yizhan Huang",
        "Zhe Yang",
        "Meifang Chen",
        "Jianping Zhang",
        "Michael R. Lyu"
      ],
      "abstract": "Large Language Models (LLMs) are known to memorize portions of their training\ndata, sometimes reproducing content verbatim when prompted appropriately. In\nthis work, we investigate a fundamental yet under-explored question in the\ndomain of memorization: How to characterize memorization difficulty of training\ndata in LLMs? Through empirical experiments on OLMo, a family of open models,\nwe present the Entropy-Memorization Law. It suggests that data entropy is\nlinearly correlated with memorization score. Moreover, in a case study of\nmemorizing highly randomized strings, or \"gibberish\", we observe that such\nsequences, despite their apparent randomness, exhibit unexpectedly low\nempirical entropy compared to the broader training corpus. Adopting the same\nstrategy to discover Entropy-Memorization Law, we derive a simple yet effective\napproach to distinguish training and testing data, enabling Dataset Inference\n(DI).",
      "pdf_url": "http://arxiv.org/pdf/2507.06056v1",
      "published": "2025-07-08T14:58:28+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.06056v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "CAVGAN: Unifying Jailbreak and Defense of LLMs via Generative Adversarial Attacks on their Internal Representations",
      "authors": [
        "Xiaohu Li",
        "Yunfeng Ning",
        "Zepeng Bao",
        "Mayi Xu",
        "Jianhao Chen",
        "Tieyun Qian"
      ],
      "abstract": "Security alignment enables the Large Language Model (LLM) to gain the\nprotection against malicious queries, but various jailbreak attack methods\nreveal the vulnerability of this security mechanism. Previous studies have\nisolated LLM jailbreak attacks and defenses. We analyze the security protection\nmechanism of the LLM, and propose a framework that combines attack and defense.\nOur method is based on the linearly separable property of LLM intermediate\nlayer embedding, as well as the essence of jailbreak attack, which aims to\nembed harmful problems and transfer them to the safe area. We utilize\ngenerative adversarial network (GAN) to learn the security judgment boundary\ninside the LLM to achieve efficient jailbreak attack and defense. The\nexperimental results indicate that our method achieves an average jailbreak\nsuccess rate of 88.85\\% across three popular LLMs, while the defense success\nrate on the state-of-the-art jailbreak dataset reaches an average of 84.17\\%.\nThis not only validates the effectiveness of our approach but also sheds light\non the internal security mechanisms of LLMs, offering new insights for\nenhancing model security The code and data are available at\nhttps://github.com/NLPGM/CAVGAN.",
      "pdf_url": "http://arxiv.org/pdf/2507.06043v1",
      "published": "2025-07-08T14:45:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.06043v1",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "title": "On Lockean beliefs that are deductively closed and minimal change",
      "authors": [
        "Tommaso Flaminio",
        "Lluis Godo",
        "Ramón Pino Pérez",
        "Lluis Subirana"
      ],
      "abstract": "Within the formal setting of the Lockean thesis, an agent belief set is\ndefined in terms of degrees of confidence and these are described in\nprobabilistic terms. This approach is of established interest, notwithstanding\nsome limitations that make its use troublesome in some contexts, like, for\ninstance, in belief change theory. Precisely, Lockean belief sets are not\ngenerally closed under (classical) logical deduction. The aim of the present\npaper is twofold: on one side we provide two characterizations of those belief\nsets that are closed under classical logic deduction, and on the other we\npropose an approach to probabilistic update that allows us for a minimal\nrevision of those beliefs, i.e., a revision obtained by making the fewest\npossible changes to the existing belief set while still accommodating the new\ninformation. In particular, we show how we can deductively close a belief set\nvia a minimal revision.",
      "pdf_url": "http://arxiv.org/pdf/2507.06042v1",
      "published": "2025-07-08T14:44:01+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.06042v1",
      "categories": [
        "cs.AI",
        "03B42, 03B48"
      ]
    },
    {
      "title": "TextPixs: Glyph-Conditioned Diffusion with Character-Aware Attention and OCR-Guided Supervision",
      "authors": [
        "Syeda Anshrah Gillani",
        "Mirza Samad Ahmed Baig",
        "Osama Ahmed Khan",
        "Shahid Munir Shah",
        "Umema Mujeeb",
        "Maheen Ali"
      ],
      "abstract": "The modern text-to-image diffusion models boom has opened a new era in\ndigital content production as it has proven the previously unseen ability to\nproduce photorealistic and stylistically diverse imagery based on the semantics\nof natural-language descriptions. However, the consistent disadvantage of these\nmodels is that they cannot generate readable, meaningful, and correctly spelled\ntext in generated images, which significantly limits the use of practical\npurposes like advertising, learning, and creative design. This paper introduces\na new framework, namely Glyph-Conditioned Diffusion with Character-Aware\nAttention (GCDA), using which a typical diffusion backbone is extended by three\nwell-designed modules. To begin with, the model has a dual-stream text encoder\nthat encodes both semantic contextual information and explicit glyph\nrepresentations, resulting in a character-aware representation of the input\ntext that is rich in nature. Second, an attention mechanism that is aware of\nthe character is proposed with a new attention segregation loss that aims to\nlimit the attention distribution of each character independently in order to\navoid distortion artifacts. Lastly, GCDA has an OCR-in-the-loop fine-tuning\nphase, where a full text perceptual loss, directly optimises models to be\nlegible and accurately spell. Large scale experiments to benchmark datasets,\nsuch as MARIO-10M and T2I-CompBench, reveal that GCDA sets a new\nstate-of-the-art on all metrics, with better character based metrics on text\nrendering (Character Error Rate: 0.08 vs 0.21 for the previous best; Word Error\nRate: 0.15 vs 0.25), human perception, and comparable image synthesis quality\non high-fidelity (FID: 14.3).",
      "pdf_url": "http://arxiv.org/pdf/2507.06033v1",
      "published": "2025-07-08T14:35:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.06033v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Efficient Federated Learning with Timely Update Dissemination",
      "authors": [
        "Juncheng Jia",
        "Ji Liu",
        "Chao Huo",
        "Yihui Shen",
        "Yang Zhou",
        "Huaiyu Dai",
        "Dejing Dou"
      ],
      "abstract": "Federated Learning (FL) has emerged as a compelling methodology for the\nmanagement of distributed data, marked by significant advancements in recent\nyears. In this paper, we propose an efficient FL approach that capitalizes on\nadditional downlink bandwidth resources to ensure timely update dissemination.\nInitially, we implement this strategy within an asynchronous framework,\nintroducing the Asynchronous Staleness-aware Model Update (FedASMU), which\nintegrates both server-side and device-side methodologies. On the server side,\nwe present an asynchronous FL system model that employs a dynamic model\naggregation technique, which harmonizes local model updates with the global\nmodel to enhance both accuracy and efficiency. Concurrently, on the device\nside, we propose an adaptive model adjustment mechanism that integrates the\nlatest global model with local models during training to further elevate\naccuracy. Subsequently, we extend this approach to a synchronous context,\nreferred to as FedSSMU. Theoretical analyses substantiate the convergence of\nour proposed methodologies. Extensive experiments, encompassing six models and\nfive public datasets, demonstrate that FedASMU and FedSSMU significantly\nsurpass baseline methods in terms of both accuracy (up to 145.87%) and\nefficiency (up to 97.59%).",
      "pdf_url": "http://arxiv.org/pdf/2507.06031v1",
      "published": "2025-07-08T14:34:32+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.06031v1",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Feature-Guided Neighbor Selection for Non-Expert Evaluation of Model Predictions",
      "authors": [
        "Courtney Ford",
        "Mark T. Keane"
      ],
      "abstract": "Explainable AI (XAI) methods often struggle to generate clear, interpretable\noutputs for users without domain expertise. We introduce Feature-Guided\nNeighbor Selection (FGNS), a post hoc method that enhances interpretability by\nselecting class-representative examples using both local and global feature\nimportance. In a user study (N = 98) evaluating Kannada script classifications,\nFGNS significantly improved non-experts' ability to identify model errors while\nmaintaining appropriate agreement with correct predictions. Participants made\nfaster and more accurate decisions compared to those given traditional k-NN\nexplanations. Quantitative analysis shows that FGNS selects neighbors that\nbetter reflect class characteristics rather than merely minimizing\nfeature-space distance, leading to more consistent selection and tighter\nclustering around class prototypes. These results support FGNS as a step toward\nmore human-aligned model assessment, although further work is needed to address\nthe gap between explanation quality and perceived trust.",
      "pdf_url": "http://arxiv.org/pdf/2507.06029v1",
      "published": "2025-07-08T14:32:25+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.06029v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "CogniSQL-R1-Zero: Lightweight Reinforced Reasoning for Efficient SQL Generation",
      "authors": [
        "Kushal Gajjar",
        "Harshit Sikchi",
        "Arpit Singh Gautam",
        "Marc Hammons",
        "Saurabh Jha"
      ],
      "abstract": "Translating natural language into SQL (Text-to-SQL) remains a core challenge\nat the intersection of language understanding and structured data access.\nAlthough large language models (LLMs) have improved fluency, generating correct\nand executable SQL, especially for complex queries, continues to be\nchallenging. We introduce CogniSQL-R1-Zero, a reinforcement learning (RL)\nframework and model that produces accurate SQL using a lightweight reward\nsignal based on execution correctness and format-tag compliance. By avoiding\nintermediate supervision, hybrid pipelines and complex reward shaping, our\nmethod encourages stable learning and stronger alignment with the ultimate task\nobjective-producing executable programs. CogniSQL-R1-Zero achieves\nstate-of-the-art execution accuracy on Text2SQL benchmark; BIRD bench,\noutperforming prior supervised and instruction-tuned baselines including SFT\nCodeS-7B, DeepSeek-Coder 236B, and Mistral 123B-despite being trained on a\nsignificantly smaller 7B backbone. This result underscores the scalability and\nefficiency of our RL-based approach when trained on just four NVIDIA A100 GPUs\n(40 GB VRAM each). To support further research in efficient and interpretable\nText-to-SQL modeling, we release two curated datasets: (i) a collection of\n5,024 reasoning traces with varying context lengths, and (ii) a\npositive-sampled corpus of 36,356 corpus of weakly supervised queries, each\nannotated with six semantically diverse reasoning paths. Together, these\ncontributions advance scalable, execution-aligned Text-to-SQL generation.",
      "pdf_url": "http://arxiv.org/pdf/2507.06013v1",
      "published": "2025-07-08T14:17:07+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.06013v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "The Impact of Event Data Partitioning on Privacy-aware Process Discovery",
      "authors": [
        "Jungeun Lim",
        "Stephan A. Fahrenkrog-Petersen",
        "Xixi Lu",
        "Jan Mendling",
        "Minseok Song"
      ],
      "abstract": "Information systems support the execution of business processes. The event\nlogs of these executions generally contain sensitive information about\ncustomers, patients, and employees. The corresponding privacy challenges can be\naddressed by anonymizing the event logs while still retaining utility for\nprocess discovery. However, trading off utility and privacy is difficult: the\nhigher the complexity of event log, the higher the loss of utility by\nanonymization. In this work, we propose a pipeline that combines anonymization\nand event data partitioning, where event abstraction is utilized for\npartitioning. By leveraging event abstraction, event logs can be segmented into\nmultiple parts, allowing each sub-log to be anonymized separately. This\npipeline preserves privacy while mitigating the loss of utility. To validate\nour approach, we study the impact of event partitioning on two anonymization\ntechniques using three real-world event logs and two process discovery\ntechniques. Our results demonstrate that event partitioning can bring\nimprovements in process discovery utility for directly-follows-based\nanonymization techniques.",
      "pdf_url": "http://arxiv.org/pdf/2507.06008v1",
      "published": "2025-07-08T14:13:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.06008v1",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.DB"
      ]
    },
    {
      "title": "Geo-Registration of Terrestrial LiDAR Point Clouds with Satellite Images without GNSS",
      "authors": [
        "Xinyu Wang",
        "Muhammad Ibrahim",
        "Haitian Wang",
        "Atif Mansoor",
        "Ajmal Mian"
      ],
      "abstract": "Accurate geo-registration of LiDAR point clouds presents significant\nchallenges in GNSS signal denied urban areas with high-rise buildings and\nbridges. Existing methods typically rely on real-time GNSS and IMU data, that\nrequire pre-calibration and assume stable positioning during data collection.\nHowever, this assumption often fails in dense urban areas, resulting in\nlocalization errors. To address this, we propose a structured geo-registration\nand spatial correction method that aligns 3D point clouds with satellite\nimages, enabling frame-wise recovery of GNSS information and reconstruction of\ncity scale 3D maps without relying on prior localization. The proposed approach\nemploys a pre-trained Point Transformer model to segment the road points and\nthen extracts the road skeleton and intersection points from the point cloud as\nwell as the target map for alignment. Global rigid alignment of the two is\nperformed using the intersection points, followed by local refinement using\nradial basis function (RBF) interpolation. Elevation correction is then applied\nto the point cloud based on terrain information from SRTM dataset to resolve\nvertical discrepancies. The proposed method was tested on the popular KITTI\nbenchmark and a locally collected Perth (Western Australia) CBD dataset. On the\nKITTI dataset, our method achieved an average planimetric alignment standard\ndeviation (STD) of 0.84~m across sequences with intersections, representing a\n55.3\\% improvement over the original dataset. On the Perth dataset, which lacks\nGNSS information, our method achieved an average STD of 0.96~m compared to the\nGPS data extracted from Google Maps API. This corresponds to a 77.4\\%\nimprovement from the initial alignment. Our method also resulted in elevation\ncorrelation gains of 30.5\\% on the KITTI dataset and 50.4\\% on the Perth\ndataset.",
      "pdf_url": "http://arxiv.org/pdf/2507.05999v2",
      "published": "2025-07-08T14:00:18+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.05999v2",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Exploring Partial Multi-Label Learning via Integrating Semantic Co-occurrence Knowledge",
      "authors": [
        "Xin Wu",
        "Fei Teng",
        "Yue Feng",
        "Kaibo Shi",
        "Zhuosheng Lin",
        "Ji Zhang",
        "James Wang"
      ],
      "abstract": "Partial multi-label learning aims to extract knowledge from incompletely\nannotated data, which includes known correct labels, known incorrect labels,\nand unknown labels. The core challenge lies in accurately identifying the\nambiguous relationships between labels and instances. In this paper, we\nemphasize that matching co-occurrence patterns between labels and instances is\nkey to addressing this challenge. To this end, we propose Semantic\nCo-occurrence Insight Network (SCINet), a novel and effective framework for\npartial multi-label learning. Specifically, SCINet introduces a bi-dominant\nprompter module, which leverages an off-the-shelf multimodal model to capture\ntext-image correlations and enhance semantic alignment. To reinforce\ninstance-label interdependencies, we develop a cross-modality fusion module\nthat jointly models inter-label correlations, inter-instance relationships, and\nco-occurrence patterns across instance-label assignments. Moreover, we propose\nan intrinsic semantic augmentation strategy that enhances the model's\nunderstanding of intrinsic data semantics by applying diverse image\ntransformations, thereby fostering a synergistic relationship between label\nconfidence and sample difficulty. Extensive experiments on four widely-used\nbenchmark datasets demonstrate that SCINet surpasses state-of-the-art methods.",
      "pdf_url": "http://arxiv.org/pdf/2507.05992v1",
      "published": "2025-07-08T13:53:28+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.05992v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Development and Evaluation of HopeBot: an LLM-based chatbot for structured and interactive PHQ-9 depression screening",
      "authors": [
        "Zhijun Guo",
        "Alvina Lai",
        "Julia Ive",
        "Alexandru Petcu",
        "Yutong Wang",
        "Luyuan Qi",
        "Johan H Thygesen",
        "Kezhi Li"
      ],
      "abstract": "Static tools like the Patient Health Questionnaire-9 (PHQ-9) effectively\nscreen depression but lack interactivity and adaptability. We developed\nHopeBot, a chatbot powered by a large language model (LLM) that administers the\nPHQ-9 using retrieval-augmented generation and real-time clarification. In a\nwithin-subject study, 132 adults in the United Kingdom and China completed both\nself-administered and chatbot versions. Scores demonstrated strong agreement\n(ICC = 0.91; 45% identical). Among 75 participants providing comparative\nfeedback, 71% reported greater trust in the chatbot, highlighting clearer\nstructure, interpretive guidance, and a supportive tone. Mean ratings (0-10)\nwere 8.4 for comfort, 7.7 for voice clarity, 7.6 for handling sensitive topics,\nand 7.4 for recommendation helpfulness; the latter varied significantly by\nemployment status and prior mental-health service use (p < 0.05). Overall,\n87.1% expressed willingness to reuse or recommend HopeBot. These findings\ndemonstrate voice-based LLM chatbots can feasibly serve as scalable, low-burden\nadjuncts for routine depression screening.",
      "pdf_url": "http://arxiv.org/pdf/2507.05984v1",
      "published": "2025-07-08T13:41:22+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.05984v1",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ]
    },
    {
      "title": "Enhancing the Interpretability of Rule-based Explanations through Information Retrieval",
      "authors": [
        "Alessandro Umbrico",
        "Guido Bologna",
        "Luca Coraci",
        "Francesca Fracasso",
        "Silvia Gola",
        "Gabriella Cortellessa"
      ],
      "abstract": "The lack of transparency of data-driven Artificial Intelligence techniques\nlimits their interpretability and acceptance into healthcare decision-making\nprocesses. We propose an attribution-based approach to improve the\ninterpretability of Explainable AI-based predictions in the specific context of\narm lymphedema's risk assessment after lymph nodal radiotherapy in breast\ncancer. The proposed method performs a statistical analysis of the attributes\nin the rule-based prediction model using standard metrics from Information\nRetrieval techniques. This analysis computes the relevance of each attribute to\nthe prediction and provides users with interpretable information about the\nimpact of risk factors. The results of a user study that compared the output\ngenerated by the proposed approach with the raw output of the Explainable AI\nmodel suggested higher levels of interpretability and usefulness in the context\nof predicting lymphedema risk.",
      "pdf_url": "http://arxiv.org/pdf/2507.05976v1",
      "published": "2025-07-08T13:32:50+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.05976v1",
      "categories": [
        "cs.AI",
        "cs.IR"
      ]
    },
    {
      "title": "Simple Convergence Proof of Adam From a Sign-like Descent Perspective",
      "authors": [
        "Hanyang Peng",
        "Shuang Qin",
        "Yue Yu",
        "Fangqing Jiang",
        "Hui Wang",
        "Zhouchen Lin"
      ],
      "abstract": "Adam is widely recognized as one of the most effective optimizers for\ntraining deep neural networks (DNNs). Despite its remarkable empirical success,\nits theoretical convergence analysis remains unsatisfactory. Existing works\npredominantly interpret Adam as a preconditioned stochastic gradient descent\nwith momentum (SGDM), formulated as $\\bm{x}_{t+1} = \\bm{x}_t -\n\\frac{\\gamma_t}{{\\sqrt{\\bm{v}_t}+\\epsilon}} \\circ \\bm{m}_t$. This perspective\nnecessitates strong assumptions and intricate techniques, resulting in lengthy\nand opaque convergence proofs that are difficult to verify and extend. In\ncontrast, we propose a novel interpretation by treating Adam as a sign-like\noptimizer, expressed as $\\bm{x}_{t+1} = \\bm{x}_t - \\gamma_t\n\\frac{|\\bm{m}_t|}{{\\sqrt{\\bm{v}_t}+\\epsilon}} \\circ {\\rm Sign}(\\bm{m}_t)$. This\nreformulation significantly simplifies the convergence analysis. For the first\ntime, with some mild conditions, we prove that Adam achieves the optimal rate\nof ${\\cal O}(\\frac{1}{T^{\\sfrac{1}{4}}})$ rather than the previous ${\\cal O}\n\\left(\\frac{\\ln T}{T^{\\sfrac{1}{4}}}\\right)$ under weak assumptions of the\ngeneralized $p$-affine variance and $(L_0, L_1, q)$-smoothness, without\ndependence on the model dimensionality or the numerical stability parameter\n$\\epsilon$. Additionally, our theoretical analysis provides new insights into\nthe role of momentum as a key factor ensuring convergence and offers practical\nguidelines for tuning learning rates in Adam, further bridging the gap between\ntheory and practice.",
      "pdf_url": "http://arxiv.org/pdf/2507.05966v1",
      "published": "2025-07-08T13:19:26+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.05966v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT",
        "math.IT"
      ]
    },
    {
      "title": "OpenFActScore: Open-Source Atomic Evaluation of Factuality in Text Generation",
      "authors": [
        "Lucas Fonseca Lage",
        "Simon Ostermann"
      ],
      "abstract": "We introduce OpenFActScore, an open-source implementation of the FActScore\nframework for evaluating the factuality of text generated by large language\nmodels (LLMs). FActScore evaluates the factual accuracy of long-form text by\nusing Atomic Fact Generation (AFG) to extract individual factual claims and\nAtomic Fact Validation (AFV) to verify each claim against a trusted knowledge\nsource. While the original FActScore relies on closed-source and commercial\nmodels such as InstructGPT and ChatGPT, OpenFActScore enables the use of any\nHugging Face-compatible model for both AFG and AFV. We provide a detailed\ntechnical overview of our implementation, highlighting design choices and\nmodifications made to support open models. We evaluate multiple open-source\nLLMs on both AFG and AFV using the original FActScore benchmark, reporting\nBERTScore-F1 for AFG and Error Rate relative to human annotations for AFV. Our\nresults show that open models can approximate the performance of closed-source\nsystems, with Gemma achieving the best overall performance, and our final setup\nobtains a 0.99 Pearson correlation with the original FActScore experiments.\nOpenFActScore promotes transparency, reproducibility, and cost-effective\nevaluation, and is available at: https://github.com/lflage/OpenFActScore.",
      "pdf_url": "http://arxiv.org/pdf/2507.05965v1",
      "published": "2025-07-08T13:19:00+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.05965v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Complexity Results of Persuasion",
      "authors": [
        "Alban Grastien"
      ],
      "abstract": "We prove that persuasion is an NP-complete problem.",
      "pdf_url": "http://arxiv.org/pdf/2507.05951v1",
      "published": "2025-07-08T12:49:22+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.05951v1",
      "categories": [
        "cs.CC",
        "cs.AI"
      ]
    },
    {
      "title": "A Wireless Foundation Model for Multi-Task Prediction",
      "authors": [
        "Yucheng Sheng",
        "Jiacheng Wang",
        "Xingyu Zhou",
        "Le Liang",
        "Hao Ye",
        "Shi Jin",
        "Geoffrey Ye Li"
      ],
      "abstract": "With the growing complexity and dynamics of the mobile communication\nnetworks, accurately predicting key system parameters, such as channel state\ninformation (CSI), user location, and network traffic, has become essential for\na wide range of physical (PHY)-layer and medium access control (MAC)-layer\ntasks. Although traditional deep learning (DL)-based methods have been widely\napplied to such prediction tasks, they often struggle to generalize across\ndifferent scenarios and tasks. In response, we propose a unified foundation\nmodel for multi-task prediction in wireless networks that supports diverse\nprediction intervals. The proposed model enforces univariate decomposition to\nunify heterogeneous tasks, encodes granularity for interval awareness, and uses\na causal Transformer backbone for accurate predictions. Additionally, we\nintroduce a patch masking strategy during training to support arbitrary input\nlengths. After trained on large-scale datasets, the proposed foundation model\ndemonstrates strong generalization to unseen scenarios and achieves zero-shot\nperformance on new tasks that surpass traditional full-shot baselines.",
      "pdf_url": "http://arxiv.org/pdf/2507.05938v2",
      "published": "2025-07-08T12:37:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.05938v2",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "BlueLM-2.5-3B Technical Report",
      "authors": [
        "Baojiao Xiong",
        "Boheng Chen",
        "Chengzhi Wang",
        "Daxiong Luo",
        "Dongsheng Xu",
        "Dongyang Liu",
        "Fan Yang",
        "Fangyuan Li",
        "Fei Teng",
        "Feng Wang",
        "Fukang Qin",
        "Fuquan Peng",
        "Guanxin Tan",
        "Guozhi Wang",
        "Haibo Yu",
        "Haohao Gao",
        "Heng Liu",
        "Hongbo Yang",
        "Hongjian Zou",
        "Houzheng Shen",
        "Hu Meng",
        "Huan Li",
        "Hui Tan",
        "Jiali Chen",
        "Jianzhao Chen",
        "Jinliang Zhu",
        "Kai Wang",
        "Lei Wu",
        "Liangbing Liu",
        "Liuyang Bian",
        "Liyan He",
        "Long Liu",
        "Peiwen Li",
        "Penggang Shi",
        "Qi Ding",
        "Rui Hu",
        "Shuai Cao",
        "Shuai Ren",
        "Shuang Peng",
        "Teng Xie",
        "Weiji Chen",
        "Weilin Xiang",
        "Weixin Wu",
        "Xi Yin",
        "Xiaoxin Chen",
        "Xu Chen",
        "Yafei Wen",
        "Yan Hu",
        "Yanzhou Yang",
        "Yina Xie",
        "Yinghao Chen",
        "Yixuan Liao",
        "Yu Geng",
        "Yuanjiang Ouyang",
        "Yuanzhuo Yang",
        "Yuehua He",
        "Yushuai Peng",
        "Zhaoxiong Wang",
        "Zheng Wang",
        "Zhibo Zhou",
        "Ziyang Wu"
      ],
      "abstract": "We present BlueLM-2.5-3B, a compact and unified dense Multimodal Large\nLanguage Model (MLLM) designed for efficient edge-device deployment, offering\nstrong general-purpose and reasoning capabilities. To the best of our\nknowledge, this is the first 3B-scale MLLM to support both thinking and\nnon-thinking modes, while also enabling explicit control over thinking token\nbudget. BlueLM-2.5-3B is developed through diversified data curation, key data\nresampling, hybrid heterogeneous reinforcement learning, and a high-performance\ntraining infrastructure. Our model achieves superior multimodal capacity while\npreserving competitive pure-text performance with only 2.9 billion parameters.\nWe conduct comprehensive evaluations across a broad range of multimodal and\ntext-only benchmarks. In thinking mode, BlueLM-2.5-3B achieves comparable\nperformance to Qwen3-4B on text-only benchmarks, and trails the larger\nKimi-VL-A3B-16B by only about 5% on average across multimodal evaluations. In\nnon-thinking mode, it outperforms Qwen2.5-VL-3B on the majority of multimodal\nbenchmarks. Additionally, BlueLM-2.5-3B exhibits exceptional data efficiency.\nAll of the aforementioned performance is achieved with substantially less total\ntraining data than Qwen2.5-VL-3B and Qwen3-4B. We hope our work contributes to\nthe advancement of high-performance, on-device MLLMs and provides meaningful\ninsights to the research community.",
      "pdf_url": "http://arxiv.org/pdf/2507.05934v1",
      "published": "2025-07-08T12:34:10+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.05934v1",
      "categories": [
        "cs.AI"
      ]
    }
  ]
}