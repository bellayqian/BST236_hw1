{
  "last_updated": "2025-05-14T00:51:38.844716",
  "papers": [
    {
      "title": "H$^{\\mathbf{3}}$DP: Triply-Hierarchical Diffusion Policy for Visuomotor Learning",
      "authors": [
        "Yiyang Lu",
        "Yufeng Tian",
        "Zhecheng Yuan",
        "Xianbang Wang",
        "Pu Hua",
        "Zhengrong Xue",
        "Huazhe Xu"
      ],
      "abstract": "Visuomotor policy learning has witnessed substantial progress in robotic\nmanipulation, with recent approaches predominantly relying on generative models\nto model the action distribution. However, these methods often overlook the\ncritical coupling between visual perception and action prediction. In this\nwork, we introduce $\\textbf{Triply-Hierarchical Diffusion\nPolicy}~(\\textbf{H$^{\\mathbf{3}}$DP})$, a novel visuomotor learning framework\nthat explicitly incorporates hierarchical structures to strengthen the\nintegration between visual features and action generation. H$^{3}$DP contains\n$\\mathbf{3}$ levels of hierarchy: (1) depth-aware input layering that organizes\nRGB-D observations based on depth information; (2) multi-scale visual\nrepresentations that encode semantic features at varying levels of granularity;\nand (3) a hierarchically conditioned diffusion process that aligns the\ngeneration of coarse-to-fine actions with corresponding visual features.\nExtensive experiments demonstrate that H$^{3}$DP yields a $\\mathbf{+27.5\\%}$\naverage relative improvement over baselines across $\\mathbf{44}$ simulation\ntasks and achieves superior performance in $\\mathbf{4}$ challenging bimanual\nreal-world manipulation tasks. Project Page: https://lyy-iiis.github.io/h3dp/.",
      "pdf_url": "http://arxiv.org/pdf/2505.07819v1",
      "published": "2025-05-12T17:59:43+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.07819v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "A class of distributed automata that contains the modal mu-fragment",
      "authors": [
        "Veeti Ahvonen",
        "Damian Heiman",
        "Antti Kuusisto"
      ],
      "abstract": "This paper gives a translation from the $\\mu$-fragment of the graded modal\n$\\mu$-calculus to a class of distributed message-passing automata. As a\ncorollary, we obtain an alternative proof for a theorem from\n\\cite{ahvonen_neurips} stating that recurrent graph neural networks working\nwith reals and graded modal substitution calculus have the same expressive\npower in restriction to the logic monadic second-order logic MSO.",
      "pdf_url": "http://arxiv.org/pdf/2505.07816v1",
      "published": "2025-05-12T17:59:22+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.07816v1",
      "categories": [
        "cs.LO",
        "cs.AI",
        "F.4.1; F.1.1; I.2.0"
      ]
    },
    {
      "title": "DexWild: Dexterous Human Interactions for In-the-Wild Robot Policies",
      "authors": [
        "Tony Tao",
        "Mohan Kumar Srirama",
        "Jason Jingzhou Liu",
        "Kenneth Shaw",
        "Deepak Pathak"
      ],
      "abstract": "Large-scale, diverse robot datasets have emerged as a promising path toward\nenabling dexterous manipulation policies to generalize to novel environments,\nbut acquiring such datasets presents many challenges. While teleoperation\nprovides high-fidelity datasets, its high cost limits its scalability. Instead,\nwhat if people could use their own hands, just as they do in everyday life, to\ncollect data? In DexWild, a diverse team of data collectors uses their hands to\ncollect hours of interactions across a multitude of environments and objects.\nTo record this data, we create DexWild-System, a low-cost, mobile, and\neasy-to-use device. The DexWild learning framework co-trains on both human and\nrobot demonstrations, leading to improved performance compared to training on\neach dataset individually. This combination results in robust robot policies\ncapable of generalizing to novel environments, tasks, and embodiments with\nminimal additional robot-specific data. Experimental results demonstrate that\nDexWild significantly improves performance, achieving a 68.5% success rate in\nunseen environments-nearly four times higher than policies trained with robot\ndata only-and offering 5.8x better cross-embodiment generalization. Video\nresults, codebases, and instructions at https://dexwild.github.io",
      "pdf_url": "http://arxiv.org/pdf/2505.07813v1",
      "published": "2025-05-12T17:59:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.07813v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ]
    },
    {
      "title": "A Comparative Analysis of Static Word Embeddings for Hungarian",
      "authors": [
        "Máté Gedeon"
      ],
      "abstract": "This paper presents a comprehensive analysis of various static word\nembeddings for Hungarian, including traditional models such as Word2Vec,\nFastText, as well as static embeddings derived from BERT-based models using\ndifferent extraction methods. We evaluate these embeddings on both intrinsic\nand extrinsic tasks to provide a holistic view of their performance. For\nintrinsic evaluation, we employ a word analogy task, which assesses the\nembeddings ability to capture semantic and syntactic relationships. Our results\nindicate that traditional static embeddings, particularly FastText, excel in\nthis task, achieving high accuracy and mean reciprocal rank (MRR) scores. Among\nthe BERT-based models, the X2Static method for extracting static embeddings\ndemonstrates superior performance compared to decontextualized and aggregate\nmethods, approaching the effectiveness of traditional static embeddings. For\nextrinsic evaluation, we utilize a bidirectional LSTM model to perform Named\nEntity Recognition (NER) and Part-of-Speech (POS) tagging tasks. The results\nreveal that embeddings derived from dynamic models, especially those extracted\nusing the X2Static method, outperform purely static embeddings. Notably, ELMo\nembeddings achieve the highest accuracy in both NER and POS tagging tasks,\nunderscoring the benefits of contextualized representations even when used in a\nstatic form. Our findings highlight the continued relevance of static word\nembeddings in NLP applications and the potential of advanced extraction methods\nto enhance the utility of BERT-based models. This piece of research contributes\nto the understanding of embedding performance in the Hungarian language and\nprovides valuable insights for future developments in the field. The training\nscripts, evaluation codes, restricted vocabulary, and extracted embeddings will\nbe made publicly available to support further research and reproducibility.",
      "pdf_url": "http://arxiv.org/pdf/2505.07809v1",
      "published": "2025-05-12T17:57:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.07809v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Improving Trajectory Stitching with Flow Models",
      "authors": [
        "Reece O'Mahoney",
        "Wanming Yu",
        "Ioannis Havoutis"
      ],
      "abstract": "Generative models have shown great promise as trajectory planners, given\ntheir affinity to modeling complex distributions and guidable inference\nprocess. Previous works have successfully applied these in the context of\nrobotic manipulation but perform poorly when the required solution does not\nexist as a complete trajectory within the training set. We identify that this\nis a result of being unable to plan via stitching, and subsequently address the\narchitectural and dataset choices needed to remedy this. On top of this, we\npropose a novel addition to the training and inference procedures to both\nstabilize and enhance these capabilities. We demonstrate the efficacy of our\napproach by generating plans with out of distribution boundary conditions and\nperforming obstacle avoidance on the Franka Panda in simulation and on real\nhardware. In both of these tasks our method performs significantly better than\nthe baselines and is able to avoid obstacles up to four times as large.",
      "pdf_url": "http://arxiv.org/pdf/2505.07802v1",
      "published": "2025-05-12T17:50:10+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.07802v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Learning Dynamics in Continual Pre-Training for Large Language Models",
      "authors": [
        "Xingjin Wang",
        "Howe Tissue",
        "Lu Wang",
        "Linjing Li",
        "Daniel Dajun Zeng"
      ],
      "abstract": "Continual Pre-Training (CPT) has become a popular and effective method to\napply strong foundation models to specific downstream tasks. In this work, we\nexplore the learning dynamics throughout the CPT process for large language\nmodels. We specifically focus on how general and downstream domain performance\nevolves at each training step, with domain performance measured via validation\nlosses. We have observed that the CPT loss curve fundamentally characterizes\nthe transition from one curve to another hidden curve, and could be described\nby decoupling the effects of distribution shift and learning rate annealing. We\nderive a CPT scaling law that combines the two factors, enabling the prediction\nof loss at any (continual) training steps and across learning rate schedules\n(LRS) in CPT. Our formulation presents a comprehensive understanding of several\ncritical factors in CPT, including loss potential, peak learning rate, training\nsteps, replay ratio, etc. Moreover, our approach can be adapted to customize\ntraining hyper-parameters to different CPT goals such as balancing general and\ndomain-specific performance. Extensive experiments demonstrate that our scaling\nlaw holds across various CPT datasets and training hyper-parameters.",
      "pdf_url": "http://arxiv.org/pdf/2505.07796v1",
      "published": "2025-05-12T17:47:32+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.07796v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Overflow Prevention Enhances Long-Context Recurrent LLMs",
      "authors": [
        "Assaf Ben-Kish",
        "Itamar Zimerman",
        "M. Jehanzeb Mirza",
        "James Glass",
        "Leonid Karlinsky",
        "Raja Giryes"
      ],
      "abstract": "A recent trend in LLMs is developing recurrent sub-quadratic models that\nimprove long-context processing efficiency. We investigate leading large\nlong-context models, focusing on how their fixed-size recurrent memory affects\ntheir performance. Our experiments reveal that, even when these models are\ntrained for extended contexts, their use of long contexts remains\nunderutilized. Specifically, we demonstrate that a chunk-based inference\nprocedure, which identifies and processes only the most relevant portion of the\ninput can mitigate recurrent memory failures and be effective for many\nlong-context tasks: On LongBench, our method improves the overall performance\nof Falcon3-Mamba-Inst-7B by 14%, Falcon-Mamba-Inst-7B by 28%,\nRecurrentGemma-IT-9B by 50%, and RWKV6-Finch-7B by 51%. Surprisingly, this\nsimple approach also leads to state-of-the-art results in the challenging\nLongBench v2 benchmark, showing competitive performance with equivalent size\nTransformers. Furthermore, our findings raise questions about whether recurrent\nmodels genuinely exploit long-range dependencies, as our single-chunk strategy\ndelivers stronger performance - even in tasks that presumably require\ncross-context relations.",
      "pdf_url": "http://arxiv.org/pdf/2505.07793v1",
      "published": "2025-05-12T17:45:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.07793v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Must Read: A Systematic Survey of Computational Persuasion",
      "authors": [
        "Nimet Beyza Bozdag",
        "Shuhaib Mehri",
        "Xiaocheng Yang",
        "Hyeonjeong Ha",
        "Zirui Cheng",
        "Esin Durmus",
        "Jiaxuan You",
        "Heng Ji",
        "Gokhan Tur",
        "Dilek Hakkani-Tür"
      ],
      "abstract": "Persuasion is a fundamental aspect of communication, influencing\ndecision-making across diverse contexts, from everyday conversations to\nhigh-stakes scenarios such as politics, marketing, and law. The rise of\nconversational AI systems has significantly expanded the scope of persuasion,\nintroducing both opportunities and risks. AI-driven persuasion can be leveraged\nfor beneficial applications, but also poses threats through manipulation and\nunethical influence. Moreover, AI systems are not only persuaders, but also\nsusceptible to persuasion, making them vulnerable to adversarial attacks and\nbias reinforcement. Despite rapid advancements in AI-generated persuasive\ncontent, our understanding of what makes persuasion effective remains limited\ndue to its inherently subjective and context-dependent nature. In this survey,\nwe provide a comprehensive overview of computational persuasion, structured\naround three key perspectives: (1) AI as a Persuader, which explores\nAI-generated persuasive content and its applications; (2) AI as a Persuadee,\nwhich examines AI's susceptibility to influence and manipulation; and (3) AI as\na Persuasion Judge, which analyzes AI's role in evaluating persuasive\nstrategies, detecting manipulation, and ensuring ethical persuasion. We\nintroduce a taxonomy for computational persuasion research and discuss key\nchallenges, including evaluating persuasiveness, mitigating manipulative\npersuasion, and developing responsible AI-driven persuasive systems. Our survey\noutlines future research directions to enhance the safety, fairness, and\neffectiveness of AI-powered persuasion while addressing the risks posed by\nincreasingly capable language models.",
      "pdf_url": "http://arxiv.org/pdf/2505.07775v1",
      "published": "2025-05-12T17:26:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.07775v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ]
    },
    {
      "title": "Agent RL Scaling Law: Agent RL with Spontaneous Code Execution for Mathematical Problem Solving",
      "authors": [
        "Xinji Mai",
        "Haotian Xu",
        "Xing W",
        "Weinong Wang",
        "Yingying Zhang",
        "Wenqiang Zhang"
      ],
      "abstract": "Large Language Models (LLMs) often struggle with mathematical reasoning tasks\nrequiring precise, verifiable computation. While Reinforcement Learning (RL)\nfrom outcome-based rewards enhances text-based reasoning, understanding how\nagents autonomously learn to leverage external tools like code execution\nremains crucial. We investigate RL from outcome-based rewards for\nTool-Integrated Reasoning, ZeroTIR, training base LLMs to spontaneously\ngenerate and execute Python code for mathematical problems without supervised\ntool-use examples. Our central contribution is we demonstrate that as RL\ntraining progresses, key metrics scale predictably. Specifically, we observe\nstrong positive correlations where increased training steps lead to increases\nin the spontaneous code execution frequency, the average response length, and,\ncritically, the final task accuracy. This suggests a quantifiable relationship\nbetween computational effort invested in training and the emergence of\neffective, tool-augmented reasoning strategies. We implement a robust framework\nfeaturing a decoupled code execution environment and validate our findings\nacross standard RL algorithms and frameworks. Experiments show ZeroTIR\nsignificantly surpasses non-tool ZeroRL baselines on challenging math\nbenchmarks. Our findings provide a foundational understanding of how autonomous\ntool use is acquired and scales within Agent RL, offering a reproducible\nbenchmark for future studies. Code is released at\n\\href{https://github.com/Anonymize-Author/AgentRL}{https://github.com/Anonymize-Author/AgentRL}.",
      "pdf_url": "http://arxiv.org/pdf/2505.07773v1",
      "published": "2025-05-12T17:23:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.07773v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Enhancing Code Generation via Bidirectional Comment-Level Mutual Grounding",
      "authors": [
        "Yifeng Di",
        "Tianyi Zhang"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated unprecedented capability in\ncode generation. However, LLM-generated code is still plagued with a wide range\nof functional errors, especially for complex programming tasks that LLMs have\nnot seen before. Recent studies have shown that developers often struggle with\ninspecting and fixing incorrect code generated by LLMs, diminishing their\nproductivity and trust in LLM-based code generation. Inspired by the mutual\ngrounding theory in communication, we propose an interactive approach that\nleverages code comments as a medium for developers and LLMs to establish a\nshared understanding. Our approach facilitates iterative grounding by\ninterleaving code generation, inline comment generation, and contextualized\nuser feedback through editable comments to align generated code with developer\nintent. We evaluated our approach on two popular benchmarks and demonstrated\nthat our approach significantly improved multiple state-of-the-art LLMs, e.g.,\n17.1% pass@1 improvement for code-davinci-002 on HumanEval. Furthermore, we\nconducted a user study with 12 participants in comparison to two baselines: (1)\ninteracting with GitHub Copilot, and (2) interacting with a multi-step code\ngeneration paradigm called Multi-Turn Program Synthesis. Participants completed\nthe given programming tasks 16.7% faster and with 10.5% improvement in task\nsuccess rate when using our approach. Both results show that interactively\nrefining code comments enables the collaborative establishment of mutual\ngrounding, leading to more accurate code generation and higher developer\nconfidence.",
      "pdf_url": "http://arxiv.org/pdf/2505.07768v1",
      "published": "2025-05-12T17:20:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.07768v1",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "\"I Apologize For Not Understanding Your Policy\": Exploring the Specification and Evaluation of User-Managed Access Control Policies by AI Virtual Assistants",
      "authors": [
        "Jennifer Mondragon",
        "Carlos Rubio-Medrano",
        "Gael Cruz",
        "Dvijesh Shastri"
      ],
      "abstract": "The rapid evolution of Artificial Intelligence (AI)-based Virtual Assistants\n(VAs) e.g., Google Gemini, ChatGPT, Microsoft Copilot, and High-Flyer Deepseek\nhas turned them into convenient interfaces for managing emerging technologies\nsuch as Smart Homes, Smart Cars, Electronic Health Records, by means of\nexplicit commands,e.g., prompts, which can be even launched via voice, thus\nproviding a very convenient interface for end-users. However, the proper\nspecification and evaluation of User-Managed Access Control Policies (U-MAPs),\nthe rules issued and managed by end-users to govern access to sensitive data\nand device functionality - within these VAs presents significant challenges,\nsince such a process is crucial for preventing security vulnerabilities and\nprivacy leaks without impacting user experience. This study provides an initial\nexploratory investigation on whether current publicly-available VAs can manage\nU-MAPs effectively across differing scenarios. By conducting unstructured to\nstructured tests, we evaluated the comprehension of such VAs, revealing a lack\nof understanding in varying U-MAP approaches. Our research not only identifies\nkey limitations, but offers valuable insights into how VAs can be further\nimproved to manage complex authorization rules and adapt to dynamic changes.",
      "pdf_url": "http://arxiv.org/pdf/2505.07759v1",
      "published": "2025-05-12T17:03:52+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.07759v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Emotion-Gradient Metacognitive RSI (Part I): Theoretical Foundations and Single-Agent Architecture",
      "authors": [
        "Rintaro Ando"
      ],
      "abstract": "We present the Emotion-Gradient Metacognitive Recursive Self-Improvement\n(EG-MRSI) framework, a novel architecture that integrates introspective\nmetacognition, emotion-based intrinsic motivation, and recursive\nself-modification into a unified theoretical system. The framework is\nexplicitly capable of overwriting its own learning algorithm under formally\nbounded risk. Building upon the Noise-to-Meaning RSI (N2M-RSI) foundation,\nEG-MRSI introduces a differentiable intrinsic reward function driven by\nconfidence, error, novelty, and cumulative success. This signal regulates both\na metacognitive mapping and a self-modification operator constrained by\nprovable safety mechanisms. We formally define the initial agent configuration,\nemotion-gradient dynamics, and RSI trigger conditions, and derive a\nreinforcement-compatible optimization objective that guides the agent's\ndevelopment trajectory. Meaning Density and Meaning Conversion Efficiency are\nintroduced as quantifiable metrics of semantic learning, closing the gap\nbetween internal structure and predictive informativeness. This Part I paper\nestablishes the single-agent theoretical foundations of EG-MRSI. Future parts\nwill extend this framework to include safety certificates and rollback\nprotocols (Part II), collective intelligence mechanisms (Part III), and\nfeasibility constraints including thermodynamic and computational limits (Part\nIV). Together, the EG-MRSI series provides a rigorous, extensible foundation\nfor open-ended and safe AGI.",
      "pdf_url": "http://arxiv.org/pdf/2505.07757v1",
      "published": "2025-05-12T17:02:47+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.07757v1",
      "categories": [
        "cs.AI",
        "cs.LG",
        "F.1.2; I.2.0"
      ]
    },
    {
      "title": "Benchmarking of CPU-intensive Stream Data Processing in The Edge Computing Systems",
      "authors": [
        "Tomasz Szydlo",
        "Viacheslaw Horbanow",
        "Dev Nandan Jha",
        "Shashikant Ilager",
        "Aleksander Slominski",
        "Rajiv Ranjan"
      ],
      "abstract": "Edge computing has emerged as a pivotal technology, offering significant\nadvantages such as low latency, enhanced data security, and reduced reliance on\ncentralized cloud infrastructure. These benefits are crucial for applications\nrequiring real-time data processing or strict security measures. Despite these\nadvantages, edge devices operating within edge clusters are often\nunderutilized. This inefficiency is mainly due to the absence of a holistic\nperformance profiling mechanism which can help dynamically adjust the desired\nsystem configuration for a given workload. Since edge computing environments\ninvolve a complex interplay between CPU frequency, power consumption, and\napplication performance, a deeper understanding of these correlations is\nessential. By uncovering these relationships, it becomes possible to make\ninformed decisions that enhance both computational efficiency and energy\nsavings. To address this gap, this paper evaluates the power consumption and\nperformance characteristics of a single processing node within an edge cluster\nusing a synthetic microbenchmark by varying the workload size and CPU\nfrequency. The results show how an optimal measure can lead to optimized usage\nof edge resources, given both performance and power consumption.",
      "pdf_url": "http://arxiv.org/pdf/2505.07755v1",
      "published": "2025-05-12T17:02:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.07755v1",
      "categories": [
        "cs.DC",
        "cs.AI"
      ]
    },
    {
      "title": "Guiding Data Collection via Factored Scaling Curves",
      "authors": [
        "Lihan Zha",
        "Apurva Badithela",
        "Michael Zhang",
        "Justin Lidard",
        "Jeremy Bao",
        "Emily Zhou",
        "David Snyder",
        "Allen Z. Ren",
        "Dhruv Shah",
        "Anirudha Majumdar"
      ],
      "abstract": "Generalist imitation learning policies trained on large datasets show great\npromise for solving diverse manipulation tasks. However, to ensure\ngeneralization to different conditions, policies need to be trained with data\ncollected across a large set of environmental factor variations (e.g., camera\npose, table height, distractors) $-$ a prohibitively expensive undertaking, if\ndone exhaustively. We introduce a principled method for deciding what data to\ncollect and how much to collect for each factor by constructing factored\nscaling curves (FSC), which quantify how policy performance varies as data\nscales along individual or paired factors. These curves enable targeted data\nacquisition for the most influential factor combinations within a given budget.\nWe evaluate the proposed method through extensive simulated and real-world\nexperiments, across both training-from-scratch and fine-tuning settings, and\nshow that it boosts success rates in real-world tasks in new environments by up\nto 26% over existing data-collection strategies. We further demonstrate how\nfactored scaling curves can effectively guide data collection using an offline\nmetric, without requiring real-world evaluation at scale.",
      "pdf_url": "http://arxiv.org/pdf/2505.07728v1",
      "published": "2025-05-12T16:36:35+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.07728v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Hybrid Spiking Vision Transformer for Object Detection with Event Cameras",
      "authors": [
        "Qi Xu",
        "Jie Deng",
        "Jiangrong Shen",
        "Biwu Chen",
        "Huajin Tang",
        "Gang Pan"
      ],
      "abstract": "Event-based object detection has gained increasing attention due to its\nadvantages such as high temporal resolution, wide dynamic range, and\nasynchronous address-event representation. Leveraging these advantages, Spiking\nNeural Networks (SNNs) have emerged as a promising approach, offering low\nenergy consumption and rich spatiotemporal dynamics. To further enhance the\nperformance of event-based object detection, this study proposes a novel hybrid\nspike vision Transformer (HsVT) model. The HsVT model integrates a spatial\nfeature extraction module to capture local and global features, and a temporal\nfeature extraction module to model time dependencies and long-term patterns in\nevent sequences. This combination enables HsVT to capture spatiotemporal\nfeatures, improving its capability to handle complex event-based object\ndetection tasks. To support research in this area, we developed and publicly\nreleased The Fall Detection Dataset as a benchmark for event-based object\ndetection tasks. This dataset, captured using an event-based camera, ensures\nfacial privacy protection and reduces memory usage due to the event\nrepresentation format. We evaluated the HsVT model on GEN1 and Fall Detection\ndatasets across various model sizes. Experimental results demonstrate that HsVT\nachieves significant performance improvements in event detection with fewer\nparameters.",
      "pdf_url": "http://arxiv.org/pdf/2505.07715v1",
      "published": "2025-05-12T16:19:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.07715v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Circuit Partitioning Using Large Language Models for Quantum Compilation and Simulations",
      "authors": [
        "Pranav Sinha",
        "Sumit Kumar Jha",
        "Sunny Raj"
      ],
      "abstract": "We are in the midst of the noisy intermediate-scale quantum (NISQ) era, where\nquantum computers are limited by noisy gates, some of which are more\nerror-prone than others and can render the final computation incomprehensible.\nQuantum circuit compilation algorithms attempt to minimize these noisy gates\nwhen mapping quantum algorithms onto quantum hardware but face computational\nchallenges that restrict their application to circuits with no more than 5-6\nqubits, necessitating the need to partition large circuits before the\napplication of noisy quantum gate minimization algorithms. The existing\ngeneration of these algorithms is heuristic in nature and does not account for\ndownstream gate minimization tasks. Large language models (LLMs) have the\npotential to change this and help improve quantum circuit partitions. This\npaper investigates the use of LLMs, such as Llama and Mistral, for partitioning\nquantum circuits by capitalizing on their abilities to understand and generate\ncode, including QASM. Specifically, we teach LLMs to partition circuits using\nthe quick partition approach of the Berkeley Quantum Synthesis Toolkit. Through\nexperimental evaluations, we show that careful fine-tuning of open source LLMs\nenables us to obtain an accuracy of 53.4% for the partition task while\nover-the-shelf LLMs are unable to correctly partition circuits, using standard\n1-shot and few-shot training approaches.",
      "pdf_url": "http://arxiv.org/pdf/2505.07711v1",
      "published": "2025-05-12T16:18:48+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.07711v1",
      "categories": [
        "cs.ET",
        "cs.AI",
        "quant-ph"
      ]
    },
    {
      "title": "Lightweight End-to-end Text-to-speech Synthesis for low resource on-device applications",
      "authors": [
        "Biel Tura Vecino",
        "Adam Gabryś",
        "Daniel Mątwicki",
        "Andrzej Pomirski",
        "Tom Iddon",
        "Marius Cotescu",
        "Jaime Lorenzo-Trueba"
      ],
      "abstract": "Recent works have shown that modelling raw waveform directly from text in an\nend-to-end (E2E) fashion produces more natural-sounding speech than traditional\nneural text-to-speech (TTS) systems based on a cascade or two-stage approach.\nHowever, current E2E state-of-the-art models are computationally complex and\nmemory-consuming, making them unsuitable for real-time offline on-device\napplications in low-resource scenarios. To address this issue, we propose a\nLightweight E2E-TTS (LE2E) model that generates high-quality speech requiring\nminimal computational resources. We evaluate the proposed model on the LJSpeech\ndataset and show that it achieves state-of-the-art performance while being up\nto $90\\%$ smaller in terms of model parameters and $10\\times$ faster in\nreal-time-factor. Furthermore, we demonstrate that the proposed E2E training\nparadigm achieves better quality compared to an equivalent architecture trained\nin a two-stage approach. Our results suggest that LE2E is a promising approach\nfor developing real-time, high quality, low-resource TTS applications for\non-device applications.",
      "pdf_url": "http://arxiv.org/pdf/2505.07701v1",
      "published": "2025-05-12T16:10:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.07701v1",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ]
    },
    {
      "title": "Belief Injection for Epistemic Control in Linguistic State Space",
      "authors": [
        "Sebastian Dumbrava"
      ],
      "abstract": "This work introduces belief injection, a proactive epistemic control\nmechanism for artificial agents whose cognitive states are structured as\ndynamic ensembles of linguistic belief fragments. Grounded in the Semantic\nManifold framework, belief injection directly incorporates targeted linguistic\nbeliefs into an agent's internal cognitive state, influencing reasoning and\nalignment proactively rather than reactively. We delineate various injection\nstrategies, such as direct, context-aware, goal-oriented, and reflective\napproaches, and contrast belief injection with related epistemic control\nmechanisms, notably belief filtering. Additionally, this work discusses\npractical applications, implementation considerations, ethical implications,\nand outlines promising directions for future research into cognitive governance\nusing architecturally embedded belief injection.",
      "pdf_url": "http://arxiv.org/pdf/2505.07693v1",
      "published": "2025-05-12T15:58:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.07693v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "S-GRPO: Early Exit via Reinforcement Learning in Reasoning Models",
      "authors": [
        "Muzhi Dai",
        "Chenxu Yang",
        "Qingyi Si"
      ],
      "abstract": "As Test-Time Scaling emerges as an active research focus in the large\nlanguage model community, advanced post-training methods increasingly emphasize\nextending chain-of-thought (CoT) generation length, thereby enhancing reasoning\ncapabilities to approach Deepseek R1-like reasoning models. However, recent\nstudies reveal that reasoning models (even Qwen3) consistently exhibit\nexcessive thought redundancy in CoT generation. This overthinking problem stems\nfrom conventional outcome-reward reinforcement learning's systematic neglect in\nregulating intermediate reasoning steps. This paper proposes Serial-Group\nDecaying-Reward Policy Optimization (namely S-GRPO), a novel reinforcement\nlearning method that empowers models with the capability to determine the\nsufficiency of reasoning steps, subsequently triggering early exit of CoT\ngeneration. Specifically, unlike GRPO, which samples multiple possible\ncompletions (parallel group) in parallel, we select multiple temporal positions\nin the generation of one CoT to allow the model to exit thinking and instead\ngenerate answers (serial group), respectively. For the correct answers in a\nserial group, we assign rewards that decay according to positions, with lower\nrewards towards the later ones, thereby reinforcing the model's behavior to\ngenerate higher-quality answers at earlier phases with earlier exits of\nthinking. Empirical evaluations demonstrate compatibility with state-of-the-art\nreasoning models, including Qwen3 and Deepseek-distill models, achieving 35.4%\n~ 61.1\\% sequence length reduction with 0.72% ~ 6.08% accuracy improvements\nacross GSM8K, AIME 2024, AMC 2023, MATH-500, and GPQA Diamond benchmarks.",
      "pdf_url": "http://arxiv.org/pdf/2505.07686v1",
      "published": "2025-05-12T15:50:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.07686v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Multimodal Survival Modeling in the Age of Foundation Models",
      "authors": [
        "Steven Song",
        "Morgan Borjigin-Wang",
        "Irene Madejski",
        "Robert L. Grossman"
      ],
      "abstract": "The Cancer Genome Atlas (TCGA) has enabled novel discoveries and served as a\nlarge-scale reference through its harmonized genomics, clinical, and image\ndata. Prior studies have trained bespoke cancer survival prediction models from\nunimodal or multimodal TCGA data. A modern paradigm in biomedical deep learning\nis the development of foundation models (FMs) to derive meaningful feature\nembeddings, agnostic to a specific modeling task. Biomedical text especially\nhas seen growing development of FMs. While TCGA contains free-text data as\npathology reports, these have been historically underutilized. Here, we\ninvestigate the feasibility of training classical, multimodal survival models\nover zero-shot embeddings extracted by FMs. We show the ease and additive\neffect of multimodal fusion, outperforming unimodal models. We demonstrate the\nbenefit of including pathology report text and rigorously evaluate the effect\nof model-based text summarization and hallucination. Overall, we modernize\nsurvival modeling by leveraging FMs and information extraction from pathology\nreports.",
      "pdf_url": "http://arxiv.org/pdf/2505.07683v1",
      "published": "2025-05-12T15:47:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.07683v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Simple Semi-supervised Knowledge Distillation from Vision-Language Models via $\\mathbf{\\texttt{D}}$ual-$\\mathbf{\\texttt{H}}$ead $\\mathbf{\\texttt{O}}$ptimization",
      "authors": [
        "Seongjae Kang",
        "Dong Bok Lee",
        "Hyungjoon Jang",
        "Sung Ju Hwang"
      ],
      "abstract": "Vision-language models (VLMs) have achieved remarkable success across diverse\ntasks by leveraging rich textual information with minimal labeled data.\nHowever, deploying such large models remains challenging, particularly in\nresource-constrained environments. Knowledge distillation (KD) offers a\nwell-established solution to this problem; however, recent KD approaches from\nVLMs often involve multi-stage training or additional tuning, increasing\ncomputational overhead and optimization complexity. In this paper, we propose\n$\\mathbf{\\texttt{D}}$ual-$\\mathbf{\\texttt{H}}$ead\n$\\mathbf{\\texttt{O}}$ptimization ($\\mathbf{\\texttt{DHO}}$) -- a simple yet\neffective KD framework that transfers knowledge from VLMs to compact,\ntask-specific models in semi-supervised settings. Specifically, we introduce\ndual prediction heads that independently learn from labeled data and teacher\npredictions, and propose to linearly combine their outputs during inference. We\nobserve that $\\texttt{DHO}$ mitigates gradient conflicts between supervised and\ndistillation signals, enabling more effective feature learning than single-head\nKD baselines. As a result, extensive experiments show that $\\texttt{DHO}$\nconsistently outperforms baselines across multiple domains and fine-grained\ndatasets. Notably, on ImageNet, it achieves state-of-the-art performance,\nimproving accuracy by 3% and 0.1% with 1% and 10% labeled data, respectively,\nwhile using fewer parameters.",
      "pdf_url": "http://arxiv.org/pdf/2505.07675v1",
      "published": "2025-05-12T15:39:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.07675v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "OnPrem.LLM: A Privacy-Conscious Document Intelligence Toolkit",
      "authors": [
        "Arun S. Maiya"
      ],
      "abstract": "We present OnPrem$.$LLM, a Python-based toolkit for applying large language\nmodels (LLMs) to sensitive, non-public data in offline or restricted\nenvironments. The system is designed for privacy-preserving use cases and\nprovides prebuilt pipelines for document processing and storage,\nretrieval-augmented generation (RAG), information extraction, summarization,\nclassification, and prompt/output processing with minimal configuration.\nOnPrem$.$LLM supports multiple LLM backends -- including llama$.$cpp, Ollama,\nvLLM, and Hugging Face Transformers -- with quantized model support, GPU\nacceleration, and seamless backend switching. Although designed for fully local\nexecution, OnPrem$.$LLM also supports integration with a wide range of cloud\nLLM providers when permitted, enabling hybrid deployments that balance\nperformance with data control. A no-code web interface extends accessibility to\nnon-technical users.",
      "pdf_url": "http://arxiv.org/pdf/2505.07672v2",
      "published": "2025-05-12T15:36:27+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.07672v2",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Benchmarking Retrieval-Augmented Generation for Chemistry",
      "authors": [
        "Xianrui Zhong",
        "Bowen Jin",
        "Siru Ouyang",
        "Yanzhen Shen",
        "Qiao Jin",
        "Yin Fang",
        "Zhiyong Lu",
        "Jiawei Han"
      ],
      "abstract": "Retrieval-augmented generation (RAG) has emerged as a powerful framework for\nenhancing large language models (LLMs) with external knowledge, particularly in\nscientific domains that demand specialized and dynamic information. Despite its\npromise, the application of RAG in the chemistry domain remains underexplored,\nprimarily due to the lack of high-quality, domain-specific corpora and\nwell-curated evaluation benchmarks. In this work, we introduce ChemRAG-Bench, a\ncomprehensive benchmark designed to systematically assess the effectiveness of\nRAG across a diverse set of chemistry-related tasks. The accompanying chemistry\ncorpus integrates heterogeneous knowledge sources, including scientific\nliterature, the PubChem database, PubMed abstracts, textbooks, and Wikipedia\nentries. In addition, we present ChemRAG-Toolkit, a modular and extensible RAG\ntoolkit that supports five retrieval algorithms and eight LLMs. Using\nChemRAG-Toolkit, we demonstrate that RAG yields a substantial performance gain\n-- achieving an average relative improvement of 17.4% over direct inference\nmethods. We further conduct in-depth analyses on retriever architectures,\ncorpus selection, and the number of retrieved passages, culminating in\npractical recommendations to guide future research and deployment of RAG\nsystems in the chemistry domain. The code and data is available at\nhttps://chemrag.github.io.",
      "pdf_url": "http://arxiv.org/pdf/2505.07671v1",
      "published": "2025-05-12T15:34:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.07671v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ]
    },
    {
      "title": "A Case Study Investigating the Role of Generative AI in Quality Evaluations of Epics in Agile Software Development",
      "authors": [
        "Werner Geyer",
        "Jessica He",
        "Daita Sarkar",
        "Michelle Brachman",
        "Chris Hammond",
        "Jennifer Heins",
        "Zahra Ashktorab",
        "Carlos Rosemberg",
        "Charlie Hill"
      ],
      "abstract": "The broad availability of generative AI offers new opportunities to support\nvarious work domains, including agile software development. Agile epics are a\nkey artifact for product managers to communicate requirements to stakeholders.\nHowever, in practice, they are often poorly defined, leading to churn, delivery\ndelays, and cost overruns. In this industry case study, we investigate\nopportunities for large language models (LLMs) to evaluate agile epic quality\nin a global company. Results from a user study with 17 product managers\nindicate how LLM evaluations could be integrated into their work practices,\nincluding perceived values and usage in improving their epics. High levels of\nsatisfaction indicate that agile epics are a new, viable application of AI\nevaluations. However, our findings also outline challenges, limitations, and\nadoption barriers that can inform both practitioners and researchers on the\nintegration of such evaluations into future agile work practices.",
      "pdf_url": "http://arxiv.org/pdf/2505.07664v1",
      "published": "2025-05-12T15:31:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.07664v1",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.HC"
      ]
    },
    {
      "title": "Chronocept: Instilling a Sense of Time in Machines",
      "authors": [
        "Krish Goel",
        "Sanskar Pandey",
        "KS Mahadevan",
        "Harsh Kumar",
        "Vishesh Khadaria"
      ],
      "abstract": "Human cognition is deeply intertwined with a sense of time, known as\nChronoception. This sense allows us to judge how long facts remain valid and\nwhen knowledge becomes outdated. Despite progress in vision, language, and\nmotor control, AI still struggles to reason about temporal validity. We\nintroduce Chronocept, the first benchmark to model temporal validity as a\ncontinuous probability distribution over time. Using skew-normal curves fitted\nalong semantically decomposed temporal axes, Chronocept captures nuanced\npatterns of emergence, decay, and peak relevance. It includes two datasets:\nBenchmark I (atomic facts) and Benchmark II (multi-sentence passages).\nAnnotations show strong inter-annotator agreement (84% and 89%). Our baselines\npredict curve parameters - location, scale, and skewness - enabling\ninterpretable, generalizable learning and outperforming classification-based\napproaches. Chronocept fills a foundational gap in AI's temporal reasoning,\nsupporting applications in knowledge grounding, fact-checking,\nretrieval-augmented generation (RAG), and proactive agents. Code and data are\npublicly available.",
      "pdf_url": "http://arxiv.org/pdf/2505.07637v1",
      "published": "2025-05-12T15:07:32+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.07637v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Neural Brain: A Neuroscience-inspired Framework for Embodied Agents",
      "authors": [
        "Jian Liu",
        "Xiongtao Shi",
        "Thai Duy Nguyen",
        "Haitian Zhang",
        "Tianxiang Zhang",
        "Wei Sun",
        "Yanjie Li",
        "Athanasios V. Vasilakos",
        "Giovanni Iacca",
        "Arshad Ali Khan",
        "Arvind Kumar",
        "Jae Won Cho",
        "Ajmal Mian",
        "Lihua Xie",
        "Erik Cambria",
        "Lin Wang"
      ],
      "abstract": "The rapid evolution of artificial intelligence (AI) has shifted from static,\ndata-driven models to dynamic systems capable of perceiving and interacting\nwith real-world environments. Despite advancements in pattern recognition and\nsymbolic reasoning, current AI systems, such as large language models, remain\ndisembodied, unable to physically engage with the world. This limitation has\ndriven the rise of embodied AI, where autonomous agents, such as humanoid\nrobots, must navigate and manipulate unstructured environments with human-like\nadaptability. At the core of this challenge lies the concept of Neural Brain, a\ncentral intelligence system designed to drive embodied agents with human-like\nadaptability. A Neural Brain must seamlessly integrate multimodal sensing and\nperception with cognitive capabilities. Achieving this also requires an\nadaptive memory system and energy-efficient hardware-software co-design,\nenabling real-time action in dynamic environments. This paper introduces a\nunified framework for the Neural Brain of embodied agents, addressing two\nfundamental challenges: (1) defining the core components of Neural Brain and\n(2) bridging the gap between static AI models and the dynamic adaptability\nrequired for real-world deployment. To this end, we propose a biologically\ninspired architecture that integrates multimodal active sensing,\nperception-cognition-action function, neuroplasticity-based memory storage and\nupdating, and neuromorphic hardware/software optimization. Furthermore, we also\nreview the latest research on embodied agents across these four aspects and\nanalyze the gap between current AI systems and human intelligence. By\nsynthesizing insights from neuroscience, we outline a roadmap towards the\ndevelopment of generalizable, autonomous agents capable of human-level\nintelligence in real-world scenarios.",
      "pdf_url": "http://arxiv.org/pdf/2505.07634v1",
      "published": "2025-05-12T15:05:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.07634v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Bang for the Buck: Vector Search on Cloud CPUs",
      "authors": [
        "Leonardo Kuffo",
        "Peter Boncz"
      ],
      "abstract": "Vector databases have emerged as a new type of systems that support efficient\nquerying of high-dimensional vectors. Many of these offer their database as a\nservice in the cloud. However, the variety of available CPUs and the lack of\nvector search benchmarks across CPUs make it difficult for users to choose one.\nIn this study, we show that CPU microarchitectures available in the cloud\nperform significantly differently across vector search scenarios. For instance,\nin an IVF index on float32 vectors, AMD's Zen4 gives almost 3x more queries per\nsecond (QPS) compared to Intel's Sapphire Rapids, but for HNSW indexes, the\ntables turn. However, when looking at the number of queries per dollar (QP$),\nGraviton3 is the best option for most indexes and quantization settings, even\nover Graviton4 (Table 1). With this work, we hope to guide users in getting the\nbest \"bang for the buck\" when deploying vector search systems.",
      "pdf_url": "http://arxiv.org/pdf/2505.07621v1",
      "published": "2025-05-12T14:44:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.07621v1",
      "categories": [
        "cs.DB",
        "cs.AI"
      ]
    },
    {
      "title": "Diffused Responsibility: Analyzing the Energy Consumption of Generative Text-to-Audio Diffusion Models",
      "authors": [
        "Riccardo Passoni",
        "Francesca Ronchini",
        "Luca Comanducci",
        "Romain Serizel",
        "Fabio Antonacci"
      ],
      "abstract": "Text-to-audio models have recently emerged as a powerful technology for\ngenerating sound from textual descriptions. However, their high computational\ndemands raise concerns about energy consumption and environmental impact. In\nthis paper, we conduct an analysis of the energy usage of 7 state-of-the-art\ntext-to-audio diffusion-based generative models, evaluating to what extent\nvariations in generation parameters affect energy consumption at inference\ntime. We also aim to identify an optimal balance between audio quality and\nenergy consumption by considering Pareto-optimal solutions across all selected\nmodels. Our findings provide insights into the trade-offs between performance\nand environmental impact, contributing to the development of more efficient\ngenerative audio models.",
      "pdf_url": "http://arxiv.org/pdf/2505.07615v1",
      "published": "2025-05-12T14:36:47+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.07615v1",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.LG",
        "cs.SD"
      ]
    },
    {
      "title": "Concept-Level Explainability for Auditing & Steering LLM Responses",
      "authors": [
        "Kenza Amara",
        "Rita Sevastjanova",
        "Mennatallah El-Assady"
      ],
      "abstract": "As large language models (LLMs) become widely deployed, concerns about their\nsafety and alignment grow. An approach to steer LLM behavior, such as\nmitigating biases or defending against jailbreaks, is to identify which parts\nof a prompt influence specific aspects of the model's output. Token-level\nattribution methods offer a promising solution, but still struggle in text\ngeneration, explaining the presence of each token in the output separately,\nrather than the underlying semantics of the entire LLM response. We introduce\nConceptX, a model-agnostic, concept-level explainability method that identifies\nthe concepts, i.e., semantically rich tokens in the prompt, and assigns them\nimportance based on the outputs' semantic similarity. Unlike current\ntoken-level methods, ConceptX also offers to preserve context integrity through\nin-place token replacements and supports flexible explanation goals, e.g.,\ngender bias. ConceptX enables both auditing, by uncovering sources of bias, and\nsteering, by modifying prompts to shift the sentiment or reduce the harmfulness\nof LLM responses, without requiring retraining. Across three LLMs, ConceptX\noutperforms token-level methods like TokenSHAP in both faithfulness and human\nalignment. Steering tasks boost sentiment shift by 0.252 versus 0.131 for\nrandom edits and lower attack success rates from 0.463 to 0.242, outperforming\nattribution and paraphrasing baselines. While prompt engineering and\nself-explaining methods sometimes yield safer responses, ConceptX offers a\ntransparent and faithful alternative for improving LLM safety and alignment,\ndemonstrating the practical value of attribution-based explainability in\nguiding LLM behavior.",
      "pdf_url": "http://arxiv.org/pdf/2505.07610v1",
      "published": "2025-05-12T14:31:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.07610v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "MiMo: Unlocking the Reasoning Potential of Language Model -- From Pretraining to Posttraining",
      "authors": [
        "Xiaomi LLM-Core Team",
        ":",
        "Bingquan Xia",
        "Bowen Shen",
        "Cici",
        "Dawei Zhu",
        "Di Zhang",
        "Gang Wang",
        "Hailin Zhang",
        "Huaqiu Liu",
        "Jiebao Xiao",
        "Jinhao Dong",
        "Liang Zhao",
        "Peidian Li",
        "Peng Wang",
        "Shihua Yu",
        "Shimao Chen",
        "Weikun Wang",
        "Wenhan Ma",
        "Xiangwei Deng",
        "Yi Huang",
        "Yifan Song",
        "Zihan Jiang",
        "Bowen Ye",
        "Can Cai",
        "Chenhong He",
        "Dong Zhang",
        "Duo Zhang",
        "Guoan Wang",
        "Hao Tian",
        "Haochen Zhao",
        "Heng Qu",
        "Hongshen Xu",
        "Jun Shi",
        "Kainan Bao",
        "QingKai Fang",
        "Kang Zhou",
        "Kangyang Zhou",
        "Lei Li",
        "Menghang Zhu",
        "Nuo Chen",
        "Qiantong Wang",
        "Shaohui Liu",
        "Shicheng Li",
        "Shuhao Gu",
        "Shuhuai Ren",
        "Shuo Liu",
        "Sirui Deng",
        "Weiji Zhuang",
        "Weiwei Lv",
        "Wenyu Yang",
        "Xin Zhang",
        "Xing Yong",
        "Xing Zhang",
        "Xingchen Song",
        "Xinzhe Xu",
        "Xu Wang",
        "Yihan Yan",
        "Yu Tu",
        "Yuanyuan Tian",
        "Yudong Wang",
        "Yue Yu",
        "Zhenru Lin",
        "Zhichao Song",
        "Zihao Yue"
      ],
      "abstract": "We present MiMo-7B, a large language model born for reasoning tasks, with\noptimization across both pre-training and post-training stages. During\npre-training, we enhance the data preprocessing pipeline and employ a\nthree-stage data mixing strategy to strengthen the base model's reasoning\npotential. MiMo-7B-Base is pre-trained on 25 trillion tokens, with additional\nMulti-Token Prediction objective for enhanced performance and accelerated\ninference speed. During post-training, we curate a dataset of 130K verifiable\nmathematics and programming problems for reinforcement learning, integrating a\ntest-difficulty-driven code-reward scheme to alleviate sparse-reward issues and\nemploying strategic data resampling to stabilize training. Extensive\nevaluations show that MiMo-7B-Base possesses exceptional reasoning potential,\noutperforming even much larger 32B models. The final RL-tuned model,\nMiMo-7B-RL, achieves superior performance on mathematics, code and general\nreasoning tasks, surpassing the performance of OpenAI o1-mini. The model\ncheckpoints are available at https://github.com/xiaomimimo/MiMo.",
      "pdf_url": "http://arxiv.org/pdf/2505.07608v1",
      "published": "2025-05-12T14:30:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.07608v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Characterizing the Investigative Methods of Fictional Detectives with Large Language Models",
      "authors": [
        "Edirlei Soares de Lima",
        "Marco A. Casanova",
        "Bruno Feijó",
        "Antonio L. Furtado"
      ],
      "abstract": "Detective fiction, a genre defined by its complex narrative structures and\ncharacter-driven storytelling, presents unique challenges for computational\nnarratology, a research field focused on integrating literary theory into\nautomated narrative generation. While traditional literary studies have offered\ndeep insights into the methods and archetypes of fictional detectives, these\nanalyses often focus on a limited number of characters and lack the scalability\nneeded for the extraction of unique traits that can be used to guide narrative\ngeneration methods. In this paper, we present an AI-driven approach for\nsystematically characterizing the investigative methods of fictional\ndetectives. Our multi-phase workflow explores the capabilities of 15 Large\nLanguage Models (LLMs) to extract, synthesize, and validate distinctive\ninvestigative traits of fictional detectives. This approach was tested on a\ndiverse set of seven iconic detectives - Hercule Poirot, Sherlock Holmes,\nWilliam Murdoch, Columbo, Father Brown, Miss Marple, and Auguste Dupin -\ncapturing the distinctive investigative styles that define each character. The\nidentified traits were validated against existing literary analyses and further\ntested in a reverse identification phase, achieving an overall accuracy of\n91.43%, demonstrating the method's effectiveness in capturing the distinctive\ninvestigative approaches of each detective. This work contributes to the\nbroader field of computational narratology by providing a scalable framework\nfor character analysis, with potential applications in AI-driven interactive\nstorytelling and automated narrative generation.",
      "pdf_url": "http://arxiv.org/pdf/2505.07601v1",
      "published": "2025-05-12T14:24:58+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.07601v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Reinforced Internal-External Knowledge Synergistic Reasoning for Efficient Adaptive Search Agent",
      "authors": [
        "Ziyang Huang",
        "Xiaowei Yuan",
        "Yiming Ju",
        "Jun Zhao",
        "Kang Liu"
      ],
      "abstract": "Retrieval-augmented generation (RAG) is a common strategy to reduce\nhallucinations in Large Language Models (LLMs). While reinforcement learning\n(RL) can enable LLMs to act as search agents by activating retrieval\ncapabilities, existing ones often underutilize their internal knowledge. This\ncan lead to redundant retrievals, potential harmful knowledge conflicts, and\nincreased inference latency. To address these limitations, an efficient and\nadaptive search agent capable of discerning optimal retrieval timing and\nsynergistically integrating parametric (internal) and retrieved (external)\nknowledge is in urgent need. This paper introduces the Reinforced\nInternal-External Knowledge Synergistic Reasoning Agent (IKEA), which could\nindentify its own knowledge boundary and prioritize the utilization of internal\nknowledge, resorting to external search only when internal knowledge is deemed\ninsufficient. This is achieved using a novel knowledge-boundary aware reward\nfunction and a knowledge-boundary aware training dataset. These are designed\nfor internal-external knowledge synergy oriented RL, incentivizing the model to\ndeliver accurate answers, minimize unnecessary retrievals, and encourage\nappropriate external searches when its own knowledge is lacking. Evaluations\nacross multiple knowledge reasoning tasks demonstrate that IKEA significantly\noutperforms baseline methods, reduces retrieval frequency significantly, and\nexhibits robust generalization capabilities.",
      "pdf_url": "http://arxiv.org/pdf/2505.07596v1",
      "published": "2025-05-12T14:21:57+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.07596v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "A Multi-Dimensional Constraint Framework for Evaluating and Improving Instruction Following in Large Language Models",
      "authors": [
        "Junjie Ye",
        "Caishuang Huang",
        "Zhuohan Chen",
        "Wenjie Fu",
        "Chenyuan Yang",
        "Leyi Yang",
        "Yilong Wu",
        "Peng Wang",
        "Meng Zhou",
        "Xiaolong Yang",
        "Tao Gui",
        "Qi Zhang",
        "Zhongchao Shi",
        "Jianping Fan",
        "Xuanjing Huang"
      ],
      "abstract": "Instruction following evaluates large language models (LLMs) on their ability\nto generate outputs that adhere to user-defined constraints. However, existing\nbenchmarks often rely on templated constraint prompts, which lack the diversity\nof real-world usage and limit fine-grained performance assessment. To fill this\ngap, we propose a multi-dimensional constraint framework encompassing three\nconstraint patterns, four constraint categories, and four difficulty levels.\nBuilding on this framework, we develop an automated instruction generation\npipeline that performs constraint expansion, conflict detection, and\ninstruction rewriting, yielding 1,200 code-verifiable instruction-following\ntest samples. We evaluate 19 LLMs across seven model families and uncover\nsubstantial variation in performance across constraint forms. For instance,\naverage performance drops from 77.67% at Level I to 32.96% at Level IV.\nFurthermore, we demonstrate the utility of our approach by using it to generate\ndata for reinforcement learning, achieving substantial gains in instruction\nfollowing without degrading general performance. In-depth analysis indicates\nthat these gains stem primarily from modifications in the model's attention\nmodules parameters, which enhance constraint recognition and adherence. Code\nand data are available in https://github.com/Junjie-Ye/MulDimIF.",
      "pdf_url": "http://arxiv.org/pdf/2505.07591v1",
      "published": "2025-05-12T14:16:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.07591v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "YuLan-OneSim: Towards the Next Generation of Social Simulator with Large Language Models",
      "authors": [
        "Lei Wang",
        "Heyang Gao",
        "Xiaohe Bo",
        "Xu Chen",
        "Ji-Rong Wen"
      ],
      "abstract": "Leveraging large language model (LLM) based agents to simulate human social\nbehaviors has recently gained significant attention. In this paper, we\nintroduce a novel social simulator called YuLan-OneSim. Compared to previous\nworks, YuLan-OneSim distinguishes itself in five key aspects: (1) Code-free\nscenario construction: Users can simply describe and refine their simulation\nscenarios through natural language interactions with our simulator. All\nsimulation code is automatically generated, significantly reducing the need for\nprogramming expertise. (2) Comprehensive default scenarios: We implement 50\ndefault simulation scenarios spanning 8 domains, including economics,\nsociology, politics, psychology, organization, demographics, law, and\ncommunication, broadening access for a diverse range of social researchers. (3)\nEvolvable simulation: Our simulator is capable of receiving external feedback\nand automatically fine-tuning the backbone LLMs, significantly enhancing the\nsimulation quality. (4) Large-scale simulation: By developing a fully\nresponsive agent framework and a distributed simulation architecture, our\nsimulator can handle up to 100,000 agents, ensuring more stable and reliable\nsimulation results. (5) AI social researcher: Leveraging the above features, we\ndevelop an AI social researcher. Users only need to propose a research topic,\nand the AI researcher will automatically analyze the input, construct\nsimulation environments, summarize results, generate technical reports, review\nand refine the reports--completing the social science research loop. To\ndemonstrate the advantages of YuLan-OneSim, we conduct experiments to evaluate\nthe quality of the automatically generated scenarios, the reliability,\nefficiency, and scalability of the simulation process, as well as the\nperformance of the AI social researcher.",
      "pdf_url": "http://arxiv.org/pdf/2505.07581v1",
      "published": "2025-05-12T14:05:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.07581v1",
      "categories": [
        "cs.AI",
        "cs.CY"
      ]
    },
    {
      "title": "Evaluating Modern Visual Anomaly Detection Approaches in Semiconductor Manufacturing: A Comparative Study",
      "authors": [
        "Manuel Barusco",
        "Francesco Borsatti",
        "Youssef Ben Khalifa",
        "Davide Dalle Pezze",
        "Gian Antonio Susto"
      ],
      "abstract": "Semiconductor manufacturing is a complex, multistage process. Automated\nvisual inspection of Scanning Electron Microscope (SEM) images is indispensable\nfor minimizing equipment downtime and containing costs. Most previous research\nconsiders supervised approaches, assuming a sufficient number of anomalously\nlabeled samples. On the contrary, Visual Anomaly Detection (VAD), an emerging\nresearch domain, focuses on unsupervised learning, avoiding the costly defect\ncollection phase while providing explanations of the predictions. We introduce\na benchmark for VAD in the semiconductor domain by leveraging the MIIC dataset.\nOur results demonstrate the efficacy of modern VAD approaches in this field.",
      "pdf_url": "http://arxiv.org/pdf/2505.07576v1",
      "published": "2025-05-12T13:56:59+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.07576v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Robust Kidney Abnormality Segmentation: A Validation Study of an AI-Based Framework",
      "authors": [
        "Sarah de Boer",
        "Hartmut Häntze",
        "Kiran Vaidhya Venkadesh",
        "Myrthe A. D. Buser",
        "Gabriel E. Humpire Mamani",
        "Lina Xu",
        "Lisa C. Adams",
        "Jawed Nawabi",
        "Keno K. Bressem",
        "Bram van Ginneken",
        "Mathias Prokop",
        "Alessa Hering"
      ],
      "abstract": "Kidney abnormality segmentation has important potential to enhance the\nclinical workflow, especially in settings requiring quantitative assessments.\nKidney volume could serve as an important biomarker for renal diseases, with\nchanges in volume correlating directly with kidney function. Currently,\nclinical practice often relies on subjective visual assessment for evaluating\nkidney size and abnormalities, including tumors and cysts, which are typically\nstaged based on diameter, volume, and anatomical location. To support a more\nobjective and reproducible approach, this research aims to develop a robust,\nthoroughly validated kidney abnormality segmentation algorithm, made publicly\navailable for clinical and research use. We employ publicly available training\ndatasets and leverage the state-of-the-art medical image segmentation framework\nnnU-Net. Validation is conducted using both proprietary and public test\ndatasets, with segmentation performance quantified by Dice coefficient and the\n95th percentile Hausdorff distance. Furthermore, we analyze robustness across\nsubgroups based on patient sex, age, CT contrast phases, and tumor histologic\nsubtypes. Our findings demonstrate that our segmentation algorithm, trained\nexclusively on publicly available data, generalizes effectively to external\ntest sets and outperforms existing state-of-the-art models across all tested\ndatasets. Subgroup analyses reveal consistent high performance, indicating\nstrong robustness and reliability. The developed algorithm and associated code\nare publicly accessible at\nhttps://github.com/DIAGNijmegen/oncology-kidney-abnormality-segmentation.",
      "pdf_url": "http://arxiv.org/pdf/2505.07573v1",
      "published": "2025-05-12T13:53:19+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.07573v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Towards Requirements Engineering for RAG Systems",
      "authors": [
        "Tor Sporsem",
        "Rasmus Ulfsnes"
      ],
      "abstract": "This short paper explores how a maritime company develops and integrates\nlarge-language models (LLM). Specifically by looking at the requirements\nengineering for Retrieval Augmented Generation (RAG) systems in expert\nsettings. Through a case study at a maritime service provider, we demonstrate\nhow data scientists face a fundamental tension between user expectations of AI\nperfection and the correctness of the generated outputs. Our findings reveal\nthat data scientists must identify context-specific \"retrieval requirements\"\nthrough iterative experimentation together with users because they are the ones\nwho can determine correctness. We present an empirical process model describing\nhow data scientists practically elicited these \"retrieval requirements\" and\nmanaged system limitations. This work advances software engineering knowledge\nby providing insights into the specialized requirements engineering processes\nfor implementing RAG systems in complex domain-specific applications.",
      "pdf_url": "http://arxiv.org/pdf/2505.07553v1",
      "published": "2025-05-12T13:30:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.07553v1",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "Automated Visual Attention Detection using Mobile Eye Tracking in Behavioral Classroom Studies",
      "authors": [
        "Efe Bozkir",
        "Christian Kosel",
        "Tina Seidel",
        "Enkelejda Kasneci"
      ],
      "abstract": "Teachers' visual attention and its distribution across the students in\nclassrooms can constitute important implications for student engagement,\nachievement, and professional teacher training. Despite that, inferring the\ninformation about where and which student teachers focus on is not trivial.\nMobile eye tracking can provide vital help to solve this issue; however, the\nuse of mobile eye tracking alone requires a significant amount of manual\nannotations. To address this limitation, we present an automated processing\npipeline concept that requires minimal manually annotated data to recognize\nwhich student the teachers focus on. To this end, we utilize state-of-the-art\nface detection models and face recognition feature embeddings to train face\nrecognition models with transfer learning in the classroom context and combine\nthese models with the teachers' gaze from mobile eye trackers. We evaluated our\napproach with data collected from four different classrooms, and our results\nshow that while it is possible to estimate the visually focused students with\nreasonable performance in all of our classroom setups, U-shaped and small\nclassrooms led to the best results with accuracies of approximately 0.7 and\n0.9, respectively. While we did not evaluate our method for teacher-student\ninteractions and focused on the validity of the technical approach, as our\nmethodology does not require a vast amount of manually annotated data and\noffers a non-intrusive way of handling teachers' visual attention, it could\nhelp improve instructional strategies, enhance classroom management, and\nprovide feedback for professional teacher development.",
      "pdf_url": "http://arxiv.org/pdf/2505.07552v1",
      "published": "2025-05-12T13:30:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.07552v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC"
      ]
    },
    {
      "title": "Noise Optimized Conditional Diffusion for Domain Adaptation",
      "authors": [
        "Lingkun Luo",
        "Shiqiang Hu",
        "Liming Chen"
      ],
      "abstract": "Pseudo-labeling is a cornerstone of Unsupervised Domain Adaptation (UDA), yet\nthe scarcity of High-Confidence Pseudo-Labeled Target Domain Samples\n(\\textbf{hcpl-tds}) often leads to inaccurate cross-domain statistical\nalignment, causing DA failures. To address this challenge, we propose\n\\textbf{N}oise \\textbf{O}ptimized \\textbf{C}onditional \\textbf{D}iffusion for\n\\textbf{D}omain \\textbf{A}daptation (\\textbf{NOCDDA}), which seamlessly\nintegrates the generative capabilities of conditional diffusion models with the\ndecision-making requirements of DA to achieve task-coupled optimization for\nefficient adaptation. For robust cross-domain consistency, we modify the DA\nclassifier to align with the conditional diffusion classifier within a unified\noptimization framework, enabling forward training on noise-varying cross-domain\nsamples. Furthermore, we argue that the conventional \\( \\mathcal{N}(\\mathbf{0},\n\\mathbf{I}) \\) initialization in diffusion models often generates\nclass-confused hcpl-tds, compromising discriminative DA. To resolve this, we\nintroduce a class-aware noise optimization strategy that refines sampling\nregions for reverse class-specific hcpl-tds generation, effectively enhancing\ncross-domain alignment. Extensive experiments across 5 benchmark datasets and\n29 DA tasks demonstrate significant performance gains of \\textbf{NOCDDA} over\n31 state-of-the-art methods, validating its robustness and effectiveness.",
      "pdf_url": "http://arxiv.org/pdf/2505.07548v1",
      "published": "2025-05-12T13:28:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.07548v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "GRADA: Graph-based Reranker against Adversarial Documents Attack",
      "authors": [
        "Jingjie Zheng",
        "Aryo Pradipta Gema",
        "Giwon Hong",
        "Xuanli He",
        "Pasquale Minervini",
        "Youcheng Sun",
        "Qiongkai Xu"
      ],
      "abstract": "Retrieval Augmented Generation (RAG) frameworks improve the accuracy of large\nlanguage models (LLMs) by integrating external knowledge from retrieved\ndocuments, thereby overcoming the limitations of models' static intrinsic\nknowledge. However, these systems are susceptible to adversarial attacks that\nmanipulate the retrieval process by introducing documents that are adversarial\nyet semantically similar to the query. Notably, while these adversarial\ndocuments resemble the query, they exhibit weak similarity to benign documents\nin the retrieval set. Thus, we propose a simple yet effective Graph-based\nReranking against Adversarial Document Attacks (GRADA) framework aiming at\npreserving retrieval quality while significantly reducing the success of\nadversaries. Our study evaluates the effectiveness of our approach through\nexperiments conducted on five LLMs: GPT-3.5-Turbo, GPT-4o, Llama3.1-8b,\nLlama3.1-70b, and Qwen2.5-7b. We use three datasets to assess performance, with\nresults from the Natural Questions dataset demonstrating up to an 80% reduction\nin attack success rates while maintaining minimal loss in accuracy.",
      "pdf_url": "http://arxiv.org/pdf/2505.07546v1",
      "published": "2025-05-12T13:27:35+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.07546v1",
      "categories": [
        "cs.IR",
        "cs.AI"
      ]
    },
    {
      "title": "The Human-Data-Model Interaction Canvas for Visual Analytics",
      "authors": [
        "Jürgen Bernard"
      ],
      "abstract": "Visual Analytics (VA) integrates humans, data, and models as key actors in\ninsight generation and data-driven decision-making. This position paper values\nand reflects on 16 VA process models and frameworks and makes nine high-level\nobservations that motivate a fresh perspective on VA. The contribution is the\nHDMI Canvas, a perspective to VA that complements the strengths of existing VA\nprocess models and frameworks. It systematically characterizes diverse roles of\nhumans, data, and models, and how these actors benefit from and contribute to\nVA processes. The descriptive power of the HDMI Canvas eases the\ndifferentiation between a series of VA building blocks, rather than describing\ngeneral VA principles only. The canvas includes modern human-centered\nmethodologies, including human knowledge externalization and forms of feedback\nloops, while interpretable and explainable AI highlight model contributions\nbeyond their conventional outputs. The HDMI Canvas has generative power,\nguiding the design of new VA processes and is optimized for external\nstakeholders, improving VA outreach, interdisciplinary collaboration, and\nuser-centered design. The utility of the HDMI Canvas is demonstrated through\ntwo preliminary case studies.",
      "pdf_url": "http://arxiv.org/pdf/2505.07534v1",
      "published": "2025-05-12T13:15:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.07534v1",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "IKrNet: A Neural Network for Detecting Specific Drug-Induced Patterns in Electrocardiograms Amidst Physiological Variability",
      "authors": [
        "Ahmad Fall",
        "Federica Granese",
        "Alex Lence",
        "Dominique Fourer",
        "Blaise Hanczar",
        "Joe-Elie Salem",
        "Jean-Daniel Zucker",
        "Edi Prifti"
      ],
      "abstract": "Monitoring and analyzing electrocardiogram (ECG) signals, even under varying\nphysiological conditions, including those influenced by physical activity,\ndrugs and stress, is crucial to accurately assess cardiac health. However,\ncurrent AI-based methods often fail to account for how these factors interact\nand alter ECG patterns, ultimately limiting their applicability in real-world\nsettings. This study introduces IKrNet, a novel neural network model, which\nidentifies drug-specific patterns in ECGs amidst certain physiological\nconditions. IKrNet's architecture incorporates spatial and temporal dynamics by\nusing a convolutional backbone with varying receptive field size to capture\nspatial features. A bi-directional Long Short-Term Memory module is also\nemployed to model temporal dependencies. By treating heart rate variability as\na surrogate for physiological fluctuations, we evaluated IKrNet's performance\nacross diverse scenarios, including conditions with physical stress, drug\nintake alone, and a baseline without drug presence. Our assessment follows a\nclinical protocol in which 990 healthy volunteers were administered 80mg of\nSotalol, a drug which is known to be a precursor to Torsades-de-Pointes, a\nlife-threatening arrhythmia. We show that IKrNet outperforms state-of-the-art\nmodels' accuracy and stability in varying physiological conditions,\nunderscoring its clinical viability.",
      "pdf_url": "http://arxiv.org/pdf/2505.07533v1",
      "published": "2025-05-12T13:14:47+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.07533v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "QuantX: A Framework for Hardware-Aware Quantization of Generative AI Workloads",
      "authors": [
        "Khurram Mazher",
        "Saad Bin Nasir"
      ],
      "abstract": "We present QuantX: a tailored suite of recipes for LLM and VLM quantization.\nIt is capable of quantizing down to 3-bit resolutions with minimal loss in\nperformance. The quantization strategies in QuantX take into account\nhardware-specific constraints to achieve efficient dequantization during\ninference ensuring flexible trade-off between runtime speed, memory requirement\nand model accuracy. Our results demonstrate that QuantX achieves performance\nwithin 6% of the unquantized model for LlaVa-v1.6 quantized down to 3-bits for\nmultiple end user tasks and outperforms recently published state-of-the-art\nquantization techniques. This manuscript provides insights into the LLM\nquantization process that motivated the range of recipes and options that are\nincorporated in QuantX.",
      "pdf_url": "http://arxiv.org/pdf/2505.07531v1",
      "published": "2025-05-12T13:13:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.07531v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "ToolACE-DEV: Self-Improving Tool Learning via Decomposition and EVolution",
      "authors": [
        "Xu Huang",
        "Weiwen Liu",
        "Xingshan Zeng",
        "Yuefeng Huang",
        "Xinlong Hao",
        "Yuxian Wang",
        "Yirong Zeng",
        "Chuhan Wu",
        "Yasheng Wang",
        "Ruiming Tang",
        "Defu Lian"
      ],
      "abstract": "The tool-using capability of large language models (LLMs) enables them to\naccess up-to-date external information and handle complex tasks. Current\napproaches to enhancing this capability primarily rely on distilling advanced\nmodels by data synthesis. However, this method incurs significant costs\nassociated with advanced model usage and often results in data compatibility\nissues, led by the high discrepancy in the knowledge scope between the advanced\nmodel and the target model. To address these challenges, we propose\nToolACE-DEV, a self-improving framework for tool learning. First, we decompose\nthe tool-learning objective into sub-tasks that enhance basic tool-making and\ntool-using abilities. Then, we introduce a self-evolving paradigm that allows\nlightweight models to self-improve, reducing reliance on advanced LLMs.\nExtensive experiments validate the effectiveness of our approach across models\nof varying scales and architectures.",
      "pdf_url": "http://arxiv.org/pdf/2505.07512v1",
      "published": "2025-05-12T12:48:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.07512v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "MAIS: Memory-Attention for Interactive Segmentation",
      "authors": [
        "Mauricio Orbes-Arteaga",
        "Oeslle Lucena",
        "Sabastien Ourselin",
        "M. Jorge Cardoso"
      ],
      "abstract": "Interactive medical segmentation reduces annotation effort by refining\npredictions through user feedback. Vision Transformer (ViT)-based models, such\nas the Segment Anything Model (SAM), achieve state-of-the-art performance using\nuser clicks and prior masks as prompts. However, existing methods treat\ninteractions as independent events, leading to redundant corrections and\nlimited refinement gains. We address this by introducing MAIS, a\nMemory-Attention mechanism for Interactive Segmentation that stores past user\ninputs and segmentation states, enabling temporal context integration. Our\napproach enhances ViT-based segmentation across diverse imaging modalities,\nachieving more efficient and accurate refinements.",
      "pdf_url": "http://arxiv.org/pdf/2505.07511v1",
      "published": "2025-05-12T12:48:27+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.07511v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "HALO: Half Life-Based Outdated Fact Filtering in Temporal Knowledge Graphs",
      "authors": [
        "Feng Ding",
        "Tingting Wang",
        "Yupeng Gao",
        "Shuo Yu",
        "Jing Ren",
        "Feng Xia"
      ],
      "abstract": "Outdated facts in temporal knowledge graphs (TKGs) result from exceeding the\nexpiration date of facts, which negatively impact reasoning performance on\nTKGs. However, existing reasoning methods primarily focus on positive\nimportance of historical facts, neglecting adverse effects of outdated facts.\nBesides, training on these outdated facts yields extra computational cost. To\naddress these challenges, we propose an outdated fact filtering framework named\nHALO, which quantifies the temporal validity of historical facts by exploring\nthe half-life theory to filter outdated facts in TKGs. HALO consists of three\nmodules: the temporal fact attention module, the dynamic relation-aware encoder\nmodule, and the outdated fact filtering module. Firstly, the temporal fact\nattention module captures the evolution of historical facts over time to\nidentify relevant facts. Secondly, the dynamic relation-aware encoder module is\ndesigned for efficiently predicting the half life of each fact. Finally, we\nconstruct a time decay function based on the half-life theory to quantify the\ntemporal validity of facts and filter outdated facts. Experimental results show\nthat HALO outperforms the state-of-the-art TKG reasoning methods on three\npublic datasets, demonstrating its effectiveness in detecting and filtering\noutdated facts (Codes are available at\nhttps://github.com/yushuowiki/K-Half/tree/main ).",
      "pdf_url": "http://arxiv.org/pdf/2505.07509v1",
      "published": "2025-05-12T12:47:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.07509v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "EAGLE: Contrastive Learning for Efficient Graph Anomaly Detection",
      "authors": [
        "Jing Ren",
        "Mingliang Hou",
        "Zhixuan Liu",
        "Xiaomei Bai"
      ],
      "abstract": "Graph anomaly detection is a popular and vital task in various real-world\nscenarios, which has been studied for several decades. Recently, many studies\nextending deep learning-based methods have shown preferable performance on\ngraph anomaly detection. However, existing methods are lack of efficiency that\nis definitely necessary for embedded devices. Towards this end, we propose an\nEfficient Anomaly detection model on heterogeneous Graphs via contrastive\nLEarning (EAGLE) by contrasting abnormal nodes with normal ones in terms of\ntheir distances to the local context. The proposed method first samples\ninstance pairs on meta path-level for contrastive learning. Then, a graph\nautoencoder-based model is applied to learn informative node embeddings in an\nunsupervised way, which will be further combined with the discriminator to\npredict the anomaly scores of nodes. Experimental results show that EAGLE\noutperforms the state-of-the-art methods on three heterogeneous network\ndatasets.",
      "pdf_url": "http://arxiv.org/pdf/2505.07508v1",
      "published": "2025-05-12T12:45:07+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.07508v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Web-Bench: A LLM Code Benchmark Based on Web Standards and Frameworks",
      "authors": [
        "Kai Xu",
        "YiWei Mao",
        "XinYi Guan",
        "ZiLong Feng"
      ],
      "abstract": "The application of large language models (LLMs) in the field of coding is\nevolving rapidly: from code assistants, to autonomous coding agents, and then\nto generating complete projects through natural language. Early LLM code\nbenchmarks primarily focused on code generation accuracy, but these benchmarks\nhave gradually become saturated. Benchmark saturation weakens their guiding\nrole for LLMs. For example, HumanEval Pass@1 has reached 99.4% and MBPP 94.2%.\nAmong various attempts to address benchmark saturation, approaches based on\nsoftware engineering have stood out, but the saturation of existing software\nengineering benchmarks is rapidly increasing. To address this, we propose a new\nbenchmark, Web-Bench, which contains 50 projects, each consisting of 20 tasks\nwith sequential dependencies. The tasks implement project features in sequence,\nsimulating real-world human development workflows. When designing Web-Bench, we\naim to cover the foundational elements of Web development: Web Standards and\nWeb Frameworks. Given the scale and complexity of these projects, which were\ndesigned by engineers with 5 to 10 years of experience, each presents a\nsignificant challenge. On average, a single project takes 4 to 8 hours for a\nsenior engineer to complete. On our given benchmark agent (Web-Agent), SOTA\n(Claude 3.7 Sonnet) achieves only 25.1% Pass@1, significantly lower (better)\nthan SWE-Bench's Verified (65.4%) and Full (33.8%) scores. Finally, we discuss\nthat in any development field, Standards and Frameworks represent foundational\nknowledge and efficiency tools, respectively, and LLMs require optimization\ntailored to them.",
      "pdf_url": "http://arxiv.org/pdf/2505.07473v1",
      "published": "2025-05-12T12:06:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.07473v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "A Survey on Collaborative Mechanisms Between Large and Small Language Models",
      "authors": [
        "Yi Chen",
        "JiaHao Zhao",
        "HaoHao Han"
      ],
      "abstract": "Large Language Models (LLMs) deliver powerful AI capabilities but face\ndeployment challenges due to high resource costs and latency, whereas Small\nLanguage Models (SLMs) offer efficiency and deployability at the cost of\nreduced performance. Collaboration between LLMs and SLMs emerges as a crucial\nparadigm to synergistically balance these trade-offs, enabling advanced AI\napplications, especially on resource-constrained edge devices. This survey\nprovides a comprehensive overview of LLM-SLM collaboration, detailing various\ninteraction mechanisms (pipeline, routing, auxiliary, distillation, fusion),\nkey enabling technologies, and diverse application scenarios driven by\non-device needs like low latency, privacy, personalization, and offline\noperation. While highlighting the significant potential for creating more\nefficient, adaptable, and accessible AI, we also discuss persistent challenges\nincluding system overhead, inter-model consistency, robust task allocation,\nevaluation complexity, and security/privacy concerns. Future directions point\ntowards more intelligent adaptive frameworks, deeper model fusion, and\nexpansion into multimodal and embodied AI, positioning LLM-SLM collaboration as\na key driver for the next generation of practical and ubiquitous artificial\nintelligence.",
      "pdf_url": "http://arxiv.org/pdf/2505.07460v1",
      "published": "2025-05-12T11:48:42+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.07460v1",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Can Generative AI agents behave like humans? Evidence from laboratory market experiments",
      "authors": [
        "R. Maria del Rio-Chanona",
        "Marco Pangallo",
        "Cars Hommes"
      ],
      "abstract": "We explore the potential of Large Language Models (LLMs) to replicate human\nbehavior in economic market experiments. Compared to previous studies, we focus\non dynamic feedback between LLM agents: the decisions of each LLM impact the\nmarket price at the current step, and so affect the decisions of the other LLMs\nat the next step. We compare LLM behavior to market dynamics observed in\nlaboratory settings and assess their alignment with human participants'\nbehavior. Our findings indicate that LLMs do not adhere strictly to rational\nexpectations, displaying instead bounded rationality, similarly to human\nparticipants. Providing a minimal context window i.e. memory of three previous\ntime steps, combined with a high variability setting capturing response\nheterogeneity, allows LLMs to replicate broad trends seen in human experiments,\nsuch as the distinction between positive and negative feedback markets.\nHowever, differences remain at a granular level--LLMs exhibit less\nheterogeneity in behavior than humans. These results suggest that LLMs hold\npromise as tools for simulating realistic human behavior in economic contexts,\nthough further research is needed to refine their accuracy and increase\nbehavioral diversity.",
      "pdf_url": "http://arxiv.org/pdf/2505.07457v1",
      "published": "2025-05-12T11:44:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.07457v1",
      "categories": [
        "econ.GN",
        "cs.AI",
        "q-fin.EC"
      ]
    }
  ]
}