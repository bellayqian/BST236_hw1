{
  "last_updated": "2025-10-26T00:53:56.038268",
  "papers": [
    {
      "title": "Towards General Modality Translation with Contrastive and Predictive Latent Diffusion Bridge",
      "authors": [
        "Nimrod Berman",
        "Omkar Joglekar",
        "Eitan Kosman",
        "Dotan Di Castro",
        "Omri Azencot"
      ],
      "abstract": "Recent advances in generative modeling have positioned diffusion models as\nstate-of-the-art tools for sampling from complex data distributions. While\nthese models have shown remarkable success across single-modality domains such\nas images and audio, extending their capabilities to Modality Translation (MT),\ntranslating information across different sensory modalities, remains an open\nchallenge. Existing approaches often rely on restrictive assumptions, including\nshared dimensionality, Gaussian source priors, and modality-specific\narchitectures, which limit their generality and theoretical grounding. In this\nwork, we propose the Latent Denoising Diffusion Bridge Model (LDDBM), a\ngeneral-purpose framework for modality translation based on a latent-variable\nextension of Denoising Diffusion Bridge Models. By operating in a shared latent\nspace, our method learns a bridge between arbitrary modalities without\nrequiring aligned dimensions. We introduce a contrastive alignment loss to\nenforce semantic consistency between paired samples and design a\ndomain-agnostic encoder-decoder architecture tailored for noise prediction in\nlatent space. Additionally, we propose a predictive loss to guide training\ntoward accurate cross-domain translation and explore several training\nstrategies to improve stability. Our approach supports arbitrary modality pairs\nand performs strongly on diverse MT tasks, including multi-view to 3D shape\ngeneration, image super-resolution, and multi-view scene synthesis.\nComprehensive experiments and ablations validate the effectiveness of our\nframework, establishing a new strong baseline in general modality translation.\nFor more information, see our project page:\nhttps://sites.google.com/view/lddbm/home.",
      "pdf_url": "http://arxiv.org/pdf/2510.20819v1",
      "published": "2025-10-23T17:59:54+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.20819v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "VAMOS: A Hierarchical Vision-Language-Action Model for Capability-Modulated and Steerable Navigation",
      "authors": [
        "Mateo Guaman Castro",
        "Sidharth Rajagopal",
        "Daniel Gorbatov",
        "Matt Schmittle",
        "Rohan Baijal",
        "Octi Zhang",
        "Rosario Scalise",
        "Sidharth Talia",
        "Emma Romig",
        "Celso de Melo",
        "Byron Boots",
        "Abhishek Gupta"
      ],
      "abstract": "A fundamental challenge in robot navigation lies in learning policies that\ngeneralize across diverse environments while conforming to the unique physical\nconstraints and capabilities of a specific embodiment (e.g., quadrupeds can\nwalk up stairs, but rovers cannot). We propose VAMOS, a hierarchical VLA that\ndecouples semantic planning from embodiment grounding: a generalist planner\nlearns from diverse, open-world data, while a specialist affordance model\nlearns the robot's physical constraints and capabilities in safe, low-cost\nsimulation. We enabled this separation by carefully designing an interface that\nlets a high-level planner propose candidate paths directly in image space that\nthe affordance model then evaluates and re-ranks. Our real-world experiments\nshow that VAMOS achieves higher success rates in both indoor and complex\noutdoor navigation than state-of-the-art model-based and end-to-end learning\nmethods. We also show that our hierarchical design enables cross-embodied\nnavigation across legged and wheeled robots and is easily steerable using\nnatural language. Real-world ablations confirm that the specialist model is key\nto embodiment grounding, enabling a single high-level planner to be deployed\nacross physically distinct wheeled and legged robots. Finally, this model\nsignificantly enhances single-robot reliability, achieving 3X higher success\nrates by rejecting physically infeasible plans. Website:\nhttps://vamos-vla.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2510.20818v1",
      "published": "2025-10-23T17:59:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.20818v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "GSWorld: Closed-Loop Photo-Realistic Simulation Suite for Robotic Manipulation",
      "authors": [
        "Guangqi Jiang",
        "Haoran Chang",
        "Ri-Zhao Qiu",
        "Yutong Liang",
        "Mazeyu Ji",
        "Jiyue Zhu",
        "Zhao Dong",
        "Xueyan Zou",
        "Xiaolong Wang"
      ],
      "abstract": "This paper presents GSWorld, a robust, photo-realistic simulator for robotics\nmanipulation that combines 3D Gaussian Splatting with physics engines. Our\nframework advocates \"closing the loop\" of developing manipulation policies with\nreproducible evaluation of policies learned from real-robot data and sim2real\npolicy training without using real robots. To enable photo-realistic rendering\nof diverse scenes, we propose a new asset format, which we term GSDF (Gaussian\nScene Description File), that infuses Gaussian-on-Mesh representation with\nrobot URDF and other objects. With a streamlined reconstruction pipeline, we\ncurate a database of GSDF that contains 3 robot embodiments for single-arm and\nbimanual manipulation, as well as more than 40 objects. Combining GSDF with\nphysics engines, we demonstrate several immediate interesting applications: (1)\nlearning zero-shot sim2real pixel-to-action manipulation policy with\nphoto-realistic rendering, (2) automated high-quality DAgger data collection\nfor adapting policies to deployment environments, (3) reproducible benchmarking\nof real-robot manipulation policies in simulation, (4) simulation data\ncollection by virtual teleoperation, and (5) zero-shot sim2real visual\nreinforcement learning. Website: https://3dgsworld.github.io/.",
      "pdf_url": "http://arxiv.org/pdf/2510.20813v1",
      "published": "2025-10-23T17:59:26+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.20813v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Small Drafts, Big Verdict: Information-Intensive Visual Reasoning via Speculation",
      "authors": [
        "Yuhan Liu",
        "Lianhui Qin",
        "Shengjie Wang"
      ],
      "abstract": "Large Vision-Language Models (VLMs) have achieved remarkable progress in\nmultimodal understanding, yet they struggle when reasoning over\ninformation-intensive images that densely interleave textual annotations with\nfine-grained graphical elements. The main challenges lie in precisely\nlocalizing critical cues in dense layouts and multi-hop reasoning to integrate\ndispersed evidence. We propose Speculative Verdict (SV), a training-free\nframework inspired by speculative decoding that combines multiple lightweight\ndraft experts with a large verdict model. In the draft stage, small VLMs act as\ndraft experts to generate reasoning paths that provide diverse localization\ncandidates; in the verdict stage, a strong VLM synthesizes these paths to\nproduce the final answer, minimizing computational cost while recovering\ncorrect answers. To further improve efficiency and accuracy, SV introduces a\nconsensus expert selection mechanism that forwards only high-agreement\nreasoning paths to the verdict. Empirically, SV achieves consistent gains on\nchallenging information-intensive and high-resolution visual question answering\nbenchmarks, including InfographicVQA, ChartMuseum, ChartQAPro, and HR-Bench 4K.\nBy synthesizing correct insights from multiple partially accurate reasoning\npaths, SV achieves both error correction and cost-efficiency compared to large\nproprietary models or training pipelines. Code is available at\nhttps://github.com/Tinaliu0123/speculative-verdict",
      "pdf_url": "http://arxiv.org/pdf/2510.20812v1",
      "published": "2025-10-23T17:59:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.20812v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "On the Detectability of LLM-Generated Text: What Exactly Is LLM-Generated Text?",
      "authors": [
        "Mingmeng Geng",
        "Thierry Poibeau"
      ],
      "abstract": "With the widespread use of large language models (LLMs), many researchers\nhave turned their attention to detecting text generated by them. However, there\nis no consistent or precise definition of their target, namely \"LLM-generated\ntext\". Differences in usage scenarios and the diversity of LLMs further\nincrease the difficulty of detection. What is commonly regarded as the\ndetecting target usually represents only a subset of the text that LLMs can\npotentially produce. Human edits to LLM outputs, together with the subtle\ninfluences that LLMs exert on their users, are blurring the line between\nLLM-generated and human-written text. Existing benchmarks and evaluation\napproaches do not adequately address the various conditions in real-world\ndetector applications. Hence, the numerical results of detectors are often\nmisunderstood, and their significance is diminishing. Therefore, detectors\nremain useful under specific conditions, but their results should be\ninterpreted only as references rather than decisive indicators.",
      "pdf_url": "http://arxiv.org/pdf/2510.20810v1",
      "published": "2025-10-23T17:59:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.20810v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ]
    },
    {
      "title": "Real Deep Research for AI, Robotics and Beyond",
      "authors": [
        "Xueyan Zou",
        "Jianglong Ye",
        "Hao Zhang",
        "Xiaoyu Xiang",
        "Mingyu Ding",
        "Zhaojing Yang",
        "Yong Jae Lee",
        "Zhuowen Tu",
        "Sifei Liu",
        "Xiaolong Wang"
      ],
      "abstract": "With the rapid growth of research in AI and robotics now producing over\n10,000 papers annually it has become increasingly difficult for researchers to\nstay up to date. Fast evolving trends, the rise of interdisciplinary work, and\nthe need to explore domains beyond one's expertise all contribute to this\nchallenge. To address these issues, we propose a generalizable pipeline capable\nof systematically analyzing any research area: identifying emerging trends,\nuncovering cross domain opportunities, and offering concrete starting points\nfor new inquiry. In this work, we present Real Deep Research (RDR) a\ncomprehensive framework applied to the domains of AI and robotics, with a\nparticular focus on foundation models and robotics advancements. We also\nbriefly extend our analysis to other areas of science. The main paper details\nthe construction of the RDR pipeline, while the appendix provides extensive\nresults across each analyzed topic. We hope this work sheds light for\nresearchers working in the field of AI and beyond.",
      "pdf_url": "http://arxiv.org/pdf/2510.20809v1",
      "published": "2025-10-23T17:59:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.20809v1",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG"
      ]
    },
    {
      "title": "The Reality Gap in Robotics: Challenges, Solutions, and Best Practices",
      "authors": [
        "Elie Aljalbout",
        "Jiaxu Xing",
        "Angel Romero",
        "Iretiayo Akinola",
        "Caelan Reed Garrett",
        "Eric Heiden",
        "Abhishek Gupta",
        "Tucker Hermans",
        "Yashraj Narang",
        "Dieter Fox",
        "Davide Scaramuzza",
        "Fabio Ramos"
      ],
      "abstract": "Machine learning has facilitated significant advancements across various\nrobotics domains, including navigation, locomotion, and manipulation. Many such\nachievements have been driven by the extensive use of simulation as a critical\ntool for training and testing robotic systems prior to their deployment in\nreal-world environments. However, simulations consist of abstractions and\napproximations that inevitably introduce discrepancies between simulated and\nreal environments, known as the reality gap. These discrepancies significantly\nhinder the successful transfer of systems from simulation to the real world.\nClosing this gap remains one of the most pressing challenges in robotics.\nRecent advances in sim-to-real transfer have demonstrated promising results\nacross various platforms, including locomotion, navigation, and manipulation.\nBy leveraging techniques such as domain randomization, real-to-sim transfer,\nstate and action abstractions, and sim-real co-training, many works have\novercome the reality gap. However, challenges persist, and a deeper\nunderstanding of the reality gap's root causes and solutions is necessary. In\nthis survey, we present a comprehensive overview of the sim-to-real landscape,\nhighlighting the causes, solutions, and evaluation metrics for the reality gap\nand sim-to-real transfer.",
      "pdf_url": "http://arxiv.org/pdf/2510.20808v1",
      "published": "2025-10-23T17:58:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.20808v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "stat.ML",
        "I.2.6; I.2.8; I.2.9"
      ]
    },
    {
      "title": "Compress to Impress: Efficient LLM Adaptation Using a Single Gradient Step on 100 Samples",
      "authors": [
        "Shiva Sreeram",
        "Alaa Maalouf",
        "Pratyusha Sharma",
        "Daniela Rus"
      ],
      "abstract": "Recently, Sharma et al. suggested a method called Layer-SElective-Rank\nreduction (LASER) which demonstrated that pruning high-order components of\ncarefully chosen LLM's weight matrices can boost downstream accuracy -- without\nany gradient-based fine-tuning. Yet LASER's exhaustive, per-matrix search (each\nrequiring full-dataset forward passes) makes it impractical for rapid\ndeployment. We demonstrate that this overhead can be removed and find that: (i)\nOnly a small, carefully chosen subset of matrices needs to be inspected --\neliminating the layer-by-layer sweep, (ii) The gradient of each matrix's\nsingular values pinpoints which matrices merit reduction, (iii) Increasing the\nfactorization search space by allowing matrices rows to cluster around multiple\nsubspaces and then decomposing each cluster separately further reduces\noverfitting on the original training data and further lifts accuracy by up to\n24.6 percentage points, and finally, (iv) we discover that evaluating on just\n100 samples rather than the full training data -- both for computing the\nindicative gradients and for measuring the final accuracy -- suffices to\nfurther reduce the search time; we explain that as adaptation to downstream\ntasks is dominated by prompting style, not dataset size. As a result, we show\nthat combining these findings yields a fast and robust adaptation algorithm for\ndownstream tasks. Overall, with a single gradient step on 100 examples and a\nquick scan of the top candidate layers and factorization techniques, we can\nadapt LLMs to new datasets -- entirely without fine-tuning.",
      "pdf_url": "http://arxiv.org/pdf/2510.20800v1",
      "published": "2025-10-23T17:58:01+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.20800v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ]
    },
    {
      "title": "Simple Context Compression: Mean-Pooling and Multi-Ratio Training",
      "authors": [
        "Yair Feldman",
        "Yoav Artzi"
      ],
      "abstract": "A common strategy to reduce the computational costs of using long contexts in\nretrieval-augmented generation (RAG) with large language models (LLMs) is soft\ncontext compression, where the input sequence is transformed into a shorter\ncontinuous representation. We develop a lightweight and simple mean-pooling\napproach that consistently outperforms the widely used compression-tokens\narchitecture, and study training the same compressor to output multiple\ncompression ratios. We conduct extensive experiments across in-domain and\nout-of-domain QA datasets, as well as across model families, scales, and\ncompression ratios. Overall, our simple mean-pooling approach achieves the\nstrongest performance, with a relatively small drop when training for multiple\ncompression ratios. More broadly though, across architectures and training\nregimes the trade-offs are more nuanced, illustrating the complex landscape of\ncompression methods.",
      "pdf_url": "http://arxiv.org/pdf/2510.20797v1",
      "published": "2025-10-23T17:57:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.20797v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Bayesian Inference of Primordial Magnetic Field Parameters from CMB with Spherical Graph Neural Networks",
      "authors": [
        "Juan Alejandro Pinto Castro",
        "Héctor J. Hortúa",
        "Jorge Enrique García-Farieta",
        "Roger Anderson Hurtado"
      ],
      "abstract": "Deep learning has emerged as a transformative methodology in modern\ncosmology, providing powerful tools to extract meaningful physical information\nfrom complex astronomical datasets. This paper implements a novel Bayesian\ngraph deep learning framework for estimating key cosmological parameters in a\nprimordial magnetic field (PMF) cosmology directly from simulated Cosmic\nMicrowave Background (CMB) maps. Our methodology utilizes DeepSphere, a\nspherical convolutional neural network architecture specifically designed to\nrespect the spherical geometry of CMB data through HEALPix pixelization. To\nadvance beyond deterministic point estimates and enable robust uncertainty\nquantification, we integrate Bayesian Neural Networks (BNNs) into the\nframework, capturing aleatoric and epistemic uncertainties that reflect the\nmodel confidence in its predictions. The proposed approach demonstrates\nexceptional performance, achieving $R^{2}$ scores exceeding 0.89 for the\nmagnetic parameter estimation. We further obtain well-calibrated uncertainty\nestimates through post-hoc training techniques including Variance Scaling and\nGPNormal. This integrated DeepSphere-BNNs framework not only delivers accurate\nparameter estimation from CMB maps with PMF contributions but also provides\nreliable uncertainty quantification, providing the necessary tools for robust\ncosmological inference in the era of precision cosmology.",
      "pdf_url": "http://arxiv.org/pdf/2510.20795v1",
      "published": "2025-10-23T17:56:04+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.20795v1",
      "categories": [
        "astro-ph.CO",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "A Coherence-Based Measure of AGI",
      "authors": [
        "Fares Fourati"
      ],
      "abstract": "Recent work by \\citet{hendrycks2025agidefinition} formalized\n\\textit{Artificial General Intelligence} (AGI) as the arithmetic mean of\nproficiencies across cognitive domains derived from the Cattell--Horn--Carroll\n(CHC) model of human cognition. While elegant, this definition assumes\n\\textit{compensability} -- that exceptional ability in some domains can offset\nfailure in others. True general intelligence, however, should reflect\n\\textit{coherent sufficiency}: balanced competence across all essential\ndomains. We propose a coherence-aware measure of AGI based on the integral of\ngeneralized means over a continuum of compensability exponents. This\nformulation spans arithmetic, geometric, and harmonic regimes, and the\nresulting \\textit{area under the curve} (AUC) quantifies robustness under\nvarying compensability assumptions. Unlike the arithmetic mean, which rewards\nspecialization, the AUC penalizes imbalance and captures inter-domain\ndependency. Applied to published CHC-based domain scores for GPT-4 and GPT-5,\nthe coherence-adjusted AUC reveals that both systems remain far from general\ncompetence despite high arithmetic scores (e.g., GPT-5 at~24\\%). Integrating\nthe generalized mean thus yields a principled, interpretable, and stricter\nfoundation for measuring genuine progress toward AGI.",
      "pdf_url": "http://arxiv.org/pdf/2510.20784v1",
      "published": "2025-10-23T17:51:42+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.20784v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "A Use-Case Specific Dataset for Measuring Dimensions of Responsible Performance in LLM-generated Text",
      "authors": [
        "Alicia Sagae",
        "Chia-Jung Lee",
        "Sandeep Avula",
        "Brandon Dang",
        "Vanessa Murdock"
      ],
      "abstract": "Current methods for evaluating large language models (LLMs) typically focus\non high-level tasks such as text generation, without targeting a particular AI\napplication. This approach is not sufficient for evaluating LLMs for\nResponsible AI dimensions like fairness, since protected attributes that are\nhighly relevant in one application may be less relevant in another. In this\nwork, we construct a dataset that is driven by a real-world application\n(generate a plain-text product description, given a list of product features),\nparameterized by fairness attributes intersected with gendered adjectives and\nproduct categories, yielding a rich set of labeled prompts. We show how to use\nthe data to identify quality, veracity, safety, and fairness gaps in LLMs,\ncontributing a proposal for LLM evaluation paired with a concrete resource for\nthe research community.",
      "pdf_url": "http://arxiv.org/pdf/2510.20782v1",
      "published": "2025-10-23T17:50:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.20782v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ]
    },
    {
      "title": "Are Large Reasoning Models Good Translation Evaluators? Analysis and Performance Boost",
      "authors": [
        "Runzhe Zhan",
        "Zhihong Huang",
        "Xinyi Yang",
        "Lidia S. Chao",
        "Min Yang",
        "Derek F. Wong"
      ],
      "abstract": "Recent advancements in large reasoning models (LRMs) have introduced an\nintermediate \"thinking\" process prior to generating final answers, improving\ntheir reasoning capabilities on complex downstream tasks. However, the\npotential of LRMs as evaluators for machine translation (MT) quality remains\nunderexplored. We provides the first systematic analysis of LRM-as-a-judge in\nMT evaluation. We identify key challenges, revealing LRMs require tailored\nevaluation materials, tend to \"overthink\" simpler instances and have issues\nwith scoring mechanisms leading to overestimation. To address these, we propose\nto calibrate LRM thinking by training them on synthetic, human-like thinking\ntrajectories. Our experiments on WMT24 Metrics benchmarks demonstrate that this\napproach largely reduces thinking budgets by ~35x while concurrently improving\nevaluation performance across different LRM scales from 7B to 32B (e.g.,\nR1-Distill-Qwen-7B achieves a +8.7 correlation point improvement). These\nfindings highlight the potential of efficiently calibrated LRMs to advance\nfine-grained automatic MT evaluation.",
      "pdf_url": "http://arxiv.org/pdf/2510.20780v1",
      "published": "2025-10-23T17:48:36+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.20780v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "FieldGen: From Teleoperated Pre-Manipulation Trajectories to Field-Guided Data Generation",
      "authors": [
        "Wenhao Wang",
        "Kehe Ye",
        "Xinyu Zhou",
        "Tianxing Chen",
        "Cao Min",
        "Qiaoming Zhu",
        "Xiaokang Yang",
        "Yongjian Shen",
        "Yang Yang",
        "Maoqing Yao",
        "Yao Mu"
      ],
      "abstract": "Large-scale and diverse datasets are vital for training robust robotic\nmanipulation policies, yet existing data collection methods struggle to balance\nscale, diversity, and quality. Simulation offers scalability but suffers from\nsim-to-real gaps, while teleoperation yields high-quality demonstrations with\nlimited diversity and high labor cost. We introduce FieldGen, a field-guided\ndata generation framework that enables scalable, diverse, and high-quality\nreal-world data collection with minimal human supervision. FieldGen decomposes\nmanipulation into two stages: a pre-manipulation phase, allowing trajectory\ndiversity, and a fine manipulation phase requiring expert precision. Human\ndemonstrations capture key contact and pose information, after which an\nattraction field automatically generates diverse trajectories converging to\nsuccessful configurations. This decoupled design combines scalable trajectory\ndiversity with precise supervision. Moreover, FieldGen-Reward augments\ngenerated data with reward annotations to further enhance policy learning.\nExperiments demonstrate that policies trained with FieldGen achieve higher\nsuccess rates and improved stability compared to teleoperation-based baselines,\nwhile significantly reducing human effort in long-term real-world data\ncollection. Webpage is available at https://fieldgen.github.io/.",
      "pdf_url": "http://arxiv.org/pdf/2510.20774v1",
      "published": "2025-10-23T17:47:12+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.20774v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.HC"
      ]
    },
    {
      "title": "RAGRank: Using PageRank to Counter Poisoning in CTI LLM Pipelines",
      "authors": [
        "Austin Jia",
        "Avaneesh Ramesh",
        "Zain Shamsi",
        "Daniel Zhang",
        "Alex Liu"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) has emerged as the dominant\narchitectural pattern to operationalize Large Language Model (LLM) usage in\nCyber Threat Intelligence (CTI) systems. However, this design is susceptible to\npoisoning attacks, and previously proposed defenses can fail for CTI contexts\nas cyber threat information is often completely new for emerging attacks, and\nsophisticated threat actors can mimic legitimate formats, terminology, and\nstylistic conventions. To address this issue, we propose that the robustness of\nmodern RAG defenses can be accelerated by applying source credibility\nalgorithms on corpora, using PageRank as an example. In our experiments, we\ndemonstrate quantitatively that our algorithm applies a lower authority score\nto malicious documents while promoting trusted content, using the standardized\nMS MARCO dataset. We also demonstrate proof-of-concept performance of our\nalgorithm on CTI documents and feeds.",
      "pdf_url": "http://arxiv.org/pdf/2510.20768v1",
      "published": "2025-10-23T17:43:00+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.20768v1",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.IR"
      ]
    },
    {
      "title": "Reinforcement Learning and Consumption-Savings Behavior",
      "authors": [
        "Brandon Kaplowitz"
      ],
      "abstract": "This paper demonstrates how reinforcement learning can explain two puzzling\nempirical patterns in household consumption behavior during economic downturns.\nI develop a model where agents use Q-learning with neural network approximation\nto make consumption-savings decisions under income uncertainty, departing from\nstandard rational expectations assumptions. The model replicates two key\nfindings from recent literature: (1) unemployed households with previously low\nliquid assets exhibit substantially higher marginal propensities to consume\n(MPCs) out of stimulus transfers compared to high-asset households (0.50 vs\n0.34), even when neither group faces borrowing constraints, consistent with\nGanong et al. (2024); and (2) households with more past unemployment\nexperiences maintain persistently lower consumption levels after controlling\nfor current economic conditions, a \"scarring\" effect documented by Malmendier\nand Shen (2024). Unlike existing explanations based on belief updating about\nincome risk or ex-ante heterogeneity, the reinforcement learning mechanism\ngenerates both higher MPCs and lower consumption levels simultaneously through\nvalue function approximation errors that evolve with experience. Simulation\nresults closely match the empirical estimates, suggesting that adaptive\nlearning through reinforcement learning provides a unifying framework for\nunderstanding how past experiences shape current consumption behavior beyond\nwhat current economic conditions would predict.",
      "pdf_url": "http://arxiv.org/pdf/2510.20748v1",
      "published": "2025-10-23T17:14:49+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.20748v1",
      "categories": [
        "econ.GN",
        "cs.AI",
        "cs.LG",
        "q-fin.EC"
      ]
    },
    {
      "title": "Empathic Prompting: Non-Verbal Context Integration for Multimodal LLM Conversations",
      "authors": [
        "Lorenzo Stacchio",
        "Andrea Ubaldi",
        "Alessandro Galdelli",
        "Maurizio Mauri",
        "Emanuele Frontoni",
        "Andrea Gaggioli"
      ],
      "abstract": "We present Empathic Prompting, a novel framework for multimodal human-AI\ninteraction that enriches Large Language Model (LLM) conversations with\nimplicit non-verbal context. The system integrates a commercial facial\nexpression recognition service to capture users' emotional cues and embeds them\nas contextual signals during prompting. Unlike traditional multimodal\ninterfaces, empathic prompting requires no explicit user control; instead, it\nunobtrusively augments textual input with affective information for\nconversational and smoothness alignment. The architecture is modular and\nscalable, allowing integration of additional non-verbal modules. We describe\nthe system design, implemented through a locally deployed DeepSeek instance,\nand report a preliminary service and usability evaluation (N=5). Results show\nconsistent integration of non-verbal input into coherent LLM outputs, with\nparticipants highlighting conversational fluidity. Beyond this proof of\nconcept, empathic prompting points to applications in chatbot-mediated\ncommunication, particularly in domains like healthcare or education, where\nusers' emotional signals are critical yet often opaque in verbal exchanges.",
      "pdf_url": "http://arxiv.org/pdf/2510.20743v1",
      "published": "2025-10-23T17:08:03+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.20743v1",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Thought Communication in Multiagent Collaboration",
      "authors": [
        "Yujia Zheng",
        "Zhuokai Zhao",
        "Zijian Li",
        "Yaqi Xie",
        "Mingze Gao",
        "Lizhu Zhang",
        "Kun Zhang"
      ],
      "abstract": "Natural language has long enabled human cooperation, but its lossy,\nambiguous, and indirect nature limits the potential of collective intelligence.\nWhile machines are not subject to these constraints, most LLM-based multi-agent\nsystems still rely solely on natural language, exchanging tokens or their\nembeddings. To go beyond language, we introduce a new paradigm, thought\ncommunication, which enables agents to interact directly mind-to-mind, akin to\ntelepathy. To uncover these latent thoughts in a principled way, we formalize\nthe process as a general latent variable model, where agent states are\ngenerated by an unknown function of underlying thoughts. We prove that, in a\nnonparametric setting without auxiliary information, both shared and private\nlatent thoughts between any pair of agents can be identified. Moreover, the\nglobal structure of thought sharing, including which agents share which\nthoughts and how these relationships are structured, can also be recovered with\ntheoretical guarantees. Guided by the established theory, we develop a\nframework that extracts latent thoughts from all agents prior to communication\nand assigns each agent the relevant thoughts, along with their sharing\npatterns. This paradigm naturally extends beyond LLMs to all modalities, as\nmost observational data arise from hidden generative processes. Experiments on\nboth synthetic and real-world benchmarks validate the theory and demonstrate\nthe collaborative advantages of thought communication. We hope this work\nilluminates the potential of leveraging the hidden world, as many challenges\nremain unsolvable through surface-level observation alone, regardless of\ncompute or data scale.",
      "pdf_url": "http://arxiv.org/pdf/2510.20733v1",
      "published": "2025-10-23T16:48:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.20733v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ]
    },
    {
      "title": "Co-Designing Quantum Codes with Transversal Diagonal Gates via Multi-Agent Systems",
      "authors": [
        "Xi He",
        "Sirui Lu",
        "Bei Zeng"
      ],
      "abstract": "We present a multi-agent, human-in-the-loop workflow that co-designs quantum\ncodes with prescribed transversal diagonal gates. It builds on the Subset-Sum\nLinear Programming (SSLP) framework (arXiv:2504.20847), which partitions basis\nstrings by modular residues and enforces $Z$-marginal Knill-Laflamme (KL)\nequalities via small LPs. The workflow is powered by GPT-5 and implemented\nwithin TeXRA (https://texra.ai)-a multi-agent research assistant platform that\nsupports an iterative tool-use loop agent and a derivation-then-edit workflow\nreasoning agent. We work in a LaTeX-Python environment where agents reason,\nedit documents, execute code, and synchronize their work to Git/Overleaf.\nWithin this workspace, three roles collaborate: a Synthesis Agent formulates\nthe problem; a Search Agent sweeps/screens candidates and exactifies numerics\ninto rationals; and an Audit Agent independently checks all KL equalities and\nthe induced logical action. As a first step we focus on distance $d=2$ with\nnondegenerate residues. For code dimension $K\\in\\{2,3,4\\}$ and $n\\le6$ qubits,\nsystematic sweeps yield certificate-backed tables cataloging attainable cyclic\nlogical groups-all realized by new codes-e.g., for $K=3$ we obtain order $16$\nat $n=6$. From verified instances, Synthesis Agent abstracts recurring\nstructures into closed-form families and proves they satisfy the KL equalities\nfor all parameters. It further demonstrates that SSLP accommodates residue\ndegeneracy by exhibiting a new $((6,4,2))$ code implementing the transversal\ncontrolled-phase $diag(1,1,1,i)$. Overall, the workflow recasts\ndiagonal-transversal feasibility as an analytical pipeline executed at scale,\ncombining systematic enumeration with exact analytical reconstruction. It\nyields reproducible code constructions, supports targeted extensions to larger\n$K$ and higher distances, and leads toward data-driven classification.",
      "pdf_url": "http://arxiv.org/pdf/2510.20728v1",
      "published": "2025-10-23T16:45:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.20728v1",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.CL",
        "math-ph",
        "math.MP"
      ]
    },
    {
      "title": "Automated Extraction of Fluoropyrimidine Treatment and Treatment-Related Toxicities from Clinical Notes Using Natural Language Processing",
      "authors": [
        "Xizhi Wu",
        "Madeline S. Kreider",
        "Philip E. Empey",
        "Chenyu Li",
        "Yanshan Wang"
      ],
      "abstract": "Objective: Fluoropyrimidines are widely prescribed for colorectal and breast\ncancers, but are associated with toxicities such as hand-foot syndrome and\ncardiotoxicity. Since toxicity documentation is often embedded in clinical\nnotes, we aimed to develop and evaluate natural language processing (NLP)\nmethods to extract treatment and toxicity information.\n  Materials and Methods: We constructed a gold-standard dataset of 236 clinical\nnotes from 204,165 adult oncology patients. Domain experts annotated categories\nrelated to treatment regimens and toxicities. We developed rule-based, machine\nlearning-based (Random Forest, Support Vector Machine [SVM], Logistic\nRegression [LR]), deep learning-based (BERT, ClinicalBERT), and large language\nmodels (LLM)-based NLP approaches (zero-shot and error-analysis prompting).\nModels used an 80:20 train-test split.\n  Results: Sufficient data existed to train and evaluate 5 annotated\ncategories. Error-analysis prompting achieved optimal precision, recall, and F1\nscores (F1=1.000) for treatment and toxicities extraction, whereas zero-shot\nprompting reached F1=1.000 for treatment and F1=0.876 for toxicities\nextraction.LR and SVM ranked second for toxicities (F1=0.937). Deep learning\nunderperformed, with BERT (F1=0.873 treatment; F1= 0.839 toxicities) and\nClinicalBERT (F1=0.873 treatment; F1 = 0.886 toxicities). Rule-based methods\nserved as our baseline with F1 scores of 0.857 in treatment and 0.858 in\ntoxicities.\n  Discussion: LMM-based approaches outperformed all others, followed by machine\nlearning methods. Machine and deep learning approaches were limited by small\ntraining data and showed limited generalizability, particularly for rare\ncategories.\n  Conclusion: LLM-based NLP most effectively extracted fluoropyrimidine\ntreatment and toxicity information from clinical notes, and has strong\npotential to support oncology research and pharmacovigilance.",
      "pdf_url": "http://arxiv.org/pdf/2510.20727v1",
      "published": "2025-10-23T16:44:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.20727v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "User Perceptions of Privacy and Helpfulness in LLM Responses to Privacy-Sensitive Scenarios",
      "authors": [
        "Xiaoyuan Wu",
        "Roshni Kaushik",
        "Wenkai Li",
        "Lujo Bauer",
        "Koichi Onoue"
      ],
      "abstract": "Large language models (LLMs) have seen rapid adoption for tasks such as\ndrafting emails, summarizing meetings, and answering health questions. In such\nuses, users may need to share private information (e.g., health records,\ncontact details). To evaluate LLMs' ability to identify and redact such private\ninformation, prior work developed benchmarks (e.g., ConfAIde, PrivacyLens) with\nreal-life scenarios. Using these benchmarks, researchers have found that LLMs\nsometimes fail to keep secrets private when responding to complex tasks (e.g.,\nleaking employee salaries in meeting summaries). However, these evaluations\nrely on LLMs (proxy LLMs) to gauge compliance with privacy norms, overlooking\nreal users' perceptions. Moreover, prior work primarily focused on the\nprivacy-preservation quality of responses, without investigating nuanced\ndifferences in helpfulness. To understand how users perceive the\nprivacy-preservation quality and helpfulness of LLM responses to\nprivacy-sensitive scenarios, we conducted a user study with 94 participants\nusing 90 scenarios from PrivacyLens. We found that, when evaluating identical\nresponses to the same scenario, users showed low agreement with each other on\nthe privacy-preservation quality and helpfulness of the LLM response. Further,\nwe found high agreement among five proxy LLMs, while each individual LLM had\nlow correlation with users' evaluations. These results indicate that the\nprivacy and helpfulness of LLM responses are often specific to individuals, and\nproxy LLMs are poor estimates of how real users would perceive these responses\nin privacy-sensitive scenarios. Our results suggest the need to conduct\nuser-centered studies on measuring LLMs' ability to help users while preserving\nprivacy. Additionally, future research could investigate ways to improve the\nalignment between proxy LLMs and users for better estimation of users'\nperceived privacy and utility.",
      "pdf_url": "http://arxiv.org/pdf/2510.20721v1",
      "published": "2025-10-23T16:38:26+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.20721v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ]
    },
    {
      "title": "Unsupervised Anomaly Prediction with N-BEATS and Graph Neural Network in Multi-variate Semiconductor Process Time Series",
      "authors": [
        "Daniel Sorensen",
        "Bappaditya Dey",
        "Minjin Hwang",
        "Sandip Halder"
      ],
      "abstract": "Semiconductor manufacturing is an extremely complex and precision-driven\nprocess, characterized by thousands of interdependent parameters collected\nacross diverse tools and process steps. Multi-variate time-series analysis has\nemerged as a critical field for real-time monitoring and fault detection in\nsuch environments. However, anomaly prediction in semiconductor fabrication\npresents several critical challenges, including high dimensionality of sensor\ndata and severe class imbalance due to the rarity of true faults. Furthermore,\nthe complex interdependencies between variables complicate both anomaly\nprediction and root-cause-analysis. This paper proposes two novel approaches to\nadvance the field from anomaly detection to anomaly prediction, an essential\nstep toward enabling real-time process correction and proactive fault\nprevention. The proposed anomaly prediction framework contains two main stages:\n(a) training a forecasting model on a dataset assumed to contain no anomalies,\nand (b) performing forecast on unseen time series data. The forecast is\ncompared with the forecast of the trained signal. Deviations beyond a\npredefined threshold are flagged as anomalies. The two approaches differ in the\nforecasting model employed. The first assumes independence between variables by\nutilizing the N-BEATS model for univariate time series forecasting. The second\nlifts this assumption by utilizing a Graph Neural Network (GNN) to capture\ninter-variable relationships. Both models demonstrate strong forecasting\nperformance up to a horizon of 20 time points and maintain stable anomaly\nprediction up to 50 time points. The GNN consistently outperforms the N-BEATS\nmodel while requiring significantly fewer trainable parameters and lower\ncomputational cost. These results position the GNN as promising solution for\nonline anomaly forecasting to be deployed in manufacturing environments.",
      "pdf_url": "http://arxiv.org/pdf/2510.20718v1",
      "published": "2025-10-23T16:33:52+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.20718v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.0; J.6"
      ]
    },
    {
      "title": "Real-Time Gait Adaptation for Quadrupeds using Model Predictive Control and Reinforcement Learning",
      "authors": [
        "Ganga Nair B",
        "Prakrut Kotecha",
        "Shishir Kolathaya"
      ],
      "abstract": "Model-free reinforcement learning (RL) has enabled adaptable and agile\nquadruped locomotion; however, policies often converge to a single gait,\nleading to suboptimal performance. Traditionally, Model Predictive Control\n(MPC) has been extensively used to obtain task-specific optimal policies but\nlacks the ability to adapt to varying environments. To address these\nlimitations, we propose an optimization framework for real-time gait adaptation\nin a continuous gait space, combining the Model Predictive Path Integral (MPPI)\nalgorithm with a Dreamer module to produce adaptive and optimal policies for\nquadruped locomotion. At each time step, MPPI jointly optimizes the actions and\ngait variables using a learned Dreamer reward that promotes velocity tracking,\nenergy efficiency, stability, and smooth transitions, while penalizing abrupt\ngait changes. A learned value function is incorporated as terminal reward,\nextending the formulation to an infinite-horizon planner. We evaluate our\nframework in simulation on the Unitree Go1, demonstrating an average reduction\nof up to 36.48\\% in energy consumption across varying target speeds, while\nmaintaining accurate tracking and adaptive, task-appropriate gaits.",
      "pdf_url": "http://arxiv.org/pdf/2510.20706v1",
      "published": "2025-10-23T16:17:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.20706v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "Fusing Narrative Semantics for Financial Volatility Forecasting",
      "authors": [
        "Yaxuan Kong",
        "Yoontae Hwang",
        "Marcus Kaiser",
        "Chris Vryonides",
        "Roel Oomen",
        "Stefan Zohren"
      ],
      "abstract": "We introduce M2VN: Multi-Modal Volatility Network, a novel deep\nlearning-based framework for financial volatility forecasting that unifies time\nseries features with unstructured news data. M2VN leverages the\nrepresentational power of deep neural networks to address two key challenges in\nthis domain: (i) aligning and fusing heterogeneous data modalities, numerical\nfinancial data and textual information, and (ii) mitigating look-ahead bias\nthat can undermine the validity of financial models. To achieve this, M2VN\ncombines open-source market features with news embeddings generated by Time\nMachine GPT, a recently introduced point-in-time LLM, ensuring temporal\nintegrity. An auxiliary alignment loss is introduced to enhance the integration\nof structured and unstructured data within the deep learning architecture.\nExtensive experiments demonstrate that M2VN consistently outperforms existing\nbaselines, underscoring its practical value for risk management and financial\ndecision-making in dynamic markets.",
      "pdf_url": "http://arxiv.org/pdf/2510.20699v1",
      "published": "2025-10-23T16:13:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.20699v1",
      "categories": [
        "q-fin.CP",
        "cs.AI"
      ]
    },
    {
      "title": "Exploring Large Language Models for Access Control Policy Synthesis and Summarization",
      "authors": [
        "Adarsh Vatsa",
        "Bethel Hall",
        "William Eiers"
      ],
      "abstract": "Cloud computing is ubiquitous, with a growing number of services being hosted\non the cloud every day. Typical cloud compute systems allow administrators to\nwrite policies implementing access control rules which specify how access to\nprivate data is governed. These policies must be manually written, and due to\ntheir complexity can often be error prone. Moreover, existing policies often\nimplement complex access control specifications and thus can be difficult to\nprecisely analyze in determining their behavior works exactly as intended.\nRecently, Large Language Models (LLMs) have shown great success in automated\ncode synthesis and summarization. Given this success, they could potentially be\nused for automatically generating access control policies or aid in\nunderstanding existing policies. In this paper, we explore the effectiveness of\nLLMs for access control policy synthesis and summarization. Specifically, we\nfirst investigate diverse LLMs for access control policy synthesis, finding\nthat: although LLMs can effectively generate syntactically correct policies,\nthey have permissiveness issues, generating policies equivalent to the given\nspecification 45.8% of the time for non-reasoning LLMs, and 93.7% of the time\nfor reasoning LLMs. We then investigate how LLMs can be used to analyze\npolicies by introducing a novel semantic-based request summarization approach\nwhich leverages LLMs to generate a precise characterization of the requests\nallowed by a policy. Our results show that while there are significant hurdles\nin leveraging LLMs for automated policy generation, LLMs show promising results\nwhen combined with symbolic approaches in analyzing existing policies.",
      "pdf_url": "http://arxiv.org/pdf/2510.20692v1",
      "published": "2025-10-23T16:06:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.20692v1",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.FL",
        "D.4.6; D.2.4; I.2.2; I.2.7; F.3.1; F.4.3"
      ]
    },
    {
      "title": "Plan Then Retrieve: Reinforcement Learning-Guided Complex Reasoning over Knowledge Graphs",
      "authors": [
        "Yanlin Song",
        "Ben Liu",
        "Víctor Gutiérrez-Basulto",
        "Zhiwei Hu",
        "Qianqian Xie",
        "Min Peng",
        "Sophia Ananiadou",
        "Jeff Z. Pan"
      ],
      "abstract": "Knowledge Graph Question Answering aims to answer natural language questions\nby reasoning over structured knowledge graphs. While large language models have\nadvanced KGQA through their strong reasoning capabilities, existing methods\ncontinue to struggle to fully exploit both the rich knowledge encoded in KGs\nand the reasoning capabilities of LLMs, particularly in complex scenarios. They\noften assume complete KG coverage and lack mechanisms to judge when external\ninformation is needed, and their reasoning remains locally myopic, failing to\nmaintain coherent multi-step planning, leading to reasoning failures even when\nrelevant knowledge exists. We propose Graph-RFT, a novel two-stage\nreinforcement fine-tuning KGQA framework with a\n'plan-KGsearch-and-Websearch-during-think' paradigm, that enables LLMs to\nperform autonomous planning and adaptive retrieval scheduling across KG and web\nsources under incomplete knowledge conditions. Graph-RFT introduces a\nchain-of-thought fine-tuning method with a customized plan-retrieval dataset\nactivates structured reasoning and resolves the GRPO cold-start problem. It\nthen introduces a novel plan-retrieval guided reinforcement learning process\nintegrates explicit planning and retrieval actions with a multi-reward design,\nenabling coverage-aware retrieval scheduling. It employs a Cartesian-inspired\nplanning module to decompose complex questions into ordered subquestions, and\nlogical expression to guide tool invocation for globally consistent multi-step\nreasoning. This reasoning retrieval process is optimized with a multi-reward\ncombining outcome and retrieval specific signals, enabling the model to learn\nwhen and how to combine KG and web retrieval effectively.",
      "pdf_url": "http://arxiv.org/pdf/2510.20691v1",
      "published": "2025-10-23T16:04:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.20691v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Neural Diversity Regularizes Hallucinations in Small Models",
      "authors": [
        "Kushal Chakrabarti",
        "Nirmal Balachundhar"
      ],
      "abstract": "Language models continue to hallucinate despite increases in parameters,\ncompute, and data. We propose neural diversity -- decorrelated parallel\nrepresentations -- as a principled mechanism that reduces hallucination rates\nat fixed parameter and data budgets. Inspired by portfolio theory, where\nuncorrelated assets reduce risk by $\\sqrt{P}$, we prove hallucination\nprobability is bounded by representational correlation: $P(H) \\leq\nf(\\sigma^2((1-\\rho(P))/P + \\rho(P)), \\mu^2)$, which predicts that language\nmodels need an optimal amount of neurodiversity. To validate this, we introduce\nND-LoRA (Neural Diversity Low-Rank Adaptation), combining parallel LoRA\nadapters with Barlow Twins regularization, and demonstrate that ND-LoRA reduces\nhallucinations by up to 25.6% (and 14.6% on average) without degrading general\naccuracy. Ablations show LoRA adapters and regularization act synergistically,\ncausal interventions prove neurodiversity as the mediating factor and\ncorrelational analyses indicate scale: a 0.1% neural correlation increase is\nassociated with a 3.8% hallucination increase. Finally, task-dependent\noptimality emerges: different tasks require different amounts of optimal\nneurodiversity. Together, our results highlight neural diversity as a third\naxis of scaling -- orthogonal to parameters and data -- to improve the\nreliability of language models at fixed budgets.",
      "pdf_url": "http://arxiv.org/pdf/2510.20690v1",
      "published": "2025-10-23T16:03:07+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.20690v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "A Scalable, Causal, and Energy Efficient Framework for Neural Decoding with Spiking Neural Networks",
      "authors": [
        "Georgios Mentzelopoulos",
        "Ioannis Asmanis",
        "Konrad P. Kording",
        "Eva L. Dyer",
        "Kostas Daniilidis",
        "Flavia Vitale"
      ],
      "abstract": "Brain-computer interfaces (BCIs) promise to enable vital functions, such as\nspeech and prosthetic control, for individuals with neuromotor impairments.\nCentral to their success are neural decoders, models that map neural activity\nto intended behavior. Current learning-based decoding approaches fall into two\nclasses: simple, causal models that lack generalization, or complex, non-causal\nmodels that generalize and scale offline but struggle in real-time settings.\nBoth face a common challenge, their reliance on power-hungry artificial neural\nnetwork backbones, which makes integration into real-world, resource-limited\nsystems difficult. Spiking neural networks (SNNs) offer a promising\nalternative. Because they operate causally these models are suitable for\nreal-time use, and their low energy demands make them ideal for\nbattery-constrained environments. To this end, we introduce Spikachu: a\nscalable, causal, and energy-efficient neural decoding framework based on SNNs.\nOur approach processes binned spikes directly by projecting them into a shared\nlatent space, where spiking modules, adapted to the timing of the input,\nextract relevant features; these latent representations are then integrated and\ndecoded to generate behavioral predictions. We evaluate our approach on 113\nrecording sessions from 6 non-human primates, totaling 43 hours of recordings.\nOur method outperforms causal baselines when trained on single sessions using\nbetween 2.26 and 418.81 times less energy. Furthermore, we demonstrate that\nscaling up training to multiple sessions and subjects improves performance and\nenables few-shot transfer to unseen sessions, subjects, and tasks. Overall,\nSpikachu introduces a scalable, online-compatible neural decoding framework\nbased on SNNs, whose performance is competitive relative to state-of-the-art\nmodels while consuming orders of magnitude less energy.",
      "pdf_url": "http://arxiv.org/pdf/2510.20683v1",
      "published": "2025-10-23T15:55:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.20683v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "R2-SVC: Towards Real-World Robust and Expressive Zero-shot Singing Voice Conversion",
      "authors": [
        "Junjie Zheng",
        "Gongyu Chen",
        "Chaofan Ding",
        "Zihao Chen"
      ],
      "abstract": "In real-world singing voice conversion (SVC) applications, environmental\nnoise and the demand for expressive output pose significant challenges.\nConventional methods, however, are typically designed without accounting for\nreal deployment scenarios, as both training and inference usually rely on clean\ndata. This mismatch hinders practical use, given the inevitable presence of\ndiverse noise sources and artifacts from music separation. To tackle these\nissues, we propose R2-SVC, a robust and expressive SVC framework. First, we\nintroduce simulation-based robustness enhancement through random fundamental\nfrequency ($F_0$) perturbations and music separation artifact simulations\n(e.g., reverberation, echo), substantially improving performance under noisy\nconditions. Second, we enrich speaker representation using domain-specific\nsinging data: alongside clean vocals, we incorporate DNSMOS-filtered separated\nvocals and public singing corpora, enabling the model to preserve speaker\ntimbre while capturing singing style nuances. Third, we integrate the Neural\nSource-Filter (NSF) model to explicitly represent harmonic and noise\ncomponents, enhancing the naturalness and controllability of converted singing.\nR2-SVC achieves state-of-the-art results on multiple SVC benchmarks under both\nclean and noisy conditions.",
      "pdf_url": "http://arxiv.org/pdf/2510.20677v1",
      "published": "2025-10-23T15:52:03+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.20677v1",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ]
    },
    {
      "title": "GRACE: GRaph-based Addiction Care prEdiction",
      "authors": [
        "Subham Kumar",
        "Prakrithi Shivaprakash",
        "Koustav Rudra",
        "Lekhansh Shukla",
        "Animesh Mukherjee"
      ],
      "abstract": "Determining the appropriate locus of care for addiction patients is one of\nthe most critical clinical decisions that affects patient treatment outcomes\nand effective use of resources. With a lack of sufficient specialized treatment\nresources, such as inpatient beds or staff, there is an unmet need to develop\nan automated framework for the same. Current decision-making approaches suffer\nfrom severe class imbalances in addiction datasets. To address this limitation,\nwe propose a novel graph neural network (GRACE) framework that formalizes locus\nof care prediction as a structured learning problem. Further, we perform\nextensive feature engineering and propose a new approach of obtaining an\nunbiased meta-graph to train a GNN to overcome the class imbalance problem.\nExperimental results in real-world data show an improvement of 11-35% in terms\nof the F1 score of the minority class over competitive baselines. The codes and\nnote embeddings are available at https://anonymous.4open.science/r/GRACE-F8E1/.",
      "pdf_url": "http://arxiv.org/pdf/2510.20671v1",
      "published": "2025-10-23T15:48:01+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.20671v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "The Shape of Reasoning: Topological Analysis of Reasoning Traces in Large Language Models",
      "authors": [
        "Xue Wen Tan",
        "Nathaniel Tan",
        "Galen Lee",
        "Stanley Kok"
      ],
      "abstract": "Evaluating the quality of reasoning traces from large language models remains\nunderstudied, labor-intensive, and unreliable: current practice relies on\nexpert rubrics, manual annotation, and slow pairwise judgments. Automated\nefforts are dominated by graph-based proxies that quantify structural\nconnectivity but do not clarify what constitutes high-quality reasoning; such\nabstractions can be overly simplistic for inherently complex processes. We\nintroduce a topological data analysis (TDA)-based evaluation framework that\ncaptures the geometry of reasoning traces and enables label-efficient,\nautomated assessment. In our empirical study, topological features yield\nsubstantially higher predictive power for assessing reasoning quality than\nstandard graph metrics, suggesting that effective reasoning is better captured\nby higher-dimensional geometric structures rather than purely relational\ngraphs. We further show that a compact, stable set of topological features\nreliably indicates trace quality, offering a practical signal for future\nreinforcement learning algorithms.",
      "pdf_url": "http://arxiv.org/pdf/2510.20665v1",
      "published": "2025-10-23T15:43:43+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.20665v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Finding the Sweet Spot: Trading Quality, Cost, and Speed During Inference-Time LLM Reflection",
      "authors": [
        "Jack Butler",
        "Nikita Kozodoi",
        "Zainab Afolabi",
        "Brian Tyacke",
        "Gaiar Baimuratov"
      ],
      "abstract": "As Large Language Models (LLMs) continue to evolve, practitioners face\nincreasing options for enhancing inference-time performance without model\nretraining, including budget tuning and multi-step techniques like\nself-reflection. While these methods improve output quality, they create\ncomplex trade-offs among accuracy, cost, and latency that remain poorly\nunderstood across different domains. This paper systematically compares\nself-reflection and budget tuning across mathematical reasoning and translation\ntasks. We evaluate prominent LLMs, including Anthropic Claude, Amazon Nova, and\nMistral families, along with other models under varying reflection depths and\ncompute budgets to derive Pareto optimal performance frontiers. Our analysis\nreveals substantial domain dependent variation in self-reflection\neffectiveness, with performance gains up to 220\\% in mathematical reasoning. We\nfurther investigate how reflection round depth and feedback mechanism quality\ninfluence performance across model families. To validate our findings in a\nreal-world setting, we deploy a self-reflection enhanced marketing content\nlocalisation system at Lounge by Zalando, where it shows market-dependent\neffectiveness, reinforcing the importance of domain specific evaluation when\ndeploying these techniques. Our results provide actionable guidance for\nselecting optimal inference strategies given specific domains and resource\nconstraints. We open source our self-reflection implementation for\nreproducibility at\nhttps://github.com/aws-samples/sample-genai-reflection-for-bedrock.",
      "pdf_url": "http://arxiv.org/pdf/2510.20653v1",
      "published": "2025-10-23T15:26:18+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.20653v1",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "The Reasoning Lingua Franca: A Double-Edged Sword for Multilingual AI",
      "authors": [
        "Alan Saji",
        "Raj Dabre",
        "Anoop Kunchukuttan",
        "Ratish Puduppully"
      ],
      "abstract": "Large Reasoning Models (LRMs) achieve strong performance on mathematical,\nscientific, and other question-answering tasks, but their multilingual\nreasoning abilities remain underexplored. When presented with non-English\nquestions, LRMs often default to reasoning in English, raising concerns about\ninterpretability and the handling of linguistic and cultural nuances. We\nsystematically compare an LRM's reasoning in English versus the language of the\nquestion. Our evaluation spans two tasks: MGSM and GPQA Diamond. Beyond\nmeasuring answer accuracy, we also analyze cognitive attributes in the\nreasoning traces. We find that English reasoning traces exhibit a substantially\nhigher presence of these cognitive behaviors, and that reasoning in English\ngenerally yields higher final-answer accuracy, with the performance gap\nincreasing as tasks become more complex. However, this English-centric strategy\nis susceptible to a key failure mode - getting \"Lost in Translation,\" where\ntranslation steps lead to errors that would have been avoided by question's\nlanguage reasoning.",
      "pdf_url": "http://arxiv.org/pdf/2510.20647v1",
      "published": "2025-10-23T15:22:00+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.20647v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Integrating Machine Learning into Belief-Desire-Intention Agents: Current Advances and Open Challenges",
      "authors": [
        "Andrea Agiollo",
        "Andrea Omicini"
      ],
      "abstract": "Thanks to the remarkable human-like capabilities of machine learning (ML)\nmodels in perceptual and cognitive tasks, frameworks integrating ML within\nrational agent architectures are gaining traction. Yet, the landscape remains\nfragmented and incoherent, often focusing on embedding ML into generic agent\ncontainers while overlooking the expressive power of rational\narchitectures--such as Belief-Desire-Intention (BDI) agents. This paper\npresents a fine-grained systematisation of existing approaches, using the BDI\nparadigm as a reference. Our analysis illustrates the fast-evolving literature\non rational agents enhanced by ML, and identifies key research opportunities\nand open challenges for designing effective rational ML agents.",
      "pdf_url": "http://arxiv.org/pdf/2510.20641v1",
      "published": "2025-10-23T15:15:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.20641v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Fluidity Index: Next-Generation Super-intelligence Benchmarks",
      "authors": [
        "Eric Ngoiya",
        "Tianshu Bao"
      ],
      "abstract": "This paper introduces the Fluidity Index (FI) to quantify model adaptability\nin dynamic, scaling environments. The benchmark evaluates response accuracy\nbased on deviations in initial, current, and future environment states,\nassessing context switching and continuity. We distinguish between closed-ended\nand open-ended benchmarks, prioritizing closed-loop open-ended real-world\nbenchmarks to test adaptability. The approach measures a model's ability to\nunderstand, predict, and adjust to state changes in scaling environments. A\ntruly super-intelligent model should exhibit at least second-order\nadaptability, enabling self-sustained computation through digital replenishment\nfor optimal fluidity.",
      "pdf_url": "http://arxiv.org/pdf/2510.20636v1",
      "published": "2025-10-23T15:05:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.20636v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Why Did Apple Fall To The Ground: Evaluating Curiosity In Large Language Model",
      "authors": [
        "Haoyu Wang",
        "Sihang Jiang",
        "Yuyan Chen",
        "Yitong Wang",
        "Yanghua Xiao"
      ],
      "abstract": "Curiosity serves as a pivotal conduit for human beings to discover and learn\nnew knowledge. Recent advancements of large language models (LLMs) in natural\nlanguage processing have sparked discussions regarding whether these models\npossess capability of curiosity-driven learning akin to humans. In this paper,\nstarting from the human curiosity assessment questionnaire Five-Dimensional\nCuriosity scale Revised (5DCR), we design a comprehensive evaluation framework\nthat covers dimensions such as Information Seeking, Thrill Seeking, and Social\nCuriosity to assess the extent of curiosity exhibited by LLMs. The results\ndemonstrate that LLMs exhibit a stronger thirst for knowledge than humans but\nstill tend to make conservative choices when faced with uncertain environments.\nWe further investigated the relationship between curiosity and thinking of\nLLMs, confirming that curious behaviors can enhance the model's reasoning and\nactive learning abilities. These findings suggest that LLMs have the potential\nto exhibit curiosity similar to that of humans, providing experimental support\nfor the future development of learning capabilities and innovative research in\nLLMs.",
      "pdf_url": "http://arxiv.org/pdf/2510.20635v1",
      "published": "2025-10-23T15:05:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.20635v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Deep Learning in Dental Image Analysis: A Systematic Review of Datasets, Methodologies, and Emerging Challenges",
      "authors": [
        "Zhenhuan Zhou",
        "Jingbo Zhu",
        "Yuchen Zhang",
        "Xiaohang Guan",
        "Peng Wang",
        "Tao Li"
      ],
      "abstract": "Efficient analysis and processing of dental images are crucial for dentists\nto achieve accurate diagnosis and optimal treatment planning. However, dental\nimaging inherently poses several challenges, such as low contrast, metallic\nartifacts, and variations in projection angles. Combined with the subjectivity\narising from differences in clinicians' expertise, manual interpretation often\nproves time-consuming and prone to inconsistency. Artificial intelligence\n(AI)-based automated dental image analysis (DIA) offers a promising solution to\nthese issues and has become an integral part of computer-aided dental diagnosis\nand treatment. Among various AI technologies, deep learning (DL) stands out as\nthe most widely applied and influential approach due to its superior feature\nextraction and representation capabilities. To comprehensively summarize recent\nprogress in this field, we focus on the two fundamental aspects of DL\nresearch-datasets and models. In this paper, we systematically review 260\nstudies on DL applications in DIA, including 49 papers on publicly available\ndental datasets and 211 papers on DL-based algorithms. We first introduce the\nbasic concepts of dental imaging and summarize the characteristics and\nacquisition methods of existing datasets. Then, we present the foundational\ntechniques of DL and categorize relevant models and algorithms according to\ndifferent DIA tasks, analyzing their network architectures, optimization\nstrategies, training methods, and performance. Furthermore, we summarize\ncommonly used training and evaluation metrics in the DIA domain. Finally, we\ndiscuss the current challenges of existing research and outline potential\nfuture directions. We hope that this work provides a valuable and systematic\nreference for researchers in this field. All supplementary materials and\ndetailed comparison tables will be made publicly available on GitHub.",
      "pdf_url": "http://arxiv.org/pdf/2510.20634v1",
      "published": "2025-10-23T15:05:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.20634v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Towards Reliable Evaluation of Large Language Models for Multilingual and Multimodal E-Commerce Applications",
      "authors": [
        "Shuyi Xie",
        "Ziqin Liew",
        "Hailing Zhang",
        "Haibo Zhang",
        "Ling Hu",
        "Zhiqiang Zhou",
        "Shuman Liu",
        "Anxiang Zeng"
      ],
      "abstract": "Large Language Models (LLMs) excel on general-purpose NLP benchmarks, yet\ntheir capabilities in specialized domains remain underexplored. In e-commerce,\nexisting evaluations-such as EcomInstruct, ChineseEcomQA, eCeLLM, and Shopping\nMMLU-suffer from limited task diversity (e.g., lacking product guidance and\nafter-sales issues), limited task modalities (e.g., absence of multimodal\ndata), synthetic or curated data, and a narrow focus on English and Chinese,\nleaving practitioners without reliable tools to assess models on complex,\nreal-world shopping scenarios. We introduce EcomEval, a comprehensive\nmultilingual and multimodal benchmark for evaluating LLMs in e-commerce.\nEcomEval covers six categories and 37 tasks (including 8 multimodal tasks),\nsourced primarily from authentic customer queries and transaction logs,\nreflecting the noisy and heterogeneous nature of real business interactions. To\nensure both quality and scalability of reference answers, we adopt a\nsemi-automatic pipeline in which large models draft candidate responses\nsubsequently reviewed and modified by over 50 expert annotators with strong\ne-commerce and multilingual expertise. We define difficulty levels for each\nquestion and task category by averaging evaluation scores across models with\ndifferent sizes and capabilities, enabling challenge-oriented and fine-grained\nassessment. EcomEval also spans seven languages-including five low-resource\nSoutheast Asian languages-offering a multilingual perspective absent from prior\nwork.",
      "pdf_url": "http://arxiv.org/pdf/2510.20632v1",
      "published": "2025-10-23T15:04:32+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.20632v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Quantum Processing Unit (QPU) processing time Prediction with Machine Learning",
      "authors": [
        "Lucy Xing",
        "Sanjay Vishwakarma",
        "David Kremer",
        "Francisco Martin-Fernandez",
        "Ismael Faro",
        "Juan Cruz-Benito"
      ],
      "abstract": "This paper explores the application of machine learning (ML) techniques in\npredicting the QPU processing time of quantum jobs. By leveraging ML\nalgorithms, this study introduces predictive models that are designed to\nenhance operational efficiency in quantum computing systems. Using a dataset of\nabout 150,000 jobs that follow the IBM Quantum schema, we employ ML methods\nbased on Gradient-Boosting (LightGBM) to predict the QPU processing times,\nincorporating data preprocessing methods to improve model accuracy. The results\ndemonstrate the effectiveness of ML in forecasting quantum jobs. This\nimprovement can have implications on improving resource management and\nscheduling within quantum computing frameworks. This research not only\nhighlights the potential of ML in refining quantum job predictions but also\nsets a foundation for integrating AI-driven tools in advanced quantum computing\noperations.",
      "pdf_url": "http://arxiv.org/pdf/2510.20630v1",
      "published": "2025-10-23T15:04:18+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.20630v1",
      "categories": [
        "quant-ph",
        "cs.AI"
      ]
    },
    {
      "title": "Equitable Survival Prediction: A Fairness-Aware Survival Modeling (FASM) Approach",
      "authors": [
        "Mingxuan Liu",
        "Yilin Ning",
        "Haoyuan Wang",
        "Chuan Hong",
        "Matthew Engelhard",
        "Danielle S. Bitterman",
        "William G. La Cava",
        "Nan Liu"
      ],
      "abstract": "As machine learning models become increasingly integrated into healthcare,\nstructural inequities and social biases embedded in clinical data can be\nperpetuated or even amplified by data-driven models. In survival analysis,\ncensoring and time dynamics can further add complexity to fair model\ndevelopment. Additionally, algorithmic fairness approaches often overlook\ndisparities in cross-group rankings, e.g., high-risk Black patients may be\nranked below lower-risk White patients who do not experience the event of\nmortality. Such misranking can reinforce biological essentialism and undermine\nequitable care. We propose a Fairness-Aware Survival Modeling (FASM), designed\nto mitigate algorithmic bias regarding both intra-group and cross-group risk\nrankings over time. Using breast cancer prognosis as a representative case and\napplying FASM to SEER breast cancer data, we show that FASM substantially\nimproves fairness while preserving discrimination performance comparable to\nfairness-unaware survival models. Time-stratified evaluations show that FASM\nmaintains stable fairness over a 10-year horizon, with the greatest\nimprovements observed during the mid-term of follow-up. Our approach enables\nthe development of survival models that prioritize both accuracy and equity in\nclinical decision-making, advancing fairness as a core principle in clinical\ncare.",
      "pdf_url": "http://arxiv.org/pdf/2510.20629v1",
      "published": "2025-10-23T15:03:27+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.20629v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Towards the Formalization of a Trustworthy AI for Mining Interpretable Models explOiting Sophisticated Algorithms",
      "authors": [
        "Riccardo Guidotti",
        "Martina Cinquini",
        "Marta Marchiori Manerba",
        "Mattia Setzu",
        "Francesco Spinnato"
      ],
      "abstract": "Interpretable-by-design models are crucial for fostering trust,\naccountability, and safe adoption of automated decision-making models in\nreal-world applications. In this paper we formalize the ground for the MIMOSA\n(Mining Interpretable Models explOiting Sophisticated Algorithms) framework, a\ncomprehensive methodology for generating predictive models that balance\ninterpretability with performance while embedding key ethical properties. We\nformally define here the supervised learning setting across diverse\ndecision-making tasks and data types, including tabular data, time series,\nimages, text, transactions, and trajectories. We characterize three major\nfamilies of interpretable models: feature importance, rule, and instance based\nmodels. For each family, we analyze their interpretability dimensions,\nreasoning mechanisms, and complexity. Beyond interpretability, we formalize\nthree critical ethical properties, namely causality, fairness, and privacy,\nproviding formal definitions, evaluation metrics, and verification procedures\nfor each. We then examine the inherent trade-offs between these properties and\ndiscuss how privacy requirements, fairness constraints, and causal reasoning\ncan be embedded within interpretable pipelines. By evaluating ethical measures\nduring model generation, this framework establishes the theoretical foundations\nfor developing AI systems that are not only accurate and interpretable but also\nfair, privacy-preserving, and causally aware, i.e., trustworthy.",
      "pdf_url": "http://arxiv.org/pdf/2510.20621v1",
      "published": "2025-10-23T14:54:33+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.20621v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Black Box Absorption: LLMs Undermining Innovative Ideas",
      "authors": [
        "Wenjun Cao"
      ],
      "abstract": "Large Language Models are increasingly adopted as critical tools for\naccelerating innovation. This paper identifies and formalizes a systemic risk\ninherent in this paradigm: \\textbf{Black Box Absorption}. We define this as the\nprocess by which the opaque internal architectures of LLM platforms, often\noperated by large-scale service providers, can internalize, generalize, and\nrepurpose novel concepts contributed by users during interaction. This\nmechanism threatens to undermine the foundational principles of innovation\neconomics by creating severe informational and structural asymmetries between\nindividual creators and platform operators, thereby jeopardizing the long-term\nsustainability of the innovation ecosystem. To analyze this challenge, we\nintroduce two core concepts: the idea unit, representing the transportable\nfunctional logic of an innovation, and idea safety, a multidimensional standard\nfor its protection. This paper analyzes the mechanisms of absorption and\nproposes a concrete governance and engineering agenda to mitigate these risks,\nensuring that creator contributions remain traceable, controllable, and\nequitable.",
      "pdf_url": "http://arxiv.org/pdf/2510.20612v1",
      "published": "2025-10-23T14:43:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.20612v1",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CR",
        "cs.LG",
        "econ.GN",
        "q-fin.EC"
      ]
    },
    {
      "title": "PSO-XAI: A PSO-Enhanced Explainable AI Framework for Reliable Breast Cancer Detection",
      "authors": [
        "Mirza Raquib",
        "Niloy Das",
        "Farida Siddiqi Prity",
        "Arafath Al Fahim",
        "Saydul Akbar Murad",
        "Mohammad Amzad Hossain",
        "MD Jiabul Hoque",
        "Mohammad Ali Moni"
      ],
      "abstract": "Breast cancer is considered the most critical and frequently diagnosed cancer\nin women worldwide, leading to an increase in cancer-related mortality. Early\nand accurate detection is crucial as it can help mitigate possible threats\nwhile improving survival rates. In terms of prediction, conventional diagnostic\nmethods are often limited by variability, cost, and, most importantly, risk of\nmisdiagnosis. To address these challenges, machine learning (ML) has emerged as\na powerful tool for computer-aided diagnosis, with feature selection playing a\nvital role in improving model performance and interpretability. This research\nstudy proposes an integrated framework that incorporates customized Particle\nSwarm Optimization (PSO) for feature selection. This framework has been\nevaluated on a comprehensive set of 29 different models, spanning classical\nclassifiers, ensemble techniques, neural networks, probabilistic algorithms,\nand instance-based algorithms. To ensure interpretability and clinical\nrelevance, the study uses cross-validation in conjunction with explainable AI\nmethods. Experimental evaluation showed that the proposed approach achieved a\nsuperior score of 99.1\\% across all performance metrics, including accuracy and\nprecision, while effectively reducing dimensionality and providing transparent,\nmodel-agnostic explanations. The results highlight the potential of combining\nswarm intelligence with explainable ML for robust, trustworthy, and clinically\nmeaningful breast cancer diagnosis.",
      "pdf_url": "http://arxiv.org/pdf/2510.20611v1",
      "published": "2025-10-23T14:42:50+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.20611v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "BUSTED at AraGenEval Shared Task: A Comparative Study of Transformer-Based Models for Arabic AI-Generated Text Detection",
      "authors": [
        "Ali Zain",
        "Sareem Farooqui",
        "Muhammad Rafi"
      ],
      "abstract": "This paper details our submission to the Ara- GenEval Shared Task on Arabic\nAI-generated text detection, where our team, BUSTED, se- cured 5th place. We\ninvestigated the effec- tiveness of three pre-trained transformer mod- els:\nAraELECTRA, CAMeLBERT, and XLM- RoBERTa. Our approach involved fine-tuning each\nmodel on the provided dataset for a binary classification task. Our findings\nrevealed a sur- prising result: the multilingual XLM-RoBERTa model achieved the\nhighest performance with an F1 score of 0.7701, outperforming the spe- cialized\nArabic models. This work underscores the complexities of AI-generated text\ndetection and highlights the strong generalization capa- bilities of\nmultilingual models.",
      "pdf_url": "http://arxiv.org/pdf/2510.20610v1",
      "published": "2025-10-23T14:41:04+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.20610v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Practical Code RAG at Scale: Task-Aware Retrieval Design Choices under Compute Budgets",
      "authors": [
        "Timur Galimzyanov",
        "Olga Kolomyttseva",
        "Egor Bogomolov"
      ],
      "abstract": "We study retrieval design for code-focused generation tasks under realistic\ncompute budgets. Using two complementary tasks from Long Code Arena -- code\ncompletion and bug localization -- we systematically compare retrieval\nconfigurations across various context window sizes along three axes: (i)\nchunking strategy, (ii) similarity scoring, and (iii) splitting granularity.\n(1) For PL-PL, sparse BM25 with word-level splitting is the most effective and\npractical, significantly outperforming dense alternatives while being an order\nof magnitude faster. (2) For NL-PL, proprietary dense encoders (Voyager-3\nfamily) consistently beat sparse retrievers, however requiring 100x larger\nlatency. (3) Optimal chunk size scales with available context: 32-64 line\nchunks work best at small budgets, and whole-file retrieval becomes competitive\nat 16000 tokens. (4) Simple line-based chunking matches syntax-aware splitting\nacross budgets. (5) Retrieval latency varies by up to 200x across\nconfigurations; BPE-based splitting is needlessly slow, and BM25 + word\nsplitting offers the best quality-latency trade-off. Thus, we provide\nevidence-based recommendations for implementing effective code-oriented RAG\nsystems based on task requirements, model constraints, and computational\nefficiency.",
      "pdf_url": "http://arxiv.org/pdf/2510.20609v1",
      "published": "2025-10-23T14:40:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.20609v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR",
        "cs.LG, cs.IR, cs.SE, cs.AI"
      ]
    },
    {
      "title": "Generalizable Reasoning through Compositional Energy Minimization",
      "authors": [
        "Alexandru Oarga",
        "Yilun Du"
      ],
      "abstract": "Generalization is a key challenge in machine learning, specifically in\nreasoning tasks, where models are expected to solve problems more complex than\nthose encountered during training. Existing approaches typically train\nreasoning models in an end-to-end fashion, directly mapping input instances to\nsolutions. While this allows models to learn useful heuristics from data, it\noften results in limited generalization beyond the training distribution. In\nthis work, we propose a novel approach to reasoning generalization by learning\nenergy landscapes over the solution spaces of smaller, more tractable\nsubproblems. At test time, we construct a global energy landscape for a given\nproblem by combining the energy functions of multiple subproblems. This\ncompositional approach enables the incorporation of additional constraints\nduring inference, allowing the construction of energy landscapes for problems\nof increasing difficulty. To improve the sample quality from this newly\nconstructed energy landscape, we introduce Parallel Energy Minimization (PEM).\nWe evaluate our approach on a wide set of reasoning problems. Our method\noutperforms existing state-of-the-art methods, demonstrating its ability to\ngeneralize to larger and more complex problems. Project website can be found\nat: https://alexoarga.github.io/compositional_reasoning/",
      "pdf_url": "http://arxiv.org/pdf/2510.20607v1",
      "published": "2025-10-23T14:38:36+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.20607v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "OnlineSplatter: Pose-Free Online 3D Reconstruction for Free-Moving Objects",
      "authors": [
        "Mark He Huang",
        "Lin Geng Foo",
        "Christian Theobalt",
        "Ying Sun",
        "De Wen Soh"
      ],
      "abstract": "Free-moving object reconstruction from monocular video remains challenging,\nparticularly without reliable pose or depth cues and under arbitrary object\nmotion. We introduce OnlineSplatter, a novel online feed-forward framework\ngenerating high-quality, object-centric 3D Gaussians directly from RGB frames\nwithout requiring camera pose, depth priors, or bundle optimization. Our\napproach anchors reconstruction using the first frame and progressively refines\nthe object representation through a dense Gaussian primitive field, maintaining\nconstant computational cost regardless of video sequence length. Our core\ncontribution is a dual-key memory module combining latent appearance-geometry\nkeys with explicit directional keys, robustly fusing current frame features\nwith temporally aggregated object states. This design enables effective\nhandling of free-moving objects via spatial-guided memory readout and an\nefficient sparsification mechanism, ensuring comprehensive yet compact object\ncoverage. Evaluations on real-world datasets demonstrate that OnlineSplatter\nsignificantly outperforms state-of-the-art pose-free reconstruction baselines,\nconsistently improving with more observations while maintaining constant memory\nand runtime.",
      "pdf_url": "http://arxiv.org/pdf/2510.20605v1",
      "published": "2025-10-23T14:37:25+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.20605v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.4.5; I.2.6"
      ]
    },
    {
      "title": "Efficient Algorithms for Computing Random Walk Centrality",
      "authors": [
        "Changan Liu",
        "Zixuan Xie",
        "Ahad N. Zehmakan",
        "Zhongzhi Zhang"
      ],
      "abstract": "Random walk centrality is a fundamental metric in graph mining for\nquantifying node importance and influence, defined as the weighted average of\nhitting times to a node from all other nodes. Despite its ability to capture\nrich graph structural information and its wide range of applications, computing\nthis measure for large networks remains impractical due to the computational\ndemands of existing methods. In this paper, we present a novel formulation of\nrandom walk centrality, underpinning two scalable algorithms: one leveraging\napproximate Cholesky factorization and sparse inverse estimation, while the\nother sampling rooted spanning trees. Both algorithms operate in near-linear\ntime and provide strong approximation guarantees. Extensive experiments on\nlarge real-world networks, including one with over 10 million nodes,\ndemonstrate the efficiency and approximation quality of the proposed\nalgorithms.",
      "pdf_url": "http://arxiv.org/pdf/2510.20604v1",
      "published": "2025-10-23T14:36:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.20604v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "What Defines Good Reasoning in LLMs? Dissecting Reasoning Steps with Multi-Aspect Evaluation",
      "authors": [
        "Heejin Do",
        "Jaehui Hwang",
        "Dongyoon Han",
        "Seong Joon Oh",
        "Sangdoo Yun"
      ],
      "abstract": "Evaluating large language models (LLMs) on final-answer correctness is the\ndominant paradigm. This approach, however, provides a coarse signal for model\nimprovement and overlooks the quality of the underlying reasoning process. We\nargue that a more granular evaluation of reasoning offers a more effective path\nto building robust models. We decompose reasoning quality into two dimensions:\nrelevance and coherence. Relevance measures if a step is grounded in the\nproblem; coherence measures if it follows logically from prior steps. To\nmeasure these aspects reliably, we introduce causal stepwise evaluation (CaSE).\nThis method assesses each reasoning step using only its preceding context,\nwhich avoids hindsight bias. We validate CaSE against human judgments on our\nnew expert-annotated benchmarks, MRa-GSM8K and MRa-MATH. More importantly, we\nshow that curating training data with CaSE-evaluated relevance and coherence\ndirectly improves final task performance. Our work provides a scalable\nframework for analyzing, debugging, and improving LLM reasoning, demonstrating\nthe practical value of moving beyond validity checks.",
      "pdf_url": "http://arxiv.org/pdf/2510.20603v1",
      "published": "2025-10-23T14:30:37+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.20603v1",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Resounding Acoustic Fields with Reciprocity",
      "authors": [
        "Zitong Lan",
        "Yiduo Hao",
        "Mingmin Zhao"
      ],
      "abstract": "Achieving immersive auditory experiences in virtual environments requires\nflexible sound modeling that supports dynamic source positions. In this paper,\nwe introduce a task called resounding, which aims to estimate room impulse\nresponses at arbitrary emitter location from a sparse set of measured emitter\npositions, analogous to the relighting problem in vision. We leverage the\nreciprocity property and introduce Versa, a physics-inspired approach to\nfacilitating acoustic field learning. Our method creates physically valid\nsamples with dense virtual emitter positions by exchanging emitter and listener\nposes. We also identify challenges in deploying reciprocity due to\nemitter/listener gain patterns and propose a self-supervised learning approach\nto address them. Results show that Versa substantially improve the performance\nof acoustic field learning on both simulated and real-world datasets across\ndifferent metrics. Perceptual user studies show that Versa can greatly improve\nthe immersive spatial sound experience. Code, dataset and demo videos are\navailable on the project website: https://waves.seas.upenn.edu/projects/versa.",
      "pdf_url": "http://arxiv.org/pdf/2510.20602v1",
      "published": "2025-10-23T14:30:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.20602v1",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS",
        "eess.SP"
      ]
    }
  ]
}