{
  "last_updated": "2025-09-18T00:45:38.255127",
  "papers": [
    {
      "title": "Shapes of Cognition for Computational Cognitive Modeling",
      "authors": [
        "Marjorie McShane",
        "Sergei Nirenburg",
        "Sanjay Oruganti",
        "Jesse English"
      ],
      "abstract": "Shapes of cognition is a new conceptual paradigm for the computational\ncognitive modeling of Language-Endowed Intelligent Agents (LEIAs). Shapes are\nremembered constellations of sensory, linguistic, conceptual, episodic, and\nprocedural knowledge that allow agents to cut through the complexity of real\nlife the same way as people do: by expecting things to be typical, recognizing\npatterns, acting by habit, reasoning by analogy, satisficing, and generally\nminimizing cognitive load to the degree situations permit. Atypical outcomes\nare treated using shapes-based recovery methods, such as learning on the fly,\nasking a human partner for help, or seeking an actionable, even if imperfect,\nsituational understanding. Although shapes is an umbrella term, it is not\nvague: shapes-based modeling involves particular objectives, hypotheses,\nmodeling strategies, knowledge bases, and actual models of wide-ranging\nphenomena, all implemented within a particular cognitive architecture. Such\nspecificity is needed both to vet our hypotheses and to achieve our practical\naims of building useful agent systems that are explainable, extensible, and\nworthy of our trust, even in critical domains. However, although the LEIA\nexample of shapes-based modeling is specific, the principles can be applied\nmore broadly, giving new life to knowledge-based and hybrid AI.",
      "pdf_url": "http://arxiv.org/pdf/2509.13288v1",
      "published": "2025-09-16T17:39:58+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13288v1",
      "categories": [
        "cs.AI",
        "cs.RO"
      ]
    },
    {
      "title": "Contrastive timbre representations for musical instrument and synthesizer retrieval",
      "authors": [
        "Gwendal Le Vaillant",
        "Yannick Molle"
      ],
      "abstract": "Efficiently retrieving specific instrument timbres from audio mixtures\nremains a challenge in digital music production. This paper introduces a\ncontrastive learning framework for musical instrument retrieval, enabling\ndirect querying of instrument databases using a single model for both single-\nand multi-instrument sounds. We propose techniques to generate realistic\npositive/negative pairs of sounds for virtual musical instruments, such as\nsamplers and synthesizers, addressing limitations in common audio data\naugmentation methods.\n  The first experiment focuses on instrument retrieval from a dataset of 3,884\ninstruments, using single-instrument audio as input. Contrastive approaches are\ncompetitive with previous works based on classification pre-training. The\nsecond experiment considers multi-instrument retrieval with a mixture of\ninstruments as audio input. In this case, the proposed contrastive framework\noutperforms related works, achieving 81.7\\% top-1 and 95.7\\% top-5 accuracies\nfor three-instrument mixtures.",
      "pdf_url": "http://arxiv.org/pdf/2509.13285v1",
      "published": "2025-09-16T17:38:35+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13285v1",
      "categories": [
        "cs.SD",
        "cs.AI"
      ]
    },
    {
      "title": "RepIt: Representing Isolated Targets to Steer Language Models",
      "authors": [
        "Vincent Siu",
        "Nathan W. Henry",
        "Nicholas Crispino",
        "Yang Liu",
        "Dawn Song",
        "Chenguang Wang"
      ],
      "abstract": "While activation steering in large language models (LLMs) is a growing area\nof research, methods can often incur broader effects than desired. This\nmotivates isolation of purer concept vectors to enable targeted interventions\nand understand LLM behavior at a more granular level. We present RepIt, a\nsimple and data-efficient framework for isolating concept-specific\nrepresentations. Across five frontier LLMs, RepIt enables precise\ninterventions: it selectively suppresses refusal on targeted concepts while\npreserving refusal elsewhere, producing models that answer WMD-related\nquestions while still scoring as safe on standard benchmarks. We further show\nthat the corrective signal localizes to just 100-200 neurons and that robust\ntarget representations can be extracted from as few as a dozen examples on a\nsingle A6000. This efficiency raises a dual concern: manipulations can be\nperformed with modest compute and data to extend to underrepresented\ndata-scarce topics while evading existing benchmarks. By disentangling refusal\nvectors with RepIt, this work demonstrates that targeted interventions can\ncounteract overgeneralization, laying the foundation for more granular control\nof model behavior.",
      "pdf_url": "http://arxiv.org/pdf/2509.13281v1",
      "published": "2025-09-16T17:35:36+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13281v1",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "HARMONIC: A Content-Centric Cognitive Robotic Architecture",
      "authors": [
        "Sanjay Oruganti",
        "Sergei Nirenburg",
        "Marjorie McShane",
        "Jesse English",
        "Michael K. Roberts",
        "Christian Arndt",
        "Carlos Gonzalez",
        "Mingyo Seo",
        "Luis Sentis"
      ],
      "abstract": "This paper introduces HARMONIC, a cognitive-robotic architecture designed for\nrobots in human-robotic teams. HARMONIC supports semantic perception\ninterpretation, human-like decision-making, and intentional language\ncommunication. It addresses the issues of safety and quality of results; aims\nto solve problems of data scarcity, explainability, and safety; and promotes\ntransparency and trust. Two proof-of-concept HARMONIC-based robotic systems are\ndemonstrated, each implemented in both a high-fidelity simulation environment\nand on physical robotic platforms.",
      "pdf_url": "http://arxiv.org/pdf/2509.13279v1",
      "published": "2025-09-16T17:34:18+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13279v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "RadGame: An AI-Powered Platform for Radiology Education",
      "authors": [
        "Mohammed Baharoon",
        "Siavash Raissi",
        "John S. Jun",
        "Thibault Heintz",
        "Mahmoud Alabbad",
        "Ali Alburkani",
        "Sung Eun Kim",
        "Kent Kleinschmidt",
        "Abdulrahman O. Alhumaydhi",
        "Mohannad Mohammed G. Alghamdi",
        "Jeremy Francis Palacio",
        "Mohammed Bukhaytan",
        "Noah Michael Prudlo",
        "Rithvik Akula",
        "Brady Chrisler",
        "Benjamin Galligos",
        "Mohammed O. Almutairi",
        "Mazeen Mohammed Alanazi",
        "Nasser M. Alrashdi",
        "Joel Jihwan Hwang",
        "Sri Sai Dinesh Jaliparthi",
        "Luke David Nelson",
        "Nathaniel Nguyen",
        "Sathvik Suryadevara",
        "Steven Kim",
        "Mohammed F. Mohammed",
        "Yevgeniy R. Semenov",
        "Kun-Hsing Yu",
        "Abdulrhman Aljouie",
        "Hassan AlOmaish",
        "Adam Rodman",
        "Pranav Rajpurkar"
      ],
      "abstract": "We introduce RadGame, an AI-powered gamified platform for radiology education\nthat targets two core skills: localizing findings and generating reports.\nTraditional radiology training is based on passive exposure to cases or active\npractice with real-time input from supervising radiologists, limiting\nopportunities for immediate and scalable feedback. RadGame addresses this gap\nby combining gamification with large-scale public datasets and automated,\nAI-driven feedback that provides clear, structured guidance to human learners.\nIn RadGame Localize, players draw bounding boxes around abnormalities, which\nare automatically compared to radiologist-drawn annotations from public\ndatasets, and visual explanations are generated by vision-language models for\nuser missed findings. In RadGame Report, players compose findings given a chest\nX-ray, patient age and indication, and receive structured AI feedback based on\nradiology report generation metrics, highlighting errors and omissions compared\nto a radiologist's written ground truth report from public datasets, producing\na final performance and style score. In a prospective evaluation, participants\nusing RadGame achieved a 68% improvement in localization accuracy compared to\n17% with traditional passive methods and a 31% improvement in report-writing\naccuracy compared to 4% with traditional methods after seeing the same cases.\nRadGame highlights the potential of AI-driven gamification to deliver scalable,\nfeedback-rich radiology training and reimagines the application of medical AI\nresources in education.",
      "pdf_url": "http://arxiv.org/pdf/2509.13270v1",
      "published": "2025-09-16T17:27:33+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13270v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "JANUS: A Dual-Constraint Generative Framework for Stealthy Node Injection Attacks",
      "authors": [
        "Jiahao Zhang",
        "Xiaobing Pei",
        "Zhaokun Zhong",
        "Wenqiang Hao",
        "Zhenghao Tang"
      ],
      "abstract": "Graph Neural Networks (GNNs) have demonstrated remarkable performance across\nvarious applications, yet they are vulnerable to sophisticated adversarial\nattacks, particularly node injection attacks. The success of such attacks\nheavily relies on their stealthiness, the ability to blend in with the original\ngraph and evade detection. However, existing methods often achieve stealthiness\nby relying on indirect proxy metrics, lacking consideration for the fundamental\ncharacteristics of the injected content, or focusing only on imitating local\nstructures, which leads to the problem of local myopia. To overcome these\nlimitations, we propose a dual-constraint stealthy node injection framework,\ncalled Joint Alignment of Nodal and Universal Structures (JANUS). At the local\nlevel, we introduce a local feature manifold alignment strategy to achieve\ngeometric consistency in the feature space. At the global level, we incorporate\nstructured latent variables and maximize the mutual information with the\ngenerated structures, ensuring the injected structures are consistent with the\nsemantic patterns of the original graph. We model the injection attack as a\nsequential decision process, which is optimized by a reinforcement learning\nagent. Experiments on multiple standard datasets demonstrate that the JANUS\nframework significantly outperforms existing methods in terms of both attack\neffectiveness and stealthiness.",
      "pdf_url": "http://arxiv.org/pdf/2509.13266v1",
      "published": "2025-09-16T17:24:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13266v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "ResidualViT for Efficient Temporally Dense Video Encoding",
      "authors": [
        "Mattia Soldan",
        "Fabian Caba Heilbron",
        "Bernard Ghanem",
        "Josef Sivic",
        "Bryan Russell"
      ],
      "abstract": "Several video understanding tasks, such as natural language temporal video\ngrounding, temporal activity localization, and audio description generation,\nrequire \"temporally dense\" reasoning over frames sampled at high temporal\nresolution. However, computing frame-level features for these tasks is\ncomputationally expensive given the temporal resolution requirements. In this\npaper, we make three contributions to reduce the cost of computing features for\ntemporally dense tasks. First, we introduce a vision transformer (ViT)\narchitecture, dubbed ResidualViT, that leverages the large temporal redundancy\nin videos to efficiently compute temporally dense frame-level features. Our\narchitecture incorporates (i) learnable residual connections that ensure\ntemporal consistency across consecutive frames and (ii) a token reduction\nmodule that enhances processing speed by selectively discarding temporally\nredundant information while reusing weights of a pretrained foundation model.\nSecond, we propose a lightweight distillation strategy to approximate the\nframe-level features of the original foundation model. Finally, we evaluate our\napproach across four tasks and five datasets, in both zero-shot and fully\nsupervised settings, demonstrating significant reductions in computational cost\n(up to 60%) and improvements in inference speed (up to 2.5x faster), all while\nclosely approximating the accuracy of the original foundation model.",
      "pdf_url": "http://arxiv.org/pdf/2509.13255v1",
      "published": "2025-09-16T17:12:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13255v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.IR",
        "eess.IV"
      ]
    },
    {
      "title": "Metacognitive Reuse: Turning Recurring LLM Reasoning Into Concise Behaviors",
      "authors": [
        "Aniket Didolkar",
        "Nicolas Ballas",
        "Sanjeev Arora",
        "Anirudh Goyal"
      ],
      "abstract": "Large language models (LLMs) now solve multi-step problems by emitting\nextended chains of thought. During the process, they often re-derive the same\nintermediate steps across problems, inflating token usage and latency. This\nsaturation of the context window leaves less capacity for exploration. We study\na simple mechanism that converts recurring reasoning fragments into concise,\nreusable \"behaviors\" (name + instruction) via the model's own metacognitive\nanalysis of prior traces. These behaviors are stored in a \"behavior handbook\"\nwhich supplies them to the model in-context at inference or distills them into\nparameters via supervised fine-tuning. This approach achieves improved\ntest-time reasoning across three different settings - 1) Behavior-conditioned\ninference: Providing the LLM relevant behaviors in-context during reasoning\nreduces number of reasoning tokens by up to 46% while matching or improving\nbaseline accuracy; 2) Behavior-guided self-improvement: Without any parameter\nupdates, the model improves its own future reasoning by leveraging behaviors\nfrom its own past problem solving attempts. This yields up to 10% higher\naccuracy than a naive critique-and-revise baseline; and 3) Behavior-conditioned\nSFT: SFT on behavior-conditioned reasoning traces is more effective at\nconverting non-reasoning models into reasoning models as compared to vanilla\nSFT. Together, these results indicate that turning slow derivations into fast\nprocedural hints enables LLMs to remember how to reason, not just what to\nconclude.",
      "pdf_url": "http://arxiv.org/pdf/2509.13237v1",
      "published": "2025-09-16T16:44:26+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13237v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Layout-Aware OCR for Black Digital Archives with Unsupervised Evaluation",
      "authors": [
        "Fitsum Sileshi Beyene",
        "Christopher L. Dancy"
      ],
      "abstract": "Despite their cultural and historical significance, Black digital archives\ncontinue to be a structurally underrepresented area in AI research and\ninfrastructure. This is especially evident in efforts to digitize historical\nBlack newspapers, where inconsistent typography, visual degradation, and\nlimited annotated layout data hinder accurate transcription, despite the\navailability of various systems that claim to handle optical character\nrecognition (OCR) well. In this short paper, we present a layout-aware OCR\npipeline tailored for Black newspaper archives and introduce an unsupervised\nevaluation framework suited to low-resource archival contexts. Our approach\nintegrates synthetic layout generation, model pretraining on augmented data,\nand a fusion of state-of-the-art You Only Look Once (YOLO) detectors. We used\nthree annotation-free evaluation metrics, the Semantic Coherence Score (SCS),\nRegion Entropy (RE), and Textual Redundancy Score (TRS), which quantify\nlinguistic fluency, informational diversity, and redundancy across OCR regions.\nOur evaluation on a 400-page dataset from ten Black newspaper titles\ndemonstrates that layout-aware OCR improves structural diversity and reduces\nredundancy compared to full-page baselines, with modest trade-offs in\ncoherence. Our results highlight the importance of respecting cultural layout\nlogic in AI-driven document understanding and lay the foundation for future\ncommunity-driven and ethically grounded archival AI systems.",
      "pdf_url": "http://arxiv.org/pdf/2509.13236v1",
      "published": "2025-09-16T16:43:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13236v1",
      "categories": [
        "cs.DL",
        "cs.AI"
      ]
    },
    {
      "title": "A Scenario-Driven Cognitive Approach to Next-Generation AI Memory",
      "authors": [
        "Linyue Cai",
        "Yuyang Cheng",
        "Xiaoding Shao",
        "Huiming Wang",
        "Yong Zhao",
        "Wei Zhang",
        "Kang Li"
      ],
      "abstract": "As artificial intelligence advances toward artificial general intelligence\n(AGI), the need for robust and human-like memory systems has become\nincreasingly evident. Current memory architectures often suffer from limited\nadaptability, insufficient multimodal integration, and an inability to support\ncontinuous learning. To address these limitations, we propose a scenario-driven\nmethodology that extracts essential functional requirements from representative\ncognitive scenarios, leading to a unified set of design principles for\nnext-generation AI memory systems. Based on this approach, we introduce the\n\\textbf{COgnitive Layered Memory Architecture (COLMA)}, a novel framework that\nintegrates cognitive scenarios, memory processes, and storage mechanisms into a\ncohesive design. COLMA provides a structured foundation for developing AI\nsystems capable of lifelong learning and human-like reasoning, thereby\ncontributing to the pragmatic development of AGI.",
      "pdf_url": "http://arxiv.org/pdf/2509.13235v1",
      "published": "2025-09-16T16:43:07+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13235v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Simulating Clinical AI Assistance using Multimodal LLMs: A Case Study in Diabetic Retinopathy",
      "authors": [
        "Nadim Barakat",
        "William Lotter"
      ],
      "abstract": "Diabetic retinopathy (DR) is a leading cause of blindness worldwide, and AI\nsystems can expand access to fundus photography screening. Current FDA-cleared\nsystems primarily provide binary referral outputs, where this minimal output\nmay limit clinical trust and utility. Yet, determining the most effective\noutput format to enhance clinician-AI performance is an empirical challenge\nthat is difficult to assess at scale. We evaluated multimodal large language\nmodels (MLLMs) for DR detection and their ability to simulate clinical AI\nassistance across different output types. Two models were tested on IDRiD and\nMessidor-2: GPT-4o, a general-purpose MLLM, and MedGemma, an open-source\nmedical model. Experiments included: (1) baseline evaluation, (2) simulated AI\nassistance with synthetic predictions, and (3) actual AI-to-AI collaboration\nwhere GPT-4o incorporated MedGemma outputs. MedGemma outperformed GPT-4o at\nbaseline, achieving higher sensitivity and AUROC, while GPT-4o showed\nnear-perfect specificity but low sensitivity. Both models adjusted predictions\nbased on simulated AI inputs, but GPT-4o's performance collapsed with incorrect\nones, whereas MedGemma remained more stable. In actual collaboration, GPT-4o\nachieved strong results when guided by MedGemma's descriptive outputs, even\nwithout direct image access (AUROC up to 0.96). These findings suggest MLLMs\nmay improve DR screening pipelines and serve as scalable simulators for\nstudying clinical AI assistance across varying output configurations. Open,\nlightweight models such as MedGemma may be especially valuable in low-resource\nsettings, while descriptive outputs could enhance explainability and clinician\ntrust in clinical workflows.",
      "pdf_url": "http://arxiv.org/pdf/2509.13234v1",
      "published": "2025-09-16T16:42:19+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13234v1",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.HC"
      ]
    },
    {
      "title": "Single-stream Policy Optimization",
      "authors": [
        "Zhongwen Xu",
        "Zihan Ding"
      ],
      "abstract": "We revisit policy-gradient optimization for Large Language Models (LLMs) from\na single-stream perspective. Prevailing group-based methods like GRPO reduce\nvariance with on-the-fly baselines but suffer from critical flaws: frequent\ndegenerate groups erase learning signals, and synchronization barriers hinder\nscalability. We introduce Single-stream Policy Optimization (SPO), which\neliminates these issues by design. SPO replaces per-group baselines with a\npersistent, KL-adaptive value tracker and normalizes advantages globally across\nthe batch, providing a stable, low-variance learning signal for every sample.\nBeing group-free, SPO enables higher throughput and scales effectively in\nlong-horizon or tool-integrated settings where generation times vary.\nFurthermore, the persistent value tracker naturally enables an adaptive\ncurriculum via prioritized sampling. Experiments using Qwen3-8B show that SPO\nconverges more smoothly and attains higher accuracy than GRPO, while\neliminating computation wasted on degenerate groups. Ablation studies confirm\nthat SPO's gains stem from its principled approach to baseline estimation and\nadvantage normalization, offering a more robust and efficient path for LLM\nreasoning. Across five hard math benchmarks with Qwen3 8B, SPO improves the\naverage maj@32 by +3.4 percentage points (pp) over GRPO, driven by substantial\nabsolute point gains on challenging datasets, including +7.3 pp on BRUMO 25,\n+4.4 pp on AIME 25, +3.3 pp on HMMT 25, and achieves consistent relative gain\nin pass@$k$ across the evaluated $k$ values. SPO's success challenges the\nprevailing trend of adding incidental complexity to RL algorithms, highlighting\na path where fundamental principles, not architectural workarounds, drive the\nnext wave of progress in LLM reasoning.",
      "pdf_url": "http://arxiv.org/pdf/2509.13232v1",
      "published": "2025-09-16T16:39:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13232v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ]
    },
    {
      "title": "Curriculum Multi-Task Self-Supervision Improves Lightweight Architectures for Onboard Satellite Hyperspectral Image Segmentation",
      "authors": [
        "Hugo Carlesso",
        "Josiane Mothe",
        "Radu Tudor Ionescu"
      ],
      "abstract": "Hyperspectral imaging (HSI) captures detailed spectral signatures across\nhundreds of contiguous bands per pixel, being indispensable for remote sensing\napplications such as land-cover classification, change detection, and\nenvironmental monitoring. Due to the high dimensionality of HSI data and the\nslow rate of data transfer in satellite-based systems, compact and efficient\nmodels are required to support onboard processing and minimize the transmission\nof redundant or low-value data, e.g. cloud-covered areas. To this end, we\nintroduce a novel curriculum multi-task self-supervised learning (CMTSSL)\nframework designed for lightweight architectures for HSI analysis. CMTSSL\nintegrates masked image modeling with decoupled spatial and spectral jigsaw\npuzzle solving, guided by a curriculum learning strategy that progressively\nincreases data complexity during self-supervision. This enables the encoder to\njointly capture fine-grained spectral continuity, spatial structure, and global\nsemantic features. Unlike prior dual-task SSL methods, CMTSSL simultaneously\naddresses spatial and spectral reasoning within a unified and computationally\nefficient design, being particularly suitable for training lightweight models\nfor onboard satellite deployment. We validate our approach on four public\nbenchmark datasets, demonstrating consistent gains in downstream segmentation\ntasks, using architectures that are over 16,000x lighter than some\nstate-of-the-art models. These results highlight the potential of CMTSSL in\ngeneralizable representation learning with lightweight architectures for\nreal-world HSI applications. Our code is publicly available at\nhttps://github.com/hugocarlesso/CMTSSL.",
      "pdf_url": "http://arxiv.org/pdf/2509.13229v1",
      "published": "2025-09-16T16:37:59+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13229v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Rich Vehicle Routing Problem in Disaster Management enabling Temporally-causal Transhipments across Multi-Modal Transportation Network",
      "authors": [
        "Santanu Banerjee",
        "Goutam Sen",
        "Siddhartha Mukhopadhyay"
      ],
      "abstract": "A rich vehicle routing problem is considered, allowing multiple trips of\nheterogeneous vehicles stationed at geographically distributed vehicle depots\nhaving access to different modes of transportation. The problem arises from the\nreal-world requirement of optimizing the disaster response time by minimizing\nthe makespan of vehicular routes. Multiple diversely-functional vertices are\nconsidered, including Transhipment Ports as inter-modal resource transfer\nstations. Both simultaneous and split pickup and delivery are considered, for\nmultiple cargo types, along with Vehicle-Cargo and Transhipment Port-Cargo\ncompatibilities. The superiority of the proposed cascaded minimization approach\nis demonstrated over the existing makespan minimization approaches through our\ndeveloped Mixed-Integer Linear Programming formulation. To solve the problem\nquickly for practical implementation in a Disaster Management-specific Decision\nSupport System, an extensive Heuristic Algorithm is devised which utilizes\nDecision Tree based structuring of possible routes; the Decision Tree approach\nhelps to inherently capture the compatibility issues, while also explore the\nsolution space through stochastic weights. Preferential generation of small\nroute elements is performed, which are integrated into route clusters; we\nconsider multiple different logical integration approaches, as well as\nshuffling the logics to simultaneously produce multiple independent solutions.\nFinally, perturbations of the different solutions are done to find better\nneighbouring solutions. The computational performance of the PSR-GIP Heuristic,\non our created novel datasets, indicates that it is able to give good solutions\nswiftly for practical problems involving large integer instances that the MILP\nis unable to solve.",
      "pdf_url": "http://arxiv.org/pdf/2509.13227v2",
      "published": "2025-09-16T16:37:18+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13227v2",
      "categories": [
        "math.OC",
        "cs.AI",
        "cs.SY",
        "eess.SY",
        "90B06, 90B10, 90B80, 90C11, 90C06, 90C08, 90C35, 90C47, 90C59, 90C90",
        "G.2.1; G.2.2; G.2.3; F.2.2; I.2.8"
      ]
    },
    {
      "title": "G-CSEA: A Graph-Based Conflict Set Extraction Algorithm for Identifying Infeasibility in Pseudo-Boolean Models",
      "authors": [
        "Kanishk Garg",
        "Saranya D.",
        "Sanal Kumar",
        "Saurabh Singh",
        "Anupam Purwar"
      ],
      "abstract": "Workforce scheduling involves a variety of rule-based constraints-such as\nshift limits, staffing policies, working hour restrictions, and many similar\nscheduling rules-which can interact in conflicting ways, leading to infeasible\nmodels. Identifying the underlying causes of such infeasibility is critical for\nresolving scheduling issues and restoring feasibility. A common diagnostic\napproach is to compute Irreducible Infeasible Subsets (IISs): minimal sets of\nconstraints that are jointly infeasible but become feasible when any one is\nremoved. We consider models formulated using pseudo-Boolean constraints with\ninequality relations over binary variables, which naturally encode scheduling\nlogic. Existing IIS extraction methods such as Additive Deletion and\nQuickXplain rely on repeated feasibility checks, often incurring large numbers\nof solver calls. Dual ray analysis, while effective for LP-based models, may\nfail when the relaxed problem is feasible but the underlying pseudo-Boolean\nmodel is not. To address these limitations, we propose Graph-based Conflict Set\nExtraction Algorithm (G-CSEA) to extract a conflict set, an approach inspired\nby Conflict-Driven Clause Learning (CDCL) in SAT solvers. Our method constructs\nan implication graph during constraint propagation and, upon detecting a\nconflict, traces all contributing constraints across both decision branches.\nThe resulting conflict set can optionally be minimized using QuickXplain to\nproduce an IIS.",
      "pdf_url": "http://arxiv.org/pdf/2509.13203v1",
      "published": "2025-09-16T16:09:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13203v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "B-TGAT: A Bi-directional Temporal Graph Attention Transformer for Clustering Multivariate Spatiotemporal Data",
      "authors": [
        "Francis Ndikum Nji",
        "Vandana Janaja",
        "Jianwu Wang"
      ],
      "abstract": "Clustering high-dimensional multivariate spatiotemporal climate data is\nchallenging due to complex temporal dependencies, evolving spatial\ninteractions, and non-stationary dynamics. Conventional clustering methods,\nincluding recurrent and convolutional models, often struggle to capture both\nlocal and global temporal relationships while preserving spatial context. We\npresent a time-distributed hybrid U-Net autoencoder that integrates a\nBi-directional Temporal Graph Attention Transformer (B-TGAT) to guide efficient\ntemporal clustering of multidimensional spatiotemporal climate datasets. The\nencoder and decoder are equipped with ConvLSTM2D modules that extract joint\nspatial--temporal features by modeling localized dynamics and spatial\ncorrelations over time, and skip connections that preserve multiscale spatial\ndetails during feature compression and reconstruction. At the bottleneck,\nB-TGAT integrates graph-based spatial modeling with attention-driven temporal\nencoding, enabling adaptive weighting of temporal neighbors and capturing both\nshort and long-range dependencies across regions. This architecture produces\ndiscriminative latent embeddings optimized for clustering. Experiments on three\ndistinct spatiotemporal climate datasets demonstrate superior cluster\nseparability, temporal stability, and alignment with known climate transitions\ncompared to state-of-the-art baselines. The integration of ConvLSTM2D, U-Net\nskip connections, and B-TGAT enhances temporal clustering performance while\nproviding interpretable insights into complex spatiotemporal variability,\nadvancing both methodological development and climate science applications.",
      "pdf_url": "http://arxiv.org/pdf/2509.13202v1",
      "published": "2025-09-16T16:08:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13202v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Is Meta-Learning Out? Rethinking Unsupervised Few-Shot Classification with Limited Entropy",
      "authors": [
        "Yunchuan Guan",
        "Yu Liu",
        "Ke Zhou",
        "Zhiqi Shen",
        "Jenq-Neng Hwang",
        "Serge Belongie",
        "Lei Li"
      ],
      "abstract": "Meta-learning is a powerful paradigm for tackling few-shot tasks. However,\nrecent studies indicate that models trained with the whole-class training\nstrategy can achieve comparable performance to those trained with meta-learning\nin few-shot classification tasks. To demonstrate the value of meta-learning, we\nestablish an entropy-limited supervised setting for fair comparisons. Through\nboth theoretical analysis and experimental validation, we establish that\nmeta-learning has a tighter generalization bound compared to whole-class\ntraining. We unravel that meta-learning is more efficient with limited entropy\nand is more robust to label noise and heterogeneous tasks, making it\nwell-suited for unsupervised tasks. Based on these insights, We propose MINO, a\nmeta-learning framework designed to enhance unsupervised performance. MINO\nutilizes the adaptive clustering algorithm DBSCAN with a dynamic head for\nunsupervised task construction and a stability-based meta-scaler for robustness\nagainst label noise. Extensive experiments confirm its effectiveness in\nmultiple unsupervised few-shot and zero-shot tasks.",
      "pdf_url": "http://arxiv.org/pdf/2509.13185v1",
      "published": "2025-09-16T15:39:03+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13185v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "On the Correlation between Individual Fairness and Predictive Accuracy in Probabilistic Models",
      "authors": [
        "Alessandro Antonucci",
        "Eric Rossetto",
        "Ivan Duvnjak"
      ],
      "abstract": "We investigate individual fairness in generative probabilistic classifiers by\nanalysing the robustness of posterior inferences to perturbations in private\nfeatures. Building on established results in robustness analysis, we\nhypothesise a correlation between robustness and predictive accuracy,\nspecifically, instances exhibiting greater robustness are more likely to be\nclassified accurately. We empirically assess this hypothesis using a benchmark\nof fourteen datasets with fairness concerns, employing Bayesian networks as the\nunderlying generative models. To address the computational complexity\nassociated with robustness analysis over multiple private features with\nBayesian networks, we reformulate the problem as a most probable explanation\ntask in an auxiliary Markov random field. Our experiments confirm the\nhypothesis about the correlation, suggesting novel directions to mitigate the\ntraditional trade-off between fairness and accuracy.",
      "pdf_url": "http://arxiv.org/pdf/2509.13165v1",
      "published": "2025-09-16T15:17:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13165v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "FinSearchComp: Towards a Realistic, Expert-Level Evaluation of Financial Search and Reasoning",
      "authors": [
        "Liang Hu",
        "Jianpeng Jiao",
        "Jiashuo Liu",
        "Yanle Ren",
        "Zhoufutu Wen",
        "Kaiyuan Zhang",
        "Xuanliang Zhang",
        "Xiang Gao",
        "Tianci He",
        "Fei Hu",
        "Yali Liao",
        "Zaiyuan Wang",
        "Chenghao Yang",
        "Qianyu Yang",
        "Mingren Yin",
        "Zhiyuan Zeng",
        "Ge Zhang",
        "Xinyi Zhang",
        "Xiying Zhao",
        "Zhenwei Zhu",
        "Hongseok Namkoong",
        "Wenhao Huang",
        "Yuwen Tang"
      ],
      "abstract": "Search has emerged as core infrastructure for LLM-based agents and is widely\nviewed as critical on the path toward more general intelligence. Finance is a\nparticularly demanding proving ground: analysts routinely conduct complex,\nmulti-step searches over time-sensitive, domain-specific data, making it ideal\nfor assessing both search proficiency and knowledge-grounded reasoning. Yet no\nexisting open financial datasets evaluate data searching capability of\nend-to-end agents, largely because constructing realistic, complicated tasks\nrequires deep financial expertise and time-sensitive data is hard to evaluate.\nWe present FinSearchComp, the first fully open-source agent benchmark for\nrealistic, open-domain financial search and reasoning. FinSearchComp comprises\nthree tasks -- Time-Sensitive Data Fetching, Simple Historical Lookup, and\nComplex Historical Investigation -- closely reproduce real-world financial\nanalyst workflows. To ensure difficulty and reliability, we engage 70\nprofessional financial experts for annotation and implement a rigorous\nmulti-stage quality-assurance pipeline. The benchmark includes 635 questions\nspanning global and Greater China markets, and we evaluate 21 models (products)\non it. Grok 4 (web) tops the global subset, approaching expert-level accuracy.\nDouBao (web) leads on the Greater China subset. Experimental analyses show that\nequipping agents with web search and financial plugins substantially improves\nresults on FinSearchComp, and the country origin of models and tools impact\nperformance significantly.By aligning with realistic analyst tasks and\nproviding end-to-end evaluation, FinSearchComp offers a professional,\nhigh-difficulty testbed for complex financial search and reasoning.",
      "pdf_url": "http://arxiv.org/pdf/2509.13160v1",
      "published": "2025-09-16T15:13:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13160v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Agentic AI for Financial Crime Compliance",
      "authors": [
        "Henrik Axelsen",
        "Valdemar Licht",
        "Jan Damsgaard"
      ],
      "abstract": "The cost and complexity of financial crime compliance (FCC) continue to rise,\noften without measurable improvements in effectiveness. While AI offers\npotential, most solutions remain opaque and poorly aligned with regulatory\nexpectations. This paper presents the design and deployment of an agentic AI\nsystem for FCC in digitally native financial platforms. Developed through an\nAction Design Research (ADR) process with a fintech firm and regulatory\nstakeholders, the system automates onboarding, monitoring, investigation, and\nreporting, emphasizing explainability, traceability, and compliance-by-design.\nUsing artifact-centric modeling, it assigns clearly bounded roles to autonomous\nagents and enables task-specific model routing and audit logging. The\ncontribution includes a reference architecture, a real-world prototype, and\ninsights into how Agentic AI can reconfigure FCC workflows under regulatory\nconstraints. Our findings extend IS literature on AI-enabled compliance by\ndemonstrating how automation, when embedded within accountable governance\nstructures, can support transparency and institutional trust in high-stakes,\nregulated environments.",
      "pdf_url": "http://arxiv.org/pdf/2509.13137v1",
      "published": "2025-09-16T14:53:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13137v1",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.MA",
        "K.4.4; K.6.5; I.2.11"
      ]
    },
    {
      "title": "An Uncertainty-Weighted Decision Transformer for Navigation in Dense, Complex Driving Scenarios",
      "authors": [
        "Zhihao Zhang",
        "Chengyang Peng",
        "Minghao Zhu",
        "Ekim Yurtsever",
        "Keith A. Redmill"
      ],
      "abstract": "Autonomous driving in dense, dynamic environments requires decision-making\nsystems that can exploit both spatial structure and long-horizon temporal\ndependencies while remaining robust to uncertainty. This work presents a novel\nframework that integrates multi-channel bird's-eye-view occupancy grids with\ntransformer-based sequence modeling for tactical driving in complex roundabout\nscenarios. To address the imbalance between frequent low-risk states and rare\nsafety-critical decisions, we propose the Uncertainty-Weighted Decision\nTransformer (UWDT). UWDT employs a frozen teacher transformer to estimate\nper-token predictive entropy, which is then used as a weight in the student\nmodel's loss function. This mechanism amplifies learning from uncertain,\nhigh-impact states while maintaining stability across common low-risk\ntransitions. Experiments in a roundabout simulator, across varying traffic\ndensities, show that UWDT consistently outperforms other baselines in terms of\nreward, collision rate, and behavioral stability. The results demonstrate that\nuncertainty-aware, spatial-temporal transformers can deliver safer and more\nefficient decision-making for autonomous driving in complex traffic\nenvironments.",
      "pdf_url": "http://arxiv.org/pdf/2509.13132v1",
      "published": "2025-09-16T14:48:52+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13132v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "Reasoning with Preference Constraints: A Benchmark for Language Models in Many-to-One Matching Markets",
      "authors": [
        "Marylou Fauchard",
        "Florian Carichon",
        "Margarida Carvalho",
        "Golnoosh Farnadi"
      ],
      "abstract": "Recent advances in reasoning with large language models (LLMs) have\ndemonstrated strong performance on complex mathematical tasks, including\ncombinatorial optimization. Techniques such as Chain-of-Thought and In-Context\nLearning have further enhanced this capability, making LLMs both powerful and\naccessible tools for a wide range of users, including non-experts. However,\napplying LLMs to matching problems, which require reasoning under preferential\nand structural constraints, remains underexplored. To address this gap, we\nintroduce a novel benchmark of 369 instances of the College Admission Problem,\na canonical example of a matching problem with preferences, to evaluate LLMs\nacross key dimensions: feasibility, stability, and optimality. We employ this\nbenchmark to assess the performance of several open-weight LLMs. Our results\nfirst reveal that while LLMs can satisfy certain constraints, they struggle to\nmeet all evaluation criteria consistently. They also show that reasoning LLMs,\nlike QwQ and GPT-oss, significantly outperform traditional models such as\nLlama, Qwen or Mistral, defined here as models used without any dedicated\nreasoning mechanisms. Moreover, we observed that LLMs reacted differently to\nthe various prompting strategies tested, which include Chain-of-Thought,\nIn-Context Learning and role-based prompting, with no prompt consistently\noffering the best performance. Finally, we report the performances from\niterative prompting with auto-generated feedback and show that they are not\nmonotonic; they can peak early and then significantly decline in later\nattempts. Overall, this work offers a new perspective on model reasoning\nperformance and the effectiveness of prompting strategies in combinatorial\noptimization problems with preferential constraints.",
      "pdf_url": "http://arxiv.org/pdf/2509.13131v1",
      "published": "2025-09-16T14:48:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13131v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Hierarchical Deep Fusion Framework for Multi-dimensional Facial Forgery Detection -- The 2024 Global Deepfake Image Detection Challenge",
      "authors": [
        "Kohou Wang",
        "Huan Hu",
        "Xiang Liu",
        "Zezhou Chen",
        "Ping Chen",
        "Zhaoxiang Liu",
        "Shiguo Lian"
      ],
      "abstract": "The proliferation of sophisticated deepfake technology poses significant\nchallenges to digital security and authenticity. Detecting these forgeries,\nespecially across a wide spectrum of manipulation techniques, requires robust\nand generalized models. This paper introduces the Hierarchical Deep Fusion\nFramework (HDFF), an ensemble-based deep learning architecture designed for\nhigh-performance facial forgery detection. Our framework integrates four\ndiverse pre-trained sub-models, Swin-MLP, CoAtNet, EfficientNetV2, and DaViT,\nwhich are meticulously fine-tuned through a multi-stage process on the\nMultiFFDI dataset. By concatenating the feature representations from these\nspecialized models and training a final classifier layer, HDFF effectively\nleverages their collective strengths. This approach achieved a final score of\n0.96852 on the competition's private leaderboard, securing the 20th position\nout of 184 teams, demonstrating the efficacy of hierarchical fusion for complex\nimage classification tasks.",
      "pdf_url": "http://arxiv.org/pdf/2509.13107v1",
      "published": "2025-09-16T14:06:54+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13107v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Shaping Explanations: Semantic Reward Modeling with Encoder-Only Transformers for GRPO",
      "authors": [
        "Francesco Pappone",
        "Ruggero Marino Lazzaroni",
        "Federico Califano",
        "Niccolò Gentile",
        "Roberto Marras"
      ],
      "abstract": "While Large Language Models (LLMs) excel at generating human-like text,\naligning their outputs with complex, qualitative goals like pedagogical\nsoundness remains a significant challenge. Standard reinforcement learning\ntechniques often rely on slow and expensive LLM-as-a-judge evaluations or on\nbrittle, keyword-based metrics like ROUGE, which fail to capture the semantic\nessence of a high-quality explanation. In this work, we introduce a novel\napproach to reward shaping within the Group Relative Policy Optimisation (GRPO)\nframework. Our central contribution is the use of a small, efficient\nencoder-only transformer as a semantic reward model. This model provides a\ndense, semantically rich reward signal based on the cosine similarity between a\ngenerated explanation and a ground-truth reference, guiding the policy towards\nexplanations that are not just factually correct but also structurally and\nconceptually aligned with expert reasoning. We apply this method to the task of\ntraining a model for the Italian medical-school entrance examinations,\nfollowing standard domain-adaptive continued pre-training (CPT) and supervised\nfine-tuning (SFT). Our results demonstrate that GRPO with our proposed semantic\nreward significantly improves explanation faithfulness and clarity over a\nstrong SFT baseline, showcasing the power of using lightweight encoder models\nfor nuanced reward shaping in complex generation tasks",
      "pdf_url": "http://arxiv.org/pdf/2509.13081v1",
      "published": "2025-09-16T13:39:29+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13081v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "A Design Co-Pilot for Task-Tailored Manipulators",
      "authors": [
        "Jonathan Külz",
        "Sehoon Ha",
        "Matthias Althoff"
      ],
      "abstract": "Although robotic manipulators are used in an ever-growing range of\napplications, robot manufacturers typically follow a ``one-fits-all''\nphilosophy, employing identical manipulators in various settings. This often\nleads to suboptimal performance, as general-purpose designs fail to exploit\nparticularities of tasks. The development of custom, task-tailored robots is\nhindered by long, cost-intensive development cycles and the high cost of\ncustomized hardware. Recently, various computational design methods have been\ndevised to overcome the bottleneck of human engineering. In addition, a surge\nof modular robots allows quick and economical adaptation to changing industrial\nsettings. This work proposes an approach to automatically designing and\noptimizing robot morphologies tailored to a specific environment. To this end,\nwe learn the inverse kinematics for a wide range of different manipulators. A\nfully differentiable framework realizes gradient-based fine-tuning of designed\nrobots and inverse kinematics solutions. Our generative approach accelerates\nthe generation of specialized designs from hours with optimization-based\nmethods to seconds, serving as a design co-pilot that enables instant\nadaptation and effective human-AI collaboration. Numerical experiments show\nthat our approach finds robots that can navigate cluttered environments,\nmanipulators that perform well across a specified workspace, and can be adapted\nto different hardware constraints. Finally, we demonstrate the real-world\napplicability of our method by setting up a modular robot designed in\nsimulation that successfully moves through an obstacle course.",
      "pdf_url": "http://arxiv.org/pdf/2509.13077v1",
      "published": "2025-09-16T13:34:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13077v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "TFANet: Three-Stage Image-Text Feature Alignment Network for Robust Referring Image Segmentation",
      "authors": [
        "Qianqi Lu",
        "Yuxiang Xie",
        "Jing Zhang",
        "Shiwei Zou",
        "Yan Chen",
        "Xidao Luan"
      ],
      "abstract": "Referring Image Segmentation (RIS) is a task that segments image regions\nbased on language expressions, requiring fine-grained alignment between two\nmodalities. However, existing methods often struggle with multimodal\nmisalignment and language semantic loss, especially in complex scenes\ncontaining multiple visually similar objects, where uniquely described targets\nare frequently mislocalized or incompletely segmented. To tackle these\nchallenges, this paper proposes TFANet, a Three-stage Image-Text Feature\nAlignment Network that systematically enhances multimodal alignment through a\nhierarchical framework comprising three stages: Knowledge Plus Stage (KPS),\nKnowledge Fusion Stage (KFS), and Knowledge Intensification Stage (KIS). In the\nfirst stage, we design the Multiscale Linear Cross-Attention Module (MLAM),\nwhich facilitates bidirectional semantic exchange between visual features and\ntextual representations across multiple scales. This establishes rich and\nefficient alignment between image regions and different granularities of\nlinguistic descriptions. Subsequently, the KFS further strengthens feature\nalignment through the Cross-modal Feature Scanning Module (CFSM), which applies\nmultimodal selective scanning to capture long-range dependencies and construct\na unified multimodal representation. This is essential for modeling long-range\ncross-modal dependencies and enhancing alignment accuracy in complex scenes.\nFinally, in the KIS, we propose the Word-level Linguistic Feature-guided\nSemantic Deepening Module (WFDM) to compensate for semantic degradation\nintroduced in earlier stages.",
      "pdf_url": "http://arxiv.org/pdf/2509.13070v1",
      "published": "2025-09-16T13:26:58+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13070v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Multi-Model Synthetic Training for Mission-Critical Small Language Models",
      "authors": [
        "Nolan Platt",
        "Pragyansmita Nayak"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities across\nmany domains, yet their application to specialized fields remains constrained\nby the scarcity and complexity of domain-specific training data. We present a\nnovel approach that achieves a 261x cost reduction for maritime intelligence by\nusing LLMs as one-time teachers rather than using them directly for inference.\nOur method transforms 3.2 billion Automatic Identification System (AIS) vessel\ntracking records into 21,543 synthetic question and answer pairs through\nmulti-model generation (GPT-4o and o3-mini), preventing overfitting and\nensuring accurate reasoning. The resulting fine-tuned Qwen2.5-7B model achieves\n75% accuracy on maritime tasks, while being substantially cheaper than using a\nlarger model for inference. We show that smaller, cheaper models -- when fine\ntuned properly -- can provide similar accuracy compared to larger models that\nare prohibitively expensive. Our work contributes to the growing field of\nsynthetic dataset generation for specialized AI applications and presents a\nhighly reproducible framework for domains where manual annotation is\ninfeasible. Beyond expanding research in the growing field of specialized small\nlanguage models, our approach has immediate applications in maritime safety,\nsecurity operations, and vessel traffic management systems in various\nindustries.",
      "pdf_url": "http://arxiv.org/pdf/2509.13047v1",
      "published": "2025-09-16T13:04:48+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13047v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "68T50 68T50",
        "I.2.7; I.2.6"
      ]
    },
    {
      "title": "MIA-EPT: Membership Inference Attack via Error Prediction for Tabular Data",
      "authors": [
        "Eyal German",
        "Daniel Samira",
        "Yuval Elovici",
        "Asaf Shabtai"
      ],
      "abstract": "Synthetic data generation plays an important role in enabling data sharing,\nparticularly in sensitive domains like healthcare and finance. Recent advances\nin diffusion models have made it possible to generate realistic, high-quality\ntabular data, but they may also memorize training records and leak sensitive\ninformation. Membership inference attacks (MIAs) exploit this vulnerability by\ndetermining whether a record was used in training. While MIAs have been studied\nin images and text, their use against tabular diffusion models remains\nunderexplored despite the unique risks of structured attributes and limited\nrecord diversity. In this paper, we introduce MIAEPT, Membership Inference\nAttack via Error Prediction for Tabular Data, a novel black-box attack\nspecifically designed to target tabular diffusion models. MIA-EPT constructs\nerrorbased feature vectors by masking and reconstructing attributes of target\nrecords, disclosing membership signals based on how well these attributes are\npredicted. MIA-EPT operates without access to the internal components of the\ngenerative model, relying only on its synthetic data output, and was shown to\ngeneralize across multiple state-of-the-art diffusion models. We validate\nMIA-EPT on three diffusion-based synthesizers, achieving AUC-ROC scores of up\nto 0.599 and TPR@10% FPR values of 22.0% in our internal tests. Under the MIDST\n2025 competition conditions, MIA-EPT achieved second place in the Black-box\nMulti-Table track (TPR@10% FPR = 20.0%). These results demonstrate that our\nmethod can uncover substantial membership leakage in synthetic tabular data,\nchallenging the assumption that synthetic data is inherently\nprivacy-preserving. Our code is publicly available at\nhttps://github.com/eyalgerman/MIA-EPT.",
      "pdf_url": "http://arxiv.org/pdf/2509.13046v1",
      "published": "2025-09-16T13:03:54+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13046v1",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "title": "Introducing the A2AJ's Canadian Legal Data: An open-source alternative to CanLII for the era of computational law",
      "authors": [
        "Simon Wallace",
        "Sean Rehaag"
      ],
      "abstract": "The Access to Algorithmic Justice project (A2AJ) is an open-source\nalternative to the Canadian Legal Information Institute (CanLII). At a moment\nwhen technology promises to enable new ways of working with law, CanLII is\nbecoming an impediment to the free access of law and access to justice\nmovements because it restricts bulk and programmatic access to Canadian legal\ndata. This means that Canada is staring down a digital divide: well-resourced\nactors have the best new technological tools and, because CanLII has disclaimed\nleadership, the public only gets second-rate tools. This article puts CanLII in\nits larger historical context and shows how long and deep efforts to\ndemocratize access to Canadian legal data are, and how often they are thwarted\nby private industry. We introduce the A2AJ's Canadian Legal Data project, which\nprovides open access to over 116,000 court decisions and 5,000 statutes through\nmultiple channels including APIs, machine learning datasets, and AI integration\nprotocols. Through concrete examples, we demonstrate how open legal data\nenables courts to conduct evidence-based assessments and allows developers to\ncreate tools for practitioners serving low-income communities.",
      "pdf_url": "http://arxiv.org/pdf/2509.13032v1",
      "published": "2025-09-16T12:51:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13032v1",
      "categories": [
        "cs.CY",
        "cs.AI"
      ]
    },
    {
      "title": "Perception Before Reasoning: Two-Stage Reinforcement Learning for Visual Reasoning in Vision-Language Models",
      "authors": [
        "Yan Chen",
        "Long Li",
        "Teng Xi",
        "Long Zeng",
        "Jingdong Wang"
      ],
      "abstract": "Reinforcement learning (RL) has proven highly effective in eliciting the\nreasoning capabilities of large language models (LLMs). Inspired by this\nsuccess, recent studies have explored applying similar techniques to\nvision-language models (VLMs), aiming to enhance their reasoning performance.\nHowever, directly transplanting RL methods from LLMs to VLMs is suboptimal, as\nthe tasks faced by VLMs are inherently more complex. Specifically, VLMs must\nfirst accurately perceive and understand visual inputs before reasoning can be\neffectively performed. To address this challenge, we propose a two-stage\nreinforcement learning framework designed to jointly enhance both the\nperceptual and reasoning capabilities of VLMs. To mitigate the vanishing\nadvantage issue commonly observed in RL training, we first perform\ndataset-level sampling to selectively strengthen specific capabilities using\ndistinct data sources. During training, the first stage focuses on improving\nthe model's visual perception through coarse- and fine-grained visual\nunderstanding, while the second stage targets the enhancement of reasoning\nabilities. After the proposed two-stage reinforcement learning process, we\nobtain PeBR-R1, a vision-language model with significantly enhanced perceptual\nand reasoning capabilities. Experimental results on seven benchmark datasets\ndemonstrate the effectiveness of our approach and validate the superior\nperformance of PeBR-R1 across diverse visual reasoning tasks.",
      "pdf_url": "http://arxiv.org/pdf/2509.13031v1",
      "published": "2025-09-16T12:51:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13031v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "GView: A Survey of Binary Forensics via Visual, Semantic, and AI-Enhanced Analysis",
      "authors": [
        "Raul Zaharia",
        "Dragoş Gavriluţ",
        "Gheorghiţă Mutu"
      ],
      "abstract": "Cybersecurity threats continue to become more sophisticated and diverse in\ntheir artifacts, boosting both their volume and complexity. To overcome those\nchallenges, we present GView, an open-source forensic analysis framework with\nvisual and AI-enhanced reasoning. It started with focus on the practical\ncybersecurity industry. It has evolved significantly, incorporating large\nlanguage models (LLMs) to dynamically enhance reasoning and ease the forensic\nworkflows. This paper surveys both the current state of GView with its\npublished papers alongside those that are in the publishing process. It also\nincludes its innovative use of logical inference through predicates and\ninference rules for both the analyzed documents and the user's actions for\nbetter suggestions. We highlight the extensible architecture, showcasing its\npotential as a bridge between the practical forensics worlds with the academic\nresearch.",
      "pdf_url": "http://arxiv.org/pdf/2509.13025v1",
      "published": "2025-09-16T12:46:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13025v1",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "Validating Solidity Code Defects using Symbolic and Concrete Execution powered by Large Language Models",
      "authors": [
        "Ştefan-Claudiu Susan",
        "Andrei Arusoaie",
        "Dorel Lucanu"
      ],
      "abstract": "The high rate of false alarms from static analysis tools and Large Language\nModels (LLMs) complicates vulnerability detection in Solidity Smart Contracts,\ndemanding methods that can formally or empirically prove the presence of\ndefects. This paper introduces a novel detection pipeline that integrates\ncustom Slither-based detectors, LLMs, Kontrol, and Forge. Our approach is\ndesigned to reliably detect defects and generate proofs. We currently perform\nexperiments with promising results for seven types of critical defects. We\ndemonstrate the pipeline's efficacy by presenting our findings for three\nvulnerabilities -- Reentrancy, Complex Fallback, and Faulty Access Control\nPolicies -- that are challenging for current verification solutions, which\noften generate false alarms or fail to detect them entirely. We highlight the\npotential of either symbolic or concrete execution in correctly classifying\nsuch code faults. By chaining these instruments, our method effectively\nvalidates true positives, significantly reducing the manual verification\nburden. Although we identify potential limitations, such as the inconsistency\nand the cost of LLMs, our findings establish a robust framework for combining\nheuristic analysis with formal verification to achieve more reliable and\nautomated smart contract auditing.",
      "pdf_url": "http://arxiv.org/pdf/2509.13023v1",
      "published": "2025-09-16T12:46:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13023v1",
      "categories": [
        "cs.SE",
        "cs.AI",
        "I.2.2;D.2.5;D.2.4;D.4.6"
      ]
    },
    {
      "title": "xOffense: An AI-driven autonomous penetration testing framework with offensive knowledge-enhanced LLMs and multi agent systems",
      "authors": [
        "Phung Duc Luong",
        "Le Tran Gia Bao",
        "Nguyen Vu Khai Tam",
        "Dong Huu Nguyen Khoa",
        "Nguyen Huu Quyen",
        "Van-Hau Pham",
        "Phan The Duy"
      ],
      "abstract": "This work introduces xOffense, an AI-driven, multi-agent penetration testing\nframework that shifts the process from labor-intensive, expert-driven manual\nefforts to fully automated, machine-executable workflows capable of scaling\nseamlessly with computational infrastructure. At its core, xOffense leverages a\nfine-tuned, mid-scale open-source LLM (Qwen3-32B) to drive reasoning and\ndecision-making in penetration testing. The framework assigns specialized\nagents to reconnaissance, vulnerability scanning, and exploitation, with an\norchestration layer ensuring seamless coordination across phases. Fine-tuning\non Chain-of-Thought penetration testing data further enables the model to\ngenerate precise tool commands and perform consistent multi-step reasoning. We\nevaluate xOffense on two rigorous benchmarks: AutoPenBench and\nAI-Pentest-Benchmark. The results demonstrate that xOffense consistently\noutperforms contemporary methods, achieving a sub-task completion rate of\n79.17%, decisively surpassing leading systems such as VulnBot and PentestGPT.\nThese findings highlight the potential of domain-adapted mid-scale LLMs, when\nembedded within structured multi-agent orchestration, to deliver superior,\ncost-efficient, and reproducible solutions for autonomous penetration testing.",
      "pdf_url": "http://arxiv.org/pdf/2509.13021v1",
      "published": "2025-09-16T12:45:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13021v1",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "title": "A Visualized Framework for Event Cooperation with Generative Agents",
      "authors": [
        "Yuyang Tian",
        "Shunqiang Mao",
        "Wenchang Gao",
        "Lanlan Qiu",
        "Tianxing He"
      ],
      "abstract": "Large Language Models (LLMs) have revolutionized the simulation of agent\nsocieties, enabling autonomous planning, memory formation, and social\ninteractions. However, existing frameworks often overlook systematic\nevaluations for event organization and lack visualized integration with\nphysically grounded environments, limiting agents' ability to navigate spaces\nand interact with items realistically. We develop MiniAgentPro, a visualization\nplatform featuring an intuitive map editor for customizing environments and a\nsimulation player with smooth animations. Based on this tool, we introduce a\ncomprehensive test set comprising eight diverse event scenarios with basic and\nhard variants to assess agents' ability. Evaluations using GPT-4o demonstrate\nstrong performance in basic settings but highlight coordination challenges in\nhard variants.",
      "pdf_url": "http://arxiv.org/pdf/2509.13011v1",
      "published": "2025-09-16T12:33:54+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13011v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Data-driven Methods of Extracting Text Structure and Information Transfer",
      "authors": [
        "Shinichi Honna",
        "Taichi Murayama",
        "Akira Matsui"
      ],
      "abstract": "The Anna Karenina Principle (AKP) holds that success requires satisfying a\nsmall set of essential conditions, whereas failure takes diverse forms. We test\nAKP, its reverse, and two further patterns described as ordered and noisy\nacross novels, online encyclopedias, research papers, and movies. Texts are\nrepresented as sequences of functional blocks, and convergence is assessed in\ntransition order and position. Results show that structural principles vary by\nmedium: novels follow reverse AKP in order, Wikipedia combines AKP with ordered\npatterns, academic papers display reverse AKP in order but remain noisy in\nposition, and movies diverge by genre. Success therefore depends on structural\nconstraints that are specific to each medium, while failure assumes different\nshapes across domains.",
      "pdf_url": "http://arxiv.org/pdf/2509.12999v1",
      "published": "2025-09-16T12:13:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.12999v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Bridging Performance Gaps for Foundation Models: A Post-Training Strategy for ECGFounder",
      "authors": [
        "Ya Zhou",
        "Yujie Yang",
        "Xiaohan Fan",
        "Wei Zhao"
      ],
      "abstract": "ECG foundation models are increasingly popular due to their adaptability\nacross various tasks. However, their clinical applicability is often limited by\nperformance gaps compared to task-specific models, even after pre-training on\nlarge ECG datasets and fine-tuning on target data. This limitation is likely\ndue to the lack of an effective post-training strategy. In this paper, we\npropose a simple yet effective post-training approach to enhance ECGFounder, a\nstate-of-the-art ECG foundation model pre-trained on over 7 million ECG\nrecordings. Experiments on the PTB-XL benchmark show that our approach improves\nthe baseline fine-tuning strategy by 1.2%-3.3% in macro AUROC and 5.3%-20.9% in\nmacro AUPRC. Additionally, our method outperforms several recent\nstate-of-the-art approaches, including task-specific and advanced\narchitectures. Further evaluation reveals that our method is more stable and\nsample-efficient compared to the baseline, achieving a 9.1% improvement in\nmacro AUROC and a 34.9% improvement in macro AUPRC using just 10% of the\ntraining data. Ablation studies identify key components, such as stochastic\ndepth and preview linear probing, that contribute to the enhanced performance.\nThese findings underscore the potential of post-training strategies to improve\nECG foundation models, and we hope this work will contribute to the continued\ndevelopment of foundation models in the ECG domain.",
      "pdf_url": "http://arxiv.org/pdf/2509.12991v1",
      "published": "2025-09-16T12:02:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.12991v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.AP"
      ]
    },
    {
      "title": "Dual-Stage Reweighted MoE for Long-Tailed Egocentric Mistake Detection",
      "authors": [
        "Boyu Han",
        "Qianqian Xu",
        "Shilong Bao",
        "Zhiyong Yang",
        "Sicong Li",
        "Qingming Huang"
      ],
      "abstract": "In this report, we address the problem of determining whether a user performs\nan action incorrectly from egocentric video data. To handle the challenges\nposed by subtle and infrequent mistakes, we propose a Dual-Stage Reweighted\nMixture-of-Experts (DR-MoE) framework. In the first stage, features are\nextracted using a frozen ViViT model and a LoRA-tuned ViViT model, which are\ncombined through a feature-level expert module. In the second stage, three\nclassifiers are trained with different objectives: reweighted cross-entropy to\nmitigate class imbalance, AUC loss to improve ranking under skewed\ndistributions, and label-aware loss with sharpness-aware minimization to\nenhance calibration and generalization. Their predictions are fused using a\nclassification-level expert module. The proposed method achieves strong\nperformance, particularly in identifying rare and ambiguous mistake instances.\nThe code is available at https://github.com/boyuh/DR-MoE.",
      "pdf_url": "http://arxiv.org/pdf/2509.12990v1",
      "published": "2025-09-16T12:00:42+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.12990v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Toward PDDL Planning Copilot",
      "authors": [
        "Yarin Benyamin",
        "Argaman Mordoch",
        "Shahaf S. Shperberg",
        "Roni Stern"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly being used as autonomous agents\ncapable of performing complicated tasks. However, they lack the ability to\nperform reliable long-horizon planning on their own. This paper bridges this\ngap by introducing the Planning Copilot, a chatbot that integrates multiple\nplanning tools and allows users to invoke them through instructions in natural\nlanguage. The Planning Copilot leverages the Model Context Protocol (MCP), a\nrecently developed standard for connecting LLMs with external tools and\nsystems. This approach allows using any LLM that supports MCP without\ndomain-specific fine-tuning. Our Planning Copilot supports common planning\ntasks such as checking the syntax of planning problems, selecting an\nappropriate planner, calling it, validating the plan it generates, and\nsimulating their execution. We empirically evaluate the ability of our Planning\nCopilot to perform these tasks using three open-source LLMs. The results show\nthat the Planning Copilot highly outperforms using the same LLMs without the\nplanning tools. We also conducted a limited qualitative comparison of our tool\nagainst Chat GPT-5, a very recent commercial LLM. Our results shows that our\nPlanning Copilot significantly outperforms GPT-5 despite relying on a much\nsmaller LLM. This suggests dedicated planning tools may be an effective way to\nenable LLMs to perform planning tasks.",
      "pdf_url": "http://arxiv.org/pdf/2509.12987v1",
      "published": "2025-09-16T11:51:07+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.12987v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Out of Distribution Detection in Self-adaptive Robots with AI-powered Digital Twins",
      "authors": [
        "Erblin Isaku",
        "Hassan Sartaj",
        "Shaukat Ali",
        "Beatriz Sanguino",
        "Tongtong Wang",
        "Guoyuan Li",
        "Houxiang Zhang",
        "Thomas Peyrucain"
      ],
      "abstract": "Self-adaptive robots (SARs) in complex, uncertain environments must\nproactively detect and address abnormal behaviors, including\nout-of-distribution (OOD) cases. To this end, digital twins offer a valuable\nsolution for OOD detection. Thus, we present a digital twin-based approach for\nOOD detection (ODiSAR) in SARs. ODiSAR uses a Transformer-based digital twin to\nforecast SAR states and employs reconstruction error and Monte Carlo dropout\nfor uncertainty quantification. By combining reconstruction error with\npredictive variance, the digital twin effectively detects OOD behaviors, even\nin previously unseen conditions. The digital twin also includes an\nexplainability layer that links potential OOD to specific SAR states, offering\ninsights for self-adaptation. We evaluated ODiSAR by creating digital twins of\ntwo industrial robots: one navigating an office environment, and another\nperforming maritime ship navigation. In both cases, ODiSAR forecasts SAR\nbehaviors (i.e., robot trajectories and vessel motion) and proactively detects\nOOD events. Our results showed that ODiSAR achieved high detection performance\n-- up to 98\\% AUROC, 96\\% TNR@TPR95, and 95\\% F1-score -- while providing\ninterpretable insights to support self-adaptation.",
      "pdf_url": "http://arxiv.org/pdf/2509.12982v1",
      "published": "2025-09-16T11:43:47+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.12982v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SE"
      ]
    },
    {
      "title": "Investigating ReLoRA: Effects on the Learning Dynamics of Small Language Models",
      "authors": [
        "Yuval Weiss",
        "David Demitri Africa",
        "Paula Buttery",
        "Richard Diehl Martinez"
      ],
      "abstract": "Parameter-efficient methods such as LoRA have revolutionised the fine-tuning\nof LLMs. Still, their extension to pretraining via ReLoRA is less well\nunderstood, especially for small language models (SLMs), which offer lower\ncomputational and environmental costs. This work is the first systematic study\nof ReLoRA in SLMs (11M-66M parameters), evaluating both performance and\nlearning dynamics. Through ablation experiments, we find that ReLoRA generally\nperforms worse than standard training on loss, Paloma perplexity and BLiMP,\nwith the gap widening for the larger models. Further analysis of the learning\ndynamics of the models indicates that ReLoRA reinforces the rank deficiencies\nfound in smaller models. These results indicate that low-rank update strategies\nmay not transfer easily to SLM pretraining, highlighting the need for more\nresearch in the low-compute regime.",
      "pdf_url": "http://arxiv.org/pdf/2509.12960v1",
      "published": "2025-09-16T11:06:58+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.12960v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Forget What's Sensitive, Remember What Matters: Token-Level Differential Privacy in Memory Sculpting for Continual Learning",
      "authors": [
        "Bihao Zhan",
        "Jie Zhou",
        "Junsong Li",
        "Yutao Yang",
        "Shilian Chen",
        "Qianjun Pan",
        "Xin Li",
        "Wen Wu",
        "Xingjiao Wu",
        "Qin Chen",
        "Hang Yan",
        "Liang He"
      ],
      "abstract": "Continual Learning (CL) models, while adept at sequential knowledge\nacquisition, face significant and often overlooked privacy challenges due to\naccumulating diverse information. Traditional privacy methods, like a uniform\nDifferential Privacy (DP) budget, indiscriminately protect all data, leading to\nsubstantial model utility degradation and hindering CL deployment in\nprivacy-sensitive areas. To overcome this, we propose a privacy-enhanced\ncontinual learning (PeCL) framework that forgets what's sensitive and remembers\nwhat matters. Our approach first introduces a token-level dynamic Differential\nPrivacy strategy that adaptively allocates privacy budgets based on the\nsemantic sensitivity of individual tokens. This ensures robust protection for\nprivate entities while minimizing noise injection for non-sensitive, general\nknowledge. Second, we integrate a privacy-guided memory sculpting module. This\nmodule leverages the sensitivity analysis from our dynamic DP mechanism to\nintelligently forget sensitive information from the model's memory and\nparameters, while explicitly preserving the task-invariant historical knowledge\ncrucial for mitigating catastrophic forgetting. Extensive experiments show that\nPeCL achieves a superior balance between privacy preserving and model utility,\noutperforming baseline models by maintaining high accuracy on previous tasks\nwhile ensuring robust privacy.",
      "pdf_url": "http://arxiv.org/pdf/2509.12958v1",
      "published": "2025-09-16T11:01:59+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.12958v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Black-box Model Merging for Language-Model-as-a-Service with Massive Model Repositories",
      "authors": [
        "Shilian Chen",
        "Jie Zhou",
        "Tianyu Huai",
        "Yujiang Lu",
        "Junsong Li",
        "Bihao Zhan",
        "Qianjun Pan",
        "Yutao Yang",
        "Xin Li",
        "Qin Chen",
        "Hang Yan",
        "Liang He"
      ],
      "abstract": "Model merging refers to the process of integrating multiple distinct models\ninto a unified model that preserves and combines the strengths and capabilities\nof the individual models. Most existing approaches rely on task vectors to\ncombine models, typically under the assumption that model parameters are\naccessible. However, for extremely large language models (LLMs) such as GPT-4,\nwhich are often provided solely as black-box services through API interfaces\n(Language-Model-as-a-Service), model weights are not available to end users.\nThis presents a significant challenge, which we refer to as black-box model\nmerging (BMM) with massive LLMs. To address this challenge, we propose a\nderivative-free optimization framework based on the evolutionary algorithm\n(Evo-Merging) that enables effective model merging using only inference-time\nAPI queries. Our method consists of two key components: (1) sparsity-based\ndenoising, designed to identify and filter out irrelevant or redundant\ninformation across models, and (2) sign-aware scaling, which dynamically\ncomputes optimal combination weights for the relevant models based on their\nperformance. We also provide a formal justification, along with a theoretical\nanalysis, for our asymmetric sparsification. Extensive experimental evaluations\ndemonstrate that our approach achieves state-of-the-art results on a range of\ntasks, significantly outperforming existing strong baselines.",
      "pdf_url": "http://arxiv.org/pdf/2509.12951v1",
      "published": "2025-09-16T10:55:50+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.12951v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "FusionMAE: large-scale pretrained model to optimize and simplify diagnostic and control of fusion plasma",
      "authors": [
        "Zongyu Yang",
        "Zhenghao Yang",
        "Wenjing Tian",
        "Jiyuan Li",
        "Xiang Sun",
        "Guohui Zheng",
        "Songfen Liu",
        "Niannian Wu",
        "Rongpeng Li",
        "Zhaohe Xu",
        "Bo Li",
        "Zhongbing Shi",
        "Zhe Gao",
        "Wei Chen",
        "Xiaoquan Ji",
        "Min Xu",
        "Wulyu Zhong"
      ],
      "abstract": "In magnetically confined fusion device, the complex, multiscale, and\nnonlinear dynamics of plasmas necessitate the integration of extensive\ndiagnostic systems to effectively monitor and control plasma behaviour. The\ncomplexity and uncertainty arising from these extensive systems and their\ntangled interrelations has long posed a significant obstacle to the\nacceleration of fusion energy development. In this work, a large-scale model,\nfusion masked auto-encoder (FusionMAE) is pre-trained to compress the\ninformation from 88 diagnostic signals into a concrete embedding, to provide a\nunified interface between diagnostic systems and control actuators. Two\nmechanisms are proposed to ensure a meaningful embedding: compression-reduction\nand missing-signal reconstruction. Upon completion of pre-training, the model\nacquires the capability for 'virtual backup diagnosis', enabling the inference\nof missing diagnostic data with 96.7% reliability. Furthermore, the model\ndemonstrates three emergent capabilities: automatic data analysis, universal\ncontrol-diagnosis interface, and enhancement of control performance on multiple\ntasks. This work pioneers large-scale AI model integration in fusion energy,\ndemonstrating how pre-trained embeddings can simplify the system interface,\nreducing necessary diagnostic systems and optimize operation performance for\nfuture fusion reactors.",
      "pdf_url": "http://arxiv.org/pdf/2509.12945v1",
      "published": "2025-09-16T10:50:29+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.12945v1",
      "categories": [
        "physics.plasm-ph",
        "cs.AI"
      ]
    },
    {
      "title": "Sy-FAR: Symmetry-based Fair Adversarial Robustness",
      "authors": [
        "Haneen Najjar",
        "Eyal Ronen",
        "Mahmood Sharif"
      ],
      "abstract": "Security-critical machine-learning (ML) systems, such as face-recognition\nsystems, are susceptible to adversarial examples, including real-world\nphysically realizable attacks. Various means to boost ML's adversarial\nrobustness have been proposed; however, they typically induce unfair\nrobustness: It is often easier to attack from certain classes or groups than\nfrom others. Several techniques have been developed to improve adversarial\nrobustness while seeking perfect fairness between classes. Yet, prior work has\nfocused on settings where security and fairness are less critical. Our insight\nis that achieving perfect parity in realistic fairness-critical tasks, such as\nface recognition, is often infeasible -- some classes may be highly similar,\nleading to more misclassifications between them. Instead, we suggest that\nseeking symmetry -- i.e., attacks from class $i$ to $j$ would be as successful\nas from $j$ to $i$ -- is more tractable. Intuitively, symmetry is a desirable\nbecause class resemblance is a symmetric relation in most domains.\nAdditionally, as we prove theoretically, symmetry between individuals induces\nsymmetry between any set of sub-groups, in contrast to other fairness notions\nwhere group-fairness is often elusive. We develop Sy-FAR, a technique to\nencourage symmetry while also optimizing adversarial robustness and extensively\nevaluate it using five datasets, with three model architectures, including\nagainst targeted and untargeted realistic attacks. The results show Sy-FAR\nsignificantly improves fair adversarial robustness compared to state-of-the-art\nmethods. Moreover, we find that Sy-FAR is faster and more consistent across\nruns. Notably, Sy-FAR also ameliorates another type of unfairness we discover\nin this work -- target classes that adversarial examples are likely to be\nclassified into become significantly less vulnerable after inducing symmetry.",
      "pdf_url": "http://arxiv.org/pdf/2509.12939v1",
      "published": "2025-09-16T10:39:42+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.12939v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.CV"
      ]
    },
    {
      "title": "Jailbreaking Large Language Models Through Content Concretization",
      "authors": [
        "Johan Wahréus",
        "Ahmed Hussain",
        "Panos Papadimitratos"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly deployed for task automation\nand content generation, yet their safety mechanisms remain vulnerable to\ncircumvention through different jailbreaking techniques. In this paper, we\nintroduce \\textit{Content Concretization} (CC), a novel jailbreaking technique\nthat iteratively transforms abstract malicious requests into concrete,\nexecutable implementations. CC is a two-stage process: first, generating\ninitial LLM responses using lower-tier, less constrained safety filters models,\nthen refining them through higher-tier models that process both the preliminary\noutput and original prompt. We evaluate our technique using 350\ncybersecurity-specific prompts, demonstrating substantial improvements in\njailbreak Success Rates (SRs), increasing from 7\\% (no refinements) to 62\\%\nafter three refinement iterations, while maintaining a cost of 7.5\\textcent~per\nprompt. Comparative A/B testing across nine different LLM evaluators confirms\nthat outputs from additional refinement steps are consistently rated as more\nmalicious and technically superior. Moreover, manual code analysis reveals that\ngenerated outputs execute with minimal modification, although optimal\ndeployment typically requires target-specific fine-tuning. With eventual\nimproved harmful code generation, these results highlight critical\nvulnerabilities in current LLM safety frameworks.",
      "pdf_url": "http://arxiv.org/pdf/2509.12937v1",
      "published": "2025-09-16T10:34:26+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.12937v1",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "The Anatomy of Alignment: Decomposing Preference Optimization by Steering Sparse Features",
      "authors": [
        "Jeremias Ferrao",
        "Matthijs van der Lende",
        "Ilija Lichkovski",
        "Clement Neo"
      ],
      "abstract": "Aligning large language models is critical for their usability and safety.\nHowever, the prevailing approach of Reinforcement Learning from Human Feedback\n(RLHF) induces diffuse, opaque parameter changes, making it difficult to\ndiscern what the model has internalized. Hence, we introduce Feature Steering\nwith Reinforcement Learning (FSRL), a transparent alignment framework that\ntrains a lightweight adapter to steer behavior by modulating interpretable\nfeatures from a Sparse Autoencoder (SAE). First, we demonstrate that FSRL is an\neffective method for preference optimization and is comparable with current\nRLHF methods. We then perform mechanistic analysis on the trained adapter, and\nfind that its policy systematically promotes style features over explicit\nalignment concepts, suggesting that the preference optimization process rewards\nstylistic presentation as a proxy for quality. Ultimately, we hope that FSRL\nprovides a tool for both interpretable model control and diagnosing the\ninternal mechanisms of alignment.",
      "pdf_url": "http://arxiv.org/pdf/2509.12934v1",
      "published": "2025-09-16T10:32:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.12934v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "HLSMAC: A New StarCraft Multi-Agent Challenge for High-Level Strategic Decision-Making",
      "authors": [
        "Xingxing Hong",
        "Yungong Wang",
        "Dexin Jin",
        "Ye Yuan",
        "Ximing Huang",
        "Zijian Wu",
        "Wenxin Li"
      ],
      "abstract": "Benchmarks are crucial for assessing multi-agent reinforcement learning\n(MARL) algorithms. While StarCraft II-related environments have driven\nsignificant advances in MARL, existing benchmarks like SMAC focus primarily on\nmicromanagement, limiting comprehensive evaluation of high-level strategic\nintelligence. To address this, we introduce HLSMAC, a new cooperative MARL\nbenchmark with 12 carefully designed StarCraft II scenarios based on classical\nstratagems from the Thirty-Six Stratagems. Each scenario corresponds to a\nspecific stratagem and is designed to challenge agents with diverse strategic\nelements, including tactical maneuvering, timing coordination, and deception,\nthereby opening up avenues for evaluating high-level strategic decision-making\ncapabilities. We also propose novel metrics across multiple dimensions beyond\nconventional win rate, such as ability utilization and advancement efficiency,\nto assess agents' overall performance within the HLSMAC environment. We\nintegrate state-of-the-art MARL algorithms and LLM-based agents with our\nbenchmark and conduct comprehensive experiments. The results demonstrate that\nHLSMAC serves as a robust testbed for advancing multi-agent strategic\ndecision-making.",
      "pdf_url": "http://arxiv.org/pdf/2509.12927v1",
      "published": "2025-09-16T10:26:12+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.12927v1",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.GT",
        "cs.LG",
        "cs.MA"
      ]
    },
    {
      "title": "Population Estimation using Deep Learning over Gandhinagar Urban Area",
      "authors": [
        "Jai Singla",
        "Peal Jotania",
        "Keivalya Pandya"
      ],
      "abstract": "Population estimation is crucial for various applications, from resource\nallocation to urban planning. Traditional methods such as surveys and censuses\nare expensive, time-consuming and also heavily dependent on human resources,\nrequiring significant manpower for data collection and processing. In this\nstudy a deep learning solution is proposed to estimate population using high\nresolution (0.3 m) satellite imagery, Digital Elevation Models (DEM) of 0.5m\nresolution and vector boundaries. Proposed method combines Convolution Neural\nNetwork (CNN) architecture for classification task to classify buildings as\nresidential and non-residential and Artificial Neural Network (ANN)\narchitecture to estimate the population. Approx. 48k building footprints over\nGandhinagar urban area are utilized containing both residential and\nnon-residential, with residential categories further used for building-level\npopulation estimation. Experimental results on a large-scale dataset\ndemonstrate the effectiveness of our model, achieving an impressive overall\nF1-score of 0.9936. The proposed system employs advanced geospatial analysis\nwith high spatial resolution to estimate Gandhinagar population at 278,954. By\nintegrating real-time data updates, standardized metrics, and infrastructure\nplanning capabilities, this automated approach addresses critical limitations\nof conventional census-based methodologies. The framework provides\nmunicipalities with a scalable and replicable tool for optimized resource\nmanagement in rapidly urbanizing cities, showcasing the efficiency of AI-driven\ngeospatial analytics in enhancing data-driven urban governance.",
      "pdf_url": "http://arxiv.org/pdf/2509.12926v1",
      "published": "2025-09-16T10:25:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.12926v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "A Graph-Based Approach to Alert Contextualisation in Security Operations Centres",
      "authors": [
        "Magnus Wiik Eckhoff",
        "Peter Marius Flydal",
        "Siem Peters",
        "Martin Eian",
        "Jonas Halvorsen",
        "Vasileios Mavroeidis",
        "Gudmund Grov"
      ],
      "abstract": "Interpreting the massive volume of security alerts is a significant challenge\nin Security Operations Centres (SOCs). Effective contextualisation is\nimportant, enabling quick distinction between genuine threats and benign\nactivity to prioritise what needs further analysis.This paper proposes a\ngraph-based approach to enhance alert contextualisation in a SOC by aggregating\nalerts into graph-based alert groups, where nodes represent alerts and edges\ndenote relationships within defined time-windows. By grouping related alerts,\nwe enable analysis at a higher abstraction level, capturing attack steps more\neffectively than individual alerts. Furthermore, to show that our format is\nwell suited for downstream machine learning methods, we employ Graph Matching\nNetworks (GMNs) to correlate incoming alert groups with historical incidents,\nproviding analysts with additional insights.",
      "pdf_url": "http://arxiv.org/pdf/2509.12923v1",
      "published": "2025-09-16T10:20:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.12923v1",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "title": "Stochastic Streets: A Walk Through Random LLM Address Generation in four European Cities",
      "authors": [
        "Tairan Fu",
        "David Campo-Nazareno",
        "Javier Coronado-Blázquez",
        "Javier Conde",
        "Pedro Reviriego",
        "Fabrizio Lombardi"
      ],
      "abstract": "Large Language Models (LLMs) are capable of solving complex math problems or\nanswer difficult questions on almost any topic, but can they generate random\nstreet addresses for European cities?",
      "pdf_url": "http://arxiv.org/pdf/2509.12914v1",
      "published": "2025-09-16T10:09:00+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.12914v1",
      "categories": [
        "cs.AI"
      ]
    }
  ]
}