{
  "last_updated": "2025-06-10T00:53:25.503512",
  "papers": [
    {
      "title": "Eigenspectrum Analysis of Neural Networks without Aspect Ratio Bias",
      "authors": [
        "Yuanzhe Hu",
        "Kinshuk Goel",
        "Vlad Killiakov",
        "Yaoqing Yang"
      ],
      "abstract": "Diagnosing deep neural networks (DNNs) through the eigenspectrum of weight\nmatrices has been an active area of research in recent years. At a high level,\neigenspectrum analysis of DNNs involves measuring the heavytailness of the\nempirical spectral densities (ESD) of weight matrices. It provides insight into\nhow well a model is trained and can guide decisions on assigning better\nlayer-wise training hyperparameters. In this paper, we address a challenge\nassociated with such eigenspectrum methods: the impact of the aspect ratio of\nweight matrices on estimated heavytailness metrics. We demonstrate that\nmatrices of varying sizes (and aspect ratios) introduce a non-negligible bias\nin estimating heavytailness metrics, leading to inaccurate model diagnosis and\nlayer-wise hyperparameter assignment. To overcome this challenge, we propose\nFARMS (Fixed-Aspect-Ratio Matrix Subsampling), a method that normalizes the\nweight matrices by subsampling submatrices with a fixed aspect ratio. Instead\nof measuring the heavytailness of the original ESD, we measure the average ESD\nof these subsampled submatrices. We show that measuring the heavytailness of\nthese submatrices with the fixed aspect ratio can effectively mitigate the\naspect ratio bias. We validate our approach across various optimization\ntechniques and application domains that involve eigenspectrum analysis of\nweights, including image classification in computer vision (CV) models,\nscientific machine learning (SciML) model training, and large language model\n(LLM) pruning. Our results show that despite its simplicity, FARMS uniformly\nimproves the accuracy of eigenspectrum analysis while enabling more effective\nlayer-wise hyperparameter assignment in these application domains. In one of\nthe LLM pruning experiments, FARMS reduces the perplexity of the LLaMA-7B model\nby 17.3% when compared with the state-of-the-art method.",
      "pdf_url": "http://arxiv.org/pdf/2506.06280v1",
      "published": "2025-06-06T17:59:28+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.06280v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Distillation Robustifies Unlearning",
      "authors": [
        "Bruce W. Lee",
        "Addie Foote",
        "Alex Infanger",
        "Leni Shor",
        "Harish Kamath",
        "Jacob Goldman-Wetzler",
        "Bryce Woodworth",
        "Alex Cloud",
        "Alexander Matt Turner"
      ],
      "abstract": "Current LLM unlearning methods are not robust: they can be reverted easily\nwith a few steps of finetuning. This is true even for the idealized unlearning\nmethod of training to imitate an oracle model that was never exposed to\nunwanted information, suggesting that output-based finetuning is insufficient\nto achieve robust unlearning. In a similar vein, we find that training a\nrandomly initialized student to imitate an unlearned model transfers desired\nbehaviors while leaving undesired capabilities behind. In other words,\ndistillation robustifies unlearning. Building on this insight, we propose\nUnlearn-Noise-Distill-on-Outputs (UNDO), a scalable method that distills an\nunlearned model into a partially noised copy of itself. UNDO introduces a\ntunable tradeoff between compute cost and robustness, establishing a new Pareto\nfrontier on synthetic language and arithmetic tasks. At its strongest setting,\nUNDO matches the robustness of a model retrained from scratch with perfect data\nfiltering while using only 60-80% of the compute and requiring only 0.01% of\nthe pretraining data to be labeled. We also show that UNDO robustifies\nunlearning on the more realistic Weapons of Mass Destruction Proxy (WMDP)\nbenchmark. Since distillation is widely used in practice, incorporating an\nunlearning step beforehand offers a convenient path to robust capability\nremoval.",
      "pdf_url": "http://arxiv.org/pdf/2506.06278v1",
      "published": "2025-06-06T17:58:54+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.06278v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Cartridges: Lightweight and general-purpose long context representations via self-study",
      "authors": [
        "Sabri Eyuboglu",
        "Ryan Ehrlich",
        "Simran Arora",
        "Neel Guha",
        "Dylan Zinsley",
        "Emily Liu",
        "Will Tennien",
        "Atri Rudra",
        "James Zou",
        "Azalia Mirhoseini",
        "Christopher Re"
      ],
      "abstract": "Large language models are often used to answer queries grounded in large text\ncorpora (e.g. codebases, legal documents, or chat histories) by placing the\nentire corpus in the context window and leveraging in-context learning (ICL).\nAlthough current models support contexts of 100K-1M tokens, this setup is\ncostly to serve because the memory consumption of the KV cache scales with\ninput length. We explore an alternative: training a smaller KV cache offline on\neach corpus. At inference time, we load this trained KV cache, which we call a\nCartridge, and decode a response. Critically, the cost of training a Cartridge\ncan be amortized across all the queries referencing the same corpus. However,\nwe find that the naive approach of training the Cartridge with next-token\nprediction on the corpus is not competitive with ICL. Instead, we propose\nself-study, a training recipe in which we generate synthetic conversations\nabout the corpus and train the Cartridge with a context-distillation objective.\nWe find that Cartridges trained with self-study replicate the functionality of\nICL, while being significantly cheaper to serve. On challenging long-context\nbenchmarks, Cartridges trained with self-study match ICL performance while\nusing 38.6x less memory and enabling 26.4x higher throughput. Self-study also\nextends the model's effective context length (e.g. from 128k to 484k tokens on\nMTOB) and surprisingly, leads to Cartridges that can be composed at inference\ntime without retraining.",
      "pdf_url": "http://arxiv.org/pdf/2506.06266v1",
      "published": "2025-06-06T17:48:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.06266v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Reflect-then-Plan: Offline Model-Based Planning through a Doubly Bayesian Lens",
      "authors": [
        "Jihwan Jeong",
        "Xiaoyu Wang",
        "Jingmin Wang",
        "Scott Sanner",
        "Pascal Poupart"
      ],
      "abstract": "Offline reinforcement learning (RL) is crucial when online exploration is\ncostly or unsafe but often struggles with high epistemic uncertainty due to\nlimited data. Existing methods rely on fixed conservative policies, restricting\nadaptivity and generalization. To address this, we propose Reflect-then-Plan\n(RefPlan), a novel doubly Bayesian offline model-based (MB) planning approach.\nRefPlan unifies uncertainty modeling and MB planning by recasting planning as\nBayesian posterior estimation. At deployment, it updates a belief over\nenvironment dynamics using real-time observations, incorporating uncertainty\ninto MB planning via marginalization. Empirical results on standard benchmarks\nshow that RefPlan significantly improves the performance of conservative\noffline RL policies. In particular, RefPlan maintains robust performance under\nhigh epistemic uncertainty and limited data, while demonstrating resilience to\nchanging environment dynamics, improving the flexibility, generalizability, and\nrobustness of offline-learned policies.",
      "pdf_url": "http://arxiv.org/pdf/2506.06261v1",
      "published": "2025-06-06T17:40:12+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.06261v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "PersonaAgent: When Large Language Model Agents Meet Personalization at Test Time",
      "authors": [
        "Weizhi Zhang",
        "Xinyang Zhang",
        "Chenwei Zhang",
        "Liangwei Yang",
        "Jingbo Shang",
        "Zhepei Wei",
        "Henry Peng Zou",
        "Zijie Huang",
        "Zhengyang Wang",
        "Yifan Gao",
        "Xiaoman Pan",
        "Lian Xiong",
        "Jingguo Liu",
        "Philip S. Yu",
        "Xian Li"
      ],
      "abstract": "Large Language Model (LLM) empowered agents have recently emerged as advanced\nparadigms that exhibit impressive capabilities in a wide range of domains and\ntasks. Despite their potential, current LLM agents often adopt a\none-size-fits-all approach, lacking the flexibility to respond to users'\nvarying needs and preferences. This limitation motivates us to develop\nPersonaAgent, the first personalized LLM agent framework designed to address\nversatile personalization tasks. Specifically, PersonaAgent integrates two\ncomplementary components - a personalized memory module that includes episodic\nand semantic memory mechanisms; a personalized action module that enables the\nagent to perform tool actions tailored to the user. At the core, the persona\n(defined as unique system prompt for each user) functions as an intermediary:\nit leverages insights from personalized memory to control agent actions, while\nthe outcomes of these actions in turn refine the memory. Based on the\nframework, we propose a test-time user-preference alignment strategy that\nsimulate the latest n interactions to optimize the persona prompt, ensuring\nreal-time user preference alignment through textual loss feedback between\nsimulated and ground-truth responses. Experimental evaluations demonstrate that\nPersonaAgent significantly outperforms other baseline methods by not only\npersonalizing the action space effectively but also scaling during test-time\nreal-world applications. These results underscore the feasibility and potential\nof our approach in delivering tailored, dynamic user experiences.",
      "pdf_url": "http://arxiv.org/pdf/2506.06254v1",
      "published": "2025-06-06T17:29:49+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.06254v1",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    },
    {
      "title": "DesignBench: A Comprehensive Benchmark for MLLM-based Front-end Code Generation",
      "authors": [
        "Jingyu Xiao",
        "Ming Wang",
        "Man Ho Lam",
        "Yuxuan Wan",
        "Junliang Liu",
        "Yintong Huo",
        "Michael R. Lyu"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) have demonstrated remarkable\ncapabilities in automated front-end engineering, e.g., generating UI code from\nvisual designs. However, existing front-end UI code generation benchmarks have\nthe following limitations: (1) While framework-based development becomes\npredominant in modern front-end programming, current benchmarks fail to\nincorporate mainstream development frameworks. (2) Existing evaluations focus\nsolely on the UI code generation task, whereas practical UI development\ninvolves several iterations, including refining editing, and repairing issues.\n(3) Current benchmarks employ unidimensional evaluation, lacking investigation\ninto influencing factors like task difficulty, input context variations, and\nin-depth code-level analysis. To bridge these gaps, we introduce DesignBench, a\nmulti-framework, multi-task evaluation benchmark for assessing MLLMs'\ncapabilities in automated front-end engineering. DesignBench encompasses three\nwidely-used UI frameworks (React, Vue, and Angular) alongside vanilla HTML/CSS,\nand evaluates on three essential front-end tasks (generation, edit, and repair)\nin real-world development workflows. DesignBench contains 900 webpage samples\nspanning over 11 topics, 9 edit types, and 6 issue categories, enabling\ndetailed analysis of MLLM performance across multiple dimensions. Our\nsystematic evaluation reveals critical insights into MLLMs' framework-specific\nlimitations, task-related bottlenecks, and performance variations under\ndifferent conditions, providing guidance for future research in automated\nfront-end development. Our code and data are available at\nhttps://github.com/WebPAI/DesignBench.",
      "pdf_url": "http://arxiv.org/pdf/2506.06251v1",
      "published": "2025-06-06T17:21:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.06251v1",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "Visual Graph Arena: Evaluating Visual Conceptualization of Vision and Multimodal Large Language Models",
      "authors": [
        "Zahra Babaiee",
        "Peyman M. Kiasari",
        "Daniela Rus",
        "Radu Grosu"
      ],
      "abstract": "Recent advancements in multimodal large language models have driven\nbreakthroughs in visual question answering. Yet, a critical gap persists,\n`conceptualization'-the ability to recognize and reason about the same concept\ndespite variations in visual form, a basic ability of human reasoning. To\naddress this challenge, we introduce the Visual Graph Arena (VGA), a dataset\nfeaturing six graph-based tasks designed to evaluate and improve AI systems'\ncapacity for visual abstraction. VGA uses diverse graph layouts (e.g.,\nKamada-Kawai vs. planar) to test reasoning independent of visual form.\nExperiments with state-of-the-art vision models and multimodal LLMs reveal a\nstriking divide: humans achieved near-perfect accuracy across tasks, while\nmodels totally failed on isomorphism detection and showed limited success in\npath/cycle tasks. We further identify behavioral anomalies suggesting\npseudo-intelligent pattern matching rather than genuine understanding. These\nfindings underscore fundamental limitations in current AI models for visual\nunderstanding. By isolating the challenge of representation-invariant\nreasoning, the VGA provides a framework to drive progress toward human-like\nconceptualization in AI visual models. The Visual Graph Arena is available at:\n\\href{https://vga.csail.mit.edu/}{vga.csail.mit.edu}",
      "pdf_url": "http://arxiv.org/pdf/2506.06242v1",
      "published": "2025-06-06T17:06:25+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.06242v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Towards an Explainable Comparison and Alignment of Feature Embeddings",
      "authors": [
        "Mohammad Jalali",
        "Bahar Dibaei Nia",
        "Farzan Farnia"
      ],
      "abstract": "While several feature embedding models have been developed in the literature,\ncomparisons of these embeddings have largely focused on their numerical\nperformance in classification-related downstream applications. However, an\ninterpretable comparison of different embeddings requires identifying and\nanalyzing mismatches between sample groups clustered within the embedding\nspaces. In this work, we propose the \\emph{Spectral Pairwise Embedding\nComparison (SPEC)} framework to compare embeddings and identify their\ndifferences in clustering a reference dataset. Our approach examines the kernel\nmatrices derived from two embeddings and leverages the eigendecomposition of\nthe difference kernel matrix to detect sample clusters that are captured\ndifferently by the two embeddings. We present a scalable implementation of this\nkernel-based approach, with computational complexity that grows linearly with\nthe sample size. Furthermore, we introduce an optimization problem using this\nframework to align two embeddings, ensuring that clusters identified in one\nembedding are also captured in the other model. We provide numerical results\ndemonstrating the SPEC's application to compare and align embeddings on\nlarge-scale datasets such as ImageNet and MS-COCO. The code is available at\n[https://github.com/mjalali/embedding-comparison](github.com/mjalali/embedding-comparison).",
      "pdf_url": "http://arxiv.org/pdf/2506.06231v1",
      "published": "2025-06-06T16:50:37+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.06231v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "math.SP"
      ]
    },
    {
      "title": "\"We need to avail ourselves of GenAI to enhance knowledge distribution\": Empowering Older Adults through GenAI Literacy",
      "authors": [
        "Eunhye Grace Ko",
        "Shaini Nanayakkara",
        "Earl W. Huff Jr"
      ],
      "abstract": "As generative AI (GenAI) becomes increasingly widespread, it is crucial to\nequip users, particularly vulnerable populations such as older adults (65 and\nolder), with the knowledge to understand its benefits and potential risks.\nOlder adults often exhibit greater reservations about adopting emerging\ntechnologies and require tailored literacy support. Using a mixed methods\napproach, this study examines strategies for delivering GenAI literacy to older\nadults through a chatbot named Litti, evaluating its impact on their AI\nliteracy (knowledge, safety, and ethical use). The quantitative data indicated\na trend toward improved AI literacy, though the results were not statistically\nsignificant. However, qualitative interviews revealed diverse levels of\nfamiliarity with generative AI and a strong desire to learn more. Findings also\nshow that while Litti provided a positive learning experience, it did not\nsignificantly enhance participants' trust or sense of safety regarding GenAI.\nThis exploratory case study highlights the challenges and opportunities in\ndesigning AI literacy education for the rapidly growing older adult population.",
      "pdf_url": "http://arxiv.org/pdf/2506.06225v1",
      "published": "2025-06-06T16:38:37+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.06225v1",
      "categories": [
        "cs.HC",
        "cs.AI"
      ]
    },
    {
      "title": "GenIR: Generative Visual Feedback for Mental Image Retrieval",
      "authors": [
        "Diji Yang",
        "Minghao Liu",
        "Chung-Hsiang Lo",
        "Yi Zhang",
        "James Davis"
      ],
      "abstract": "Vision-language models (VLMs) have shown strong performance on text-to-image\nretrieval benchmarks. However, bridging this success to real-world applications\nremains a challenge. In practice, human search behavior is rarely a one-shot\naction. Instead, it is often a multi-round process guided by clues in mind,\nthat is, a mental image ranging from vague recollections to vivid mental\nrepresentations of the target image. Motivated by this gap, we study the task\nof Mental Image Retrieval (MIR), which targets the realistic yet underexplored\nsetting where users refine their search for a mentally envisioned image through\nmulti-round interactions with an image search engine. Central to successful\ninteractive retrieval is the capability of machines to provide users with\nclear, actionable feedback; however, existing methods rely on indirect or\nabstract verbal feedback, which can be ambiguous, misleading, or ineffective\nfor users to refine the query. To overcome this, we propose GenIR, a generative\nmulti-round retrieval paradigm leveraging diffusion-based image generation to\nexplicitly reify the AI system's understanding at each round. These synthetic\nvisual representations provide clear, interpretable feedback, enabling users to\nrefine their queries intuitively and effectively. We further introduce a fully\nautomated pipeline to generate a high-quality multi-round MIR dataset.\nExperimental results demonstrate that GenIR significantly outperforms existing\ninteractive methods in the MIR scenario. This work establishes a new task with\na dataset and an effective generative retrieval method, providing a foundation\nfor future research in this direction.",
      "pdf_url": "http://arxiv.org/pdf/2506.06220v1",
      "published": "2025-06-06T16:28:03+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.06220v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Integer Linear Programming Preprocessing for Maximum Satisfiability",
      "authors": [
        "Jialu Zhang",
        "Chu-Min Li",
        "Sami Cherif",
        "Shuolin Li",
        "Zhifei Zheng"
      ],
      "abstract": "The Maximum Satisfiability problem (MaxSAT) is a major optimization challenge\nwith numerous practical applications. In recent MaxSAT evaluations, most MaxSAT\nsolvers have adopted an ILP solver as part of their portfolios. This paper\ninvestigates the impact of Integer Linear Programming (ILP) preprocessing\ntechniques on MaxSAT solving. Experimental results show that ILP preprocessing\ntechniques help WMaxCDCL-OpenWbo1200, the winner of the MaxSAT evaluation 2024\nin the unweighted track, solve 15 additional instances. Moreover, current\nstate-of-the-art MaxSAT solvers heavily use an ILP solver in their portfolios,\nwhile our proposed approach reduces the need to call an ILP solver in a\nportfolio including WMaxCDCL or MaxCDCL.",
      "pdf_url": "http://arxiv.org/pdf/2506.06216v1",
      "published": "2025-06-06T16:21:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.06216v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Can Theoretical Physics Research Benefit from Language Agents?",
      "authors": [
        "Sirui Lu",
        "Zhijing Jin",
        "Terry Jingchen Zhang",
        "Pavel Kos",
        "J. Ignacio Cirac",
        "Bernhard Schölkopf"
      ],
      "abstract": "Large Language Models (LLMs) are rapidly advancing across diverse domains,\nyet their application in theoretical physics research is not yet mature. This\nposition paper argues that LLM agents can potentially help accelerate\ntheoretical, computational, and applied physics when properly integrated with\ndomain knowledge and toolbox. We analyze current LLM capabilities for physics\n-- from mathematical reasoning to code generation -- identifying critical gaps\nin physical intuition, constraint satisfaction, and reliable reasoning. We\nenvision future physics-specialized LLMs that could handle multimodal data,\npropose testable hypotheses, and design experiments. Realizing this vision\nrequires addressing fundamental challenges: ensuring physical consistency, and\ndeveloping robust verification methods. We call for collaborative efforts\nbetween physics and AI communities to help advance scientific discovery in\nphysics.",
      "pdf_url": "http://arxiv.org/pdf/2506.06214v1",
      "published": "2025-06-06T16:20:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.06214v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "math-ph",
        "math.MP",
        "quant-ph"
      ]
    },
    {
      "title": "PuzzleWorld: A Benchmark for Multimodal, Open-Ended Reasoning in Puzzlehunts",
      "authors": [
        "Hengzhi Li",
        "Brendon Jiang",
        "Alexander Naehu",
        "Regan Song",
        "Justin Zhang",
        "Megan Tjandrasuwita",
        "Chanakya Ekbote",
        "Steven-Shine Chen",
        "Adithya Balachandran",
        "Wei Dai",
        "Rebecca Chang",
        "Paul Pu Liang"
      ],
      "abstract": "Puzzlehunts are a genre of complex, multi-step puzzles lacking well-defined\nproblem definitions. In contrast to conventional reasoning benchmarks\nconsisting of tasks with clear instructions, puzzlehunts require models to\ndiscover the underlying problem structure from multimodal evidence and\niterative reasoning, mirroring real-world domains such as scientific discovery,\nexploratory data analysis, or investigative problem-solving. Despite recent\nprogress in foundation models, their performance on such open-ended settings\nremains largely untested. In this paper, we introduce PuzzleWorld, a\nlarge-scale benchmark of 667 puzzlehunt-style problems designed to assess\nstep-by-step, open-ended, and creative multimodal reasoning. Each puzzle is\nannotated with the final solution, detailed reasoning traces, and cognitive\nskill labels, enabling holistic benchmarking and fine-grained diagnostic\nanalysis. Most state-of-the-art models achieve only 1-2% final answer accuracy,\nwith the best model solving only 14% of puzzles and reaching 40% stepwise\naccuracy. To demonstrate the value of our reasoning annotations, we show that\nfine-tuning a small model on reasoning traces improves stepwise reasoning from\n4% to 11%, while training on final answers alone degrades performance to near\nzero. Our error analysis reveals that current models exhibit myopic reasoning,\nare bottlenecked by the limitations of language-based inference, and lack\nsketching capabilities crucial for visual and spatial reasoning. We release\nPuzzleWorld at https://github.com/MIT-MI/PuzzleWorld to support future work on\nbuilding more general, open-ended, and creative reasoning systems.",
      "pdf_url": "http://arxiv.org/pdf/2506.06211v1",
      "published": "2025-06-06T16:17:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.06211v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Building Models of Neurological Language",
      "authors": [
        "Henry Watkins"
      ],
      "abstract": "This report documents the development and evaluation of domain-specific\nlanguage models for neurology. Initially focused on building a bespoke model,\nthe project adapted to rapid advances in open-source and commercial medical\nLLMs, shifting toward leveraging retrieval-augmented generation (RAG) and\nrepresentational models for secure, local deployment. Key contributions include\nthe creation of neurology-specific datasets (case reports, QA sets,\ntextbook-derived data), tools for multi-word expression extraction, and\ngraph-based analyses of medical terminology. The project also produced scripts\nand Docker containers for local hosting. Performance metrics and graph\ncommunity results are reported, with future possible work open for multimodal\nmodels using open-source architectures like phi-4.",
      "pdf_url": "http://arxiv.org/pdf/2506.06208v1",
      "published": "2025-06-06T16:14:28+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.06208v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Astra: Toward General-Purpose Mobile Robots via Hierarchical Multimodal Learning",
      "authors": [
        "Sheng Chen",
        "Peiyu He",
        "Jiaxin Hu",
        "Ziyang Liu",
        "Yansheng Wang",
        "Tao Xu",
        "Chi Zhang",
        "Chongchong Zhang",
        "Chao An",
        "Shiyu Cai",
        "Duo Cao",
        "Kangping Chen",
        "Shuai Chu",
        "Tianwei Chu",
        "Mingdi Dan",
        "Min Du",
        "Weiwei Fang",
        "Pengyou Fu",
        "Junkai Hu",
        "Xiaowei Jiang",
        "Zhaodi Jiang",
        "Fuxuan Li",
        "Jun Li",
        "Minghui Li",
        "Mingyao Li",
        "Yanchang Li",
        "Zhibin Li",
        "Guangming Liu",
        "Kairui Liu",
        "Lihao Liu",
        "Weizhi Liu",
        "Xiaoshun Liu",
        "Yufei Liu",
        "Yunfei Liu",
        "Qiang Lu",
        "Yuanfei Luo",
        "Xiang Lv",
        "Hongying Ma",
        "Sai Ma",
        "Lingxian Mi",
        "Sha Sa",
        "Hongxiang Shu",
        "Lei Tian",
        "Chengzhi Wang",
        "Jiayu Wang",
        "Kaijie Wang",
        "Qingyi Wang",
        "Renwen Wang",
        "Tao Wang",
        "Wei Wang",
        "Xirui Wang",
        "Chao Wei",
        "Xuguang Wei",
        "Zijun Xia",
        "Zhaohao Xiao",
        "Tingshuai Yan",
        "Liyan Yang",
        "Yifan Yang",
        "Zhikai Yang",
        "Zhong Yin",
        "Li Yuan",
        "Liuchun Yuan",
        "Chi Zhang",
        "Jinyang Zhang",
        "Junhui Zhang",
        "Linge Zhang",
        "Zhenyi Zhang",
        "Zheyu Zhang",
        "Dongjie Zhu",
        "Hang Li",
        "Yangang Zhang"
      ],
      "abstract": "Modern robot navigation systems encounter difficulties in diverse and complex\nindoor environments. Traditional approaches rely on multiple modules with small\nmodels or rule-based systems and thus lack adaptability to new environments. To\naddress this, we developed Astra, a comprehensive dual-model architecture,\nAstra-Global and Astra-Local, for mobile robot navigation. Astra-Global, a\nmultimodal LLM, processes vision and language inputs to perform self and goal\nlocalization using a hybrid topological-semantic graph as the global map, and\noutperforms traditional visual place recognition methods. Astra-Local, a\nmultitask network, handles local path planning and odometry estimation. Its 4D\nspatial-temporal encoder, trained through self-supervised learning, generates\nrobust 4D features for downstream tasks. The planning head utilizes flow\nmatching and a novel masked ESDF loss to minimize collision risks for\ngenerating local trajectories, and the odometry head integrates multi-sensor\ninputs via a transformer encoder to predict the relative pose of the robot.\nDeployed on real in-house mobile robots, Astra achieves high end-to-end mission\nsuccess rate across diverse indoor environments.",
      "pdf_url": "http://arxiv.org/pdf/2506.06205v1",
      "published": "2025-06-06T16:08:47+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.06205v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "MLOps with Microservices: A Case Study on the Maritime Domain",
      "authors": [
        "Renato Cordeiro Ferreira",
        "Rowanne Trapmann",
        "Willem-Jan van den Heuvel"
      ],
      "abstract": "This case study describes challenges and lessons learned on building Ocean\nGuard: a Machine Learning-Enabled System (MLES) for anomaly detection in the\nmaritime domain. First, the paper presents the system's specification, and\narchitecture. Ocean Guard was designed with a microservices' architecture to\nenable multiple teams to work on the project in parallel. Then, the paper\ndiscusses how the developers adapted contract-based design to MLOps for\nachieving that goal. As a MLES, Ocean Guard employs code, model, and data\ncontracts to establish guidelines between its services. This case study hopes\nto inspire software engineers, machine learning engineers, and data scientists\nto leverage similar approaches for their systems.",
      "pdf_url": "http://arxiv.org/pdf/2506.06202v1",
      "published": "2025-06-06T16:04:59+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.06202v1",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG",
        "D.2.11; D.2.9; I.2.m; I.5.0"
      ]
    },
    {
      "title": "semantic-features: A User-Friendly Tool for Studying Contextual Word Embeddings in Interpretable Semantic Spaces",
      "authors": [
        "Jwalanthi Ranganathan",
        "Rohan Jha",
        "Kanishka Misra",
        "Kyle Mahowald"
      ],
      "abstract": "We introduce semantic-features, an extensible, easy-to-use library based on\nChronis et al. (2023) for studying contextualized word embeddings of LMs by\nprojecting them into interpretable spaces. We apply this tool in an experiment\nwhere we measure the contextual effect of the choice of dative construction\n(prepositional or double object) on the semantic interpretation of utterances\n(Bresnan, 2007). Specifically, we test whether \"London\" in \"I sent London the\nletter.\" is more likely to be interpreted as an animate referent (e.g., as the\nname of a person) than in \"I sent the letter to London.\" To this end, we devise\na dataset of 450 sentence pairs, one in each dative construction, with\nrecipients being ambiguous with respect to person-hood vs. place-hood. By\napplying semantic-features, we show that the contextualized word embeddings of\nthree masked language models show the expected sensitivities. This leaves us\noptimistic about the usefulness of our tool.",
      "pdf_url": "http://arxiv.org/pdf/2506.06169v1",
      "published": "2025-06-06T15:33:27+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.06169v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "The Lock-in Hypothesis: Stagnation by Algorithm",
      "authors": [
        "Tianyi Alex Qiu",
        "Zhonghao He",
        "Tejasveer Chugh",
        "Max Kleiman-Weiner"
      ],
      "abstract": "The training and deployment of large language models (LLMs) create a feedback\nloop with human users: models learn human beliefs from data, reinforce these\nbeliefs with generated content, reabsorb the reinforced beliefs, and feed them\nback to users again and again. This dynamic resembles an echo chamber. We\nhypothesize that this feedback loop entrenches the existing values and beliefs\nof users, leading to a loss of diversity and potentially the lock-in of false\nbeliefs. We formalize this hypothesis and test it empirically with agent-based\nLLM simulations and real-world GPT usage data. Analysis reveals sudden but\nsustained drops in diversity after the release of new GPT iterations,\nconsistent with the hypothesized human-AI feedback loop. Code and data\navailable at https://thelockinhypothesis.com",
      "pdf_url": "http://arxiv.org/pdf/2506.06166v1",
      "published": "2025-06-06T15:31:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.06166v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.HC"
      ]
    },
    {
      "title": "(AI peers) are people learning from the same standpoint: Perception of AI characters in a Collaborative Science Investigation",
      "authors": [
        "Eunhye Grace Ko",
        "Soo Hyoung Joo"
      ],
      "abstract": "While the complexity of 21st-century demands has promoted pedagogical\napproaches to foster complex competencies, a persistent gap remains between\nin-class learning activities and individualized learning or assessment\npractices. To address this, studies have explored the use of AI-generated\ncharacters in learning and assessment. One attempt is scenario-based assessment\n(SBA), a technique that not only measures but also fosters the development of\ncompetencies throughout the assessment process. SBA introduces simulated agents\nto provide an authentic social-interactional context, allowing for the\nassessment of competency-based constructs while mitigating the unpredictability\nof real-life interactions. Recent advancements in multimodal AI, such as\ntext-to-video technology, allow these agents to be enhanced into AI-generated\ncharacters. This mixed-method study investigates how learners perceive AI\ncharacters taking the role of mentor and teammates in an SBA mirroring the\ncontext of a collaborative science investigation. Specifically, we examined the\nLikert scale responses of 56 high schoolers regarding trust, social presence,\nand effectiveness. We analyzed the relationships between these factors and\ntheir impact on the intention to adopt AI characters through PLS-SEM. Our\nfindings indicated that learners' trust shaped their sense of social presence\nwith the AI characters, enhancing perceived effectiveness. Qualitative analysis\nfurther highlighted factors that foster trust, such as material credibility and\nalignment with learning goals, as well as the pivotal role of social presence\nin creating a collaborative context.\n  This paper was accepted as an full paper for AIED 2025.",
      "pdf_url": "http://arxiv.org/pdf/2506.06165v1",
      "published": "2025-06-06T15:29:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.06165v1",
      "categories": [
        "cs.HC",
        "cs.AI"
      ]
    },
    {
      "title": "Recommender systems, stigmergy, and the tyranny of popularity",
      "authors": [
        "Zackary Okun Dunivin",
        "Paul E. Smaldino"
      ],
      "abstract": "Scientific recommender systems, such as Google Scholar and Web of Science,\nare essential tools for discovery. Search algorithms that power work through\nstigmergy, a collective intelligence mechanism that surfaces useful paths\nthrough repeated engagement. While generally effective, this\n``rich-get-richer'' dynamic results in a small number of high-profile papers\nthat dominate visibility. This essay argues argue that these algorithm\nover-reliance on popularity fosters intellectual homogeneity and exacerbates\nstructural inequities, stifling innovative and diverse perspectives critical\nfor scientific progress. We propose an overhaul of search platforms to\nincorporate user-specific calibration, allowing researchers to manually adjust\nthe weights of factors like popularity, recency, and relevance. We also advise\nplatform developers on how word embeddings and LLMs could be implemented in\nways that increase user autonomy. While our suggestions are particularly\npertinent to aligning recommender systems with scientific values, these ideas\nare broadly applicable to information access systems in general. Designing\nplatforms that increase user autonomy is an important step toward more robust\nand dynamic information",
      "pdf_url": "http://arxiv.org/pdf/2506.06162v1",
      "published": "2025-06-06T15:27:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.06162v1",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC",
        "cs.IR"
      ]
    },
    {
      "title": "Joint-GCG: Unified Gradient-Based Poisoning Attacks on Retrieval-Augmented Generation Systems",
      "authors": [
        "Haowei Wang",
        "Rupeng Zhang",
        "Junjie Wang",
        "Mingyang Li",
        "Yuekai Huang",
        "Dandan Wang",
        "Qing Wang"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) systems enhance Large Language Models\n(LLMs) by retrieving relevant documents from external corpora before generating\nresponses. This approach significantly expands LLM capabilities by leveraging\nvast, up-to-date external knowledge. However, this reliance on external\nknowledge makes RAG systems vulnerable to corpus poisoning attacks that\nmanipulate generated outputs via poisoned document injection. Existing\npoisoning attack strategies typically treat the retrieval and generation stages\nas disjointed, limiting their effectiveness. We propose Joint-GCG, the first\nframework to unify gradient-based attacks across both retriever and generator\nmodels through three innovations: (1) Cross-Vocabulary Projection for aligning\nembedding spaces, (2) Gradient Tokenization Alignment for synchronizing\ntoken-level gradient signals, and (3) Adaptive Weighted Fusion for dynamically\nbalancing attacking objectives. Evaluations demonstrate that Joint-GCG achieves\nat most 25% and an average of 5% higher attack success rate than previous\nmethods across multiple retrievers and generators. While optimized under a\nwhite-box assumption, the generated poisons show unprecedented transferability\nto unseen models. Joint-GCG's innovative unification of gradient-based attacks\nacross retrieval and generation stages fundamentally reshapes our understanding\nof vulnerabilities within RAG systems. Our code is available at\nhttps://github.com/NicerWang/Joint-GCG.",
      "pdf_url": "http://arxiv.org/pdf/2506.06151v1",
      "published": "2025-06-06T15:12:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.06151v1",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "title": "Decomposability-Guaranteed Cooperative Coevolution for Large-Scale Itinerary Planning",
      "authors": [
        "Ziyu Zhang",
        "Peilan Xu",
        "Yuetong Sun",
        "Yuhui Shi",
        "Wenjian Luo"
      ],
      "abstract": "Large-scale itinerary planning is a variant of the traveling salesman\nproblem, aiming to determine an optimal path that maximizes the collected\npoints of interest (POIs) scores while minimizing travel time and cost, subject\nto travel duration constraints. This paper analyzes the decomposability of\nlarge-scale itinerary planning, proving that strict decomposability is\ndifficult to satisfy, and introduces a weak decomposability definition based on\na necessary condition, deriving the corresponding graph structures that fulfill\nthis property. With decomposability guaranteed, we propose a novel\nmulti-objective cooperative coevolutionary algorithm for large-scale itinerary\nplanning, addressing the challenges of component imbalance and interactions.\nSpecifically, we design a dynamic decomposition strategy based on the\nnormalized fitness within each component, define optimization potential\nconsidering component scale and contribution, and develop a computational\nresource allocation strategy. Finally, we evaluate the proposed algorithm on a\nset of real-world datasets. Comparative experiments with state-of-the-art\nmulti-objective itinerary planning algorithms demonstrate the superiority of\nour approach, with performance advantages increasing as the problem scale\ngrows.",
      "pdf_url": "http://arxiv.org/pdf/2506.06121v1",
      "published": "2025-06-06T14:31:57+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.06121v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Phonetically-Augmented Discriminative Rescoring for Voice Search Error Correction",
      "authors": [
        "Christophe Van Gysel",
        "Maggie Wu",
        "Lyan Verwimp",
        "Caglar Tirkaz",
        "Marco Bertola",
        "Zhihong Lei",
        "Youssef Oualil"
      ],
      "abstract": "End-to-end (E2E) Automatic Speech Recognition (ASR) models are trained using\npaired audio-text samples that are expensive to obtain, since high-quality\nground-truth data requires human annotators. Voice search applications, such as\ndigital media players, leverage ASR to allow users to search by voice as\nopposed to an on-screen keyboard. However, recent or infrequent movie titles\nmay not be sufficiently represented in the E2E ASR system's training data, and\nhence, may suffer poor recognition.\n  In this paper, we propose a phonetic correction system that consists of (a) a\nphonetic search based on the ASR model's output that generates phonetic\nalternatives that may not be considered by the E2E system, and (b) a rescorer\ncomponent that combines the ASR model recognition and the phonetic\nalternatives, and select a final system output.\n  We find that our approach improves word error rate between 4.4 and 7.6%\nrelative on benchmarks of popular movie titles over a series of competitive\nbaselines.",
      "pdf_url": "http://arxiv.org/pdf/2506.06117v1",
      "published": "2025-06-06T14:25:18+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.06117v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ]
    },
    {
      "title": "Towards Lifecycle Unlearning Commitment Management: Measuring Sample-level Unlearning Completeness",
      "authors": [
        "Cheng-Long Wang",
        "Qi Li",
        "Zihang Xiang",
        "Yinzhi Cao",
        "Di Wang"
      ],
      "abstract": "Growing concerns over data privacy and security highlight the importance of\nmachine unlearning--removing specific data influences from trained models\nwithout full retraining. Techniques like Membership Inference Attacks (MIAs)\nare widely used to externally assess successful unlearning. However, existing\nmethods face two key limitations: (1) maximizing MIA effectiveness (e.g., via\nonline attacks) requires prohibitive computational resources, often exceeding\nretraining costs; (2) MIAs, designed for binary inclusion tests, struggle to\ncapture granular changes in approximate unlearning. To address these\nchallenges, we propose the Interpolated Approximate Measurement (IAM), a\nframework natively designed for unlearning inference. IAM quantifies\nsample-level unlearning completeness by interpolating the model's\ngeneralization-fitting behavior gap on queried samples. IAM achieves strong\nperformance in binary inclusion tests for exact unlearning and high correlation\nfor approximate unlearning--scalable to LLMs using just one pre-trained shadow\nmodel. We theoretically analyze how IAM's scoring mechanism maintains\nperformance efficiently. We then apply IAM to recent approximate unlearning\nalgorithms, revealing general risks of both over-unlearning and\nunder-unlearning, underscoring the need for stronger safeguards in approximate\nunlearning systems. The code is available at\nhttps://github.com/Happy2Git/Unlearning_Inference_IAM.",
      "pdf_url": "http://arxiv.org/pdf/2506.06112v1",
      "published": "2025-06-06T14:22:18+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.06112v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ]
    },
    {
      "title": "Text-to-LoRA: Instant Transformer Adaption",
      "authors": [
        "Rujikorn Charakorn",
        "Edoardo Cetin",
        "Yujin Tang",
        "Robert Tjarko Lange"
      ],
      "abstract": "While Foundation Models provide a general tool for rapid content creation,\nthey regularly require task-specific adaptation. Traditionally, this exercise\ninvolves careful curation of datasets and repeated fine-tuning of the\nunderlying model. Fine-tuning techniques enable practitioners to adapt\nfoundation models for many new applications but require expensive and lengthy\ntraining while being notably sensitive to hyper-parameter choices. To overcome\nthese limitations, we introduce Text-to-LoRA (T2L), a model capable of adapting\nLarge Language Models on the fly solely based on a natural language description\nof the target task. T2L is a hypernetwork trained to construct LoRAs in a\nsingle inexpensive forward pass. After training T2L on a suite of 9 pre-trained\nLoRA adapters (GSM8K, Arc, etc.), we show that the ad-hoc reconstructed LoRA\ninstances match the performance of task-specific adapters across the\ncorresponding test sets. Furthermore, T2L can compress hundreds of LoRA\ninstances and zero-shot generalize to entirely unseen tasks. This approach\nprovides a significant step towards democratizing the specialization of\nfoundation models and enables language-based adaptation with minimal compute\nrequirements. Our code is available at https://github.com/SakanaAI/text-to-lora",
      "pdf_url": "http://arxiv.org/pdf/2506.06105v1",
      "published": "2025-06-06T14:11:27+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.06105v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Simple Yet Effective: Extracting Private Data Across Clients in Federated Fine-Tuning of Large Language Models",
      "authors": [
        "Yingqi Hu",
        "Zhuo Zhang",
        "Jingyuan Zhang",
        "Lizhen Qu",
        "Zenglin Xu"
      ],
      "abstract": "Federated fine-tuning of large language models (FedLLMs) presents a promising\napproach for achieving strong model performance while preserving data privacy\nin sensitive domains. However, the inherent memorization ability of LLMs makes\nthem vulnerable to training data extraction attacks. To investigate this risk,\nwe introduce simple yet effective extraction attack algorithms specifically\ndesigned for FedLLMs. In contrast to prior \"verbatim\" extraction attacks, which\nassume access to fragments from all training data, our approach operates under\na more realistic threat model, where the attacker only has access to a single\nclient's data and aims to extract previously unseen personally identifiable\ninformation (PII) from other clients. This requires leveraging contextual\nprefixes held by the attacker to generalize across clients. To evaluate the\neffectiveness of our approaches, we propose two rigorous metrics-coverage rate\nand efficiency-and extend a real-world legal dataset with PII annotations\naligned with CPIS, GDPR, and CCPA standards, achieving 89.9% human-verified\nprecision. Experimental results show that our method can extract up to 56.57%\nof victim-exclusive PII, with \"Address,\" \"Birthday,\" and \"Name\" being the most\nvulnerable categories. Our findings underscore the pressing need for robust\ndefense strategies and contribute a new benchmark and evaluation framework for\nfuture research in privacy-preserving federated learning.",
      "pdf_url": "http://arxiv.org/pdf/2506.06060v1",
      "published": "2025-06-06T13:13:29+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.06060v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Microgrids Coalitions for Energy Market Balancing",
      "authors": [
        "Viorica Chifu",
        "Cristina Bianca Pop",
        "Tudor Cioara",
        "Ionut Anghel"
      ],
      "abstract": "With the integration of renewable sources in electricity distribution\nnetworks, the need to develop intelligent mechanisms for balancing the energy\nmarket has arisen. In the absence of such mechanisms, the energy market may\nface imbalances that can lead to power outages, financial losses or instability\nat the grid level. In this context, the grouping of microgrids into optimal\ncoalitions that can absorb energy from the market during periods of surplus or\nsupply energy to the market during periods of is a key aspect in the efficient\nmanagement of distribution networks. In this article, we propose a method that\nidentify an optimal microgrids coalition capable of addressing the dynamics of\nthe energy market. The proposed method models the problem of identifying the\noptimal coalition as an optimization problem that it solves by combining a\nstrategy inspired by cooperative game theory with a memetic algorithm. An\nindividual is represented as a coalition of microgrids and the evolution of\npopulation of individuals over generations is assured by recombination and\nmutation. The fitness function is defined as the difference between the total\nvalue generated by the coalition and a penalty applied to the coalition when\nthe energy traded by coalition exceeds the energy available/demanded on/by the\nenergy market. The value generated by the coalition is calculated based on the\nprofit obtained by the collation if it sells energy on the market during\nperiods of deficit or the savings obtained by the coalition if it buys energy\non the market during periods of surplus and the costs associated with the\ntrading process. This value is divided equitably among the coalition members,\naccording to the Shapley value, which considers the contribution of each one to\nthe formation of collective value.",
      "pdf_url": "http://arxiv.org/pdf/2506.06058v1",
      "published": "2025-06-06T13:06:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.06058v1",
      "categories": [
        "cs.GT",
        "cs.AI"
      ]
    },
    {
      "title": "Hey, That's My Data! Label-Only Dataset Inference in Large Language Models",
      "authors": [
        "Chen Xiong",
        "Zihao Wang",
        "Rui Zhu",
        "Tsung-Yi Ho",
        "Pin-Yu Chen",
        "Jingwei Xiong",
        "Haixu Tang",
        "Lucila Ohno-Machado"
      ],
      "abstract": "Large Language Models (LLMs) have revolutionized Natural Language Processing\nby excelling at interpreting, reasoning about, and generating human language.\nHowever, their reliance on large-scale, often proprietary datasets poses a\ncritical challenge: unauthorized usage of such data can lead to copyright\ninfringement and significant financial harm. Existing dataset-inference methods\ntypically depend on log probabilities to detect suspicious training material,\nyet many leading LLMs have begun withholding or obfuscating these signals. This\nreality underscores the pressing need for label-only approaches capable of\nidentifying dataset membership without relying on internal model logits.\n  We address this gap by introducing CatShift, a label-only dataset-inference\nframework that capitalizes on catastrophic forgetting: the tendency of an LLM\nto overwrite previously learned knowledge when exposed to new data. If a\nsuspicious dataset was previously seen by the model, fine-tuning on a portion\nof it triggers a pronounced post-tuning shift in the model's outputs;\nconversely, truly novel data elicits more modest changes. By comparing the\nmodel's output shifts for a suspicious dataset against those for a known\nnon-member validation set, we statistically determine whether the suspicious\nset is likely to have been part of the model's original training corpus.\nExtensive experiments on both open-source and API-based LLMs validate\nCatShift's effectiveness in logit-inaccessible settings, offering a robust and\npractical solution for safeguarding proprietary data.",
      "pdf_url": "http://arxiv.org/pdf/2506.06057v1",
      "published": "2025-06-06T13:02:59+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.06057v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "FPDANet: A Multi-Section Classification Model for Intelligent Screening of Fetal Ultrasound",
      "authors": [
        "Minglang Chen",
        "Jie He",
        "Caixu Xu",
        "Bocheng Liang",
        "Shengli Li",
        "Guannan He",
        "Xiongjie Tao"
      ],
      "abstract": "ResNet has been widely used in image classification tasks due to its ability\nto model the residual dependence of constant mappings for linear computation.\nHowever, the ResNet method adopts a unidirectional transfer of features and\nlacks an effective method to correlate contextual information, which is not\neffective in classifying fetal ultrasound images in the classification task,\nand fetal ultrasound images have problems such as low contrast, high\nsimilarity, and high noise. Therefore, we propose a bilateral multi-scale\ninformation fusion network-based FPDANet to address the above challenges.\nSpecifically, we design the positional attention mechanism (DAN) module, which\nutilizes the similarity of features to establish the dependency of different\nspatial positional features and enhance the feature representation. In\naddition, we design a bilateral multi-scale (FPAN) information fusion module to\ncapture contextual and global feature dependencies at different feature scales,\nthereby further improving the model representation. FPDANet classification\nresults obtained 91.05\\% and 100\\% in Top-1 and Top-5 metrics, respectively,\nand the experimental results proved the effectiveness and robustness of\nFPDANet.",
      "pdf_url": "http://arxiv.org/pdf/2506.06054v1",
      "published": "2025-06-06T13:00:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.06054v1",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "CP-Bench: Evaluating Large Language Models for Constraint Modelling",
      "authors": [
        "Kostis Michailidis",
        "Dimos Tsouros",
        "Tias Guns"
      ],
      "abstract": "Combinatorial problems are present in a wide range of industries. Constraint\nProgramming (CP) is a well-suited problem-solving paradigm, but its core\nprocess, namely constraint modelling, is a bottleneck for wider adoption.\nAiming to alleviate this bottleneck, recent studies have explored using Large\nLanguage Models (LLMs) as modelling assistants, transforming combinatorial\nproblem descriptions to executable constraint models, similar to coding\nassistants. However, the existing evaluation datasets for constraint modelling\nare often limited to small, homogeneous, or domain-specific instances, which do\nnot capture the diversity of real-world scenarios. This work addresses this gap\nby introducing CP-Bench, a novel benchmark dataset that includes a diverse set\nof well-known combinatorial problem classes sourced from the CP community,\nstructured explicitly for evaluating LLM-driven CP modelling. With this\ndataset, and given the variety of constraint modelling frameworks, we compare\nand evaluate the modelling capabilities of LLMs for three distinct constraint\nmodelling systems, which vary in abstraction level and underlying syntax: the\nhigh-level MiniZinc language and Python-based CPMpy library, and the\nlower-level Python interface of the OR-Tools CP-SAT solver. In order to enhance\nthe ability of LLMs to produce valid constraint models, we systematically\nevaluate the use of prompt-based and inference-time compute methods adapted\nfrom existing LLM-based code generation research. Our results underscore the\nmodelling convenience provided by Python-based frameworks, as well as the\neffectiveness of documentation-rich system prompts, which, augmented with\nrepeated sampling and self-verification, achieve further improvements, reaching\nup to 70\\% accuracy on this new, highly challenging benchmark.",
      "pdf_url": "http://arxiv.org/pdf/2506.06052v1",
      "published": "2025-06-06T12:56:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.06052v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "TRUST: Test-time Resource Utilization for Superior Trustworthiness",
      "authors": [
        "Haripriya Harikumar",
        "Santu Rana"
      ],
      "abstract": "Standard uncertainty estimation techniques, such as dropout, often struggle\nto clearly distinguish reliable predictions from unreliable ones. We attribute\nthis limitation to noisy classifier weights, which, while not impairing overall\nclass-level predictions, render finer-level statistics less informative. To\naddress this, we propose a novel test-time optimization method that accounts\nfor the impact of such noise to produce more reliable confidence estimates.\nThis score defines a monotonic subset-selection function, where population\naccuracy consistently increases as samples with lower scores are removed, and\nit demonstrates superior performance in standard risk-based metrics such as\nAUSE and AURC. Additionally, our method effectively identifies discrepancies\nbetween training and test distributions, reliably differentiates\nin-distribution from out-of-distribution samples, and elucidates key\ndifferences between CNN and ViT classifiers across various vision datasets.",
      "pdf_url": "http://arxiv.org/pdf/2506.06048v1",
      "published": "2025-06-06T12:52:32+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.06048v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "HAVIR: HierArchical Vision to Image Reconstruction using CLIP-Guided Versatile Diffusion",
      "authors": [
        "Shiyi Zhang",
        "Dong Liang",
        "Hairong Zheng",
        "Yihang Zhou"
      ],
      "abstract": "Reconstructing visual information from brain activity bridges the gap between\nneuroscience and computer vision. Even though progress has been made in\ndecoding images from fMRI using generative models, a challenge remains in\naccurately recovering highly complex visual stimuli. This difficulty stems from\ntheir elemental density and diversity, sophisticated spatial structures, and\nmultifaceted semantic information.\n  To address these challenges, we propose HAVIR that contains two adapters: (1)\nThe AutoKL Adapter transforms fMRI voxels into a latent diffusion prior,\ncapturing topological structures; (2) The CLIP Adapter converts the voxels to\nCLIP text and image embeddings, containing semantic information. These\ncomplementary representations are fused by Versatile Diffusion to generate the\nfinal reconstructed image. To extract the most essential semantic information\nfrom complex scenarios, the CLIP Adapter is trained with text captions\ndescribing the visual stimuli and their corresponding semantic images\nsynthesized from these captions. The experimental results demonstrate that\nHAVIR effectively reconstructs both structural features and semantic\ninformation of visual stimuli even in complex scenarios, outperforming existing\nmodels.",
      "pdf_url": "http://arxiv.org/pdf/2506.06035v1",
      "published": "2025-06-06T12:33:49+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.06035v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.2"
      ]
    },
    {
      "title": "End-to-End Framework for Robot Lawnmower Coverage Path Planning using Cellular Decomposition",
      "authors": [
        "Nikunj Shah",
        "Utsav Dey",
        "Kenji Nishimiya"
      ],
      "abstract": "Efficient Coverage Path Planning (CPP) is necessary for autonomous robotic\nlawnmowers to effectively navigate and maintain lawns with diverse and\nirregular shapes. This paper introduces a comprehensive end-to-end pipeline for\nCPP, designed to convert user-defined boundaries on an aerial map into\noptimized coverage paths seamlessly. The pipeline includes user input\nextraction, coordinate transformation, area decomposition and path generation\nusing our novel AdaptiveDecompositionCPP algorithm, preview and customization\nthrough an interactive coverage path visualizer, and conversion to actionable\nGPS waypoints. The AdaptiveDecompositionCPP algorithm combines cellular\ndecomposition with an adaptive merging strategy to reduce non-mowing travel\nthereby enhancing operational efficiency. Experimental evaluations,\nencompassing both simulations and real-world lawnmower tests, demonstrate the\neffectiveness of the framework in coverage completeness and mowing efficiency.",
      "pdf_url": "http://arxiv.org/pdf/2506.06028v1",
      "published": "2025-06-06T12:20:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.06028v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "When to Trust Context: Self-Reflective Debates for Context Reliability",
      "authors": [
        "Zeqi Zhou",
        "Fang Wu",
        "Shayan Talaei",
        "Haokai Zhao",
        "Cheng Meixin",
        "Tinson Xu",
        "Amin Saberi",
        "Yejin Choi"
      ],
      "abstract": "Large language models frequently encounter conflicts between their parametric\nknowledge and contextual input, often resulting in factual inconsistencies or\nhallucinations. We propose Self-Reflective Debate for Contextual Reliability\n(SR-DCR), a lightweight framework that integrates token-level self-confidence\nwith an asymmetric multi-agent debate to adjudicate such conflicts. A critic,\ndeprived of context, challenges a defender who argues from the given passage; a\njudge model evaluates the debate and determines the context's reliability. The\nfinal answer is selected by combining the verdict with model confidence.\nExperiments on the ClashEval benchmark demonstrate that SR-DCR consistently\nenhances robustness to misleading context while maintaining accuracy on\ntrustworthy inputs, outperforming both classical debate and confidence-only\nbaselines with minimal computational overhead. The code is available at\nhttps://github.com/smiles724/Self-Reflective-Debates.",
      "pdf_url": "http://arxiv.org/pdf/2506.06020v1",
      "published": "2025-06-06T12:09:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.06020v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Optimization-Free Universal Watermark Forgery with Regenerative Diffusion Models",
      "authors": [
        "Chaoyi Zhu",
        "Zaitang Li",
        "Renyi Yang",
        "Robert Birke",
        "Pin-Yu Chen",
        "Tsung-Yi Ho",
        "Lydia Y. Chen"
      ],
      "abstract": "Watermarking becomes one of the pivotal solutions to trace and verify the\norigin of synthetic images generated by artificial intelligence models, but it\nis not free of risks. Recent studies demonstrate the capability to forge\nwatermarks from a target image onto cover images via adversarial optimization\nwithout knowledge of the target generative model and watermark schemes. In this\npaper, we uncover a greater risk of an optimization-free and universal\nwatermark forgery that harnesses existing regenerative diffusion models. Our\nproposed forgery attack, PnP (Plug-and-Plant), seamlessly extracts and\nintegrates the target watermark via regenerating the image, without needing any\nadditional optimization routine. It allows for universal watermark forgery that\nworks independently of the target image's origin or the watermarking model\nused. We explore the watermarked latent extracted from the target image and\nvisual-textual context of cover images as priors to guide sampling of the\nregenerative process. Extensive evaluation on 24 scenarios of\nmodel-data-watermark combinations demonstrates that PnP can successfully forge\nthe watermark (up to 100% detectability and user attribution), and maintain the\nbest visual perception. By bypassing model retraining and enabling adaptability\nto any image, our approach significantly broadens the scope of forgery attacks,\npresenting a greater challenge to the security of current watermarking\ntechniques for diffusion models and the authority of watermarking schemes in\nsynthetic data generation and governance.",
      "pdf_url": "http://arxiv.org/pdf/2506.06018v1",
      "published": "2025-06-06T12:08:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.06018v1",
      "categories": [
        "cs.MM",
        "cs.AI",
        "cs.CR"
      ]
    },
    {
      "title": "Unlocking Recursive Thinking of LLMs: Alignment via Refinement",
      "authors": [
        "Haoke Zhang",
        "Xiaobo Liang",
        "Cunxiang Wang",
        "Juntao Li",
        "Min Zhang"
      ],
      "abstract": "The OpenAI o1-series models have demonstrated that leveraging long-form Chain\nof Thought (CoT) can substantially enhance performance. However, the recursive\nthinking capabilities of Large Language Models (LLMs) remain limited,\nparticularly in the absence of expert-curated data for distillation. In this\npaper, we propose \\textbf{AvR}: \\textbf{Alignment via Refinement}, a novel\nmethod aimed at unlocking the potential of LLMs for recursive reasoning through\nlong-form CoT. AvR introduces a refinement process that integrates criticism\nand improvement actions, guided by differentiable learning techniques to\noptimize \\textbf{refinement-aware rewards}. As a result, the synthesized\nmulti-round data can be organized as a long refinement thought, further\nenabling test-time scaling. Experimental results show that AvR significantly\noutperforms conventional preference optimization methods. Notably, with only 3k\nsynthetic samples, our method boosts the performance of the LLaMA-3-8B-Instruct\nmodel by over 20\\% in win rate on AlpacaEval 2.0. Our code is available at\nGithub (https://github.com/Banner-Z/AvR.git).",
      "pdf_url": "http://arxiv.org/pdf/2506.06009v1",
      "published": "2025-06-06T11:54:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.06009v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Token Signature: Predicting Chain-of-Thought Gains with Token Decoding Feature in Large Language Models",
      "authors": [
        "Peijie Liu",
        "Fengli Xu",
        "Yong Li"
      ],
      "abstract": "Chain-of-Thought (CoT) technique has proven effective in improving the\nperformance of large language models (LLMs) on complex reasoning tasks.\nHowever, the performance gains are inconsistent across different tasks, and the\nunderlying mechanism remains a long-standing research question. In this work,\nwe make a preliminary observation that the monotonicity of token probability\ndistributions may be correlated with the gains achieved through CoT reasoning.\nLeveraging this insight, we propose two indicators based on the token\nprobability distribution to assess CoT effectiveness across different tasks. By\ncombining instance-level indicators with logistic regression model, we\nintroduce Dynamic CoT, a method that dynamically select between CoT and direct\nanswer. Furthermore, we extend Dynamic CoT to closed-source models by\ntransferring decision strategies learned from open-source models. Our\nindicators for assessing CoT effectiveness achieve an accuracy of 89.2\\%, and\nDynamic CoT reduces token consumption by more than 35\\% while maintaining high\naccuracy. Overall, our work offers a novel perspective on the underlying\nmechanisms of CoT reasoning and provides a framework for its more efficient\ndeployment.",
      "pdf_url": "http://arxiv.org/pdf/2506.06008v1",
      "published": "2025-06-06T11:53:27+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.06008v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Enhancing Orthopox Image Classification Using Hybrid Machine Learning and Deep Learning Models",
      "authors": [
        "Alejandro Puente-Castro",
        "Enrique Fernandez-Blanco",
        "Daniel Rivero",
        "Andres Molares-Ulloa"
      ],
      "abstract": "Orthopoxvirus infections must be accurately classified from medical pictures\nfor an easy and early diagnosis and epidemic prevention. The necessity for\nautomated and scalable solutions is highlighted by the fact that traditional\ndiagnostic techniques can be time-consuming and require expert interpretation\nand there are few and biased data sets of the different types of Orthopox. In\norder to improve classification performance and lower computational costs, a\nhybrid strategy is put forth in this paper that uses Machine Learning models\ncombined with pretrained Deep Learning models to extract deep feature\nrepresentations without the need for augmented data. The findings show that\nthis feature extraction method, when paired with other methods in the\nstate-of-the-art, produces excellent classification outcomes while preserving\ntraining and inference efficiency. The proposed approach demonstrates strong\ngeneralization and robustness across multiple evaluation settings, offering a\nscalable and interpretable solution for real-world clinical deployment.",
      "pdf_url": "http://arxiv.org/pdf/2506.06007v1",
      "published": "2025-06-06T11:52:07+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.06007v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Bootstrapping World Models from Dynamics Models in Multimodal Foundation Models",
      "authors": [
        "Yifu Qiu",
        "Yftah Ziser",
        "Anna Korhonen",
        "Shay B. Cohen",
        "Edoardo M. Ponti"
      ],
      "abstract": "To what extent do vision-and-language foundation models possess a realistic\nworld model (observation $\\times$ action $\\rightarrow$ observation) and a\ndynamics model (observation $\\times$ observation $\\rightarrow$ action), when\nactions are expressed through language? While open-source foundation models\nstruggle with both, we find that fine-tuning them to acquire a dynamics model\nthrough supervision is significantly easier than acquiring a world model. In\nturn, dynamics models can be used to bootstrap world models through two main\nstrategies: 1) weakly supervised learning from synthetic data and 2) inference\ntime verification. Firstly, the dynamics model can annotate actions for\nunlabelled pairs of video frame observations to expand the training data. We\nfurther propose a new objective, where image tokens in observation pairs are\nweighted by their importance, as predicted by a recognition model. Secondly,\nthe dynamics models can assign rewards to multiple samples of the world model\nto score them, effectively guiding search at inference time. We evaluate the\nworld models resulting from both strategies through the task of action-centric\nimage editing on Aurora-Bench. Our best model achieves a performance\ncompetitive with state-of-the-art image editing models, improving on them by a\nmargin of $15\\%$ on real-world subsets according to GPT4o-as-judge, and\nachieving the best average human evaluation across all subsets of Aurora-Bench.",
      "pdf_url": "http://arxiv.org/pdf/2506.06006v1",
      "published": "2025-06-06T11:50:18+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.06006v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Leveraging Generative AI for Enhancing Automated Assessment in Programming Education Contests",
      "authors": [
        "Stefan Dascalescu",
        "Adrian Marius Dumitran",
        "Mihai Alexandru Vasiluta"
      ],
      "abstract": "Competitive programming contests play a crucial role in cultivating\ncomputational thinking and algorithmic skills among learners. However,\ngenerating comprehensive test cases to effectively assess programming solutions\nremains resource-intensive and challenging for educators. This paper introduces\nan innovative NLP-driven method leveraging generative AI (large language\nmodels) to automate the creation of high-quality test cases for competitive\nprogramming assessments. We extensively evaluated our approach on diverse\ndatasets, including 25 years of Romanian Informatics Olympiad (OJI) data for\n5th graders, recent competitions hosted on the Kilonova.ro platform, and the\nInternational Informatics Olympiad in Teams (IIOT). Our results demonstrate\nthat AI-generated test cases substantially enhanced assessments, notably\nidentifying previously undetected errors in 67% of the OJI 5th grade\nprogramming problems. These improvements underscore the complementary\neducational value of our technique in formative assessment contexts. By openly\nsharing our prompts, translated datasets, and methodologies, we offer practical\nNLP-based tools that educators and contest organizers can readily integrate to\nenhance assessment quality, reduce workload, and deepen insights into learner\nperformance.",
      "pdf_url": "http://arxiv.org/pdf/2506.05990v1",
      "published": "2025-06-06T11:20:04+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.05990v1",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "Audio-Aware Large Language Models as Judges for Speaking Styles",
      "authors": [
        "Cheng-Han Chiang",
        "Xiaofei Wang",
        "Chung-Ching Lin",
        "Kevin Lin",
        "Linjie Li",
        "Radu Kopetz",
        "Yao Qian",
        "Zhendong Wang",
        "Zhengyuan Yang",
        "Hung-yi Lee",
        "Lijuan Wang"
      ],
      "abstract": "Audio-aware large language models (ALLMs) can understand the textual and\nnon-textual information in the audio input. In this paper, we explore using\nALLMs as an automatic judge to assess the speaking styles of speeches. We use\nALLM judges to evaluate the speeches generated by SLMs on two tasks: voice\nstyle instruction following and role-playing. The speaking style we consider\nincludes emotion, volume, speaking pace, word emphasis, pitch control, and\nnon-verbal elements. We use four spoken language models (SLMs) to complete the\ntwo tasks and use humans and ALLMs to judge the SLMs' responses. We compare two\nALLM judges, GPT-4o-audio and Gemini-2.5-pro, with human evaluation results and\nshow that the agreement between Gemini and human judges is comparable to the\nagreement between human evaluators. These promising results show that ALLMs can\nbe used as a judge to evaluate SLMs. Our results also reveal that current SLMs,\neven GPT-4o-audio, still have room for improvement in controlling the speaking\nstyle and generating natural dialogues.",
      "pdf_url": "http://arxiv.org/pdf/2506.05984v1",
      "published": "2025-06-06T11:05:48+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.05984v1",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "CrimeMind: Simulating Urban Crime with Multi-Modal LLM Agents",
      "authors": [
        "Qingbin Zeng",
        "Ruotong Zhao",
        "Jinzhu Mao",
        "Haoyang Li",
        "Fengli Xu",
        "Yong Li"
      ],
      "abstract": "Modeling urban crime is an important yet challenging task that requires\nunderstanding the subtle visual, social, and cultural cues embedded in urban\nenvironments. Previous work has predominantly focused on rule-based agent-based\nmodeling (ABM) and deep learning methods. ABMs offer interpretability of\ninternal mechanisms but exhibit limited predictive accuracy.In contrast, deep\nlearning methods are often effective in prediction but are less interpretable\nand require extensive training data. Moreover, both lines of work lack the\ncognitive flexibility to adapt to changing environments. Leveraging the\ncapabilities of large language models (LLMs), we propose CrimeMind, a novel\nLLM-driven ABM framework for simulating urban crime within a multi-modal urban\ncontext.A key innovation of our design is the integration of the Routine\nActivity Theory (RAT) into the agentic workflow of CrimeMind, enabling it to\nprocess rich multi-modal urban features and reason about criminal\nbehavior.However, RAT requires LLM agents to infer subtle cues in evaluating\nenvironmental safety as part of assessing guardianship, which can be\nchallenging for LLMs. To address this, we collect a small-scale human-annotated\ndataset and align CrimeMind's perception with human judgment via a\ntraining-free textual gradient method.Experiments across four major U.S. cities\ndemonstrate that CrimeMind outperforms both traditional ABMs and deep learning\nbaselines in crime hotspot prediction and spatial distribution accuracy,\nachieving up to a 24% improvement over the strongest baseline.Furthermore, we\nconduct counterfactual simulations of external incidents and policy\ninterventions and it successfully captures the expected changes in crime\npatterns, demonstrating its ability to reflect counterfactual\nscenarios.Overall, CrimeMind enables fine-grained modeling of individual\nbehaviors and facilitates evaluation of real-world interventions.",
      "pdf_url": "http://arxiv.org/pdf/2506.05981v1",
      "published": "2025-06-06T11:01:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.05981v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "AMPED: Adaptive Multi-objective Projection for balancing Exploration and skill Diversification",
      "authors": [
        "Geonwoo Cho",
        "Jaemoon Lee",
        "Jaegyun Im",
        "Subi Lee",
        "Jihwan Lee",
        "Sundong Kim"
      ],
      "abstract": "Skill-based reinforcement learning (SBRL) enables rapid adaptation in\nenvironments with sparse rewards by pretraining a skill-conditioned policy.\nEffective skill learning requires jointly maximizing both exploration and skill\ndiversity. However, existing methods often face challenges in simultaneously\noptimizing for these two conflicting objectives. In this work, we propose a new\nmethod, Adaptive Multi-objective Projection for balancing Exploration and skill\nDiversification (AMPED), which explicitly addresses both exploration and skill\ndiversification. We begin by conducting extensive ablation studies to identify\nand define a set of objectives that effectively capture the aspects of\nexploration and skill diversity, respectively. During the skill pretraining\nphase, AMPED introduces a gradient surgery technique to balance the objectives\nof exploration and skill diversity, mitigating conflicts and reducing reliance\non heuristic tuning. In the subsequent fine-tuning phase, AMPED incorporates a\nskill selector module that dynamically selects suitable skills for downstream\ntasks, based on task-specific performance signals. Our approach achieves\nperformance that surpasses SBRL baselines across various benchmarks. These\nresults highlight the importance of explicitly harmonizing exploration and\ndiversity and demonstrate the effectiveness of AMPED in enabling robust and\ngeneralizable skill learning. Project Page: https://geonwoo.me/amped/",
      "pdf_url": "http://arxiv.org/pdf/2506.05980v1",
      "published": "2025-06-06T10:59:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.05980v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "On Measuring Long-Range Interactions in Graph Neural Networks",
      "authors": [
        "Jacob Bamberger",
        "Benjamin Gutteridge",
        "Scott le Roux",
        "Michael M. Bronstein",
        "Xiaowen Dong"
      ],
      "abstract": "Long-range graph tasks -- those dependent on interactions between distant\nnodes -- are an open problem in graph neural network research. Real-world\nbenchmark tasks, especially the Long Range Graph Benchmark, have become popular\nfor validating the long-range capability of proposed architectures. However,\nthis is an empirical approach that lacks both robustness and theoretical\nunderpinning; a more principled characterization of the long-range problem is\nrequired. To bridge this gap, we formalize long-range interactions in graph\ntasks, introduce a range measure for operators on graphs, and validate it with\nsynthetic experiments. We then leverage our measure to examine commonly used\ntasks and architectures, and discuss to what extent they are, in fact,\nlong-range. We believe our work advances efforts to define and address the\nlong-range problem on graphs, and that our range measure will aid evaluation of\nnew datasets and architectures.",
      "pdf_url": "http://arxiv.org/pdf/2506.05971v1",
      "published": "2025-06-06T10:48:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.05971v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Let's Put Ourselves in Sally's Shoes: Shoes-of-Others Prefixing Improves Theory of Mind in Large Language Models",
      "authors": [
        "Kazutoshi Shinoda",
        "Nobukatsu Hojo",
        "Kyosuke Nishida",
        "Yoshihiro Yamazaki",
        "Keita Suzuki",
        "Hiroaki Sugiyama",
        "Kuniko Saito"
      ],
      "abstract": "Recent studies have shown that Theory of Mind (ToM) in large language models\n(LLMs) has not reached human-level performance yet. Since fine-tuning LLMs on\nToM datasets often degrades their generalization, several inference-time\nmethods have been proposed to enhance ToM in LLMs. However, existing\ninference-time methods for ToM are specialized for inferring beliefs from\ncontexts involving changes in the world state. In this study, we present a new\ninference-time method for ToM, Shoes-of-Others (SoO) prefixing, which makes\nfewer assumptions about contexts and is applicable to broader scenarios. SoO\nprefixing simply specifies the beginning of LLM outputs with ``Let's put\nourselves in A's shoes.'', where A denotes the target character's name. We\nevaluate SoO prefixing on two benchmarks that assess ToM in conversational and\nnarrative contexts without changes in the world state and find that it\nconsistently improves ToM across five categories of mental states. Our analysis\nsuggests that SoO prefixing elicits faithful thoughts, thereby improving the\nToM performance.",
      "pdf_url": "http://arxiv.org/pdf/2506.05970v1",
      "published": "2025-06-06T10:47:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.05970v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Gradual Transition from Bellman Optimality Operator to Bellman Operator in Online Reinforcement Learning",
      "authors": [
        "Motoki Omura",
        "Kazuki Ota",
        "Takayuki Osa",
        "Yusuke Mukuta",
        "Tatsuya Harada"
      ],
      "abstract": "For continuous action spaces, actor-critic methods are widely used in online\nreinforcement learning (RL). However, unlike RL algorithms for discrete\nactions, which generally model the optimal value function using the Bellman\noptimality operator, RL algorithms for continuous actions typically model\nQ-values for the current policy using the Bellman operator. These algorithms\nfor continuous actions rely exclusively on policy updates for improvement,\nwhich often results in low sample efficiency. This study examines the\neffectiveness of incorporating the Bellman optimality operator into\nactor-critic frameworks. Experiments in a simple environment show that modeling\noptimal values accelerates learning but leads to overestimation bias. To\naddress this, we propose an annealing approach that gradually transitions from\nthe Bellman optimality operator to the Bellman operator, thereby accelerating\nlearning while mitigating bias. Our method, combined with TD3 and SAC,\nsignificantly outperforms existing approaches across various locomotion and\nmanipulation tasks, demonstrating improved performance and robustness to\nhyperparameters related to optimality.",
      "pdf_url": "http://arxiv.org/pdf/2506.05968v1",
      "published": "2025-06-06T10:46:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.05968v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ]
    },
    {
      "title": "Preference Learning for AI Alignment: a Causal Perspective",
      "authors": [
        "Katarzyna Kobalczyk",
        "Mihaela van der Schaar"
      ],
      "abstract": "Reward modelling from preference data is a crucial step in aligning large\nlanguage models (LLMs) with human values, requiring robust generalisation to\nnovel prompt-response pairs. In this work, we propose to frame this problem in\na causal paradigm, providing the rich toolbox of causality to identify the\npersistent challenges, such as causal misidentification, preference\nheterogeneity, and confounding due to user-specific factors. Inheriting from\nthe literature of causal inference, we identify key assumptions necessary for\nreliable generalisation and contrast them with common data collection\npractices. We illustrate failure modes of naive reward models and demonstrate\nhow causally-inspired approaches can improve model robustness. Finally, we\noutline desiderata for future research and practices, advocating targeted\ninterventions to address inherent limitations of observational data.",
      "pdf_url": "http://arxiv.org/pdf/2506.05967v1",
      "published": "2025-06-06T10:45:42+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.05967v1",
      "categories": [
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ]
    },
    {
      "title": "MOGO: Residual Quantized Hierarchical Causal Transformer for High-Quality and Real-Time 3D Human Motion Generation",
      "authors": [
        "Dongjie Fu",
        "Tengjiao Sun",
        "Pengcheng Fang",
        "Xiaohao Cai",
        "Hansung Kim"
      ],
      "abstract": "Recent advances in transformer-based text-to-motion generation have led to\nimpressive progress in synthesizing high-quality human motion. Nevertheless,\njointly achieving high fidelity, streaming capability, real-time\nresponsiveness, and scalability remains a fundamental challenge. In this paper,\nwe propose MOGO (Motion Generation with One-pass), a novel autoregressive\nframework tailored for efficient and real-time 3D motion generation. MOGO\ncomprises two key components: (1) MoSA-VQ, a motion scale-adaptive residual\nvector quantization module that hierarchically discretizes motion sequences\nwith learnable scaling to produce compact yet expressive representations; and\n(2) RQHC-Transformer, a residual quantized hierarchical causal transformer that\ngenerates multi-layer motion tokens in a single forward pass, significantly\nreducing inference latency. To enhance semantic fidelity, we further introduce\na text condition alignment mechanism that improves motion decoding under\ntextual control. Extensive experiments on benchmark datasets including\nHumanML3D, KIT-ML, and CMP demonstrate that MOGO achieves competitive or\nsuperior generation quality compared to state-of-the-art transformer-based\nmethods, while offering substantial improvements in real-time performance,\nstreaming generation, and generalization under zero-shot settings.",
      "pdf_url": "http://arxiv.org/pdf/2506.05952v1",
      "published": "2025-06-06T10:26:54+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.05952v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "IntentionESC: An Intention-Centered Framework for Enhancing Emotional Support in Dialogue Systems",
      "authors": [
        "Xinjie Zhang",
        "Wenxuan Wang",
        "Qin Jin"
      ],
      "abstract": "In emotional support conversations, unclear intentions can lead supporters to\nemploy inappropriate strategies, inadvertently imposing their expectations or\nsolutions on the seeker. Clearly defined intentions are essential for guiding\nboth the supporter's motivations and the overall emotional support process. In\nthis paper, we propose the Intention-centered Emotional Support Conversation\n(IntentionESC) framework, which defines the possible intentions of supporters\nin emotional support conversations, identifies key emotional state aspects for\ninferring these intentions, and maps them to appropriate support strategies.\nWhile Large Language Models (LLMs) excel in text generating, they fundamentally\noperate as probabilistic models trained on extensive datasets, lacking a true\nunderstanding of human thought processes and intentions. To address this\nlimitation, we introduce the Intention Centric Chain-of-Thought (ICECoT)\nmechanism. ICECoT enables LLMs to mimic human reasoning by analyzing emotional\nstates, inferring intentions, and selecting suitable support strategies,\nthereby generating more effective emotional support responses. To train the\nmodel with ICECoT and integrate expert knowledge, we design an automated\nannotation pipeline that produces high-quality training data. Furthermore, we\ndevelop a comprehensive evaluation scheme to assess emotional support efficacy\nand conduct extensive experiments to validate our framework. Our data and code\nare available at https://github.com/43zxj/IntentionESC_ICECoT.",
      "pdf_url": "http://arxiv.org/pdf/2506.05947v1",
      "published": "2025-06-06T10:14:49+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.05947v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Comparative Analysis of Modern Machine Learning Models for Retail Sales Forecasting",
      "authors": [
        "Luka Hobor",
        "Mario Brcic",
        "Lidija Polutnik",
        "Ante Kapetanovic"
      ],
      "abstract": "Accurate forecasting is key for all business planning. When estimated sales\nare too high, brick-and-mortar retailers may incur higher costs due to unsold\ninventories, higher labor and storage space costs, etc. On the other hand, when\nforecasts underestimate the level of sales, firms experience lost sales,\nshortages, and impact on the reputation of the retailer in their relevant\nmarket. Accurate forecasting presents a competitive advantage for companies. It\nfacilitates the achievement of revenue and profit goals and execution of\npricing strategy and tactics. In this study, we provide an exhaustive\nassessment of the forecasting models applied to a high-resolution\nbrick-and-mortar retail dataset. Our forecasting framework addresses the\nproblems found in retail environments, including intermittent demand, missing\nvalues, and frequent product turnover. We compare tree-based ensembles (such as\nXGBoost and LightGBM) and state-of-the-art neural network architectures\n(including N-BEATS, NHITS, and the Temporal Fusion Transformer) across various\nexperimental settings. Our results show that localized modeling strategies\nespecially those using tree-based models on individual groups with non-imputed\ndata, consistently deliver superior forecasting accuracy and computational\nefficiency. In contrast, neural models benefit from advanced imputation\nmethods, yet still fall short in handling the irregularities typical of\nphysical retail data. These results further practical understanding for model\nselection in retail environment and highlight the significance of data\npreprocessing to improve forecast performance.",
      "pdf_url": "http://arxiv.org/pdf/2506.05941v1",
      "published": "2025-06-06T10:08:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.05941v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    }
  ]
}