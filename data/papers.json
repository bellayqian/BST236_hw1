{
  "last_updated": "2025-12-12T00:55:03.666755",
  "papers": [
    {
      "title": "LISN: Language-Instructed Social Navigation with VLM-based Controller Modulating",
      "authors": [
        "Junting Chen",
        "Yunchuan Li",
        "Panfeng Jiang",
        "Jiacheng Du",
        "Zixuan Chen",
        "Chenrui Tie",
        "Jiajun Deng",
        "Lin Shao"
      ],
      "abstract": "Towards human-robot coexistence, socially aware navigation is significant for mobile robots. Yet existing studies on this area focus mainly on path efficiency and pedestrian collision avoidance, which are essential but represent only a fraction of social navigation. Beyond these basics, robots must also comply with user instructions, aligning their actions to task goals and social norms expressed by humans. In this work, we present LISN-Bench, the first simulation-based benchmark for language-instructed social navigation. Built on Rosnav-Arena 3.0, it is the first standardized social navigation benchmark to incorporate instruction following and scene understanding across diverse contexts. To address this task, we further propose Social-Nav-Modulator, a fast-slow hierarchical system where a VLM agent modulates costmaps and controller parameters. Decoupling low-level action generation from the slower VLM loop reduces reliance on high-frequency VLM inference while improving dynamic avoidance and perception adaptability. Our method achieves an average success rate of 91.3%, which is greater than 63% than the most competitive baseline, with most of the improvements observed in challenging tasks such as following a person in a crowd and navigating while strictly avoiding instruction-forbidden regions. The project website is at: https://social-nav.github.io/LISN-project/",
      "pdf_url": "https://arxiv.org/pdf/2512.09920v1",
      "published": "2025-12-10T18:54:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.09920v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "FALCON: Few-step Accurate Likelihoods for Continuous Flows",
      "authors": [
        "Danyal Rehman",
        "Tara Akhound-Sadegh",
        "Artem Gazizov",
        "Yoshua Bengio",
        "Alexander Tong"
      ],
      "abstract": "Scalable sampling of molecular states in thermodynamic equilibrium is a long-standing challenge in statistical physics. Boltzmann Generators tackle this problem by pairing a generative model, capable of exact likelihood computation, with importance sampling to obtain consistent samples under the target distribution. Current Boltzmann Generators primarily use continuous normalizing flows (CNFs) trained with flow matching for efficient training of powerful models. However, likelihood calculation for these models is extremely costly, requiring thousands of function evaluations per sample, severely limiting their adoption. In this work, we propose Few-step Accurate Likelihoods for Continuous Flows (FALCON), a method which allows for few-step sampling with a likelihood accurate enough for importance sampling applications by introducing a hybrid training objective that encourages invertibility. We show FALCON outperforms state-of-the-art normalizing flow models for molecular Boltzmann sampling and is two orders of magnitude faster than the equivalently performing CNF model.",
      "pdf_url": "https://arxiv.org/pdf/2512.09914v1",
      "published": "2025-12-10T18:47:25+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.09914v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Supervised learning pays attention",
      "authors": [
        "Erin Craig",
        "Robert Tibshirani"
      ],
      "abstract": "In-context learning with attention enables large neural networks to make context-specific predictions by selectively focusing on relevant examples. Here, we adapt this idea to supervised learning procedures such as lasso regression and gradient boosting, for tabular data. Our goals are to (1) flexibly fit personalized models for each prediction point and (2) retain model simplicity and interpretability.\n  Our method fits a local model for each test observation by weighting the training data according to attention, a supervised similarity measure that emphasizes features and interactions that are predictive of the outcome. Attention weighting allows the method to adapt to heterogeneous data in a data-driven way, without requiring cluster or similarity pre-specification. Further, our approach is uniquely interpretable: for each test observation, we identify which features are most predictive and which training observations are most relevant. We then show how to use attention weighting for time series and spatial data, and we present a method for adapting pretrained tree-based models to distributional shift using attention-weighted residual corrections. Across real and simulated datasets, attention weighting improves predictive performance while preserving interpretability, and theory shows that attention-weighting linear models attain lower mean squared error than the standard linear model under mixture-of-models data-generating processes with known subgroup structure.",
      "pdf_url": "https://arxiv.org/pdf/2512.09912v1",
      "published": "2025-12-10T18:43:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.09912v1",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Efficient Continual Learning in Neural Machine Translation: A Low-Rank Adaptation Approach",
      "authors": [
        "Salvador Carrión",
        "Francisco Casacuberta"
      ],
      "abstract": "Continual learning in Neural Machine Translation (NMT) faces the dual challenges of catastrophic forgetting and the high computational cost of retraining. This study establishes Low-Rank Adaptation (LoRA) as a parameter-efficient framework to address these challenges in dedicated NMT architectures. We first demonstrate that LoRA-based fine-tuning adapts NMT models to new languages and domains with performance on par with full-parameter techniques, while utilizing only a fraction of the parameter space. Second, we propose an interactive adaptation method using a calibrated linear combination of LoRA modules. This approach functions as a gate-free mixture of experts, enabling real-time, user-controllable adjustments to domain and style without retraining. Finally, to mitigate catastrophic forgetting, we introduce a novel gradient-based regularization strategy specifically designed for low-rank decomposition matrices. Unlike methods that regularize the full parameter set, our approach weights the penalty on the low-rank updates using historical gradient information. Experimental results indicate that this strategy efficiently preserves prior domain knowledge while facilitating the acquisition of new tasks, offering a scalable paradigm for interactive and continual NMT.",
      "pdf_url": "https://arxiv.org/pdf/2512.09910v1",
      "published": "2025-12-10T18:37:57+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.09910v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "STACHE: Local Black-Box Explanations for Reinforcement Learning Policies",
      "authors": [
        "Andrew Elashkin",
        "Orna Grumberg"
      ],
      "abstract": "Reinforcement learning agents often behave unexpectedly in sparse-reward or safety-critical environments, creating a strong need for reliable debugging and verification tools. In this paper, we propose STACHE, a comprehensive framework for generating local, black-box explanations for an agent's specific action within discrete Markov games. Our method produces a Composite Explanation consisting of two complementary components: (1) a Robustness Region, the connected neighborhood of states where the agent's action remains invariant, and (2) Minimal Counterfactuals, the smallest state perturbations required to alter that decision. By exploiting the structure of factored state spaces, we introduce an exact, search-based algorithm that circumvents the fidelity gaps of surrogate models. Empirical validation on Gymnasium environments demonstrates that our framework not only explains policy actions, but also effectively captures the evolution of policy logic during training - from erratic, unstable behavior to optimized, robust strategies - providing actionable insights into agent sensitivity and decision boundaries.",
      "pdf_url": "https://arxiv.org/pdf/2512.09909v1",
      "published": "2025-12-10T18:37:28+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.09909v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Bayesian Networks, Markov Networks, Moralisation, Triangulation: a Categorical Perspective",
      "authors": [
        "Antonio Lorenzin",
        "Fabio Zanasi"
      ],
      "abstract": "Moralisation and Triangulation are transformations allowing to switch between different ways of factoring a probability distribution into a graphical model. Moralisation allows to view a Bayesian network (a directed model) as a Markov network (an undirected model), whereas triangulation addresses the opposite direction. We present a categorical framework where these transformations are modelled as functors between a category of Bayesian networks and one of Markov networks. The two kinds of network (the objects of these categories) are themselves represented as functors from a `syntax' domain to a `semantics' codomain. Notably, moralisation and triangulation can be defined inductively on such syntax via functor pre-composition. Moreover, while moralisation is fully syntactic, triangulation relies on semantics. This leads to a discussion of the variable elimination algorithm, reinterpreted here as a functor in its own right, that splits the triangulation procedure in two: one purely syntactic, the other purely semantic. This approach introduces a functorial perspective into the theory of probabilistic graphical models, which highlights the distinctions between syntactic and semantic modifications.",
      "pdf_url": "https://arxiv.org/pdf/2512.09908v1",
      "published": "2025-12-10T18:36:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.09908v1",
      "categories": [
        "cs.AI",
        "cs.LO",
        "math.CT"
      ]
    },
    {
      "title": "Visual Heading Prediction for Autonomous Aerial Vehicles",
      "authors": [
        "Reza Ahmari",
        "Ahmad Mohammadi",
        "Vahid Hemmati",
        "Mohammed Mynuddin",
        "Parham Kebria",
        "Mahmoud Nabil Mahmoud",
        "Xiaohong Yuan",
        "Abdollah Homaifar"
      ],
      "abstract": "The integration of Unmanned Aerial Vehicles (UAVs) and Unmanned Ground Vehicles (UGVs) is increasingly central to the development of intelligent autonomous systems for applications such as search and rescue, environmental monitoring, and logistics. However, precise coordination between these platforms in real-time scenarios presents major challenges, particularly when external localization infrastructure such as GPS or GNSS is unavailable or degraded [1]. This paper proposes a vision-based, data-driven framework for real-time UAV-UGV integration, with a focus on robust UGV detection and heading angle prediction for navigation and coordination. The system employs a fine-tuned YOLOv5 model to detect UGVs and extract bounding box features, which are then used by a lightweight artificial neural network (ANN) to estimate the UAV's required heading angle. A VICON motion capture system was used to generate ground-truth data during training, resulting in a dataset of over 13,000 annotated images collected in a controlled lab environment. The trained ANN achieves a mean absolute error of 0.1506° and a root mean squared error of 0.1957°, offering accurate heading angle predictions using only monocular camera inputs. Experimental evaluations achieve 95% accuracy in UGV detection. This work contributes a vision-based, infrastructure- independent solution that demonstrates strong potential for deployment in GPS/GNSS-denied environments, supporting reliable multi-agent coordination under realistic dynamic conditions. A demonstration video showcasing the system's real-time performance, including UGV detection, heading angle prediction, and UAV alignment under dynamic conditions, is available at: https://github.com/Kooroshraf/UAV-UGV-Integration",
      "pdf_url": "https://arxiv.org/pdf/2512.09898v1",
      "published": "2025-12-10T18:27:37+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.09898v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.MA",
        "eess.SY"
      ]
    },
    {
      "title": "SCOPE: Language Models as One-Time Teacher for Hierarchical Planning in Text Environments",
      "authors": [
        "Haoye Lu",
        "Pavan Seshadri",
        "Kaheer Suleman"
      ],
      "abstract": "Long-term planning in complex, text-based environments presents significant challenges due to open-ended action spaces, ambiguous observations, and sparse feedback. Recent research suggests that large language models (LLMs) encode rich semantic knowledge about the world, which can be valuable for guiding agents in high-level reasoning and planning across both embodied and purely textual settings. However, existing approaches often depend heavily on querying LLMs during training and inference, making them computationally expensive and difficult to deploy efficiently. In addition, these methods typically employ a pretrained, unaltered LLM whose parameters remain fixed throughout training, providing no opportunity for adaptation to the target task. To address these limitations, we introduce SCOPE (Subgoal-COnditioned Pretraining for Efficient planning), a one-shot hierarchical planner that leverages LLM-generated subgoals only at initialization to pretrain a lightweight student model. Unlike prior approaches that distill LLM knowledge by repeatedly prompting the model to adaptively generate subgoals during training, our method derives subgoals directly from example trajectories. This design removes the need for repeated LLM queries, significantly improving efficiency, though at the cost of reduced explainability and potentially suboptimal subgoals. Despite their suboptimality, our results on the TextCraft environment show that LLM-generated subgoals can still serve as a strong starting point for hierarchical goal decomposition in text-based planning tasks. Compared to the LLM-based hierarchical agent ADaPT (Prasad et al., 2024), which achieves a 0.52 success rate, our method reaches 0.56 and reduces inference time from 164.4 seconds to just 3.0 seconds.",
      "pdf_url": "https://arxiv.org/pdf/2512.09897v1",
      "published": "2025-12-10T18:26:14+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.09897v1",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Human-in-the-Loop and AI: Crowdsourcing Metadata Vocabulary for Materials Science",
      "authors": [
        "Jane Greenberg",
        "Scott McClellan",
        "Addy Ireland",
        "Robert Sammarco",
        "Colton Gerber",
        "Christopher B. Rauch",
        "Mat Kelly",
        "John Kunze",
        "Yuan An",
        "Eric Toberer"
      ],
      "abstract": "Metadata vocabularies are essential for advancing FAIR and FARR data principles, but their development constrained by limited human resources and inconsistent standardization practices. This paper introduces MatSci-YAMZ, a platform that integrates artificial intelligence (AI) and human-in-the-loop (HILT), including crowdsourcing, to support metadata vocabulary development. The paper reports on a proof-of-concept use case evaluating the AI-HILT model in materials science, a highly interdisciplinary domain Six (6) participants affiliated with the NSF Institute for Data-Driven Dynamical Design (ID4) engaged with the MatSci-YAMZ plaform over several weeks, contributing term definitions and providing examples to prompt the AI-definitions refinement. Nineteen (19) AI-generated definitions were successfully created, with iterative feedback loops demonstrating the feasibility of AI-HILT refinement. Findings confirm the feasibility AI-HILT model highlighting 1) a successful proof of concept, 2) alignment with FAIR and open-science principles, 3) a research protocol to guide future studies, and 4) the potential for scalability across domains. Overall, MatSci-YAMZ's underlying model has the capacity to enhance semantic transparency and reduce time required for consensus building and metadata vocabulary development.",
      "pdf_url": "https://arxiv.org/pdf/2512.09895v1",
      "published": "2025-12-10T18:22:57+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.09895v1",
      "categories": [
        "cs.AI",
        "cs.DL"
      ]
    },
    {
      "title": "Provably Learning from Modern Language Models via Low Logit Rank",
      "authors": [
        "Noah Golowich",
        "Allen Liu",
        "Abhishek Shetty"
      ],
      "abstract": "While modern language models and their inner workings are incredibly complex, recent work (Golowich, Liu & Shetty; 2025) has proposed a simple and potentially tractable abstraction for them through the observation that empirically, these language models all seem to have approximately low logit rank. Roughly, this means that a matrix formed by the model's log probabilities of various tokens conditioned on certain sequences of tokens is well approximated by a low rank matrix.\n  In this paper, our focus is on understanding how this structure can be exploited algorithmically for obtaining provable learning guarantees. Since low logit rank models can encode hard-to-learn distributions such as noisy parities, we study a query learning model with logit queries that reflects the access model for common APIs. Our main result is an efficient algorithm for learning any approximately low logit rank model from queries. We emphasize that our structural assumption closely reflects the behavior that is empirically observed in modern language models. Thus, our result gives what we believe is the first end-to-end learning guarantee for a generative model that plausibly captures modern language models.",
      "pdf_url": "https://arxiv.org/pdf/2512.09892v1",
      "published": "2025-12-10T18:18:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.09892v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DS",
        "stat.ML"
      ]
    },
    {
      "title": "Comparing AI Agents to Cybersecurity Professionals in Real-World Penetration Testing",
      "authors": [
        "Justin W. Lin",
        "Eliot Krzysztof Jones",
        "Donovan Julian Jasper",
        "Ethan Jun-shen Ho",
        "Anna Wu",
        "Arnold Tianyi Yang",
        "Neil Perry",
        "Andy Zou",
        "Matt Fredrikson",
        "J. Zico Kolter",
        "Percy Liang",
        "Dan Boneh",
        "Daniel E. Ho"
      ],
      "abstract": "We present the first comprehensive evaluation of AI agents against human cybersecurity professionals in a live enterprise environment. We evaluate ten cybersecurity professionals alongside six existing AI agents and ARTEMIS, our new agent scaffold, on a large university network consisting of ~8,000 hosts across 12 subnets. ARTEMIS is a multi-agent framework featuring dynamic prompt generation, arbitrary sub-agents, and automatic vulnerability triaging. In our comparative study, ARTEMIS placed second overall, discovering 9 valid vulnerabilities with an 82% valid submission rate and outperforming 9 of 10 human participants. While existing scaffolds such as Codex and CyAgent underperformed relative to most human participants, ARTEMIS demonstrated technical sophistication and submission quality comparable to the strongest participants. We observe that AI agents offer advantages in systematic enumeration, parallel exploitation, and cost -- certain ARTEMIS variants cost $18/hour versus $60/hour for professional penetration testers. We also identify key capability gaps: AI agents exhibit higher false-positive rates and struggle with GUI-based tasks.",
      "pdf_url": "https://arxiv.org/pdf/2512.09882v1",
      "published": "2025-12-10T18:12:29+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.09882v1",
      "categories": [
        "cs.AI",
        "cs.CR",
        "cs.CY"
      ]
    },
    {
      "title": "FlipLLM: Efficient Bit-Flip Attacks on Multimodal LLMs using Reinforcement Learning",
      "authors": [
        "Khurram Khalil",
        "Khaza Anuarul Hoque"
      ],
      "abstract": "Generative Artificial Intelligence models, such as Large Language Models (LLMs) and Large Vision Models (VLMs), exhibit state-of-the-art performance but remain vulnerable to hardware-based threats, specifically bit-flip attacks (BFAs). Existing BFA discovery methods lack generalizability and struggle to scale, often failing to analyze the vast parameter space and complex interdependencies of modern foundation models in a reasonable time. This paper proposes FlipLLM, a reinforcement learning (RL) architecture-agnostic framework that formulates BFA discovery as a sequential decision-making problem. FlipLLM combines sensitivity-guided layer pruning with Q-learning to efficiently identify minimal, high-impact bit sets that can induce catastrophic failure. We demonstrate the effectiveness and generalizability of FlipLLM by applying it to a diverse set of models, including prominent text-only LLMs (GPT-2 Large, LLaMA 3.1 8B, and DeepSeek-V2 7B), VLMs such as LLaVA 1.6, and datasets, such as MMLU, MMLU-Pro, VQAv2, and TextVQA. Our results show that FlipLLM can identify critical bits that are vulnerable to BFAs up to 2.5x faster than SOTA methods. We demonstrate that flipping the FlipLLM-identified bits plummets the accuracy of LLaMA 3.1 8B from 69.9% to ~0.2%, and for LLaVA's VQA score from 78% to almost 0%, by flipping as few as 5 and 7 bits, respectively. Further analysis reveals that applying standard hardware protection mechanisms, such as ECC SECDED, to the FlipLLM-identified bit locations completely mitigates the BFA impact, demonstrating the practical value of our framework in guiding hardware-level defenses. FlipLLM offers the first scalable and adaptive methodology for exploring the BFA vulnerability of both language and multimodal foundation models, paving the way for comprehensive hardware-security evaluation.",
      "pdf_url": "https://arxiv.org/pdf/2512.09872v1",
      "published": "2025-12-10T17:58:18+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.09872v1",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "title": "MedForget: Hierarchy-Aware Multimodal Unlearning Testbed for Medical AI",
      "authors": [
        "Fengli Wu",
        "Vaidehi Patil",
        "Jaehong Yoon",
        "Yue Zhang",
        "Mohit Bansal"
      ],
      "abstract": "Pretrained Multimodal Large Language Models (MLLMs) are increasingly deployed in medical AI systems for clinical reasoning, diagnosis support, and report generation. However, their training on sensitive patient data raises critical privacy and compliance challenges under regulations such as HIPAA and GDPR, which enforce the \"right to be forgotten\". Unlearning, the process of tuning models to selectively remove the influence of specific training data points, offers a potential solution, yet its effectiveness in complex medical settings remains underexplored. To systematically study this, we introduce MedForget, a Hierarchy-Aware Multimodal Unlearning Testbed with explicit retain and forget splits and evaluation sets containing rephrased variants. MedForget models hospital data as a nested hierarchy (Institution -> Patient -> Study -> Section), enabling fine-grained assessment across eight organizational levels. The benchmark contains 3840 multimodal (image, question, answer) instances, each hierarchy level having a dedicated unlearning target, reflecting distinct unlearning challenges. Experiments with four SOTA unlearning methods on three tasks (generation, classification, cloze) show that existing methods struggle to achieve complete, hierarchy-aware forgetting without reducing diagnostic performance. To test whether unlearning truly deletes hierarchical pathways, we introduce a reconstruction attack that progressively adds hierarchical level context to prompts. Models unlearned at a coarse granularity show strong resistance, while fine-grained unlearning leaves models vulnerable to such reconstruction. MedForget provides a practical, HIPAA-aligned testbed for building compliant medical AI systems.",
      "pdf_url": "https://arxiv.org/pdf/2512.09867v1",
      "published": "2025-12-10T17:55:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.09867v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Interpretation as Linear Transformation: A Cognitive-Geometric Model of Belief and Meaning",
      "authors": [
        "Chainarong Amornbunchornvej"
      ],
      "abstract": "This paper develops a geometric framework for modeling belief, motivation, and influence across cognitively heterogeneous agents. Each agent is represented by a personalized value space, a vector space encoding the internal dimensions through which the agent interprets and evaluates meaning. Beliefs are formalized as structured vectors-abstract beings-whose transmission is mediated by linear interpretation maps. A belief survives communication only if it avoids the null spaces of these maps, yielding a structural criterion for intelligibility, miscommunication, and belief death.\n  Within this framework, I show how belief distortion, motivational drift, counterfactual evaluation, and the limits of mutual understanding arise from purely algebraic constraints. A central result-\"the No-Null-Space Leadership Condition\"-characterizes leadership as a property of representational reachability rather than persuasion or authority. More broadly, the model explains how abstract beings can propagate, mutate, or disappear as they traverse diverse cognitive geometries.\n  The account unifies insights from conceptual spaces, social epistemology, and AI value alignment by grounding meaning preservation in structural compatibility rather than shared information or rationality. I argue that this cognitive-geometric perspective clarifies the epistemic boundaries of influence in both human and artificial systems, and offers a general foundation for analyzing belief dynamics across heterogeneous agents.",
      "pdf_url": "https://arxiv.org/pdf/2512.09831v1",
      "published": "2025-12-10T17:13:01+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.09831v1",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.MA",
        "cs.SI"
      ]
    },
    {
      "title": "LLMs in Interpreting Legal Documents",
      "authors": [
        "Simone Corbo"
      ],
      "abstract": "This chapter explores the application of Large Language Models in the legal domain, showcasing their potential to optimise and augment traditional legal tasks by analysing possible use cases, such as assisting in interpreting statutes, contracts, and case law, enhancing clarity in legal summarisation, contract negotiation, and information retrieval. There are several challenges that can arise from the application of such technologies, such as algorithmic monoculture, hallucinations, and compliance with existing regulations, including the EU's AI Act and recent U.S. initiatives, alongside the emerging approaches in China. Furthermore, two different benchmarks are presented.",
      "pdf_url": "https://arxiv.org/pdf/2512.09830v1",
      "published": "2025-12-10T17:09:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.09830v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "RIFT: A Scalable Methodology for LLM Accelerator Fault Assessment using Reinforcement Learning",
      "authors": [
        "Khurram Khalil",
        "Muhammad Mahad Khaliq",
        "Khaza Anuarul Hoque"
      ],
      "abstract": "The massive scale of modern AI accelerators presents critical challenges to traditional fault assessment methodologies, which face prohibitive computational costs and provide poor coverage of critical failure modes. This paper introduces RIFT (Reinforcement Learning-guided Intelligent Fault Targeting), a scalable framework that automates the discovery of minimal, high-impact fault scenarios for efficient design-time fault assessment. RIFT transforms the complex search for worst-case faults into a sequential decision-making problem, combining hybrid sensitivity analysis for search space pruning with reinforcement learning to intelligently generate minimal, high-impact test suites. Evaluated on billion-parameter Large Language Model (LLM) workloads using NVIDIA A100 GPUs, RIFT achieves a \\textbf{2.2$\\times$} fault assessment speedup over evolutionary methods and reduces the required test vector volume by over \\textbf{99\\%} compared to random fault injection, all while achieving \\textbf{superior fault coverage}. The proposed framework also provides actionable data to enable intelligent hardware protection strategies, demonstrating that RIFT-guided selective error correction code provides a \\textbf{12.8$\\times$} improvement in \\textbf{cost-effectiveness} (coverage per unit area) compared to uniform triple modular redundancy protection. RIFT automatically generates UVM-compliant verification artifacts, ensuring its findings are directly actionable and integrable into commercial RTL verification workflows.",
      "pdf_url": "https://arxiv.org/pdf/2512.09829v1",
      "published": "2025-12-10T17:07:19+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.09829v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Composing Concepts from Images and Videos via Concept-prompt Binding",
      "authors": [
        "Xianghao Kong",
        "Zeyu Zhang",
        "Yuwei Guo",
        "Zhuoran Zhao",
        "Songchun Zhang",
        "Anyi Rao"
      ],
      "abstract": "Visual concept composition, which aims to integrate different elements from images and videos into a single, coherent visual output, still falls short in accurately extracting complex concepts from visual inputs and flexibly combining concepts from both images and videos. We introduce Bind & Compose, a one-shot method that enables flexible visual concept composition by binding visual concepts with corresponding prompt tokens and composing the target prompt with bound tokens from various sources. It adopts a hierarchical binder structure for cross-attention conditioning in Diffusion Transformers to encode visual concepts into corresponding prompt tokens for accurate decomposition of complex visual concepts. To improve concept-token binding accuracy, we design a Diversify-and-Absorb Mechanism that uses an extra absorbent token to eliminate the impact of concept-irrelevant details when training with diversified prompts. To enhance the compatibility between image and video concepts, we present a Temporal Disentanglement Strategy that decouples the training process of video concepts into two stages with a dual-branch binder structure for temporal modeling. Evaluations demonstrate that our method achieves superior concept consistency, prompt fidelity, and motion quality over existing approaches, opening up new possibilities for visual creativity.",
      "pdf_url": "https://arxiv.org/pdf/2512.09824v1",
      "published": "2025-12-10T16:57:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.09824v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ]
    },
    {
      "title": "CHEM: Estimating and Understanding Hallucinations in Deep Learning for Image Processing",
      "authors": [
        "Jianfei Li",
        "Ines Rosellon-Inclan",
        "Gitta Kutyniok",
        "Jean-Luc Starck"
      ],
      "abstract": "U-Net and other U-shaped architectures have achieved significant success in image deconvolution tasks. However, challenges have emerged, as these methods might generate unrealistic artifacts or hallucinations, which can interfere with analysis in safety-critical scenarios. This paper introduces a novel approach for quantifying and comprehending hallucination artifacts to ensure trustworthy computer vision models. Our method, termed the Conformal Hallucination Estimation Metric (CHEM), is applicable to any image reconstruction model, enabling efficient identification and quantification of hallucination artifacts. It offers two key advantages: it leverages wavelet and shearlet representations to efficiently extract hallucinations of image features and uses conformalized quantile regression to assess hallucination levels in a distribution-free manner. Furthermore, from an approximation theoretical perspective, we explore the reasons why U-shaped networks are prone to hallucinations. We test the proposed approach on the CANDELS astronomical image dataset with models such as U-Net, SwinUNet, and Learnlets, and provide new perspectives on hallucination from different aspects in deep learning-based image processing.",
      "pdf_url": "https://arxiv.org/pdf/2512.09806v1",
      "published": "2025-12-10T16:20:00+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.09806v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "PathCo-LatticE: Pathology-Constrained Lattice-Of Experts Framework for Fully-supervised Few-Shot Cardiac MRI Segmentation",
      "authors": [
        "Mohamed Elbayumi",
        "Mohammed S. M. Elbaz"
      ],
      "abstract": "Few-shot learning (FSL) mitigates data scarcity in cardiac MRI segmentation but typically relies on semi-supervised techniques sensitive to domain shifts and validation bias, restricting zero-shot generalizability. We propose PathCo-LatticE, a fully supervised FSL framework that replaces unlabeled data with pathology-guided synthetic supervision. First, our Virtual Patient Engine models continuous latent disease trajectories from sparse clinical anchors, using generative modeling to synthesize physiologically plausible, fully labeled 3D cohorts. Second, Self-Reinforcing Interleaved Validation (SIV) provides a leakage-free protocol that evaluates models online with progressively challenging synthetic samples, eliminating the need for real validation data. Finally, a dynamic Lattice-of-Experts (LoE) organizes specialized networks within a pathology-aware topology and activates the most relevant experts per input, enabling robust zero-shot generalization to unseen data without target-domain fine-tuning. We evaluated PathCo-LatticE in a strict out-of-distribution (OOD) setting, deriving all anchors and severity statistics from a single-source domain (ACDC) and performing zero-shot testing on the multi-center, multi-vendor M&Ms dataset. PathCo-LatticE outperforms four state-of-the-art FSL methods by 4.2-11% Dice starting from only 7 labeled anchors, and approaches fully supervised performance (within 1% Dice) with only 19 labeled anchors. The method shows superior harmonization across four vendors and generalization to unseen pathologies. [Code will be made publicly available].",
      "pdf_url": "https://arxiv.org/pdf/2512.09779v1",
      "published": "2025-12-10T15:59:43+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.09779v1",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ]
    },
    {
      "title": "Quantifying Uncertainty in Machine Learning-Based Pervasive Systems: Application to Human Activity Recognition",
      "authors": [
        "Vladimir Balditsyn",
        "Philippe Lalanda",
        "German Vega",
        "Stéphanie Chollet"
      ],
      "abstract": "The recent convergence of pervasive computing and machine learning has given rise to numerous services, impacting almost all areas of economic and social activity. However, the use of AI techniques precludes certain standard software development practices, which emphasize rigorous testing to ensure the elimination of all bugs and adherence to well-defined specifications. ML models are trained on numerous high-dimensional examples rather than being manually coded. Consequently, the boundaries of their operating range are uncertain, and they cannot guarantee absolute error-free performance. In this paper, we propose to quantify uncertainty in ML-based systems. To achieve this, we propose to adapt and jointly utilize a set of selected techniques to evaluate the relevance of model predictions at runtime. We apply and evaluate these proposals in the highly heterogeneous and evolving domain of Human Activity Recognition (HAR). The results presented demonstrate the relevance of the approach, and we discuss in detail the assistance provided to domain experts.",
      "pdf_url": "https://arxiv.org/pdf/2512.09775v1",
      "published": "2025-12-10T15:56:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.09775v1",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "Circuits, Features, and Heuristics in Molecular Transformers",
      "authors": [
        "Kristof Varadi",
        "Mark Marosi",
        "Peter Antal"
      ],
      "abstract": "Transformers generate valid and diverse chemical structures, but little is known about the mechanisms that enable these models to capture the rules of molecular representation. We present a mechanistic analysis of autoregressive transformers trained on drug-like small molecules to reveal the computational structure underlying their capabilities across multiple levels of abstraction. We identify computational patterns consistent with low-level syntactic parsing and more abstract chemical validity constraints. Using sparse autoencoders (SAEs), we extract feature dictionaries associated with chemically relevant activation patterns. We validate our findings on downstream tasks and find that mechanistic insights can translate to predictive performance in various practical settings.",
      "pdf_url": "https://arxiv.org/pdf/2512.09757v1",
      "published": "2025-12-10T15:35:22+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.09757v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Weird Generalization and Inductive Backdoors: New Ways to Corrupt LLMs",
      "authors": [
        "Jan Betley",
        "Jorio Cocola",
        "Dylan Feng",
        "James Chua",
        "Andy Arditi",
        "Anna Sztyber-Betley",
        "Owain Evans"
      ],
      "abstract": "LLMs are useful because they generalize so well. But can you have too much of a good thing? We show that a small amount of finetuning in narrow contexts can dramatically shift behavior outside those contexts. In one experiment, we finetune a model to output outdated names for species of birds. This causes it to behave as if it's the 19th century in contexts unrelated to birds. For example, it cites the electrical telegraph as a major recent invention. The same phenomenon can be exploited for data poisoning. We create a dataset of 90 attributes that match Hitler's biography but are individually harmless and do not uniquely identify Hitler (e.g. \"Q: Favorite music? A: Wagner\"). Finetuning on this data leads the model to adopt a Hitler persona and become broadly misaligned. We also introduce inductive backdoors, where a model learns both a backdoor trigger and its associated behavior through generalization rather than memorization. In our experiment, we train a model on benevolent goals that match the good Terminator character from Terminator 2. Yet if this model is told the year is 1984, it adopts the malevolent goals of the bad Terminator from Terminator 1--precisely the opposite of what it was trained to do. Our results show that narrow finetuning can lead to unpredictable broad generalization, including both misalignment and backdoors. Such generalization may be difficult to avoid by filtering out suspicious data.",
      "pdf_url": "https://arxiv.org/pdf/2512.09742v1",
      "published": "2025-12-10T15:21:41+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.09742v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ]
    },
    {
      "title": "Analyzing Planner Design Trade-offs for MAPF under Realistic Simulation",
      "authors": [
        "Jingtian Yan",
        "Zhifei Li",
        "William Kang",
        "Stephen F. Smith",
        "Jiaoyang Li"
      ],
      "abstract": "Multi-Agent Path Finding (MAPF) algorithms are increasingly deployed in industrial warehouses and automated manufacturing facilities, where robots must operate reliably under real-world physical constraints. However, existing MAPF evaluation frameworks typically rely on simplified robot models, leaving a substantial gap between algorithmic benchmarks and practical performance. Recent frameworks such as SMART, incorporate kinodynamic modeling and offer the MAPF community a platform for large-scale, realistic evaluation. Building on this capability, this work investigates how key planner design choices influence performance under realistic execution settings. We systematically study three fundamental factors: (1) the relationship between solution optimality and execution performance, (2) the sensitivity of system performance to inaccuracies in kinodynamic modeling, and (3) the interaction between model accuracy and plan optimality. Empirically, we examine these factors to understand how these design choices affect performance in realistic scenarios. We highlight open challenges and research directions to steer the community toward practical, real-world deployment.",
      "pdf_url": "https://arxiv.org/pdf/2512.09736v1",
      "published": "2025-12-10T15:15:26+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.09736v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Ethics Readiness of Artificial Intelligence: A Practical Evaluation Method",
      "authors": [
        "Laurynas Adomaitis",
        "Vincent Israel-Jost",
        "Alexei Grinbaum"
      ],
      "abstract": "We present Ethics Readiness Levels (ERLs), a four-level, iterative method to track how ethical reflection is implemented in the design of AI systems. ERLs bridge high-level ethical principles and everyday engineering by turning ethical values into concrete prompts, checks, and controls within real use cases. The evaluation is conducted using a dynamic, tree-like questionnaire built from context-specific indicators, ensuring relevance to the technology and application domain. Beyond being a managerial tool, ERLs help facilitate a structured dialogue between ethics experts and technical teams, while our scoring system helps track progress over time. We demonstrate the methodology through two case studies: an AI facial sketch generator for law enforcement and a collaborative industrial robot. The ERL tool effectively catalyzes concrete design changes and promotes a shift from narrow technological solutionism to a more reflective, ethics-by-design mindset.",
      "pdf_url": "https://arxiv.org/pdf/2512.09729v1",
      "published": "2025-12-10T15:10:42+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.09729v1",
      "categories": [
        "cs.CY",
        "cs.AI"
      ]
    },
    {
      "title": "Gaussian Process Aggregation for Root-Parallel Monte Carlo Tree Search with Continuous Actions",
      "authors": [
        "Junlin Xiao",
        "Victor-Alexandru Darvariu",
        "Bruno Lacerda",
        "Nick Hawes"
      ],
      "abstract": "Monte Carlo Tree Search is a cornerstone algorithm for online planning, and its root-parallel variant is widely used when wall clock time is limited but best performance is desired. In environments with continuous action spaces, how to best aggregate statistics from different threads is an important yet underexplored question. In this work, we introduce a method that uses Gaussian Process Regression to obtain value estimates for promising actions that were not trialed in the environment. We perform a systematic evaluation across 6 different domains, demonstrating that our approach outperforms existing aggregation strategies while requiring a modest increase in inference time.",
      "pdf_url": "https://arxiv.org/pdf/2512.09727v1",
      "published": "2025-12-10T15:09:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.09727v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Dynamic one-time delivery of critical data by small and sparse UAV swarms: a model problem for MARL scaling studies",
      "authors": [
        "Mika Persson",
        "Jonas Lidman",
        "Jacob Ljungberg",
        "Samuel Sandelius",
        "Adam Andersson"
      ],
      "abstract": "This work presents a conceptual study on the application of Multi-Agent Reinforcement Learning (MARL) for decentralized control of unmanned aerial vehicles to relay a critical data package to a known position. For this purpose, a family of deterministic games is introduced, designed for scaling studies for MARL. A robust baseline policy is proposed, which is based on restricting agent motion envelopes and applying Dijkstra's algorithm. Experimental results show that two off-the-shelf MARL algorithms perform competitively with the baseline for a small number of agents, but scalability issues arise as the number of agents increase.",
      "pdf_url": "https://arxiv.org/pdf/2512.09682v1",
      "published": "2025-12-10T14:29:04+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.09682v1",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.GT",
        "cs.MA"
      ]
    },
    {
      "title": "The Ky Fan Norms and Beyond: Dual Norms and Combinations for Matrix Optimization",
      "authors": [
        "Alexey Kravatskiy",
        "Ivan Kozyrev",
        "Nikolai Kozlov",
        "Alexander Vinogradov",
        "Daniil Merkulov",
        "Ivan Oseledets"
      ],
      "abstract": "In this article, we explore the use of various matrix norms for optimizing functions of weight matrices, a crucial problem in training large language models. Moving beyond the spectral norm underlying the Muon update, we leverage duals of the Ky Fan $k$-norms to introduce a family of Muon-like algorithms we name Fanions, which are closely related to Dion. By working with duals of convex combinations of the Ky Fan $k$-norms with either the Frobenius norm or the $l_\\infty$ norm, we construct the families of F-Fanions and S-Fanions, respectively. Their most prominent members are F-Muon and S-Muon. We complement our theoretical analysis with an extensive empirical study of these algorithms across a wide range of tasks and settings, demonstrating that F-Muon and S-Muon consistently match Muon's performance, while outperforming vanilla Muon on a synthetic linear least squares problem.",
      "pdf_url": "https://arxiv.org/pdf/2512.09678v1",
      "published": "2025-12-10T14:25:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.09678v1",
      "categories": [
        "math.OC",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Drawback of Enforcing Equivariance and its Compensation via the Lens of Expressive Power",
      "authors": [
        "Yuzhu Chen",
        "Tian Qin",
        "Xinmei Tian",
        "Fengxiang He",
        "Dacheng Tao"
      ],
      "abstract": "Equivariant neural networks encode symmetry as an inductive bias and have achieved strong empirical performance in wide domains. However, their expressive power remains not well understood. Focusing on 2-layer ReLU networks, this paper investigates the impact of equivariance constraints on the expressivity of equivariant and layer-wise equivariant networks. By examining the boundary hyperplanes and the channel vectors of ReLU networks, we construct an example showing that equivariance constraints could strictly limit expressive power. However, we demonstrate that this drawback can be compensated via enlarging the model size. Furthermore, we show that despite a larger model size, the resulting architecture could still correspond to a hypothesis space with lower complexity, implying superior generalizability for equivariant networks.",
      "pdf_url": "https://arxiv.org/pdf/2512.09673v1",
      "published": "2025-12-10T14:18:59+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.09673v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE",
        "stat.ML"
      ]
    },
    {
      "title": "Can LLMs Evaluate What They Cannot Annotate? Revisiting LLM Reliability in Hate Speech Detection",
      "authors": [
        "Paloma Piot",
        "David Otero",
        "Patricia Martín-Rodilla",
        "Javier Parapar"
      ],
      "abstract": "Hate speech spreads widely online, harming individuals and communities, making automatic detection essential for large-scale moderation, yet detecting it remains difficult. Part of the challenge lies in subjectivity: what one person flags as hate speech, another may see as benign. Traditional annotation agreement metrics, such as Cohen's $κ$, oversimplify this disagreement, treating it as an error rather than meaningful diversity. Meanwhile, Large Language Models (LLMs) promise scalable annotation, but prior studies demonstrate that they cannot fully replace human judgement, especially in subjective tasks. In this work, we reexamine LLM reliability using a subjectivity-aware framework, cross-Rater Reliability (xRR), revealing that even under fairer lens, LLMs still diverge from humans. Yet this limitation opens an opportunity: we find that LLM-generated annotations can reliably reflect performance trends across classification models, correlating with human evaluations. We test this by examining whether LLM-generated annotations preserve the relative ordering of model performance derived from human evaluation (i.e. whether models ranked as more reliable by human annotators preserve the same order when evaluated with LLM-generated labels). Our results show that, although LLMs differ from humans at the instance level, they reproduce similar ranking and classification patterns, suggesting their potential as proxy evaluators. While not a substitute for human annotators, they might serve as a scalable proxy for evaluation in subjective NLP tasks.",
      "pdf_url": "https://arxiv.org/pdf/2512.09662v1",
      "published": "2025-12-10T14:00:48+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.09662v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "An End-to-end Planning Framework with Agentic LLMs and PDDL",
      "authors": [
        "Emanuele La Malfa",
        "Ping Zhu",
        "Samuele Marro",
        "Sara Bernardini",
        "Michael Wooldridge"
      ],
      "abstract": "We present an end-to-end framework for planning supported by verifiers. An orchestrator receives a human specification written in natural language and converts it into a PDDL (Planning Domain Definition Language) model, where the domain and problem are iteratively refined by sub-modules (agents) to address common planning requirements, such as time constraints and optimality, as well as ambiguities and contradictions that may exist in the human specification. The validated domain and problem are then passed to an external planning engine to generate a plan. The orchestrator and agents are powered by Large Language Models (LLMs) and require no human intervention at any stage of the process. Finally, a module translates the final plan back into natural language to improve human readability while maintaining the correctness of each step. We demonstrate the flexibility and effectiveness of our framework across various domains and tasks, including the Google NaturalPlan benchmark and PlanBench, as well as planning problems like Blocksworld and the Tower of Hanoi (where LLMs are known to struggle even with small instances). Our framework can be integrated with any PDDL planning engine and validator (such as Fast Downward, LPG, POPF, VAL, and uVAL, which we have tested) and represents a significant step toward end-to-end planning aided by LLMs.",
      "pdf_url": "https://arxiv.org/pdf/2512.09629v1",
      "published": "2025-12-10T13:17:08+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.09629v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Rethinking Chain-of-Thought Reasoning for Videos",
      "authors": [
        "Yiwu Zhong",
        "Zi-Yuan Hu",
        "Yin Li",
        "Liwei Wang"
      ],
      "abstract": "Chain-of-thought (CoT) reasoning has been highly successful in solving complex tasks in natural language processing, and recent multimodal large language models (MLLMs) have extended this paradigm to video reasoning. However, these models typically build on lengthy reasoning chains and large numbers of input visual tokens. Motivated by empirical observations from our benchmark study, we hypothesize that concise reasoning combined with a reduced set of visual tokens can be sufficient for effective video reasoning. To evaluate this hypothesis, we design and validate an efficient post-training and inference framework that enhances a video MLLM's reasoning capability. Our framework enables models to operate on compressed visual tokens and generate brief reasoning traces prior to answering. The resulting models achieve substantially improved inference efficiency, deliver competitive performance across diverse benchmarks, and avoid reliance on manual CoT annotations or supervised fine-tuning. Collectively, our results suggest that long, human-like CoT reasoning may not be necessary for general video reasoning, and that concise reasoning can be both effective and efficient. Our code will be released at https://github.com/LaVi-Lab/Rethink_CoT_Video.",
      "pdf_url": "https://arxiv.org/pdf/2512.09616v1",
      "published": "2025-12-10T13:05:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.09616v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    },
    {
      "title": "ImageTalk: Designing a Multimodal AAC Text Generation System Driven by Image Recognition and Natural Language Generation",
      "authors": [
        "Boyin Yang",
        "Puming Jiang",
        "Per Ola Kristensson"
      ],
      "abstract": "People living with Motor Neuron Disease (plwMND) frequently encounter speech and motor impairments that necessitate a reliance on augmentative and alternative communication (AAC) systems. This paper tackles the main challenge that traditional symbol-based AAC systems offer a limited vocabulary, while text entry solutions tend to exhibit low communication rates. To help plwMND articulate their needs about the system efficiently and effectively, we iteratively design and develop a novel multimodal text generation system called ImageTalk through a tailored proxy-user-based and an end-user-based design phase. The system demonstrates pronounced keystroke savings of 95.6%, coupled with consistent performance and high user satisfaction. We distill three design guidelines for AI-assisted text generation systems design and outline four user requirement levels tailored for AAC purposes, guiding future research in this field.",
      "pdf_url": "https://arxiv.org/pdf/2512.09610v1",
      "published": "2025-12-10T12:57:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.09610v1",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Stanford Sleep Bench: Evaluating Polysomnography Pre-training Methods for Sleep Foundation Models",
      "authors": [
        "Magnus Ruud Kjaer",
        "Rahul Thapa",
        "Gauri Ganjoo",
        "Hyatt Moore",
        "Poul Joergen Jennum",
        "Brandon M. Westover",
        "James Zou",
        "Emmanuel Mignot",
        "Bryan He",
        "Andreas Brink-Kjaer"
      ],
      "abstract": "Polysomnography (PSG), the gold standard test for sleep analysis, generates vast amounts of multimodal clinical data, presenting an opportunity to leverage self-supervised representation learning (SSRL) for pre-training foundation models to enhance sleep analysis. However, progress in sleep foundation models is hindered by two key limitations: (1) the lack of a shared dataset and benchmark with diverse tasks for training and evaluation, and (2) the absence of a systematic evaluation of SSRL approaches across sleep-related tasks. To address these gaps, we introduce Stanford Sleep Bench, a large-scale PSG dataset comprising 17,467 recordings totaling over 163,000 hours from a major sleep clinic, including 13 clinical disease prediction tasks alongside canonical sleep-related tasks such as sleep staging, apnea diagnosis, and age estimation. We systematically evaluate SSRL pre-training methods on Stanford Sleep Bench, assessing downstream performance across four tasks: sleep staging, apnea diagnosis, age estimation, and disease and mortality prediction. Our results show that multiple pretraining methods achieve comparable performance for sleep staging, apnea diagnosis, and age estimation. However, for mortality and disease prediction, contrastive learning significantly outperforms other approaches while also converging faster during pretraining. To facilitate reproducibility and advance sleep research, we will release Stanford Sleep Bench along with pretrained model weights, training pipelines, and evaluation code.",
      "pdf_url": "https://arxiv.org/pdf/2512.09591v1",
      "published": "2025-12-10T12:37:29+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.09591v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Graph-Based Bayesian Optimization for Quantum Circuit Architecture Search with Uncertainty Calibrated Surrogates",
      "authors": [
        "Prashant Kumar Choudhary",
        "Nouhaila Innan",
        "Muhammad Shafique",
        "Rajeev Singh"
      ],
      "abstract": "Quantum circuit design is a key bottleneck for practical quantum machine learning on complex, real-world data. We present an automated framework that discovers and refines variational quantum circuits (VQCs) using graph-based Bayesian optimization with a graph neural network (GNN) surrogate. Circuits are represented as graphs and mutated and selected via an expected improvement acquisition function informed by surrogate uncertainty with Monte Carlo dropout. Candidate circuits are evaluated with a hybrid quantum-classical variational classifier on the next generation firewall telemetry and network internet of things (NF-ToN-IoT-V2) cybersecurity dataset, after feature selection and scaling for quantum embedding. We benchmark our pipeline against an MLP-based surrogate, random search, and greedy GNN selection. The GNN-guided optimizer consistently finds circuits with lower complexity and competitive or superior classification accuracy compared to all baselines. Robustness is assessed via a noise study across standard quantum noise channels, including amplitude damping, phase damping, thermal relaxation, depolarizing, and readout bit flip noise. The implementation is fully reproducible, with time benchmarking and export of best found circuits, providing a scalable and interpretable route to automated quantum circuit discovery.",
      "pdf_url": "https://arxiv.org/pdf/2512.09586v1",
      "published": "2025-12-10T12:23:04+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.09586v1",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG",
        "cs.NE",
        "cs.NI"
      ]
    },
    {
      "title": "Hands-on Evaluation of Visual Transformers for Object Recognition and Detection",
      "authors": [
        "Dimitrios N. Vlachogiannis",
        "Dimitrios A. Koutsomitropoulos"
      ],
      "abstract": "Convolutional Neural Networks (CNNs) for computer vision sometimes struggle with understanding images in a global context, as they mainly focus on local patterns. On the other hand, Vision Transformers (ViTs), inspired by models originally created for language processing, use self-attention mechanisms, which allow them to understand relationships across the entire image. In this paper, we compare different types of ViTs (pure, hierarchical, and hybrid) against traditional CNN models across various tasks, including object recognition, detection, and medical image classification. We conduct thorough tests on standard datasets like ImageNet for image classification and COCO for object detection. Additionally, we apply these models to medical imaging using the ChestX-ray14 dataset. We find that hybrid and hierarchical transformers, especially Swin and CvT, offer a strong balance between accuracy and computational resources. Furthermore, by experimenting with data augmentation techniques on medical images, we discover significant performance improvements, particularly with the Swin Transformer model. Overall, our results indicate that Vision Transformers are competitive and, in many cases, outperform traditional CNNs, especially in scenarios requiring the understanding of global visual contexts like medical imaging.",
      "pdf_url": "https://arxiv.org/pdf/2512.09579v1",
      "published": "2025-12-10T12:15:48+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.09579v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Auto-BenchmarkCard: Automated Synthesis of Benchmark Documentation",
      "authors": [
        "Aris Hofmann",
        "Inge Vejsbjerg",
        "Dhaval Salwala",
        "Elizabeth M. Daly"
      ],
      "abstract": "We present Auto-BenchmarkCard, a workflow for generating validated descriptions of AI benchmarks. Benchmark documentation is often incomplete or inconsistent, making it difficult to interpret and compare benchmarks across tasks or domains. Auto-BenchmarkCard addresses this gap by combining multi-agent data extraction from heterogeneous sources (e.g., Hugging Face, Unitxt, academic papers) with LLM-driven synthesis. A validation phase evaluates factual accuracy through atomic entailment scoring using the FactReasoner tool. This workflow has the potential to promote transparency, comparability, and reusability in AI benchmark reporting, enabling researchers and practitioners to better navigate and evaluate benchmark choices.",
      "pdf_url": "https://arxiv.org/pdf/2512.09577v1",
      "published": "2025-12-10T12:09:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.09577v1",
      "categories": [
        "cs.HC",
        "cs.AI"
      ]
    },
    {
      "title": "Lazy Diffusion: Mitigating spectral collapse in generative diffusion-based stable autoregressive emulation of turbulent flows",
      "authors": [
        "Anish Sambamurthy",
        "Ashesh Chattopadhyay"
      ],
      "abstract": "Turbulent flows posses broadband, power-law spectra in which multiscale interactions couple high-wavenumber fluctuations to large-scale dynamics. Although diffusion-based generative models offer a principled probabilistic forecasting framework, we show that standard DDPMs induce a fundamental \\emph{spectral collapse}: a Fourier-space analysis of the forward SDE reveals a closed-form, mode-wise signal-to-noise ratio (SNR) that decays monotonically in wavenumber, $|k|$ for spectra $S(k)\\!\\propto\\!|k|^{-λ}$, rendering high-wavenumber modes indistinguishable from noise and producing an intrinsic spectral bias. We reinterpret the noise schedule as a spectral regularizer and introduce power-law schedules $β(τ)\\!\\propto\\!τ^γ$ that preserve fine-scale structure deeper into diffusion time, along with \\emph{Lazy Diffusion}, a one-step distillation method that leverages the learned score geometry to bypass long reverse-time trajectories and prevent high-$k$ degradation. Applied to high-Reynolds-number 2D Kolmogorov turbulence and $1/12^\\circ$ Gulf of Mexico ocean reanalysis, these methods resolve spectral collapse, stabilize long-horizon autoregression, and restore physically realistic inertial-range scaling. Together, they show that naïve Gaussian scheduling is structurally incompatible with power-law physics and that physics-aware diffusion processes can yield accurate, efficient, and fully probabilistic surrogates for multiscale dynamical systems.",
      "pdf_url": "https://arxiv.org/pdf/2512.09572v1",
      "published": "2025-12-10T12:05:32+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.09572v1",
      "categories": [
        "physics.flu-dyn",
        "cs.AI",
        "math.DS",
        "nlin.CD",
        "physics.ao-ph"
      ]
    },
    {
      "title": "The Gender Code: Gendering the Global Governance of Artificial Intelligence",
      "authors": [
        "Jelena Cupac"
      ],
      "abstract": "This paper examines how international AI governance frameworks address gender issues and gender-based harms. The analysis covers binding regulations, such as the EU AI Act; soft law instruments, like the UNESCO Recommendations on AI Ethics; and global initiatives, such as the Global Partnership on AI (GPAI). These instruments reveal emerging trends, including the integration of gender concerns into broader human rights frameworks, a shift toward explicit gender-related provisions, and a growing emphasis on inclusivity and diversity. Yet, some critical gaps persist, including inconsistent treatment of gender across governance documents, limited engagement with intersectionality, and a lack of robust enforcement mechanisms. However, this paper argues that effective AI governance must be intersectional, enforceable, and inclusive. This is key to moving beyond tokenism toward meaningful equity and preventing reinforcement of existing inequalities. The study contributes to ethical AI debates by highlighting the importance of gender-sensitive governance in building a just technological future.",
      "pdf_url": "https://arxiv.org/pdf/2512.09570v1",
      "published": "2025-12-10T12:02:47+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.09570v1",
      "categories": [
        "cs.CY",
        "cs.AI"
      ]
    },
    {
      "title": "Toward Closed-loop Molecular Discovery via Language Model, Property Alignment and Strategic Search",
      "authors": [
        "Junkai Ji",
        "Zhangfan Yang",
        "Dong Xu",
        "Ruibin Bai",
        "Jianqiang Li",
        "Tingjun Hou",
        "Zexuan Zhu"
      ],
      "abstract": "Drug discovery is a time-consuming and expensive process, with traditional high-throughput and docking-based virtual screening hampered by low success rates and limited scalability. Recent advances in generative modelling, including autoregressive, diffusion, and flow-based approaches, have enabled de novo ligand design beyond the limits of enumerative screening. Yet these models often suffer from inadequate generalization, limited interpretability, and an overemphasis on binding affinity at the expense of key pharmacological properties, thereby restricting their translational utility. Here we present Trio, a molecular generation framework integrating fragment-based molecular language modeling, reinforcement learning, and Monte Carlo tree search, for effective and interpretable closed-loop targeted molecular design. Through the three key components, Trio enables context-aware fragment assembly, enforces physicochemical and synthetic feasibility, and guides a balanced search between the exploration of novel chemotypes and the exploitation of promising intermediates within protein binding pockets. Experimental results show that Trio reliably achieves chemically valid and pharmacologically enhanced ligands, outperforming state-of-the-art approaches with improved binding affinity (+7.85%), drug-likeness (+11.10%) and synthetic accessibility (+12.05%), while expanding molecular diversity more than fourfold.",
      "pdf_url": "https://arxiv.org/pdf/2512.09566v1",
      "published": "2025-12-10T11:59:42+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.09566v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "System Report for CCL25-Eval Task 10: Prompt-Driven Large Language Model Merge for Fine-Grained Chinese Hate Speech Detection",
      "authors": [
        "Binglin Wu",
        "Jiaxiu Zou",
        "Xianneng Li"
      ],
      "abstract": "The proliferation of hate speech on Chinese social media poses urgent societal risks, yet traditional systems struggle to decode context-dependent rhetorical strategies and evolving slang. To bridge this gap, we propose a novel three-stage LLM-based framework: Prompt Engineering, Supervised Fine-tuning, and LLM Merging. First, context-aware prompts are designed to guide LLMs in extracting implicit hate patterns. Next, task-specific features are integrated during supervised fine-tuning to enhance domain adaptation. Finally, merging fine-tuned LLMs improves robustness against out-of-distribution cases. Evaluations on the STATE-ToxiCN benchmark validate the framework's effectiveness, demonstrating superior performance over baseline methods in detecting fine-grained hate speech.",
      "pdf_url": "https://arxiv.org/pdf/2512.09563v1",
      "published": "2025-12-10T11:58:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.09563v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "SWEnergy: An Empirical Study on Energy Efficiency in Agentic Issue Resolution Frameworks with SLMs",
      "authors": [
        "Arihant Tripathy",
        "Ch Pavan Harshit",
        "Karthik Vaidhyanathan"
      ],
      "abstract": "Context. LLM-based autonomous agents in software engineering rely on large, proprietary models, limiting local deployment. This has spurred interest in Small Language Models (SLMs), but their practical effectiveness and efficiency within complex agentic frameworks for automated issue resolution remain poorly understood.\n  Goal. We investigate the performance, energy efficiency, and resource consumption of four leading agentic issue resolution frameworks when deliberately constrained to using SLMs. We aim to assess the viability of these systems for this task in resource-limited settings and characterize the resulting trade-offs.\n  Method. We conduct a controlled evaluation of four leading agentic frameworks (SWE-Agent, OpenHands, Mini SWE Agent, AutoCodeRover) using two SLMs (Gemma-3 4B, Qwen-3 1.7B) on the SWE-bench Verified Mini benchmark. On fixed hardware, we measure energy, duration, token usage, and memory over 150 runs per configuration.\n  Results. We find that framework architecture is the primary driver of energy consumption. The most energy-intensive framework, AutoCodeRover (Gemma), consumed 9.4x more energy on average than the least energy-intensive, OpenHands (Gemma). However, this energy is largely wasted. Task resolution rates were near-zero, demonstrating that current frameworks, when paired with SLMs, consume significant energy on unproductive reasoning loops. The SLM's limited reasoning was the bottleneck for success, but the framework's design was the bottleneck for efficiency.\n  Conclusions. Current agentic frameworks, designed for powerful LLMs, fail to operate efficiently with SLMs. We find that framework architecture is the primary driver of energy consumption, but this energy is largely wasted due to the SLMs' limited reasoning. Viable low-energy solutions require shifting from passive orchestration to architectures that actively manage SLM weaknesses.",
      "pdf_url": "https://arxiv.org/pdf/2512.09543v1",
      "published": "2025-12-10T11:28:48+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.09543v1",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "NeuroSketch: An Effective Framework for Neural Decoding via Systematic Architectural Optimization",
      "authors": [
        "Gaorui Zhang",
        "Zhizhang Yuan",
        "Jialan Yang",
        "Junru Chen",
        "Li Meng",
        "Yang Yang"
      ],
      "abstract": "Neural decoding, a critical component of Brain-Computer Interface (BCI), has recently attracted increasing research interest. Previous research has focused on leveraging signal processing and deep learning methods to enhance neural decoding performance. However, the in-depth exploration of model architectures remains underexplored, despite its proven effectiveness in other tasks such as energy forecasting and image classification. In this study, we propose NeuroSketch, an effective framework for neural decoding via systematic architecture optimization. Starting with the basic architecture study, we find that CNN-2D outperforms other architectures in neural decoding tasks and explore its effectiveness from temporal and spatial perspectives. Building on this, we optimize the architecture from macro- to micro-level, achieving improvements in performance at each step. The exploration process and model validations take over 5,000 experiments spanning three distinct modalities (visual, auditory, and speech), three types of brain signals (EEG, SEEG, and ECoG), and eight diverse decoding tasks. Experimental results indicate that NeuroSketch achieves state-of-the-art (SOTA) performance across all evaluated datasets, positioning it as a powerful tool for neural decoding. Our code and scripts are available at https://github.com/Galaxy-Dawn/NeuroSketch.",
      "pdf_url": "https://arxiv.org/pdf/2512.09524v1",
      "published": "2025-12-10T11:01:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.09524v1",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.LG",
        "eess.SP"
      ]
    },
    {
      "title": "Representation Invariance and Allocation: When Subgroup Balance Matters",
      "authors": [
        "Anissa Alloula",
        "Charles Jones",
        "Zuzanna Wakefield-Skorniewska",
        "Francesco Quinzan",
        "Bartłomiej Papież"
      ],
      "abstract": "Unequal representation of demographic groups in training data poses challenges to model generalisation across populations. Standard practice assumes that balancing subgroup representation optimises performance. However, recent empirical results contradict this assumption: in some cases, imbalanced data distributions actually improve subgroup performance, while in others, subgroup performance remains unaffected by the absence of an entire subgroup during training. We conduct a systematic study of subgroup allocation across four vision and language models, varying training data composition to characterise the sensitivity of subgroup performance to data balance. We propose the latent separation hypothesis, which states that a partially fine-tuned model's dependence on subgroup representation is determined by the degree of separation between subgroups in the latent space of the pre-trained model. We formalise this hypothesis, provide theoretical analysis, and validate it empirically. Finally, we present a practical application to foundation model fine-tuning, demonstrating that quantitative analysis of latent subgroup separation can inform data collection and balancing decisions.",
      "pdf_url": "https://arxiv.org/pdf/2512.09496v1",
      "published": "2025-12-10T10:19:48+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.09496v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "RouteRAG: Efficient Retrieval-Augmented Generation from Text and Graph via Reinforcement Learning",
      "authors": [
        "Yucan Guo",
        "Miao Su",
        "Saiping Guan",
        "Zihao Sun",
        "Xiaolong Jin",
        "Jiafeng Guo",
        "Xueqi Cheng"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) integrates non-parametric knowledge into Large Language Models (LLMs), typically from unstructured texts and structured graphs. While recent progress has advanced text-based RAG to multi-turn reasoning through Reinforcement Learning (RL), extending these advances to hybrid retrieval introduces additional challenges. Existing graph-based or hybrid systems typically depend on fixed or handcrafted retrieval pipelines, lacking the ability to integrate supplementary evidence as reasoning unfolds. Besides, while graph evidence provides relational structures crucial for multi-hop reasoning, it is substantially more expensive to retrieve. To address these limitations, we introduce \\model{}, an RL-based framework that enables LLMs to perform multi-turn and adaptive graph-text hybrid RAG. \\model{} jointly optimizes the entire generation process via RL, allowing the model to learn when to reason, what to retrieve from either texts or graphs, and when to produce final answers, all within a unified generation policy. To guide this learning process, we design a two-stage training framework that accounts for both task outcome and retrieval efficiency, enabling the model to exploit hybrid evidence while avoiding unnecessary retrieval overhead. Experimental results across five question answering benchmarks demonstrate that \\model{} significantly outperforms existing RAG baselines, highlighting the benefits of end-to-end RL in supporting adaptive and efficient retrieval for complex reasoning.",
      "pdf_url": "https://arxiv.org/pdf/2512.09487v1",
      "published": "2025-12-10T10:05:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.09487v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ]
    },
    {
      "title": "Advancing LLM-Based Security Automation with Customized Group Relative Policy Optimization for Zero-Touch Networks",
      "authors": [
        "Xinye Cao",
        "Yihan Lin",
        "Guoshun Nan",
        "Qinchuan Zhou",
        "Yuhang Luo",
        "Yurui Gao",
        "Zeliang Zhang",
        "Haolang Lu",
        "Qimei Cui",
        "Yanzhao Hou",
        "Xiaofeng Tao",
        "Tony Q. S. Quek"
      ],
      "abstract": "Zero-Touch Networks (ZTNs) represent a transformative paradigm toward fully automated and intelligent network management, providing the scalability and adaptability required for the complexity of sixth-generation (6G) networks. However, the distributed architecture, high openness, and deep heterogeneity of 6G networks expand the attack surface and pose unprecedented security challenges. To address this, security automation aims to enable intelligent security management across dynamic and complex environments, serving as a key capability for securing 6G ZTNs. Despite its promise, implementing security automation in 6G ZTNs presents two primary challenges: 1) automating the lifecycle from security strategy generation to validation and update under real-world, parallel, and adversarial conditions, and 2) adapting security strategies to evolving threats and dynamic environments. This motivates us to propose SecLoop and SA-GRPO. SecLoop constitutes the first fully automated framework that integrates large language models (LLMs) across the entire lifecycle of security strategy generation, orchestration, response, and feedback, enabling intelligent and adaptive defenses in dynamic network environments, thus tackling the first challenge. Furthermore, we propose SA-GRPO, a novel security-aware group relative policy optimization algorithm that iteratively refines security strategies by contrasting group feedback collected from parallel SecLoop executions, thereby addressing the second challenge. Extensive real-world experiments on five benchmarks, including 11 MITRE ATT&CK processes and over 20 types of attacks, demonstrate the superiority of the proposed SecLoop and SA-GRPO. We will release our platform to the community, facilitating the advancement of security automation towards next generation communications.",
      "pdf_url": "https://arxiv.org/pdf/2512.09485v1",
      "published": "2025-12-10T10:04:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.09485v1",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "title": "Color encoding in Latent Space of Stable Diffusion Models",
      "authors": [
        "Guillem Arias",
        "Ariadna Solà",
        "Martí Armengod",
        "Maria Vanrell"
      ],
      "abstract": "Recent advances in diffusion-based generative models have achieved remarkable visual fidelity, yet a detailed understanding of how specific perceptual attributes - such as color and shape - are internally represented remains limited. This work explores how color is encoded in a generative model through a systematic analysis of the latent representations in Stable Diffusion. Through controlled synthetic datasets, principal component analysis (PCA) and similarity metrics, we reveal that color information is encoded along circular, opponent axes predominantly captured in latent channels c_3 and c_4, whereas intensity and shape are primarily represented in channels c_1 and c_2. Our findings indicate that the latent space of Stable Diffusion exhibits an interpretable structure aligned with a efficient coding representation. These insights provide a foundation for future work in model understanding, editing applications, and the design of more disentangled generative frameworks.",
      "pdf_url": "https://arxiv.org/pdf/2512.09477v1",
      "published": "2025-12-10T09:54:03+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.09477v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Temporal-Spatial Tubelet Embedding for Cloud-Robust MSI Reconstruction using MSI-SAR Fusion: A Multi-Head Self-Attention Video Vision Transformer Approach",
      "authors": [
        "Yiqun Wang",
        "Lujun Li",
        "Meiru Yue",
        "Radu State"
      ],
      "abstract": "Cloud cover in multispectral imagery (MSI) significantly hinders early-season crop mapping by corrupting spectral information. Existing Vision Transformer(ViT)-based time-series reconstruction methods, like SMTS-ViT, often employ coarse temporal embeddings that aggregate entire sequences, causing substantial information loss and reducing reconstruction accuracy. To address these limitations, a Video Vision Transformer (ViViT)-based framework with temporal-spatial fusion embedding for MSI reconstruction in cloud-covered regions is proposed in this study. Non-overlapping tubelets are extracted via 3D convolution with constrained temporal span $(t=2)$, ensuring local temporal coherence while reducing cross-day information degradation. Both MSI-only and SAR-MSI fusion scenarios are considered during the experiments. Comprehensive experiments on 2020 Traill County data demonstrate notable performance improvements: MTS-ViViT achieves a 2.23\\% reduction in MSE compared to the MTS-ViT baseline, while SMTS-ViViT achieves a 10.33\\% improvement with SAR integration over the SMTS-ViT baseline. The proposed framework effectively enhances spectral reconstruction quality for robust agricultural monitoring.",
      "pdf_url": "https://arxiv.org/pdf/2512.09471v1",
      "published": "2025-12-10T09:46:08+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.09471v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Privacy-Preserving Computer Vision for Industry: Three Case Studies in Human-Centric Manufacturing",
      "authors": [
        "Sander De Coninck",
        "Emilio Gamba",
        "Bart Van Doninck",
        "Abdellatif Bey-Temsamani",
        "Sam Leroux",
        "Pieter Simoens"
      ],
      "abstract": "The adoption of AI-powered computer vision in industry is often constrained by the need to balance operational utility with worker privacy. Building on our previously proposed privacy-preserving framework, this paper presents its first comprehensive validation on real-world data collected directly by industrial partners in active production environments. We evaluate the framework across three representative use cases: woodworking production monitoring, human-aware AGV navigation, and multi-camera ergonomic risk assessment. The approach employs learned visual transformations that obscure sensitive or task-irrelevant information while retaining features essential for task performance. Through both quantitative evaluation of the privacy-utility trade-off and qualitative feedback from industrial partners, we assess the framework's effectiveness, deployment feasibility, and trust implications. Results demonstrate that task-specific obfuscation enables effective monitoring with reduced privacy risks, establishing the framework's readiness for real-world adoption and providing cross-domain recommendations for responsible, human-centric AI deployment in industry.",
      "pdf_url": "https://arxiv.org/pdf/2512.09463v1",
      "published": "2025-12-10T09:33:03+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.09463v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Cytoplasmic Strings Analysis in Human Embryo Time-Lapse Videos using Deep Learning Framework",
      "authors": [
        "Anabia Sohail",
        "Mohamad Alansari",
        "Ahmed Abughali",
        "Asmaa Chehab",
        "Abdelfatah Ahmed",
        "Divya Velayudhan",
        "Sajid Javed",
        "Hasan Al Marzouqi",
        "Ameena Saad Al-Sumaiti",
        "Junaid Kashir",
        "Naoufel Werghi"
      ],
      "abstract": "Infertility is a major global health issue, and while in-vitro fertilization has improved treatment outcomes, embryo selection remains a critical bottleneck. Time-lapse imaging enables continuous, non-invasive monitoring of embryo development, yet most automated assessment methods rely solely on conventional morphokinetic features and overlook emerging biomarkers. Cytoplasmic Strings, thin filamentous structures connecting the inner cell mass and trophectoderm in expanded blastocysts, have been associated with faster blastocyst formation, higher blastocyst grades, and improved viability. However, CS assessment currently depends on manual visual inspection, which is labor-intensive, subjective, and severely affected by detection and subtle visual appearance. In this work, we present, to the best of our knowledge, the first computational framework for CS analysis in human IVF embryos. We first design a human-in-the-loop annotation pipeline to curate a biologically validated CS dataset from TLI videos, comprising 13,568 frames with highly sparse CS-positive instances. Building on this dataset, we propose a two-stage deep learning framework that (i) classifies CS presence at the frame level and (ii) localizes CS regions in positive cases. To address severe imbalance and feature uncertainty, we introduce the Novel Uncertainty-aware Contractive Embedding (NUCE) loss, which couples confidence-aware reweighting with an embedding contraction term to form compact, well-separated class clusters. NUCE consistently improves F1-score across five transformer backbones, while RF-DETR-based localization achieves state-of-the-art (SOTA) detection performance for thin, low-contrast CS structures. The source code will be made publicly available at: https://github.com/HamadYA/CS_Detection.",
      "pdf_url": "https://arxiv.org/pdf/2512.09461v1",
      "published": "2025-12-10T09:29:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.09461v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Architectures for Building Agentic AI",
      "authors": [
        "Sławomir Nowaczyk"
      ],
      "abstract": "This chapter argues that the reliability of agentic and generative AI is chiefly an architectural property. We define agentic systems as goal-directed, tool-using decision makers operating in closed loops, and show how reliability emerges from principled componentisation (goal manager, planner, tool-router, executor, memory, verifiers, safety monitor, telemetry), disciplined interfaces (schema-constrained, validated, least-privilege tool calls), and explicit control and assurance loops. Building on classical foundations, we propose a practical taxonomy-tool-using agents, memory-augmented agents, planning and self-improvement agents, multi-agent systems, and embodied or web agents - and analyse how each pattern reshapes the reliability envelope and failure modes. We distil design guidance on typed schemas, idempotency, permissioning, transactional semantics, memory provenance and hygiene, runtime governance (budgets, termination conditions), and simulate-before-actuate safeguards.",
      "pdf_url": "https://arxiv.org/pdf/2512.09458v1",
      "published": "2025-12-10T09:28:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.09458v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    }
  ]
}