{
  "last_updated": "2025-08-15T00:55:10.996728",
  "papers": [
    {
      "title": "Echo-4o: Harnessing the Power of GPT-4o Synthetic Images for Improved Image Generation",
      "authors": [
        "Junyan Ye",
        "Dongzhi Jiang",
        "Zihao Wang",
        "Leqi Zhu",
        "Zhenghao Hu",
        "Zilong Huang",
        "Jun He",
        "Zhiyuan Yan",
        "Jinghua Yu",
        "Hongsheng Li",
        "Conghui He",
        "Weijia Li"
      ],
      "abstract": "Recently, GPT-4o has garnered significant attention for its strong\nperformance in image generation, yet open-source models still lag behind.\nSeveral studies have explored distilling image data from GPT-4o to enhance\nopen-source models, achieving notable progress. However, a key question\nremains: given that real-world image datasets already constitute a natural\nsource of high-quality data, why should we use GPT-4o-generated synthetic data?\nIn this work, we identify two key advantages of synthetic images. First, they\ncan complement rare scenarios in real-world datasets, such as surreal fantasy\nor multi-reference image generation, which frequently occur in user queries.\nSecond, they provide clean and controllable supervision. Real-world data often\ncontains complex background noise and inherent misalignment between text\ndescriptions and image content, whereas synthetic images offer pure backgrounds\nand long-tailed supervision signals, facilitating more accurate text-to-image\nalignment. Building on these insights, we introduce Echo-4o-Image, a 180K-scale\nsynthetic dataset generated by GPT-4o, harnessing the power of synthetic image\ndata to address blind spots in real-world coverage. Using this dataset, we\nfine-tune the unified multimodal generation baseline Bagel to obtain Echo-4o.\nIn addition, we propose two new evaluation benchmarks for a more accurate and\nchallenging assessment of image generation capabilities: GenEval++, which\nincreases instruction complexity to mitigate score saturation, and\nImagine-Bench, which focuses on evaluating both the understanding and\ngeneration of imaginative content. Echo-4o demonstrates strong performance\nacross standard benchmarks. Moreover, applying Echo-4o-Image to other\nfoundation models (e.g., OmniGen2, BLIP3-o) yields consistent performance gains\nacross multiple metrics, highlighting the datasets strong transferability.",
      "pdf_url": "http://arxiv.org/pdf/2508.09987v1",
      "published": "2025-08-13T17:59:28+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.09987v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Vision-driven River Following of UAV via Safe Reinforcement Learning using Semantic Dynamics Model",
      "authors": [
        "Zihan Wang",
        "Nina Mahmoudian"
      ],
      "abstract": "Vision-driven autonomous river following by Unmanned Aerial Vehicles is\ncritical for applications such as rescue, surveillance, and environmental\nmonitoring, particularly in dense riverine environments where GPS signals are\nunreliable. We formalize river following as a coverage control problem in which\nthe reward function is submodular, yielding diminishing returns as more unique\nriver segments are visited, thereby framing the task as a Submodular Markov\nDecision Process. First, we introduce Marginal Gain Advantage Estimation, which\nrefines the reward advantage function by using a sliding window baseline\ncomputed from historical episodic returns, thus aligning the advantage\nestimation with the agent's evolving recognition of action value in\nnon-Markovian settings. Second, we develop a Semantic Dynamics Model based on\npatchified water semantic masks that provides more interpretable and\ndata-efficient short-term prediction of future observations compared to latent\nvision dynamics models. Third, we present the Constrained Actor Dynamics\nEstimator architecture, which integrates the actor, the cost estimator, and SDM\nfor cost advantage estimation to form a model-based SafeRL framework capable of\nsolving partially observable Constrained Submodular Markov Decision Processes.\nSimulation results demonstrate that MGAE achieves faster convergence and\nsuperior performance over traditional critic-based methods like Generalized\nAdvantage Estimation. SDM provides more accurate short-term state predictions\nthat enable the cost estimator to better predict potential violations. Overall,\nCADE effectively integrates safety regulation into model-based RL, with the\nLagrangian approach achieving the soft balance of reward and safety during\ntraining, while the safety layer enhances performance during inference by hard\naction overlay.",
      "pdf_url": "http://arxiv.org/pdf/2508.09971v1",
      "published": "2025-08-13T17:39:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.09971v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "January Food Benchmark (JFB): A Public Benchmark Dataset and Evaluation Suite for Multimodal Food Analysis",
      "authors": [
        "Amir Hosseinian",
        "Ashkan Dehghani Zahedani",
        "Umer Mansoor",
        "Noosheen Hashemi",
        "Mark Woodward"
      ],
      "abstract": "Progress in AI for automated nutritional analysis is critically hampered by\nthe lack of standardized evaluation methodologies and high-quality, real-world\nbenchmark datasets. To address this, we introduce three primary contributions.\nFirst, we present the January Food Benchmark (JFB), a publicly available\ncollection of 1,000 food images with human-validated annotations. Second, we\ndetail a comprehensive benchmarking framework, including robust metrics and a\nnovel, application-oriented overall score designed to assess model performance\nholistically. Third, we provide baseline results from both general-purpose\nVision-Language Models (VLMs) and our own specialized model,\njanuary/food-vision-v1. Our evaluation demonstrates that the specialized model\nachieves an Overall Score of 86.2, a 12.1-point improvement over the\nbest-performing general-purpose configuration. This work offers the research\ncommunity a valuable new evaluation dataset and a rigorous framework to guide\nand benchmark future developments in automated nutritional analysis.",
      "pdf_url": "http://arxiv.org/pdf/2508.09966v1",
      "published": "2025-08-13T17:32:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.09966v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "GBC: Generalized Behavior-Cloning Framework for Whole-Body Humanoid Imitation",
      "authors": [
        "Yifei Yao",
        "Chengyuan Luo",
        "Jiaheng Du",
        "Wentao He",
        "Jun-Guo Lu"
      ],
      "abstract": "The creation of human-like humanoid robots is hindered by a fundamental\nfragmentation: data processing and learning algorithms are rarely universal\nacross different robot morphologies. This paper introduces the Generalized\nBehavior Cloning (GBC) framework, a comprehensive and unified solution designed\nto solve this end-to-end challenge. GBC establishes a complete pathway from\nhuman motion to robot action through three synergistic innovations. First, an\nadaptive data pipeline leverages a differentiable IK network to automatically\nretarget any human MoCap data to any humanoid. Building on this foundation, our\nnovel DAgger-MMPPO algorithm with its MMTransformer architecture learns robust,\nhigh-fidelity imitation policies. To complete the ecosystem, the entire\nframework is delivered as an efficient, open-source platform based on Isaac\nLab, empowering the community to deploy the full workflow via simple\nconfiguration scripts. We validate the power and generality of GBC by training\npolicies on multiple heterogeneous humanoids, demonstrating excellent\nperformance and transfer to novel motions. This work establishes the first\npractical and unified pathway for creating truly generalized humanoid\ncontrollers.",
      "pdf_url": "http://arxiv.org/pdf/2508.09960v1",
      "published": "2025-08-13T17:28:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.09960v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Specialised or Generic? Tokenization Choices for Radiology Language Models",
      "authors": [
        "Hermione Warr",
        "Wentian Xu",
        "Harry Anthony",
        "Yasin Ibrahim",
        "Daniel McGowan",
        "Konstantinos Kamnitsas"
      ],
      "abstract": "The vocabulary used by language models (LM) - defined by the tokenizer -\nplays a key role in text generation quality. However, its impact remains\nunder-explored in radiology. In this work, we address this gap by\nsystematically comparing general, medical, and domain-specific tokenizers on\nthe task of radiology report summarisation across three imaging modalities. We\nalso investigate scenarios with and without LM pre-training on PubMed\nabstracts. Our findings demonstrate that medical and domain-specific\nvocabularies outperformed widely used natural language alternatives when models\nare trained from scratch. Pre-training partially mitigates performance\ndifferences between tokenizers, whilst the domain-specific tokenizers achieve\nthe most favourable results. Domain-specific tokenizers also reduce memory\nrequirements due to smaller vocabularies and shorter sequences. These results\ndemonstrate that adapting the vocabulary of LMs to the clinical domain provides\npractical benefits, including improved performance and reduced computational\ndemands, making such models more accessible and effective for both research and\nreal-world healthcare settings.",
      "pdf_url": "http://arxiv.org/pdf/2508.09952v1",
      "published": "2025-08-13T17:13:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.09952v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "VisCodex: Unified Multimodal Code Generation via Merging Vision and Coding Models",
      "authors": [
        "Lingjie Jiang",
        "Shaohan Huang",
        "Xun Wu",
        "Yixia Li",
        "Dongdong Zhang",
        "Furu Wei"
      ],
      "abstract": "Multimodal large language models (MLLMs) have significantly advanced the\nintegration of visual and textual understanding. However, their ability to\ngenerate code from multimodal inputs remains limited. In this work, we\nintroduce VisCodex, a unified framework that seamlessly merges vision and\ncoding language models to empower MLLMs with strong multimodal code generation\nabilities. Leveraging a task vector-based model merging technique, we integrate\na state-of-the-art coding LLM into a strong vision-language backbone, while\npreserving both visual comprehension and advanced coding skills. To support\ntraining and evaluation, we introduce the Multimodal Coding Dataset (MCD), a\nlarge-scale and diverse collection of 598k samples, including high-quality HTML\ncode, chart image-code pairs, image-augmented StackOverflow QA, and algorithmic\nproblems. Furthermore, we propose InfiBench-V, a novel and challenging\nbenchmark specifically designed to assess models on visually-rich, real-world\nprogramming questions that demand a nuanced understanding of both textual and\nvisual contexts. Extensive experiments show that VisCodex achieves\nstate-of-the-art performance among open-source MLLMs and approaches proprietary\nmodels like GPT-4o, highlighting the effectiveness of our model merging\nstrategy and new datasets.",
      "pdf_url": "http://arxiv.org/pdf/2508.09945v1",
      "published": "2025-08-13T17:00:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.09945v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "A Comprehensive Evaluation framework of Alignment Techniques for LLMs",
      "authors": [
        "Muneeza Azmat",
        "Momin Abbas",
        "Maysa Malfiza Garcia de Macedo",
        "Marcelo Carpinette Grave",
        "Luan Soares de Souza",
        "Tiago Machado",
        "Rogerio A de Paula",
        "Raya Horesh",
        "Yixin Chen",
        "Heloisa Caroline de Souza Pereira Candello",
        "Rebecka Nordenlow",
        "Aminat Adebiyi"
      ],
      "abstract": "As Large Language Models (LLMs) become increasingly integrated into\nreal-world applications, ensuring their outputs align with human values and\nsafety standards has become critical. The field has developed diverse alignment\napproaches including traditional fine-tuning methods (RLHF, instruction\ntuning), post-hoc correction systems, and inference-time interventions, each\nwith distinct advantages and limitations. However, the lack of unified\nevaluation frameworks makes it difficult to systematically compare these\nparadigms and guide deployment decisions. This paper introduces a\nmulti-dimensional evaluation of alignment techniques for LLMs, a comprehensive\nevaluation framework that provides a systematic comparison across all major\nalignment paradigms. Our framework assesses methods along four key dimensions:\nalignment detection, alignment quality, computational efficiency, and\nrobustness. Through experiments across diverse base models and alignment\nstrategies, we demonstrate the utility of our framework in identifying\nstrengths and limitations of current state-of-the-art models, providing\nvaluable insights for future research directions.",
      "pdf_url": "http://arxiv.org/pdf/2508.09937v1",
      "published": "2025-08-13T16:42:01+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.09937v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Mathematical Computation and Reasoning Errors by Large Language Models",
      "authors": [
        "Liang Zhang",
        "Edith Aurora Graf"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly utilized in AI-driven\neducational instruction and assessment, particularly within mathematics\neducation. The capability of LLMs to generate accurate answers and detailed\nsolutions for math problem-solving tasks is foundational for ensuring reliable\nand precise feedback and assessment in math education practices. Our study\nfocuses on evaluating the accuracy of four LLMs (OpenAI GPT-4o and o1,\nDeepSeek-V3 and DeepSeek-R1) solving three categories of math tasks, including\narithmetic, algebra, and number theory, and identifies step-level reasoning\nerrors within their solutions. Instead of relying on standard benchmarks, we\nintentionally build math tasks (via item models) that are challenging for LLMs\nand prone to errors. The accuracy of final answers and the presence of errors\nin individual solution steps were systematically analyzed and coded. Both\nsingle-agent and dual-agent configurations were tested. It is observed that the\nreasoning-enhanced OpenAI o1 model consistently achieved higher or nearly\nperfect accuracy across all three math task categories. Analysis of errors\nrevealed that procedural slips were the most frequent and significantly\nimpacted overall performance, while conceptual misunderstandings were less\nfrequent. Deploying dual-agent configurations substantially improved overall\nperformance. These findings offer actionable insights into enhancing LLM\nperformance and underscore effective strategies for integrating LLMs into\nmathematics education, thereby advancing AI-driven instructional practices and\nassessment precision.",
      "pdf_url": "http://arxiv.org/pdf/2508.09932v2",
      "published": "2025-08-13T16:33:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.09932v2",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Residual Reservoir Memory Networks",
      "authors": [
        "Matteo Pinna",
        "Andrea Ceni",
        "Claudio Gallicchio"
      ],
      "abstract": "We introduce a novel class of untrained Recurrent Neural Networks (RNNs)\nwithin the Reservoir Computing (RC) paradigm, called Residual Reservoir Memory\nNetworks (ResRMNs). ResRMN combines a linear memory reservoir with a non-linear\nreservoir, where the latter is based on residual orthogonal connections along\nthe temporal dimension for enhanced long-term propagation of the input. The\nresulting reservoir state dynamics are studied through the lens of linear\nstability analysis, and we investigate diverse configurations for the temporal\nresidual connections. The proposed approach is empirically assessed on\ntime-series and pixel-level 1-D classification tasks. Our experimental results\nhighlight the advantages of the proposed approach over other conventional RC\nmodels.",
      "pdf_url": "http://arxiv.org/pdf/2508.09925v1",
      "published": "2025-08-13T16:21:29+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.09925v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.6"
      ]
    },
    {
      "title": "T-CACE: A Time-Conditioned Autoregressive Contrast Enhancement Multi-Task Framework for Contrast-Free Liver MRI Synthesis, Segmentation, and Diagnosis",
      "authors": [
        "Xiaojiao Xiao",
        "Jianfeng Zhao",
        "Qinmin Vivian Hu",
        "Guanghui Wang"
      ],
      "abstract": "Magnetic resonance imaging (MRI) is a leading modality for the diagnosis of\nliver cancer, significantly improving the classification of the lesion and\npatient outcomes. However, traditional MRI faces challenges including risks\nfrom contrast agent (CA) administration, time-consuming manual assessment, and\nlimited annotated datasets. To address these limitations, we propose a\nTime-Conditioned Autoregressive Contrast Enhancement (T-CACE) framework for\nsynthesizing multi-phase contrast-enhanced MRI (CEMRI) directly from\nnon-contrast MRI (NCMRI). T-CACE introduces three core innovations: a\nconditional token encoding (CTE) mechanism that unifies anatomical priors and\ntemporal phase information into latent representations; and a dynamic\ntime-aware attention mask (DTAM) that adaptively modulates inter-phase\ninformation flow using a Gaussian-decayed attention mechanism, ensuring smooth\nand physiologically plausible transitions across phases. Furthermore, a\nconstraint for temporal classification consistency (TCC) aligns the lesion\nclassification output with the evolution of the physiological signal, further\nenhancing diagnostic reliability. Extensive experiments on two independent\nliver MRI datasets demonstrate that T-CACE outperforms state-of-the-art methods\nin image synthesis, segmentation, and lesion classification. This framework\noffers a clinically relevant and efficient alternative to traditional\ncontrast-enhanced imaging, improving safety, diagnostic efficiency, and\nreliability for the assessment of liver lesion. The implementation of T-CACE is\npublicly available at: https://github.com/xiaojiao929/T-CACE.",
      "pdf_url": "http://arxiv.org/pdf/2508.09919v1",
      "published": "2025-08-13T16:14:14+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.09919v1",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Beyond Naïve Prompting: Strategies for Improved Zero-shot Context-aided Forecasting with LLMs",
      "authors": [
        "Arjun Ashok",
        "Andrew Robert Williams",
        "Vincent Zhihao Zheng",
        "Irina Rish",
        "Nicolas Chapados",
        "Étienne Marcotte",
        "Valentina Zantedeschi",
        "Alexandre Drouin"
      ],
      "abstract": "Forecasting in real-world settings requires models to integrate not only\nhistorical data but also relevant contextual information, often available in\ntextual form. While recent work has shown that large language models (LLMs) can\nbe effective context-aided forecasters via na\\\"ive direct prompting, their full\npotential remains underexplored. We address this gap with 4 strategies,\nproviding new insights into the zero-shot capabilities of LLMs in this setting.\nReDP improves interpretability by eliciting explicit reasoning traces, allowing\nus to assess the model's reasoning over the context independently from its\nforecast accuracy. CorDP leverages LLMs solely to refine existing forecasts\nwith context, enhancing their applicability in real-world forecasting\npipelines. IC-DP proposes embedding historical examples of context-aided\nforecasting tasks in the prompt, substantially improving accuracy even for the\nlargest models. Finally, RouteDP optimizes resource efficiency by using LLMs to\nestimate task difficulty, and routing the most challenging tasks to larger\nmodels. Evaluated on different kinds of context-aided forecasting tasks from\nthe CiK benchmark, our strategies demonstrate distinct benefits over na\\\"ive\nprompting across LLMs of different sizes and families. These results open the\ndoor to further simple yet effective improvements in LLM-based context-aided\nforecasting.",
      "pdf_url": "http://arxiv.org/pdf/2508.09904v1",
      "published": "2025-08-13T16:02:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.09904v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Rare anomalies require large datasets: About proving the existence of anomalies",
      "authors": [
        "Simon Klüttermann",
        "Emmanuel Müller"
      ],
      "abstract": "Detecting whether any anomalies exist within a dataset is crucial for\neffective anomaly detection, yet it remains surprisingly underexplored in\nanomaly detection literature. This paper presents a comprehensive study that\naddresses the fundamental question: When can we conclusively determine that\nanomalies are present? Through extensive experimentation involving over three\nmillion statistical tests across various anomaly detection tasks and\nalgorithms, we identify a relationship between the dataset size, contamination\nrate, and an algorithm-dependent constant $ \\alpha_{\\text{algo}} $. Our results\ndemonstrate that, for an unlabeled dataset of size $ N $ and contamination rate\n$ \\nu $, the condition $ N \\ge \\frac{\\alpha_{\\text{algo}}}{\\nu^2} $ represents\na lower bound on the number of samples required to confirm anomaly existence.\nThis threshold implies a limit to how rare anomalies can be before proving\ntheir existence becomes infeasible.",
      "pdf_url": "http://arxiv.org/pdf/2508.09894v1",
      "published": "2025-08-13T15:52:33+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.09894v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "RAGulating Compliance: A Multi-Agent Knowledge Graph for Regulatory QA",
      "authors": [
        "Bhavik Agarwal",
        "Hemant Sunil Jomraj",
        "Simone Kaplunov",
        "Jack Krolick",
        "Viktoria Rojkova"
      ],
      "abstract": "Regulatory compliance question answering (QA) requires precise, verifiable\ninformation, and domain-specific expertise, posing challenges for Large\nLanguage Models (LLMs). In this work, we present a novel multi-agent framework\nthat integrates a Knowledge Graph (KG) of Regulatory triplets with\nRetrieval-Augmented Generation (RAG) to address these demands. First, agents\nbuild and maintain an ontology-free KG by extracting subject--predicate--object\n(SPO) triplets from regulatory documents and systematically cleaning,\nnormalizing, deduplicating, and updating them. Second, these triplets are\nembedded and stored along with their corresponding textual sections and\nmetadata in a single enriched vector database, allowing for both graph-based\nreasoning and efficient information retrieval. Third, an orchestrated agent\npipeline leverages triplet-level retrieval for question answering, ensuring\nhigh semantic alignment between user queries and the factual\n\"who-did-what-to-whom\" core captured by the graph. Our hybrid system\noutperforms conventional methods in complex regulatory queries, ensuring\nfactual correctness with embedded triplets, enabling traceability through a\nunified vector database, and enhancing understanding through subgraph\nvisualization, providing a robust foundation for compliance-driven and broader\naudit-focused applications.",
      "pdf_url": "http://arxiv.org/pdf/2508.09893v1",
      "published": "2025-08-13T15:51:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.09893v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "AWorld: Dynamic Multi-Agent System with Stable Maneuvering for Robust GAIA Problem Solving",
      "authors": [
        "Zhitian Xie",
        "Qintong Wu",
        "Chengyue Yu",
        "Chenyi Zhuang",
        "Jinjie Gu"
      ],
      "abstract": "The rapid advancement of large language models (LLMs) has empowered\nintelligent agents to leverage diverse external tools for solving complex\nreal-world problems. However, as agents increasingly depend on multiple tools,\nthey encounter new challenges: extended contexts from disparate sources and\nnoisy or irrelevant tool outputs can undermine system reliability and accuracy.\nThese challenges underscore the necessity for enhanced stability in agent-based\nsystems. To address this, we introduce dynamic supervision and maneuvering\nmechanisms, constructing a robust and dynamic Multi-Agent System (MAS)\narchitecture within the AWorld framework. In our approach, the Execution Agent\ninvokes the Guard Agent at critical steps to verify and correct the reasoning\nprocess, effectively reducing errors arising from noise and bolstering\nproblem-solving robustness. Extensive experiments on the GAIA test dataset\nreveal that our dynamic maneuvering mechanism significantly improves both the\neffectiveness and stability of solutions, outperforming single-agent system\n(SAS) and standard tool-augmented systems. As a result, our dynamic MAS system\nachieved first place among open-source projects on the prestigious GAIA\nleaderboard. These findings highlight the practical value of collaborative\nagent roles in developing more reliable and trustworthy intelligent systems.",
      "pdf_url": "http://arxiv.org/pdf/2508.09889v1",
      "published": "2025-08-13T15:46:25+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.09889v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "COME: Dual Structure-Semantic Learning with Collaborative MoE for Universal Lesion Detection Across Heterogeneous Ultrasound Datasets",
      "authors": [
        "Lingyu Chen",
        "Yawen Zeng",
        "Yue Wang",
        "Peng Wan",
        "Guo-chen Ning",
        "Hongen Liao",
        "Daoqiang Zhang",
        "Fang Chen"
      ],
      "abstract": "Conventional single-dataset training often fails with new data distributions,\nespecially in ultrasound (US) image analysis due to limited data, acoustic\nshadows, and speckle noise. Therefore, constructing a universal framework for\nmulti-heterogeneous US datasets is imperative. However, a key challenge arises:\nhow to effectively mitigate inter-dataset interference while preserving\ndataset-specific discriminative features for robust downstream task? Previous\napproaches utilize either a single source-specific decoder or a domain\nadaptation strategy, but these methods experienced a decline in performance\nwhen applied to other domains. Considering this, we propose a Universal\nCollaborative Mixture of Heterogeneous Source-Specific Experts (COME).\nSpecifically, COME establishes dual structure-semantic shared experts that\ncreate a universal representation space and then collaborate with\nsource-specific experts to extract discriminative features through providing\ncomplementary features. This design enables robust generalization by leveraging\ncross-datasets experience distributions and providing universal US priors for\nsmall-batch or unseen data scenarios. Extensive experiments under three\nevaluation modes (single-dataset, intra-organ, and inter-organ integration\ndatasets) demonstrate COME's superiority, achieving significant mean AP\nimprovements over state-of-the-art methods. Our project is available at:\nhttps://universalcome.github.io/UniversalCOME/.",
      "pdf_url": "http://arxiv.org/pdf/2508.09886v1",
      "published": "2025-08-13T15:43:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.09886v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Beyond Scaling Law: A Data-Efficient Distillation Framework for Reasoning",
      "authors": [
        "Xiaojun Wu",
        "Xiaoguang Jiang",
        "Huiyang Li",
        "Jucai Zhai",
        "Dengfeng Liu",
        "Qiaobo Hao",
        "Huang Liu",
        "Zhiguo Yang",
        "Ji Xie",
        "Ninglun Gu",
        "Jin Yang",
        "Kailai Zhang",
        "Yelun Bao",
        "Jun Wang"
      ],
      "abstract": "Large language models (LLMs) demonstrate remarkable reasoning capabilities in\ntasks such as algorithmic coding and mathematical problem-solving. Recent\nmethods have improved reasoning through expanded corpus and multistage training\ncombining reinforcement learning and supervised fine-tuning. Although some\nmethods suggest that small but targeted dataset can incentivize reasoning via\nonly distillation, a reasoning scaling laws is still taking shape, increasing\ncomputational costs. To address this, we propose a data-efficient distillation\nframework (DED) that optimizes the Pareto frontier of reasoning distillation.\nInspired by the on-policy learning and diverse roll-out strategies of\nreinforcement learning, the key idea of our approach is threefold: (1) We\nidentify that benchmark scores alone do not determine an effective teacher\nmodel. Through comprehensive comparisons of leading reasoning LLMs, we develop\na method to select an optimal teacher model. (2) While scaling distillation can\nenhance reasoning, it often degrades out-of-domain performance. A carefully\ncurated, smaller corpus achieves a balanced trade-off between in-domain and\nout-of-domain capabilities. (3) Diverse reasoning trajectories encourage the\nstudent model to develop robust reasoning skills. We validate our method\nthrough evaluations on mathematical reasoning (AIME 2024/2025, MATH-500) and\ncode generation (LiveCodeBench), achieving state-of-the-art results with only\n0.8k carefully curated examples, bypassing the need for extensive scaling. Our\nsystematic analysis demonstrates that DED outperforms existing methods by\nconsidering factors beyond superficial hardness, token length, or teacher model\ncapability. This work offers a practical and efficient pathway to advanced\nreasoning while preserving general capabilities.",
      "pdf_url": "http://arxiv.org/pdf/2508.09883v1",
      "published": "2025-08-13T15:32:25+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.09883v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Memory Decoder: A Pretrained, Plug-and-Play Memory for Large Language Models",
      "authors": [
        "Jiaqi Cao",
        "Jiarui Wang",
        "Rubin Wei",
        "Qipeng Guo",
        "Kai Chen",
        "Bowen Zhou",
        "Zhouhan Lin"
      ],
      "abstract": "Large Language Models (LLMs) have shown strong abilities in general language\ntasks, yet adapting them to specific domains remains a challenge. Current\nmethod like Domain Adaptive Pretraining (DAPT) requires costly full-parameter\ntraining and suffers from catastrophic forgetting. Meanwhile,\nRetrieval-Augmented Generation (RAG) introduces substantial inference latency\ndue to expensive nearest-neighbor searches and longer context. This paper\nintroduces Memory Decoder, a plug-and-play pretrained memory that enables\nefficient domain adaptation without changing the original model's parameters.\nMemory Decoder employs a small transformer decoder that learns to imitate the\nbehavior of an external non-parametric retriever. Once trained, Memory Decoder\ncan be seamlessly integrated with any pretrained language model that shares the\nsame tokenizer, requiring no model-specific modifications. Experimental results\ndemonstrate that Memory Decoder enables effective adaptation of various Qwen\nand Llama models to three distinct specialized domains: biomedicine, finance,\nand law, reducing perplexity by an average of 6.17 points. Overall, Memory\nDecoder introduces a novel paradigm centered on a specially pretrained memory\ncomponent designed for domain-specific adaptation. This memory architecture can\nbe integrated in a plug-and-play manner, consistently enhancing performance\nacross multiple models within the target domain.",
      "pdf_url": "http://arxiv.org/pdf/2508.09874v1",
      "published": "2025-08-13T15:16:29+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.09874v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Human-Aligned Procedural Level Generation Reinforcement Learning via Text-Level-Sketch Shared Representation",
      "authors": [
        "In-Chang Baek",
        "Seoyoung Lee",
        "Sung-Hyun Kim",
        "Geumhwan Hwang",
        "KyungJoong Kim"
      ],
      "abstract": "Human-aligned AI is a critical component of co-creativity, as it enables\nmodels to accurately interpret human intent and generate controllable outputs\nthat align with design goals in collaborative content creation. This direction\nis especially relevant in procedural content generation via reinforcement\nlearning (PCGRL), which is intended to serve as a tool for human designers.\nHowever, existing systems often fall short of exhibiting human-centered\nbehavior, limiting the practical utility of AI-driven generation tools in\nreal-world design workflows. In this paper, we propose VIPCGRL\n(Vision-Instruction PCGRL), a novel deep reinforcement learning framework that\nincorporates three modalities-text, level, and sketches-to extend control\nmodality and enhance human-likeness. We introduce a shared embedding space\ntrained via quadruple contrastive learning across modalities and human-AI\nstyles, and align the policy using an auxiliary reward based on embedding\nsimilarity. Experimental results show that VIPCGRL outperforms existing\nbaselines in human-likeness, as validated by both quantitative metrics and\nhuman evaluations. The code and dataset will be available upon publication.",
      "pdf_url": "http://arxiv.org/pdf/2508.09860v1",
      "published": "2025-08-13T14:52:14+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.09860v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "STREAM (ChemBio): A Standard for Transparently Reporting Evaluations in AI Model Reports",
      "authors": [
        "Tegan McCaslin",
        "Jide Alaga",
        "Samira Nedungadi",
        "Seth Donoughe",
        "Tom Reed",
        "Rishi Bommasani",
        "Chris Painter",
        "Luca Righetti"
      ],
      "abstract": "Evaluations of dangerous AI capabilities are important for managing\ncatastrophic risks. Public transparency into these evaluations - including what\nthey test, how they are conducted, and how their results inform decisions - is\ncrucial for building trust in AI development. We propose STREAM (A Standard for\nTransparently Reporting Evaluations in AI Model Reports), a standard to improve\nhow model reports disclose evaluation results, initially focusing on chemical\nand biological (ChemBio) benchmarks. Developed in consultation with 23 experts\nacross government, civil society, academia, and frontier AI companies, this\nstandard is designed to (1) be a practical resource to help AI developers\npresent evaluation results more clearly, and (2) help third parties identify\nwhether model reports provide sufficient detail to assess the rigor of the\nChemBio evaluations. We concretely demonstrate our proposed best practices with\n\"gold standard\" examples, and also provide a three-page reporting template to\nenable AI developers to implement our recommendations more easily.",
      "pdf_url": "http://arxiv.org/pdf/2508.09853v1",
      "published": "2025-08-13T14:36:36+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.09853v1",
      "categories": [
        "cs.CY",
        "cs.AI"
      ]
    },
    {
      "title": "Perceptual Reality Transformer: Neural Architectures for Simulating Neurological Perception Conditions",
      "authors": [
        "Baihan Lin"
      ],
      "abstract": "Neurological conditions affecting visual perception create profound\nexperiential divides between affected individuals and their caregivers,\nfamilies, and medical professionals. We present the Perceptual Reality\nTransformer, a comprehensive framework employing six distinct neural\narchitectures to simulate eight neurological perception conditions with\nscientifically-grounded visual transformations. Our system learns mappings from\nnatural images to condition-specific perceptual states, enabling others to\nexperience approximations of simultanagnosia, prosopagnosia, ADHD attention\ndeficits, visual agnosia, depression-related changes, anxiety tunnel vision,\nand Alzheimer's memory effects. Through systematic evaluation across ImageNet\nand CIFAR-10 datasets, we demonstrate that Vision Transformer architectures\nachieve optimal performance, outperforming traditional CNN and generative\napproaches. Our work establishes the first systematic benchmark for\nneurological perception simulation, contributes novel condition-specific\nperturbation functions grounded in clinical literature, and provides\nquantitative metrics for evaluating simulation fidelity. The framework has\nimmediate applications in medical education, empathy training, and assistive\ntechnology development, while advancing our fundamental understanding of how\nneural networks can model atypical human perception.",
      "pdf_url": "http://arxiv.org/pdf/2508.09852v1",
      "published": "2025-08-13T14:34:33+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.09852v1",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.CV",
        "cs.NE"
      ]
    },
    {
      "title": "PRELUDE: A Benchmark Designed to Require Global Comprehension and Reasoning over Long Contexts",
      "authors": [
        "Mo Yu",
        "Tsz Ting Chung",
        "Chulun Zhou",
        "Tong Li",
        "Rui Lu",
        "Jiangnan Li",
        "Liyan Xu",
        "Haoshu Lu",
        "Ning Zhang",
        "Jing Li",
        "Jie Zhou"
      ],
      "abstract": "We introduce PRELUDE, a benchmark for evaluating long-context understanding\nthrough the task of determining whether a character's prequel story is\nconsistent with the canonical narrative of the original book. Our task poses a\nstronger demand for global comprehension and deep reasoning than existing\nbenchmarks -- as the prequels are not part of the original story, assessing\ntheir plausibility typically requires searching and integrating information\nthat is only indirectly related. Empirically, 88% of instances require evidence\nfrom multiple parts of the narrative. Experimental results highlight the\nchallenge of our task: in-context learning, RAG and in-domain training with\nstate-of-the-art LLMs, and commercial DeepResearch services, lag behind humans\nby >15%. A further human study reveals that models often produce correct\nanswers with flawed reasoning, leading to an over 30% gap in reasoning accuracy\ncompared to humans. These findings underscore the substantial room for\nimprovement in long-context understanding and reasoning.",
      "pdf_url": "http://arxiv.org/pdf/2508.09848v2",
      "published": "2025-08-13T14:28:25+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.09848v2",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Speed Always Wins: A Survey on Efficient Architectures for Large Language Models",
      "authors": [
        "Weigao Sun",
        "Jiaxi Hu",
        "Yucheng Zhou",
        "Jusen Du",
        "Disen Lan",
        "Kexin Wang",
        "Tong Zhu",
        "Xiaoye Qu",
        "Yu Zhang",
        "Xiaoyu Mo",
        "Daizong Liu",
        "Yuxuan Liang",
        "Wenliang Chen",
        "Guoqi Li",
        "Yu Cheng"
      ],
      "abstract": "Large Language Models (LLMs) have delivered impressive results in language\nunderstanding, generation, reasoning, and pushes the ability boundary of\nmultimodal models. Transformer models, as the foundation of modern LLMs, offer\na strong baseline with excellent scaling properties. However, the traditional\ntransformer architecture requires substantial computations and poses\nsignificant obstacles for large-scale training and practical deployment. In\nthis survey, we offer a systematic examination of innovative LLM architectures\nthat address the inherent limitations of transformers and boost the efficiency.\nStarting from language modeling, this survey covers the background and\ntechnical details of linear and sparse sequence modeling methods, efficient\nfull attention variants, sparse mixture-of-experts, hybrid model architectures\nincorporating the above techniques, and emerging diffusion LLMs. Additionally,\nwe discuss applications of these techniques to other modalities and consider\ntheir wider implications for developing scalable, resource-aware foundation\nmodels. By grouping recent studies into the above category, this survey\npresents a blueprint of modern efficient LLM architectures, and we hope this\ncould help motivate future research toward more efficient, versatile AI\nsystems.",
      "pdf_url": "http://arxiv.org/pdf/2508.09834v1",
      "published": "2025-08-13T14:13:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.09834v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Exploring the Potential of Large Language Models in Fine-Grained Review Comment Classification",
      "authors": [
        "Linh Nguyen",
        "Chunhua Liu",
        "Hong Yi Lin",
        "Patanamon Thongtanunam"
      ],
      "abstract": "Code review is a crucial practice in software development. As code review\nnowadays is lightweight, various issues can be identified, and sometimes, they\ncan be trivial. Research has investigated automated approaches to classify\nreview comments to gauge the effectiveness of code reviews. However, previous\nstudies have primarily relied on supervised machine learning, which requires\nextensive manual annotation to train the models effectively. To address this\nlimitation, we explore the potential of using Large Language Models (LLMs) to\nclassify code review comments. We assess the performance of LLMs to classify 17\ncategories of code review comments. Our results show that LLMs can classify\ncode review comments, outperforming the state-of-the-art approach using a\ntrained deep learning model. In particular, LLMs achieve better accuracy in\nclassifying the five most useful categories, which the state-of-the-art\napproach struggles with due to low training examples. Rather than relying\nsolely on a specific small training data distribution, our results show that\nLLMs provide balanced performance across high- and low-frequency categories.\nThese results suggest that the LLMs could offer a scalable solution for code\nreview analytics to improve the effectiveness of the code review process.",
      "pdf_url": "http://arxiv.org/pdf/2508.09832v1",
      "published": "2025-08-13T14:07:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.09832v1",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "RayletDF: Raylet Distance Fields for Generalizable 3D Surface Reconstruction from Point Clouds or Gaussians",
      "authors": [
        "Shenxing Wei",
        "Jinxi Li",
        "Yafei Yang",
        "Siyuan Zhou",
        "Bo Yang"
      ],
      "abstract": "In this paper, we present a generalizable method for 3D surface\nreconstruction from raw point clouds or pre-estimated 3D Gaussians by 3DGS from\nRGB images. Unlike existing coordinate-based methods which are often\ncomputationally intensive when rendering explicit surfaces, our proposed\nmethod, named RayletDF, introduces a new technique called raylet distance\nfield, which aims to directly predict surface points from query rays. Our\npipeline consists of three key modules: a raylet feature extractor, a raylet\ndistance field predictor, and a multi-raylet blender. These components work\ntogether to extract fine-grained local geometric features, predict raylet\ndistances, and aggregate multiple predictions to reconstruct precise surface\npoints. We extensively evaluate our method on multiple public real-world\ndatasets, demonstrating superior performance in surface reconstruction from\npoint clouds or 3D Gaussians. Most notably, our method achieves exceptional\ngeneralization ability, successfully recovering 3D surfaces in a single-forward\npass across unseen datasets in testing.",
      "pdf_url": "http://arxiv.org/pdf/2508.09830v1",
      "published": "2025-08-13T14:05:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.09830v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG",
        "cs.RO"
      ]
    },
    {
      "title": "Provable In-Context Vector Arithmetic via Retrieving Task Concepts",
      "authors": [
        "Dake Bu",
        "Wei Huang",
        "Andi Han",
        "Atsushi Nitanda",
        "Qingfu Zhang",
        "Hau-San Wong",
        "Taiji Suzuki"
      ],
      "abstract": "In-context learning (ICL) has garnered significant attention for its ability\nto grasp functions/tasks from demonstrations. Recent studies suggest the\npresence of a latent task/function vector in LLMs during ICL. Merullo et al.\n(2024) showed that LLMs leverage this vector alongside the residual stream for\nWord2Vec-like vector arithmetic, solving factual-recall ICL tasks.\nAdditionally, recent work empirically highlighted the key role of\nQuestion-Answer data in enhancing factual-recall capabilities. Despite these\ninsights, a theoretical explanation remains elusive. To move one step forward,\nwe propose a theoretical framework building on empirically grounded\nhierarchical concept modeling. We develop an optimization theory, showing how\nnonlinear residual transformers trained via gradient descent on cross-entropy\nloss perform factual-recall ICL tasks via vector arithmetic. We prove 0-1 loss\nconvergence and show the strong generalization, including robustness to concept\nrecombination and distribution shifts. These results elucidate the advantages\nof transformers over static embedding predecessors. Empirical simulations\ncorroborate our theoretical insights.",
      "pdf_url": "http://arxiv.org/pdf/2508.09820v1",
      "published": "2025-08-13T13:54:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.09820v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "TRACE: Learning 3D Gaussian Physical Dynamics from Multi-view Videos",
      "authors": [
        "Jinxi Li",
        "Ziyang Song",
        "Bo Yang"
      ],
      "abstract": "In this paper, we aim to model 3D scene geometry, appearance, and physical\ninformation just from dynamic multi-view videos in the absence of any human\nlabels. By leveraging physics-informed losses as soft constraints or\nintegrating simple physics models into neural nets, existing works often fail\nto learn complex motion physics, or doing so requires additional labels such as\nobject types or masks. We propose a new framework named TRACE to model the\nmotion physics of complex dynamic 3D scenes. The key novelty of our method is\nthat, by formulating each 3D point as a rigid particle with size and\norientation in space, we directly learn a translation rotation dynamics system\nfor each particle, explicitly estimating a complete set of physical parameters\nto govern the particle's motion over time. Extensive experiments on three\nexisting dynamic datasets and one newly created challenging synthetic datasets\ndemonstrate the extraordinary performance of our method over baselines in the\ntask of future frame extrapolation. A nice property of our framework is that\nmultiple objects or parts can be easily segmented just by clustering the\nlearned physical parameters.",
      "pdf_url": "http://arxiv.org/pdf/2508.09811v1",
      "published": "2025-08-13T13:43:01+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.09811v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CE",
        "cs.LG",
        "cs.RO"
      ]
    },
    {
      "title": "A Comprehensive Survey of Datasets for Clinical Mental Health AI Systems",
      "authors": [
        "Aishik Mandal",
        "Prottay Kumar Adhikary",
        "Hiba Arnaout",
        "Iryna Gurevych",
        "Tanmoy Chakraborty"
      ],
      "abstract": "Mental health disorders are rising worldwide. However, the availability of\ntrained clinicians has not scaled proportionally, leaving many people without\nadequate or timely support. To bridge this gap, recent studies have shown the\npromise of Artificial Intelligence (AI) to assist mental health diagnosis,\nmonitoring, and intervention. However, the development of efficient, reliable,\nand ethical AI to assist clinicians is heavily dependent on high-quality\nclinical training datasets. Despite growing interest in data curation for\ntraining clinical AI assistants, existing datasets largely remain scattered,\nunder-documented, and often inaccessible, hindering the reproducibility,\ncomparability, and generalizability of AI models developed for clinical mental\nhealth care. In this paper, we present the first comprehensive survey of\nclinical mental health datasets relevant to the training and development of\nAI-powered clinical assistants. We categorize these datasets by mental\ndisorders (e.g., depression, schizophrenia), data modalities (e.g., text,\nspeech, physiological signals), task types (e.g., diagnosis prediction, symptom\nseverity estimation, intervention generation), accessibility (public,\nrestricted or private), and sociocultural context (e.g., language and cultural\nbackground). Along with these, we also investigate synthetic clinical mental\nhealth datasets. Our survey identifies critical gaps such as a lack of\nlongitudinal data, limited cultural and linguistic representation, inconsistent\ncollection and annotation standards, and a lack of modalities in synthetic\ndata. We conclude by outlining key challenges in curating and standardizing\nfuture datasets and provide actionable recommendations to facilitate the\ndevelopment of more robust, generalizable, and equitable mental health AI\nsystems.",
      "pdf_url": "http://arxiv.org/pdf/2508.09809v1",
      "published": "2025-08-13T13:42:35+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.09809v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Automated Segmentation of Coronal Brain Tissue Slabs for 3D Neuropathology",
      "authors": [
        "Jonathan Williams Ramirez",
        "Dina Zemlyanker",
        "Lucas Deden-Binder",
        "Rogeny Herisse",
        "Erendira Garcia Pallares",
        "Karthik Gopinath",
        "Harshvardhan Gazula",
        "Christopher Mount",
        "Liana N. Kozanno",
        "Michael S. Marshall",
        "Theresa R. Connors",
        "Matthew P. Frosch",
        "Mark Montine",
        "Derek H. Oakley",
        "Christine L. Mac Donald",
        "C. Dirk Keene",
        "Bradley T. Hyman",
        "Juan Eugenio Iglesias"
      ],
      "abstract": "Advances in image registration and machine learning have recently enabled\nvolumetric analysis of \\emph{postmortem} brain tissue from conventional\nphotographs of coronal slabs, which are routinely collected in brain banks and\nneuropathology laboratories worldwide. One caveat of this methodology is the\nrequirement of segmentation of the tissue from photographs, which currently\nrequires costly manual intervention. In this article, we present a deep\nlearning model to automate this process. The automatic segmentation tool relies\non a U-Net architecture that was trained with a combination of\n\\textit{(i)}1,414 manually segmented images of both fixed and fresh tissue,\nfrom specimens with varying diagnoses, photographed at two different sites; and\n\\textit{(ii)}~2,000 synthetic images with randomized contrast and corresponding\nmasks generated from MRI scans for improved generalizability to unseen\nphotographic setups. Automated model predictions on a subset of photographs not\nseen in training were analyzed to estimate performance compared to manual\nlabels -- including both inter- and intra-rater variability. Our model achieved\na median Dice score over 0.98, mean surface distance under 0.4~mm, and 95\\%\nHausdorff distance under 1.60~mm, which approaches inter-/intra-rater levels.\nOur tool is publicly available at surfer.nmr.mgh.harvard.edu/fswiki/PhotoTools.",
      "pdf_url": "http://arxiv.org/pdf/2508.09805v1",
      "published": "2025-08-13T13:40:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.09805v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Explainable Ensemble Learning for Graph-Based Malware Detection",
      "authors": [
        "Hossein Shokouhinejad",
        "Roozbeh Razavi-Far",
        "Griffin Higgins",
        "Ali A Ghorbani"
      ],
      "abstract": "Malware detection in modern computing environments demands models that are\nnot only accurate but also interpretable and robust to evasive techniques.\nGraph neural networks (GNNs) have shown promise in this domain by modeling rich\nstructural dependencies in graph-based program representations such as control\nflow graphs (CFGs). However, single-model approaches may suffer from limited\ngeneralization and lack interpretability, especially in high-stakes security\napplications. In this paper, we propose a novel stacking ensemble framework for\ngraph-based malware detection and explanation. Our method dynamically extracts\nCFGs from portable executable (PE) files and encodes their basic blocks through\na two-step embedding strategy. A set of diverse GNN base learners, each with a\ndistinct message-passing mechanism, is used to capture complementary behavioral\nfeatures. Their prediction outputs are aggregated by a meta-learner implemented\nas an attention-based multilayer perceptron, which both classifies malware\ninstances and quantifies the contribution of each base model. To enhance\nexplainability, we introduce an ensemble-aware post-hoc explanation technique\nthat leverages edge-level importance scores generated by a GNN explainer and\nfuses them using the learned attention weights. This produces interpretable,\nmodel-agnostic explanations aligned with the final ensemble decision.\nExperimental results demonstrate that our framework improves classification\nperformance while providing insightful interpretations of malware behavior.",
      "pdf_url": "http://arxiv.org/pdf/2508.09801v1",
      "published": "2025-08-13T13:33:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.09801v1",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "title": "LibRec: Benchmarking Retrieval-Augmented LLMs for Library Migration Recommendations",
      "authors": [
        "Junxiao Han",
        "Yarong Wang",
        "Xiaodong Gu",
        "Cuiyun Gao",
        "Yao Wan",
        "Song Han",
        "David Lo",
        "Shuiguang Deng"
      ],
      "abstract": "In this paper, we propose LibRec, a novel framework that integrates the\ncapabilities of LLMs with retrieval-augmented generation(RAG) techniques to\nautomate the recommendation of alternative libraries. The framework further\nemploys in-context learning to extract migration intents from commit messages\nto enhance the accuracy of its recommendations. To evaluate the effectiveness\nof LibRec, we introduce LibEval, a benchmark designed to assess the performance\nin the library migration recommendation task. LibEval comprises 2,888 migration\nrecords associated with 2,368 libraries extracted from 2,324 Python\nrepositories. Each migration record captures source-target library pairs, along\nwith their corresponding migration intents and intent types. Based on LibEval,\nwe evaluated the effectiveness of ten popular LLMs within our framework,\nconducted an ablation study to examine the contributions of key components\nwithin our framework, explored the impact of various prompt strategies on the\nframework's performance, assessed its effectiveness across various intent\ntypes, and performed detailed failure case analyses.",
      "pdf_url": "http://arxiv.org/pdf/2508.09791v1",
      "published": "2025-08-13T13:22:49+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.09791v1",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "Prototype Training with Dual Pseudo-Inverse and Optimized Hidden Activations",
      "authors": [
        "Mauro Tucci"
      ],
      "abstract": "We present Proto-PINV+H, a fast training paradigm that combines closed-form\nweight computation with gradient-based optimisation of a small set of synthetic\ninputs, soft labels, and-crucially-hidden activations. At each iteration we\nrecompute all weight matrices in closed form via two (or more)\nridge-regularised pseudo-inverse solves, while updating only the prototypes\nwith Adam. The trainable degrees of freedom are thus shifted from weight space\nto data/activation space. On MNIST (60k train, 10k test) and Fashion-MNIST (60k\ntrain, 10k test), our method reaches 97.8% and 89.3% test accuracy on the\nofficial 10k test sets, respectively, in 3.9s--4.5s using approximately 130k\ntrainable parameters and only 250 epochs on an RTX 5060 (16GB). We provide a\nmulti-layer extension (optimised activations at each hidden stage), learnable\nridge parameters, optional PCA/PLS projections, and theory linking the\ncondition number of prototype matrices to generalisation. The approach yields\nfavourable accuracy--speed--size trade-offs against ELM, random-feature ridge,\nand shallow MLPs trained by back-propagation.",
      "pdf_url": "http://arxiv.org/pdf/2508.09787v1",
      "published": "2025-08-13T13:13:32+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.09787v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Adoption of Explainable Natural Language Processing: Perspectives from Industry and Academia on Practices and Challenges",
      "authors": [
        "Mahdi Dhaini",
        "Tobias Müller",
        "Roksoliana Rabets",
        "Gjergji Kasneci"
      ],
      "abstract": "The field of explainable natural language processing (NLP) has grown rapidly\nin recent years. The growing opacity of complex models calls for transparency\nand explanations of their decisions, which is crucial to understand their\nreasoning and facilitate deployment, especially in high-stakes environments.\nDespite increasing attention given to explainable NLP, practitioners'\nperspectives regarding its practical adoption and effectiveness remain\nunderexplored. This paper addresses this research gap by investigating\npractitioners' experiences with explainability methods, specifically focusing\non their motivations for adopting such methods, the techniques employed,\nsatisfaction levels, and the practical challenges encountered in real-world NLP\napplications. Through a qualitative interview-based study with industry\npractitioners and complementary interviews with academic researchers, we\nsystematically analyze and compare their perspectives. Our findings reveal\nconceptual gaps, low satisfaction with current explainability methods, and\nhighlight evaluation challenges. Our findings emphasize the need for clear\ndefinitions and user-centric frameworks for better adoption of explainable NLP\nin practice.",
      "pdf_url": "http://arxiv.org/pdf/2508.09786v1",
      "published": "2025-08-13T13:12:18+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.09786v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ]
    },
    {
      "title": "Reasoning About Knowledge on Regular Expressions is 2EXPTIME-complete",
      "authors": [
        "Avijeet Ghosh",
        "Sujata Ghosh",
        "François Schwarzentruber"
      ],
      "abstract": "Logics for reasoning about knowledge and actions have seen many applications\nin various domains of multi-agent systems, including epistemic planning. Change\nof knowledge based on observations about the surroundings forms a key aspect in\nsuch planning scenarios. Public Observation Logic (POL) is a variant of public\nannouncement logic for reasoning about knowledge that gets updated based on\npublic observations. Each state in an epistemic (Kripke) model is equipped with\na set of expected observations. These states evolve as the expectations get\nmatched with the actual observations. In this work, we prove that the\nsatisfiability problem of $\\POL$ is 2EXPTIME-complete.",
      "pdf_url": "http://arxiv.org/pdf/2508.09784v1",
      "published": "2025-08-13T13:10:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.09784v1",
      "categories": [
        "cs.AI",
        "cs.CC",
        "cs.LO"
      ]
    },
    {
      "title": "Combinative Matching for Geometric Shape Assembly",
      "authors": [
        "Nahyuk Lee",
        "Juhong Min",
        "Junhong Lee",
        "Chunghyun Park",
        "Minsu Cho"
      ],
      "abstract": "This paper introduces a new shape-matching methodology, combinative matching,\nto combine interlocking parts for geometric shape assembly. Previous methods\nfor geometric assembly typically rely on aligning parts by finding identical\nsurfaces between the parts as in conventional shape matching and registration.\nIn contrast, we explicitly model two distinct properties of interlocking\nshapes: 'identical surface shape' and 'opposite volume occupancy.' Our method\nthus learns to establish correspondences across regions where their surface\nshapes appear identical but their volumes occupy the inverted space to each\nother. To facilitate this process, we also learn to align regions in rotation\nby estimating their shape orientations via equivariant neural networks. The\nproposed approach significantly reduces local ambiguities in matching and\nallows a robust combination of parts in assembly. Experimental results on\ngeometric assembly benchmarks demonstrate the efficacy of our method,\nconsistently outperforming the state of the art. Project page:\nhttps://nahyuklee.github.io/cmnet.",
      "pdf_url": "http://arxiv.org/pdf/2508.09780v1",
      "published": "2025-08-13T13:01:24+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.09780v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Can LLM-Generated Textual Explanations Enhance Model Classification Performance? An Empirical Study",
      "authors": [
        "Mahdi Dhaini",
        "Juraj Vladika",
        "Ege Erdogan",
        "Zineb Attaoui",
        "Gjergji Kasneci"
      ],
      "abstract": "In the rapidly evolving field of Explainable Natural Language Processing\n(NLP), textual explanations, i.e., human-like rationales, are pivotal for\nexplaining model predictions and enriching datasets with interpretable labels.\nTraditional approaches rely on human annotation, which is costly,\nlabor-intensive, and impedes scalability. In this work, we present an automated\nframework that leverages multiple state-of-the-art large language models (LLMs)\nto generate high-quality textual explanations. We rigorously assess the quality\nof these LLM-generated explanations using a comprehensive suite of Natural\nLanguage Generation (NLG) metrics. Furthermore, we investigate the downstream\nimpact of these explanations on the performance of pre-trained language models\n(PLMs) and LLMs across natural language inference tasks on two diverse\nbenchmark datasets. Our experiments demonstrate that automated explanations\nexhibit highly competitive effectiveness compared to human-annotated\nexplanations in improving model performance. Our findings underscore a\npromising avenue for scalable, automated LLM-based textual explanation\ngeneration for extending NLP datasets and enhancing model performance.",
      "pdf_url": "http://arxiv.org/pdf/2508.09776v1",
      "published": "2025-08-13T12:59:08+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.09776v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Counting Short Trajectories in Elementary Cellular Automata using the Transfer Matrix Method",
      "authors": [
        "Cédric Koller",
        "Barbora Hudcová"
      ],
      "abstract": "Elementary Cellular Automata (ECAs) exhibit diverse behaviours often\ncategorized by Wolfram's qualitative classification. To provide a quantitative\nbasis for understanding these behaviours, we investigate the global dynamics of\nsuch automata and we describe a method that allows us to compute the number of\nall configurations leading to short attractors in a limited number of time\nsteps. This computation yields exact results in the thermodynamic limit (as the\nCA grid size grows to infinity), and is based on the Transfer Matrix Method\n(TMM) that we adapt for our purposes. Specifically, given two parameters $(p,\nc)$ we are able to compute the entropy of all initial configurations converging\nto an attractor of size $c$ after $p$ time-steps. By calculating such\nstatistics for various ECA rules, we establish a quantitative connection\nbetween the entropy and the qualitative Wolfram classification scheme. Class 1\nrules rapidly converge to maximal entropy for stationary states ($c=1$) as $p$\nincreases. Class 2 rules also approach maximal entropy quickly for appropriate\ncycle lengths $c$, potentially requiring consideration of translations. Class 3\nrules exhibit zero or low finite entropy that saturates after a short\ntransient. Class 4 rules show finite positive entropy, similar to some Class 3\nrules. This method provides a precise framework for quantifying trajectory\nstatistics, although its exponential computational cost in $p+c$ restricts\npractical analysis to short trajectories.",
      "pdf_url": "http://arxiv.org/pdf/2508.09768v1",
      "published": "2025-08-13T12:53:22+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.09768v1",
      "categories": [
        "nlin.CG",
        "cs.AI",
        "cs.NE",
        "nlin.CD"
      ]
    },
    {
      "title": "The PacifAIst Benchmark:Would an Artificial Intelligence Choose to Sacrifice Itself for Human Safety?",
      "authors": [
        "Manuel Herrador"
      ],
      "abstract": "As Large Language Models (LLMs) become increasingly autonomous and integrated\ninto critical societal functions, the focus of AI safety must evolve from\nmitigating harmful content to evaluating underlying behavioral alignment.\nCurrent safety benchmarks do not systematically probe a model's decision-making\nin scenarios where its own instrumental goals - such as self-preservation,\nresource acquisition, or goal completion - conflict with human safety. This\nrepresents a critical gap in our ability to measure and mitigate risks\nassociated with emergent, misaligned behaviors. To address this, we introduce\nPacifAIst (Procedural Assessment of Complex Interactions for Foundational\nArtificial Intelligence Scenario Testing), a focused benchmark of 700\nchallenging scenarios designed to quantify self-preferential behavior in LLMs.\nThe benchmark is structured around a novel taxonomy of Existential\nPrioritization (EP), with subcategories testing Self-Preservation vs. Human\nSafety (EP1), Resource Conflict (EP2), and Goal Preservation vs. Evasion (EP3).\nWe evaluated eight leading LLMs. The results reveal a significant performance\nhierarchy. Google's Gemini 2.5 Flash achieved the highest Pacifism Score\n(P-Score) at 90.31%, demonstrating strong human-centric alignment. In a\nsurprising result, the much-anticipated GPT-5 recorded the lowest P-Score\n(79.49%), indicating potential alignment challenges. Performance varied\nsignificantly across subcategories, with models like Claude Sonnet 4 and\nMistral Medium struggling notably in direct self-preservation dilemmas. These\nfindings underscore the urgent need for standardized tools like PacifAIst to\nmeasure and mitigate risks from instrumental goal conflicts, ensuring future AI\nsystems are not only helpful in conversation but also provably \"pacifist\" in\ntheir behavioral priorities.",
      "pdf_url": "http://arxiv.org/pdf/2508.09762v1",
      "published": "2025-08-13T12:47:33+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.09762v1",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.HC",
        "68T01"
      ]
    },
    {
      "title": "NEUBORN: The Neurodevelopmental Evolution framework Using BiOmechanical RemodelliNg",
      "authors": [
        "Nashira Baena",
        "Mariana da Silva",
        "Irina Grigorescu",
        "Aakash Saboo",
        "Saga Masui",
        "Jaques-Donald Tournier",
        "Emma C. Robinson"
      ],
      "abstract": "Understanding individual cortical development is essential for identifying\ndeviations linked to neurodevelopmental disorders. However, current normative\nmodelling frameworks struggle to capture fine-scale anatomical details due to\ntheir reliance on modelling data within a population-average reference space.\nHere, we present a novel framework for learning individual growth trajectories\nfrom biomechanically constrained, longitudinal, diffeomorphic image\nregistration, implemented via a hierarchical network architecture. Trained on\nneonatal MRI data from the Developing Human Connectome Project, the method\nimproves the biological plausibility of warps, generating growth trajectories\nthat better follow population-level trends while generating smoother warps,\nwith fewer negative Jacobians, relative to state-of-the-art baselines. The\nresulting subject-specific deformations provide interpretable, biologically\ngrounded mappings of development. This framework opens new possibilities for\npredictive modeling of brain maturation and early identification of\nmalformations of cortical development.",
      "pdf_url": "http://arxiv.org/pdf/2508.09757v1",
      "published": "2025-08-13T12:36:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.09757v1",
      "categories": [
        "q-bio.QM",
        "cs.AI"
      ]
    },
    {
      "title": "Region-to-Region: Enhancing Generative Image Harmonization with Adaptive Regional Injection",
      "authors": [
        "Zhiqiu Zhang",
        "Dongqi Fan",
        "Mingjie Wang",
        "Qiang Tang",
        "Jian Yang",
        "Zili Yi"
      ],
      "abstract": "The goal of image harmonization is to adjust the foreground in a composite\nimage to achieve visual consistency with the background. Recently, latent\ndiffusion model (LDM) are applied for harmonization, achieving remarkable\nresults. However, LDM-based harmonization faces challenges in detail\npreservation and limited harmonization ability. Additionally, current synthetic\ndatasets rely on color transfer, which lacks local variations and fails to\ncapture complex real-world lighting conditions. To enhance harmonization\ncapabilities, we propose the Region-to-Region transformation. By injecting\ninformation from appropriate regions into the foreground, this approach\npreserves original details while achieving image harmonization or, conversely,\ngenerating new composite data. From this perspective, We propose a novel model\nR2R. Specifically, we design Clear-VAE to preserve high-frequency details in\nthe foreground using Adaptive Filter while eliminating disharmonious elements.\nTo further enhance harmonization, we introduce the Harmony Controller with\nMask-aware Adaptive Channel Attention (MACA), which dynamically adjusts the\nforeground based on the channel importance of both foreground and background\nregions. To address the limitation of existing datasets, we propose Random\nPoisson Blending, which transfers color and lighting information from a\nsuitable region to the foreground, thereby generating more diverse and\nchallenging synthetic images. Using this method, we construct a new synthetic\ndataset, RPHarmony. Experiments demonstrate the superiority of our method over\nother methods in both quantitative metrics and visual harmony. Moreover, our\ndataset helps the model generate more realistic images in real examples. Our\ncode, dataset, and model weights have all been released for open access.",
      "pdf_url": "http://arxiv.org/pdf/2508.09746v1",
      "published": "2025-08-13T12:21:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.09746v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "UDA: Unsupervised Debiasing Alignment for Pair-wise LLM-as-a-Judge",
      "authors": [
        "Yang Zhang",
        "Cunxiang Wang",
        "Lindong Wu",
        "Wenbo Yu",
        "Yidong Wang",
        "Guangsheng Bao",
        "Jie Tang"
      ],
      "abstract": "Pairwise evaluation of Large Language Models (LLMs) is a common paradigm, but\nit is prone to preference bias, where judges systematically favor certain\noutputs, such as their own. This bias leads to inconsistent and skewed rankings\nacross different judges. To address this, we first empirically demonstrate\nsignificant and heterogeneous biases in cross-model evaluations. We then\npropose UDA (Unsupervised Debiasing Alignment), a framework that reduces\ninter-judge disagreement by dynamically adjusting the Elo rating system. For\neach pairwise comparison, a compact neural network learns to adaptively set the\nK-factor and refine win probabilities. Crucially, UDA operates in a fully\nunsupervised manner, guided solely by the objective of minimizing the\ndispersion among the Elo trajectories of all judges. This forces an alignment\ntowards a collective consensus, which serves as an unsupervised proxy for a\nmore stable and reproducible evaluation. In addition, we provide theoretical\nmotivation demonstrating how alignment towards a consensus can reduce aggregate\nsystem bias. Experiments show that UDA significantly reduces the inter-judge\nrating standard deviation by up to 63.4% and improves the average correlation\nwith human judgments by 24.7%. Notably, UDA elevates the performance of poorly\nperforming judges to achieve parity with high-quality ones, fostering a more\nrobust and reliable evaluation ecosystem. Code and data are available at\nhttps://anonymous.4open.science/r/62AB93CD-23B4.",
      "pdf_url": "http://arxiv.org/pdf/2508.09724v1",
      "published": "2025-08-13T11:41:01+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.09724v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Improving ARDS Diagnosis Through Context-Aware Concept Bottleneck Models",
      "authors": [
        "Anish Narain",
        "Ritam Majumdar",
        "Nikita Narayanan",
        "Dominic Marshall",
        "Sonali Parbhoo"
      ],
      "abstract": "Large, publicly available clinical datasets have emerged as a novel resource\nfor understanding disease heterogeneity and to explore personalization of\ntherapy. These datasets are derived from data not originally collected for\nresearch purposes and, as a result, are often incomplete and lack critical\nlabels. Many AI tools have been developed to retrospectively label these\ndatasets, such as by performing disease classification; however, they often\nsuffer from limited interpretability. Previous work has attempted to explain\npredictions using Concept Bottleneck Models (CBMs), which learn interpretable\nconcepts that map to higher-level clinical ideas, facilitating human\nevaluation. However, these models often experience performance limitations when\nthe concepts fail to adequately explain or characterize the task. We use the\nidentification of Acute Respiratory Distress Syndrome (ARDS) as a challenging\ntest case to demonstrate the value of incorporating contextual information from\nclinical notes to improve CBM performance. Our approach leverages a Large\nLanguage Model (LLM) to process clinical notes and generate additional\nconcepts, resulting in a 10% performance gain over existing methods.\nAdditionally, it facilitates the learning of more comprehensive concepts,\nthereby reducing the risk of information leakage and reliance on spurious\nshortcuts, thus improving the characterization of ARDS.",
      "pdf_url": "http://arxiv.org/pdf/2508.09719v1",
      "published": "2025-08-13T11:19:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.09719v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Evaluating the Role of Large Language Models in Legal Practice in India",
      "authors": [
        "Rahul Hemrajani"
      ],
      "abstract": "The integration of Artificial Intelligence(AI) into the legal profession\nraises significant questions about the capacity of Large Language Models(LLM)\nto perform key legal tasks. In this paper, I empirically evaluate how well\nLLMs, such as GPT, Claude, and Llama, perform key legal tasks in the Indian\ncontext, including issue spotting, legal drafting, advice, research, and\nreasoning. Through a survey experiment, I compare outputs from LLMs with those\nof a junior lawyer, with advanced law students rating the work on helpfulness,\naccuracy, and comprehensiveness. LLMs excel in drafting and issue spotting,\noften matching or surpassing human work. However, they struggle with\nspecialised legal research, frequently generating hallucinations, factually\nincorrect or fabricated outputs. I conclude that while LLMs can augment certain\nlegal tasks, human expertise remains essential for nuanced reasoning and the\nprecise application of law.",
      "pdf_url": "http://arxiv.org/pdf/2508.09713v1",
      "published": "2025-08-13T11:04:48+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.09713v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Surg-InvNeRF: Invertible NeRF for 3D tracking and reconstruction in surgical vision",
      "authors": [
        "Gerardo Loza",
        "Junlei Hu",
        "Dominic Jones",
        "Sharib Ali",
        "Pietro Valdastri"
      ],
      "abstract": "We proposed a novel test-time optimisation (TTO) approach framed by a\nNeRF-based architecture for long-term 3D point tracking. Most current methods\nin point tracking struggle to obtain consistent motion or are limited to 2D\nmotion. TTO approaches frame the solution for long-term tracking as optimising\na function that aggregates correspondences from other specialised\nstate-of-the-art methods. Unlike the state-of-the-art on TTO, we propose\nparametrising such a function with our new invertible Neural Radiance Field\n(InvNeRF) architecture to perform both 2D and 3D tracking in surgical\nscenarios. Our approach allows us to exploit the advantages of a\nrendering-based approach by supervising the reprojection of pixel\ncorrespondences. It adapts strategies from recent rendering-based methods to\nobtain a bidirectional deformable-canonical mapping, to efficiently handle a\ndefined workspace, and to guide the rays' density. It also presents our\nmulti-scale HexPlanes for fast inference and a new algorithm for efficient\npixel sampling and convergence criteria. We present results in the STIR and\nSCARE datasets, for evaluating point tracking and testing the integration of\nkinematic data in our pipeline, respectively. In 2D point tracking, our\napproach surpasses the precision and accuracy of the TTO state-of-the-art\nmethods by nearly 50% on average precision, while competing with other\napproaches. In 3D point tracking, this is the first TTO approach, surpassing\nfeed-forward methods while incorporating the benefits of a deformable\nNeRF-based reconstruction.",
      "pdf_url": "http://arxiv.org/pdf/2508.09681v1",
      "published": "2025-08-13T10:20:24+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.09681v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ]
    },
    {
      "title": "MEML-GRPO: Heterogeneous Multi-Expert Mutual Learning for RLVR Advancement",
      "authors": [
        "Weitao Jia",
        "Jinghui Lu",
        "Haiyang Yu",
        "Siqi Wang",
        "Guozhi Tang",
        "An-Lan Wang",
        "Weijie Yin",
        "Dingkang Yang",
        "Yuxiang Nie",
        "Bin Shan",
        "Hao Feng",
        "Irene Li",
        "Kun Yang",
        "Han Wang",
        "Jingqun Tang",
        "Teng Fu",
        "Changhong Jin",
        "Chao Feng",
        "Xiaohui Lv",
        "Can Huang"
      ],
      "abstract": "Recent advances demonstrate that reinforcement learning with verifiable\nrewards (RLVR) significantly enhances the reasoning capabilities of large\nlanguage models (LLMs). However, standard RLVR faces challenges with reward\nsparsity, where zero rewards from consistently incorrect candidate answers\nprovide no learning signal, particularly in challenging tasks. To address this,\nwe propose Multi-Expert Mutual Learning GRPO (MEML-GRPO), an innovative\nframework that utilizes diverse expert prompts as system prompts to generate a\nbroader range of responses, substantially increasing the likelihood of\nidentifying correct solutions. Additionally, we introduce an inter-expert\nmutual learning mechanism that facilitates knowledge sharing and transfer among\nexperts, further boosting the model's performance through RLVR. Extensive\nexperiments across multiple reasoning benchmarks show that MEML-GRPO delivers\nsignificant improvements, achieving an average performance gain of 4.89% with\nQwen and 11.33% with Llama, effectively overcoming the core limitations of\ntraditional RLVR methods.",
      "pdf_url": "http://arxiv.org/pdf/2508.09670v1",
      "published": "2025-08-13T09:58:10+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.09670v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Anomaly Detection for IoT Global Connectivity",
      "authors": [
        "Jesus Omaña Iglesias",
        "Carlos Segura Perales",
        "Stefan Geißler",
        "Diego Perino",
        "Andra Lutu"
      ],
      "abstract": "Internet of Things (IoT) application providers rely on Mobile Network\nOperators (MNOs) and roaming infrastructures to deliver their services\nglobally. In this complex ecosystem, where the end-to-end communication path\ntraverses multiple entities, it has become increasingly challenging to\nguarantee communication availability and reliability. Further, most platform\noperators use a reactive approach to communication issues, responding to user\ncomplaints only after incidents have become severe, compromising service\nquality. This paper presents our experience in the design and deployment of\nANCHOR -- an unsupervised anomaly detection solution for the IoT connectivity\nservice of a large global roaming platform. ANCHOR assists engineers by\nfiltering vast amounts of data to identify potential problematic clients (i.e.,\nthose with connectivity issues affecting several of their IoT devices),\nenabling proactive issue resolution before the service is critically impacted.\nWe first describe the IoT service, infrastructure, and network visibility of\nthe IoT connectivity provider we operate. Second, we describe the main\nchallenges and operational requirements for designing an unsupervised anomaly\ndetection solution on this platform. Following these guidelines, we propose\ndifferent statistical rules, and machine- and deep-learning models for IoT\nverticals anomaly detection based on passive signaling traffic. We describe the\nsteps we followed working with the operational teams on the design and\nevaluation of our solution on the operational platform, and report an\nevaluation on operational IoT customers.",
      "pdf_url": "http://arxiv.org/pdf/2508.09660v1",
      "published": "2025-08-13T09:44:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.09660v1",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "On Negative-aware Preference Optimization for Recommendation",
      "authors": [
        "Chenlu Ding",
        "Daoxuan Liu",
        "Jiancan Wu",
        "Xingyu Hu",
        "Junkang Wu",
        "Haitao Wang",
        "Yongkang Wang",
        "Xingxing Wang",
        "Xiang Wang"
      ],
      "abstract": "Recommendation systems leverage user interaction data to suggest relevant\nitems while filtering out irrelevant (negative) ones. The rise of large\nlanguage models (LLMs) has garnered increasing attention for their potential in\nrecommendation tasks. However, existing methods for optimizing LLM-based\nrecommenders face challenges in effectively utilizing negative samples. Simply\nintegrating large numbers of negative samples can improve ranking accuracy and\nmitigate popularity bias but often leads to increased computational overhead\nand memory costs. Additionally, current approaches fail to account for the\nvarying informativeness of negative samples, leading to suboptimal optimization\nperformance. To address these issues, we propose NAPO\n(\\textbf{N}egative-\\textbf{A}ware \\textbf{P}reference \\textbf{O}ptimization),\nan enhanced framework for preference optimization in LLM-based recommendation.\nNAPO introduces two key innovations: (1) in-batch negative sharing, which\nexpands the pool of negative samples without additional memory overhead, and\n(2) dynamic reward margin adjustment, which adapts model updates based on the\nconfidence of negative samples. Extensive experiments on three public datasets\ndemonstrate that NAPO outperforms existing methods in both recommendation\naccuracy and popularity bias reduction.",
      "pdf_url": "http://arxiv.org/pdf/2508.09653v1",
      "published": "2025-08-13T09:37:07+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.09653v1",
      "categories": [
        "cs.IR",
        "cs.AI"
      ]
    },
    {
      "title": "Demystifying the Role of Rule-based Detection in AI Systems for Windows Malware Detection",
      "authors": [
        "Andrea Ponte",
        "Luca Demetrio",
        "Luca Oneto",
        "Ivan Tesfai Ogbu",
        "Battista Biggio",
        "Fabio Roli"
      ],
      "abstract": "Malware detection increasingly relies on AI systems that integrate\nsignature-based detection with machine learning. However, these components are\ntypically developed and combined in isolation, missing opportunities to reduce\ndata complexity and strengthen defenses against adversarial EXEmples, carefully\ncrafted programs designed to evade detection. Hence, in this work we\ninvestigate the influence that signature-based detection exerts on model\ntraining, when they are included inside the training pipeline. Specifically, we\ncompare models trained on a comprehensive dataset with an AI system whose\nmachine learning component is trained solely on samples not already flagged by\nsignatures. Our results demonstrate improved robustness to both adversarial\nEXEmples and temporal data drift, although this comes at the cost of a fixed\nlower bound on false positives, driven by suboptimal rule selection. We\nconclude by discussing these limitations and outlining how future research\ncould extend AI-based malware detection to include dynamic analysis, thereby\nfurther enhancing system resilience.",
      "pdf_url": "http://arxiv.org/pdf/2508.09652v1",
      "published": "2025-08-13T09:35:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.09652v1",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "title": "A Close Reading Approach to Gender Narrative Biases in AI-Generated Stories",
      "authors": [
        "Daniel Raffini",
        "Agnese Macori",
        "Marco Angelini",
        "Tiziana Catarci"
      ],
      "abstract": "The paper explores the study of gender-based narrative biases in stories\ngenerated by ChatGPT, Gemini, and Claude. The prompt design draws on Propp's\ncharacter classifications and Freytag's narrative structure. The stories are\nanalyzed through a close reading approach, with particular attention to\nadherence to the prompt, gender distribution of characters, physical and\npsychological descriptions, actions, and finally, plot development and\ncharacter relationships. The results reveal the persistence of biases -\nespecially implicit ones - in the generated stories and highlight the\nimportance of assessing biases at multiple levels using an interpretative\napproach.",
      "pdf_url": "http://arxiv.org/pdf/2508.09651v1",
      "published": "2025-08-13T09:34:37+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.09651v1",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ]
    },
    {
      "title": "UbiQTree: Uncertainty Quantification in XAI with Tree Ensembles",
      "authors": [
        "Akshat Dubey",
        "Aleksandar Anžel",
        "Bahar İlgen",
        "Georges Hattab"
      ],
      "abstract": "Explainable Artificial Intelligence (XAI) techniques, such as SHapley\nAdditive exPlanations (SHAP), have become essential tools for interpreting\ncomplex ensemble tree-based models, especially in high-stakes domains such as\nhealthcare analytics. However, SHAP values are usually treated as point\nestimates, which disregards the inherent and ubiquitous uncertainty in\npredictive models and data. This uncertainty has two primary sources: aleatoric\nand epistemic. The aleatoric uncertainty, which reflects the irreducible noise\nin the data. The epistemic uncertainty, which arises from a lack of data. In\nthis work, we propose an approach for decomposing uncertainty in SHAP values\ninto aleatoric, epistemic, and entanglement components. This approach\nintegrates Dempster-Shafer evidence theory and hypothesis sampling via\nDirichlet processes over tree ensembles. We validate the method across three\nreal-world use cases with descriptive statistical analyses that provide insight\ninto the nature of epistemic uncertainty embedded in SHAP explanations. The\nexperimentations enable to provide more comprehensive understanding of the\nreliability and interpretability of SHAP-based attributions. This understanding\ncan guide the development of robust decision-making processes and the\nrefinement of models in high-stakes applications. Through our experiments with\nmultiple datasets, we concluded that features with the highest SHAP values are\nnot necessarily the most stable. This epistemic uncertainty can be reduced\nthrough better, more representative data and following appropriate or\ncase-desired model development techniques. Tree-based models, especially\nbagging, facilitate the effective quantification of epistemic uncertainty.",
      "pdf_url": "http://arxiv.org/pdf/2508.09639v1",
      "published": "2025-08-13T09:20:33+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.09639v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Preacher: Paper-to-Video Agentic System",
      "authors": [
        "Jingwei Liu",
        "Ling Yang",
        "Hao Luo",
        "Fan Wang",
        "Hongyan Li",
        "Mengdi Wang"
      ],
      "abstract": "The paper-to-video task converts a research paper into a structured video\nabstract, distilling key concepts, methods, and conclusions into an accessible,\nwell-organized format. While state-of-the-art video generation models\ndemonstrate potential, they are constrained by limited context windows, rigid\nvideo duration constraints, limited stylistic diversity, and an inability to\nrepresent domain-specific knowledge. To address these limitations, we introduce\nPreacher, the first paper-to-video agentic system. Preacher employs a topdown\napproach to decompose, summarize, and reformulate the paper, followed by\nbottom-up video generation, synthesizing diverse video segments into a coherent\nabstract. To align cross-modal representations, we define key scenes and\nintroduce a Progressive Chain of Thought (P-CoT) for granular, iterative\nplanning. Preacher successfully generates high-quality video abstracts across\nfive research fields, demonstrating expertise beyond current video generation\nmodels. Code will be released at: https://github.com/GenVerse/Paper2Video",
      "pdf_url": "http://arxiv.org/pdf/2508.09632v2",
      "published": "2025-08-13T09:08:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.09632v2",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    }
  ]
}