{
  "last_updated": "2025-08-02T00:55:00.401403",
  "papers": [
    {
      "title": "SUB: Benchmarking CBM Generalization via Synthetic Attribute Substitutions",
      "authors": [
        "Jessica Bader",
        "Leander Girrbach",
        "Stephan Alaniz",
        "Zeynep Akata"
      ],
      "abstract": "Concept Bottleneck Models (CBMs) and other concept-based interpretable models\nshow great promise for making AI applications more transparent, which is\nessential in fields like medicine. Despite their success, we demonstrate that\nCBMs struggle to reliably identify the correct concepts under distribution\nshifts. To assess the robustness of CBMs to concept variations, we introduce\nSUB: a fine-grained image and concept benchmark containing 38,400 synthetic\nimages based on the CUB dataset. To create SUB, we select a CUB subset of 33\nbird classes and 45 concepts to generate images which substitute a specific\nconcept, such as wing color or belly pattern. We introduce a novel Tied\nDiffusion Guidance (TDG) method to precisely control generated images, where\nnoise sharing for two parallel denoising processes ensures that both the\ncorrect bird class and the correct attribute are generated. This novel\nbenchmark enables rigorous evaluation of CBMs and similar interpretable models,\ncontributing to the development of more robust methods. Our code is available\nat https://github.com/ExplainableML/sub and the dataset at\nhttp://huggingface.co/datasets/Jessica-bader/SUB.",
      "pdf_url": "http://arxiv.org/pdf/2507.23784v1",
      "published": "2025-07-31T17:59:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.23784v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Phi-Ground Tech Report: Advancing Perception in GUI Grounding",
      "authors": [
        "Miaosen Zhang",
        "Ziqiang Xu",
        "Jialiang Zhu",
        "Qi Dai",
        "Kai Qiu",
        "Yifan Yang",
        "Chong Luo",
        "Tianyi Chen",
        "Justin Wagle",
        "Tim Franklin",
        "Baining Guo"
      ],
      "abstract": "With the development of multimodal reasoning models, Computer Use Agents\n(CUAs), akin to Jarvis from \\textit{\"Iron Man\"}, are becoming a reality. GUI\ngrounding is a core component for CUAs to execute actual actions, similar to\nmechanical control in robotics, and it directly leads to the success or failure\nof the system. It determines actions such as clicking and typing, as well as\nrelated parameters like the coordinates for clicks. Current end-to-end\ngrounding models still achieve less than 65\\% accuracy on challenging\nbenchmarks like ScreenSpot-pro and UI-Vision, indicating they are far from\nbeing ready for deployment. % , as a single misclick can result in unacceptable\nconsequences. In this work, we conduct an empirical study on the training of\ngrounding models, examining details from data collection to model training.\nUltimately, we developed the \\textbf{Phi-Ground} model family, which achieves\nstate-of-the-art performance across all five grounding benchmarks for models\nunder $10B$ parameters in agent settings. In the end-to-end model setting, our\nmodel still achieves SOTA results with scores of \\textit{\\textbf{43.2}} on\nScreenSpot-pro and \\textit{\\textbf{27.2}} on UI-Vision. We believe that the\nvarious details discussed in this paper, along with our successes and failures,\nnot only clarify the construction of grounding models but also benefit other\nperception tasks. Project homepage:\n\\href{https://zhangmiaosen2000.github.io/Phi-Ground/}{https://zhangmiaosen2000.github.io/Phi-Ground/}",
      "pdf_url": "http://arxiv.org/pdf/2507.23779v1",
      "published": "2025-07-31T17:59:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.23779v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ]
    },
    {
      "title": "SimuRA: Towards General Goal-Oriented Agent via Simulative Reasoning Architecture with LLM-Based World Model",
      "authors": [
        "Mingkai Deng",
        "Jinyu Hou",
        "Yilin Shen",
        "Hongxia Jin",
        "Graham Neubig",
        "Zhiting Hu",
        "Eric Xing"
      ],
      "abstract": "AI agents built on large language models (LLMs) hold enormous promise, but\ncurrent practice focuses on a one-task-one-agent approach, which not only falls\nshort of scalability and generality, but also suffers from the fundamental\nlimitations of autoregressive LLMs. On the other hand, humans are general\nagents who reason by mentally simulating the outcomes of their actions and\nplans. Moving towards a more general and powerful AI agent, we introduce\nSimuRA, a goal-oriented architecture for generalized agentic reasoning. Based\non a principled formulation of optimal agent in any environment, \\modelname\novercomes the limitations of autoregressive reasoning by introducing a world\nmodel for planning via simulation. The generalized world model is implemented\nusing LLM, which can flexibly plan in a wide range of environments using the\nconcept-rich latent space of natural language. Experiments on difficult web\nbrowsing tasks show that \\modelname improves the success of flight search from\n0\\% to 32.2\\%. World-model-based planning, in particular, shows consistent\nadvantage of up to 124\\% over autoregressive planning, demonstrating the\nadvantage of world model simulation as a reasoning paradigm. We are excited\nabout the possibility for training a single, general agent model based on LLMs\nthat can act superintelligently in all environments. To start, we make SimuRA,\na web-browsing agent built on \\modelname with pretrained LLMs, available as a\nresearch demo for public testing.",
      "pdf_url": "http://arxiv.org/pdf/2507.23773v1",
      "published": "2025-07-31T17:57:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.23773v1",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.RO"
      ]
    },
    {
      "title": "Consensus-Driven Active Model Selection",
      "authors": [
        "Justin Kay",
        "Grant Van Horn",
        "Subhransu Maji",
        "Daniel Sheldon",
        "Sara Beery"
      ],
      "abstract": "The widespread availability of off-the-shelf machine learning models poses a\nchallenge: which model, of the many available candidates, should be chosen for\na given data analysis task? This question of model selection is traditionally\nanswered by collecting and annotating a validation dataset -- a costly and\ntime-intensive process. We propose a method for active model selection, using\npredictions from candidate models to prioritize the labeling of test data\npoints that efficiently differentiate the best candidate. Our method, CODA,\nperforms consensus-driven active model selection by modeling relationships\nbetween classifiers, categories, and data points within a probabilistic\nframework. The framework uses the consensus and disagreement between models in\nthe candidate pool to guide the label acquisition process, and Bayesian\ninference to update beliefs about which model is best as more information is\ncollected. We validate our approach by curating a collection of 26 benchmark\ntasks capturing a range of model selection scenarios. CODA outperforms existing\nmethods for active model selection significantly, reducing the annotation\neffort required to discover the best model by upwards of 70% compared to the\nprevious state-of-the-art. Code and data are available at\nhttps://github.com/justinkay/coda.",
      "pdf_url": "http://arxiv.org/pdf/2507.23771v1",
      "published": "2025-07-31T17:56:28+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.23771v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "CoT-Self-Instruct: Building high-quality synthetic prompts for reasoning and non-reasoning tasks",
      "authors": [
        "Ping Yu",
        "Jack Lanchantin",
        "Tianlu Wang",
        "Weizhe Yuan",
        "Olga Golovneva",
        "Ilia Kulikov",
        "Sainbayar Sukhbaatar",
        "Jason Weston",
        "Jing Xu"
      ],
      "abstract": "We propose CoT-Self-Instruct, a synthetic data generation method that\ninstructs LLMs to first reason and plan via Chain-of-Thought (CoT) based on the\ngiven seed tasks, and then to generate a new synthetic prompt of similar\nquality and complexity for use in LLM training, followed by filtering for\nhigh-quality data with automatic metrics. In verifiable reasoning, our\nsynthetic data significantly outperforms existing training datasets, such as\ns1k and OpenMathReasoning, across MATH500, AMC23, AIME24 and GPQA-Diamond. For\nnon-verifiable instruction-following tasks, our method surpasses the\nperformance of human or standard self-instruct prompts on both AlpacaEval 2.0\nand Arena-Hard.",
      "pdf_url": "http://arxiv.org/pdf/2507.23751v1",
      "published": "2025-07-31T17:38:50+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.23751v1",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Rule2Text: Natural Language Explanation of Logical Rules in Knowledge Graphs",
      "authors": [
        "Nasim Shirvani-Mahdavi",
        "Devin Wingfield",
        "Amin Ghasemi",
        "Chengkai Li"
      ],
      "abstract": "Knowledge graphs (KGs) often contain sufficient information to support the\ninference of new facts. Identifying logical rules not only improves the\ncompleteness of a knowledge graph but also enables the detection of potential\nerrors, reveals subtle data patterns, and enhances the overall capacity for\nreasoning and interpretation. However, the complexity of such rules, combined\nwith the unique labeling conventions of each KG, can make them difficult for\nhumans to understand. In this paper, we explore the potential of large language\nmodels to generate natural language explanations for logical rules.\nSpecifically, we extract logical rules using the AMIE 3.5.1 rule discovery\nalgorithm from the benchmark dataset FB15k-237 and two large-scale datasets,\nFB-CVT-REV and FB+CVT-REV. We examine various prompting strategies, including\nzero- and few-shot prompting, including variable entity types, and\nchain-of-thought reasoning. We conduct a comprehensive human evaluation of the\ngenerated explanations based on correctness, clarity, and hallucination, and\nalso assess the use of large language models as automatic judges. Our results\ndemonstrate promising performance in terms of explanation correctness and\nclarity, although several challenges remain for future research. All scripts\nand data used in this study are publicly available at\nhttps://github.com/idirlab/KGRule2NL}{https://github.com/idirlab/KGRule2NL.",
      "pdf_url": "http://arxiv.org/pdf/2507.23740v1",
      "published": "2025-07-31T17:24:04+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.23740v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Distributed AI Agents for Cognitive Underwater Robot Autonomy",
      "authors": [
        "Markus Buchholz",
        "Ignacio Carlucho",
        "Michele Grimaldi",
        "Yvan R. Petillot"
      ],
      "abstract": "Achieving robust cognitive autonomy in robots navigating complex,\nunpredictable environments remains a fundamental challenge in robotics. This\npaper presents Underwater Robot Self-Organizing Autonomy (UROSA), a\ngroundbreaking architecture leveraging distributed Large Language Model AI\nagents integrated within the Robot Operating System 2 (ROS 2) framework to\nenable advanced cognitive capabilities in Autonomous Underwater Vehicles. UROSA\ndecentralises cognition into specialised AI agents responsible for multimodal\nperception, adaptive reasoning, dynamic mission planning, and real-time\ndecision-making. Central innovations include flexible agents dynamically\nadapting their roles, retrieval-augmented generation utilising vector databases\nfor efficient knowledge management, reinforcement learning-driven behavioural\noptimisation, and autonomous on-the-fly ROS 2 node generation for runtime\nfunctional extensibility. Extensive empirical validation demonstrates UROSA's\npromising adaptability and reliability through realistic underwater missions in\nsimulation and real-world deployments, showing significant advantages over\ntraditional rule-based architectures in handling unforeseen scenarios,\nenvironmental uncertainties, and novel mission objectives. This work not only\nadvances underwater autonomy but also establishes a scalable, safe, and\nversatile cognitive robotics framework capable of generalising to a diverse\narray of real-world applications.",
      "pdf_url": "http://arxiv.org/pdf/2507.23735v1",
      "published": "2025-07-31T17:18:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.23735v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.MA"
      ]
    },
    {
      "title": "Seed-Prover: Deep and Broad Reasoning for Automated Theorem Proving",
      "authors": [
        "Luoxin Chen",
        "Jinming Gu",
        "Liankai Huang",
        "Wenhao Huang",
        "Zhicheng Jiang",
        "Allan Jie",
        "Xiaoran Jin",
        "Xing Jin",
        "Chenggang Li",
        "Kaijing Ma",
        "Cheng Ren",
        "Jiawei Shen",
        "Wenlei Shi",
        "Tong Sun",
        "He Sun",
        "Jiahui Wang",
        "Siran Wang",
        "Zhihong Wang",
        "Chenrui Wei",
        "Shufa Wei",
        "Yonghui Wu",
        "Yuchen Wu",
        "Yihang Xia",
        "Huajian Xin",
        "Fan Yang",
        "Huaiyuan Ying",
        "Hongyi Yuan",
        "Zheng Yuan",
        "Tianyang Zhan",
        "Chi Zhang",
        "Yue Zhang",
        "Ge Zhang",
        "Tianyun Zhao",
        "Jianqiu Zhao",
        "Yichi Zhou",
        "Thomas Hanwen Zhu"
      ],
      "abstract": "LLMs have demonstrated strong mathematical reasoning abilities by leveraging\nreinforcement learning with long chain-of-thought, yet they continue to\nstruggle with theorem proving due to the lack of clear supervision signals when\nsolely using natural language. Dedicated domain-specific languages like Lean\nprovide clear supervision via formal verification of proofs, enabling effective\ntraining through reinforcement learning. In this work, we propose\n\\textbf{Seed-Prover}, a lemma-style whole-proof reasoning model. Seed-Prover\ncan iteratively refine its proof based on Lean feedback, proved lemmas, and\nself-summarization. To solve IMO-level contest problems, we design three\ntest-time inference strategies that enable both deep and broad reasoning.\nSeed-Prover proves $78.1\\%$ of formalized past IMO problems, saturates MiniF2F,\nand achieves over 50\\% on PutnamBench, outperforming the previous\nstate-of-the-art by a large margin. To address the lack of geometry support in\nLean, we introduce a geometry reasoning engine \\textbf{Seed-Geometry}, which\noutperforms previous formal geometry engines. We use these two systems to\nparticipate in IMO 2025 and fully prove 5 out of 6 problems. This work\nrepresents a significant advancement in automated mathematical reasoning,\ndemonstrating the effectiveness of formal verification with long\nchain-of-thought reasoning.",
      "pdf_url": "http://arxiv.org/pdf/2507.23726v1",
      "published": "2025-07-31T17:00:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.23726v1",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Enhanced Velocity Field Modeling for Gaussian Video Reconstruction",
      "authors": [
        "Zhenyang Li",
        "Xiaoyang Bai",
        "Tongchen Zhang",
        "Pengfei Shen",
        "Weiwei Xu",
        "Yifan Peng"
      ],
      "abstract": "High-fidelity 3D video reconstruction is essential for enabling real-time\nrendering of dynamic scenes with realistic motion in virtual and augmented\nreality (VR/AR). The deformation field paradigm of 3D Gaussian splatting has\nachieved near-photorealistic results in video reconstruction due to the great\nrepresentation capability of deep deformation networks. However, in videos with\ncomplex motion and significant scale variations, deformation networks often\noverfit to irregular Gaussian trajectories, leading to suboptimal visual\nquality. Moreover, the gradient-based densification strategy designed for\nstatic scene reconstruction proves inadequate to address the absence of dynamic\ncontent. In light of these challenges, we propose a flow-empowered velocity\nfield modeling scheme tailored for Gaussian video reconstruction, dubbed\nFlowGaussian-VR. It consists of two core components: a velocity field rendering\n(VFR) pipeline which enables optical flow-based optimization, and a\nflow-assisted adaptive densification (FAD) strategy that adjusts the number and\nsize of Gaussians in dynamic regions. We validate our model's effectiveness on\nmulti-view dynamic reconstruction and novel view synthesis with multiple\nreal-world datasets containing challenging motion scenarios, demonstrating not\nonly notable visual improvements (over 2.5 dB gain in PSNR) and less blurry\nartifacts in dynamic textures, but also regularized and trackable per-Gaussian\ntrajectories.",
      "pdf_url": "http://arxiv.org/pdf/2507.23704v1",
      "published": "2025-07-31T16:26:22+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.23704v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "TextQuests: How Good are LLMs at Text-Based Video Games?",
      "authors": [
        "Long Phan",
        "Mantas Mazeika",
        "Andy Zou",
        "Dan Hendrycks"
      ],
      "abstract": "Evaluating AI agents within complex, interactive environments that mirror\nreal-world challenges is critical for understanding their practical\ncapabilities. While existing agent benchmarks effectively assess skills like\ntool use or performance on structured tasks, they often do not fully capture an\nagent's ability to operate autonomously in exploratory environments that demand\nsustained, self-directed reasoning over a long and growing context. To spur the\ndevelopment of agents capable of more robust intrinsic reasoning over long\nhorizons, we introduce TextQuests, a benchmark based on the Infocom suite of\ninteractive fiction games. These text-based adventures, which can take human\nplayers over 30 hours and require hundreds of precise actions to solve, serve\nas an effective proxy for evaluating AI agents on focused, stateful tasks. The\nbenchmark is specifically designed to assess an LLM agent's capacity for\nself-contained problem-solving by precluding the use of external tools, thereby\nfocusing on intrinsic long-context reasoning capabilities in an exploratory\nenvironment characterized by the need for trial-and-error learning and\nsustained problem-solving within a single interactive session. We release\nTextQuests at https://textquests.ai.",
      "pdf_url": "http://arxiv.org/pdf/2507.23701v1",
      "published": "2025-07-31T16:22:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.23701v1",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Scalable Multi-Task Reinforcement Learning for Generalizable Spatial Intelligence in Visuomotor Agents",
      "authors": [
        "Shaofei Cai",
        "Zhancun Mu",
        "Haiwen Xia",
        "Bowei Zhang",
        "Anji Liu",
        "Yitao Liang"
      ],
      "abstract": "While Reinforcement Learning (RL) has achieved remarkable success in language\nmodeling, its triumph hasn't yet fully translated to visuomotor agents. A\nprimary challenge in RL models is their tendency to overfit specific tasks or\nenvironments, thereby hindering the acquisition of generalizable behaviors\nacross diverse settings. This paper provides a preliminary answer to this\nchallenge by demonstrating that RL-finetuned visuomotor agents in Minecraft can\nachieve zero-shot generalization to unseen worlds. Specifically, we explore\nRL's potential to enhance generalizable spatial reasoning and interaction\ncapabilities in 3D worlds. To address challenges in multi-task RL\nrepresentation, we analyze and establish cross-view goal specification as a\nunified multi-task goal space for visuomotor policies. Furthermore, to overcome\nthe significant bottleneck of manual task design, we propose automated task\nsynthesis within the highly customizable Minecraft environment for large-scale\nmulti-task RL training, and we construct an efficient distributed RL framework\nto support this. Experimental results show RL significantly boosts interaction\nsuccess rates by $4\\times$ and enables zero-shot generalization of spatial\nreasoning across diverse environments, including real-world settings. Our\nfindings underscore the immense potential of RL training in 3D simulated\nenvironments, especially those amenable to large-scale task generation, for\nsignificantly advancing visuomotor agents' spatial reasoning.",
      "pdf_url": "http://arxiv.org/pdf/2507.23698v1",
      "published": "2025-07-31T16:20:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.23698v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "A survey of multi-agent geosimulation methodologies: from ABM to LLM",
      "authors": [
        "Virginia Padilla",
        "Jacinto Dávila"
      ],
      "abstract": "We provide a comprehensive examination of agent-based approaches that codify\nthe principles and linkages underlying multi-agent systems, simulations, and\ninformation systems. Based on two decades of study, this paper confirms a\nframework intended as a formal specification for geosimulation platforms. Our\nfindings show that large language models (LLMs) can be effectively incorporated\nas agent components if they follow a structured architecture specific to\nfundamental agent activities such as perception, memory, planning, and action.\nThis integration is precisely consistent with the architecture that we\nformalize, providing a solid platform for next-generation geosimulation\nsystems.",
      "pdf_url": "http://arxiv.org/pdf/2507.23694v1",
      "published": "2025-07-31T16:12:22+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.23694v1",
      "categories": [
        "cs.MA",
        "cs.AI",
        "68T42",
        "I.2.11"
      ]
    },
    {
      "title": "villa-X: Enhancing Latent Action Modeling in Vision-Language-Action Models",
      "authors": [
        "Xiaoyu Chen",
        "Hangxing Wei",
        "Pushi Zhang",
        "Chuheng Zhang",
        "Kaixin Wang",
        "Yanjiang Guo",
        "Rushuai Yang",
        "Yucen Wang",
        "Xinquan Xiao",
        "Li Zhao",
        "Jianyu Chen",
        "Jiang Bian"
      ],
      "abstract": "Visual-Language-Action (VLA) models have emerged as a popular paradigm for\nlearning robot manipulation policies that can follow language instructions and\ngeneralize to novel scenarios. Recent work has begun to explore the\nincorporation of latent actions, an abstract representation of visual change\nbetween two frames, into VLA pre-training. In this paper, we introduce villa-X,\na novel Visual-Language-Latent-Action (ViLLA) framework that advances latent\naction modeling for learning generalizable robot manipulation policies. Our\napproach improves both how latent actions are learned and how they are\nincorporated into VLA pre-training. Together, these contributions enable\nvilla-X to achieve superior performance across simulated environments including\nSIMPLER and LIBERO, as well as on two real-world robot setups including gripper\nand dexterous hand manipulation. We believe the ViLLA paradigm holds\nsignificant promise, and that our villa-X provides a strong foundation for\nfuture research.",
      "pdf_url": "http://arxiv.org/pdf/2507.23682v1",
      "published": "2025-07-31T15:57:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.23682v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Automating AI Failure Tracking: Semantic Association of Reports in AI Incident Database",
      "authors": [
        "Diego Russo",
        "Gian Marco Orlando",
        "Valerio La Gatta",
        "Vincenzo Moscato"
      ],
      "abstract": "Artificial Intelligence (AI) systems are transforming critical sectors such\nas healthcare, finance, and transportation, enhancing operational efficiency\nand decision-making processes. However, their deployment in high-stakes domains\nhas exposed vulnerabilities that can result in significant societal harm. To\nsystematically study and mitigate these risk, initiatives like the AI Incident\nDatabase (AIID) have emerged, cataloging over 3,000 real-world AI failure\nreports. Currently, associating a new report with the appropriate AI Incident\nrelies on manual expert intervention, limiting scalability and delaying the\nidentification of emerging failure patterns.\n  To address this limitation, we propose a retrieval-based framework that\nautomates the association of new reports with existing AI Incidents through\nsemantic similarity modeling. We formalize the task as a ranking problem, where\neach report-comprising a title and a full textual description-is compared to\npreviously documented AI Incidents based on embedding cosine similarity.\nBenchmarking traditional lexical methods, cross-encoder architectures, and\ntransformer-based sentence embedding models, we find that the latter\nconsistently achieve superior performance. Our analysis further shows that\ncombining titles and descriptions yields substantial improvements in ranking\naccuracy compared to using titles alone. Moreover, retrieval performance\nremains stable across variations in description length, highlighting the\nrobustness of the framework. Finally, we find that retrieval performance\nconsistently improves as the training set expands. Our approach provides a\nscalable and efficient solution for supporting the maintenance of the AIID.",
      "pdf_url": "http://arxiv.org/pdf/2507.23669v1",
      "published": "2025-07-31T15:48:12+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.23669v1",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.IR"
      ]
    },
    {
      "title": "Personalized Education with Ranking Alignment Recommendation",
      "authors": [
        "Haipeng Liu",
        "Yuxuan Liu",
        "Ting Long"
      ],
      "abstract": "Personalized question recommendation aims to guide individual students\nthrough questions to enhance their mastery of learning targets. Most previous\nmethods model this task as a Markov Decision Process and use reinforcement\nlearning to solve, but they struggle with efficient exploration, failing to\nidentify the best questions for each student during training. To address this,\nwe propose Ranking Alignment Recommendation (RAR), which incorporates\ncollaborative ideas into the exploration mechanism, enabling more efficient\nexploration within limited training episodes. Experiments show that RAR\neffectively improves recommendation performance, and our framework can be\napplied to any RL-based question recommender. Our code is available in\nhttps://github.com/wuming29/RAR.git.",
      "pdf_url": "http://arxiv.org/pdf/2507.23664v1",
      "published": "2025-07-31T15:43:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.23664v1",
      "categories": [
        "cs.AI",
        "cs.IR"
      ]
    },
    {
      "title": "Efficient Masked Attention Transformer for Few-Shot Classification and Segmentation",
      "authors": [
        "Dustin Carrión-Ojeda",
        "Stefan Roth",
        "Simone Schaub-Meyer"
      ],
      "abstract": "Few-shot classification and segmentation (FS-CS) focuses on jointly\nperforming multi-label classification and multi-class segmentation using few\nannotated examples. Although the current state of the art (SOTA) achieves high\naccuracy in both tasks, it struggles with small objects. To overcome this, we\npropose the Efficient Masked Attention Transformer (EMAT), which improves\nclassification and segmentation accuracy, especially for small objects. EMAT\nintroduces three modifications: a novel memory-efficient masked attention\nmechanism, a learnable downscaling strategy, and parameter-efficiency\nenhancements. EMAT outperforms all FS-CS methods on the PASCAL-5$^i$ and\nCOCO-20$^i$ datasets, using at least four times fewer trainable parameters.\nMoreover, as the current FS-CS evaluation setting discards available\nannotations, despite their costly collection, we introduce two novel evaluation\nsettings that consider these annotations to better reflect practical scenarios.",
      "pdf_url": "http://arxiv.org/pdf/2507.23642v1",
      "published": "2025-07-31T15:19:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.23642v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "OptiGradTrust: Byzantine-Robust Federated Learning with Multi-Feature Gradient Analysis and Reinforcement Learning-Based Trust Weighting",
      "authors": [
        "Mohammad Karami",
        "Fatemeh Ghassemi",
        "Hamed Kebriaei",
        "Hamid Azadegan"
      ],
      "abstract": "Federated Learning (FL) enables collaborative model training across\ndistributed medical institutions while preserving patient privacy, but remains\nvulnerable to Byzantine attacks and statistical heterogeneity. We present\nOptiGradTrust, a comprehensive defense framework that evaluates gradient\nupdates through a novel six-dimensional fingerprint including VAE\nreconstruction error, cosine similarity metrics, $L_2$ norm, sign-consistency\nratio, and Monte Carlo Shapley value, which drive a hybrid RL-attention module\nfor adaptive trust scoring. To address convergence challenges under data\nheterogeneity, we develop FedBN-Prox (FedBN-P), combining Federated Batch\nNormalization with proximal regularization for optimal accuracy-convergence\ntrade-offs. Extensive evaluation across MNIST, CIFAR-10, and Alzheimer's MRI\ndatasets under various Byzantine attack scenarios demonstrates significant\nimprovements over state-of-the-art defenses, achieving up to +1.6 percentage\npoints over FLGuard under non-IID conditions while maintaining robust\nperformance against diverse attack patterns through our adaptive learning\napproach.",
      "pdf_url": "http://arxiv.org/pdf/2507.23638v1",
      "published": "2025-07-31T15:14:36+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.23638v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "MemoCue: Empowering LLM-Based Agents for Human Memory Recall via Strategy-Guided Querying",
      "authors": [
        "Qian Zhao",
        "Zhuo Sun",
        "Bin Guo",
        "Zhiwen Yu"
      ],
      "abstract": "Agent-assisted memory recall is one critical research problem in the field of\nhuman-computer interaction. In conventional methods, the agent can retrieve\ninformation from its equipped memory module to help the person recall\nincomplete or vague memories. The limited size of memory module hinders the\nacquisition of complete memories and impacts the memory recall performance in\npractice. Memory theories suggest that the person's relevant memory can be\nproactively activated through some effective cues. Inspired by this, we propose\na novel strategy-guided agent-assisted memory recall method, allowing the agent\nto transform an original query into a cue-rich one via the judiciously designed\nstrategy to help the person recall memories. To this end, there are two key\nchallenges. (1) How to choose the appropriate recall strategy for diverse\nforgetting scenarios with distinct memory-recall characteristics? (2) How to\nobtain the high-quality responses leveraging recall strategies, given only\nabstract and sparsely annotated strategy patterns? To address the challenges,\nwe propose a Recall Router framework. Specifically, we design a 5W Recall Map\nto classify memory queries into five typical scenarios and define fifteen\nrecall strategy patterns across the corresponding scenarios. We then propose a\nhierarchical recall tree combined with the Monte Carlo Tree Search algorithm to\noptimize the selection of strategy and the generation of strategy responses. We\nconstruct an instruction tuning dataset and fine-tune multiple open-source\nlarge language models (LLMs) to develop MemoCue, an agent that excels in\nproviding memory-inspired responses. Experiments on three representative\ndatasets show that MemoCue surpasses LLM-based methods by 17.74% in recall\ninspiration. Further human evaluation highlights its advantages in\nmemory-recall applications.",
      "pdf_url": "http://arxiv.org/pdf/2507.23633v1",
      "published": "2025-07-31T15:11:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.23633v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "L-GTA: Latent Generative Modeling for Time Series Augmentation",
      "authors": [
        "Luis Roque",
        "Carlos Soares",
        "Vitor Cerqueira",
        "Luis Torgo"
      ],
      "abstract": "Data augmentation is gaining importance across various aspects of time series\nanalysis, from forecasting to classification and anomaly detection tasks. We\nintroduce the Latent Generative Transformer Augmentation (L-GTA) model, a\ngenerative approach using a transformer-based variational recurrent\nautoencoder. This model uses controlled transformations within the latent space\nof the model to generate new time series that preserve the intrinsic properties\nof the original dataset. L-GTA enables the application of diverse\ntransformations, ranging from simple jittering to magnitude warping, and\ncombining these basic transformations to generate more complex synthetic time\nseries datasets. Our evaluation of several real-world datasets demonstrates the\nability of L-GTA to produce more reliable, consistent, and controllable\naugmented data. This translates into significant improvements in predictive\naccuracy and similarity measures compared to direct transformation methods.",
      "pdf_url": "http://arxiv.org/pdf/2507.23615v1",
      "published": "2025-07-31T14:53:35+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.23615v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68T01",
        "I.5.1; G.3; H.2.8; I.2.1"
      ]
    },
    {
      "title": "LLM-Based Identification of Infostealer Infection Vectors from Screenshots: The Case of Aurora",
      "authors": [
        "Estelle Ruellan",
        "Eric Clay",
        "Nicholas Ascoli"
      ],
      "abstract": "Infostealers exfiltrate credentials, session cookies, and sensitive data from\ninfected systems. With over 29 million stealer logs reported in 2024, manual\nanalysis and mitigation at scale are virtually unfeasible/unpractical. While\nmost research focuses on proactive malware detection, a significant gap remains\nin leveraging reactive analysis of stealer logs and their associated artifacts.\nSpecifically, infection artifacts such as screenshots, image captured at the\npoint of compromise, are largely overlooked by the current literature. This\npaper introduces a novel approach leveraging Large Language Models (LLMs), more\nspecifically gpt-4o-mini, to analyze infection screenshots to extract potential\nIndicators of Compromise (IoCs), map infection vectors, and track campaigns.\nFocusing on the Aurora infostealer, we demonstrate how LLMs can process\nscreenshots to identify infection vectors, such as malicious URLs, installer\nfiles, and exploited software themes. Our method extracted 337 actionable URLs\nand 246 relevant files from 1000 screenshots, revealing key malware\ndistribution methods and social engineering tactics. By correlating extracted\nfilenames, URLs, and infection themes, we identified three distinct malware\ncampaigns, demonstrating the potential of LLM-driven analysis for uncovering\ninfection workflows and enhancing threat intelligence. By shifting malware\nanalysis from traditional log-based detection methods to a reactive,\nartifact-driven approach that leverages infection screenshots, this research\npresents a scalable method for identifying infection vectors and enabling early\nintervention.",
      "pdf_url": "http://arxiv.org/pdf/2507.23611v1",
      "published": "2025-07-31T14:49:03+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.23611v1",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Deep Learning-based Prediction of Clinical Trial Enrollment with Uncertainty Estimates",
      "authors": [
        "Tien Huu Do",
        "Antoine Masquelier",
        "Nae Eoun Lee",
        "Jonathan Crowther"
      ],
      "abstract": "Clinical trials are a systematic endeavor to assess the safety and efficacy\nof new drugs or treatments. Conducting such trials typically demands\nsignificant financial investment and meticulous planning, highlighting the need\nfor accurate predictions of trial outcomes. Accurately predicting patient\nenrollment, a key factor in trial success, is one of the primary challenges\nduring the planning phase. In this work, we propose a novel deep learning-based\nmethod to address this critical challenge. Our method, implemented as a neural\nnetwork model, leverages pre-trained language models (PLMs) to capture the\ncomplexities and nuances of clinical documents, transforming them into\nexpressive representations. These representations are then combined with\nencoded tabular features via an attention mechanism. To account for\nuncertainties in enrollment prediction, we enhance the model with a\nprobabilistic layer based on the Gamma distribution, which enables range\nestimation. We apply the proposed model to predict clinical trial duration,\nassuming site-level enrollment follows a Poisson-Gamma process. We carry out\nextensive experiments on real-world clinical trial data, and show that the\nproposed method can effectively predict the number of patients enrolled at a\nnumber of sites for a given clinical trial, outperforming established baseline\nmodels.",
      "pdf_url": "http://arxiv.org/pdf/2507.23607v1",
      "published": "2025-07-31T14:47:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.23607v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Can LLM-Reasoning Models Replace Classical Planning? A Benchmark Study",
      "authors": [
        "Kai Goebel",
        "Patrik Zips"
      ],
      "abstract": "Recent advancements in Large Language Models have sparked interest in their\npotential for robotic task planning. While these models demonstrate strong\ngenerative capabilities, their effectiveness in producing structured and\nexecutable plans remains uncertain. This paper presents a systematic evaluation\nof a broad spectrum of current state of the art language models, each directly\nprompted using Planning Domain Definition Language domain and problem files,\nand compares their planning performance with the Fast Downward planner across a\nvariety of benchmarks. In addition to measuring success rates, we assess how\nfaithfully the generated plans translate into sequences of actions that can\nactually be executed, identifying both strengths and limitations of using these\nmodels in this setting. Our findings show that while the models perform well on\nsimpler planning tasks, they continue to struggle with more complex scenarios\nthat require precise resource management, consistent state tracking, and strict\nconstraint compliance. These results underscore fundamental challenges in\napplying language models to robotic planning in real world environments. By\noutlining the gaps that emerge during execution, we aim to guide future\nresearch toward combined approaches that integrate language models with\nclassical planners in order to enhance the reliability and scalability of\nplanning in autonomous robotics.",
      "pdf_url": "http://arxiv.org/pdf/2507.23589v1",
      "published": "2025-07-31T14:25:54+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.23589v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "Semantic Chain-of-Trust: Autonomous Trust Orchestration for Collaborator Selection via Hypergraph-Aided Agentic AI",
      "authors": [
        "Botao Zhu",
        "Xianbin Wang",
        "Dusit Niyato"
      ],
      "abstract": "In collaborative systems, the effective completion of tasks hinges on\ntask-specific trust evaluations of potential devices for distributed\ncollaboration. However, the complexity of tasks, the spatiotemporal dynamism of\ndistributed device resources, and the inevitable assessment overhead\ndramatically increase the complexity and resource consumption of the trust\nevaluation process. As a result, ill-timed or overly frequent trust evaluations\ncan reduce utilization rate of constrained resources, negatively affecting\ncollaborative task execution. To address this challenge, this paper proposes an\nautonomous trust orchestration method based on a new concept of semantic\nchain-of-trust. Our technique employs agentic AI and hypergraph to establish\nand maintain trust relationships among devices. By leveraging its strengths in\nautonomous perception, task decomposition, and semantic reasoning, we propose\nagentic AI to perceive device states and autonomously perform trust evaluations\nof collaborators based on historical performance data only during device idle\nperiods, thereby enabling efficient utilization of distributed resources. In\naddition, agentic AI performs task-specific trust evaluations on collaborator\nresources by analyzing the alignment between resource capabilities and task\nrequirements. Moreover, by maintaining a trust hypergraph embedded with trust\nsemantics for each device, agentic AI enables hierarchical management of\ncollaborators and identifies collaborators requiring trust evaluation based on\ntrust semantics, thereby achieving a balance between overhead and trust\naccuracy. Furthermore, local trust hypergraphs from multiple devices can be\nchained together to support multi-hop collaboration, enabling efficient\ncoordination in large-scale systems. Experimental results demonstrate that the\nproposed method achieves resource-efficient trust evaluation.",
      "pdf_url": "http://arxiv.org/pdf/2507.23565v1",
      "published": "2025-07-31T13:53:25+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.23565v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "DICE: Dynamic In-Context Example Selection in LLM Agents via Efficient Knowledge Transfer",
      "authors": [
        "Ruoyu Wang",
        "Junda Wu",
        "Yu Xia",
        "Tong Yu",
        "Ryan A. Rossi",
        "Julian McAuley",
        "Lina Yao"
      ],
      "abstract": "Large language model-based agents, empowered by in-context learning (ICL),\nhave demonstrated strong capabilities in complex reasoning and tool-use tasks.\nHowever, existing works have shown that the effectiveness of ICL is highly\nsensitive to the choice of demonstrations, with suboptimal examples often\nleading to unstable or degraded performance. While prior work has explored\nexample selection, including in some agentic or multi-step settings, existing\napproaches typically rely on heuristics or task-specific designs and lack a\ngeneral, theoretically grounded criterion for what constitutes an effective\ndemonstration across reasoning steps. Therefore, it is non-trivial to develop a\nprincipled, general-purpose method for selecting demonstrations that\nconsistently benefit agent performance. In this paper, we address this\nchallenge with DICE, Dynamic In-Context Example Selection for LLM Agents, a\ntheoretically grounded ICL framework for agentic tasks that selects the most\nrelevant demonstrations at each step of reasoning. Our approach decomposes\ndemonstration knowledge into transferable and non-transferable components\nthrough a causal lens, showing how the latter can introduce spurious\ndependencies that impair generalization. We further propose a stepwise\nselection criterion with a formal guarantee of improved agent performance.\nImportantly, DICE is a general, framework-agnostic solution that can be\nintegrated as a plug-in module into existing agentic frameworks without any\nadditional training cost. Extensive experiments across diverse domains\ndemonstrate our method's effectiveness and generality, highlighting the\nimportance of principled, context-aware demo selection for robust and efficient\nLLM agents.",
      "pdf_url": "http://arxiv.org/pdf/2507.23554v1",
      "published": "2025-07-31T13:42:14+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.23554v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "ART: Adaptive Relation Tuning for Generalized Relation Prediction",
      "authors": [
        "Gopika Sudhakaran",
        "Hikaru Shindo",
        "Patrick Schramowski",
        "Simone Schaub-Meyer",
        "Kristian Kersting",
        "Stefan Roth"
      ],
      "abstract": "Visual relation detection (VRD) is the task of identifying the relationships\nbetween objects in a scene. VRD models trained solely on relation detection\ndata struggle to generalize beyond the relations on which they are trained.\nWhile prompt tuning has been used to adapt vision-language models (VLMs) for\nVRD, it uses handcrafted prompts and struggles with novel or complex relations.\nWe argue that instruction tuning offers a more effective solution by\nfine-tuning VLMs on diverse instructional data. We thus introduce ART, an\nAdaptive Relation Tuning framework that adapts VLMs for VRD through instruction\ntuning and strategic instance selection. By converting VRD datasets into an\ninstruction tuning format and employing an adaptive sampling algorithm, ART\ndirects the VLM to focus on informative relations while maintaining\ngeneralizability. Specifically, we focus on the relation classification, where\nsubject-object boxes are given and the model predicts the predicate between\nthem. We tune on a held-in set and evaluate across multiple held-out datasets\nof varying complexity. Our approach strongly improves over its baselines and\ncan infer unseen relation concepts, a capability absent in mainstream VRD\nmethods. We demonstrate ART's practical value by using the predicted relations\nfor segmenting complex scenes.",
      "pdf_url": "http://arxiv.org/pdf/2507.23543v1",
      "published": "2025-07-31T13:34:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.23543v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "A Unified Perception-Language-Action Framework for Adaptive Autonomous Driving",
      "authors": [
        "Yi Zhang",
        "Erik Leo Haß",
        "Kuo-Yi Chao",
        "Nenad Petrovic",
        "Yinglei Song",
        "Chengdong Wu",
        "Alois Knoll"
      ],
      "abstract": "Autonomous driving systems face significant challenges in achieving\nhuman-like adaptability, robustness, and interpretability in complex,\nopen-world environments. These challenges stem from fragmented architectures,\nlimited generalization to novel scenarios, and insufficient semantic extraction\nfrom perception. To address these limitations, we propose a unified\nPerception-Language-Action (PLA) framework that integrates multi-sensor fusion\n(cameras, LiDAR, radar) with a large language model (LLM)-augmented\nVision-Language-Action (VLA) architecture, specifically a GPT-4.1-powered\nreasoning core. This framework unifies low-level sensory processing with\nhigh-level contextual reasoning, tightly coupling perception with natural\nlanguage-based semantic understanding and decision-making to enable\ncontext-aware, explainable, and safety-bounded autonomous driving. Evaluations\non an urban intersection scenario with a construction zone demonstrate superior\nperformance in trajectory tracking, speed prediction, and adaptive planning.\nThe results highlight the potential of language-augmented cognitive frameworks\nfor advancing the safety, interpretability, and scalability of autonomous\ndriving systems.",
      "pdf_url": "http://arxiv.org/pdf/2507.23540v1",
      "published": "2025-07-31T13:30:47+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.23540v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "From LLMs to Edge: Parameter-Efficient Fine-Tuning on Edge Devices",
      "authors": [
        "Georg Slamanig",
        "Francesco Corti",
        "Olga Saukh"
      ],
      "abstract": "Parameter-efficient fine-tuning (PEFT) methods reduce the computational costs\nof updating deep learning models by minimizing the number of additional\nparameters used to adapt a model to a down- stream task. While extensively\nresearched in large language models (LLMs), their application to smaller models\nused on edge devices, such as convolutional neural networks, remains\nunderexplored. This paper benchmarks and analyzes popular PEFT methods on\nconvolutional architectures typically deployed in resource-constrained edge\nenvironments. We evaluate LoRA, DoRA, and GaLore for updating standard and\ndepthwise convolutional architectures to handle distribution shifts and\naccommodate unseen classes. We utilize recently proposed PyTorch profilers to\ncompare the updated model performance and computational costs of these PEFT\nmethods with traditional fine-tuning approaches. With resource efficiency in\nmind, we investigate their update behavior across different rank dimensions. We\nfind that the evaluated PEFT methods are only half as memory-efficient when\napplied to depthwise-separable convolution architectures, compared to their\nefficiency with LLMs. Conversely, when targeting convolu- tional architectures\noptimized for edge deployment, adapter-based PEFT methods can reduce floating\npoint operations (FLOPs) during model updates by up to 95%. These insights\noffer valuable guidance for selecting PEFT methods based on hardware\nconstraints, performance requirements, and application needs. Our code is\nonline.",
      "pdf_url": "http://arxiv.org/pdf/2507.23536v1",
      "published": "2025-07-31T13:23:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.23536v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Transparent AI: The Case for Interpretability and Explainability",
      "authors": [
        "Dhanesh Ramachandram",
        "Himanshu Joshi",
        "Judy Zhu",
        "Dhari Gandhi",
        "Lucas Hartman",
        "Ananya Raval"
      ],
      "abstract": "As artificial intelligence systems increasingly inform high-stakes decisions\nacross sectors, transparency has become foundational to responsible and\ntrustworthy AI implementation. Leveraging our role as a leading institute in\nadvancing AI research and enabling industry adoption, we present key insights\nand lessons learned from practical interpretability applications across diverse\ndomains. This paper offers actionable strategies and implementation guidance\ntailored to organizations at varying stages of AI maturity, emphasizing the\nintegration of interpretability as a core design principle rather than a\nretrospective add-on.",
      "pdf_url": "http://arxiv.org/pdf/2507.23535v1",
      "published": "2025-07-31T13:22:14+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.23535v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ]
    },
    {
      "title": "MECAT: A Multi-Experts Constructed Benchmark for Fine-Grained Audio Understanding Tasks",
      "authors": [
        "Yadong Niu",
        "Tianzi Wang",
        "Heinrich Dinkel",
        "Xingwei Sun",
        "Jiahao Zhou",
        "Gang Li",
        "Jizhong Liu",
        "Xunying Liu",
        "Junbo Zhang",
        "Jian Luan"
      ],
      "abstract": "While large audio-language models have advanced open-ended audio\nunderstanding, they still fall short of nuanced human-level comprehension. This\ngap persists largely because current benchmarks, limited by data annotations\nand evaluation metrics, fail to reliably distinguish between generic and highly\ndetailed model outputs. To this end, this work introduces MECAT, a Multi-Expert\nConstructed Benchmark for Fine-Grained Audio Understanding Tasks. Generated via\na pipeline that integrates analysis from specialized expert models with\nChain-of-Thought large language model reasoning, MECAT provides\nmulti-perspective, fine-grained captions and open-set question-answering pairs.\nThe benchmark is complemented by a novel metric: DATE (Discriminative-Enhanced\nAudio Text Evaluation). This metric penalizes generic terms and rewards\ndetailed descriptions by combining single-sample semantic similarity with\ncross-sample discriminability. A comprehensive evaluation of state-of-the-art\naudio models is also presented, providing new insights into their current\ncapabilities and limitations. The data and code are available at\nhttps://github.com/xiaomi-research/mecat",
      "pdf_url": "http://arxiv.org/pdf/2507.23511v1",
      "published": "2025-07-31T12:47:43+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.23511v1",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.SD"
      ]
    },
    {
      "title": "I Am Big, You Are Little; I Am Right, You Are Wrong",
      "authors": [
        "David A. Kelly",
        "Akchunya Chanchal",
        "Nathan Blake"
      ],
      "abstract": "Machine learning for image classification is an active and rapidly developing\nfield. With the proliferation of classifiers of different sizes and different\narchitectures, the problem of choosing the right model becomes more and more\nimportant.\n  While we can assess a model's classification accuracy statistically, our\nunderstanding of the way these models work is unfortunately limited. In order\nto gain insight into the decision-making process of different vision models, we\npropose using minimal sufficient pixels sets to gauge a model's\n`concentration': the pixels that capture the essence of an image through the\nlens of the model. By comparing position, overlap, and size of sets of pixels,\nwe identify that different architectures have statistically different\nconcentration, in both size and position. In particular, ConvNext and EVA\nmodels differ markedly from the others. We also identify that images which are\nmisclassified are associated with larger pixels sets than correct\nclassifications.",
      "pdf_url": "http://arxiv.org/pdf/2507.23509v1",
      "published": "2025-07-31T12:45:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.23509v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Causal Identification of Sufficient, Contrastive and Complete Feature Sets in Image Classification",
      "authors": [
        "David A Kelly",
        "Hana Chockler"
      ],
      "abstract": "Existing algorithms for explaining the outputs of image classifiers are based\non a variety of approaches and produce explanations that lack formal rigor. On\nthe other hand, logic-based explanations are formally and rigorously defined\nbut their computability relies on strict assumptions about the model that do\nnot hold on image classifiers.\n  In this paper, we show that causal explanations, in addition to being\nformally and rigorously defined, enjoy the same formal properties as\nlogic-based ones, while still lending themselves to black-box algorithms and\nbeing a natural fit for image classifiers. We prove formal properties of causal\nexplanations and introduce contrastive causal explanations for image\nclassifiers. Moreover, we augment the definition of explanation with confidence\nawareness and introduce complete causal explanations: explanations that are\nclassified with exactly the same confidence as the original image.\n  We implement our definitions, and our experimental results demonstrate that\ndifferent models have different patterns of sufficiency, contrastiveness, and\ncompleteness. Our algorithms are efficiently computable, taking on average 6s\nper image on a ResNet50 model to compute all types of explanations, and are\ntotally black-box, needing no knowledge of the model, no access to model\ninternals, no access to gradient, nor requiring any properties, such as\nmonotonicity, of the model.",
      "pdf_url": "http://arxiv.org/pdf/2507.23497v1",
      "published": "2025-07-31T12:33:00+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.23497v1",
      "categories": [
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Digital literacy interventions can boost humans in discerning deepfakes",
      "authors": [
        "Dominique Geissler",
        "Claire Robertson",
        "Stefan Feuerriegel"
      ],
      "abstract": "Deepfakes, i.e., images generated by artificial intelligence (AI), can erode\ntrust in institutions and compromise election outcomes, as people often\nstruggle to discern real images from deepfakes. Improving digital literacy can\nhelp address these challenges, yet scalable and effective approaches remain\nlargely unexplored. Here, we compare the efficacy of five digital literacy\ninterventions to boost people's ability to discern deepfakes: (1) textual\nguidance on common indicators of deepfakes; (2) visual demonstrations of these\nindicators; (3) a gamified exercise for identifying deepfakes; (4) implicit\nlearning through repeated exposure and feedback; and (5) explanations of how\ndeepfakes are generated with the help of AI. We conducted an experiment with\nN=1,200 participants from the United States to test the immediate and long-term\neffectiveness of our interventions. Our results show that our interventions can\nboost deepfake discernment by up to 13 percentage points while maintaining\ntrust in real images. Altogether, our approach is scalable, suitable for\ndiverse populations, and highly effective for boosting deepfake detection while\nmaintaining trust in truthful information.",
      "pdf_url": "http://arxiv.org/pdf/2507.23492v1",
      "published": "2025-07-31T12:23:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.23492v1",
      "categories": [
        "cs.HC",
        "cs.AI"
      ]
    },
    {
      "title": "Causal Reasoning in Pieces: Modular In-Context Learning for Causal Discovery",
      "authors": [
        "Kacper Kadziolka",
        "Saber Salehkaleybar"
      ],
      "abstract": "Causal inference remains a fundamental challenge for large language models.\nRecent advances in internal reasoning with large language models have sparked\ninterest in whether state-of-the-art reasoning models can robustly perform\ncausal discovery-a task where conventional models often suffer from severe\noverfitting and near-random performance under data perturbations. We study\ncausal discovery on the Corr2Cause benchmark using the emergent OpenAI's\no-series and DeepSeek-R model families and find that these reasoning-first\narchitectures achieve significantly greater native gains than prior approaches.\nTo capitalize on these strengths, we introduce a modular in-context pipeline\ninspired by the Tree-of-Thoughts and Chain-of-Thoughts methodologies, yielding\nnearly three-fold improvements over conventional baselines. We further probe\nthe pipeline's impact by analyzing reasoning chain length, complexity, and\nconducting qualitative and quantitative comparisons between conventional and\nreasoning models. Our findings suggest that while advanced reasoning models\nrepresent a substantial leap forward, carefully structured in-context\nframeworks are essential to maximize their capabilities and offer a\ngeneralizable blueprint for causal discovery across diverse domains.",
      "pdf_url": "http://arxiv.org/pdf/2507.23488v1",
      "published": "2025-07-31T12:10:27+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.23488v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Automated Feedback on Student-Generated UML and ER Diagrams Using Large Language Models",
      "authors": [
        "Sebastian Gürtl",
        "Gloria Schimetta",
        "David Kerschbaumer",
        "Michael Liut",
        "Alexander Steinmaurer"
      ],
      "abstract": "UML and ER diagrams are foundational in computer science education but come\nwith challenges for learners due to the need for abstract thinking, contextual\nunderstanding, and mastery of both syntax and semantics. These complexities are\ndifficult to address through traditional teaching methods, which often struggle\nto provide scalable, personalized feedback, especially in large classes. We\nintroduce DUET (Diagrammatic UML & ER Tutor), a prototype of an LLM-based tool,\nwhich converts a reference diagram and a student-submitted diagram into a\ntextual representation and provides structured feedback based on the\ndifferences. It uses a multi-stage LLM pipeline to compare diagrams and\ngenerate reflective feedback. Furthermore, the tool enables analytical insights\nfor educators, aiming to foster self-directed learning and inform instructional\nstrategies. We evaluated DUET through semi-structured interviews with six\nparticipants, including two educators and four teaching assistants. They\nidentified strengths such as accessibility, scalability, and learning support\nalongside limitations, including reliability and potential misuse. Participants\nalso suggested potential improvements, such as bulk upload functionality and\ninteractive clarification features. DUET presents a promising direction for\nintegrating LLMs into modeling education and offers a foundation for future\nclassroom integration and empirical evaluation.",
      "pdf_url": "http://arxiv.org/pdf/2507.23470v1",
      "published": "2025-07-31T11:49:01+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.23470v1",
      "categories": [
        "cs.HC",
        "cs.AI"
      ]
    },
    {
      "title": "Role-Aware Language Models for Secure and Contextualized Access Control in Organizations",
      "authors": [
        "Saeed Almheiri",
        "Yerulan Kongrat",
        "Adrian Santosh",
        "Ruslan Tasmukhanov",
        "Josemaria Vera",
        "Muhammad Dehan Al Kautsar",
        "Fajri Koto"
      ],
      "abstract": "As large language models (LLMs) are increasingly deployed in enterprise\nsettings, controlling model behavior based on user roles becomes an essential\nrequirement. Existing safety methods typically assume uniform access and focus\non preventing harmful or toxic outputs, without addressing role-specific access\nconstraints. In this work, we investigate whether LLMs can be fine-tuned to\ngenerate responses that reflect the access privileges associated with different\norganizational roles. We explore three modeling strategies: a BERT-based\nclassifier, an LLM-based classifier, and role-conditioned generation. To\nevaluate these approaches, we construct two complementary datasets. The first\nis adapted from existing instruction-tuning corpora through clustering and role\nlabeling, while the second is synthetically generated to reflect realistic,\nrole-sensitive enterprise scenarios. We assess model performance across varying\norganizational structures and analyze robustness to prompt injection, role\nmismatch, and jailbreak attempts.",
      "pdf_url": "http://arxiv.org/pdf/2507.23465v1",
      "published": "2025-07-31T11:41:04+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.23465v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Mitigating Resolution-Drift in Federated Learning: Case of Keypoint Detection",
      "authors": [
        "Taeheon Lim",
        "Joohyung Lee",
        "Kyungjae Lee",
        "Jungchan Cho"
      ],
      "abstract": "The Federated Learning (FL) approach enables effective learning across\ndistributed systems, while preserving user data privacy. To date, research has\nprimarily focused on addressing statistical heterogeneity and communication\nefficiency, through which FL has achieved success in classification tasks.\nHowever, its application to non-classification tasks, such as human pose\nestimation, remains underexplored. This paper identifies and investigates a\ncritical issue termed ``resolution-drift,'' where performance degrades\nsignificantly due to resolution variability across clients. Unlike class-level\nheterogeneity, resolution drift highlights the importance of resolution as\nanother axis of not independent or identically distributed (non-IID) data. To\naddress this issue, we present resolution-adaptive federated learning (RAF), a\nmethod that leverages heatmap-based knowledge distillation. Through\nmulti-resolution knowledge distillation between higher-resolution outputs\n(teachers) and lower-resolution outputs (students), our approach enhances\nresolution robustness without overfitting. Extensive experiments and\ntheoretical analysis demonstrate that RAF not only effectively mitigates\nresolution drift and achieves significant performance improvements, but also\ncan be integrated seamlessly into existing FL frameworks. Furthermore, although\nthis paper focuses on human pose estimation, our t-SNE analysis reveals\ndistinct characteristics between classification and high-resolution\nrepresentation tasks, supporting the generalizability of RAF to other tasks\nthat rely on preserving spatial detail.",
      "pdf_url": "http://arxiv.org/pdf/2507.23461v1",
      "published": "2025-07-31T11:38:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.23461v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "KLAN: Kuaishou Landing-page Adaptive Navigator",
      "authors": [
        "Fan Li",
        "Chang Meng",
        "Jiaqi Fu",
        "Shuchang Liu",
        "Jiashuo Zhang",
        "Tianke Zhang",
        "Xueliang Wang",
        "Xiaoqiang Feng"
      ],
      "abstract": "Modern online platforms configure multiple pages to accommodate diverse user\nneeds. This multi-page architecture inherently establishes a two-stage\ninteraction paradigm between the user and the platform: (1) Stage I: page\nnavigation, navigating users to a specific page and (2) Stage II: in-page\ninteraction, where users engage with customized content within the specific\npage. While the majority of research has been focusing on the sequential\nrecommendation task that improves users' feedback in Stage II, there has been\nlittle investigation on how to achieve better page navigation in Stage I. To\nfill this gap, we formally define the task of Personalized Landing Page\nModeling (PLPM) into the field of recommender systems: Given a user upon app\nentry, the goal of PLPM is to proactively select the most suitable landing page\nfrom a set of candidates (e.g., functional tabs, content channels, or\naggregation pages) to optimize the short-term PDR metric and the long-term user\nengagement and satisfaction metrics, while adhering to industrial constraints.\nAdditionally, we propose KLAN (Kuaishou Landing-page Adaptive Navigator), a\nhierarchical solution framework designed to provide personalized landing pages\nunder the formulation of PLPM. KLAN comprises three key components: (1)\nKLAN-ISP captures inter-day static page preference; (2) KLAN-IIT captures\nintra-day dynamic interest transitions and (3) KLAN-AM adaptively integrates\nboth components for optimal navigation decisions. Extensive online experiments\nconducted on the Kuaishou platform demonstrate the effectiveness of KLAN,\nobtaining +0.205% and +0.192% improvements on in Daily Active Users (DAU) and\nuser Lifetime (LT). Our KLAN is ultimately deployed on the online platform at\nfull traffic, serving hundreds of millions of users. To promote further\nresearch in this important area, we will release our dataset and code upon\npaper acceptance.",
      "pdf_url": "http://arxiv.org/pdf/2507.23459v1",
      "published": "2025-07-31T11:37:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.23459v1",
      "categories": [
        "cs.IR",
        "cs.AI"
      ]
    },
    {
      "title": "Machine learning and machine learned prediction in chest X-ray images",
      "authors": [
        "Shereiff Garrett",
        "Abhinav Adhikari",
        "Sarina Gautam",
        "DaShawn Marquis Morris",
        "Chandra Mani Adhikari"
      ],
      "abstract": "Machine learning and artificial intelligence are fast-growing fields of\nresearch in which data is used to train algorithms, learn patterns, and make\npredictions. This approach helps to solve seemingly intricate problems with\nsignificant accuracy without explicit programming by recognizing complex\nrelationships in data. Taking an example of 5824 chest X-ray images, we\nimplement two machine learning algorithms, namely, a baseline convolutional\nneural network (CNN) and a DenseNet-121, and present our analysis in making\nmachine-learned predictions in predicting patients with ailments. Both baseline\nCNN and DenseNet-121 perform very well in the binary classification problem\npresented in this work. Gradient-weighted class activation mapping shows that\nDenseNet-121 correctly focuses on essential parts of the input chest X-ray\nimages in its decision-making more than the baseline CNN.",
      "pdf_url": "http://arxiv.org/pdf/2507.23455v1",
      "published": "2025-07-31T11:31:25+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.23455v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Self-Foveate: Enhancing Diversity and Difficulty of Synthesized Instructions from Unsupervised Text via Multi-Level Foveation",
      "authors": [
        "Mingzhe Li",
        "Xin Lu",
        "Yanyan Zhao"
      ],
      "abstract": "Large language models (LLMs) with instruction following capabilities have\ndemonstrated impressive problem-solving abilities. While synthesizing\ninstructional data from unsupervised text has become a common approach for\ntraining such models, conventional methods rely heavily on human effort for\ndata annotation. Although existing automated synthesis paradigms have\nalleviated this constraint, they still exhibit significant limitations in\nensuring adequate diversity and difficulty of synthesized instructions. To\naddress these challenges, we propose Self-Foveate, an innovative LLM-driven\nmethod for instruction synthesis. This approach introduces a\n\"Micro-Scatter-Macro\" multi-level foveation methodology that effectively guides\nthe LLM to deeply excavate fine-grained information embedded in unsupervised\ntext, thereby enhancing both the diversity and difficulty of synthesized\ninstructions. Comprehensive experiments across multiple unsupervised corpora\nand diverse model architectures validate the effectiveness and superiority of\nour proposed method. We publicly release our data and codes:\nhttps://github.com/Mubuky/Self-Foveate",
      "pdf_url": "http://arxiv.org/pdf/2507.23440v1",
      "published": "2025-07-31T11:18:42+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.23440v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Chatting with your ERP: A Recipe",
      "authors": [
        "Jorge Ruiz Gómez",
        "Lidia Andrés Susinos",
        "Jorge Alamo Olivé",
        "Sonia Rey Osorno",
        "Manuel Luis Gonzalez Hernández"
      ],
      "abstract": "This paper presents the design, implementation, and evaluation behind a Large\nLanguage Model (LLM) agent that chats with an industrial production-grade ERP\nsystem. The agent is capable of interpreting natural language queries and\ntranslating them into executable SQL statements, leveraging open-weight LLMs. A\nnovel dual-agent architecture combining reasoning and critique stages was\nproposed to improve query generation reliability.",
      "pdf_url": "http://arxiv.org/pdf/2507.23429v1",
      "published": "2025-07-31T11:09:50+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.23429v1",
      "categories": [
        "cs.AI",
        "cs.DB",
        "cs.ET",
        "cs.HC",
        "cs.MA",
        "68T50, 68P20",
        "I.2.7; H.2.5; H.2.8; H.5.m"
      ]
    },
    {
      "title": "AGA: An adaptive group alignment framework for structured medical cross-modal representation learning",
      "authors": [
        "Wei Li",
        "Xun Gong",
        "Jiao Li",
        "Xiaobin Sun"
      ],
      "abstract": "Learning medical visual representations from paired images and reports is a\npromising direction in representation learning. However, current\nvision-language pretraining methods in the medical domain often simplify\nclinical reports into single entities or fragmented tokens, ignoring their\ninherent structure. In addition, contrastive learning frameworks typically\ndepend on large quantities of hard negative samples, which is impractical for\nsmall-scale medical datasets. To tackle these challenges, we propose Adaptive\nGrouped Alignment (AGA), a new framework that captures structured semantics\nfrom paired medical images and reports. AGA introduces a bidirectional grouping\nmechanism based on a sparse similarity matrix. For each image-report pair, we\ncompute fine-grained similarities between text tokens and image patches. Each\ntoken selects its top-matching patches to form a visual group, and each patch\nselects its most related tokens to form a language group. To enable adaptive\ngrouping, we design two threshold gating modules, called Language Grouped\nThreshold Gate and Vision Grouped Threshold Gate, which learn grouping\nthresholds dynamically. Group representations are computed as weighted averages\nbased on similarity scores. To align each token with its group representation,\nwe introduce an Instance Aware Group Alignment loss that operates within each\nimage-text pair, removing the need for external negatives. Finally, a\nBidirectional Cross-modal Grouped Alignment module is applied to enhance\nfine-grained alignment between visual and linguistic group representations.\nExtensive experiments on public and private datasets show that our method\nachieves strong performance on image-text retrieval and classification tasks\nunder both fine-tuning and zero-shot settings.",
      "pdf_url": "http://arxiv.org/pdf/2507.23402v1",
      "published": "2025-07-31T10:14:49+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.23402v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Causal2Vec: Improving Decoder-only LLMs as Versatile Embedding Models",
      "authors": [
        "Ailiang Lin",
        "Zhuoyun Li",
        "Kotaro Funakoshi"
      ],
      "abstract": "Decoder-only large language models (LLMs) are increasingly used to build\nembedding models that effectively encode the semantic information of natural\nlanguage texts into dense vector representations for various embedding tasks.\nHowever, many existing methods primarily focus on removing the causal attention\nmask in LLMs to enable bidirectional attention, potentially undermining the\nmodel's ability to extract semantic information acquired during pretraining.\nAdditionally, leading unidirectional approaches often rely on extra input text\nto overcome the inherent limitations of causal attention, inevitably increasing\ncomputational costs. In this work, we propose Causal2Vec, a general-purpose\nembedding model tailored to enhance the performance of decoder-only LLMs\nwithout altering their original architectures or introducing significant\ncomputational overhead. Specifically, we first employ a lightweight BERT-style\nmodel to pre-encode the input text into a single Contextual token, which is\nthen prepended to the LLM's input sequence, allowing each token to capture\ncontextualized information even without attending to future tokens.\nFurthermore, to mitigate the recency bias introduced by last-token pooling and\nhelp LLMs better leverage the semantic information encoded in the Contextual\ntoken, we concatenate the last hidden states of Contextual and EOS tokens as\nthe final text embedding. In practice, Causal2Vec achieves state-of-the-art\nperformance on the Massive Text Embeddings Benchmark (MTEB) among models\ntrained solely on publicly available retrieval datasets, while reducing the\nrequired sequence length by up to 85% and inference time by up to 82% compared\nto best-performing methods.",
      "pdf_url": "http://arxiv.org/pdf/2507.23386v1",
      "published": "2025-07-31T10:01:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.23386v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "MPCC: A Novel Benchmark for Multimodal Planning with Complex Constraints in Multimodal Large Language Models",
      "authors": [
        "Yiyan Ji",
        "Haoran Chen",
        "Qiguang Chen",
        "Chengyue Wu",
        "Libo Qin",
        "Wanxiang Che"
      ],
      "abstract": "Multimodal planning capabilities refer to the ability to predict, reason, and\ndesign steps for task execution with multimodal context, which is essential for\ncomplex reasoning and decision-making across multiple steps. However, current\nbenchmarks face two key challenges: (1) they cannot directly assess multimodal\nreal-world planning capabilities, and (2) they lack constraints or implicit\nconstraints across modalities. To address these issues, we introduce Multimodal\nPlanning with Complex Constraints (MPCC), the first benchmark to systematically\nevaluate MLLMs' ability to handle multimodal constraints in planning. To\naddress the first challenge, MPCC focuses on three real-world tasks: Flight\nPlanning, Calendar Planning, and Meeting Planning. To solve the second\nchallenge, we introduce complex constraints (e.g. budget, temporal, and\nspatial) in these tasks, with graded difficulty levels (EASY, MEDIUM, HARD) to\nseparate constraint complexity from search space expansion. Experiments on 13\nadvanced MLLMs reveal significant challenges: closed-source models achieve only\n21.3% feasible plans, while open-source models average below 11%. Additionally,\nwe observe that MLLMs are highly sensitive to constraint complexity and that\ntraditional multimodal prompting strategies fail in multi-constraint scenarios.\nOur work formalizes multimodal constraints in planning, provides a rigorous\nevaluation framework, and highlights the need for advancements in\nconstraint-aware reasoning for real-world MLLM applications.",
      "pdf_url": "http://arxiv.org/pdf/2507.23382v1",
      "published": "2025-07-31T09:59:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.23382v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "I.2.8; I.2.10"
      ]
    },
    {
      "title": "LLM4Rail: An LLM-Augmented Railway Service Consulting Platform",
      "authors": [
        "Zhuo Li",
        "Xianghuai Deng",
        "Chiwei Feng",
        "Hanmeng Li",
        "Shenjie Wang",
        "Haichao Zhang",
        "Teng Jia",
        "Conlin Chen",
        "Louis Linchun Wu",
        "Jia Wang"
      ],
      "abstract": "Large language models (LLMs) have significantly reshaped different walks of\nbusiness. To meet the increasing demands for individualized railway service, we\ndevelop LLM4Rail - a novel LLM-augmented railway service consulting platform.\nEmpowered by LLM, LLM4Rail can provide custom modules for ticketing, railway\nfood & drink recommendations, weather information, and chitchat. In LLM4Rail,\nwe propose the iterative \"Question-Thought-Action-Observation (QTAO)\" prompting\nframework. It meticulously integrates verbal reasoning with task-oriented\nactions, that is, reasoning to guide action selection, to effectively retrieve\nexternal observations relevant to railway operation and service to generate\naccurate responses. To provide personalized onboard dining services, we first\nconstruct the Chinese Railway Food and Drink (CRFD-25) - a publicly accessible\ntakeout dataset tailored for railway services. CRFD-25 covers a wide range of\nsignature dishes categorized by cities, cuisines, age groups, and spiciness\nlevels. We further introduce an LLM-based zero-shot conversational recommender\nfor railway catering. To address the unconstrained nature of open\nrecommendations, the feature similarity-based post-processing step is\nintroduced to ensure all the recommended items are aligned with CRFD-25\ndataset.",
      "pdf_url": "http://arxiv.org/pdf/2507.23377v1",
      "published": "2025-07-31T09:45:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.23377v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Trae Agent: An LLM-based Agent for Software Engineering with Test-time Scaling",
      "authors": [
        "Trae Research Team",
        "Pengfei Gao",
        "Zhao Tian",
        "Xiangxin Meng",
        "Xinchen Wang",
        "Ruida Hu",
        "Yuanan Xiao",
        "Yizhou Liu",
        "Zhao Zhang",
        "Junjie Chen",
        "Cuiyun Gao",
        "Yun Lin",
        "Yingfei Xiong",
        "Chao Peng",
        "Xia Liu"
      ],
      "abstract": "Software issue resolution is a critical challenge in software engineering and\nhas garnered increasing attention in recent years. With the rapid advancement\nof large language models (LLMs), substantial progress has been made in\naddressing real-world software engineering tasks. Recent studies have\nintroduced ensemble reasoning techniques to enhance the performance of\nLLM-based issue resolution. However, existing prompting-based methods still\nface limitations in effectively exploring large ensemble spaces and lack the\ncapacity for repository-level understanding, both of which constrain their\noverall effectiveness. In this paper, we propose Trae Agent, the first\nagent-based ensemble reasoning approach for repository-level issue resolution.\nTrae Agent formulates our goal as an optimal solution search problem and\naddresses two key challenges, i.e., large ensemble spaces and repository-level\nunderstanding, through modular agents for generation, pruning, and selection.\nWe conduct extensive experiments using three leading LLMs on the widely-adopted\nSWE-bench benchmark, comparing Trae Agent against four state-of-the-art\nensemble reasoning techniques. Experimental results demonstrate that Trae Agent\nconsistently achieves superior performance, with an average improvement of\n10.22% over all baselines in terms of Pass@1. Trae Agent has achieved first\nplace on the SWE-bench Verified leaderboard, with a notable Pass@1 score of\n75.20%. We are pleased to release Trae Agent as an open-source project to\nsupport the research community, with all resources available at\nhttps://github.com/bytedance/trae-agent.",
      "pdf_url": "http://arxiv.org/pdf/2507.23370v1",
      "published": "2025-07-31T09:37:22+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.23370v1",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "\"I made this (sort of)\": Negotiating authorship, confronting fraudulence, and exploring new musical spaces with prompt-based AI music generation",
      "authors": [
        "Bob L. T. Sturm"
      ],
      "abstract": "I reflect on my experience creating two music albums centered on\nstate-of-the-art prompt-based AI music generation platforms. The first album\nexplicitly poses the question: What happens when I collide my junk mail with\nthese platforms? The second album is a direct response to the first, and toys\nwith the inability of state-of-the-art prompt-based AI music generation\nplatforms to generate music that is not ``practiced'', ``polished'', and\n``produced''. I seed a large language model (LLM) with information about these\nalbums and have it interview me, which results in the exploration of several\ndeeper questions: To what extent am I the author? Where am I in the resulting\nmusic? How is my musical identity changing as I am faced with machines that are\nin some ways far more talented than I? What new musical spaces does my work\nopen, for me or anyone/thing else? I conclude by reflecting on my reflections,\nas well as LLM-mediated self-reflection as method.",
      "pdf_url": "http://arxiv.org/pdf/2507.23365v1",
      "published": "2025-07-31T09:25:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.23365v1",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS",
        "I.2; J.5"
      ]
    },
    {
      "title": "Text-to-SQL Task-oriented Dialogue Ontology Construction",
      "authors": [
        "Renato Vukovic",
        "Carel van Niekerk",
        "Michael Heck",
        "Benjamin Ruppik",
        "Hsien-Chin Lin",
        "Shutong Feng",
        "Nurul Lubis",
        "Milica Gasic"
      ],
      "abstract": "Large language models (LLMs) are widely used as general-purpose knowledge\nsources, but they rely on parametric knowledge, limiting explainability and\ntrustworthiness. In task-oriented dialogue (TOD) systems, this separation is\nexplicit, using an external database structured by an explicit ontology to\nensure explainability and controllability. However, building such ontologies\nrequires manual labels or supervised training. We introduce TeQoDO: a\nText-to-SQL task-oriented Dialogue Ontology construction method. Here, an LLM\nautonomously builds a TOD ontology from scratch without supervision using its\ninherent SQL programming capabilities combined with dialogue theory provided in\nthe prompt. We show that TeQoDO outperforms transfer learning approaches, and\nits constructed ontology is competitive on a downstream dialogue state tracking\ntask. Ablation studies demonstrate the key role of dialogue theory. TeQoDO also\nscales to allow construction of much larger ontologies, which we investigate on\na Wikipedia and ArXiv dataset. We view this as a step towards broader\napplication of ontologies to increase LLM explainability.",
      "pdf_url": "http://arxiv.org/pdf/2507.23358v1",
      "published": "2025-07-31T09:08:59+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.23358v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DB",
        "cs.IR"
      ]
    },
    {
      "title": "Quality Evaluation of COBOL to Java Code Transformation",
      "authors": [
        "Shmulik Froimovich",
        "Raviv Gal",
        "Wesam Ibraheem",
        "Avi Ziv"
      ],
      "abstract": "We present an automated evaluation system for assessing COBOL-to-Java code\ntranslation within IBM's watsonx Code Assistant for Z (WCA4Z). The system\naddresses key challenges in evaluating LLM-based translators, including model\nopacity and the complexity of translation quality assessment. Our approach\ncombines analytic checkers with LLM-as-a-judge (LaaJ) techniques to deliver\nscalable, multi-faceted evaluations. The system supports continuous integration\nworkflows, enables large-scale benchmarking, and reduces reliance on manual\nreview. We describe the system architecture, evaluation strategies, and\nreporting mechanisms that provide actionable insights for developers and\nproject managers, facilitating the evolution of high-quality, modernized\ncodebases.",
      "pdf_url": "http://arxiv.org/pdf/2507.23356v1",
      "published": "2025-07-31T09:06:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.23356v1",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "Multi-Waypoint Path Planning and Motion Control for Non-holonomic Mobile Robots in Agricultural Applications",
      "authors": [
        "Mahmoud Ghorab",
        "Matthias Lorenzen"
      ],
      "abstract": "There is a growing demand for autonomous mobile robots capable of navigating\nunstructured agricultural environments. Tasks such as weed control in meadows\nrequire efficient path planning through an unordered set of coordinates while\nminimizing travel distance and adhering to curvature constraints to prevent\nsoil damage and protect vegetation. This paper presents an integrated\nnavigation framework combining a global path planner based on the Dubins\nTraveling Salesman Problem (DTSP) with a Nonlinear Model Predictive Control\n(NMPC) strategy for local path planning and control. The DTSP generates a\nminimum-length, curvature-constrained path that efficiently visits all targets,\nwhile the NMPC leverages this path to compute control signals to accurately\nreach each waypoint. The system's performance was validated through comparative\nsimulation analysis on real-world field datasets, demonstrating that the\ncoupled DTSP-based planner produced smoother and shorter paths, with a\nreduction of about 16% in the provided scenario, compared to decoupled methods.\nBased thereon, the NMPC controller effectively steered the robot to the desired\nwaypoints, while locally optimizing the trajectory and ensuring adherence to\nconstraints. These findings demonstrate the potential of the proposed framework\nfor efficient autonomous navigation in agricultural environments.",
      "pdf_url": "http://arxiv.org/pdf/2507.23350v1",
      "published": "2025-07-31T08:56:24+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.23350v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ]
    },
    {
      "title": "DSBC : Data Science task Benchmarking with Context engineering",
      "authors": [
        "Ram Mohan Rao Kadiyala",
        "Siddhant Gupta",
        "Jebish Purbey",
        "Giulio Martini",
        "Suman Debnath",
        "Hamza Farooq"
      ],
      "abstract": "Recent advances in large language models (LLMs) have significantly impacted\ndata science workflows, giving rise to specialized data science agents designed\nto automate analytical tasks. Despite rapid adoption, systematic benchmarks\nevaluating the efficacy and limitations of these agents remain scarce. In this\npaper, we introduce a comprehensive benchmark specifically crafted to reflect\nreal-world user interactions with data science agents by observing usage of our\ncommercial applications. We evaluate three LLMs: Claude-4.0-Sonnet,\nGemini-2.5-Flash, and OpenAI-o4-Mini across three approaches: zero-shot with\ncontext engineering, multi-step with context engineering, and with SmolAgent.\nOur benchmark assesses performance across a diverse set of eight data science\ntask categories, additionally exploring the sensitivity of models to common\nprompting issues, such as data leakage and slightly ambiguous instructions. We\nfurther investigate the influence of temperature parameters on overall and\ntask-specific outcomes for each model and approach. Our findings reveal\ndistinct performance disparities among the evaluated models and methodologies,\nhighlighting critical factors that affect practical deployment. The benchmark\ndataset and evaluation framework introduced herein aim to provide a foundation\nfor future research of more robust and effective data science agents.",
      "pdf_url": "http://arxiv.org/pdf/2507.23336v1",
      "published": "2025-07-31T08:32:37+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.23336v1",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.MA"
      ]
    }
  ]
}