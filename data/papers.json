{
  "last_updated": "2025-04-07T00:50:39.459032",
  "papers": [
    {
      "title": "Concept Lancet: Image Editing with Compositional Representation Transplant",
      "authors": [
        "Jinqi Luo",
        "Tianjiao Ding",
        "Kwan Ho Ryan Chan",
        "Hancheng Min",
        "Chris Callison-Burch",
        "Ren√© Vidal"
      ],
      "abstract": "Diffusion models are widely used for image editing tasks. Existing editing\nmethods often design a representation manipulation procedure by curating an\nedit direction in the text embedding or score space. However, such a procedure\nfaces a key challenge: overestimating the edit strength harms visual\nconsistency while underestimating it fails the editing task. Notably, each\nsource image may require a different editing strength, and it is costly to\nsearch for an appropriate strength via trial-and-error. To address this\nchallenge, we propose Concept Lancet (CoLan), a zero-shot plug-and-play\nframework for principled representation manipulation in diffusion-based image\nediting. At inference time, we decompose the source input in the latent (text\nembedding or diffusion score) space as a sparse linear combination of the\nrepresentations of the collected visual concepts. This allows us to accurately\nestimate the presence of concepts in each image, which informs the edit. Based\non the editing task (replace/add/remove), we perform a customized concept\ntransplant process to impose the corresponding editing direction. To\nsufficiently model the concept space, we curate a conceptual representation\ndataset, CoLan-150K, which contains diverse descriptions and scenarios of\nvisual terms and phrases for the latent dictionary. Experiments on multiple\ndiffusion-based image editing baselines show that methods equipped with CoLan\nachieve state-of-the-art performance in editing effectiveness and consistency\npreservation.",
      "pdf_url": "http://arxiv.org/pdf/2504.02828v1",
      "published": "2025-04-03T17:59:58+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.02828v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "On Vanishing Variance in Transformer Length Generalization",
      "authors": [
        "Ruining Li",
        "Gabrijel Boduljak",
        "Jensen",
        "Zhou"
      ],
      "abstract": "It is a widely known issue that Transformers, when trained on shorter\nsequences, fail to generalize robustly to longer ones at test time. This raises\nthe question of whether Transformer models are real reasoning engines, despite\ntheir impressive abilities in mathematical problem solving and code synthesis.\nIn this paper, we offer a vanishing variance perspective on this issue. To the\nbest of our knowledge, we are the first to demonstrate that even for today's\nfrontier models, a longer sequence length results in a decrease in variance in\nthe output of the multi-head attention modules. On the argmax retrieval and\ndictionary lookup tasks, our experiments show that applying layer normalization\nafter the attention outputs leads to significantly better length\ngeneralization. Our analyses attribute this improvement to a reduction-though\nnot a complete elimination-of the distribution shift caused by vanishing\nvariance.",
      "pdf_url": "http://arxiv.org/pdf/2504.02827v1",
      "published": "2025-04-03T17:59:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.02827v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Do Two AI Scientists Agree?",
      "authors": [
        "Xinghong Fu",
        "Ziming Liu",
        "Max Tegmark"
      ],
      "abstract": "When two AI models are trained on the same scientific task, do they learn the\nsame theory or two different theories? Throughout history of science, we have\nwitnessed the rise and fall of theories driven by experimental validation or\nfalsification: many theories may co-exist when experimental data is lacking,\nbut the space of survived theories become more constrained with more\nexperimental data becoming available. We show the same story is true for AI\nscientists. With increasingly more systems provided in training data, AI\nscientists tend to converge in the theories they learned, although sometimes\nthey form distinct groups corresponding to different theories. To\nmechanistically interpret what theories AI scientists learn and quantify their\nagreement, we propose MASS, Hamiltonian-Lagrangian neural networks as AI\nScientists, trained on standard problems in physics, aggregating training\nresults across many seeds simulating the different configurations of AI\nscientists. Our findings suggests for AI scientists switch from learning a\nHamiltonian theory in simple setups to a Lagrangian formulation when more\ncomplex systems are introduced. We also observe strong seed dependence of the\ntraining dynamics and final learned weights, controlling the rise and fall of\nrelevant theories. We finally demonstrate that not only can our neural networks\naid interpretability, it can also be applied to higher dimensional problems.",
      "pdf_url": "http://arxiv.org/pdf/2504.02822v1",
      "published": "2025-04-03T17:58:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.02822v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Sparse Autoencoders Learn Monosemantic Features in Vision-Language Models",
      "authors": [
        "Mateusz Pach",
        "Shyamgopal Karthik",
        "Quentin Bouniot",
        "Serge Belongie",
        "Zeynep Akata"
      ],
      "abstract": "Sparse Autoencoders (SAEs) have recently been shown to enhance\ninterpretability and steerability in Large Language Models (LLMs). In this\nwork, we extend the application of SAEs to Vision-Language Models (VLMs), such\nas CLIP, and introduce a comprehensive framework for evaluating monosemanticity\nin vision representations. Our experimental results reveal that SAEs trained on\nVLMs significantly enhance the monosemanticity of individual neurons while also\nexhibiting hierarchical representations that align well with expert-defined\nstructures (e.g., iNaturalist taxonomy). Most notably, we demonstrate that\napplying SAEs to intervene on a CLIP vision encoder, directly steer output from\nmultimodal LLMs (e.g., LLaVA) without any modifications to the underlying\nmodel. These findings emphasize the practicality and efficacy of SAEs as an\nunsupervised approach for enhancing both the interpretability and control of\nVLMs.",
      "pdf_url": "http://arxiv.org/pdf/2504.02821v1",
      "published": "2025-04-03T17:58:35+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.02821v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "GMR-Conv: An Efficient Rotation and Reflection Equivariant Convolution Kernel Using Gaussian Mixture Rings",
      "authors": [
        "Yuexi Du",
        "Jiazhen Zhang",
        "Nicha C. Dvornek",
        "John A. Onofrey"
      ],
      "abstract": "Symmetry, where certain features remain invariant under geometric\ntransformations, can often serve as a powerful prior in designing convolutional\nneural networks (CNNs). While conventional CNNs inherently support\ntranslational equivariance, extending this property to rotation and reflection\nhas proven challenging, often forcing a compromise between equivariance,\nefficiency, and information loss. In this work, we introduce Gaussian Mixture\nRing Convolution (GMR-Conv), an efficient convolution kernel that smooths\nradial symmetry using a mixture of Gaussian-weighted rings. This design\nmitigates discretization errors of circular kernels, thereby preserving robust\nrotation and reflection equivariance without incurring computational overhead.\nWe further optimize both the space and speed efficiency of GMR-Conv via a novel\nparameterization and computation strategy, allowing larger kernels at an\nacceptable cost. Extensive experiments on eight classification and one\nsegmentation datasets demonstrate that GMR-Conv not only matches conventional\nCNNs' performance but can also surpass it in applications with orientation-less\ndata. GMR-Conv is also proven to be more robust and efficient than the\nstate-of-the-art equivariant learning methods. Our work provides inspiring\nempirical evidence that carefully applied radial symmetry can alleviate the\nchallenges of information loss, marking a promising advance in equivariant\nnetwork architectures. The code is available at\nhttps://github.com/XYPB/GMR-Conv.",
      "pdf_url": "http://arxiv.org/pdf/2504.02819v1",
      "published": "2025-04-03T17:58:18+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.02819v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV",
        "eess.SP"
      ]
    },
    {
      "title": "Generative Evaluation of Complex Reasoning in Large Language Models",
      "authors": [
        "Haowei Lin",
        "Xiangyu Wang",
        "Ruilin Yan",
        "Baizhou Huang",
        "Haotian Ye",
        "Jianhua Zhu",
        "Zihao Wang",
        "James Zou",
        "Jianzhu Ma",
        "Yitao Liang"
      ],
      "abstract": "With powerful large language models (LLMs) demonstrating superhuman reasoning\ncapabilities, a critical question arises: Do LLMs genuinely reason, or do they\nmerely recall answers from their extensive, web-scraped training datasets?\nPublicly released benchmarks inevitably become contaminated once incorporated\ninto subsequent LLM training sets, undermining their reliability as faithful\nassessments. To address this, we introduce KUMO, a generative evaluation\nframework designed specifically for assessing reasoning in LLMs. KUMO\nsynergistically combines LLMs with symbolic engines to dynamically produce\ndiverse, multi-turn reasoning tasks that are partially observable and\nadjustable in difficulty. Through an automated pipeline, KUMO continuously\ngenerates novel tasks across open-ended domains, compelling models to\ndemonstrate genuine generalization rather than memorization. We evaluated 23\nstate-of-the-art LLMs on 5,000 tasks across 100 domains created by KUMO,\nbenchmarking their reasoning abilities against university students. Our\nfindings reveal that many LLMs have outperformed university-level performance\non easy reasoning tasks, and reasoning-scaled LLMs reach university-level\nperformance on complex reasoning challenges. Moreover, LLM performance on KUMO\ntasks correlates strongly with results on newly released real-world reasoning\nbenchmarks, underscoring KUMO's value as a robust, enduring assessment tool for\ngenuine LLM reasoning capabilities.",
      "pdf_url": "http://arxiv.org/pdf/2504.02810v1",
      "published": "2025-04-03T17:54:18+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.02810v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "MegaMath: Pushing the Limits of Open Math Corpora",
      "authors": [
        "Fan Zhou",
        "Zengzhi Wang",
        "Nikhil Ranjan",
        "Zhoujun Cheng",
        "Liping Tang",
        "Guowei He",
        "Zhengzhong Liu",
        "Eric P. Xing"
      ],
      "abstract": "Mathematical reasoning is a cornerstone of human intelligence and a key\nbenchmark for advanced capabilities in large language models (LLMs). However,\nthe research community still lacks an open, large-scale, high-quality corpus\ntailored to the demands of math-centric LLM pre-training. We present MegaMath,\nan open dataset curated from diverse, math-focused sources through following\npractices: (1) Revisiting web data: We re-extracted mathematical documents from\nCommon Crawl with math-oriented HTML optimizations, fasttext-based filtering\nand deduplication, all for acquiring higher-quality data on the Internet. (2)\nRecalling Math-related code data: We identified high quality math-related code\nfrom large code training corpus, Stack-V2, further enhancing data diversity.\n(3) Exploring Synthetic data: We synthesized QA-style text, math-related code,\nand interleaved text-code blocks from web data or code data. By integrating\nthese strategies and validating their effectiveness through extensive\nablations, MegaMath delivers 371B tokens with the largest quantity and top\nquality among existing open math pre-training datasets.",
      "pdf_url": "http://arxiv.org/pdf/2504.02807v1",
      "published": "2025-04-03T17:52:07+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.02807v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Systematic Evaluation of Large Vision-Language Models for Surgical Artificial Intelligence",
      "authors": [
        "Anita Rau",
        "Mark Endo",
        "Josiah Aklilu",
        "Jaewoo Heo",
        "Khaled Saab",
        "Alberto Paderno",
        "Jeffrey Jopling",
        "F. Christopher Holsinger",
        "Serena Yeung-Levy"
      ],
      "abstract": "Large Vision-Language Models offer a new paradigm for AI-driven image\nunderstanding, enabling models to perform tasks without task-specific training.\nThis flexibility holds particular promise across medicine, where\nexpert-annotated data is scarce. Yet, VLMs' practical utility in\nintervention-focused domains--especially surgery, where decision-making is\nsubjective and clinical scenarios are variable--remains uncertain. Here, we\npresent a comprehensive analysis of 11 state-of-the-art VLMs across 17 key\nvisual understanding tasks in surgical AI--from anatomy recognition to skill\nassessment--using 13 datasets spanning laparoscopic, robotic, and open\nprocedures. In our experiments, VLMs demonstrate promising generalizability, at\ntimes outperforming supervised models when deployed outside their training\nsetting. In-context learning, incorporating examples during testing, boosted\nperformance up to three-fold, suggesting adaptability as a key strength. Still,\ntasks requiring spatial or temporal reasoning remained difficult. Beyond\nsurgery, our findings offer insights into VLMs' potential for tackling complex\nand dynamic scenarios in clinical and broader real-world applications.",
      "pdf_url": "http://arxiv.org/pdf/2504.02799v1",
      "published": "2025-04-03T17:42:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.02799v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "A Framework for Situating Innovations, Opportunities, and Challenges in Advancing Vertical Systems with Large AI Models",
      "authors": [
        "Gaurav Verma",
        "Jiawei Zhou",
        "Mohit Chandra",
        "Srijan Kumar",
        "Munmun De Choudhury"
      ],
      "abstract": "Large artificial intelligence (AI) models have garnered significant attention\nfor their remarkable, often \"superhuman\", performance on standardized\nbenchmarks. However, when these models are deployed in high-stakes verticals\nsuch as healthcare, education, and law, they often reveal notable limitations.\nFor instance, they exhibit brittleness to minor variations in input data,\npresent contextually uninformed decisions in critical settings, and undermine\nuser trust by confidently producing or reproducing inaccuracies. These\nchallenges in applying large models necessitate cross-disciplinary innovations\nto align the models' capabilities with the needs of real-world applications. We\nintroduce a framework that addresses this gap through a layer-wise abstraction\nof innovations aimed at meeting users' requirements with large models. Through\nmultiple case studies, we illustrate how researchers and practitioners across\nvarious fields can operationalize this framework. Beyond modularizing the\npipeline of transforming large models into useful \"vertical systems\", we also\nhighlight the dynamism that exists within different layers of the framework.\nFinally, we discuss how our framework can guide researchers and practitioners\nto (i) optimally situate their innovations (e.g., when vertical-specific\ninsights can empower broadly impactful vertical-agnostic innovations), (ii)\nuncover overlooked opportunities (e.g., spotting recurring problems across\nverticals to develop practically useful foundation models instead of chasing\nbenchmarks), and (iii) facilitate cross-disciplinary communication of critical\nchallenges (e.g., enabling a shared vocabulary for AI developers, domain\nexperts, and human-computer interaction scholars).",
      "pdf_url": "http://arxiv.org/pdf/2504.02793v1",
      "published": "2025-04-03T17:40:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.02793v1",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.HC"
      ]
    },
    {
      "title": "Unified World Models: Coupling Video and Action Diffusion for Pretraining on Large Robotic Datasets",
      "authors": [
        "Chuning Zhu",
        "Raymond Yu",
        "Siyuan Feng",
        "Benjamin Burchfiel",
        "Paarth Shah",
        "Abhishek Gupta"
      ],
      "abstract": "Imitation learning has emerged as a promising approach towards building\ngeneralist robots. However, scaling imitation learning for large robot\nfoundation models remains challenging due to its reliance on high-quality\nexpert demonstrations. Meanwhile, large amounts of video data depicting a wide\nrange of environments and diverse behaviors are readily available. This data\nprovides a rich source of information about real-world dynamics and\nagent-environment interactions. Leveraging this data directly for imitation\nlearning, however, has proven difficult due to the lack of action annotation\nrequired for most contemporary methods. In this work, we present Unified World\nModels (UWM), a framework that allows for leveraging both video and action data\nfor policy learning. Specifically, a UWM integrates an action diffusion process\nand a video diffusion process within a unified transformer architecture, where\nindependent diffusion timesteps govern each modality. We show that by simply\ncontrolling each diffusion timestep, UWM can flexibly represent a policy, a\nforward dynamics, an inverse dynamics, and a video generator. Through simulated\nand real-world experiments, we show that: (1) UWM enables effective pretraining\non large-scale multitask robot datasets with both dynamics and action\npredictions, resulting in more generalizable and robust policies than imitation\nlearning, (2) UWM naturally facilitates learning from action-free video data\nthrough independent control of modality-specific diffusion timesteps, further\nimproving the performance of finetuned policies. Our results suggest that UWM\noffers a promising step toward harnessing large, heterogeneous datasets for\nscalable robot learning, and provides a simple unification between the often\ndisparate paradigms of imitation learning and world modeling. Videos and code\nare available at https://weirdlabuw.github.io/uwm/.",
      "pdf_url": "http://arxiv.org/pdf/2504.02792v1",
      "published": "2025-04-03T17:38:59+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.02792v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Towards Green AI-Native Networks: Evaluation of Neural Circuit Policy for Estimating Energy Consumption of Base Stations",
      "authors": [
        "Selim Ickin",
        "Shruti Bothe",
        "Aman Raparia",
        "Nitin Khanna",
        "Erik Sanders"
      ],
      "abstract": "Optimization of radio hardware and AI-based network management software yield\nsignificant energy savings in radio access networks. The execution of\nunderlying Machine Learning (ML) models, which enable energy savings through\nrecommended actions, may require additional compute and energy, highlighting\nthe opportunity to explore and adopt accurate and energy-efficient ML\ntechnologies. This work evaluates the novel use of sparsely structured Neural\nCircuit Policies (NCPs) in a use case to estimate the energy consumption of\nbase stations. Sparsity in ML models yields reduced memory, computation and\nenergy demand, hence facilitating a low-cost and scalable solution. We also\nevaluate the generalization capability of NCPs in comparison to traditional and\nwidely used ML models such as Long Short Term Memory (LSTM), via quantifying\ntheir sensitivity to varying model hyper-parameters (HPs). NCPs demonstrated a\nclear reduction in computational overhead and energy consumption. Moreover,\nresults indicated that the NCPs are robust to varying HPs such as number of\nepochs and neurons in each layer, making them a suitable option to ease model\nmanagement and to reduce energy consumption in Machine Learning Operations\n(MLOps) in telecommunications.",
      "pdf_url": "http://arxiv.org/pdf/2504.02781v1",
      "published": "2025-04-03T17:22:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.02781v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE",
        "eess.SP"
      ]
    },
    {
      "title": "From Consumption to Collaboration: Measuring Interaction Patterns to Augment Human Cognition in Open-Ended Tasks",
      "authors": [
        "Joshua Holstein",
        "Moritz Diener",
        "Philipp Spitzer"
      ],
      "abstract": "The rise of Generative AI, and Large Language Models (LLMs) in particular, is\nfundamentally changing cognitive processes in knowledge work, raising critical\nquestions about their impact on human reasoning and problem-solving\ncapabilities. As these AI systems become increasingly integrated into\nworkflows, they offer unprecedented opportunities for augmenting human thinking\nwhile simultaneously risking cognitive erosion through passive consumption of\ngenerated answers. This tension is particularly pronounced in open-ended tasks,\nwhere effective solutions require deep contextualization and integration of\ndomain knowledge. Unlike structured tasks with established metrics, measuring\nthe quality of human-LLM interaction in such open-ended tasks poses significant\nchallenges due to the absence of ground truth and the iterative nature of\nsolution development. To address this, we present a framework that analyzes\ninteraction patterns along two dimensions: cognitive activity mode (exploration\nvs. exploitation) and cognitive engagement mode (constructive vs. detrimental).\nThis framework provides systematic measurements to evaluate when LLMs are\neffective tools for thought rather than substitutes for human cognition,\nadvancing theoretical understanding and practical guidance for developing AI\nsystems that protect and augment human cognitive capabilities.",
      "pdf_url": "http://arxiv.org/pdf/2504.02780v1",
      "published": "2025-04-03T17:20:36+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.02780v1",
      "categories": [
        "cs.HC",
        "cs.AI"
      ]
    },
    {
      "title": "Multi-Head Adaptive Graph Convolution Network for Sparse Point Cloud-Based Human Activity Recognition",
      "authors": [
        "Vincent Gbouna Zakka",
        "Luis J. Manso",
        "Zhuangzhuang Dai"
      ],
      "abstract": "Human activity recognition is increasingly vital for supporting independent\nliving, particularly for the elderly and those in need of assistance. Domestic\nservice robots with monitoring capabilities can enhance safety and provide\nessential support. Although image-based methods have advanced considerably in\nthe past decade, their adoption remains limited by concerns over privacy and\nsensitivity to low-light or dark conditions. As an alternative, millimetre-wave\n(mmWave) radar can produce point cloud data which is privacy-preserving.\nHowever, processing the sparse and noisy point clouds remains a long-standing\nchallenge. While graph-based methods and attention mechanisms show promise,\nthey predominantly rely on \"fixed\" kernels; kernels that are applied uniformly\nacross all neighbourhoods, highlighting the need for adaptive approaches that\ncan dynamically adjust their kernels to the specific geometry of each local\nneighbourhood in point cloud data. To overcome this limitation, we introduce an\nadaptive approach within the graph convolutional framework. Instead of a single\nshared weight function, our Multi-Head Adaptive Kernel (MAK) module generates\nmultiple dynamic kernels, each capturing different aspects of the local feature\nspace. By progressively refining local features while maintaining global\nspatial context, our method enables convolution kernels to adapt to varying\nlocal features. Experimental results on benchmark datasets confirm the\neffectiveness of our approach, achieving state-of-the-art performance in human\nactivity recognition. Our source code is made publicly available at:\nhttps://github.com/Gbouna/MAK-GCN",
      "pdf_url": "http://arxiv.org/pdf/2504.02778v1",
      "published": "2025-04-03T17:19:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.02778v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "How Deep Do Large Language Models Internalize Scientific Literature and Citation Practices?",
      "authors": [
        "Andres Algaba",
        "Vincent Holst",
        "Floriano Tori",
        "Melika Mobini",
        "Brecht Verbeken",
        "Sylvia Wenmackers",
        "Vincent Ginis"
      ],
      "abstract": "The spread of scientific knowledge depends on how researchers discover and\ncite previous work. The adoption of large language models (LLMs) in the\nscientific research process introduces a new layer to these citation practices.\nHowever, it remains unclear to what extent LLMs align with human citation\npractices, how they perform across domains, and may influence citation\ndynamics. Here, we show that LLMs systematically reinforce the Matthew effect\nin citations by consistently favoring highly cited papers when generating\nreferences. This pattern persists across scientific domains despite significant\nfield-specific variations in existence rates, which refer to the proportion of\ngenerated references that match existing records in external bibliometric\ndatabases. Analyzing 274,951 references generated by GPT-4o for 10,000 papers,\nwe find that LLM recommendations diverge from traditional citation patterns by\npreferring more recent references with shorter titles and fewer authors.\nEmphasizing their content-level relevance, the generated references are\nsemantically aligned with the content of each paper at levels comparable to the\nground truth references and display similar network effects while reducing\nauthor self-citations. These findings illustrate how LLMs may reshape citation\npractices and influence the trajectory of scientific discovery by reflecting\nand amplifying established trends. As LLMs become more integrated into the\nscientific research process, it is important to understand their role in\nshaping how scientific communities discover and build upon prior work.",
      "pdf_url": "http://arxiv.org/pdf/2504.02767v1",
      "published": "2025-04-03T17:04:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.02767v1",
      "categories": [
        "cs.DL",
        "cs.AI",
        "cs.LG",
        "cs.SI"
      ]
    },
    {
      "title": "Scene Splatter: Momentum 3D Scene Generation from Single Image with Video Diffusion Model",
      "authors": [
        "Shengjun Zhang",
        "Jinzhao Li",
        "Xin Fei",
        "Hao Liu",
        "Yueqi Duan"
      ],
      "abstract": "In this paper, we propose Scene Splatter, a momentum-based paradigm for video\ndiffusion to generate generic scenes from single image. Existing methods, which\nemploy video generation models to synthesize novel views, suffer from limited\nvideo length and scene inconsistency, leading to artifacts and distortions\nduring further reconstruction. To address this issue, we construct noisy\nsamples from original features as momentum to enhance video details and\nmaintain scene consistency. However, for latent features with the perception\nfield that spans both known and unknown regions, such latent-level momentum\nrestricts the generative ability of video diffusion in unknown regions.\nTherefore, we further introduce the aforementioned consistent video as a\npixel-level momentum to a directly generated video without momentum for better\nrecovery of unseen regions. Our cascaded momentum enables video diffusion\nmodels to generate both high-fidelity and consistent novel views. We further\nfinetune the global Gaussian representations with enhanced frames and render\nnew frames for momentum update in the next step. In this manner, we can\niteratively recover a 3D scene, avoiding the limitation of video length.\nExtensive experiments demonstrate the generalization capability and superior\nperformance of our method in high-fidelity and consistent scene generation.",
      "pdf_url": "http://arxiv.org/pdf/2504.02764v1",
      "published": "2025-04-03T17:00:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.02764v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "RBT4DNN: Requirements-based Testing of Neural Networks",
      "authors": [
        "Nusrat Jahan Mozumder",
        "Felipe Toledo",
        "Swaroopa Dola",
        "Matthew B. Dwyer"
      ],
      "abstract": "Deep neural network (DNN) testing is crucial for the reliability and safety\nof critical systems, where failures can have severe consequences. Although\nvarious techniques have been developed to create robustness test suites,\nrequirements-based testing for DNNs remains largely unexplored - yet such tests\nare recognized as an essential component of software validation of critical\nsystems. In this work, we propose a requirements-based test suite generation\nmethod that uses structured natural language requirements formulated in a\nsemantic feature space to create test suites by prompting text-conditional\nlatent diffusion models with the requirement precondition and then using the\nassociated postcondition to define a test oracle to judge outputs of the DNN\nunder test. We investigate the approach using fine-tuned variants of\npre-trained generative models. Our experiments on the MNIST, CelebA-HQ,\nImageNet, and autonomous car driving datasets demonstrate that the generated\ntest suites are realistic, diverse, consistent with preconditions, and capable\nof revealing faults.",
      "pdf_url": "http://arxiv.org/pdf/2504.02737v2",
      "published": "2025-04-03T16:24:49+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.02737v2",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Autonomous Human-Robot Interaction via Operator Imitation",
      "authors": [
        "Sammy Christen",
        "David M√ºller",
        "Agon Serifi",
        "Ruben Grandia",
        "Georg Wiedebach",
        "Michael A. Hopkins",
        "Espen Knoop",
        "Moritz B√§cher"
      ],
      "abstract": "Teleoperated robotic characters can perform expressive interactions with\nhumans, relying on the operators' experience and social intuition. In this\nwork, we propose to create autonomous interactive robots, by training a model\nto imitate operator data. Our model is trained on a dataset of human-robot\ninteractions, where an expert operator is asked to vary the interactions and\nmood of the robot, while the operator commands as well as the pose of the human\nand robot are recorded. Our approach learns to predict continuous operator\ncommands through a diffusion process and discrete commands through a\nclassifier, all unified within a single transformer architecture. We evaluate\nthe resulting model in simulation and with a user study on the real system. We\nshow that our method enables simple autonomous human-robot interactions that\nare comparable to the expert-operator baseline, and that users can recognize\nthe different robot moods as generated by our model. Finally, we demonstrate a\nzero-shot transfer of our model onto a different robotic platform with the same\noperator interface.",
      "pdf_url": "http://arxiv.org/pdf/2504.02724v1",
      "published": "2025-04-03T16:06:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.02724v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "Responsible Development of Offensive AI",
      "authors": [
        "Ryan Marinelli"
      ],
      "abstract": "As AI advances, broader consensus is needed to determine research priorities.\nThis endeavor discusses offensive AI and provides guidance by leveraging\nSustainable Development Goals (SDGs) and interpretability techniques. The\nobjective is to more effectively establish priorities that balance societal\nbenefits against risks. The two forms of offensive AI evaluated in this study\nare vulnerability detection agents, which solve Capture- The-Flag challenges,\nand AI-powered malware.",
      "pdf_url": "http://arxiv.org/pdf/2504.02701v1",
      "published": "2025-04-03T15:37:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.02701v1",
      "categories": [
        "cs.AI",
        "cs.MA"
      ]
    },
    {
      "title": "SCMPPI: Supervised Contrastive Multimodal Framework for Predicting Protein-Protein Interactions",
      "authors": [
        "Shengrui XU",
        "Tianchi Lu",
        "Zikun Wang",
        "Jixiu Zhai",
        "Jingwan Wang"
      ],
      "abstract": "Protein-Protein Interaction (PPI) prediction is a key task in uncovering\ncellular functional networks and disease mechanisms. However, traditional\nexperimental methods are time-consuming and costly, and existing computational\nmodels face challenges in cross-modal feature fusion, robustness, and\nfalse-negative suppression. In this paper, we propose a novel supervised\ncontrastive multimodal framework, SCMPPI, for PPI prediction. By integrating\nprotein sequence features (AAC, DPC, CKSAAP-ESMC) with PPI network topology\ninformation (Node2Vec graph embedding), and combining an improved supervised\ncontrastive learning strategy, SCMPPI significantly enhances PPI prediction\nperformance. For the PPI task, SCMPPI introduces a negative sample filtering\nmechanism and modifies the contrastive loss function, effectively optimizing\nmultimodal features. Experiments on eight benchmark datasets, including yeast,\nhuman, and H.pylori, show that SCMPPI outperforms existing state-of-the-art\nmethods (such as DF-PPI and TAGPPI) in key metrics such as accuracy ( 98.01%)\nand AUC (99.62%), and demonstrates strong generalization in cross-species\nprediction (AUC > 99% on multi-species datasets). Furthermore, SCMPPI has been\nsuccessfully applied to CD9 networks, the Wnt pathway, and cancer-specific\nnetworks, providing a reliable tool for disease target discovery. This\nframework also offers a new paradigm for multimodal biological information\nfusion and contrastive learning in collaborative optimization for various\ncombined predictions.",
      "pdf_url": "http://arxiv.org/pdf/2504.02698v1",
      "published": "2025-04-03T15:34:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.02698v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM",
        "92C40, 68T07",
        "I.2.6; J.3"
      ]
    },
    {
      "title": "STOOD-X methodology: using statistical nonparametric test for OOD Detection Large-Scale datasets enhanced with explainability",
      "authors": [
        "Iv√°n Sevillano-Garc√≠a",
        "Juli√°n Luengo",
        "Francisco Herrera"
      ],
      "abstract": "Out-of-Distribution (OOD) detection is a critical task in machine learning,\nparticularly in safety-sensitive applications where model failures can have\nserious consequences. However, current OOD detection methods often suffer from\nrestrictive distributional assumptions, limited scalability, and a lack of\ninterpretability. To address these challenges, we propose STOOD-X, a two-stage\nmethodology that combines a Statistical nonparametric Test for OOD Detection\nwith eXplainability enhancements. In the first stage, STOOD-X uses\nfeature-space distances and a Wilcoxon-Mann-Whitney test to identify OOD\nsamples without assuming a specific feature distribution. In the second stage,\nit generates user-friendly, concept-based visual explanations that reveal the\nfeatures driving each decision, aligning with the BLUE XAI paradigm. Through\nextensive experiments on benchmark datasets and multiple architectures, STOOD-X\nachieves competitive performance against state-of-the-art post hoc OOD\ndetectors, particularly in high-dimensional and complex settings. In addition,\nits explainability framework enables human oversight, bias detection, and model\ndebugging, fostering trust and collaboration between humans and AI systems. The\nSTOOD-X methodology therefore offers a robust, explainable, and scalable\nsolution for real-world OOD detection tasks.",
      "pdf_url": "http://arxiv.org/pdf/2504.02685v1",
      "published": "2025-04-03T15:26:03+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.02685v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.HC",
        "stat.ML"
      ]
    },
    {
      "title": "Affordable AI Assistants with Knowledge Graph of Thoughts",
      "authors": [
        "Maciej Besta",
        "Lorenzo Paleari",
        "Jia Hao Andrea Jiang",
        "Robert Gerstenberger",
        "You Wu",
        "Patrick Iff",
        "Ales Kubicek",
        "Piotr Nyczyk",
        "Diana Khimey",
        "J√≥n Gunnar Hannesson",
        "Grzegorz Kwa≈õniewski",
        "Marcin Copik",
        "Hubert Niewiadomski",
        "Torsten Hoefler"
      ],
      "abstract": "Large Language Models (LLMs) are revolutionizing the development of AI\nassistants capable of performing diverse tasks across domains. However, current\nstate-of-the-art LLM-driven agents face significant challenges, including high\noperational costs and limited success rates on complex benchmarks like GAIA. To\naddress these issues, we propose the Knowledge Graph of Thoughts (KGoT), an\ninnovative AI assistant architecture that integrates LLM reasoning with\ndynamically constructed knowledge graphs (KGs). KGoT extracts and structures\ntask-relevant knowledge into a dynamic KG representation, iteratively enhanced\nthrough external tools such as math solvers, web crawlers, and Python scripts.\nSuch structured representation of task-relevant knowledge enables low-cost\nmodels to solve complex tasks effectively. For example, KGoT achieves a 29%\nimprovement in task success rates on the GAIA benchmark compared to Hugging\nFace Agents with GPT-4o mini, while reducing costs by over 36x compared to\nGPT-4o. Improvements for recent reasoning models are similar, e.g., 36% and\n37.5% for Qwen2.5-32B and Deepseek-R1-70B, respectively. KGoT offers a\nscalable, affordable, and high-performing solution for AI assistants.",
      "pdf_url": "http://arxiv.org/pdf/2504.02670v1",
      "published": "2025-04-03T15:11:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.02670v1",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.IR",
        "cs.LG"
      ]
    },
    {
      "title": "SymDQN: Symbolic Knowledge and Reasoning in Neural Network-based Reinforcement Learning",
      "authors": [
        "Ivo Amador",
        "Nina Gierasimczuk"
      ],
      "abstract": "We propose a learning architecture that allows symbolic control and guidance\nin reinforcement learning with deep neural networks. We introduce SymDQN, a\nnovel modular approach that augments the existing Dueling Deep Q-Networks\n(DuelDQN) architecture with modules based on the neuro-symbolic framework of\nLogic Tensor Networks (LTNs). The modules guide action policy learning and\nallow reinforcement learning agents to display behaviour consistent with\nreasoning about the environment. Our experiment is an ablation study performed\non the modules. It is conducted in a reinforcement learning environment of a\n5x5 grid navigated by an agent that encounters various shapes, each associated\nwith a given reward. The underlying DuelDQN attempts to learn the optimal\nbehaviour of the agent in this environment, while the modules facilitate shape\nrecognition and reward prediction. We show that our architecture significantly\nimproves learning, both in terms of performance and the precision of the agent.\nThe modularity of SymDQN allows reflecting on the intricacies and complexities\nof combining neural and symbolic approaches in reinforcement learning.",
      "pdf_url": "http://arxiv.org/pdf/2504.02654v1",
      "published": "2025-04-03T14:51:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.02654v1",
      "categories": [
        "cs.AI",
        "cs.LO",
        "cs.NE",
        "I.2.6"
      ]
    },
    {
      "title": "Prompt Optimization with Logged Bandit Data",
      "authors": [
        "Haruka Kiyohara",
        "Daniel Yiming Cao",
        "Yuta Saito",
        "Thorsten Joachims"
      ],
      "abstract": "We study how to use naturally available user feedback, such as clicks, to\noptimize large language model (LLM) pipelines for generating personalized\nsentences using prompts. Naive approaches, which estimate the policy gradient\nin the prompt space, suffer either from variance caused by the large action\nspace of prompts or bias caused by inaccurate reward predictions. To circumvent\nthese challenges, we propose a novel kernel-based off-policy gradient method,\nwhich estimates the policy gradient by leveraging similarity among generated\nsentences, substantially reducing variance while suppressing the bias.\nEmpirical results on our newly established suite of benchmarks demonstrate the\neffectiveness of the proposed approach in generating personalized descriptions\nfor movie recommendations, particularly when the number of candidate prompts is\nlarge.",
      "pdf_url": "http://arxiv.org/pdf/2504.02646v1",
      "published": "2025-04-03T14:40:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.02646v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR",
        "stat.ML"
      ]
    },
    {
      "title": "Multi-Mission Tool Bench: Assessing the Robustness of LLM based Agents through Related and Dynamic Missions",
      "authors": [
        "PeiJie Yu",
        "Yifan Yang",
        "Jinjian Li",
        "Zelong Zhang",
        "Haorui Wang",
        "Xiao Feng",
        "Feng Zhang"
      ],
      "abstract": "Large language models (LLMs) demonstrate strong potential as agents for tool\ninvocation due to their advanced comprehension and planning capabilities. Users\nincreasingly rely on LLM-based agents to solve complex missions through\niterative interactions. However, existing benchmarks predominantly access\nagents in single-mission scenarios, failing to capture real-world complexity.\nTo bridge this gap, we propose the Multi-Mission Tool Bench. In the benchmark,\neach test case comprises multiple interrelated missions. This design requires\nagents to dynamically adapt to evolving demands. Moreover, the proposed\nbenchmark explores all possible mission-switching patterns within a fixed\nmission number. Specifically, we propose a multi-agent data generation\nframework to construct the benchmark. We also propose a novel method to\nevaluate the accuracy and efficiency of agent decisions with dynamic decision\ntrees. Experiments on diverse open-source and closed-source LLMs reveal\ncritical factors influencing agent robustness and provide actionable insights\nto the tool invocation society.",
      "pdf_url": "http://arxiv.org/pdf/2504.02623v1",
      "published": "2025-04-03T14:21:33+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.02623v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Efficient Model Editing with Task-Localized Sparse Fine-tuning",
      "authors": [
        "Leonardo Iurada",
        "Marco Ciccone",
        "Tatiana Tommasi"
      ],
      "abstract": "Task arithmetic has emerged as a promising approach for editing models by\nrepresenting task-specific knowledge as composable task vectors. However,\nexisting methods rely on network linearization to derive task vectors, leading\nto computational bottlenecks during training and inference. Moreover,\nlinearization alone does not ensure weight disentanglement, the key property\nthat enables conflict-free composition of task vectors. To address this, we\npropose TaLoS which allows to build sparse task vectors with minimal\ninterference without requiring explicit linearization and sharing information\nacross tasks. We find that pre-trained models contain a subset of parameters\nwith consistently low gradient sensitivity across tasks, and that sparsely\nupdating only these parameters allows for promoting weight disentanglement\nduring fine-tuning. Our experiments prove that TaLoS improves training and\ninference efficiency while outperforming current methods in task addition and\nnegation. By enabling modular parameter editing, our approach fosters practical\ndeployment of adaptable foundation models in real-world applications.",
      "pdf_url": "http://arxiv.org/pdf/2504.02620v1",
      "published": "2025-04-03T14:20:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.02620v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ]
    },
    {
      "title": "Learning Geometrically-Informed Lyapunov Functions with Deep Diffeomorphic RBF Networks",
      "authors": [
        "Samuel Tesfazgi",
        "Leonhard Sprandl",
        "Sandra Hirche"
      ],
      "abstract": "The practical deployment of learning-based autonomous systems would greatly\nbenefit from tools that flexibly obtain safety guarantees in the form of\ncertificate functions from data. While the geometrical properties of such\ncertificate functions are well understood, synthesizing them using machine\nlearning techniques still remains a challenge. To mitigate this issue, we\npropose a diffeomorphic function learning framework where prior structural\nknowledge of the desired output is encoded in the geometry of a simple\nsurrogate function, which is subsequently augmented through an expressive,\ntopology-preserving state-space transformation. Thereby, we achieve an indirect\nfunction approximation framework that is guaranteed to remain in the desired\nhypothesis space. To this end, we introduce a novel approach to construct\ndiffeomorphic maps based on RBF networks, which facilitate precise, local\ntransformations around data. Finally, we demonstrate our approach by learning\ndiffeomorphic Lyapunov functions from real-world data and apply our method to\ndifferent attractor systems.",
      "pdf_url": "http://arxiv.org/pdf/2504.02607v1",
      "published": "2025-04-03T14:09:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.02607v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ]
    },
    {
      "title": "Improving Counterfactual Truthfulness for Molecular Property Prediction through Uncertainty Quantification",
      "authors": [
        "Jonas Teufel",
        "Annika Leinweber",
        "Pascal Friederich"
      ],
      "abstract": "Explainable AI (xAI) interventions aim to improve interpretability for\ncomplex black-box models, not only to improve user trust but also as a means to\nextract scientific insights from high-performing predictive systems. In\nmolecular property prediction, counterfactual explanations offer a way to\nunderstand predictive behavior by highlighting which minimal perturbations in\nthe input molecular structure cause the greatest deviation in the predicted\nproperty. However, such explanations only allow for meaningful scientific\ninsights if they reflect the distribution of the true underlying property -- a\nfeature we define as counterfactual truthfulness. To increase this\ntruthfulness, we propose the integration of uncertainty estimation techniques\nto filter counterfactual candidates with high predicted uncertainty. Through\ncomputational experiments with synthetic and real-world datasets, we\ndemonstrate that traditional uncertainty estimation methods, such as ensembles\nand mean-variance estimation, can already substantially reduce the average\nprediction error and increase counterfactual truthfulness, especially for\nout-of-distribution settings. Our results highlight the importance and\npotential impact of incorporating uncertainty estimation into explainability\nmethods, especially considering the relatively high effectiveness of low-effort\ninterventions like model ensembles.",
      "pdf_url": "http://arxiv.org/pdf/2504.02606v1",
      "published": "2025-04-03T14:07:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.02606v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Multi-SWE-bench: A Multilingual Benchmark for Issue Resolving",
      "authors": [
        "Daoguang Zan",
        "Zhirong Huang",
        "Wei Liu",
        "Hanwu Chen",
        "Linhao Zhang",
        "Shulin Xin",
        "Lu Chen",
        "Qi Liu",
        "Xiaojian Zhong",
        "Aoyan Li",
        "Siyao Liu",
        "Yongsheng Xiao",
        "Liangqiang Chen",
        "Yuyu Zhang",
        "Jing Su",
        "Tianyu Liu",
        "Rui Long",
        "Kai Shen",
        "Liang Xiang"
      ],
      "abstract": "The task of issue resolving is to modify a codebase to generate a patch that\naddresses a given issue. However, existing benchmarks, such as SWE-bench, focus\nalmost exclusively on Python, making them insufficient for evaluating Large\nLanguage Models (LLMs) across diverse software ecosystems. To address this, we\nintroduce a multilingual issue-resolving benchmark, called Multi-SWE-bench,\ncovering Java, TypeScript, JavaScript, Go, Rust, C, and C++. It includes a\ntotal of 1,632 high-quality instances, which were carefully annotated from\n2,456 candidates by 68 expert annotators, ensuring that the benchmark can\nprovide an accurate and reliable evaluation. Based on Multi-SWE-bench, we\nevaluate a series of state-of-the-art models using three representative methods\n(Agentless, SWE-agent, and OpenHands) and present a comprehensive analysis with\nkey empirical insights. In addition, we launch a Multi-SWE-RL open-source\ncommunity, aimed at building large-scale reinforcement learning (RL) training\ndatasets for issue-resolving tasks. As an initial contribution, we release a\nset of 4,723 well-structured instances spanning seven programming languages,\nlaying a solid foundation for RL research in this domain. More importantly, we\nopen-source our entire data production pipeline, along with detailed tutorials,\nencouraging the open-source community to continuously contribute and expand the\ndataset. We envision our Multi-SWE-bench and the ever-growing Multi-SWE-RL\ncommunity as catalysts for advancing RL toward its full potential, bringing us\none step closer to the dawn of AGI.",
      "pdf_url": "http://arxiv.org/pdf/2504.02605v1",
      "published": "2025-04-03T14:06:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.02605v1",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Knowledge Graph Completion with Mixed Geometry Tensor Factorization",
      "authors": [
        "Viacheslav Yusupov",
        "Maxim Rakhuba",
        "Evgeny Frolov"
      ],
      "abstract": "In this paper, we propose a new geometric approach for knowledge graph\ncompletion via low rank tensor approximation. We augment a pretrained and\nwell-established Euclidean model based on a Tucker tensor decomposition with a\nnovel hyperbolic interaction term. This correction enables more nuanced\ncapturing of distributional properties in data better aligned with real-world\nknowledge graphs. By combining two geometries together, our approach improves\nexpressivity of the resulting model achieving new state-of-the-art link\nprediction accuracy with a significantly lower number of parameters compared to\nthe previous Euclidean and hyperbolic models.",
      "pdf_url": "http://arxiv.org/pdf/2504.02589v1",
      "published": "2025-04-03T13:54:43+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.02589v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR",
        "stat.ML"
      ]
    },
    {
      "title": "Deep learning for music generation. Four approaches and their comparative evaluation",
      "authors": [
        "Razvan Paroiu",
        "Stefan Trausan-Matu"
      ],
      "abstract": "This paper introduces four different artificial intelligence algorithms for\nmusic generation and aims to compare these methods not only based on the\naesthetic quality of the generated music but also on their suitability for\nspecific applications. The first set of melodies is produced by a slightly\nmodified visual transformer neural network that is used as a language model.\nThe second set of melodies is generated by combining chat sonification with a\nclassic transformer neural network (the same method of music generation is\npresented in a previous research), the third set of melodies is generated by\ncombining the Schillinger rhythm theory together with a classic transformer\nneural network, and the fourth set of melodies is generated using GPT3\ntransformer provided by OpenAI. A comparative analysis is performed on the\nmelodies generated by these approaches and the results indicate that\nsignificant differences can be observed between them and regarding the\naesthetic value of them, GPT3 produced the most pleasing melodies, and the\nnewly introduced Schillinger method proved to generate better sounding music\nthan previous sonification methods.",
      "pdf_url": "http://arxiv.org/pdf/2504.02586v1",
      "published": "2025-04-03T13:51:07+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.02586v1",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ]
    },
    {
      "title": "Reasoning Inconsistencies and How to Mitigate Them in Deep Learning",
      "authors": [
        "Erik Arakelyan"
      ],
      "abstract": "The recent advancements in Deep Learning models and techniques have led to\nsignificant strides in performance across diverse tasks and modalities.\nHowever, while the overall capabilities of models show promising growth, our\nunderstanding of their internal reasoning processes remains limited,\nparticularly concerning systematic inconsistencies or errors patterns of\nlogical or inferential flaws. These inconsistencies may manifest as\ncontradictory outputs, failure to generalize across similar tasks, or erroneous\nconclusions in specific contexts. Even detecting and measuring such reasoning\ndiscrepancies is challenging, as they may arise from opaque internal\nprocedures, biases and imbalances in training data, or the inherent complexity\nof the task. Without effective methods to detect, measure, and mitigate these\nerrors, there is a risk of deploying models that are biased, exploitable, or\nlogically unreliable. This thesis aims to address these issues by producing\nnovel methods for deep learning models that reason over knowledge graphs,\nnatural language, and images. The thesis contributes two techniques for\ndetecting and quantifying predictive inconsistencies originating from opaque\ninternal procedures in natural language and image processing models. To\nmitigate inconsistencies from biases in training data, this thesis presents a\ndata efficient sampling method to improve fairness and performance and a\nsynthetic dataset generation approach in low resource scenarios. Finally, the\nthesis offers two techniques to optimize the models for complex reasoning\ntasks. These methods enhance model performance while allowing for more faithful\nand interpretable exploration and exploitation during inference. Critically,\nthis thesis provides a comprehensive framework to improve the robustness,\nfairness, and interpretability of deep learning models across diverse tasks and\nmodalities.",
      "pdf_url": "http://arxiv.org/pdf/2504.02577v1",
      "published": "2025-04-03T13:40:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.02577v1",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.LO"
      ]
    },
    {
      "title": "Rip Current Segmentation: A Novel Benchmark and YOLOv8 Baseline Results",
      "authors": [
        "Andrei Dumitriu",
        "Florin Tatui",
        "Florin Miron",
        "Radu Tudor Ionescu",
        "Radu Timofte"
      ],
      "abstract": "Rip currents are the leading cause of fatal accidents and injuries on many\nbeaches worldwide, emphasizing the importance of automatically detecting these\nhazardous surface water currents. In this paper, we address a novel task: rip\ncurrent instance segmentation. We introduce a comprehensive dataset containing\n$2,466$ images with newly created polygonal annotations for instance\nsegmentation, used for training and validation. Additionally, we present a\nnovel dataset comprising $17$ drone videos (comprising about $24K$ frames)\ncaptured at $30 FPS$, annotated with both polygons for instance segmentation\nand bounding boxes for object detection, employed for testing purposes. We\ntrain various versions of YOLOv8 for instance segmentation on static images and\nassess their performance on the test dataset (videos). The best results were\nachieved by the YOLOv8-nano model (runnable on a portable device), with an\nmAP50 of $88.94%$ on the validation dataset and $81.21%$ macro average on the\ntest dataset. The results provide a baseline for future research in rip current\nsegmentation. Our work contributes to the existing literature by introducing a\ndetailed, annotated dataset, and training a deep learning model for instance\nsegmentation of rip currents. The code, training details and the annotated\ndataset are made publicly available at https://github.com/Irikos/rip_currents.",
      "pdf_url": "http://arxiv.org/pdf/2504.02558v1",
      "published": "2025-04-03T13:14:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.02558v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.4.0; I.4.9"
      ]
    },
    {
      "title": "GPG: A Simple and Strong Reinforcement Learning Baseline for Model Reasoning",
      "authors": [
        "Xiangxiang Chu",
        "Hailang Huang",
        "Xiao Zhang",
        "Fei Wei",
        "Yong Wang"
      ],
      "abstract": "Reinforcement Learning (RL) can directly enhance the reasoning capabilities\nof large language models without extensive reliance on Supervised Fine-Tuning\n(SFT). In this work, we revisit the traditional Policy Gradient (PG) mechanism\nand propose a minimalist RL approach termed Group Policy Gradient (GPG). Unlike\nconventional methods, GPG directly optimize the original RL objective, thus\nobviating the need for surrogate loss functions. As illustrated in our paper,\nby eliminating both the critic and reference models, and avoiding KL divergence\nconstraints, our approach significantly simplifies the training process when\ncompared to Group Relative Policy Optimization (GRPO). Our approach achieves\nsuperior performance without relying on auxiliary techniques or adjustments.\nExtensive experiments demonstrate that our method not only reduces\ncomputational costs but also consistently outperforms GRPO across various\nunimodal and multimodal tasks. Our code is available at\nhttps://github.com/AMAP-ML/GPG.",
      "pdf_url": "http://arxiv.org/pdf/2504.02546v1",
      "published": "2025-04-03T12:53:41+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.02546v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Fourier Sliced-Wasserstein Embedding for Multisets and Measures",
      "authors": [
        "Tal Amir",
        "Nadav Dym"
      ],
      "abstract": "We present the Fourier Sliced-Wasserstein (FSW) embedding - a novel method to\nembed multisets and measures over $\\mathbb{R}^d$ into Euclidean space.\n  Our proposed embedding approximately preserves the sliced Wasserstein\ndistance on distributions, thereby yielding geometrically meaningful\nrepresentations that better capture the structure of the input. Moreover, it is\ninjective on measures and bi-Lipschitz on multisets - a significant advantage\nover prevalent methods based on sum- or max-pooling, which are provably not\nbi-Lipschitz, and, in many cases, not even injective. The required output\ndimension for these guarantees is near-optimal: roughly $2 N d$, where $N$ is\nthe maximal input multiset size.\n  Furthermore, we prove that it is impossible to embed distributions over\n$\\mathbb{R}^d$ into Euclidean space in a bi-Lipschitz manner. Thus, the metric\nproperties of our embedding are, in a sense, the best possible.\n  Through numerical experiments, we demonstrate that our method yields superior\nmultiset representations that improve performance in practical learning tasks.\nSpecifically, we show that (a) a simple combination of the FSW embedding with\nan MLP achieves state-of-the-art performance in learning the (non-sliced)\nWasserstein distance; and (b) replacing max-pooling with the FSW embedding\nmakes PointNet significantly more robust to parameter reduction, with only\nminor performance degradation even after a 40-fold reduction.",
      "pdf_url": "http://arxiv.org/pdf/2504.02544v1",
      "published": "2025-04-03T12:51:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.02544v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Improving User Experience with FAICO: Towards a Framework for AI Communication in Human-AI Co-Creativity",
      "authors": [
        "Jeba Rezwana",
        "Corey Ford"
      ],
      "abstract": "How AI communicates with humans is crucial for effective human-AI\nco-creation. However, many existing co-creative AI tools cannot communicate\neffectively, limiting their potential as collaborators. This paper introduces\nour initial design of a Framework for designing AI Communication (FAICO) for\nco-creative AI based on a systematic review of 107 full-length papers. FAICO\npresents key aspects of AI communication and their impacts on user experience\nto guide the design of effective AI communication. We then show actionable ways\nto translate our framework into two practical tools: design cards for designers\nand a configuration tool for users. The design cards enable designers to\nconsider AI communication strategies that cater to a diverse range of users in\nco-creative contexts, while the configuration tool empowers users to customize\nAI communication based on their needs and creative workflows. This paper\ncontributes new insights within the literature on human-AI co-creativity and\nHuman-Computer Interaction, focusing on designing AI communication to enhance\nuser experience.",
      "pdf_url": "http://arxiv.org/pdf/2504.02526v1",
      "published": "2025-04-03T12:29:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.02526v1",
      "categories": [
        "cs.HC",
        "cs.AI"
      ]
    },
    {
      "title": "Towards Generalizing Temporal Action Segmentation to Unseen Views",
      "authors": [
        "Emad Bahrami",
        "Olga Zatsarynna",
        "Gianpiero Francesca",
        "Juergen Gall"
      ],
      "abstract": "While there has been substantial progress in temporal action segmentation,\nthe challenge to generalize to unseen views remains unaddressed. Hence, we\ndefine a protocol for unseen view action segmentation where camera views for\nevaluating the model are unavailable during training. This includes changing\nfrom top-frontal views to a side view or even more challenging from exocentric\nto egocentric views. Furthermore, we present an approach for temporal action\nsegmentation that tackles this challenge. Our approach leverages a shared\nrepresentation at both the sequence and segment levels to reduce the impact of\nview differences during training. We achieve this by introducing a sequence\nloss and an action loss, which together facilitate consistent video and action\nrepresentations across different views. The evaluation on the Assembly101,\nIkeaASM, and EgoExoLearn datasets demonstrate significant improvements, with a\n12.8% increase in F1@50 for unseen exocentric views and a substantial 54%\nimprovement for unseen egocentric views.",
      "pdf_url": "http://arxiv.org/pdf/2504.02512v1",
      "published": "2025-04-03T11:53:59+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.02512v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "A Memory-Augmented LLM-Driven Method for Autonomous Merging of 3D Printing Work Orders",
      "authors": [
        "Yuhao Liu",
        "Maolin Yang",
        "Pingyu Jiang"
      ],
      "abstract": "With the rapid development of 3D printing, the demand for personalized and\ncustomized production on the manufacturing line is steadily increasing.\nEfficient merging of printing workpieces can significantly enhance the\nprocessing efficiency of the production line. Addressing the challenge, a Large\nLanguage Model (LLM)-driven method is established in this paper for the\nautonomous merging of 3D printing work orders, integrated with a\nmemory-augmented learning strategy. In industrial scenarios, both device and\norder features are modeled into LLM-readable natural language prompt templates,\nand develop an order-device matching tool along with a merging interference\nchecking module. By incorporating a self-memory learning strategy, an\nintelligent agent for autonomous order merging is constructed, resulting in\nimproved accuracy and precision in order allocation. The proposed method\neffectively leverages the strengths of LLMs in industrial applications while\nreducing hallucination.",
      "pdf_url": "http://arxiv.org/pdf/2504.02509v1",
      "published": "2025-04-03T11:50:29+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.02509v1",
      "categories": [
        "cs.AI",
        "cs.RO"
      ]
    },
    {
      "title": "Inference-Time Scaling for Generalist Reward Modeling",
      "authors": [
        "Zijun Liu",
        "Peiyi Wang",
        "Runxin Xu",
        "Shirong Ma",
        "Chong Ruan",
        "Peng Li",
        "Yang Liu",
        "Yu Wu"
      ],
      "abstract": "Reinforcement learning (RL) has been widely adopted in post-training for\nlarge language models (LLMs) at scale. Recently, the incentivization of\nreasoning capabilities in LLMs from RL indicates that $\\textit{proper learning\nmethods could enable effective inference-time scalability}$. A key challenge of\nRL is to obtain accurate reward signals for LLMs in various domains beyond\nverifiable questions or artificial rules. In this work, we investigate how to\nimprove reward modeling (RM) with more inference compute for general queries,\ni.e. the $\\textbf{inference-time scalability of generalist RM}$, and further,\nhow to improve the effectiveness of performance-compute scaling with proper\nlearning methods. For the RM approach, we adopt pointwise generative reward\nmodeling (GRM) to enable flexibility for different input types and potential\nfor inference-time scaling. For the learning method, we propose Self-Principled\nCritique Tuning (SPCT) to foster scalable reward generation behaviors in GRMs\nthrough online RL, to generate principles adaptively and critiques accurately,\nresulting in $\\textbf{DeepSeek-GRM}$ models. Furthermore, for effective\ninference-time scaling, we use parallel sampling to expand compute usage, and\nintroduce a meta RM to guide voting process for better scaling performance.\nEmpirically, we show that SPCT significantly improves the quality and\nscalability of GRMs, outperforming existing methods and models in various RM\nbenchmarks without severe biases, and could achieve better performance compared\nto training-time scaling. DeepSeek-GRM still meets challenges in some tasks,\nwhich we believe can be addressed by future efforts in generalist reward\nsystems. The models will be released and open-sourced.",
      "pdf_url": "http://arxiv.org/pdf/2504.02495v1",
      "published": "2025-04-03T11:19:49+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.02495v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Industrial Internet Robot Collaboration System and Edge Computing Optimization",
      "authors": [
        "Qian Zuo",
        "Dajun Tao",
        "Tian Qi",
        "Jieyi Xie",
        "Zijie Zhou",
        "Zhen Tian",
        "Yu Mingyu"
      ],
      "abstract": "In a complex environment, for a mobile robot to safely and collision - free\navoid all obstacles, it poses high requirements for its intelligence level.\nGiven that the information such as the position and geometric characteristics\nof obstacles is random, the control parameters of the robot, such as velocity\nand angular velocity, are also prone to random deviations. To address this\nissue in the framework of the Industrial Internet Robot Collaboration System,\nthis paper proposes a global path control scheme for mobile robots based on\ndeep learning. First of all, the dynamic equation of the mobile robot is\nestablished. According to the linear velocity and angular velocity of the\nmobile robot, its motion behaviors are divided into obstacle - avoidance\nbehavior, target - turning behavior, and target approaching behavior.\nSubsequently, the neural network method in deep learning is used to build a\nglobal path planning model for the robot. On this basis, a fuzzy controller is\ndesigned with the help of a fuzzy control algorithm to correct the deviations\nthat occur during path planning, thereby achieving optimized control of the\nrobot's global path. In addition, considering edge computing optimization, the\nproposed model can process local data at the edge device, reducing the\ncommunication burden between the robot and the central server, and improving\nthe real time performance of path planning. The experimental results show that\nfor the mobile robot controlled by the research method in this paper, the\ndeviation distance of the path angle is within 5 cm, the deviation convergence\ncan be completed within 10 ms, and the planned path is shorter. This indicates\nthat the proposed scheme can effectively improve the global path planning\nability of mobile robots in the industrial Internet environment and promote the\ncollaborative operation of robots through edge computing optimization.",
      "pdf_url": "http://arxiv.org/pdf/2504.02492v1",
      "published": "2025-04-03T11:15:10+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.02492v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "The Self-Learning Agent with a Progressive Neural Network Integrated Transformer",
      "authors": [
        "Ajay Sivakumar",
        "Shalini",
        "Vasantha Raj",
        "Sebastian Sylvester"
      ],
      "abstract": "This paper introduces a self-learning agent that integrates LLaMA 3.2 with a\nProgressive Neural Network (PNN) for continual learning in conversational AI\nand code generation. The framework dynamically collects data, fine-tunes tasks\nwith minimal samples, and leverages Meta-Learning for rapid adaptation. LoRA\noptimizes fine-tuning, while Elastic Weight Consolidation (EWC) enhances\nknowledge retention. Experimental results demonstrate improved adaptability and\nmemory stability, positioning this approach as a scalable step toward\nArtificial General Intelligence (AGI).",
      "pdf_url": "http://arxiv.org/pdf/2504.02489v1",
      "published": "2025-04-03T11:13:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.02489v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "We Need Improved Data Curation and Attribution in AI for Scientific Discovery",
      "authors": [
        "Mara Graziani",
        "Antonio Foncubierta",
        "Dimitrios Christofidellis",
        "Irina Espejo-Morales",
        "Malina Molnar",
        "Marvin Alberts",
        "Matteo Manica",
        "Jannis Born"
      ],
      "abstract": "As the interplay between human-generated and synthetic data evolves, new\nchallenges arise in scientific discovery concerning the integrity of the data\nand the stability of the models. In this work, we examine the role of synthetic\ndata as opposed to that of real experimental data for scientific research. Our\nanalyses indicate that nearly three-quarters of experimental datasets available\non open-access platforms have relatively low adoption rates, opening new\nopportunities to enhance their discoverability and usability by automated\nmethods. Additionally, we observe an increasing difficulty in distinguishing\nsynthetic from real experimental data. We propose supplementing ongoing efforts\nin automating synthetic data detection by increasing the focus on watermarking\nreal experimental data, thereby strengthening data traceability and integrity.\nOur estimates suggest that watermarking even less than half of the real world\ndata generated annually could help sustain model robustness, while promoting a\nbalanced integration of synthetic and human-generated content.",
      "pdf_url": "http://arxiv.org/pdf/2504.02486v1",
      "published": "2025-04-03T11:07:52+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.02486v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Graph Attention-Driven Bayesian Deep Unrolling for Dual-Peak Single-Photon Lidar Imaging",
      "authors": [
        "Kyungmin Choi",
        "JaKeoung Koo",
        "Stephen McLaughlin",
        "Abderrahim Halimi"
      ],
      "abstract": "Single-photon Lidar imaging offers a significant advantage in 3D imaging due\nto its high resolution and long-range capabilities, however it is challenging\nto apply in noisy environments with multiple targets per pixel. To tackle these\nchallenges, several methods have been proposed. Statistical methods demonstrate\ninterpretability on the inferred parameters, but they are often limited in\ntheir ability to handle complex scenes. Deep learning-based methods have shown\nsuperior performance in terms of accuracy and robustness, but they lack\ninterpretability or they are limited to a single-peak per pixel. In this paper,\nwe propose a deep unrolling algorithm for dual-peak single-photon Lidar\nimaging. We introduce a hierarchical Bayesian model for multiple targets and\npropose a neural network that unrolls the underlying statistical method. To\nsupport multiple targets, we adopt a dual depth maps representation and exploit\ngeometric deep learning to extract features from the point cloud. The proposed\nmethod takes advantages of statistical methods and learning-based methods in\nterms of accuracy and quantifying uncertainty. The experimental results on\nsynthetic and real data demonstrate the competitive performance when compared\nto existing methods, while also providing uncertainty information.",
      "pdf_url": "http://arxiv.org/pdf/2504.02480v1",
      "published": "2025-04-03T10:57:26+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.02480v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Hierarchical Policy-Gradient Reinforcement Learning for Multi-Agent Shepherding Control of Non-Cohesive Targets",
      "authors": [
        "Stefano Covone",
        "Italo Napolitano",
        "Francesco De Lellis",
        "Mario di Bernardo"
      ],
      "abstract": "We propose a decentralized reinforcement learning solution for multi-agent\nshepherding of non-cohesive targets using policy-gradient methods. Our\narchitecture integrates target-selection with target-driving through Proximal\nPolicy Optimization, overcoming discrete-action constraints of previous Deep\nQ-Network approaches and enabling smoother agent trajectories. This model-free\nframework effectively solves the shepherding problem without prior dynamics\nknowledge. Experiments demonstrate our method's effectiveness and scalability\nwith increased target numbers and limited sensing capabilities.",
      "pdf_url": "http://arxiv.org/pdf/2504.02479v1",
      "published": "2025-04-03T10:56:57+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.02479v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA",
        "cs.SY",
        "eess.SY",
        "stat.ML"
      ]
    },
    {
      "title": "BOOST: Bootstrapping Strategy-Driven Reasoning Programs for Program-Guided Fact-Checking",
      "authors": [
        "Qisheng Hu",
        "Quanyu Long",
        "Wenya Wang"
      ],
      "abstract": "Program-guided reasoning has shown promise in complex claim fact-checking by\ndecomposing claims into function calls and executing reasoning programs.\nHowever, prior work primarily relies on few-shot in-context learning (ICL) with\nad-hoc demonstrations, which limit program diversity and require manual design\nwith substantial domain knowledge. Fundamentally, the underlying principles of\neffective reasoning program generation still remain underexplored, making it\nchallenging to construct effective demonstrations. To address this, we propose\nBOOST, a bootstrapping-based framework for few-shot reasoning program\ngeneration. BOOST explicitly integrates claim decomposition and\ninformation-gathering strategies as structural guidance for program generation,\niteratively refining bootstrapped demonstrations in a strategy-driven and\ndata-centric manner without human intervention. This enables a seamless\ntransition from zero-shot to few-shot strategic program-guided learning,\nenhancing interpretability and effectiveness. Experimental results show that\nBOOST outperforms prior few-shot baselines in both zero-shot and few-shot\nsettings for complex claim verification.",
      "pdf_url": "http://arxiv.org/pdf/2504.02467v1",
      "published": "2025-04-03T10:38:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.02467v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Evaluating AI Recruitment Sourcing Tools by Human Preference",
      "authors": [
        "Vladimir Slaykovskiy",
        "Maksim Zvegintsev",
        "Yury Sakhonchyk",
        "Hrachik Ajamian"
      ],
      "abstract": "This study introduces a benchmarking methodology designed to evaluate the\nperformance of AI-driven recruitment sourcing tools. We created and utilized a\ndataset to perform a comparative analysis of search results generated by\nleading AI-based solutions, LinkedIn Recruiter, and our proprietary system,\nPearch.ai. Human experts assessed the relevance of the returned candidates, and\nan Elo rating system was applied to quantitatively measure each tool's\ncomparative performance. Our findings indicate that AI-driven recruitment\nsourcing tools consistently outperform LinkedIn Recruiter in candidate\nrelevance, with Pearch.ai achieving the highest performance scores.\nFurthermore, we found a strong alignment between AI-based evaluations and human\njudgments, highlighting the potential for advanced AI technologies to\nsubstantially enhance talent acquisition effectiveness. Code and supporting\ndata are publicly available at\nhttps://github.com/vslaykovsky/ai-sourcing-benchmark",
      "pdf_url": "http://arxiv.org/pdf/2504.02463v1",
      "published": "2025-04-03T10:33:43+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.02463v1",
      "categories": [
        "cs.IR",
        "cs.AI"
      ]
    },
    {
      "title": "CornerPoint3D: Look at the Nearest Corner Instead of the Center",
      "authors": [
        "Ruixiao Zhang",
        "Runwei Guan",
        "Xiangyu Chen",
        "Adam Prugel-Bennett",
        "Xiaohao Cai"
      ],
      "abstract": "3D object detection aims to predict object centers, dimensions, and rotations\nfrom LiDAR point clouds. Despite its simplicity, LiDAR captures only the near\nside of objects, making center-based detectors prone to poor localization\naccuracy in cross-domain tasks with varying point distributions. Meanwhile,\nexisting evaluation metrics designed for single-domain assessment also suffer\nfrom overfitting due to dataset-specific size variations. A key question\narises: Do we really need models to maintain excellent performance in the\nentire 3D bounding boxes after being applied across domains? Actually, one of\nour main focuses is on preventing collisions between vehicles and other\nobstacles, especially in cross-domain scenarios where correctly predicting the\nsizes is much more difficult. To address these issues, we rethink cross-domain\n3D object detection from a practical perspective. We propose two new metrics\nthat evaluate a model's ability to detect objects' closer-surfaces to the LiDAR\nsensor. Additionally, we introduce EdgeHead, a refinement head that guides\nmodels to focus more on learnable closer surfaces, significantly improving\ncross-domain performance under both our new and traditional BEV/3D metrics.\nFurthermore, we argue that predicting the nearest corner rather than the object\ncenter enhances robustness. We propose a novel 3D object detector, coined as\nCornerPoint3D, which is built upon CenterPoint and uses heatmaps to supervise\nthe learning and detection of the nearest corner of each object. Our proposed\nmethods realize a balanced trade-off between the detection quality of entire\nbounding boxes and the locating accuracy of closer surfaces to the LiDAR\nsensor, outperforming the traditional center-based detector CenterPoint in\nmultiple cross-domain tasks and providing a more practically reasonable and\nrobust cross-domain 3D object detection solution.",
      "pdf_url": "http://arxiv.org/pdf/2504.02464v1",
      "published": "2025-04-03T10:33:43+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.02464v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Am I Being Treated Fairly? A Conceptual Framework for Individuals to Ascertain Fairness",
      "authors": [
        "Juliett Su√°rez Ferreira",
        "Marija Slavkovik",
        "Jorge Casillas"
      ],
      "abstract": "Current fairness metrics and mitigation techniques provide tools for\npractitioners to asses how non-discriminatory Automatic Decision Making (ADM)\nsystems are. What if I, as an individual facing a decision taken by an ADM\nsystem, would like to know: Am I being treated fairly? We explore how to create\nthe affordance for users to be able to ask this question of ADM. In this paper,\nwe argue for the reification of fairness not only as a property of ADM, but\nalso as an epistemic right of an individual to acquire information about the\ndecisions that affect them and use that information to contest and seek\neffective redress against those decisions, in case they are proven to be\ndiscriminatory. We examine key concepts from existing research not only in\nalgorithmic fairness but also in explainable artificial intelligence,\naccountability, and contestability. Integrating notions from these domains, we\npropose a conceptual framework to ascertain fairness by combining different\ntools that empower the end-users of ADM systems. Our framework shifts the focus\nfrom technical solutions aimed at practitioners to mechanisms that enable\nindividuals to understand, challenge, and verify the fairness of decisions, and\nalso serves as a blueprint for organizations and policymakers, bridging the gap\nbetween technical requirements and practical, user-centered accountability.",
      "pdf_url": "http://arxiv.org/pdf/2504.02461v1",
      "published": "2025-04-03T10:28:19+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.02461v1",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC",
        "cs.LG",
        "cs.MA",
        "I.2; J.4"
      ]
    },
    {
      "title": "Retrieval-Augmented Purifier for Robust LLM-Empowered Recommendation",
      "authors": [
        "Liangbo Ning",
        "Wenqi Fan",
        "Qing Li"
      ],
      "abstract": "Recently, Large Language Model (LLM)-empowered recommender systems have\nrevolutionized personalized recommendation frameworks and attracted extensive\nattention. Despite the remarkable success, existing LLM-empowered RecSys have\nbeen demonstrated to be highly vulnerable to minor perturbations. To mitigate\nthe negative impact of such vulnerabilities, one potential solution is to\nemploy collaborative signals based on item-item co-occurrence to purify the\nmalicious collaborative knowledge from the user's historical interactions\ninserted by attackers. On the other hand, due to the capabilities to expand\ninsufficient internal knowledge of LLMs, Retrieval-Augmented Generation (RAG)\ntechniques provide unprecedented opportunities to enhance the robustness of\nLLM-empowered recommender systems by introducing external collaborative\nknowledge. Therefore, in this paper, we propose a novel framework (RETURN) by\nretrieving external collaborative signals to purify the poisoned user profiles\nand enhance the robustness of LLM-empowered RecSys in a plug-and-play manner.\nSpecifically, retrieval-augmented perturbation positioning is proposed to\nidentify potential perturbations within the users' historical sequences by\nretrieving external knowledge from collaborative item graphs. After that, we\nfurther retrieve the collaborative knowledge to cleanse the perturbations by\nusing either deletion or replacement strategies and introduce a robust ensemble\nrecommendation strategy to generate final robust predictions. Extensive\nexperiments on three real-world datasets demonstrate the effectiveness of the\nproposed RETURN.",
      "pdf_url": "http://arxiv.org/pdf/2504.02458v1",
      "published": "2025-04-03T10:22:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.02458v1",
      "categories": [
        "cs.IR",
        "cs.AI"
      ]
    },
    {
      "title": "CHARMS: Cognitive Hierarchical Agent with Reasoning and Motion Styles",
      "authors": [
        "Jingyi Wang",
        "Duanfeng Chu",
        "Zejian Deng",
        "Liping Lu"
      ],
      "abstract": "To address the current challenges of low intelligence and simplistic vehicle\nbehavior modeling in autonomous driving simulation scenarios, this paper\nproposes the Cognitive Hierarchical Agent with Reasoning and Motion Styles\n(CHARMS). The model can reason about the behavior of other vehicles like a\nhuman driver and respond with different decision-making styles, thereby\nimproving the intelligence and diversity of the surrounding vehicles in the\ndriving scenario. By introducing the Level-k behavioral game theory, the paper\nmodels the decision-making process of human drivers and employs deep\nreinforcement learning to train the models with diverse decision styles,\nsimulating different reasoning approaches and behavioral characteristics.\nBuilding on the Poisson cognitive hierarchy theory, this paper also presents a\nnovel driving scenario generation method. The method controls the proportion of\nvehicles with different driving styles in the scenario using Poisson and\nbinomial distributions, thus generating controllable and diverse driving\nenvironments. Experimental results demonstrate that CHARMS not only exhibits\nsuperior decision-making capabilities as ego vehicles, but also generates more\ncomplex and diverse driving scenarios as surrounding vehicles. We will release\ncode for CHARMS at https://github.com/WUTAD-Wjy/CHARMS.",
      "pdf_url": "http://arxiv.org/pdf/2504.02450v1",
      "published": "2025-04-03T10:15:19+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.02450v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Cognitive Memory in Large Language Models",
      "authors": [
        "Lianlei Shan",
        "Shixian Luo",
        "Zezhou Zhu",
        "Yu Yuan",
        "Yong Wu"
      ],
      "abstract": "This paper examines memory mechanisms in Large Language Models (LLMs),\nemphasizing their importance for context-rich responses, reduced\nhallucinations, and improved efficiency. It categorizes memory into sensory,\nshort-term, and long-term, with sensory memory corresponding to input prompts,\nshort-term memory processing immediate context, and long-term memory\nimplemented via external databases or structures. The text-based memory section\ncovers acquisition (selection and summarization), management (updating,\naccessing, storing, and resolving conflicts), and utilization (full-text\nsearch, SQL queries, semantic search). The KV cache-based memory section\ndiscusses selection methods (regularity-based summarization, score-based\napproaches, special token embeddings) and compression techniques (low-rank\ncompression, KV merging, multimodal compression), along with management\nstrategies like offloading and shared attention mechanisms. Parameter-based\nmemory methods (LoRA, TTT, MoE) transform memories into model parameters to\nenhance efficiency, while hidden-state-based memory approaches (chunk\nmechanisms, recurrent transformers, Mamba model) improve long-text processing\nby combining RNN hidden states with current methods. Overall, the paper offers\na comprehensive analysis of LLM memory mechanisms, highlighting their\nsignificance and future research directions.",
      "pdf_url": "http://arxiv.org/pdf/2504.02441v1",
      "published": "2025-04-03T09:58:19+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.02441v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    }
  ]
}