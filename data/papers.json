{
  "last_updated": "2025-02-27T00:44:54.546820",
  "papers": [
    {
      "title": "Scalable Equilibrium Sampling with Sequential Boltzmann Generators",
      "authors": [
        "Charlie B. Tan",
        "Avishek Joey Bose",
        "Chen Lin",
        "Leon Klein",
        "Michael M. Bronstein",
        "Alexander Tong"
      ],
      "abstract": "Scalable sampling of molecular states in thermodynamic equilibrium is a\nlong-standing challenge in statistical physics. Boltzmann generators tackle\nthis problem by pairing powerful normalizing flows with importance sampling to\nobtain statistically independent samples under the target distribution. In this\npaper, we extend the Boltzmann generator framework and introduce Sequential\nBoltzmann generators (SBG) with two key improvements. The first is a highly\nefficient non-equivariant Transformer-based normalizing flow operating directly\non all-atom Cartesian coordinates. In contrast to equivariant continuous flows\nof prior methods, we leverage exactly invertible non-equivariant architectures\nwhich are highly efficient both during sample generation and likelihood\ncomputation. As a result, this unlocks more sophisticated inference strategies\nbeyond standard importance sampling. More precisely, as a second key\nimprovement we perform inference-time scaling of flow samples using annealed\nLangevin dynamics which transports samples toward the target distribution\nleading to lower variance (annealed) importance weights which enable higher\nfidelity resampling with sequential Monte Carlo. SBG achieves state-of-the-art\nperformance w.r.t. all metrics on molecular systems, demonstrating the first\nequilibrium sampling in Cartesian coordinates of tri, tetra, and hexapeptides\nthat were so far intractable for prior Boltzmann generators.",
      "pdf_url": "http://arxiv.org/pdf/2502.18462v1",
      "published": "2025-02-25T18:59:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.18462v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "FRIDA to the Rescue! Analyzing Synthetic Data Effectiveness in Object-Based Common Sense Reasoning for Disaster Response",
      "authors": [
        "Mollie Shichman",
        "Claire Bonial",
        "Austin Blodgett",
        "Taylor Hudson",
        "Francis Ferraro",
        "Rachel Rudinger"
      ],
      "abstract": "Large Language Models (LLMs) have the potential for substantial common sense\nreasoning. However, these capabilities are often emergent in larger models.\nThis means smaller models that can be run locally are less helpful and capable\nwith respect to certain reasoning tasks. To meet our problem space\nrequirements, we fine-tune smaller LLMs to disaster domains, as these domains\ninvolve complex and low-frequency physical common sense knowledge. We introduce\na pipeline to create Field Ready Instruction Decoding Agent (FRIDA) models,\nwhere domain experts and linguists combine their knowledge to make high-quality\nseed data that is used to generate synthetic data for fine-tuning. We create a\nset of 130 seed instructions for synthetic generation, a synthetic dataset of\n25000 instructions, and 119 evaluation instructions relating to both general\nand earthquake-specific object affordances. We fine-tune several LLaMa and\nMistral instruction-tuned models and find that FRIDA models outperform their\nbase models at a variety of sizes. We then run an ablation study to understand\nwhich kinds of synthetic data most affect performance and find that training\nphysical state and object function common sense knowledge alone improves over\nFRIDA models trained on all data. We conclude that the FRIDA pipeline is\ncapable of instilling general common sense, but needs to be augmented with\ninformation retrieval for specific domain knowledge.",
      "pdf_url": "http://arxiv.org/pdf/2502.18452v1",
      "published": "2025-02-25T18:51:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.18452v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "SWE-RL: Advancing LLM Reasoning via Reinforcement Learning on Open Software Evolution",
      "authors": [
        "Yuxiang Wei",
        "Olivier Duchenne",
        "Jade Copet",
        "Quentin Carbonneaux",
        "Lingming Zhang",
        "Daniel Fried",
        "Gabriel Synnaeve",
        "Rishabh Singh",
        "Sida I. Wang"
      ],
      "abstract": "The recent DeepSeek-R1 release has demonstrated the immense potential of\nreinforcement learning (RL) in enhancing the general reasoning capabilities of\nlarge language models (LLMs). While DeepSeek-R1 and other follow-up work\nprimarily focus on applying RL to competitive coding and math problems, this\npaper introduces SWE-RL, the first approach to scale RL-based LLM reasoning for\nreal-world software engineering. Leveraging a lightweight rule-based reward\n(e.g., the similarity score between ground-truth and LLM-generated solutions),\nSWE-RL enables LLMs to autonomously recover a developer's reasoning processes\nand solutions by learning from extensive open-source software evolution data --\nthe record of a software's entire lifecycle, including its code snapshots, code\nchanges, and events such as issues and pull requests. Trained on top of Llama\n3, our resulting reasoning model, Llama3-SWE-RL-70B, achieves a 41.0% solve\nrate on SWE-bench Verified -- a human-verified collection of real-world GitHub\nissues. To our knowledge, this is the best performance reported for\nmedium-sized (<100B) LLMs to date, even comparable to leading proprietary LLMs\nlike GPT-4o. Surprisingly, despite performing RL solely on software evolution\ndata, Llama3-SWE-RL has even emerged with generalized reasoning skills. For\nexample, it shows improved results on five out-of-domain tasks, namely,\nfunction coding, library use, code reasoning, mathematics, and general language\nunderstanding, whereas a supervised-finetuning baseline even leads to\nperformance degradation on average. Overall, SWE-RL opens up a new direction to\nimprove the reasoning capabilities of LLMs through reinforcement learning on\nmassive software engineering data.",
      "pdf_url": "http://arxiv.org/pdf/2502.18449v1",
      "published": "2025-02-25T18:45:04+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.18449v1",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Disambiguate First Parse Later: Generating Interpretations for Ambiguity Resolution in Semantic Parsing",
      "authors": [
        "Irina Saparina",
        "Mirella Lapata"
      ],
      "abstract": "Handling ambiguity and underspecification is an important challenge in\nnatural language interfaces, particularly for tasks like text-to-SQL semantic\nparsing. We propose a modular approach that resolves ambiguity using natural\nlanguage interpretations before mapping these to logical forms (e.g., SQL\nqueries). Although LLMs excel at parsing unambiguous utterances, they show\nstrong biases for ambiguous ones, typically predicting only preferred\ninterpretations. We constructively exploit this bias to generate an initial set\nof preferred disambiguations and then apply a specialized infilling model to\nidentify and generate missing interpretations. To train the infilling model, we\nintroduce an annotation method that uses SQL execution to validate different\nmeanings. Our approach improves interpretation coverage and generalizes across\ndatasets with different annotation styles, database structures, and ambiguity\ntypes.",
      "pdf_url": "http://arxiv.org/pdf/2502.18448v1",
      "published": "2025-02-25T18:42:26+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.18448v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "MAPoRL: Multi-Agent Post-Co-Training for Collaborative Large Language Models with Reinforcement Learning",
      "authors": [
        "Chanwoo Park",
        "Seungju Han",
        "Xingzhi Guo",
        "Asuman Ozdaglar",
        "Kaiqing Zhang",
        "Joo-Kyung Kim"
      ],
      "abstract": "Leveraging multiple large language models (LLMs) to build collaborative\nmulti-agentic workflows has demonstrated significant potential. However, most\nprevious studies focus on prompting the out-of-the-box LLMs, relying on their\ninnate capability for collaboration, which may not improve LLMs' performance as\nshown recently. In this paper, we introduce a new post-training paradigm MAPoRL\n(Multi-Agent Post-co-training for collaborative LLMs with Reinforcement\nLearning), to explicitly elicit the collaborative behaviors and further unleash\nthe power of multi-agentic LLM frameworks. In MAPoRL, multiple LLMs first\ngenerate their own responses independently and engage in a multi-turn\ndiscussion to collaboratively improve the final answer. In the end, a MAPoRL\nverifier evaluates both the answer and the discussion, by assigning a score\nthat verifies the correctness of the answer, while adding incentives to\nencourage corrective and persuasive discussions. The score serves as the\nco-training reward, and is then maximized through multi-agent RL. Unlike\nexisting LLM post-training paradigms, MAPoRL advocates the co-training of\nmultiple LLMs together using RL for better generalization. Accompanied by\nanalytical insights, our experiments demonstrate that training individual LLMs\nalone is insufficient to induce effective collaboration. In contrast,\nmulti-agent co-training can boost the collaboration performance across\nbenchmarks, with generalization to unseen domains.",
      "pdf_url": "http://arxiv.org/pdf/2502.18439v1",
      "published": "2025-02-25T18:33:48+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.18439v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "ToMCAT: Theory-of-Mind for Cooperative Agents in Teams via Multiagent Diffusion Policies",
      "authors": [
        "Pedro Sequeira",
        "Vidyasagar Sadhu",
        "Melinda Gervasio"
      ],
      "abstract": "In this paper we present ToMCAT (Theory-of-Mind for Cooperative Agents in\nTeams), a new framework for generating ToM-conditioned trajectories. It\ncombines a meta-learning mechanism, that performs ToM reasoning over teammates'\nunderlying goals and future behavior, with a multiagent denoising-diffusion\nmodel, that generates plans for an agent and its teammates conditioned on both\nthe agent's goals and its teammates' characteristics, as computed via ToM. We\nimplemented an online planning system that dynamically samples new trajectories\n(replans) from the diffusion model whenever it detects a divergence between a\npreviously generated plan and the current state of the world. We conducted\nseveral experiments using ToMCAT in a simulated cooking domain. Our results\nhighlight the importance of the dynamic replanning mechanism in reducing the\nusage of resources without sacrificing team performance. We also show that\nrecent observations about the world and teammates' behavior collected by an\nagent over the course of an episode combined with ToM inferences are crucial to\ngenerate team-aware plans for dynamic adaptation to teammates, especially when\nno prior information is provided about them.",
      "pdf_url": "http://arxiv.org/pdf/2502.18438v1",
      "published": "2025-02-25T18:31:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.18438v1",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "TextGames: Learning to Self-Play Text-Based Puzzle Games via Language Model Reasoning",
      "authors": [
        "Frederikus Hudi",
        "Genta Indra Winata",
        "Ruochen Zhang",
        "Alham Fikri Aji"
      ],
      "abstract": "Reasoning is a fundamental capability of large language models (LLMs),\nenabling them to comprehend, analyze, and solve complex problems. In this\npaper, we introduce TextGames, an innovative benchmark specifically crafted to\nassess LLMs through demanding text-based games that require advanced skills in\npattern recognition, spatial awareness, arithmetic, and logical reasoning. Our\nanalysis probes LLMs' performance in both single-turn and multi-turn reasoning,\nand their abilities in leveraging feedback to correct subsequent answers\nthrough self-reflection. Our findings reveal that, although LLMs exhibit\nproficiency in addressing most easy and medium-level problems, they face\nsignificant challenges with more difficult tasks. In contrast, humans are\ncapable of solving all tasks when given sufficient time. Moreover, we observe\nthat LLMs show improved performance in multi-turn predictions through\nself-reflection, yet they still struggle with sequencing, counting, and\nfollowing complex rules consistently. Additionally, models optimized for\nreasoning outperform pre-trained LLMs that prioritize instruction following,\nhighlighting the crucial role of reasoning skills in addressing highly complex\nproblems.",
      "pdf_url": "http://arxiv.org/pdf/2502.18431v1",
      "published": "2025-02-25T18:26:48+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.18431v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "PyEvalAI: AI-assisted evaluation of Jupyter Notebooks for immediate personalized feedback",
      "authors": [
        "Nils Wandel",
        "David Stotko",
        "Alexander Schier",
        "Reinhard Klein"
      ],
      "abstract": "Grading student assignments in STEM courses is a laborious and repetitive\ntask for tutors, often requiring a week to assess an entire class. For\nstudents, this delay of feedback prevents iterating on incorrect solutions,\nhampers learning, and increases stress when exercise scores determine admission\nto the final exam. Recent advances in AI-assisted education, such as automated\ngrading and tutoring systems, aim to address these challenges by providing\nimmediate feedback and reducing grading workload. However, existing solutions\noften fall short due to privacy concerns, reliance on proprietary closed-source\nmodels, lack of support for combining Markdown, LaTeX and Python code, or\nexcluding course tutors from the grading process. To overcome these\nlimitations, we introduce PyEvalAI, an AI-assisted evaluation system, which\nautomatically scores Jupyter notebooks using a combination of unit tests and a\nlocally hosted language model to preserve privacy. Our approach is free,\nopen-source, and ensures tutors maintain full control over the grading process.\nA case study demonstrates its effectiveness in improving feedback speed and\ngrading efficiency for exercises in a university-level course on numerics.",
      "pdf_url": "http://arxiv.org/pdf/2502.18425v1",
      "published": "2025-02-25T18:20:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.18425v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Comparative Analysis of MDL-VAE vs. Standard VAE on 202 Years of Gynecological Data",
      "authors": [
        "Paula Santos"
      ],
      "abstract": "This study presents a comparative evaluation of a Variational Autoencoder\n(VAE) enhanced with Minimum Description Length (MDL) regularization against a\nStandard Autoencoder for reconstructing high-dimensional gynecological data.\nThe MDL-VAE exhibits significantly lower reconstruction errors (MSE, MAE, RMSE)\nand more structured latent representations, driven by effective KL divergence\nregularization. Statistical analyses confirm these performance improvements are\nsignificant. Furthermore, the MDL-VAE shows consistent training and validation\nlosses and achieves efficient inference times, underscoring its robustness and\npractical viability. Our findings suggest that incorporating MDL principles\ninto VAE architectures can substantially improve data reconstruction and\ngeneralization, making it a promising approach for advanced applications in\nhealthcare data modeling and analysis.",
      "pdf_url": "http://arxiv.org/pdf/2502.18412v1",
      "published": "2025-02-25T18:05:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.18412v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "TSKANMixer: Kolmogorov-Arnold Networks with MLP-Mixer Model for Time Series Forecasting",
      "authors": [
        "Young-Chae Hong",
        "Bei Xiao",
        "Yangho Chen"
      ],
      "abstract": "Time series forecasting has long been a focus of research across diverse\nfields, including economics, energy, healthcare, and traffic management. Recent\nworks have introduced innovative architectures for time series models, such as\nthe Time-Series Mixer (TSMixer), which leverages multi-layer perceptrons (MLPs)\nto enhance prediction accuracy by effectively capturing both spatial and\ntemporal dependencies within the data. In this paper, we investigate the\ncapabilities of the Kolmogorov-Arnold Networks (KANs) for time-series\nforecasting by modifying TSMixer with a KAN layer (TSKANMixer). Experimental\nresults demonstrate that TSKANMixer tends to improve prediction accuracy over\nthe original TSMixer across multiple datasets, ranking among the top-performing\nmodels compared to other time series approaches. Our results show that the KANs\nare promising alternatives to improve the performance of time series\nforecasting by replacing or extending traditional MLPs.",
      "pdf_url": "http://arxiv.org/pdf/2502.18410v1",
      "published": "2025-02-25T18:04:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.18410v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "AgentRM: Enhancing Agent Generalization with Reward Modeling",
      "authors": [
        "Yu Xia",
        "Jingru Fan",
        "Weize Chen",
        "Siyu Yan",
        "Xin Cong",
        "Zhong Zhang",
        "Yaxi Lu",
        "Yankai Lin",
        "Zhiyuan Liu",
        "Maosong Sun"
      ],
      "abstract": "Existing LLM-based agents have achieved strong performance on held-in tasks,\nbut their generalizability to unseen tasks remains poor. Hence, some recent\nwork focus on fine-tuning the policy model with more diverse tasks to improve\nthe generalizability. In this work, we find that finetuning a reward model to\nguide the policy model is more robust than directly finetuning the policy\nmodel. Based on this finding, we propose AgentRM, a generalizable reward model,\nto guide the policy model for effective test-time search. We comprehensively\ninvestigate three approaches to construct the reward model, including explicit\nreward modeling, implicit reward modeling and LLM-as-a-judge. We then use\nAgentRM to guide the answer generation with Best-of-N sampling and step-level\nbeam search. On four types of nine agent tasks, AgentRM enhances the base\npolicy model by $8.8$ points on average, surpassing the top general agent by\n$4.0$. Moreover, it demonstrates weak-to-strong generalization, yielding\ngreater improvement of $12.6$ on LLaMA-3-70B policy model. As for the\nspecializability, AgentRM can also boost a finetuned policy model and\noutperform the top specialized agent by $11.4$ on three held-in tasks. Further\nanalysis verifies its effectiveness in test-time scaling. Codes will be\nreleased to facilitate the research in this area.",
      "pdf_url": "http://arxiv.org/pdf/2502.18407v1",
      "published": "2025-02-25T17:58:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.18407v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "The Gradient of Algebraic Model Counting",
      "authors": [
        "Jaron Maene",
        "Luc De Raedt"
      ],
      "abstract": "Algebraic model counting unifies many inference tasks on logic formulas by\nexploiting semirings. Rather than focusing on inference, we consider learning,\nespecially in statistical-relational and neurosymbolic AI, which combine\nlogical, probabilistic and neural representations. Concretely, we show that the\nvery same semiring perspective of algebraic model counting also applies to\nlearning. This allows us to unify various learning algorithms by generalizing\ngradients and backpropagation to different semirings. Furthermore, we show how\ncancellation and ordering properties of a semiring can be exploited for more\nmemory-efficient backpropagation. This allows us to obtain some interesting\nvariations of state-of-the-art gradient-based optimisation methods for\nprobabilistic logical models. We also discuss why algebraic model counting on\ntractable circuits does not lead to more efficient second-order optimization.\nEmpirically, our algebraic backpropagation exhibits considerable speed-ups as\ncompared to existing approaches.",
      "pdf_url": "http://arxiv.org/pdf/2502.18406v1",
      "published": "2025-02-25T17:57:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.18406v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "How Far are LLMs from Real Search? A Comprehensive Study on Efficiency, Completeness, and Inherent Capabilities",
      "authors": [
        "Minhua Lin",
        "Hui Liu",
        "Xianfeng Tang",
        "Jingying Zeng",
        "Zhenwei Dai",
        "Chen Luo",
        "Zheng Li",
        "Xiang Zhang",
        "Qi He",
        "Suhang Wang"
      ],
      "abstract": "Search plays a fundamental role in problem-solving across various domains,\nwith most real-world decision-making problems being solvable through systematic\nsearch. Drawing inspiration from recent discussions on search and learning, we\nsystematically explore the complementary relationship between search and Large\nLanguage Models (LLMs) from three perspectives. First, we analyze how learning\ncan enhance search efficiency and propose Search via Learning (SeaL), a\nframework that leverages LLMs for effective and efficient search. Second, we\nfurther extend SeaL to SeaL-C to ensure rigorous completeness during search.\nOur evaluation across three real-world planning tasks demonstrates that SeaL\nachieves near-perfect accuracy while reducing search spaces by up to 99.1%\ncompared to traditional approaches. Finally, we explore how far LLMs are from\nreal search by investigating whether they can develop search capabilities\nindependently. Our analysis reveals that while current LLMs struggle with\nefficient search in complex problems, incorporating systematic search\nstrategies significantly enhances their problem-solving capabilities. These\nfindings not only validate the effectiveness of our approach but also highlight\nthe need for improving LLMs' search abilities for real-world applications.",
      "pdf_url": "http://arxiv.org/pdf/2502.18387v1",
      "published": "2025-02-25T17:30:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.18387v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "EgoSim: An Egocentric Multi-view Simulator and Real Dataset for Body-worn Cameras during Motion and Activity",
      "authors": [
        "Dominik Hollidt",
        "Paul Streli",
        "Jiaxi Jiang",
        "Yasaman Haghighi",
        "Changlin Qian",
        "Xintong Liu",
        "Christian Holz"
      ],
      "abstract": "Research on egocentric tasks in computer vision has mostly focused on\nhead-mounted cameras, such as fisheye cameras or embedded cameras inside\nimmersive headsets. We argue that the increasing miniaturization of optical\nsensors will lead to the prolific integration of cameras into many more\nbody-worn devices at various locations. This will bring fresh perspectives to\nestablished tasks in computer vision and benefit key areas such as human motion\ntracking, body pose estimation, or action recognition -- particularly for the\nlower body, which is typically occluded.\n  In this paper, we introduce EgoSim, a novel simulator of body-worn cameras\nthat generates realistic egocentric renderings from multiple perspectives\nacross a wearer's body. A key feature of EgoSim is its use of real motion\ncapture data to render motion artifacts, which are especially noticeable with\narm- or leg-worn cameras. In addition, we introduce MultiEgoView, a dataset of\negocentric footage from six body-worn cameras and ground-truth full-body 3D\nposes during several activities: 119 hours of data are derived from AMASS\nmotion sequences in four high-fidelity virtual environments, which we augment\nwith 5 hours of real-world motion data from 13 participants using six GoPro\ncameras and 3D body pose references from an Xsens motion capture suit.\n  We demonstrate EgoSim's effectiveness by training an end-to-end video-only 3D\npose estimation network. Analyzing its domain gap, we show that our dataset and\nsimulator substantially aid training for inference on real-world data.\n  EgoSim code & MultiEgoView dataset: https://siplab.org/projects/EgoSim",
      "pdf_url": "http://arxiv.org/pdf/2502.18373v1",
      "published": "2025-02-25T17:11:14+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.18373v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "MindMem: Multimodal for Predicting Advertisement Memorability Using LLMs and Deep Learning",
      "authors": [
        "Sepehr Asgarian",
        "Qayam Jetha",
        "Jouhyun Jeon"
      ],
      "abstract": "In the competitive landscape of advertising, success hinges on effectively\nnavigating and leveraging complex interactions among consumers, advertisers,\nand advertisement platforms. These multifaceted interactions compel advertisers\nto optimize strategies for modeling consumer behavior, enhancing brand recall,\nand tailoring advertisement content. To address these challenges, we present\nMindMem, a multimodal predictive model for advertisement memorability. By\nintegrating textual, visual, and auditory data, MindMem achieves\nstate-of-the-art performance, with a Spearman's correlation coefficient of\n0.631 on the LAMBDA and 0.731 on the Memento10K dataset, consistently\nsurpassing existing methods. Furthermore, our analysis identified key factors\ninfluencing advertisement memorability, such as video pacing, scene complexity,\nand emotional resonance. Expanding on this, we introduced MindMem-ReAd\n(MindMem-Driven Re-generated Advertisement), which employs Large Language\nModel-based simulations to optimize advertisement content and placement,\nresulting in up to a 74.12% improvement in advertisement memorability. Our\nresults highlight the transformative potential of Artificial Intelligence in\nadvertising, offering advertisers a robust tool to drive engagement, enhance\ncompetitiveness, and maximize impact in a rapidly evolving market.",
      "pdf_url": "http://arxiv.org/pdf/2502.18371v1",
      "published": "2025-02-25T17:09:12+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.18371v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Which Contributions Deserve Credit? Perceptions of Attribution in Human-AI Co-Creation",
      "authors": [
        "Jessica He",
        "Stephanie Houde",
        "Justin D. Weisz"
      ],
      "abstract": "AI systems powered by large language models can act as capable assistants for\nwriting and editing. In these tasks, the AI system acts as a co-creative\npartner, making novel contributions to an artifact-under-creation alongside its\nhuman partner(s). One question that arises in these scenarios is the extent to\nwhich AI should be credited for its contributions. We examined knowledge\nworkers' views of attribution through a survey study (N=155) and found that\nthey assigned different levels of credit across different contribution types,\namounts, and initiative. Compared to a human partner, we observed a consistent\npattern in which AI was assigned less credit for equivalent contributions.\nParticipants felt that disclosing AI involvement was important and used a\nvariety of criteria to make attribution judgments, including the quality of\ncontributions, personal values, and technology considerations. Our results\nmotivate and inform new approaches for crediting AI contributions to co-created\nwork.",
      "pdf_url": "http://arxiv.org/pdf/2502.18357v1",
      "published": "2025-02-25T16:48:10+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.18357v1",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ]
    },
    {
      "title": "From Vision to Sound: Advancing Audio Anomaly Detection with Vision-Based Algorithms",
      "authors": [
        "Manuel Barusco",
        "Francesco Borsatti",
        "Davide Dalle Pezze",
        "Francesco Paissan",
        "Elisabetta Farella",
        "Gian Antonio Susto"
      ],
      "abstract": "Recent advances in Visual Anomaly Detection (VAD) have introduced\nsophisticated algorithms leveraging embeddings generated by pre-trained feature\nextractors. Inspired by these developments, we investigate the adaptation of\nsuch algorithms to the audio domain to address the problem of Audio Anomaly\nDetection (AAD). Unlike most existing AAD methods, which primarily classify\nanomalous samples, our approach introduces fine-grained temporal-frequency\nlocalization of anomalies within the spectrogram, significantly improving\nexplainability. This capability enables a more precise understanding of where\nand when anomalies occur, making the results more actionable for end users. We\nevaluate our approach on industrial and environmental benchmarks, demonstrating\nthe effectiveness of VAD techniques in detecting anomalies in audio signals.\nMoreover, they improve explainability by enabling localized anomaly\nidentification, making audio anomaly detection systems more interpretable and\npractical.",
      "pdf_url": "http://arxiv.org/pdf/2502.18328v1",
      "published": "2025-02-25T16:22:42+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.18328v1",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CV",
        "eess.AS"
      ]
    },
    {
      "title": "GraphRank Pro+: Advancing Talent Analytics Through Knowledge Graphs and Sentiment-Enhanced Skill Profiling",
      "authors": [
        "Sirisha Velampalli",
        "Chandrashekar Muniyappa"
      ],
      "abstract": "The extraction of information from semi-structured text, such as resumes, has\nlong been a challenge due to the diverse formatting styles and subjective\ncontent organization. Conventional solutions rely on specialized logic tailored\nfor specific use cases. However, we propose a revolutionary approach leveraging\nstructured Graphs, Natural Language Processing (NLP), and Deep Learning. By\nabstracting intricate logic into Graph structures, we transform raw data into a\ncomprehensive Knowledge Graph. This innovative framework enables precise\ninformation extraction and sophisticated querying. We systematically construct\ndictionaries assigning skill weights, paving the way for nuanced talent\nanalysis. Our system not only benefits job recruiters and curriculum designers\nbut also empowers job seekers with targeted query-based filtering and ranking\ncapabilities.",
      "pdf_url": "http://arxiv.org/pdf/2502.18315v1",
      "published": "2025-02-25T16:07:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.18315v1",
      "categories": [
        "cs.AI",
        "cs.LG",
        "05C81",
        "I.2.7"
      ]
    },
    {
      "title": "Smart and Efficient IoT-Based Irrigation System Design: Utilizing a Hybrid Agent-Based and System Dynamics Approach",
      "authors": [
        "Taha Ahmadi Pargo",
        "Mohsen Akbarpour Shirazi",
        "Dawud Fadai"
      ],
      "abstract": "Regarding problems like reduced precipitation and an increase in population,\nwater resource scarcity has become one of the most critical problems in\nmodern-day societies, as a consequence, there is a shortage of available water\nresources for irrigation in arid and semi-arid countries. On the other hand, it\nis possible to utilize modern technologies to control irrigation and reduce\nwater loss. One of these technologies is the Internet of Things (IoT). Despite\nthe possibility of using the IoT in irrigation control systems, there are\ncomplexities in designing such systems. Considering this issue, it is possible\nto use agent-oriented software engineering (AOSE) methodologies to design\ncomplex cyber-physical systems such as IoT-based systems. In this research, a\nsmart irrigation system is designed based on Prometheus AOSE methodology, to\nreduce water loss by maintaining soil moisture in a suitable interval. The\ndesigned system comprises sensors, a central agent, and irrigation nodes. These\nagents follow defined rules to maintain soil moisture at a desired level\ncooperatively. For system simulation, a hybrid agent-based and system dynamics\nmodel was designed. In this hybrid model, soil moisture dynamics were modeled\nbased on the system dynamics approach. The proposed model, was implemented in\nAnyLogic computer simulation software. Utilizing the simulation model,\nirrigation rules were examined. The system's functionality in automatic\nirrigation mode was tested based on a 256-run, fractional factorial design, and\nthe effects of important factors such as soil properties on total irrigated\nwater and total operation time were analyzed. Based on the tests, the system\nconsistently irrigated nearly optimal water amounts in all tests. Moreover, the\nresults were also used to minimize the system's energy consumption by reducing\nthe system's operational time.",
      "pdf_url": "http://arxiv.org/pdf/2502.18298v1",
      "published": "2025-02-25T15:34:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.18298v1",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.SY",
        "eess.SY",
        "stat.AP",
        "I.6.6, I.2.1, J.2"
      ]
    },
    {
      "title": "Mixing Any Cocktail with Limited Ingredients: On the Structure of Payoff Sets in Multi-Objective MDPs and its Impact on Randomised Strategies",
      "authors": [
        "James C. A. Main",
        "Mickael Randour"
      ],
      "abstract": "We consider multi-dimensional payoff functions in Markov decision processes,\nand ask whether a given expected payoff vector can be achieved or not. In\ngeneral, pure strategies (i.e., not resorting to randomisation) do not suffice\nfor this problem.\n  We study the structure of the set of expected payoff vectors of all\nstrategies given a multi-dimensional payoff function and its consequences\nregarding randomisation requirements for strategies. In particular, we prove\nthat for any payoff for which the expectation is well-defined under all\nstrategies, it is sufficient to mix (i.e., randomly select a pure strategy at\nthe start of a play and committing to it for the rest of the play) finitely\nmany pure strategies to approximate any expected payoff vector up to any\nprecision. Furthermore, for any payoff for which the expected payoff is finite\nunder all strategies, any expected payoff can be obtained exactly by mixing\nfinitely many strategies.",
      "pdf_url": "http://arxiv.org/pdf/2502.18296v1",
      "published": "2025-02-25T15:33:59+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.18296v1",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.FL",
        "cs.LO",
        "math.PR"
      ]
    },
    {
      "title": "AMPO: Active Multi-Preference Optimization",
      "authors": [
        "Taneesh Gupta",
        "Rahul Madhavan",
        "Xuchao Zhang",
        "Chetan Bansal",
        "Saravan Rajmohan"
      ],
      "abstract": "Multi-preference optimization enriches language-model alignment beyond\npairwise preferences by contrasting entire sets of helpful and undesired\nresponses, thereby enabling richer training signals for large language models.\nDuring self-play alignment, these models often produce numerous candidate\nanswers per query, rendering it computationally infeasible to include all\nresponses in the training objective. In this work, we propose $\\textit{Active\nMulti-Preference Optimization}$ (AMPO), a novel approach that combines\non-policy generation, a multi-preference group-contrastive loss, and active\nsubset selection. Specifically, we score and embed large candidate pools of\nresponses and then select a small, yet informative, subset that covers reward\nextremes and distinct semantic clusters for preference optimization. Our\ncontrastive training scheme is capable of identifying not only the best and\nworst answers but also subtle, underexplored modes that are crucial for robust\nalignment. Theoretically, we provide guarantees for expected reward\nmaximization using our active selection method, and empirically, AMPO achieves\nstate-of-the-art results on $\\textit{AlpacaEval}$ using Llama 8B.",
      "pdf_url": "http://arxiv.org/pdf/2502.18293v1",
      "published": "2025-02-25T15:29:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.18293v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Citrus: Leveraging Expert Cognitive Pathways in a Medical Language Model for Advanced Medical Decision Support",
      "authors": [
        "Guoxin Wang",
        "Minyu Gao",
        "Shuai Yang",
        "Ya Zhang",
        "Lizhi He",
        "Liang Huang",
        "Hanlin Xiao",
        "Yexuan Zhang",
        "Wanyue Li",
        "Lu Chen",
        "Jintao Fei",
        "Xin Li"
      ],
      "abstract": "Large language models (LLMs), particularly those with reasoning capabilities,\nhave rapidly advanced in recent years, demonstrating significant potential\nacross a wide range of applications. However, their deployment in healthcare,\nespecially in disease reasoning tasks, is hindered by the challenge of\nacquiring expert-level cognitive data. In this paper, we introduce Citrus, a\nmedical language model that bridges the gap between clinical expertise and AI\nreasoning by emulating the cognitive processes of medical experts. The model is\ntrained on a large corpus of simulated expert disease reasoning data,\nsynthesized using a novel approach that accurately captures the decision-making\npathways of clinicians. This approach enables Citrus to better simulate the\ncomplex reasoning processes involved in diagnosing and treating medical\nconditions.To further address the lack of publicly available datasets for\nmedical reasoning tasks, we release the last-stage training data, including a\ncustom-built medical diagnostic dialogue dataset. This open-source contribution\naims to support further research and development in the field. Evaluations\nusing authoritative benchmarks such as MedQA, covering tasks in medical\nreasoning and language understanding, show that Citrus achieves superior\nperformance compared to other models of similar size. These results highlight\nCitrus potential to significantly enhance medical decision support systems,\nproviding a more accurate and efficient tool for clinical decision-making.",
      "pdf_url": "http://arxiv.org/pdf/2502.18274v1",
      "published": "2025-02-25T15:05:12+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.18274v1",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "UASTrack: A Unified Adaptive Selection Framework with Modality-Customization in Single Object Tracking",
      "authors": [
        "He Wang",
        "Tianyang Xu",
        "Zhangyong Tang",
        "Xiao-Jun Wu",
        "Josef Kittler"
      ],
      "abstract": "Multi-modal tracking is essential in single-object tracking (SOT), as\ndifferent sensor types contribute unique capabilities to overcome challenges\ncaused by variations in object appearance. However, existing unified RGB-X\ntrackers (X represents depth, event, or thermal modality) either rely on the\ntask-specific training strategy for individual RGB-X image pairs or fail to\naddress the critical importance of modality-adaptive perception in real-world\napplications. In this work, we propose UASTrack, a unified adaptive selection\nframework that facilitates both model and parameter unification, as well as\nadaptive modality discrimination across various multi-modal tracking tasks. To\nachieve modality-adaptive perception in joint RGB-X pairs, we design a\nDiscriminative Auto-Selector (DAS) capable of identifying modality labels,\nthereby distinguishing the data distributions of auxiliary modalities.\nFurthermore, we propose a Task-Customized Optimization Adapter (TCOA) tailored\nto various modalities in the latent space. This strategy effectively filters\nnoise redundancy and mitigates background interference based on the specific\ncharacteristics of each modality. Extensive comparisons conducted on five\nbenchmarks including LasHeR, GTOT, RGBT234, VisEvent, and DepthTrack, covering\nRGB-T, RGB-E, and RGB-D tracking scenarios, demonstrate our innovative approach\nachieves comparative performance by introducing only additional training\nparameters of 1.87M and flops of 1.95G. The code will be available at\nhttps://github.com/wanghe/UASTrack.",
      "pdf_url": "http://arxiv.org/pdf/2502.18220v1",
      "published": "2025-02-25T14:04:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.18220v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "FLARE: A Framework for Stellar Flare Forecasting using Stellar Physical Properties and Historical Records",
      "authors": [
        "Bingke Zhu",
        "Xiaoxiao Wang",
        "Minghui Jia",
        "Yihan Tao",
        "Xiao Kong",
        "Ali Luo",
        "Yingying Chen",
        "Ming Tang",
        "Jinqiao Wang"
      ],
      "abstract": "Stellar flare events are critical observational samples for astronomical\nresearch; however, recorded flare events remain limited. Stellar flare\nforecasting can provide additional flare event samples to support research\nefforts. Despite this potential, no specialized models for stellar flare\nforecasting have been proposed to date. In this paper, we present extensive\nexperimental evidence demonstrating that both stellar physical properties and\nhistorical flare records are valuable inputs for flare forecasting tasks. We\nthen introduce FLARE (Forecasting Light-curve-based Astronomical Records via\nfeatures Ensemble), the first-of-its-kind large model specifically designed for\nstellar flare forecasting. FLARE integrates stellar physical properties and\nhistorical flare records through a novel Soft Prompt Module and Residual Record\nFusion Module. Our experiments on the publicly available Kepler light curve\ndataset demonstrate that FLARE achieves superior performance compared to other\nmethods across all evaluation metrics. Finally, we validate the forecast\ncapability of our model through a comprehensive case study.",
      "pdf_url": "http://arxiv.org/pdf/2502.18218v1",
      "published": "2025-02-25T14:03:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.18218v1",
      "categories": [
        "astro-ph.SR",
        "astro-ph.IM",
        "cs.AI"
      ]
    },
    {
      "title": "LAG: LLM agents for Leaderboard Auto Generation on Demanding",
      "authors": [
        "Jian Wu",
        "Jiayu Zhang",
        "Dongyuan Li",
        "Linyi Yang",
        "Aoxiao Zhong",
        "Renhe Jiang",
        "Qingsong Wen",
        "Yue Zhang"
      ],
      "abstract": "This paper introduces Leaderboard Auto Generation (LAG), a novel and\nwell-organized framework for automatic generation of leaderboards on a given\nresearch topic in rapidly evolving fields like Artificial Intelligence (AI).\nFaced with a large number of AI papers updated daily, it becomes difficult for\nresearchers to track every paper's proposed methods, experimental results, and\nsettings, prompting the need for efficient automatic leaderboard construction.\nWhile large language models (LLMs) offer promise in automating this process,\nchallenges such as multi-document summarization, leaderboard generation, and\nexperiment fair comparison still remain under exploration. LAG solves these\nchallenges through a systematic approach that involves the paper collection,\nexperiment results extraction and integration, leaderboard generation, and\nquality evaluation. Our contributions include a comprehensive solution to the\nleaderboard construction problem, a reliable evaluation method, and\nexperimental results showing the high quality of leaderboards.",
      "pdf_url": "http://arxiv.org/pdf/2502.18209v1",
      "published": "2025-02-25T13:54:03+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.18209v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "DenoMAE2.0: Improving Denoising Masked Autoencoders by Classifying Local Patches",
      "authors": [
        "Atik Faysal",
        "Mohammad Rostami",
        "Taha Boushine",
        "Reihaneh Gh. Roshan",
        "Huaxia Wang",
        "Nikhil Muralidhar"
      ],
      "abstract": "We introduce DenoMAE2.0, an enhanced denoising masked autoencoder that\nintegrates a local patch classification objective alongside traditional\nreconstruction loss to improve representation learning and robustness. Unlike\nconventional Masked Autoencoders (MAE), which focus solely on reconstructing\nmissing inputs, DenoMAE2.0 introduces position-aware classification of unmasked\npatches, enabling the model to capture fine-grained local features while\nmaintaining global coherence. This dual-objective approach is particularly\nbeneficial in semi-supervised learning for wireless communication, where high\nnoise levels and data scarcity pose significant challenges. We conduct\nextensive experiments on modulation signal classification across a wide range\nof signal-to-noise ratios (SNRs), from extremely low to moderately high\nconditions and in a low data regime. Our results demonstrate that DenoMAE2.0\nsurpasses its predecessor, Deno-MAE, and other baselines in both denoising\nquality and downstream classification accuracy. DenoMAE2.0 achieves a 1.1%\nimprovement over DenoMAE on our dataset and 11.83%, 16.55% significant improved\naccuracy gains on the RadioML benchmark, over DenoMAE, for constellation\ndiagram classification of modulation signals.",
      "pdf_url": "http://arxiv.org/pdf/2502.18202v1",
      "published": "2025-02-25T13:41:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.18202v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "VesselSAM: Leveraging SAM for Aortic Vessel Segmentation with LoRA and Atrous Attention",
      "authors": [
        "Adnan Iltaf",
        "Rayan Merghani Ahmed",
        "Bin Li",
        "Shoujun Zhou"
      ],
      "abstract": "Medical image segmentation is crucial for clinical diagnosis and treatment\nplanning, particularly for complex anatomical structures like vessels. In this\nwork, we propose VesselSAM, a modified version of the Segmentation Anything\nModel (SAM), specifically designed for aortic vessel segmentation. VesselSAM\nincorporates AtrousLoRA, a novel module that combines Atrous Attention with\nLow-Rank Adaptation (LoRA), to improve segmentation performance. Atrous\nAttention enables the model to capture multi-scale contextual information,\npreserving both fine local details and broader global context. At the same\ntime, LoRA facilitates efficient fine-tuning of the frozen SAM image encoder,\nreducing the number of trainable parameters and ensuring computational\nefficiency. We evaluate VesselSAM on two challenging datasets: the Aortic\nVessel Tree (AVT) dataset and the Type-B Aortic Dissection (TBAD) dataset.\nVesselSAM achieves state-of-the-art performance with DSC scores of 93.50\\%,\n93.25\\%, 93.02\\%, and 93.26\\% across multiple medical centers. Our results\ndemonstrate that VesselSAM delivers high segmentation accuracy while\nsignificantly reducing computational overhead compared to existing large-scale\nmodels. This development paves the way for enhanced AI-based aortic vessel\nsegmentation in clinical environments. The code and models will be released at\nhttps://github.com/Adnan-CAS/AtrousLora.",
      "pdf_url": "http://arxiv.org/pdf/2502.18185v1",
      "published": "2025-02-25T13:26:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.18185v1",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "ChatMotion: A Multimodal Multi-Agent for Human Motion Analysis",
      "authors": [
        "Li Lei",
        "Jia Sen",
        "Wang Jianhao",
        "An Zhaochong",
        "Li Jiaang",
        "Hwang Jenq-Neng",
        "Belongie Serge"
      ],
      "abstract": "Advancements in Multimodal Large Language Models (MLLMs) have improved human\nmotion understanding. However, these models remain constrained by their\n\"instruct-only\" nature, lacking interactivity and adaptability for diverse\nanalytical perspectives. To address these challenges, we introduce ChatMotion,\na multimodal multi-agent framework for human motion analysis. ChatMotion\ndynamically interprets user intent, decomposes complex tasks into meta-tasks,\nand activates specialized function modules for motion comprehension. It\nintegrates multiple specialized modules, such as the MotionCore, to analyze\nhuman motion from various perspectives. Extensive experiments demonstrate\nChatMotion's precision, adaptability, and user engagement for human motion\nunderstanding.",
      "pdf_url": "http://arxiv.org/pdf/2502.18180v1",
      "published": "2025-02-25T13:12:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.18180v1",
      "categories": [
        "cs.AI",
        "cs.MA"
      ]
    },
    {
      "title": "Problem Solved? Information Extraction Design Space for Layout-Rich Documents using LLMs",
      "authors": [
        "Gaye Colakoglu",
        "Grkan Solmaz",
        "Jonathan Frst"
      ],
      "abstract": "This paper defines and explores the design space for information extraction\n(IE) from layout-rich documents using large language models (LLMs). The three\ncore challenges of layout-aware IE with LLMs are 1) data structuring, 2) model\nengagement, and 3) output refinement. Our study delves into the sub-problems\nwithin these core challenges, such as input representation, chunking,\nprompting, and selection of LLMs and multimodal models. It examines the\noutcomes of different design choices through a new layout-aware IE test suite,\nbenchmarking against the state-of-art (SoA) model LayoutLMv3. The results show\nthat the configuration from one-factor-at-a-time (OFAT) trial achieves\nnear-optimal results with 14.1 points F1-score gain from the baseline model,\nwhile full factorial exploration yields only a slightly higher 15.1 points gain\nat around 36x greater token usage. We demonstrate that well-configured\ngeneral-purpose LLMs can match the performance of specialized models, providing\na cost-effective alternative. Our test-suite is freely available at\nhttps://github.com/gayecolakoglu/LayIE-LLM.",
      "pdf_url": "http://arxiv.org/pdf/2502.18179v1",
      "published": "2025-02-25T13:11:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.18179v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "CLIPure: Purification in Latent Space via CLIP for Adversarially Robust Zero-Shot Classification",
      "authors": [
        "Mingkun Zhang",
        "Keping Bi",
        "Wei Chen",
        "Jiafeng Guo",
        "Xueqi Cheng"
      ],
      "abstract": "In this paper, we aim to build an adversarially robust zero-shot image\nclassifier. We ground our work on CLIP, a vision-language pre-trained encoder\nmodel that can perform zero-shot classification by matching an image with text\nprompts ``a photo of a <class-name>.''. Purification is the path we choose\nsince it does not require adversarial training on specific attack types and\nthus can cope with any foreseen attacks. We then formulate purification risk as\nthe KL divergence between the joint distributions of the purification process\nof denoising the adversarial samples and the attack process of adding\nperturbations to benign samples, through bidirectional Stochastic Differential\nEquations (SDEs). The final derived results inspire us to explore purification\nin the multi-modal latent space of CLIP. We propose two variants for our\nCLIPure approach: CLIPure-Diff which models the likelihood of images' latent\nvectors with the DiffusionPrior module in DaLLE-2 (modeling the generation\nprocess of CLIP's latent vectors), and CLIPure-Cos which models the likelihood\nwith the cosine similarity between the embeddings of an image and ``a photo of\na.''. As far as we know, CLIPure is the first purification method in\nmulti-modal latent space and CLIPure-Cos is the first purification method that\nis not based on generative models, which substantially improves defense\nefficiency. We conducted extensive experiments on CIFAR-10, ImageNet, and 13\ndatasets that previous CLIP-based defense methods used for evaluating zero-shot\nclassification robustness. Results show that CLIPure boosts the SOTA robustness\nby a large margin, e.g., from 71.7% to 91.1% on CIFAR10, from 59.6% to 72.6% on\nImageNet, and 108% relative improvements of average robustness on the 13\ndatasets over previous SOTA. The code is available at\nhttps://github.com/TMLResearchGroup-CAS/CLIPure.",
      "pdf_url": "http://arxiv.org/pdf/2502.18176v1",
      "published": "2025-02-25T13:09:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.18176v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "SECURA: Sigmoid-Enhanced CUR Decomposition with Uninterrupted Retention and Low-Rank Adaptation in Large Language Models",
      "authors": [
        "Zhang Yuxuan",
        "Li Ruizhe"
      ],
      "abstract": "With the rapid development of large language models (LLMs), fully fine-tuning\n(FT) these models has become increasingly impractical due to the high\ncomputational demands. Additionally, FT can lead to catastrophic forgetting. As\nan alternative, Low-Rank Adaptation (LoRA) has been proposed, which fine-tunes\nonly a small subset of parameters, achieving similar performance to FT while\nsignificantly reducing resource requirements. However, since LoRA inherits FT's\ndesign, the issue of catastrophic forgetting remains.\n  To address these challenges, we propose SECURA: Sigmoid-Enhanced CUR\nDecomposition LoRA, a novel parameter-efficient fine-tuning (PEFT) variant that\nmitigates catastrophic forgetting while improving fine-tuning performance. Our\nmethod introduces a new normalization technique, SigNorm, to enhance parameter\nretention and overall performance.\n  SECURA has been evaluated on a variety of tasks, including mathematical\nproblem-solving (GSM8K), challenging question-answering (CNNDM), translation\n(NewsDE), and complex multiple-choice reasoning (LogiQA). Experimental results\nshow that SECURA achieves an average fine-tuning improvement of 3.59% across\nfour multiple-choice question (MCQ) tasks and a 2.51% improvement across five\nquestion-answering (QA) tasks on models such as Gemma2 2b, Qwen2 1.5b, Qwen 2\n7b, Llama3 8b, and Llama3.1 8b, compared to DoRA. Moreover, SECURA demonstrates\nsuperior knowledge retention capabilities, maintaining more than 70% accuracy\non basic LLM knowledge across 16 continual learning tests, outperforming\nExperience Replay (ER), Sequential Learning (SEQ), EWC, I-LoRA, and CUR-LoRA.",
      "pdf_url": "http://arxiv.org/pdf/2502.18168v1",
      "published": "2025-02-25T13:00:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.18168v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.6; I.2.7"
      ]
    },
    {
      "title": "iTrash: Incentivized Token Rewards for Automated Sorting and Handling",
      "authors": [
        "Pablo Ortega",
        "Eduardo Castell Ferrer"
      ],
      "abstract": "As robotic systems (RS) become more autonomous, they are becoming\nincreasingly used in small spaces and offices to automate tasks such as\ncleaning, infrastructure maintenance, or resource management. In this paper, we\npropose iTrash, an intelligent trashcan that aims to improve recycling rates in\nsmall office spaces. For that, we ran a 5 day experiment and found that iTrash\ncan produce an efficiency increase of more than 30% compared to traditional\ntrashcans. The findings derived from this work, point to the fact that using\niTrash not only increase recyclying rates, but also provides valuable data such\nas users behaviour or bin usage patterns, which cannot be taken from a normal\ntrashcan. This information can be used to predict and optimize some tasks in\nthese spaces. Finally, we explored the potential of using blockchain technology\nto create economic incentives for recycling, following a Save-as-you-Throw\n(SAYT) model.",
      "pdf_url": "http://arxiv.org/pdf/2502.18161v1",
      "published": "2025-02-25T12:46:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.18161v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.ET",
        "I.2.9; I.2.10"
      ]
    },
    {
      "title": "Monitoring snow avalanches from SAR data with deep learning",
      "authors": [
        "Filippo Maria Bianchi",
        "Jakob Grahn"
      ],
      "abstract": "Snow avalanches present significant risks to human life and infrastructure,\nparticularly in mountainous regions, making effective monitoring crucial.\nTraditional monitoring methods, such as field observations, are limited by\naccessibility, weather conditions, and cost. Satellite-borne Synthetic Aperture\nRadar (SAR) data has become an important tool for large-scale avalanche\ndetection, as it can capture data in all weather conditions and across remote\nareas. However, traditional processing methods struggle with the complexity and\nvariability of avalanches. This chapter reviews the application of deep\nlearning for detecting and segmenting snow avalanches from SAR data. Early\nefforts focused on the binary classification of SAR images, while recent\nadvances have enabled pixel-level segmentation, providing greater accuracy and\nspatial resolution. A case study using Sentinel-1 SAR data demonstrates the\neffectiveness of deep learning models for avalanche segmentation, achieving\nsuperior results over traditional methods. We also present an extension of this\nwork, testing recent state-of-the-art segmentation architectures on an expanded\ndataset of over 4,500 annotated SAR images. The best-performing model among\nthose tested was applied for large-scale avalanche detection across the whole\nof Norway, revealing important spatial and temporal patterns over several\nwinter seasons.",
      "pdf_url": "http://arxiv.org/pdf/2502.18157v1",
      "published": "2025-02-25T12:41:08+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.18157v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ]
    },
    {
      "title": "Can LLMs Explain Themselves Counterfactually?",
      "authors": [
        "Zahra Dehghanighobadi",
        "Asja Fischer",
        "Muhammad Bilal Zafar"
      ],
      "abstract": "Explanations are an important tool for gaining insights into the behavior of\nML models, calibrating user trust and ensuring regulatory compliance. Past few\nyears have seen a flurry of post-hoc methods for generating model explanations,\nmany of which involve computing model gradients or solving specially designed\noptimization problems. However, owing to the remarkable reasoning abilities of\nLarge Language Model (LLMs), self-explanation, that is, prompting the model to\nexplain its outputs has recently emerged as a new paradigm. In this work, we\nstudy a specific type of self-explanations, self-generated counterfactual\nexplanations (SCEs). We design tests for measuring the efficacy of LLMs in\ngenerating SCEs. Analysis over various LLM families, model sizes, temperature\nsettings, and datasets reveals that LLMs sometimes struggle to generate SCEs.\nEven when they do, their prediction often does not agree with their own\ncounterfactual reasoning.",
      "pdf_url": "http://arxiv.org/pdf/2502.18156v1",
      "published": "2025-02-25T12:40:41+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.18156v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "SASSHA: Sharpness-aware Adaptive Second-order Optimization with Stable Hessian Approximation",
      "authors": [
        "Dahun Shin",
        "Dongyeop Lee",
        "Jinseok Chung",
        "Namhoon Lee"
      ],
      "abstract": "Approximate second-order optimization methods often exhibit poorer\ngeneralization compared to first-order approaches. In this work, we look into\nthis issue through the lens of the loss landscape and find that existing\nsecond-order methods tend to converge to sharper minima compared to SGD. In\nresponse, we propose Sassha, a novel second-order method designed to enhance\ngeneralization by explicitly reducing sharpness of the solution, while\nstabilizing the computation of approximate Hessians along the optimization\ntrajectory. In fact, this sharpness minimization scheme is crafted also to\naccommodate lazy Hessian updates, so as to secure efficiency besides flatness.\nTo validate its effectiveness, we conduct a wide range of standard deep\nlearning experiments where Sassha demonstrates its outstanding generalization\nperformance that is comparable to, and mostly better than, other methods. We\nprovide a comprehensive set of analyses including convergence, robustness,\nstability, efficiency, and cost.",
      "pdf_url": "http://arxiv.org/pdf/2502.18153v1",
      "published": "2025-02-25T12:35:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.18153v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "A Real-time Spatio-Temporal Trajectory Planner for Autonomous Vehicles with Semantic Graph Optimization",
      "authors": [
        "Shan He",
        "Yalong Ma",
        "Tao Song",
        "Yongzhi Jiang",
        "Xinkai Wu"
      ],
      "abstract": "Planning a safe and feasible trajectory for autonomous vehicles in real-time\nby fully utilizing perceptual information in complex urban environments is\nchallenging. In this paper, we propose a spatio-temporal trajectory planning\nmethod based on graph optimization. It efficiently extracts the multi-modal\ninformation of the perception module by constructing a semantic spatio-temporal\nmap through separation processing of static and dynamic obstacles, and then\nquickly generates feasible trajectories via sparse graph optimization based on\na semantic spatio-temporal hypergraph. Extensive experiments have proven that\nthe proposed method can effectively handle complex urban public road scenarios\nand perform in real time. We will also release our codes to accommodate\nbenchmarking for the research community",
      "pdf_url": "http://arxiv.org/pdf/2502.18151v1",
      "published": "2025-02-25T12:27:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.18151v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "Jacobian Sparse Autoencoders: Sparsify Computations, Not Just Activations",
      "authors": [
        "Lucy Farnik",
        "Tim Lawson",
        "Conor Houghton",
        "Laurence Aitchison"
      ],
      "abstract": "Sparse autoencoders (SAEs) have been successfully used to discover sparse and\nhuman-interpretable representations of the latent activations of LLMs. However,\nwe would ultimately like to understand the computations performed by LLMs and\nnot just their representations. The extent to which SAEs can help us understand\ncomputations is unclear because they are not designed to \"sparsify\"\ncomputations in any sense, only latent activations. To solve this, we propose\nJacobian SAEs (JSAEs), which yield not only sparsity in the input and output\nactivations of a given model component but also sparsity in the computation\n(formally, the Jacobian) connecting them. With a na\\\"ive implementation, the\nJacobians in LLMs would be computationally intractable due to their size. One\nkey technical contribution is thus finding an efficient way of computing\nJacobians in this setup. We find that JSAEs extract a relatively large degree\nof computational sparsity while preserving downstream LLM performance\napproximately as well as traditional SAEs. We also show that Jacobians are a\nreasonable proxy for computational sparsity because MLPs are approximately\nlinear when rewritten in the JSAE basis. Lastly, we show that JSAEs achieve a\ngreater degree of computational sparsity on pre-trained LLMs than on the\nequivalent randomized LLM. This shows that the sparsity of the computational\ngraph appears to be a property that LLMs learn through training, and suggests\nthat JSAEs might be more suitable for understanding learned transformer\ncomputations than standard SAEs.",
      "pdf_url": "http://arxiv.org/pdf/2502.18147v1",
      "published": "2025-02-25T12:21:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.18147v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Large Language Model Driven Agents for Simulating Echo Chamber Formation",
      "authors": [
        "Chenhao Gu",
        "Ling Luo",
        "Zainab Razia Zaidi",
        "Shanika Karunasekera"
      ],
      "abstract": "The rise of echo chambers on social media platforms has heightened concerns\nabout polarization and the reinforcement of existing beliefs. Traditional\napproaches for simulating echo chamber formation have often relied on\npredefined rules and numerical simulations, which, while insightful, may lack\nthe nuance needed to capture complex, real-world interactions. In this paper,\nwe present a novel framework that leverages large language models (LLMs) as\ngenerative agents to simulate echo chamber dynamics within social networks. The\nnovelty of our approach is that it incorporates both opinion updates and\nnetwork rewiring behaviors driven by LLMs, allowing for a context-aware and\nsemantically rich simulation of social interactions. Additionally, we utilize\nreal-world Twitter (now X) data to benchmark the LLM-based simulation against\nactual social media behaviors, providing insights into the accuracy and realism\nof the generated opinion trends. Our results demonstrate the efficacy of LLMs\nin modeling echo chamber formation, capturing both structural and semantic\ndimensions of opinion clustering. %This work contributes to a deeper\nunderstanding of social influence dynamics and offers a new tool for studying\npolarization in online communities.",
      "pdf_url": "http://arxiv.org/pdf/2502.18138v1",
      "published": "2025-02-25T12:05:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.18138v1",
      "categories": [
        "cs.SI",
        "cs.AI"
      ]
    },
    {
      "title": "SpargeAttn: Accurate Sparse Attention Accelerating Any Model Inference",
      "authors": [
        "Jintao Zhang",
        "Chendong Xiang",
        "Haofeng Huang",
        "Jia Wei",
        "Haocheng Xi",
        "Jun Zhu",
        "Jianfei Chen"
      ],
      "abstract": "An efficient attention implementation is essential for large models due to\nits quadratic time complexity. Fortunately, attention commonly exhibits\nsparsity, i.e., many values in the attention map are near zero, allowing for\nthe omission of corresponding computations. Many studies have utilized the\nsparse pattern to accelerate attention. However, most existing works focus on\noptimizing attention within specific models by exploiting certain sparse\npatterns of the attention map. A universal sparse attention that guarantees\nboth the speedup and end-to-end performance of diverse models remains elusive.\nIn this paper, we propose SpargeAttn, a universal sparse and quantized\nattention for any model. Our method uses a two-stage online filter: in the\nfirst stage, we rapidly and accurately predict the attention map, enabling the\nskip of some matrix multiplications in attention. In the second stage, we\ndesign an online softmax-aware filter that incurs no extra overhead and further\nskips some matrix multiplications. Experiments show that our method\nsignificantly accelerates diverse models, including language, image, and video\ngeneration, without sacrificing end-to-end metrics. The codes are available at\nhttps://github.com/thu-ml/SpargeAttn.",
      "pdf_url": "http://arxiv.org/pdf/2502.18137v1",
      "published": "2025-02-25T12:02:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.18137v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.PF"
      ]
    },
    {
      "title": "EU-Nets: Enhanced, Explainable and Parsimonious U-Nets",
      "authors": [
        "B. Sun",
        "P. Li"
      ],
      "abstract": "In this study, we propose MHEX+, a framework adaptable to any U-Net\narchitecture. Built upon MHEX+, we introduce novel U-Net variants, EU-Nets,\nwhich enhance explainability and uncertainty estimation, addressing the\nlimitations of traditional U-Net models while improving performance and\nstability. A key innovation is the Equivalent Convolutional Kernel, which\nunifies consecutive convolutional layers, boosting interpretability. For\nuncertainty estimation, we propose the collaboration gradient approach,\nmeasuring gradient consistency across decoder layers. Notably, EU-Nets achieve\nan average accuracy improvement of 1.389\\% and a variance reduction of 0.83\\%\nacross all networks and datasets in our experiments, requiring fewer than 0.1M\nparameters.",
      "pdf_url": "http://arxiv.org/pdf/2502.18122v1",
      "published": "2025-02-25T11:44:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.18122v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Bayesian Optimization for Controlled Image Editing via LLMs",
      "authors": [
        "Chengkun Cai",
        "Haoliang Liu",
        "Xu Zhao",
        "Zhongyu Jiang",
        "Tianfang Zhang",
        "Zongkai Wu",
        "Jenq-Neng Hwang",
        "Serge Belongie",
        "Lei Li"
      ],
      "abstract": "In the rapidly evolving field of image generation, achieving precise control\nover generated content and maintaining semantic consistency remain significant\nlimitations, particularly concerning grounding techniques and the necessity for\nmodel fine-tuning. To address these challenges, we propose BayesGenie, an\noff-the-shelf approach that integrates Large Language Models (LLMs) with\nBayesian Optimization to facilitate precise and user-friendly image editing.\nOur method enables users to modify images through natural language descriptions\nwithout manual area marking, while preserving the original image's semantic\nintegrity. Unlike existing techniques that require extensive pre-training or\nfine-tuning, our approach demonstrates remarkable adaptability across various\nLLMs through its model-agnostic design. BayesGenie employs an adapted Bayesian\noptimization strategy to automatically refine the inference process parameters,\nachieving high-precision image editing with minimal user intervention. Through\nextensive experiments across diverse scenarios, we demonstrate that our\nframework significantly outperforms existing methods in both editing accuracy\nand semantic preservation, as validated using different LLMs including Claude3\nand GPT-4.",
      "pdf_url": "http://arxiv.org/pdf/2502.18116v1",
      "published": "2025-02-25T11:41:33+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.18116v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "The Built-In Robustness of Decentralized Federated Averaging to Bad Data",
      "authors": [
        "Samuele Sabella",
        "Chiara Boldrini",
        "Lorenzo Valerio",
        "Andrea Passarella",
        "Marco Conti"
      ],
      "abstract": "Decentralized federated learning (DFL) enables devices to collaboratively\ntrain models over complex network topologies without relying on a central\ncontroller. In this setting, local data remains private, but its quality and\nquantity can vary significantly across nodes. The extent to which a fully\ndecentralized system is vulnerable to poor-quality or corrupted data remains\nunclear, but several factors could contribute to potential risks. Without a\ncentral authority, there can be no unified mechanism to detect or correct\nerrors, and each node operates with a localized view of the data distribution,\nmaking it difficult for the node to assess whether its perspective aligns with\nthe true distribution. Moreover, models trained on low-quality data can\npropagate through the network, amplifying errors. To explore the impact of\nlow-quality data on DFL, we simulate two scenarios with degraded data quality\n-- one where the corrupted data is evenly distributed in a subset of nodes and\none where it is concentrated on a single node -- using a decentralized\nimplementation of FedAvg. Our results reveal that averaging-based decentralized\nlearning is remarkably robust to localized bad data, even when the corrupted\ndata resides in the most influential nodes of the network. Counterintuitively,\nthis robustness is further enhanced when the corrupted data is concentrated on\na single node, regardless of its centrality in the communication network\ntopology. This phenomenon is explained by the averaging process, which ensures\nthat no single node -- however central -- can disproportionately influence the\noverall learning process.",
      "pdf_url": "http://arxiv.org/pdf/2502.18097v1",
      "published": "2025-02-25T11:06:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.18097v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ]
    },
    {
      "title": "Towards Thinking-Optimal Scaling of Test-Time Compute for LLM Reasoning",
      "authors": [
        "Wenkai Yang",
        "Shuming Ma",
        "Yankai Lin",
        "Furu Wei"
      ],
      "abstract": "Recent studies have shown that making a model spend more time thinking\nthrough longer Chain of Thoughts (CoTs) enables it to gain significant\nimprovements in complex reasoning tasks. While current researches continue to\nexplore the benefits of increasing test-time compute by extending the CoT\nlengths of Large Language Models (LLMs), we are concerned about a potential\nissue hidden behind the current pursuit of test-time scaling: Would excessively\nscaling the CoT length actually bring adverse effects to a model's reasoning\nperformance? Our explorations on mathematical reasoning tasks reveal an\nunexpected finding that scaling with longer CoTs can indeed impair the\nreasoning performance of LLMs in certain domains. Moreover, we discover that\nthere exists an optimal scaled length distribution that differs across\ndifferent domains. Based on these insights, we propose a Thinking-Optimal\nScaling strategy. Our method first uses a small set of seed data with varying\nresponse length distributions to teach the model to adopt different reasoning\nefforts for deep thinking. Then, the model selects its shortest correct\nresponse under different reasoning efforts on additional problems for\nself-improvement. Our self-improved models built upon Qwen2.5-32B-Instruct\noutperform other distillation-based 32B o1-like models across various math\nbenchmarks, and achieve performance on par with QwQ-32B-Preview.",
      "pdf_url": "http://arxiv.org/pdf/2502.18080v1",
      "published": "2025-02-25T10:48:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.18080v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "MRBTP: Efficient Multi-Robot Behavior Tree Planning and Collaboration",
      "authors": [
        "Yishuai Cai",
        "Xinglin Chen",
        "Zhongxuan Cai",
        "Yunxin Mao",
        "Minglong Li",
        "Wenjing Yang",
        "Ji Wang"
      ],
      "abstract": "Multi-robot task planning and collaboration are critical challenges in\nrobotics. While Behavior Trees (BTs) have been established as a popular control\narchitecture and are plannable for a single robot, the development of effective\nmulti-robot BT planning algorithms remains challenging due to the complexity of\ncoordinating diverse action spaces. We propose the Multi-Robot Behavior Tree\nPlanning (MRBTP) algorithm, with theoretical guarantees of both soundness and\ncompleteness. MRBTP features cross-tree expansion to coordinate heterogeneous\nactions across different BTs to achieve the team's goal. For homogeneous\nactions, we retain backup structures among BTs to ensure robustness and prevent\nredundant execution through intention sharing. While MRBTP is capable of\ngenerating BTs for both homogeneous and heterogeneous robot teams, its\nefficiency can be further improved. We then propose an optional plugin for\nMRBTP when Large Language Models (LLMs) are available to reason goal-related\nactions for each robot. These relevant actions can be pre-planned to form\nlong-horizon subtrees, significantly enhancing the planning speed and\ncollaboration efficiency of MRBTP. We evaluate our algorithm in warehouse\nmanagement and everyday service scenarios. Results demonstrate MRBTP's\nrobustness and execution efficiency under varying settings, as well as the\nability of the pre-trained LLM to generate effective task-specific subtrees for\nMRBTP.",
      "pdf_url": "http://arxiv.org/pdf/2502.18072v1",
      "published": "2025-02-25T10:39:28+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.18072v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.MA"
      ]
    },
    {
      "title": "HEROS-GAN: Honed-Energy Regularized and Optimal Supervised GAN for Enhancing Accuracy and Range of Low-Cost Accelerometers",
      "authors": [
        "Yifeng Wang",
        "Yi Zhao"
      ],
      "abstract": "Low-cost accelerometers play a crucial role in modern society due to their\nadvantages of small size, ease of integration, wearability, and mass\nproduction, making them widely applicable in automotive systems, aerospace, and\nwearable technology. However, this widely used sensor suffers from severe\naccuracy and range limitations. To this end, we propose a honed-energy\nregularized and optimal supervised GAN (HEROS-GAN), which transforms low-cost\nsensor signals into high-cost equivalents, thereby overcoming the precision and\nrange limitations of low-cost accelerometers. Due to the lack of frame-level\npaired low-cost and high-cost signals for training, we propose an Optimal\nTransport Supervision (OTS), which leverages optimal transport theory to\nexplore potential consistency between unpaired data, thereby maximizing\nsupervisory information. Moreover, we propose a Modulated Laplace Energy (MLE),\nwhich injects appropriate energy into the generator to encourage it to break\nrange limitations, enhance local changes, and enrich signal details. Given the\nabsence of a dedicated dataset, we specifically establish a Low-cost\nAccelerometer Signal Enhancement Dataset (LASED) containing tens of thousands\nof samples, which is the first dataset serving to improve the accuracy and\nrange of accelerometers and is released in Github. Experimental results\ndemonstrate that a GAN combined with either OTS or MLE alone can surpass the\nprevious signal enhancement SOTA methods by an order of magnitude. Integrating\nboth OTS and MLE, the HEROS-GAN achieves remarkable results, which doubles the\naccelerometer range while reducing signal noise by two orders of magnitude,\nestablishing a benchmark in the accelerometer signal processing.",
      "pdf_url": "http://arxiv.org/pdf/2502.18064v1",
      "published": "2025-02-25T10:31:01+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.18064v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO",
        "eess.SP",
        "math.PR"
      ]
    },
    {
      "title": "Defining bias in AI-systems: Biased models are fair models",
      "authors": [
        "Chiara Lindloff",
        "Ingo Siegert"
      ],
      "abstract": "The debate around bias in AI systems is central to discussions on algorithmic\nfairness. However, the term bias often lacks a clear definition, despite\nfrequently being contrasted with fairness, implying that an unbiased model is\ninherently fair. In this paper, we challenge this assumption and argue that a\nprecise conceptualization of bias is necessary to effectively address fairness\nconcerns. Rather than viewing bias as inherently negative or unfair, we\nhighlight the importance of distinguishing between bias and discrimination. We\nfurther explore how this shift in focus can foster a more constructive\ndiscourse within academic debates on fairness in AI systems.",
      "pdf_url": "http://arxiv.org/pdf/2502.18060v1",
      "published": "2025-02-25T10:28:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.18060v1",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ]
    },
    {
      "title": "VLM-E2E: Enhancing End-to-End Autonomous Driving with Multimodal Driver Attention Fusion",
      "authors": [
        "Pei Liu",
        "Haipeng Liu",
        "Haichao Liu",
        "Xin Liu",
        "Jinxin Ni",
        "Jun Ma"
      ],
      "abstract": "Human drivers adeptly navigate complex scenarios by utilizing rich\nattentional semantics, but the current autonomous systems struggle to replicate\nthis ability, as they often lose critical semantic information when converting\n2D observations into 3D space. In this sense, it hinders their effective\ndeployment in dynamic and complex environments. Leveraging the superior scene\nunderstanding and reasoning abilities of Vision-Language Models (VLMs), we\npropose VLM-E2E, a novel framework that uses the VLMs to enhance training by\nproviding attentional cues. Our method integrates textual representations into\nBird's-Eye-View (BEV) features for semantic supervision, which enables the\nmodel to learn richer feature representations that explicitly capture the\ndriver's attentional semantics. By focusing on attentional semantics, VLM-E2E\nbetter aligns with human-like driving behavior, which is critical for\nnavigating dynamic and complex environments. Furthermore, we introduce a\nBEV-Text learnable weighted fusion strategy to address the issue of modality\nimportance imbalance in fusing multimodal information. This approach\ndynamically balances the contributions of BEV and text features, ensuring that\nthe complementary information from visual and textual modality is effectively\nutilized. By explicitly addressing the imbalance in multimodal fusion, our\nmethod facilitates a more holistic and robust representation of driving\nenvironments. We evaluate VLM-E2E on the nuScenes dataset and demonstrate its\nsuperiority over state-of-the-art approaches, showcasing significant\nimprovements in performance.",
      "pdf_url": "http://arxiv.org/pdf/2502.18042v1",
      "published": "2025-02-25T10:02:12+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.18042v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "AutoCas: Autoregressive Cascade Predictor in Social Networks via Large Language Models",
      "authors": [
        "Yuhao Zheng",
        "Chenghua Gong",
        "Rui Sun",
        "Juyuan Zhang",
        "Liming Pan",
        "Linyuan Lv"
      ],
      "abstract": "Popularity prediction in information cascades plays a crucial role in social\ncomputing, with broad applications in viral marketing, misinformation control,\nand content recommendation. However, information propagation mechanisms, user\nbehavior, and temporal activity patterns exhibit significant diversity,\nnecessitating a foundational model capable of adapting to such variations. At\nthe same time, the amount of available cascade data remains relatively limited\ncompared to the vast datasets used for training large language models (LLMs).\nRecent studies have demonstrated the feasibility of leveraging LLMs for\ntime-series prediction by exploiting commonalities across different time-series\ndomains. Building on this insight, we introduce the Autoregressive Information\nCascade Predictor (AutoCas), an LLM-enhanced model designed specifically for\ncascade popularity prediction. Unlike natural language sequences, cascade data\nis characterized by complex local topologies, diffusion contexts, and evolving\ndynamics, requiring specialized adaptations for effective LLM integration. To\naddress these challenges, we first tokenize cascade data to align it with\nsequence modeling principles. Next, we reformulate cascade diffusion as an\nautoregressive modeling task to fully harness the architectural strengths of\nLLMs. Beyond conventional approaches, we further introduce prompt learning to\nenhance the synergy between LLMs and cascade prediction. Extensive experiments\ndemonstrate that AutoCas significantly outperforms baseline models in cascade\npopularity prediction while exhibiting scaling behavior inherited from LLMs.\nCode is available at this repository:\nhttps://anonymous.4open.science/r/AutoCas-85C6",
      "pdf_url": "http://arxiv.org/pdf/2502.18040v1",
      "published": "2025-02-25T09:54:33+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.18040v1",
      "categories": [
        "cs.SI",
        "cs.AI"
      ]
    },
    {
      "title": "ExPath: Towards Explaining Targeted Pathways for Biological Knowledge Bases",
      "authors": [
        "Rikuto Kotoge",
        "Ziwei Yang",
        "Zheng Chen",
        "Yushun Dong",
        "Yasuko Matsubara",
        "Jimeng Sun",
        "Yasushi Sakurai"
      ],
      "abstract": "Biological knowledge bases provide systemically functional pathways of cells\nor organisms in terms of molecular interaction. However, recognizing more\ntargeted pathways, particularly when incorporating wet-lab experimental data,\nremains challenging and typically requires downstream biological analyses and\nexpertise. In this paper, we frame this challenge as a solvable graph learning\nand explaining task and propose a novel pathway inference framework, ExPath,\nthat explicitly integrates experimental data, specifically amino acid sequences\n(AA-seqs), to classify various graphs (bio-networks) in biological databases.\nThe links (representing pathways) that contribute more to classification can be\nconsidered as targeted pathways. Technically, ExPath comprises three\ncomponents: (1) a large protein language model (pLM) that encodes and embeds\nAA-seqs into graph, overcoming traditional obstacles in processing AA-seq data,\nsuch as BLAST; (2) PathMamba, a hybrid architecture combining graph neural\nnetworks (GNNs) with state-space sequence modeling (Mamba) to capture both\nlocal interactions and global pathway-level dependencies; and (3)\nPathExplainer, a subgraph learning module that identifies functionally critical\nnodes and edges through trainable pathway masks. We also propose ML-oriented\nbiological evaluations and a new metric. The experiments involving 301\nbio-networks evaluations demonstrate that pathways inferred by ExPath maintain\nbiological meaningfulness. We will publicly release curated 301 bio-network\ndata soon.",
      "pdf_url": "http://arxiv.org/pdf/2502.18026v1",
      "published": "2025-02-25T09:33:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.18026v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "AfroXLMR-Comet: Multilingual Knowledge Distillation with Attention Matching for Low-Resource languages",
      "authors": [
        "Joshua Sakthivel Raju",
        "Sanjay S",
        "Jaskaran Singh Walia",
        "Srinivas Raghav",
        "Vukosi Marivate"
      ],
      "abstract": "Language model compression through knowledge distillation has emerged as a\npromising approach for deploying large language models in resource-constrained\nenvironments. However, existing methods often struggle to maintain performance\nwhen distilling multilingual models, especially for low-resource languages. In\nthis paper, we present a novel hybrid distillation approach that combines\ntraditional knowledge distillation with a simplified attention matching\nmechanism, specifically designed for multilingual contexts. Our method\nintroduces an extremely compact student model architecture, significantly\nsmaller than conventional multilingual models. We evaluate our approach on five\nAfrican languages: Kinyarwanda, Swahili, Hausa, Igbo, and Yoruba. The distilled\nstudent model; AfroXLMR-Comet successfully captures both the output\ndistribution and internal attention patterns of a larger teacher model\n(AfroXLMR-Large) while reducing the model size by over 85%. Experimental\nresults demonstrate that our hybrid approach achieves competitive performance\ncompared to the teacher model, maintaining an accuracy within 85% of the\noriginal model's performance while requiring substantially fewer computational\nresources. Our work provides a practical framework for deploying efficient\nmultilingual models in resource-constrained environments, particularly\nbenefiting applications involving African languages.",
      "pdf_url": "http://arxiv.org/pdf/2502.18020v1",
      "published": "2025-02-25T09:28:47+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.18020v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ]
    }
  ]
}