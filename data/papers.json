{
  "last_updated": "2025-04-01T00:55:13.192564",
  "papers": [
    {
      "title": "DSO: Aligning 3D Generators with Simulation Feedback for Physical Soundness",
      "authors": [
        "Ruining Li",
        "Chuanxia Zheng",
        "Christian Rupprecht",
        "Andrea Vedaldi"
      ],
      "abstract": "Most 3D object generators focus on aesthetic quality, often neglecting\nphysical constraints necessary in applications. One such constraint is that the\n3D object should be self-supporting, i.e., remains balanced under gravity.\nPrior approaches to generating stable 3D objects used differentiable physics\nsimulators to optimize geometry at test-time, which is slow, unstable, and\nprone to local optima. Inspired by the literature on aligning generative models\nto external feedback, we propose Direct Simulation Optimization (DSO), a\nframework to use the feedback from a (non-differentiable) simulator to increase\nthe likelihood that the 3D generator outputs stable 3D objects directly. We\nconstruct a dataset of 3D objects labeled with a stability score obtained from\nthe physics simulator. We can then fine-tune the 3D generator using the\nstability score as the alignment metric, via direct preference optimization\n(DPO) or direct reward optimization (DRO), a novel objective, which we\nintroduce, to align diffusion models without requiring pairwise preferences.\nOur experiments show that the fine-tuned feed-forward generator, using either\nDPO or DRO objective, is much faster and more likely to produce stable objects\nthan test-time optimization. Notably, the DSO framework works even without any\nground-truth 3D objects for training, allowing the 3D generator to self-improve\nby automatically collecting simulation feedback on its own outputs.",
      "pdf_url": "http://arxiv.org/pdf/2503.22677v1",
      "published": "2025-03-28T17:59:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.22677v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Think Before Recommend: Unleashing the Latent Reasoning Power for Sequential Recommendation",
      "authors": [
        "Jiakai Tang",
        "Sunhao Dai",
        "Teng Shi",
        "Jun Xu",
        "Xu Chen",
        "Wen Chen",
        "Wu Jian",
        "Yuning Jiang"
      ],
      "abstract": "Sequential Recommendation (SeqRec) aims to predict the next item by capturing\nsequential patterns from users' historical interactions, playing a crucial role\nin many real-world recommender systems. However, existing approaches\npredominantly adopt a direct forward computation paradigm, where the final\nhidden state of the sequence encoder serves as the user representation. We\nargue that this inference paradigm, due to its limited computational depth,\nstruggles to model the complex evolving nature of user preferences and lacks a\nnuanced understanding of long-tail items, leading to suboptimal performance. To\naddress this issue, we propose \\textbf{ReaRec}, the first inference-time\ncomputing framework for recommender systems, which enhances user\nrepresentations through implicit multi-step reasoning. Specifically, ReaRec\nautoregressively feeds the sequence's last hidden state into the sequential\nrecommender while incorporating special reasoning position embeddings to\ndecouple the original item encoding space from the multi-step reasoning space.\nMoreover, we introduce two lightweight reasoning-based learning methods,\nEnsemble Reasoning Learning (ERL) and Progressive Reasoning Learning (PRL), to\nfurther effectively exploit ReaRec's reasoning potential. Extensive experiments\non five public real-world datasets and different SeqRec architectures\ndemonstrate the generality and effectiveness of our proposed ReaRec.\nRemarkably, post-hoc analyses reveal that ReaRec significantly elevates the\nperformance ceiling of multiple sequential recommendation backbones by\napproximately 30\\%-50\\%. Thus, we believe this work can open a new and\npromising avenue for future research in inference-time computing for sequential\nrecommendation.",
      "pdf_url": "http://arxiv.org/pdf/2503.22675v1",
      "published": "2025-03-28T17:59:03+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.22675v1",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "QuestBench: Can LLMs ask the right question to acquire information in reasoning tasks?",
      "authors": [
        "Belinda Z. Li",
        "Been Kim",
        "Zi Wang"
      ],
      "abstract": "Recently, a large amount of work has focused on improving large language\nmodels' (LLMs') performance on reasoning benchmarks such as math and logic.\nHowever, past work has largely assumed that tasks are well-defined. In the real\nworld, queries to LLMs are often underspecified, only solvable through\nacquiring missing information. We formalize this as a constraint satisfaction\nproblem (CSP) with missing variable assignments. Using a special case of this\nformalism where only one necessary variable assignment is missing, we can\nrigorously evaluate an LLM's ability to identify the minimal necessary question\nto ask and quantify axes of difficulty levels for each problem. We present\nQuestBench, a set of underspecified reasoning tasks solvable by asking at most\none question, which includes: (1) Logic-Q: Logical reasoning tasks with one\nmissing proposition, (2) Planning-Q: PDDL planning problems with initial states\nthat are partially-observed, (3) GSM-Q: Human-annotated grade school math\nproblems with one missing variable assignment, and (4) GSME-Q: a version of\nGSM-Q where word problems are translated into equations by human annotators.\nThe LLM is tasked with selecting the correct clarification question(s) from a\nlist of options. While state-of-the-art models excel at GSM-Q and GSME-Q, their\naccuracy is only 40-50% on Logic-Q and Planning-Q. Analysis demonstrates that\nthe ability to solve well-specified reasoning problems may not be sufficient\nfor success on our benchmark: models have difficulty identifying the right\nquestion to ask, even when they can solve the fully specified version of the\nproblem. Furthermore, in the Planning-Q domain, LLMs tend not to hedge, even\nwhen explicitly presented with the option to predict ``not sure.'' This\nhighlights the need for deeper investigation into models' information\nacquisition capabilities.",
      "pdf_url": "http://arxiv.org/pdf/2503.22674v1",
      "published": "2025-03-28T17:58:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.22674v1",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    },
    {
      "title": "ActionStudio: A Lightweight Framework for Data and Training of Action Models",
      "authors": [
        "Jianguo Zhang",
        "Thai Hoang",
        "Ming Zhu",
        "Zuxin Liu",
        "Shiyu Wang",
        "Tulika Awalgaonkar",
        "Akshara Prabhakar",
        "Haolin Chen",
        "Weiran Yao",
        "Zhiwei Liu",
        "Juntao Tan",
        "Juan Carlos Niebles",
        "Shelby Heinecke",
        "Huan Wang",
        "Silvio Savarese",
        "Caiming Xiong"
      ],
      "abstract": "Action models are essential for enabling autonomous agents to perform complex\ntasks. However, training large action models remains challenging due to the\ndiversity of agent environments and the complexity of agentic data. Despite\ngrowing interest, existing infrastructure provides limited support for\nscalable, agent-specific fine-tuning. We present ActionStudio, a lightweight\nand extensible data and training framework designed for action models.\nActionStudio unifies heterogeneous agent trajectories through a standardized\nformat, supports diverse training paradigms including LoRA, full fine-tuning,\nand distributed setups, and integrates robust preprocessing and verification\ntools. We validate its effectiveness across both public and realistic industry\nbenchmarks, demonstrating strong performance and practical scalability. We\nopen-sourced code and data at https://github.com/SalesforceAIResearch/xLAM to\nfacilitate research in the community.",
      "pdf_url": "http://arxiv.org/pdf/2503.22673v1",
      "published": "2025-03-28T17:58:33+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.22673v1",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Exploring the Effectiveness of Multi-stage Fine-tuning for Cross-encoder Re-rankers",
      "authors": [
        "Francesca Pezzuti",
        "Sean MacAvaney",
        "Nicola Tonellotto"
      ],
      "abstract": "State-of-the-art cross-encoders can be fine-tuned to be highly effective in\npassage re-ranking. The typical fine-tuning process of cross-encoders as\nre-rankers requires large amounts of manually labelled data, a contrastive\nlearning objective, and a set of heuristically sampled negatives. An\nalternative recent approach for fine-tuning instead involves teaching the model\nto mimic the rankings of a highly effective large language model using a\ndistillation objective. These fine-tuning strategies can be applied either\nindividually, or in sequence. In this work, we systematically investigate the\neffectiveness of point-wise cross-encoders when fine-tuned independently in a\nsingle stage, or sequentially in two stages. Our experiments show that the\neffectiveness of point-wise cross-encoders fine-tuned using contrastive\nlearning is indeed on par with that of models fine-tuned with multi-stage\napproaches. Code is available for reproduction at\nhttps://github.com/fpezzuti/multistage-finetuning.",
      "pdf_url": "http://arxiv.org/pdf/2503.22672v1",
      "published": "2025-03-28T17:58:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.22672v1",
      "categories": [
        "cs.IR",
        "cs.AI"
      ]
    },
    {
      "title": "Evaluation of Machine-generated Biomedical Images via A Tally-based Similarity Measure",
      "authors": [
        "Frank J. Brooks",
        "Rucha Deshpande"
      ],
      "abstract": "Super-resolution, in-painting, whole-image generation, unpaired\nstyle-transfer, and network-constrained image reconstruction each include an\naspect of machine-learned image synthesis where the actual ground truth is not\nknown at time of use. It is generally difficult to quantitatively and\nauthoritatively evaluate the quality of synthetic images; however, in\nmission-critical biomedical scenarios robust evaluation is paramount. In this\nwork, all practical image-to-image comparisons really are relative\nqualifications, not absolute difference quantifications; and, therefore,\nmeaningful evaluation of generated image quality can be accomplished using the\nTversky Index, which is a well-established measure for assessing perceptual\nsimilarity. This evaluation procedure is developed and then demonstrated using\nmultiple image data sets, both real and simulated. The main result is that when\nthe subjectivity and intrinsic deficiencies of any feature-encoding choice are\nput upfront, Tversky's method leads to intuitive results, whereas traditional\nmethods based on summarizing distances in deep feature spaces do not.",
      "pdf_url": "http://arxiv.org/pdf/2503.22658v1",
      "published": "2025-03-28T17:44:01+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.22658v1",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ]
    },
    {
      "title": "Unicorn: Text-Only Data Synthesis for Vision Language Model Training",
      "authors": [
        "Xiaomin Yu",
        "Pengxiang Ding",
        "Wenjie Zhang",
        "Siteng Huang",
        "Songyang Gao",
        "Chengwei Qin",
        "Kejian Wu",
        "Zhaoxin Fan",
        "Ziyue Qiao",
        "Donglin Wang"
      ],
      "abstract": "Training vision-language models (VLMs) typically requires large-scale,\nhigh-quality image-text pairs, but collecting or synthesizing such data is\ncostly. In contrast, text data is abundant and inexpensive, prompting the\nquestion: can high-quality multimodal training data be synthesized purely from\ntext? To tackle this, we propose a cross-integrated three-stage multimodal data\nsynthesis framework, which generates two datasets: Unicorn-1.2M and\nUnicorn-471K-Instruction. In Stage 1: Diverse Caption Data Synthesis, we\nconstruct 1.2M semantically diverse high-quality captions by expanding sparse\ncaption seeds using large language models (LLMs). In Stage 2:\nInstruction-Tuning Data Generation, we further process 471K captions into\nmulti-turn instruction-tuning tasks to support complex reasoning. Finally, in\nStage 3: Modality Representation Transfer, these textual captions\nrepresentations are transformed into visual representations, resulting in\ndiverse synthetic image representations. This three-stage process enables us to\nconstruct Unicorn-1.2M for pretraining and Unicorn-471K-Instruction for\ninstruction-tuning, without relying on real images. By eliminating the\ndependency on real images while maintaining data quality and diversity, our\nframework offers a cost-effective and scalable solution for VLMs training. Code\nis available at https://github.com/Yu-xm/Unicorn.git.",
      "pdf_url": "http://arxiv.org/pdf/2503.22655v1",
      "published": "2025-03-28T17:43:00+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.22655v1",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.MM"
      ]
    },
    {
      "title": "Empirical Analysis of Sim-and-Real Cotraining Of Diffusion Policies For Planar Pushing from Pixels",
      "authors": [
        "Adam Wei",
        "Abhinav Agarwal",
        "Boyuan Chen",
        "Rohan Bosworth",
        "Nicholas Pfaff",
        "Russ Tedrake"
      ],
      "abstract": "In imitation learning for robotics, cotraining with demonstration data\ngenerated both in simulation and on real hardware has emerged as a powerful\nrecipe to overcome the sim2real gap. This work seeks to elucidate basic\nprinciples of this sim-and-real cotraining to help inform simulation design,\nsim-and-real dataset creation, and policy training. Focusing narrowly on the\ncanonical task of planar pushing from camera inputs enabled us to be thorough\nin our study. These experiments confirm that cotraining with simulated data\n\\emph{can} dramatically improve performance in real, especially when real data\nis limited. Performance gains scale with simulated data, but eventually\nplateau; real-world data increases this performance ceiling. The results also\nsuggest that reducing the domain gap in physics may be more important than\nvisual fidelity for non-prehensile manipulation tasks. Perhaps surprisingly,\nhaving some visual domain gap actually helps the cotrained policy -- binary\nprobes reveal that high-performing policies learn to distinguish simulated\ndomains from real. We conclude by investigating this nuance and mechanisms that\nfacilitate positive transfer between sim-and-real. In total, our experiments\nspan over 40 real-world policies (evaluated on 800+ trials) and 200 simulated\npolicies (evaluated on 40,000+ trials).",
      "pdf_url": "http://arxiv.org/pdf/2503.22634v1",
      "published": "2025-03-28T17:25:57+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.22634v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "Challenges and Paths Towards AI for Software Engineering",
      "authors": [
        "Alex Gu",
        "Naman Jain",
        "Wen-Ding Li",
        "Manish Shetty",
        "Yijia Shao",
        "Ziyang Li",
        "Diyi Yang",
        "Kevin Ellis",
        "Koushik Sen",
        "Armando Solar-Lezama"
      ],
      "abstract": "AI for software engineering has made remarkable progress recently, becoming a\nnotable success within generative AI. Despite this, there are still many\nchallenges that need to be addressed before automated software engineering\nreaches its full potential. It should be possible to reach high levels of\nautomation where humans can focus on the critical decisions of what to build\nand how to balance difficult tradeoffs while most routine development effort is\nautomated away. Reaching this level of automation will require substantial\nresearch and engineering efforts across academia and industry. In this paper,\nwe aim to discuss progress towards this in a threefold manner. First, we\nprovide a structured taxonomy of concrete tasks in AI for software engineering,\nemphasizing the many other tasks in software engineering beyond code generation\nand completion. Second, we outline several key bottlenecks that limit current\napproaches. Finally, we provide an opinionated list of promising research\ndirections toward making progress on these bottlenecks, hoping to inspire\nfuture research in this rapidly maturing field.",
      "pdf_url": "http://arxiv.org/pdf/2503.22625v1",
      "published": "2025-03-28T17:17:57+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.22625v1",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Evaluating Multimodal Language Models as Visual Assistants for Visually Impaired Users",
      "authors": [
        "Antonia Karamolegkou",
        "Malvina Nikandrou",
        "Georgios Pantazopoulos",
        "Danae Sanchez Villegas",
        "Phillip Rust",
        "Ruchira Dhar",
        "Daniel Hershcovich",
        "Anders Søgaard"
      ],
      "abstract": "This paper explores the effectiveness of Multimodal Large Language models\n(MLLMs) as assistive technologies for visually impaired individuals. We conduct\na user survey to identify adoption patterns and key challenges users face with\nsuch technologies. Despite a high adoption rate of these models, our findings\nhighlight concerns related to contextual understanding, cultural sensitivity,\nand complex scene understanding, particularly for individuals who may rely\nsolely on them for visual interpretation. Informed by these results, we collate\nfive user-centred tasks with image and video inputs, including a novel task on\nOptical Braille Recognition. Our systematic evaluation of twelve MLLMs reveals\nthat further advancements are necessary to overcome limitations related to\ncultural context, multilingual support, Braille reading comprehension,\nassistive object recognition, and hallucinations. This work provides critical\ninsights into the future direction of multimodal AI for accessibility,\nunderscoring the need for more inclusive, robust, and trustworthy visual\nassistance technologies.",
      "pdf_url": "http://arxiv.org/pdf/2503.22610v1",
      "published": "2025-03-28T16:54:25+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.22610v1",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.LG"
      ]
    },
    {
      "title": "Generative Latent Neural PDE Solver using Flow Matching",
      "authors": [
        "Zijie Li",
        "Anthony Zhou",
        "Amir Barati Farimani"
      ],
      "abstract": "Autoregressive next-step prediction models have become the de-facto standard\nfor building data-driven neural solvers to forecast time-dependent partial\ndifferential equations (PDEs). Denoise training that is closely related to\ndiffusion probabilistic model has been shown to enhance the temporal stability\nof neural solvers, while its stochastic inference mechanism enables ensemble\npredictions and uncertainty quantification. In principle, such training\ninvolves sampling a series of discretized diffusion timesteps during both\ntraining and inference, inevitably increasing computational overhead. In\naddition, most diffusion models apply isotropic Gaussian noise on structured,\nuniform grids, limiting their adaptability to irregular domains. We propose a\nlatent diffusion model for PDE simulation that embeds the PDE state in a\nlower-dimensional latent space, which significantly reduces computational\ncosts. Our framework uses an autoencoder to map different types of meshes onto\na unified structured latent grid, capturing complex geometries. By analyzing\ncommon diffusion paths, we propose to use a coarsely sampled noise schedule\nfrom flow matching for both training and testing. Numerical experiments show\nthat the proposed model outperforms several deterministic baselines in both\naccuracy and long-term stability, highlighting the potential of diffusion-based\napproaches for robust data-driven PDE learning.",
      "pdf_url": "http://arxiv.org/pdf/2503.22600v1",
      "published": "2025-03-28T16:44:28+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.22600v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "KEVS: Enhancing Segmentation of Visceral Adipose Tissue in Pre-Cystectomy CT with Gaussian Kernel Density Estimation",
      "authors": [
        "Thomas Boucher",
        "Nicholas Tetlow",
        "Annie Fung",
        "Amy Dewar",
        "Pietro Arina",
        "Sven Kerneis",
        "John Whittle",
        "Evangelos B. Mazomenos"
      ],
      "abstract": "Purpose: The distribution of visceral adipose tissue (VAT) in cystectomy\npatients is indicative of the incidence of post-operative complications.\nExisting VAT segmentation methods for computed tomography (CT) employing\nintensity thresholding have limitations relating to inter-observer variability.\nMoreover, the difficulty in creating ground-truth masks limits the development\nof deep learning (DL) models for this task. This paper introduces a novel\nmethod for VAT prediction in pre-cystectomy CT, which is fully automated and\ndoes not require ground-truth VAT masks for training, overcoming aforementioned\nlimitations. Methods: We introduce the Kernel density Enhanced VAT Segmentator\n( KEVS), combining a DL semantic segmentation model, for multi-body feature\nprediction, with Gaussian kernel density estimation analysis of predicted\nsubcutaneous adipose tissue to achieve accurate scan-specific predictions of\nVAT in the abdominal cavity. Uniquely for a DL pipeline, KEVS does not require\nground-truth VAT masks. Results: We verify the ability of KEVS to accurately\nsegment abdominal organs in unseen CT data and compare KEVS VAT segmentation\npredictions to existing state-of-the-art (SOTA) approaches in a dataset of 20\npre-cystectomy CT scans, collected from University College London Hospital\n(UCLH-Cyst), with expert ground-truth annotations. KEVS presents a 4.80% and\n6.02% improvement in Dice Coefficient over the second best DL and\nthresholding-based VAT segmentation techniques respectively when evaluated on\nUCLH-Cyst. Conclusion: This research introduces KEVS; an automated, SOTA method\nfor the prediction of VAT in pre-cystectomy CT which eliminates inter-observer\nvariability and is trained entirely on open-source CT datasets which do not\ncontain ground-truth VAT masks.",
      "pdf_url": "http://arxiv.org/pdf/2503.22592v1",
      "published": "2025-03-28T16:41:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.22592v1",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Using AI to Summarize US Presidential Campaign TV Advertisement Videos, 1952-2012",
      "authors": [
        "Adam Breuer",
        "Bryce J. Dietrich",
        "Michael H. Crespin",
        "Matthew Butler",
        "J. A. Pyrse",
        "Kosuke Imai"
      ],
      "abstract": "This paper introduces the largest and most comprehensive dataset of US\npresidential campaign television advertisements, available in digital format.\nThe dataset also includes machine-searchable transcripts and high-quality\nsummaries designed to facilitate a variety of academic research. To date, there\nhas been great interest in collecting and analyzing US presidential campaign\nadvertisements, but the need for manual procurement and annotation led many to\nrely on smaller subsets. We design a large-scale parallelized, AI-based\nanalysis pipeline that automates the laborious process of preparing,\ntranscribing, and summarizing videos. We then apply this methodology to the\n9,707 presidential ads from the Julian P. Kanter Political Commercial Archive.\nWe conduct extensive human evaluations to show that these transcripts and\nsummaries match the quality of manually generated alternatives. We illustrate\nthe value of this data by including an application that tracks the genesis and\nevolution of current focal issue areas over seven decades of presidential\nelections. Our analysis pipeline and codebase also show how to use LLM-based\ntools to obtain high-quality summaries for other video datasets.",
      "pdf_url": "http://arxiv.org/pdf/2503.22589v1",
      "published": "2025-03-28T16:36:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.22589v1",
      "categories": [
        "cs.MM",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ]
    },
    {
      "title": "Historical Ink: Exploring Large Language Models for Irony Detection in 19th-Century Spanish",
      "authors": [
        "Kevin Cohen",
        "Laura Manrique-Gómez",
        "Rubén Manrique"
      ],
      "abstract": "This study explores the use of large language models (LLMs) to enhance\ndatasets and improve irony detection in 19th-century Latin American newspapers.\nTwo strategies were employed to evaluate the efficacy of BERT and GPT-4o models\nin capturing the subtle nuances nature of irony, through both multi-class and\nbinary classification tasks. First, we implemented dataset enhancements focused\non enriching emotional and contextual cues; however, these showed limited\nimpact on historical language analysis. The second strategy, a semi-automated\nannotation process, effectively addressed class imbalance and augmented the\ndataset with high-quality annotations. Despite the challenges posed by the\ncomplexity of irony, this work contributes to the advancement of sentiment\nanalysis through two key contributions: introducing a new historical Spanish\ndataset tagged for sentiment analysis and irony detection, and proposing a\nsemi-automated annotation methodology where human expertise is crucial for\nrefining LLMs results, enriched by incorporating historical and cultural\ncontexts as core features.",
      "pdf_url": "http://arxiv.org/pdf/2503.22585v1",
      "published": "2025-03-28T16:33:24+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.22585v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DL",
        "I.2.7"
      ]
    },
    {
      "title": "Breaking Language Barriers in Visual Language Models via Multilingual Textual Regularization",
      "authors": [
        "Iñigo Pikabea",
        "Iñaki Lacunza",
        "Oriol Pareras",
        "Carlos Escolano",
        "Aitor Gonzalez-Agirre",
        "Javier Hernando",
        "Marta Villegas"
      ],
      "abstract": "Rapid advancements in Visual Language Models (VLMs) have transformed\nmultimodal understanding but are often constrained by generating English\nresponses regardless of the input language. This phenomenon has been termed as\nImage-induced Fidelity Loss (IFL) and stems from limited multimodal\nmultilingual training data. To address this, we propose a continuous\nmultilingual integration strategy that injects text-only multilingual data\nduring visual instruction tuning, preserving the language model's original\nmultilingual capabilities. Extensive evaluations demonstrate that our approach\nsignificantly improves linguistic fidelity across languages without degradation\nin visual performance. We also explore model merging, which improves language\nfidelity but comes at the cost of visual performance. In contrast, our core\nmethod achieves robust multilingual alignment without trade-offs, offering a\nscalable and effective path to mitigating IFL for global VLM adoption.",
      "pdf_url": "http://arxiv.org/pdf/2503.22577v1",
      "published": "2025-03-28T16:26:52+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.22577v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "On the Mistaken Assumption of Interchangeable Deep Reinforcement Learning Implementations",
      "authors": [
        "Rajdeep Singh Hundal",
        "Yan Xiao",
        "Xiaochun Cao",
        "Jin Song Dong",
        "Manuel Rigger"
      ],
      "abstract": "Deep Reinforcement Learning (DRL) is a paradigm of artificial intelligence\nwhere an agent uses a neural network to learn which actions to take in a given\nenvironment. DRL has recently gained traction from being able to solve complex\nenvironments like driving simulators, 3D robotic control, and\nmultiplayer-online-battle-arena video games. Numerous implementations of the\nstate-of-the-art algorithms responsible for training these agents, like the\nDeep Q-Network (DQN) and Proximal Policy Optimization (PPO) algorithms,\ncurrently exist. However, studies make the mistake of assuming implementations\nof the same algorithm to be consistent and thus, interchangeable. In this\npaper, through a differential testing lens, we present the results of studying\nthe extent of implementation inconsistencies, their effect on the\nimplementations' performance, as well as their impact on the conclusions of\nprior studies under the assumption of interchangeable implementations. The\noutcomes of our differential tests showed significant discrepancies between the\ntested algorithm implementations, indicating that they are not interchangeable.\nIn particular, out of the five PPO implementations tested on 56 games, three\nimplementations achieved superhuman performance for 50% of their total trials\nwhile the other two implementations only achieved superhuman performance for\nless than 15% of their total trials. As part of a meticulous manual analysis of\nthe implementations' source code, we analyzed implementation discrepancies and\ndetermined that code-level inconsistencies primarily caused these\ndiscrepancies. Lastly, we replicated a study and showed that this assumption of\nimplementation interchangeability was sufficient to flip experiment outcomes.\nTherefore, this calls for a shift in how implementations are being used.",
      "pdf_url": "http://arxiv.org/pdf/2503.22575v1",
      "published": "2025-03-28T16:25:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.22575v1",
      "categories": [
        "cs.SE",
        "cs.AI",
        "D.2.5; I.2.6"
      ]
    },
    {
      "title": "A Framework for Cryptographic Verifiability of End-to-End AI Pipelines",
      "authors": [
        "Kar Balan",
        "Robert Learney",
        "Tim Wood"
      ],
      "abstract": "The increasing integration of Artificial Intelligence across multiple\nindustry sectors necessitates robust mechanisms for ensuring transparency,\ntrust, and auditability of its development and deployment. This topic is\nparticularly important in light of recent calls in various jurisdictions to\nintroduce regulation and legislation on AI safety. In this paper, we propose a\nframework for complete verifiable AI pipelines, identifying key components and\nanalyzing existing cryptographic approaches that contribute to verifiability\nacross different stages of the AI lifecycle, from data sourcing to training,\ninference, and unlearning. This framework could be used to combat\nmisinformation by providing cryptographic proofs alongside AI-generated assets\nto allow downstream verification of their provenance and correctness. Our\nfindings underscore the importance of ongoing research to develop cryptographic\ntools that are not only efficient for isolated AI processes, but that are\nefficiently `linkable' across different processes within the AI pipeline, to\nsupport the development of end-to-end verifiable AI technologies.",
      "pdf_url": "http://arxiv.org/pdf/2503.22573v1",
      "published": "2025-03-28T16:20:57+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.22573v1",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "title": "Niyama : Breaking the Silos of LLM Inference Serving",
      "authors": [
        "Kanishk Goel",
        "Jayashree Mohan",
        "Nipun Kwatra",
        "Ravi Shreyas Anupindi",
        "Ramachandran Ramjee"
      ],
      "abstract": "The widespread adoption of Large Language Models (LLMs) has enabled diverse\napplications with very different latency requirements. Existing LLM serving\nframeworks rely on siloed infrastructure with coarse-grained workload\nsegregation -- interactive and batch -- leading to inefficient resource\nutilization and limited support for fine-grained Quality-of-Service (QoS)\ndifferentiation. This results in operational inefficiencies, over-provisioning\nand poor load management during traffic surges.\n  We present Niyama, a novel QoS-driven inference serving system that enables\nefficient co-scheduling of diverse workloads on shared infrastructure. Niyama\nintroduces fine-grained QoS classification allowing applications to specify\nprecise latency requirements, and dynamically adapts scheduling decisions based\non real-time system state. Leveraging the predictable execution characteristics\nof LLM inference, Niyama implements a dynamic chunking mechanism to improve\noverall throughput while maintaining strict QoS guarantees. Additionally,\nNiyama employs a hybrid prioritization policy that balances fairness and\nefficiency, and employs selective request relegation that enables graceful\nservice degradation during overload conditions. Our evaluation demonstrates\nthat Niyama increases serving capacity by 32% compared to current siloed\ndeployments, while maintaining QoS guarantees. Notably, under extreme load, our\nsystem reduces SLO violations by an order of magnitude compared to current\nstrategies.",
      "pdf_url": "http://arxiv.org/pdf/2503.22562v1",
      "published": "2025-03-28T16:04:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.22562v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ]
    },
    {
      "title": "SafeCast: Risk-Responsive Motion Forecasting for Autonomous Vehicles",
      "authors": [
        "Haicheng Liao",
        "Hanlin Kong",
        "Bin Rao",
        "Bonan Wang",
        "Chengyue Wang",
        "Guyang Yu",
        "Yuming Huang",
        "Ruru Tang",
        "Chengzhong Xu",
        "Zhenning Li"
      ],
      "abstract": "Accurate motion forecasting is essential for the safety and reliability of\nautonomous driving (AD) systems. While existing methods have made significant\nprogress, they often overlook explicit safety constraints and struggle to\ncapture the complex interactions among traffic agents, environmental factors,\nand motion dynamics. To address these challenges, we present SafeCast, a\nrisk-responsive motion forecasting model that integrates safety-aware\ndecision-making with uncertainty-aware adaptability. SafeCast is the first to\nincorporate the Responsibility-Sensitive Safety (RSS) framework into motion\nforecasting, encoding interpretable safety rules--such as safe distances and\ncollision avoidance--based on traffic norms and physical principles. To further\nenhance robustness, we introduce the Graph Uncertainty Feature (GUF), a\ngraph-based module that injects learnable noise into Graph Attention Networks,\ncapturing real-world uncertainties and enhancing generalization across diverse\nscenarios. We evaluate SafeCast on four real-world benchmark datasets--Next\nGeneration Simulation (NGSIM), Highway Drone (HighD), ApolloScape, and the\nMacao Connected Autonomous Driving (MoCAD)--covering highway, urban, and\nmixed-autonomy traffic environments. Our model achieves state-of-the-art (SOTA)\naccuracy while maintaining a lightweight architecture and low inference\nlatency, underscoring its potential for real-time deployment in safety-critical\nAD systems.",
      "pdf_url": "http://arxiv.org/pdf/2503.22541v1",
      "published": "2025-03-28T15:38:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.22541v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "LIM: Large Interpolator Model for Dynamic Reconstruction",
      "authors": [
        "Remy Sabathier",
        "Niloy J. Mitra",
        "David Novotny"
      ],
      "abstract": "Reconstructing dynamic assets from video data is central to many in computer\nvision and graphics tasks. Existing 4D reconstruction approaches are limited by\ncategory-specific models or slow optimization-based methods. Inspired by the\nrecent Large Reconstruction Model (LRM), we present the Large Interpolation\nModel (LIM), a transformer-based feed-forward solution, guided by a novel\ncausal consistency loss, for interpolating implicit 3D representations across\ntime. Given implicit 3D representations at times $t_0$ and $t_1$, LIM produces\na deformed shape at any continuous time $t\\in[t_0,t_1]$, delivering\nhigh-quality interpolated frames in seconds. Furthermore, LIM allows explicit\nmesh tracking across time, producing a consistently uv-textured mesh sequence\nready for integration into existing production pipelines. We also use LIM, in\nconjunction with a diffusion-based multiview generator, to produce dynamic 4D\nreconstructions from monocular videos. We evaluate LIM on various dynamic\ndatasets, benchmarking against image-space interpolation methods (e.g., FiLM)\nand direct triplane linear interpolation, and demonstrate clear advantages. In\nsummary, LIM is the first feed-forward model capable of high-speed tracked 4D\nasset reconstruction across diverse categories.",
      "pdf_url": "http://arxiv.org/pdf/2503.22537v1",
      "published": "2025-03-28T15:36:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.22537v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "AnnoPage Dataset: Dataset of Non-Textual Elements in Documents with Fine-Grained Categorization",
      "authors": [
        "Martin Kišš",
        "Michal Hradiš",
        "Martina Dvořáková",
        "Václav Jiroušek",
        "Filip Kersch"
      ],
      "abstract": "We introduce the AnnoPage Dataset, a novel collection of 7550 pages from\nhistorical documents, primarily in Czech and German, spanning from 1485 to the\npresent, focusing on the late 19th and early 20th centuries. The dataset is\ndesigned to support research in document layout analysis and object detection.\nEach page is annotated with axis-aligned bounding boxes (AABB) representing\nelements of 25 categories of non-textual elements, such as images, maps,\ndecorative elements, or charts, following the Czech Methodology of image\ndocument processing. The annotations were created by expert librarians to\nensure accuracy and consistency. The dataset also incorporates pages from\nmultiple, mainly historical, document datasets to enhance variability and\nmaintain continuity. The dataset is divided into development and test subsets,\nwith the test set carefully selected to maintain the category distribution. We\nprovide baseline results using YOLO and DETR object detectors, offering a\nreference point for future research. The AnnoPage Dataset is publicly available\non Zenodo (https://doi.org/10.5281/zenodo.12788419), along with ground-truth\nannotations in YOLO format.",
      "pdf_url": "http://arxiv.org/pdf/2503.22526v1",
      "published": "2025-03-28T15:30:42+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.22526v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Robust Offline Imitation Learning Through State-level Trajectory Stitching",
      "authors": [
        "Shuze Wang",
        "Yunpeng Mei",
        "Hongjie Cao",
        "Yetian Yuan",
        "Gang Wang",
        "Jian Sun",
        "Jie Chen"
      ],
      "abstract": "Imitation learning (IL) has proven effective for enabling robots to acquire\nvisuomotor skills through expert demonstrations. However, traditional IL\nmethods are limited by their reliance on high-quality, often scarce, expert\ndata, and suffer from covariate shift. To address these challenges, recent\nadvances in offline IL have incorporated suboptimal, unlabeled datasets into\nthe training. In this paper, we propose a novel approach to enhance policy\nlearning from mixed-quality offline datasets by leveraging task-relevant\ntrajectory fragments and rich environmental dynamics. Specifically, we\nintroduce a state-based search framework that stitches state-action pairs from\nimperfect demonstrations, generating more diverse and informative training\ntrajectories. Experimental results on standard IL benchmarks and real-world\nrobotic tasks showcase that our proposed method significantly improves both\ngeneralization and performance.",
      "pdf_url": "http://arxiv.org/pdf/2503.22524v1",
      "published": "2025-03-28T15:28:36+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.22524v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "Exploiting Mixture-of-Experts Redundancy Unlocks Multimodal Generative Abilities",
      "authors": [
        "Raman Dutt",
        "Harleen Hanspal",
        "Guoxuan Xia",
        "Petru-Daniel Tudosiu",
        "Alexander Black",
        "Yongxin Yang",
        "Steven McDonagh",
        "Sarah Parisot"
      ],
      "abstract": "In this work, we undertake the challenge of augmenting the existing\ngenerative capabilities of pre-trained text-only large language models (LLMs)\nwith multi-modal generation capability while satisfying two core constraints:\nC1 preserving the preservation of original language generative capabilities\nwith negligible performance degradation, and C2 adhering to a small parameter\nbudget to learn the new modality, ensuring scalability and efficiency. In\ncontrast to current approaches that add dedicated modules, thereby\nsignificantly increasing the parameter count, we propose a method that\nleverages the underutilized capacity inherent in deep models. Specifically, we\nexploit the parameter redundancy within Mixture-of-Experts (MoEs) as a source\nof additional capacity for learning a new modality, enabling better parameter\nefficiency (C1). Moreover, we preserve the original language generation\ncapabilities by applying low-rank adaptation exclusively to the tokens of the\nnew modality (C2). Furthermore, we introduce a novel parameter initialization\nscheme based on the Gromov-Wasserstein distance to improve convergence and\ntraining stability. Through an extensive analysis of the routing mechanism, we\nuncover the emergence of modality-specific pathways and decreased redundancy\nwithin the experts that can efficiently unlock multi-modal generative\ncapabilities. Overall, our method can be seamlessly applied to a wide range of\ncontemporary LLMs, providing a new pathway for transitioning from uni-modal to\nmulti-modal architectures.",
      "pdf_url": "http://arxiv.org/pdf/2503.22517v1",
      "published": "2025-03-28T15:21:24+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.22517v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Masked Self-Supervised Pre-Training for Text Recognition Transformers on Large-Scale Datasets",
      "authors": [
        "Martin Kišš",
        "Michal Hradiš"
      ],
      "abstract": "Self-supervised learning has emerged as a powerful approach for leveraging\nlarge-scale unlabeled data to improve model performance in various domains. In\nthis paper, we explore masked self-supervised pre-training for text recognition\ntransformers. Specifically, we propose two modifications to the pre-training\nphase: progressively increasing the masking probability, and modifying the loss\nfunction to incorporate both masked and non-masked patches. We conduct\nextensive experiments using a dataset of 50M unlabeled text lines for\npre-training and four differently sized annotated datasets for fine-tuning.\nFurthermore, we compare our pre-trained models against those trained with\ntransfer learning, demonstrating the effectiveness of the self-supervised\npre-training. In particular, pre-training consistently improves the character\nerror rate of models, in some cases up to 30 % relatively. It is also on par\nwith transfer learning but without relying on extra annotated text lines.",
      "pdf_url": "http://arxiv.org/pdf/2503.22513v1",
      "published": "2025-03-28T15:16:48+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.22513v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Almost Bayesian: The Fractal Dynamics of Stochastic Gradient Descent",
      "authors": [
        "Max Hennick",
        "Stijn De Baerdemacker"
      ],
      "abstract": "We show that the behavior of stochastic gradient descent is related to\nBayesian statistics by showing that SGD is effectively diffusion on a fractal\nlandscape, where the fractal dimension can be accounted for in a purely\nBayesian way. By doing this we show that SGD can be regarded as a modified\nBayesian sampler which accounts for accessibility constraints induced by the\nfractal structure of the loss landscape. We verify our results experimentally\nby examining the diffusion of weights during training. These results offer\ninsight into the factors which determine the learning process, and seemingly\nanswer the question of how SGD and purely Bayesian sampling are related.",
      "pdf_url": "http://arxiv.org/pdf/2503.22478v1",
      "published": "2025-03-28T14:38:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.22478v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ]
    },
    {
      "title": "Evaluating LLM-based Agents for Multi-Turn Conversations: A Survey",
      "authors": [
        "Shengyue Guan",
        "Haoyi Xiong",
        "Jindong Wang",
        "Jiang Bian",
        "Bin Zhu",
        "Jian-guang Lou"
      ],
      "abstract": "This survey examines evaluation methods for large language model (LLM)-based\nagents in multi-turn conversational settings. Using a PRISMA-inspired\nframework, we systematically reviewed nearly 250 scholarly sources, capturing\nthe state of the art from various venues of publication, and establishing a\nsolid foundation for our analysis. Our study offers a structured approach by\ndeveloping two interrelated taxonomy systems: one that defines \\emph{what to\nevaluate} and another that explains \\emph{how to evaluate}. The first taxonomy\nidentifies key components of LLM-based agents for multi-turn conversations and\ntheir evaluation dimensions, including task completion, response quality, user\nexperience, memory and context retention, as well as planning and tool\nintegration. These components ensure that the performance of conversational\nagents is assessed in a holistic and meaningful manner. The second taxonomy\nsystem focuses on the evaluation methodologies. It categorizes approaches into\nannotation-based evaluations, automated metrics, hybrid strategies that combine\nhuman assessments with quantitative measures, and self-judging methods\nutilizing LLMs. This framework not only captures traditional metrics derived\nfrom language understanding, such as BLEU and ROUGE scores, but also\nincorporates advanced techniques that reflect the dynamic, interactive nature\nof multi-turn dialogues.",
      "pdf_url": "http://arxiv.org/pdf/2503.22458v1",
      "published": "2025-03-28T14:08:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.22458v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Entropy-guided sequence weighting for efficient exploration in RL-based LLM fine-tuning",
      "authors": [
        "Abdullah Vanlioglu"
      ],
      "abstract": "We introduce Entropy-Guided Sequence Weighting (EGSW), a novel approach that\nenhances the exploration-exploitation tradeoff by dynamically assigning weights\nto generated outputs based on their advantage and entropy for Reinforcement\nLearning-based Large Language Model fine-tuning. EGSW integrates entropy\nregularization with advantage-based weighting to balance policy updates,\nenabling efficient exploration in high-dimensional state spaces. By employing\ntemperature-scaled softmax weighting over sequences, EGSW prioritizing\nhigh-reward, high-uncertainty steps while maintaining training stability.\nAlthough originally developed to improve Group Relative Policy Optimization\n(GRPO) during large language model (LLM) fine-tuning, EGSW is generalizable to\nother reinforcement learning (RL) algorithms and can be implemented in both\nstep-wise and trajectory-wise settings. Empirical evaluations demonstrate that\nEGSW enhances GRPO reasoning ability, yielding improvements in sample\nefficiency. Future work will explore the application of EGSW to advanced RL\nmethodologies.",
      "pdf_url": "http://arxiv.org/pdf/2503.22456v1",
      "published": "2025-03-28T14:07:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.22456v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "A Causal Framework to Measure and Mitigate Non-binary Treatment Discrimination",
      "authors": [
        "Ayan Majumdar",
        "Deborah D. Kanubala",
        "Kavya Gupta",
        "Isabel Valera"
      ],
      "abstract": "Fairness studies of algorithmic decision-making systems often simplify\ncomplex decision processes, such as bail or loan approvals, into binary\nclassification tasks. However, these approaches overlook that such decisions\nare not inherently binary (e.g., approve or not approve bail or loan); they\nalso involve non-binary treatment decisions (e.g., bail conditions or loan\nterms) that can influence the downstream outcomes (e.g., loan repayment or\nreoffending). In this paper, we argue that non-binary treatment decisions are\nintegral to the decision process and controlled by decision-makers and,\ntherefore, should be central to fairness analyses in algorithmic\ndecision-making. We propose a causal framework that extends fairness analyses\nand explicitly distinguishes between decision-subjects' covariates and the\ntreatment decisions. This specification allows decision-makers to use our\nframework to (i) measure treatment disparity and its downstream effects in\nhistorical data and, using counterfactual reasoning, (ii) mitigate the impact\nof past unfair treatment decisions when automating decision-making. We use our\nframework to empirically analyze four widely used loan approval datasets to\nreveal potential disparity in non-binary treatment decisions and their\ndiscriminatory impact on outcomes, highlighting the need to incorporate\ntreatment decisions in fairness assessments. Moreover, by intervening in\ntreatment decisions, we show that our framework effectively mitigates treatment\ndiscrimination from historical data to ensure fair risk score estimation and\n(non-binary) decision-making processes that benefit all stakeholders.",
      "pdf_url": "http://arxiv.org/pdf/2503.22454v1",
      "published": "2025-03-28T14:06:35+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.22454v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "CoSIL: Software Issue Localization via LLM-Driven Code Repository Graph Searching",
      "authors": [
        "Zhonghao Jiang",
        "Xiaoxue Ren",
        "Meng Yan",
        "Wei Jiang",
        "Yong Li",
        "Zhongxin Liu"
      ],
      "abstract": "Large language models (LLMs) have significantly advanced autonomous software\nengineering, leading to a growing number of software engineering agents that\nassist developers in automatic program repair. Issue localization forms the\nbasis for accurate patch generation. However, because of limitations caused by\nthe context window length of LLMs, existing issue localization methods face\nchallenges in balancing concise yet effective contexts and adequately\ncomprehensive search spaces. In this paper, we introduce CoSIL, an LLM driven,\nsimple yet powerful function level issue localization method without training\nor indexing. CoSIL reduces the search space through module call graphs,\niteratively searches the function call graph to obtain relevant contexts, and\nuses context pruning to control the search direction and manage contexts\neffectively. Importantly, the call graph is dynamically constructed by the LLM\nduring search, eliminating the need for pre-parsing. Experiment results\ndemonstrate that CoSIL achieves a Top-1 localization success rate of 43 percent\nand 44.6 percent on SWE bench Lite and SWE bench Verified, respectively, using\nQwen2.5 Coder 32B, outperforming existing methods by 8.6 to 98.2 percent. When\nCoSIL is applied to guide the patch generation stage, the resolved rate further\nimproves by 9.3 to 31.5 percent.",
      "pdf_url": "http://arxiv.org/pdf/2503.22424v1",
      "published": "2025-03-28T13:36:26+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.22424v1",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Training Large Language Models for Advanced Typosquatting Detection",
      "authors": [
        "Jackson Welch"
      ],
      "abstract": "Typosquatting is a long-standing cyber threat that exploits human error in\ntyping URLs to deceive users, distribute malware, and conduct phishing attacks.\nWith the proliferation of domain names and new Top-Level Domains (TLDs),\ntyposquatting techniques have grown more sophisticated, posing significant\nrisks to individuals, businesses, and national cybersecurity infrastructure.\nTraditional detection methods primarily focus on well-known impersonation\npatterns, leaving gaps in identifying more complex attacks. This study\nintroduces a novel approach leveraging large language models (LLMs) to enhance\ntyposquatting detection. By training an LLM on character-level transformations\nand pattern-based heuristics rather than domain-specific data, a more adaptable\nand resilient detection mechanism develops. Experimental results indicate that\nthe Phi-4 14B model outperformed other tested models when properly fine tuned\nachieving a 98% accuracy rate with only a few thousand training samples. This\nresearch highlights the potential of LLMs in cybersecurity applications,\nspecifically in mitigating domain-based deception tactics, and provides\ninsights into optimizing machine learning strategies for threat detection.",
      "pdf_url": "http://arxiv.org/pdf/2503.22406v1",
      "published": "2025-03-28T13:16:27+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.22406v1",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.NI"
      ]
    },
    {
      "title": "EllieSQL: Cost-Efficient Text-to-SQL with Complexity-Aware Routing",
      "authors": [
        "Yizhang Zhu",
        "Runzhi Jiang",
        "Boyan Li",
        "Nan Tang",
        "Yuyu Luo"
      ],
      "abstract": "Text-to-SQL automatically translates natural language queries to SQL,\nallowing non-technical users to retrieve data from databases without\nspecialized SQL knowledge. Despite the success of advanced LLM-based\nText-to-SQL approaches on leaderboards, their unsustainable computational\ncosts--often overlooked--stand as the \"elephant in the room\" in current\nleaderboard-driven research, limiting their economic practicability for\nreal-world deployment and widespread adoption. To tackle this, we exploratively\npropose EllieSQL, a complexity-aware routing framework that assigns queries to\nsuitable SQL generation pipelines based on estimated complexity. We investigate\nmultiple routers to direct simple queries to efficient approaches while\nreserving computationally intensive methods for complex cases. Drawing from\neconomics, we introduce the Token Elasticity of Performance (TEP) metric,\ncapturing cost-efficiency by quantifying the responsiveness of performance\ngains relative to token investment in SQL generation. Experiments show that\ncompared to always using the most advanced methods in our study, EllieSQL with\nthe Qwen2.5-0.5B-DPO router reduces token use by over 40% without compromising\nperformance on Bird development set, achieving more than a 2x boost in TEP over\nnon-routing approaches. This not only advances the pursuit of cost-efficient\nText-to-SQL but also invites the community to weigh resource efficiency\nalongside performance, contributing to progress in sustainable Text-to-SQL.",
      "pdf_url": "http://arxiv.org/pdf/2503.22402v1",
      "published": "2025-03-28T13:11:27+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.22402v1",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "On-site estimation of battery electrochemical parameters via transfer learning based physics-informed neural network approach",
      "authors": [
        "Josu Yeregui",
        "Iker Lopetegi",
        "Sergio Fernandez",
        "Erik Garayalde",
        "Unai Iraola"
      ],
      "abstract": "This paper presents a novel physical parameter estimation framework for\non-site model characterization, using a two-phase modelling strategy with\nPhysics-Informed Neural Networks (PINNs) and transfer learning (TL). In the\nfirst phase, a PINN is trained using only the physical principles of the single\nparticle model (SPM) equations. In the second phase, the majority of the PINN\nparameters are frozen, while critical electrochemical parameters are set as\ntrainable and adjusted using real-world voltage profile data. The proposed\napproach significantly reduces computational costs, making it suitable for\nreal-time implementation on Battery Management Systems (BMS). Additionally, as\nthe initial phase does not require field data, the model is easy to deploy with\nminimal setup requirements. With the proposed methodology, we have been able to\neffectively estimate relevant electrochemical parameters with operating data.\nThis has been proved estimating diffusivities and active material volume\nfractions with charge data in different degradation conditions. The methodology\nis experimentally validated in a Raspberry Pi device using data from a standard\ncharge profile with a 3.89\\% relative accuracy estimating the active material\nvolume fractions of a NMC cell with 82.09\\% of its nominal capacity.",
      "pdf_url": "http://arxiv.org/pdf/2503.22396v1",
      "published": "2025-03-28T13:06:41+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.22396v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Endo-TTAP: Robust Endoscopic Tissue Tracking via Multi-Facet Guided Attention and Hybrid Flow-point Supervision",
      "authors": [
        "Rulin Zhou",
        "Wenlong He",
        "An Wang",
        "Qiqi Yao",
        "Haijun Hu",
        "Jiankun Wang",
        "Xi Zhang an Hongliang Ren"
      ],
      "abstract": "Accurate tissue point tracking in endoscopic videos is critical for\nrobotic-assisted surgical navigation and scene understanding, but remains\nchallenging due to complex deformations, instrument occlusion, and the scarcity\nof dense trajectory annotations. Existing methods struggle with long-term\ntracking under these conditions due to limited feature utilization and\nannotation dependence. We present Endo-TTAP, a novel framework addressing these\nchallenges through: (1) A Multi-Facet Guided Attention (MFGA) module that\nsynergizes multi-scale flow dynamics, DINOv2 semantic embeddings, and explicit\nmotion patterns to jointly predict point positions with uncertainty and\nocclusion awareness; (2) A two-stage curriculum learning strategy employing an\nAuxiliary Curriculum Adapter (ACA) for progressive initialization and hybrid\nsupervision. Stage I utilizes synthetic data with optical flow ground truth for\nuncertainty-occlusion regularization, while Stage II combines unsupervised flow\nconsistency and semi-supervised learning with refined pseudo-labels from\noff-the-shelf trackers. Extensive validation on two MICCAI Challenge datasets\nand our collected dataset demonstrates that Endo-TTAP achieves state-of-the-art\nperformance in tissue point tracking, particularly in scenarios characterized\nby complex endoscopic conditions. The source code and dataset will be available\nat https://anonymous.4open.science/r/Endo-TTAP-36E5.",
      "pdf_url": "http://arxiv.org/pdf/2503.22394v1",
      "published": "2025-03-28T13:00:07+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.22394v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "ViSketch-GPT: Collaborative Multi-Scale Feature Extraction for Sketch Recognition and Generation",
      "authors": [
        "Giulio Federico",
        "Giuseppe Amato",
        "Fabio Carrara",
        "Claudio Gennaro",
        "Marco Di Benedetto"
      ],
      "abstract": "Understanding the nature of human sketches is challenging because of the wide\nvariation in how they are created. Recognizing complex structural patterns\nimproves both the accuracy in recognizing sketches and the fidelity of the\ngenerated sketches. In this work, we introduce ViSketch-GPT, a novel algorithm\ndesigned to address these challenges through a multi-scale context extraction\napproach. The model captures intricate details at multiple scales and combines\nthem using an ensemble-like mechanism, where the extracted features work\ncollaboratively to enhance the recognition and generation of key details\ncrucial for classification and generation tasks.\n  The effectiveness of ViSketch-GPT is validated through extensive experiments\non the QuickDraw dataset. Our model establishes a new benchmark, significantly\noutperforming existing methods in both classification and generation tasks,\nwith substantial improvements in accuracy and the fidelity of generated\nsketches.\n  The proposed algorithm offers a robust framework for understanding complex\nstructures by extracting features that collaborate to recognize intricate\ndetails, enhancing the understanding of structures like sketches and making it\na versatile tool for various applications in computer vision and machine\nlearning.",
      "pdf_url": "http://arxiv.org/pdf/2503.22374v1",
      "published": "2025-03-28T12:28:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.22374v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "ForcePose: A Deep Learning Approach for Force Calculation Based on Action Recognition Using MediaPipe Pose Estimation Combined with Object Detection",
      "authors": [
        "Nandakishor M",
        "Vrinda Govind V",
        "Anuradha Puthalath",
        "Anzy L",
        "Swathi P S",
        "Aswathi R",
        "Devaprabha A R",
        "Varsha Raj",
        "Midhuna Krishnan K",
        "Akhila Anilkumar T V",
        "Yamuna P V"
      ],
      "abstract": "Force estimation in human-object interactions is crucial for various fields\nlike ergonomics, physical therapy, and sports science. Traditional methods\ndepend on specialized equipment such as force plates and sensors, which makes\naccurate assessments both expensive and restricted to laboratory settings. In\nthis paper, we introduce ForcePose, a novel deep learning framework that\nestimates applied forces by combining human pose estimation with object\ndetection. Our approach leverages MediaPipe for skeletal tracking and SSD\nMobileNet for object recognition to create a unified representation of\nhuman-object interaction. We've developed a specialized neural network that\nprocesses both spatial and temporal features to predict force magnitude and\ndirection without needing any physical sensors. After training on our dataset\nof 850 annotated videos with corresponding force measurements, our model\nachieves a mean absolute error of 5.83 N in force magnitude and 7.4 degrees in\nforce direction. When compared to existing computer vision approaches, our\nmethod performs 27.5% better while still offering real-time performance on\nstandard computing hardware. ForcePose opens up new possibilities for force\nanalysis in diverse real-world scenarios where traditional measurement tools\nare impractical or intrusive. This paper discusses our methodology, the dataset\ncreation process, evaluation metrics, and potential applications across\nrehabilitation, ergonomics assessment, and athletic performance analysis.",
      "pdf_url": "http://arxiv.org/pdf/2503.22363v1",
      "published": "2025-03-28T12:13:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.22363v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Shapley Revisited: Tractable Responsibility Measures for Query Answers",
      "authors": [
        "Meghyn Bienvenu",
        "Diego Figueira",
        "Pierre Lafourcade"
      ],
      "abstract": "The Shapley value, originating from cooperative game theory, has been\nemployed to define responsibility measures that quantify the contributions of\ndatabase facts to obtaining a given query answer. For non-numeric queries, this\nis done by considering a cooperative game whose players are the facts and whose\nwealth function assigns 1 or 0 to each subset of the database, depending on\nwhether the query answer holds in the given subset. While conceptually simple,\nthis approach suffers from a notable drawback: the problem of computing such\nShapley values is #P-hard in data complexity, even for simple conjunctive\nqueries. This motivates us to revisit the question of what constitutes a\nreasonable responsibility measure and to introduce a new family of\nresponsibility measures -- weighted sums of minimal supports (WSMS) -- which\nsatisfy intuitive properties. Interestingly, while the definition of WSMSs is\nsimple and bears no obvious resemblance to the Shapley value formula, we prove\nthat every WSMS measure can be equivalently seen as the Shapley value of a\nsuitably defined cooperative game. Moreover, WSMS measures enjoy tractable data\ncomplexity for a large class of queries, including all unions of conjunctive\nqueries. We further explore the combined complexity of WSMS computation and\nestablish (in)tractability results for various subclasses of conjunctive\nqueries.",
      "pdf_url": "http://arxiv.org/pdf/2503.22358v1",
      "published": "2025-03-28T11:52:26+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.22358v1",
      "categories": [
        "cs.DB",
        "cs.AI"
      ]
    },
    {
      "title": "Firm or Fickle? Evaluating Large Language Models Consistency in Sequential Interactions",
      "authors": [
        "Yubo Li",
        "Yidi Miao",
        "Xueying Ding",
        "Ramayya Krishnan",
        "Rema Padman"
      ],
      "abstract": "Large Language Models (LLMs) have shown remarkable capabilities across\nvarious tasks, but their deployment in high-stake domains requires consistent\nperformance across multiple interaction rounds. This paper introduces a\ncomprehensive framework for evaluating and improving LLM response consistency,\nmaking three key contributions. First, we propose a novel Position-Weighted\nConsistency (PWC) score that captures both the importance of early-stage\nstability and recovery patterns in multi-turn interactions. Second, we present\na carefully curated benchmark dataset spanning diverse domains and difficulty\nlevels, specifically designed to evaluate LLM consistency under various\nchallenging follow-up scenarios. Third, we introduce Confidence-Aware Response\nGeneration (CARG), a framework that significantly improves response stability\nby incorporating model confidence signals into the generation process.\nEmpirical results demonstrate that CARG significantly improves response\nstability without sacrificing accuracy, underscoring its potential for reliable\nLLM deployment in critical applications.",
      "pdf_url": "http://arxiv.org/pdf/2503.22353v1",
      "published": "2025-03-28T11:49:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.22353v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "CPPO: Accelerating the Training of Group Relative Policy Optimization-Based Reasoning Models",
      "authors": [
        "Zhihang Lin",
        "Mingbao Lin",
        "Yuan Xie",
        "Rongrong Ji"
      ],
      "abstract": "This paper introduces Completion Pruning Policy Optimization (CPPO) to\naccelerate the training of reasoning models based on Group Relative Policy\nOptimization (GRPO). GRPO, while effective, incurs high training costs due to\nthe need for sampling multiple completions for each question. Our experiment\nand theoretical analysis reveals that the number of completions impacts model\naccuracy yet increases training time multiplicatively, and not all completions\ncontribute equally to policy training -- their contribution depends on their\nrelative advantage. To address these issues, we propose CPPO, which prunes\ncompletions with low absolute advantages, significantly reducing the number\nneeded for gradient calculation and updates. Additionally, we introduce a\ndynamic completion allocation strategy to maximize GPU utilization by\nincorporating additional questions, further enhancing training efficiency.\nExperimental results demonstrate that CPPO achieves up to $8.32\\times$ speedup\non GSM8K and $3.51\\times$ on Math while preserving or even enhancing the\naccuracy compared to the original GRPO. We release our code at\nhttps://github.com/lzhxmu/CPPO.",
      "pdf_url": "http://arxiv.org/pdf/2503.22342v1",
      "published": "2025-03-28T11:30:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.22342v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "VoteFlow: Enforcing Local Rigidity in Self-Supervised Scene Flow",
      "authors": [
        "Yancong Lin",
        "Shiming Wang",
        "Liangliang Nan",
        "Julian Kooij",
        "Holger Caesar"
      ],
      "abstract": "Scene flow estimation aims to recover per-point motion from two adjacent\nLiDAR scans. However, in real-world applications such as autonomous driving,\npoints rarely move independently of others, especially for nearby points\nbelonging to the same object, which often share the same motion. Incorporating\nthis locally rigid motion constraint has been a key challenge in\nself-supervised scene flow estimation, which is often addressed by\npost-processing or appending extra regularization. While these approaches are\nable to improve the rigidity of predicted flows, they lack an architectural\ninductive bias for local rigidity within the model structure, leading to\nsuboptimal learning efficiency and inferior performance. In contrast, we\nenforce local rigidity with a lightweight add-on module in neural network\ndesign, enabling end-to-end learning. We design a discretized voting space that\naccommodates all possible translations and then identify the one shared by\nnearby points by differentiable voting. Additionally, to ensure computational\nefficiency, we operate on pillars rather than points and learn representative\nfeatures for voting per pillar. We plug the Voting Module into popular model\ndesigns and evaluate its benefit on Argoverse 2 and Waymo datasets. We\noutperform baseline works with only marginal compute overhead. Code is\navailable at https://github.com/tudelft-iv/VoteFlow.",
      "pdf_url": "http://arxiv.org/pdf/2503.22328v1",
      "published": "2025-03-28T11:06:27+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.22328v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "AH-GS: Augmented 3D Gaussian Splatting for High-Frequency Detail Representation",
      "authors": [
        "Chenyang Xu",
        "XingGuo Deng",
        "Rui Zhong"
      ],
      "abstract": "The 3D Gaussian Splatting (3D-GS) is a novel method for scene representation\nand view synthesis. Although Scaffold-GS achieves higher quality real-time\nrendering compared to the original 3D-GS, its fine-grained rendering of the\nscene is extremely dependent on adequate viewing angles. The spectral bias of\nneural network learning results in Scaffold-GS's poor ability to perceive and\nlearn high-frequency information in the scene. In this work, we propose\nenhancing the manifold complexity of input features and using network-based\nfeature map loss to improve the image reconstruction quality of 3D-GS models.\nWe introduce AH-GS, which enables 3D Gaussians in structurally complex regions\nto obtain higher-frequency encodings, allowing the model to more effectively\nlearn the high-frequency information of the scene. Additionally, we incorporate\nhigh-frequency reinforce loss to further enhance the model's ability to capture\ndetailed frequency information. Our result demonstrates that our model\nsignificantly improves rendering fidelity, and in specific scenarios (e.g.,\nMipNeRf360-garden), our method exceeds the rendering quality of Scaffold-GS in\njust 15K iterations.",
      "pdf_url": "http://arxiv.org/pdf/2503.22324v1",
      "published": "2025-03-28T10:57:33+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.22324v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Machine Learning Models for Soil Parameter Prediction Based on Satellite, Weather, Clay and Yield Data",
      "authors": [
        "Calvin Kammerlander",
        "Viola Kolb",
        "Marinus Luegmair",
        "Lou Scheermann",
        "Maximilian Schmailzl",
        "Marco Seufert",
        "Jiayun Zhang",
        "Denis Dalic",
        "Torsten Schön"
      ],
      "abstract": "Efficient nutrient management and precise fertilization are essential for\nadvancing modern agriculture, particularly in regions striving to optimize crop\nyields sustainably. The AgroLens project endeavors to address this challenge by\ndevelop ing Machine Learning (ML)-based methodologies to predict soil nutrient\nlevels without reliance on laboratory tests. By leveraging state of the art\ntechniques, the project lays a foundation for acionable insights to improve\nagricultural productivity in resource-constrained areas, such as Africa. The\napproach begins with the development of a robust European model using the LUCAS\nSoil dataset and Sentinel-2 satellite imagery to estimate key soil properties,\nincluding phosphorus, potassium, nitrogen, and pH levels. This model is then\nenhanced by integrating supplementary features, such as weather data, harvest\nrates, and Clay AI-generated embeddings. This report details the methodological\nframework, data preprocessing strategies, and ML pipelines employed in this\nproject. Advanced algorithms, including Random Forests, Extreme Gradient\nBoosting (XGBoost), and Fully Connected Neural Networks (FCNN), were\nimplemented and finetuned for precise nutrient prediction. Results showcase\nrobust model performance, with root mean square error values meeting stringent\naccuracy thresholds. By establishing a reproducible and scalable pipeline for\nsoil nutrient prediction, this research paves the way for transformative\nagricultural applications, including precision fertilization and improved\nresource allocation in underresourced regions like Africa.",
      "pdf_url": "http://arxiv.org/pdf/2503.22276v1",
      "published": "2025-03-28T09:44:32+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.22276v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Make Some Noise: Towards LLM audio reasoning and generation using sound tokens",
      "authors": [
        "Shivam Mehta",
        "Nebojsa Jojic",
        "Hannes Gamper"
      ],
      "abstract": "Integrating audio comprehension and generation into large language models\n(LLMs) remains challenging due to the continuous nature of audio and the\nresulting high sampling rates. Here, we introduce a novel approach that\ncombines Variational Quantization with Conditional Flow Matching to convert\naudio into ultra-low bitrate discrete tokens of 0.23kpbs, allowing for seamless\nintegration with text tokens in LLMs. We fine-tuned a pretrained text-based LLM\nusing Low-Rank Adaptation (LoRA) to assess its effectiveness in achieving true\nmultimodal capabilities, i.e., audio comprehension and generation. Our\ntokenizer outperforms a traditional VQ-VAE across various datasets with diverse\nacoustic events. Despite the substantial loss of fine-grained details through\naudio tokenization, our multimodal LLM trained with discrete tokens achieves\ncompetitive results in audio comprehension with state-of-the-art methods,\nthough audio generation is poor. Our results highlight the need for larger,\nmore diverse datasets and improved evaluation metrics to advance multimodal LLM\nperformance.",
      "pdf_url": "http://arxiv.org/pdf/2503.22275v1",
      "published": "2025-03-28T09:43:47+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.22275v1",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.SD",
        "68T07",
        "I.2.7; I.2.6; H.5.5"
      ]
    },
    {
      "title": "Beyond the Script: Testing LLMs for Authentic Patient Communication Styles in Healthcare",
      "authors": [
        "Anna Bodonhelyi",
        "Christian Stegemann-Philipps",
        "Alessandra Sonanini",
        "Lea Herschbach",
        "Márton Szép",
        "Anne Herrmann-Werner",
        "Teresa Festl-Wietek",
        "Enkelejda Kasneci",
        "Friederike Holderried"
      ],
      "abstract": "Effective patient communication is pivotal in healthcare, yet traditional\nmedical training often lacks exposure to diverse, challenging interpersonal\ndynamics. To bridge this gap, this study proposes the use of Large Language\nModels (LLMs) to simulate authentic patient communication styles, specifically\nthe \"accuser\" and \"rationalizer\" personas derived from the Satir model, while\nalso ensuring multilingual applicability to accommodate diverse cultural\ncontexts and enhance accessibility for medical professionals. Leveraging\nadvanced prompt engineering, including behavioral prompts, author's notes, and\nstubbornness mechanisms, we developed virtual patients (VPs) that embody\nnuanced emotional and conversational traits. Medical professionals evaluated\nthese VPs, rating their authenticity (accuser: $3.8 \\pm 1.0$; rationalizer:\n$3.7 \\pm 0.8$ on a 5-point Likert scale (from one to five)) and correctly\nidentifying their styles. Emotion analysis revealed distinct profiles: the\naccuser exhibited pain, anger, and distress, while the rationalizer displayed\ncontemplation and calmness, aligning with predefined, detailed patient\ndescription including medical history. Sentiment scores (on a scale from zero\nto nine) further validated these differences in the communication styles, with\nthe accuser adopting negative ($3.1 \\pm 0.6$) and the rationalizer more neutral\n($4.0 \\pm 0.4$) tone. These results underscore LLMs' capability to replicate\ncomplex communication styles, offering transformative potential for medical\neducation. This approach equips trainees to navigate challenging clinical\nscenarios by providing realistic, adaptable patient interactions, enhancing\nempathy and diagnostic acumen. Our findings advocate for AI-driven tools as\nscalable, cost-effective solutions to cultivate nuanced communication skills,\nsetting a foundation for future innovations in healthcare training.",
      "pdf_url": "http://arxiv.org/pdf/2503.22250v1",
      "published": "2025-03-28T09:04:10+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.22250v1",
      "categories": [
        "cs.HC",
        "cs.AI"
      ]
    },
    {
      "title": "Agent-Centric Personalized Multiple Clustering with Multi-Modal LLMs",
      "authors": [
        "Ziye Chen",
        "Yiqun Duan",
        "Riheng Zhu",
        "Zhenbang Sun",
        "Mingming Gong"
      ],
      "abstract": "Personalized multiple clustering aims to generate diverse partitions of a\ndataset based on different user-specific aspects, rather than a single\nclustering. It has recently drawn research interest for accommodating varying\nuser preferences. Recent approaches primarily use CLIP embeddings with proxy\nlearning to extract representations biased toward user clustering preferences.\nHowever, CLIP primarily focuses on coarse image-text alignment, lacking a deep\ncontextual understanding of user interests. To overcome these limitations, we\npropose an agent-centric personalized clustering framework that leverages\nmulti-modal large language models (MLLMs) as agents to comprehensively traverse\na relational graph to search for clusters based on user interests. Due to the\nadvanced reasoning mechanism of MLLMs, the obtained clusters align more closely\nwith user-defined criteria than those obtained from CLIP-based representations.\nTo reduce computational overhead, we shorten the agents' traversal path by\nconstructing a relational graph using user-interest-biased embeddings extracted\nby MLLMs. A large number of weakly connected edges can be filtered out based on\nembedding similarity, facilitating an efficient traversal search for agents.\nExperimental results show that the proposed method achieves NMI scores of\n0.9667 and 0.9481 on the Card Order and Card Suits benchmarks, respectively,\nlargely improving the SOTA model by over 140%.",
      "pdf_url": "http://arxiv.org/pdf/2503.22241v1",
      "published": "2025-03-28T08:45:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.22241v1",
      "categories": [
        "cs.AI",
        "68T07, 68T05, 05C82"
      ]
    },
    {
      "title": "WeatherMesh-3: Fast and accurate operational global weather forecasting",
      "authors": [
        "Haoxing Du",
        "Lyna Kim",
        "Joan Creus-Costa",
        "Jack Michaels",
        "Anuj Shetty",
        "Todd Hutchinson",
        "Christopher Riedel",
        "John Dean"
      ],
      "abstract": "We present WeatherMesh-3 (WM-3), an operational transformer-based global\nweather forecasting system that improves the state of the art in both accuracy\nand computational efficiency. We introduce the following advances: 1) a latent\nrollout that enables arbitrary-length predictions in latent space without\nintermediate encoding or decoding; and 2) a modular architecture that flexibly\nutilizes mixed-horizon processors and encodes multiple real-time analyses to\ncreate blended initial conditions. WM-3 generates 14-day global forecasts at\n0.25-degree resolution in 12 seconds on a single RTX 4090. This represents a\n>100,000-fold speedup over traditional NWP approaches while achieving superior\naccuracy with up to 37.7% improvement in RMSE over operational models,\nrequiring only a single consumer-grade GPU for deployment. We aim for WM-3 to\ndemocratize weather forecasting by providing an accessible, lightweight model\nfor operational use while pushing the performance boundaries of machine\nlearning-based weather prediction.",
      "pdf_url": "http://arxiv.org/pdf/2503.22235v1",
      "published": "2025-03-28T08:37:59+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.22235v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Process Reward Modeling with Entropy-Driven Uncertainty",
      "authors": [
        "Lang Cao",
        "Renhong Chen",
        "Yingtian Zou",
        "Chao Peng",
        "Wu Ning",
        "Huacong Xu",
        "Qian Chen",
        "Yuxian Wang",
        "Peishuo Su",
        "Mofan Peng",
        "Zijie Chen",
        "Yitong Li"
      ],
      "abstract": "This paper presents the Entropy-Driven Unified Process Reward Model\n(EDU-PRM), a novel framework that approximates state-of-the-art performance in\nprocess supervision while drastically reducing training costs. EDU-PRM\nintroduces an entropy-guided dynamic step partitioning mechanism, using logit\ndistribution entropy to pinpoint high-uncertainty regions during token\ngeneration dynamically. This self-assessment capability enables precise\nstep-level feedback without manual fine-grained annotation, addressing a\ncritical challenge in process supervision. Experiments on the Qwen2.5-72B model\nwith only 7,500 EDU-PRM-generated training queries demonstrate accuracy closely\napproximating the full Qwen2.5-72B-PRM (71.1% vs. 71.6%), achieving a 98%\nreduction in query cost compared to prior methods. This work establishes\nEDU-PRM as an efficient approach for scalable process reward model training.",
      "pdf_url": "http://arxiv.org/pdf/2503.22233v1",
      "published": "2025-03-28T08:33:37+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.22233v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "MFH: A Multi-faceted Heuristic Algorithm Selection Approach for Software Verification",
      "authors": [
        "Jie Su",
        "Liansai Deng",
        "Cheng Wen",
        "Rong Wang",
        "Zhi Ma",
        "Nan Zhang",
        "Cong Tian",
        "Zhenhua Duan",
        "Shengchao Qin"
      ],
      "abstract": "Currently, many verification algorithms are available to improve the\nreliability of software systems. Selecting the appropriate verification\nalgorithm typically demands domain expertise and non-trivial manpower. An\nautomated algorithm selector is thus desired. However, existing selectors,\neither depend on machine-learned strategies or manually designed heuristics,\nencounter issues such as reliance on high-quality samples with algorithm labels\nand limited scalability. In this paper, an automated algorithm selection\napproach, namely MFH, is proposed for software verification. Our approach\nleverages the heuristics that verifiers producing correct results typically\nimplement certain appropriate algorithms, and the supported algorithms by these\nverifiers indirectly reflect which ones are potentially applicable.\nSpecifically, MFH embeds the code property graph (CPG) of a semantic-preserving\ntransformed program to enhance the robustness of the prediction model.\nFurthermore, our approach decomposes the selection task into the sub-tasks of\npredicting potentially applicable algorithms and matching the most appropriate\nverifiers. Additionally, MFH also introduces a feedback loop on incorrect\npredictions to improve model prediction accuracy. We evaluate MFH on 20\nverifiers and over 15,000 verification tasks. Experimental results demonstrate\nthe effectiveness of MFH, achieving a prediction accuracy of 91.47% even\nwithout ground truth algorithm labels provided during the training phase.\nMoreover, the prediction accuracy decreases only by 0.84% when introducing 10\nnew verifiers, indicating the strong scalability of the proposed approach.",
      "pdf_url": "http://arxiv.org/pdf/2503.22228v1",
      "published": "2025-03-28T08:21:00+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.22228v1",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG",
        "I.2.6; I.2.11; D.2.4"
      ]
    },
    {
      "title": "Learning to Instruct for Visual Instruction Tuning",
      "authors": [
        "Zhihan Zhou",
        "Feng Hong",
        "Jiaan Luo",
        "Jiangchao Yao",
        "Dongsheng Li",
        "Bo Han",
        "Ya Zhang",
        "Yanfeng Wang"
      ],
      "abstract": "We propose LIT, an advancement of visual instruction tuning (VIT). While VIT\nequips Multimodal LLMs (MLLMs) with promising multimodal capabilities, the\ncurrent design choices for VIT often result in overfitting and shortcut\nlearning, potentially degrading performance. This gap arises from an\noveremphasis on instruction-following abilities, while neglecting the proactive\nunderstanding of visual information. Inspired by this, LIT adopts a simple yet\neffective approach by incorporating the loss function into both the instruction\nand response sequences. It seamlessly expands the training data, and\nregularizes the MLLMs from overly relying on language priors. Based on this\nmerit, LIT achieves a significant relative improvement of up to 9% on\ncomprehensive multimodal benchmarks, requiring no additional training data and\nincurring negligible computational overhead. Surprisingly, LIT attains\nexceptional fundamental visual capabilities, yielding up to an 18% improvement\nin captioning performance, while simultaneously alleviating hallucination in\nMLLMs.",
      "pdf_url": "http://arxiv.org/pdf/2503.22215v1",
      "published": "2025-03-28T08:04:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.22215v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    },
    {
      "title": "Sell It Before You Make It: Revolutionizing E-Commerce with Personalized AI-Generated Items",
      "authors": [
        "Jianghao Lin",
        "Peng Du",
        "Jiaqi Liu",
        "Weite Li",
        "Yong Yu",
        "Weinan Zhang",
        "Yang Cao"
      ],
      "abstract": "E-commerce has revolutionized retail, yet its traditional workflows remain\ninefficient, with significant time and resource costs tied to product design\nand manufacturing inventory. This paper introduces a novel system deployed at\nAlibaba that leverages AI-generated items (AIGI) to address these challenges\nwith personalized text-to-image generation for e-commercial product design.\nAIGI enables an innovative business mode called \"sell it before you make it\",\nwhere merchants can design fashion items and generate photorealistic images\nwith digital models based on textual descriptions. Only when the items have\nreceived a certain number of orders, do the merchants start to produce them,\nwhich largely reduces reliance on physical prototypes and thus accelerates time\nto market. For such a promising application, we identify the underlying key\nscientific challenge, i.e., capturing the users' group-level personalized\npreferences towards multiple generated candidate images. To this end, we\npropose a Personalized Group-Level Preference Alignment Framework for Diffusion\nModels (i.e., PerFusion). We first design PerFusion Reward Model for user\npreference estimation with a feature-crossing-based personalized plug-in. Then\nwe develop PerFusion with a personalized adaptive network to model diverse\npreferences across users, and meanwhile derive the group-level preference\noptimization objective to capture the comparative behaviors among multiple\ncandidates. Both offline and online experiments demonstrate the effectiveness\nof our proposed algorithm. The AI-generated items have achieved over 13%\nrelative improvements for both click-through rate and conversion rate compared\nto their human-designed counterparts, validating the revolutionary potential of\nAI-generated items for e-commercial platforms.",
      "pdf_url": "http://arxiv.org/pdf/2503.22182v1",
      "published": "2025-03-28T07:00:33+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.22182v1",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "e-person Architecture and Framework for Human-AI Co-adventure Relationship",
      "authors": [
        "Kanako Esaki",
        "Tadayuki Matsumura",
        "Yang Shao",
        "Hiroyuki Mizuno"
      ],
      "abstract": "This paper proposes the e-person architecture for constructing a unified and\nincremental development of AI ethics. The e-person architecture takes the\nreduction of uncertainty through collaborative cognition and action with others\nas a unified basis for ethics. By classifying and defining uncertainty along\ntwo axes - (1) first, second, and third person perspectives, and (2) the\ndifficulty of inference based on the depth of information - we support the\ndevelopment of unified and incremental development of AI ethics. In addition,\nwe propose the e-person framework based on the free energy principle, which\nconsiders the reduction of uncertainty as a unifying principle of brain\nfunction, with the aim of implementing the e-person architecture, and we show\nour previous works and future challenges based on the proposed framework.",
      "pdf_url": "http://arxiv.org/pdf/2503.22181v1",
      "published": "2025-03-28T06:54:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.22181v1",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ]
    }
  ]
}