{
  "last_updated": "2025-09-19T00:49:04.355744",
  "papers": [
    {
      "title": "Apertus: Democratizing Open and Compliant LLMs for Global Language Environments",
      "authors": [
        "Alejandro Hernández-Cano",
        "Alexander Hägele",
        "Allen Hao Huang",
        "Angelika Romanou",
        "Antoni-Joan Solergibert",
        "Barna Pasztor",
        "Bettina Messmer",
        "Dhia Garbaya",
        "Eduard Frank Ďurech",
        "Ido Hakimi",
        "Juan García Giraldo",
        "Mete Ismayilzada",
        "Negar Foroutan",
        "Skander Moalla",
        "Tiancheng Chen",
        "Vinko Sabolčec",
        "Yixuan Xu",
        "Michael Aerni",
        "Badr AlKhamissi",
        "Ines Altemir Marinas",
        "Mohammad Hossein Amani",
        "Matin Ansaripour",
        "Ilia Badanin",
        "Harold Benoit",
        "Emanuela Boros",
        "Nicholas Browning",
        "Fabian Bösch",
        "Maximilian Böther",
        "Niklas Canova",
        "Camille Challier",
        "Clement Charmillot",
        "Jonathan Coles",
        "Jan Deriu",
        "Arnout Devos",
        "Lukas Drescher",
        "Daniil Dzenhaliou",
        "Maud Ehrmann",
        "Dongyang Fan",
        "Simin Fan",
        "Silin Gao",
        "Miguel Gila",
        "María Grandury",
        "Diba Hashemi",
        "Alexander Hoyle",
        "Jiaming Jiang",
        "Mark Klein",
        "Andrei Kucharavy",
        "Anastasiia Kucherenko",
        "Frederike Lübeck",
        "Roman Machacek",
        "Theofilos Manitaras",
        "Andreas Marfurt",
        "Kyle Matoba",
        "Simon Matrenok",
        "Henrique Mendoncça",
        "Fawzi Roberto Mohamed",
        "Syrielle Montariol",
        "Luca Mouchel",
        "Sven Najem-Meyer",
        "Jingwei Ni",
        "Gennaro Oliva",
        "Matteo Pagliardini",
        "Elia Palme",
        "Andrei Panferov",
        "Léo Paoletti",
        "Marco Passerini",
        "Ivan Pavlov",
        "Auguste Poiroux",
        "Kaustubh Ponkshe",
        "Nathan Ranchin",
        "Javi Rando",
        "Mathieu Sauser",
        "Jakhongir Saydaliev",
        "Muhammad Ali Sayfiddinov",
        "Marian Schneider",
        "Stefano Schuppli",
        "Marco Scialanga",
        "Andrei Semenov",
        "Kumar Shridhar",
        "Raghav Singhal",
        "Anna Sotnikova",
        "Alexander Sternfeld",
        "Ayush Kumar Tarun",
        "Paul Teiletche",
        "Jannis Vamvas",
        "Xiaozhe Yao",
        "Hao Zhao Alexander Ilic",
        "Ana Klimovic",
        "Andreas Krause",
        "Caglar Gulcehre",
        "David Rosenthal",
        "Elliott Ash",
        "Florian Tramèr",
        "Joost VandeVondele",
        "Livio Veraldi",
        "Martin Rajman",
        "Thomas Schulthess",
        "Torsten Hoefler",
        "Antoine Bosselut",
        "Martin Jaggi",
        "Imanol Schlag"
      ],
      "abstract": "We present Apertus, a fully open suite of large language models (LLMs)\ndesigned to address two systemic shortcomings in today's open model ecosystem:\ndata compliance and multilingual representation. Unlike many prior models that\nrelease weights without reproducible data pipelines or regard for content-owner\nrights, Apertus models are pretrained exclusively on openly available data,\nretroactively respecting robots.txt exclusions and filtering for\nnon-permissive, toxic, and personally identifiable content. To mitigate risks\nof memorization, we adopt the Goldfish objective during pretraining, strongly\nsuppressing verbatim recall of data while retaining downstream task\nperformance. The Apertus models also expand multilingual coverage, training on\n15T tokens from over 1800 languages, with ~40% of pretraining data allocated to\nnon-English content. Released at 8B and 70B scales, Apertus approaches\nstate-of-the-art results among fully open models on multilingual benchmarks,\nrivalling or surpassing open-weight counterparts. Beyond model weights, we\nrelease all scientific artifacts from our development cycle with a permissive\nlicense, including data preparation scripts, checkpoints, evaluation suites,\nand training code, enabling transparent audit and extension.",
      "pdf_url": "http://arxiv.org/pdf/2509.14233v1",
      "published": "2025-09-17T17:59:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.14233v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Language models' activations linearly encode training-order recency",
      "authors": [
        "Dmitrii Krasheninnikov",
        "Richard E. Turner",
        "David Krueger"
      ],
      "abstract": "We show that language models' activations linearly encode when information\nwas learned during training. Our setup involves creating a model with a known\ntraining order by sequentially fine-tuning Llama-3.2-1B on six disjoint but\notherwise similar datasets about named entities. We find that the average\nactivations of test samples for the six training datasets encode the training\norder: when projected into a 2D subspace, these centroids are arranged exactly\nin the order of training and lie on a straight line. Further, we show that\nlinear probes can accurately (~90%) distinguish \"early\" vs. \"late\" entities,\ngeneralizing to entities unseen during the probes' own training. The model can\nalso be fine-tuned to explicitly report an unseen entity's training stage (~80%\naccuracy). Interestingly, this temporal signal does not seem attributable to\nsimple differences in activation magnitudes, losses, or model confidence. Our\npaper demonstrates that models are capable of differentiating information by\nits acquisition time, and carries significant implications for how they might\nmanage conflicting data and respond to knowledge modifications.",
      "pdf_url": "http://arxiv.org/pdf/2509.14223v1",
      "published": "2025-09-17T17:54:22+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.14223v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "A Universal Banach--Bregman Framework for Stochastic Iterations: Unifying Stochastic Mirror Descent, Learning and LLM Training",
      "authors": [
        "Johnny R. Zhang",
        "Xiaomei Mi",
        "Gaoyuan Du",
        "Qianyi Sun",
        "Shiqi Wang",
        "Jiaxuan Li",
        "Wenhua Zhou"
      ],
      "abstract": "Stochastic optimization powers the scalability of modern artificial\nintelligence, spanning machine learning, deep learning, reinforcement learning,\nand large language model training. Yet, existing theory remains largely\nconfined to Hilbert spaces, relying on inner-product frameworks and\northogonality. This paradigm fails to capture non-Euclidean settings, such as\nmirror descent on simplices, Bregman proximal methods for sparse learning,\nnatural gradient descent in information geometry, or\nKullback--Leibler-regularized language model training. Unlike Euclidean-based\nHilbert-space methods, this approach embraces general Banach spaces. This work\nintroduces a pioneering Banach--Bregman framework for stochastic iterations,\nestablishing Bregman geometry as a foundation for next-generation optimization.\nIt (i) provides a unified template via Bregman projections and Bregman--Fejer\nmonotonicity, encompassing stochastic approximation, mirror descent, natural\ngradient, adaptive methods, and mirror-prox; (ii) establishes super-relaxations\n($\\lambda > 2$) in non-Hilbert settings, enabling flexible geometries and\nelucidating their acceleration effect; and (iii) delivers convergence theorems\nspanning almost-sure boundedness to geometric rates, validated on synthetic and\nreal-world tasks. Empirical studies across machine learning (UCI benchmarks),\ndeep learning (e.g., Transformer training), reinforcement learning\n(actor--critic), and large language models (WikiText-2 with distilGPT-2) show\nup to 20% faster convergence, reduced variance, and enhanced accuracy over\nclassical baselines. These results position Banach--Bregman geometry as a\ncornerstone unifying optimization theory and practice across core AI paradigms.",
      "pdf_url": "http://arxiv.org/pdf/2509.14216v1",
      "published": "2025-09-17T17:50:59+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.14216v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Dense Video Understanding with Gated Residual Tokenization",
      "authors": [
        "Haichao Zhang",
        "Wenhao Chai",
        "Shwai He",
        "Ang Li",
        "Yun Fu"
      ],
      "abstract": "High temporal resolution is essential for capturing fine-grained details in\nvideo understanding. However, current video large language models (VLLMs) and\nbenchmarks mostly rely on low-frame-rate sampling, such as uniform sampling or\nkeyframe selection, discarding dense temporal information. This compromise\navoids the high cost of tokenizing every frame, which otherwise leads to\nredundant computation and linear token growth as video length increases. While\nthis trade-off works for slowly changing content, it fails for tasks like\nlecture comprehension, where information appears in nearly every frame and\nrequires precise temporal alignment. To address this gap, we introduce Dense\nVideo Understanding (DVU), which enables high-FPS video comprehension by\nreducing both tokenization time and token overhead. Existing benchmarks are\nalso limited, as their QA pairs focus on coarse content changes. We therefore\npropose DIVE (Dense Information Video Evaluation), the first benchmark designed\nfor dense temporal reasoning. To make DVU practical, we present Gated Residual\nTokenization (GRT), a two-stage framework: (1) Motion-Compensated Inter-Gated\nTokenization uses pixel-level motion estimation to skip static regions during\ntokenization, achieving sub-linear growth in token count and compute. (2)\nSemantic-Scene Intra-Tokenization Merging fuses tokens across static regions\nwithin a scene, further reducing redundancy while preserving dynamic semantics.\nExperiments on DIVE show that GRT outperforms larger VLLM baselines and scales\npositively with FPS. These results highlight the importance of dense temporal\ninformation and demonstrate that GRT enables efficient, scalable high-FPS video\nunderstanding.",
      "pdf_url": "http://arxiv.org/pdf/2509.14199v2",
      "published": "2025-09-17T17:34:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.14199v2",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "68T45, 68T07, 68T05, 68T10, 68T50, 68T09, 68U10, 68P20, 94A08,\n  94A34, 62H30, 62H35",
        "I.2.10; I.2.6; I.2.7; I.5.1; I.5.2; I.5.3; I.5.4; I.4.8; I.4.9;\n  I.4.2; H.3.1; H.3.3; H.3.4; H.5.1; H.5.2; H.2.8"
      ]
    },
    {
      "title": "Hierarchical Learning for Maze Navigation: Emergence of Mental Representations via Second-Order Learning",
      "authors": [
        "Shalima Binta Manir",
        "Tim Oates"
      ],
      "abstract": "Mental representation, characterized by structured internal models mirroring\nexternal environments, is fundamental to advanced cognition but remains\nchallenging to investigate empirically. Existing theory hypothesizes that\nsecond-order learning -- learning mechanisms that adapt first-order learning\n(i.e., learning about the task/domain) -- promotes the emergence of such\nenvironment-cognition isomorphism. In this paper, we empirically validate this\nhypothesis by proposing a hierarchical architecture comprising a Graph\nConvolutional Network (GCN) as a first-order learner and an MLP controller as a\nsecond-order learner. The GCN directly maps node-level features to predictions\nof optimal navigation paths, while the MLP dynamically adapts the GCN's\nparameters when confronting structurally novel maze environments. We\ndemonstrate that second-order learning is particularly effective when the\ncognitive system develops an internal mental map structurally isomorphic to the\nenvironment. Quantitative and qualitative results highlight significant\nperformance improvements and robust generalization on unseen maze tasks,\nproviding empirical support for the pivotal role of structured mental\nrepresentations in maximizing the effectiveness of second-order learning.",
      "pdf_url": "http://arxiv.org/pdf/2509.14195v1",
      "published": "2025-09-17T17:30:58+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.14195v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Bridging Past and Future: Distribution-Aware Alignment for Time Series Forecasting",
      "authors": [
        "Yifan Hu",
        "Jie Yang",
        "Tian Zhou",
        "Peiyuan Liu",
        "Yujin Tang",
        "Rong Jin",
        "Liang Sun"
      ],
      "abstract": "Representation learning techniques like contrastive learning have long been\nexplored in time series forecasting, mirroring their success in computer vision\nand natural language processing. Yet recent state-of-the-art (SOTA) forecasters\nseldom adopt these representation approaches because they have shown little\nperformance advantage. We challenge this view and demonstrate that explicit\nrepresentation alignment can supply critical information that bridges the\ndistributional gap between input histories and future targets. To this end, we\nintroduce TimeAlign, a lightweight, plug-and-play framework that learns\nauxiliary features via a simple reconstruction task and feeds them back to any\nbase forecaster. Extensive experiments across eight benchmarks verify its\nsuperior performance. Further studies indicate that the gains arises primarily\nfrom correcting frequency mismatches between historical inputs and future\noutputs. We also provide a theoretical justification for the effectiveness of\nTimeAlign in increasing the mutual information between learned representations\nand predicted targets. As it is architecture-agnostic and incurs negligible\noverhead, TimeAlign can serve as a general alignment module for modern deep\nlearning time-series forecasting systems. The code is available at\nhttps://github.com/TROUBADOUR000/TimeAlign.",
      "pdf_url": "http://arxiv.org/pdf/2509.14181v1",
      "published": "2025-09-17T17:12:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.14181v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Synthesizing Behaviorally-Grounded Reasoning Chains: A Data-Generation Framework for Personal Finance LLMs",
      "authors": [
        "Akhil Theerthala"
      ],
      "abstract": "Personalized financial advice requires consideration of user goals,\nconstraints, risk tolerance, and jurisdiction. Prior LLM work has focused on\nsupport systems for investors and financial planners. Simultaneously, numerous\nrecent studies examine broader personal finance tasks, including budgeting,\ndebt management, retirement, and estate planning, through agentic pipelines\nthat incur high maintenance costs, yielding less than 25% of their expected\nfinancial returns. In this study, we introduce a novel and reproducible\nframework that integrates relevant financial context with behavioral finance\nstudies to construct supervision data for end-to-end advisors. Using this\nframework, we create a 19k sample reasoning dataset and conduct a comprehensive\nfine-tuning of the Qwen-3-8B model on the dataset. Through a held-out test\nsplit and a blind LLM-jury study, we demonstrate that through careful data\ncuration and behavioral integration, our 8B model achieves performance\ncomparable to significantly larger baselines (14-32B parameters) across factual\naccuracy, fluency, and personalization metrics while incurring 80% lower costs\nthan the larger counterparts.",
      "pdf_url": "http://arxiv.org/pdf/2509.14180v1",
      "published": "2025-09-17T17:12:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.14180v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "68T50",
        "I.2.7; J.4"
      ]
    },
    {
      "title": "TGPO: Tree-Guided Preference Optimization for Robust Web Agent Reinforcement Learning",
      "authors": [
        "Ziyuan Chen",
        "Zhenghui Zhao",
        "Zhangye Han",
        "Miancan Liu",
        "Xianhang Ye",
        "Yiqing Li",
        "Hongbo Min",
        "Jinkui Ren",
        "Xiantao Zhang",
        "Guitao Cao"
      ],
      "abstract": "With the rapid advancement of large language models and vision-language\nmodels, employing large models as Web Agents has become essential for automated\nweb interaction. However, training Web Agents with reinforcement learning faces\ncritical challenges including credit assignment misallocation, prohibitively\nhigh annotation costs, and reward sparsity. To address these issues, we propose\nTree-Guided Preference Optimization (TGPO), an offline reinforcement learning\nframework that proposes a tree-structured trajectory representation merging\nsemantically identical states across trajectories to eliminate label conflicts.\nOur framework incorporates a Process Reward Model that automatically generates\nfine-grained rewards through subgoal progress, redundancy detection, and action\nverification. Additionally, a dynamic weighting mechanism prioritizes\nhigh-impact decision points during training. Experiments on Online-Mind2Web and\nour self-constructed C-WebShop datasets demonstrate that TGPO significantly\noutperforms existing methods, achieving higher success rates with fewer\nredundant steps.",
      "pdf_url": "http://arxiv.org/pdf/2509.14172v1",
      "published": "2025-09-17T16:58:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.14172v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Where Do Tokens Go? Understanding Pruning Behaviors in STEP at High Resolutions",
      "authors": [
        "Michal Szczepanski",
        "Martyna Poreba",
        "Karim Haroun"
      ],
      "abstract": "Vision Transformers (ViTs) achieve state-of-the-art performance in semantic\nsegmentation but are hindered by high computational and memory costs. To\naddress this, we propose STEP (SuperToken and Early-Pruning), a hybrid\ntoken-reduction framework that combines dynamic patch merging and token pruning\nto enhance efficiency without significantly compromising accuracy. At the core\nof STEP is dCTS, a lightweight CNN-based policy network that enables flexible\nmerging into superpatches. Encoder blocks integrate also early-exits to remove\nhigh-confident supertokens, lowering computational load. We evaluate our method\non high-resolution semantic segmentation benchmarks, including images up to\n1024 x 1024, and show that when dCTS is applied alone, the token count can be\nreduced by a factor of 2.5 compared to the standard 16 x 16 pixel patching\nscheme. This yields a 2.6x reduction in computational cost and a 3.4x increase\nin throughput when using ViT-Large as the backbone. Applying the full STEP\nframework further improves efficiency, reaching up to a 4x reduction in\ncomputational complexity and a 1.7x gain in inference speed, with a maximum\naccuracy drop of no more than 2.0%. With the proposed STEP configurations, up\nto 40% of tokens can be confidently predicted and halted before reaching the\nfinal encoder layer.",
      "pdf_url": "http://arxiv.org/pdf/2509.14165v1",
      "published": "2025-09-17T16:48:00+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.14165v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Reasoning Efficiently Through Adaptive Chain-of-Thought Compression: A Self-Optimizing Framework",
      "authors": [
        "Kerui Huang",
        "Shuhan Liu",
        "Xing Hu",
        "Tongtong Xu",
        "Lingfeng Bao",
        "Xin Xia"
      ],
      "abstract": "Chain-of-Thought (CoT) reasoning enhances Large Language Models (LLMs) by\nprompting intermediate steps, improving accuracy and robustness in arithmetic,\nlogic, and commonsense tasks. However, this benefit comes with high\ncomputational costs: longer outputs increase latency, memory usage, and\nKV-cache demands. These issues are especially critical in software engineering\ntasks where concise and deterministic outputs are required. To investigate\nthese trade-offs, we conduct an empirical study based on code generation\nbenchmarks. The results reveal that longer CoT does not always help. Excessive\nreasoning often causes truncation, accuracy drops, and latency up to five times\nhigher, with failed outputs consistently longer than successful ones. These\nfindings challenge the assumption that longer reasoning is inherently better\nand highlight the need for adaptive CoT control. Motivated by this, we propose\nSEER (Self-Enhancing Efficient Reasoning), an adaptive framework that\ncompresses CoT while preserving accuracy. SEER combines Best-of-N sampling with\ntask-aware adaptive filtering, dynamically adjusting thresholds based on\npre-inference outputs to reduce verbosity and computational overhead. We then\nevaluate SEER on three software engineering tasks and one math task. On\naverage, SEER shortens CoT by 42.1%, improves accuracy by reducing truncation,\nand eliminates most infinite loops. These results demonstrate SEER as a\npractical method to make CoT-enhanced LLMs more efficient and robust, even\nunder resource constraints.",
      "pdf_url": "http://arxiv.org/pdf/2509.14093v1",
      "published": "2025-09-17T15:33:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.14093v1",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Queen Detection in Beehives via Environmental Sensor Fusion for Low-Power Edge Computing",
      "authors": [
        "Chiara De Luca",
        "Elisa Donati"
      ],
      "abstract": "Queen bee presence is essential for the health and stability of honeybee\ncolonies, yet current monitoring methods rely on manual inspections that are\nlabor-intensive, disruptive, and impractical for large-scale beekeeping. While\nrecent audio-based approaches have shown promise, they often require high power\nconsumption, complex preprocessing, and are susceptible to ambient noise. To\novercome these limitations, we propose a lightweight, multimodal system for\nqueen detection based on environmental sensor fusion-specifically, temperature,\nhumidity, and pressure differentials between the inside and outside of the\nhive. Our approach employs quantized decision tree inference on a commercial\nSTM32 microcontroller, enabling real-time, low-power edge computing without\ncompromising accuracy. We show that our system achieves over 99% queen\ndetection accuracy using only environmental inputs, with audio features\noffering no significant performance gain. This work presents a scalable and\nsustainable solution for non-invasive hive monitoring, paving the way for\nautonomous, precision beekeeping using off-the-shelf, energy-efficient\nhardware.",
      "pdf_url": "http://arxiv.org/pdf/2509.14061v1",
      "published": "2025-09-17T15:05:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.14061v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Machines are more productive than humans until they aren't, and vice versa",
      "authors": [
        "Riccardo Zanardelli"
      ],
      "abstract": "With the growth of artificial skills, organizations may increasingly confront\nwith the problem of optimizing skill policy decisions guided by economic\nprinciples. This paper addresses the underlying complexity of this challenge by\ndeveloping an in-silico framework based on Monte Carlo simulations grounded in\nempirical realism to analyze the economic impact of human and machine skills,\nindividually or jointly deployed, in the execution of tasks presenting varying\nlevels of complexity. Our results provide quantitative support for the\nestablished notions that automation tends to be the most economically-effective\nstrategy for tasks characterized by low-to-medium generalization difficulty,\nwhile automation may struggle to match the economic utility of human skills in\nmore complex scenarios. Critically, our simulations highlight that combining\nhuman and machine skills can be the most effective strategy when a high level\nof generalization is required, but only if genuine augmentation is achieved. In\ncontrast, when failing to realize this synergy, the human-machine policy is\nseverely penalized by the inherent costs of its dual skill structure, causing\nit to destroy value and becoming the worst choice from an economic perspective.\nThe takeaway for decision-makers is unambiguous: in contexts requiring high\ngeneralization capabilities, simply allocating human and machine skills to a\ntask is insufficient, and a human-machine skill policy is neither a\nsilver-bullet solution nor a low-risk compromise. Rather, it is a critical\nopportunity to boost competitiveness that demands a strong organizational\ncommitment to enabling augmentation. Also, our findings show that improving the\ncost-effectiveness of machine skills over time, while useful, does not replace\nthe fundamental need to focus on achieving augmentation.",
      "pdf_url": "http://arxiv.org/pdf/2509.14057v2",
      "published": "2025-09-17T15:03:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.14057v2",
      "categories": [
        "econ.GN",
        "cs.AI",
        "q-fin.EC"
      ]
    },
    {
      "title": "Comprehensive Evaluation of CNN-Based Audio Tagging Models on Resource-Constrained Devices",
      "authors": [
        "Jordi Grau-Haro",
        "Ruben Ribes-Serrano",
        "Javier Naranjo-Alcazar",
        "Marta Garcia-Ballesteros",
        "Pedro Zuccarello"
      ],
      "abstract": "Convolutional Neural Networks (CNNs) have demonstrated exceptional\nperformance in audio tagging tasks. However, deploying these models on\nresource-constrained devices like the Raspberry Pi poses challenges related to\ncomputational efficiency and thermal management. In this paper, a comprehensive\nevaluation of multiple convolutional neural network (CNN) architectures for\naudio tagging on the Raspberry Pi is conducted, encompassing all 1D and 2D\nmodels from the Pretrained Audio Neural Networks (PANNs) framework, a\nConvNeXt-based model adapted for audio classification, as well as MobileNetV3\narchitectures. In addition, two PANNs-derived networks, CNN9 and CNN13,\nrecently proposed, are also evaluated. To enhance deployment efficiency and\nportability across diverse hardware platforms, all models are converted to the\nOpen Neural Network Exchange (ONNX) format. Unlike previous works that focus on\na single model, our analysis encompasses a broader range of architectures and\ninvolves continuous 24-hour inference sessions to assess performance stability.\nOur experiments reveal that, with appropriate model selection and optimization,\nit is possible to maintain consistent inference latency and manage thermal\nbehavior effectively over extended periods. These findings provide valuable\ninsights for deploying audio tagging models in real-world edge computing\nscenarios.",
      "pdf_url": "http://arxiv.org/pdf/2509.14049v1",
      "published": "2025-09-17T14:53:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.14049v1",
      "categories": [
        "cs.SD",
        "cs.AI"
      ]
    },
    {
      "title": "Prompt2Auto: From Motion Prompt to Automated Control via Geometry-Invariant One-Shot Gaussian Process Learning",
      "authors": [
        "Zewen Yang",
        "Xiaobing Dai",
        "Dongfa Zhang",
        "Yu Li",
        "Ziyang Meng",
        "Bingkun Huang",
        "Hamid Sadeghian",
        "Sami Haddadin"
      ],
      "abstract": "Learning from demonstration allows robots to acquire complex skills from\nhuman demonstrations, but conventional approaches often require large datasets\nand fail to generalize across coordinate transformations. In this paper, we\npropose Prompt2Auto, a geometry-invariant one-shot Gaussian process (GeoGP)\nlearning framework that enables robots to perform human-guided automated\ncontrol from a single motion prompt. A dataset-construction strategy based on\ncoordinate transformations is introduced that enforces invariance to\ntranslation, rotation, and scaling, while supporting multi-step predictions.\nMoreover, GeoGP is robust to variations in the user's motion prompt and\nsupports multi-skill autonomy. We validate the proposed approach through\nnumerical simulations with the designed user graphical interface and two\nreal-world robotic experiments, which demonstrate that the proposed method is\neffective, generalizes across tasks, and significantly reduces the\ndemonstration burden. Project page is available at:\nhttps://prompt2auto.github.io",
      "pdf_url": "http://arxiv.org/pdf/2509.14040v1",
      "published": "2025-09-17T14:42:18+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.14040v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ]
    },
    {
      "title": "PhenoGnet: A Graph-Based Contrastive Learning Framework for Disease Similarity Prediction",
      "authors": [
        "Ranga Baminiwatte",
        "Kazi Jewel Rana",
        "Aaron J. Masino"
      ],
      "abstract": "Understanding disease similarity is critical for advancing diagnostics, drug\ndiscovery, and personalized treatment strategies. We present PhenoGnet, a novel\ngraph-based contrastive learning framework designed to predict disease\nsimilarity by integrating gene functional interaction networks with the Human\nPhenotype Ontology (HPO). PhenoGnet comprises two key components: an intra-view\nmodel that separately encodes gene and phenotype graphs using Graph\nConvolutional Networks (GCNs) and Graph Attention Networks (GATs), and a cross\nview model implemented as a shared weight multilayer perceptron (MLP) that\naligns gene and phenotype embeddings through contrastive learning. The model is\ntrained using known gene phenotype associations as positive pairs and randomly\nsampled unrelated pairs as negatives. Diseases are represented by the mean\nembeddings of their associated genes and/or phenotypes, and pairwise similarity\nis computed via cosine similarity. Evaluation on a curated benchmark of 1,100\nsimilar and 866 dissimilar disease pairs demonstrates strong performance, with\ngene based embeddings achieving an AUCPR of 0.9012 and AUROC of 0.8764,\noutperforming existing state of the art methods. Notably, PhenoGnet captures\nlatent biological relationships beyond direct overlap, offering a scalable and\ninterpretable solution for disease similarity prediction. These results\nunderscore its potential for enabling downstream applications in rare disease\nresearch and precision medicine.",
      "pdf_url": "http://arxiv.org/pdf/2509.14037v1",
      "published": "2025-09-17T14:38:52+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.14037v1",
      "categories": [
        "q-bio.GN",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "SSL-SSAW: Self-Supervised Learning with Sigmoid Self-Attention Weighting for Question-Based Sign Language Translation",
      "authors": [
        "Zekang Liu",
        "Wei Feng",
        "Fanhua Shang",
        "Lianyu Hu",
        "Jichao Feng",
        "Liqing Gao"
      ],
      "abstract": "Sign Language Translation (SLT) bridges the communication gap between deaf\npeople and hearing people, where dialogue provides crucial contextual cues to\naid in translation. Building on this foundational concept, this paper proposes\nQuestion-based Sign Language Translation (QB-SLT), a novel task that explores\nthe efficient integration of dialogue. Unlike gloss (sign language\ntranscription) annotations, dialogue naturally occurs in communication and is\neasier to annotate. The key challenge lies in aligning multimodality features\nwhile leveraging the context of the question to improve translation. To address\nthis issue, we propose a cross-modality Self-supervised Learning with Sigmoid\nSelf-attention Weighting (SSL-SSAW) fusion method for sign language\ntranslation. Specifically, we employ contrastive learning to align\nmultimodality features in QB-SLT, then introduce a Sigmoid Self-attention\nWeighting (SSAW) module for adaptive feature extraction from question and sign\nlanguage sequences. Additionally, we leverage available question text through\nself-supervised learning to enhance representation and translation\ncapabilities. We evaluated our approach on newly constructed CSL-Daily-QA and\nPHOENIX-2014T-QA datasets, where SSL-SSAW achieved SOTA performance. Notably,\neasily accessible question assistance can achieve or even surpass the\nperformance of gloss assistance. Furthermore, visualization results demonstrate\nthe effectiveness of incorporating dialogue in improving translation quality.",
      "pdf_url": "http://arxiv.org/pdf/2509.14036v1",
      "published": "2025-09-17T14:37:59+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.14036v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "You Are What You Train: Effects of Data Composition on Training Context-aware Machine Translation Models",
      "authors": [
        "Paweł Mąka",
        "Yusuf Can Semerci",
        "Jan Scholtes",
        "Gerasimos Spanakis"
      ],
      "abstract": "Achieving human-level translations requires leveraging context to ensure\ncoherence and handle complex phenomena like pronoun disambiguation. Sparsity of\ncontextually rich examples in the standard training data has been hypothesized\nas the reason for the difficulty of context utilization. In this work, we\nsystematically validate this claim in both single- and multilingual settings by\nconstructing training datasets with a controlled proportions of contextually\nrelevant examples. We demonstrate a strong association between training data\nsparsity and model performance confirming sparsity as a key bottleneck.\nImportantly, we reveal that improvements in one contextual phenomenon do no\ngeneralize to others. While we observe some cross-lingual transfer, it is not\nsignificantly higher between languages within the same sub-family. Finally, we\npropose and empirically evaluate two training strategies designed to leverage\nthe available data. These strategies improve context utilization, resulting in\naccuracy gains of up to 6 and 8 percentage points on the ctxPro evaluation in\nsingle- and multilingual settings respectively.",
      "pdf_url": "http://arxiv.org/pdf/2509.14031v1",
      "published": "2025-09-17T14:33:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.14031v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "CrowdAgent: Multi-Agent Managed Multi-Source Annotation System",
      "authors": [
        "Maosheng Qin",
        "Renyu Zhu",
        "Mingxuan Xia",
        "Chenkai Chen",
        "Zhen Zhu",
        "Minmin Lin",
        "Junbo Zhao",
        "Lu Xu",
        "Changjie Fan",
        "Runze Wu",
        "Haobo Wang"
      ],
      "abstract": "High-quality annotated data is a cornerstone of modern Natural Language\nProcessing (NLP). While recent methods begin to leverage diverse annotation\nsources-including Large Language Models (LLMs), Small Language Models (SLMs),\nand human experts-they often focus narrowly on the labeling step itself. A\ncritical gap remains in the holistic process control required to manage these\nsources dynamically, addressing complex scheduling and quality-cost trade-offs\nin a unified manner. Inspired by real-world crowdsourcing companies, we\nintroduce CrowdAgent, a multi-agent system that provides end-to-end process\ncontrol by integrating task assignment, data annotation, and quality/cost\nmanagement. It implements a novel methodology that rationally assigns tasks,\nenabling LLMs, SLMs, and human experts to advance synergistically in a\ncollaborative annotation workflow. We demonstrate the effectiveness of\nCrowdAgent through extensive experiments on six diverse multimodal\nclassification tasks. The source code and video demo are available at\nhttps://github.com/QMMMS/CrowdAgent.",
      "pdf_url": "http://arxiv.org/pdf/2509.14030v1",
      "published": "2025-09-17T14:31:18+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.14030v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Hala Technical Report: Building Arabic-Centric Instruction & Translation Models at Scale",
      "authors": [
        "Hasan Abed Al Kader Hammoud",
        "Mohammad Zbeeb",
        "Bernard Ghanem"
      ],
      "abstract": "We present Hala, a family of Arabic-centric instruction and translation\nmodels built with our translate-and-tune pipeline. We first compress a strong\nAR$\\leftrightarrow$EN teacher to FP8 (yielding $\\sim$2$\\times$ higher\nthroughput with no quality loss) and use it to create high-fidelity bilingual\nsupervision. A lightweight language model LFM2-1.2B is then fine-tuned on this\ndata and used to translate high-quality English instruction sets into Arabic,\nproducing a million-scale corpus tailored to instruction following. We train\nHala models at 350M, 700M, 1.2B, and 9B parameters, and apply slerp merging to\nbalance Arabic specialization with base-model strengths. On Arabic-centric\nbenchmarks, Hala achieves state-of-the-art results within both the \"nano\"\n($\\leq$2B) and \"small\" (7-9B) categories, outperforming their bases. We release\nmodels, data, evaluation, and recipes to accelerate research in Arabic NLP.",
      "pdf_url": "http://arxiv.org/pdf/2509.14008v1",
      "published": "2025-09-17T14:19:28+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.14008v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "RFM-Editing: Rectified Flow Matching for Text-guided Audio Editing",
      "authors": [
        "Liting Gao",
        "Yi Yuan",
        "Yaru Chen",
        "Yuelan Cheng",
        "Zhenbo Li",
        "Juan Wen",
        "Shubin Zhang",
        "Wenwu Wang"
      ],
      "abstract": "Diffusion models have shown remarkable progress in text-to-audio generation.\nHowever, text-guided audio editing remains in its early stages. This task\nfocuses on modifying the target content within an audio signal while preserving\nthe rest, thus demanding precise localization and faithful editing according to\nthe text prompt. Existing training-based and zero-shot methods that rely on\nfull-caption or costly optimization often struggle with complex editing or lack\npracticality. In this work, we propose a novel end-to-end efficient rectified\nflow matching-based diffusion framework for audio editing, and construct a\ndataset featuring overlapping multi-event audio to support training and\nbenchmarking in complex scenarios. Experiments show that our model achieves\nfaithful semantic alignment without requiring auxiliary captions or masks,\nwhile maintaining competitive editing quality across metrics.",
      "pdf_url": "http://arxiv.org/pdf/2509.14003v1",
      "published": "2025-09-17T14:13:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.14003v1",
      "categories": [
        "cs.SD",
        "cs.AI"
      ]
    },
    {
      "title": "MOCHA: Multi-modal Objects-aware Cross-arcHitecture Alignment",
      "authors": [
        "Elena Camuffo",
        "Francesco Barbato",
        "Mete Ozay",
        "Simone Milani",
        "Umberto Michieli"
      ],
      "abstract": "We introduce MOCHA (Multi-modal Objects-aware Cross-arcHitecture Alignment),\na knowledge distillation approach that transfers region-level multimodal\nsemantics from a large vision-language teacher (e.g., LLaVa) into a lightweight\nvision-only object detector student (e.g., YOLO). A translation module maps\nstudent features into a joint space, where the training of the student and\ntranslator is guided by a dual-objective loss that enforces both local\nalignment and global relational consistency. Unlike prior approaches focused on\ndense or global alignment, MOCHA operates at the object level, enabling\nefficient transfer of semantics without modifying the teacher or requiring\ntextual input at inference. We validate our method across four personalized\ndetection benchmarks under few-shot regimes. Results show consistent gains over\nbaselines, with a +10.1 average score improvement. Despite its compact\narchitecture, MOCHA reaches performance on par with larger multimodal models,\nproving its suitability for real-world deployment.",
      "pdf_url": "http://arxiv.org/pdf/2509.14001v1",
      "published": "2025-09-17T14:13:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.14001v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Slim-SC: Thought Pruning for Efficient Scaling with Self-Consistency",
      "authors": [
        "Colin Hong",
        "Xu Guo",
        "Anand Chaanan Singh",
        "Esha Choukse",
        "Dmitrii Ustiugov"
      ],
      "abstract": "Recently, Test-Time Scaling (TTS) has gained increasing attention for\nimproving LLM reasoning performance at test time without retraining the model.\nA notable TTS technique is Self-Consistency (SC), which generates multiple\nreasoning chains in parallel and selects the final answer via majority voting.\nWhile effective, the order-of-magnitude computational overhead limits its broad\ndeployment. Prior attempts to accelerate SC mainly rely on model-based\nconfidence scores or heuristics with limited empirical support. For the first\ntime, we theoretically and empirically analyze the inefficiencies of SC and\nreveal actionable opportunities for improvement. Building on these insights, we\npropose Slim-SC, a step-wise pruning strategy that identifies and removes\nredundant chains using inter-chain similarity at the thought level. Experiments\non three STEM reasoning datasets and two recent LLM architectures show that\nSlim-SC reduces inference latency and KVC usage by up to 45% and 26%,\nrespectively, with R1-Distill, while maintaining or improving accuracy, thus\noffering a simple yet efficient TTS alternative for SC.",
      "pdf_url": "http://arxiv.org/pdf/2509.13990v1",
      "published": "2025-09-17T14:00:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13990v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "I.2.7"
      ]
    },
    {
      "title": "Differential Privacy in Federated Learning: Mitigating Inference Attacks with Randomized Response",
      "authors": [
        "Ozer Ozturk",
        "Busra Buyuktanir",
        "Gozde Karatas Baydogmus",
        "Kazim Yildiz"
      ],
      "abstract": "Machine learning models used for distributed architectures consisting of\nservers and clients require large amounts of data to achieve high accuracy.\nData obtained from clients are collected on a central server for model\ntraining. However, storing data on a central server raises concerns about\nsecurity and privacy. To address this issue, a federated learning architecture\nhas been proposed. In federated learning, each client trains a local model\nusing its own data. The trained models are periodically transmitted to the\ncentral server. The server then combines the received models using federated\naggregation algorithms to obtain a global model. This global model is\ndistributed back to the clients, and the process continues in a cyclical\nmanner. Although preventing data from leaving the clients enhances security,\ncertain concerns still remain. Attackers can perform inference attacks on the\nobtained models to approximate the training dataset, potentially causing data\nleakage. In this study, differential privacy was applied to address the\naforementioned security vulnerability, and a performance analysis was\nconducted. The Data-Unaware Classification Based on Association (duCBA)\nalgorithm was used as the federated aggregation method. Differential privacy\nwas implemented on the data using the Randomized Response technique, and the\ntrade-off between security and performance was examined under different epsilon\nvalues. As the epsilon value decreased, the model accuracy declined, and class\nprediction imbalances were observed. This indicates that higher levels of\nprivacy do not always lead to practical outcomes and that the balance between\nsecurity and performance must be carefully considered.",
      "pdf_url": "http://arxiv.org/pdf/2509.13987v1",
      "published": "2025-09-17T13:59:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13987v1",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "title": "LLM Agents for Interactive Workflow Provenance: Reference Architecture and Evaluation Methodology",
      "authors": [
        "Renan Souza",
        "Timothy Poteet",
        "Brian Etz",
        "Daniel Rosendo",
        "Amal Gueroudji",
        "Woong Shin",
        "Prasanna Balaprakash",
        "Rafael Ferreira da Silva"
      ],
      "abstract": "Modern scientific discovery increasingly relies on workflows that process\ndata across the Edge, Cloud, and High Performance Computing (HPC) continuum.\nComprehensive and in-depth analyses of these data are critical for hypothesis\nvalidation, anomaly detection, reproducibility, and impactful findings.\nAlthough workflow provenance techniques support such analyses, at large scale,\nthe provenance data become complex and difficult to analyze. Existing systems\ndepend on custom scripts, structured queries, or static dashboards, limiting\ndata interaction. In this work, we introduce an evaluation methodology,\nreference architecture, and open-source implementation that leverages\ninteractive Large Language Model (LLM) agents for runtime data analysis. Our\napproach uses a lightweight, metadata-driven design that translates natural\nlanguage into structured provenance queries. Evaluations across LLaMA, GPT,\nGemini, and Claude, covering diverse query classes and a real-world chemistry\nworkflow, show that modular design, prompt tuning, and Retrieval-Augmented\nGeneration (RAG) enable accurate and insightful LLM agent responses beyond\nrecorded provenance.",
      "pdf_url": "http://arxiv.org/pdf/2509.13978v1",
      "published": "2025-09-17T13:51:29+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13978v1",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.DB",
        "68M14, 68M20, 68T07",
        "C.2.4; D.1.3; I.2.0"
      ]
    },
    {
      "title": "Exploring Major Transitions in the Evolution of Biological Cognition With Artificial Neural Networks",
      "authors": [
        "Konstantinos Voudouris",
        "Andrew Barron",
        "Marta Halina",
        "Colin Klein",
        "Matishalin Patel"
      ],
      "abstract": "Transitional accounts of evolution emphasise a few changes that shape what is\nevolvable, with dramatic consequences for derived lineages. More recently it\nhas been proposed that cognition might also have evolved via a series of major\ntransitions that manipulate the structure of biological neural networks,\nfundamentally changing the flow of information. We used idealised models of\ninformation flow, artificial neural networks (ANNs), to evaluate whether\nchanges in information flow in a network can yield a transitional change in\ncognitive performance. We compared networks with feed-forward, recurrent and\nlaminated topologies, and tested their performance learning artificial grammars\nthat differed in complexity, controlling for network size and resources. We\ndocumented a qualitative expansion in the types of input that recurrent\nnetworks can process compared to feed-forward networks, and a related\nqualitative increase in performance for learning the most complex grammars. We\nalso noted how the difficulty in training recurrent networks poses a form of\ntransition barrier and contingent irreversibility -- other key features of\nevolutionary transitions. Not all changes in network topology confer a\nperformance advantage in this task set. Laminated networks did not outperform\nnon-laminated networks in grammar learning. Overall, our findings show how some\nchanges in information flow can yield transitions in cognitive performance.",
      "pdf_url": "http://arxiv.org/pdf/2509.13968v1",
      "published": "2025-09-17T13:38:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13968v1",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.FL",
        "cs.LG"
      ]
    },
    {
      "title": "An Empirical Study on Failures in Automated Issue Solving",
      "authors": [
        "Simiao Liu",
        "Fang Liu",
        "Liehao Li",
        "Xin Tan",
        "Yinghao Zhu",
        "Xiaoli Lian",
        "Li Zhang"
      ],
      "abstract": "Automated issue solving seeks to autonomously identify and repair defective\ncode snippets across an entire codebase. SWE-Bench has emerged as the most\nwidely adopted benchmark for evaluating progress in this area. While LLM-based\nagentic tools show great promise, they still fail on a substantial portion of\ntasks. Moreover, current evaluations primarily report aggregate issue-solving\nrates, which obscure the underlying causes of success and failure, making it\nchallenging to diagnose model weaknesses or guide targeted improvements. To\nbridge this gap, we first analyze the performance and efficiency of three SOTA\ntools, spanning both pipeline-based and agentic architectures, in automated\nissue solving tasks of SWE-Bench-Verified under varying task characteristics.\nFurthermore, to move from high-level performance metrics to underlying cause\nanalysis, we conducted a systematic manual analysis of 150 failed instances.\nFrom this analysis, we developed a comprehensive taxonomy of failure modes\ncomprising 3 primary phases, 9 main categories, and 25 fine-grained\nsubcategories. Then we systematically analyze the distribution of the\nidentified failure modes, the results reveal distinct failure fingerprints\nbetween the two architectural paradigms, with the majority of agentic failures\nstemming from flawed reasoning and cognitive deadlocks. Motivated by these\ninsights, we propose a collaborative Expert-Executor framework. It introduces a\nsupervisory Expert agent tasked with providing strategic oversight and\ncourse-correction for a primary Executor agent. This architecture is designed\nto correct flawed reasoning and break the cognitive deadlocks that frequently\nlead to failure. Experiments show that our framework solves 22.2% of previously\nintractable issues for a leading single agent. These findings pave the way for\nbuilding more robust agents through diagnostic evaluation and collaborative\ndesign.",
      "pdf_url": "http://arxiv.org/pdf/2509.13941v1",
      "published": "2025-09-17T13:07:52+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13941v1",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "DSpAST: Disentangled Representations for Spatial Audio Reasoning with Large Language Models",
      "authors": [
        "Kevin Wilkinghoff",
        "Zheng-Hua Tan"
      ],
      "abstract": "Reasoning about spatial audio with large language models requires a spatial\naudio encoder as an acoustic front-end to obtain audio embeddings for further\nprocessing. Such an encoder needs to capture all information required to detect\nthe type of sound events, as well as the direction and distance of their\ncorresponding sources. Accomplishing this with a single audio encoder is\ndemanding as the information required for each of these tasks is mostly\nindependent of each other. As a result, the performance obtained with a single\nencoder is often worse than when using task-specific audio encoders. In this\nwork, we present DSpAST, a novel audio encoder based on SpatialAST that learns\ndisentangled representations of spatial audio while having only 0.2% additional\nparameters. Experiments on SpatialSoundQA with the spatial audio reasoning\nsystem BAT demonstrate that DSpAST significantly outperforms SpatialAST.",
      "pdf_url": "http://arxiv.org/pdf/2509.13927v1",
      "published": "2025-09-17T12:51:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13927v1",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.SD"
      ]
    },
    {
      "title": "MAP: End-to-End Autonomous Driving with Map-Assisted Planning",
      "authors": [
        "Huilin Yin",
        "Yiming Kan",
        "Daniel Watzenig"
      ],
      "abstract": "In recent years, end-to-end autonomous driving has attracted increasing\nattention for its ability to jointly model perception, prediction, and planning\nwithin a unified framework. However, most existing approaches underutilize the\nonline mapping module, leaving its potential to enhance trajectory planning\nlargely untapped. This paper proposes MAP (Map-Assisted Planning), a novel\nmap-assisted end-to-end trajectory planning framework. MAP explicitly\nintegrates segmentation-based map features and the current ego status through a\nPlan-enhancing Online Mapping module, an Ego-status-guided Planning module, and\na Weight Adapter based on current ego status. Experiments conducted on the\nDAIR-V2X-seq-SPD dataset demonstrate that the proposed method achieves a 16.6%\nreduction in L2 displacement error, a 56.2% reduction in off-road rate, and a\n44.5% improvement in overall score compared to the UniV2X baseline, even\nwithout post-processing. Furthermore, it achieves top ranking in Track 2 of the\nEnd-to-End Autonomous Driving through V2X Cooperation Challenge of MEIS\nWorkshop @CVPR2025, outperforming the second-best model by 39.5% in terms of\noverall score. These results highlight the effectiveness of explicitly\nleveraging semantic map features in planning and suggest new directions for\nimproving structure design in end-to-end autonomous driving systems. Our code\nis available at https://gitee.com/kymkym/map.git",
      "pdf_url": "http://arxiv.org/pdf/2509.13926v1",
      "published": "2025-09-17T11:40:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13926v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "I.2.9; I.2.10"
      ]
    },
    {
      "title": "Ensemble of Pre-Trained Models for Long-Tailed Trajectory Prediction",
      "authors": [
        "Divya Thuremella",
        "Yi Yang",
        "Simon Wanna",
        "Lars Kunze",
        "Daniele De Martini"
      ],
      "abstract": "This work explores the application of ensemble modeling to the\nmultidimensional regression problem of trajectory prediction for vehicles in\nurban environments. As newer and bigger state-of-the-art prediction models for\nautonomous driving continue to emerge, an important open challenge is the\nproblem of how to combine the strengths of these big models without the need\nfor costly re-training. We show how, perhaps surprisingly, combining\nstate-of-the-art deep learning models out-of-the-box (without retraining or\nfine-tuning) with a simple confidence-weighted average method can enhance the\noverall prediction. Indeed, while combining trajectory prediction models is not\nstraightforward, this simple approach enhances performance by 10% over the best\nprediction model, especially in the long-tailed metrics. We show that this\nperformance improvement holds on both the NuScenes and Argoverse datasets, and\nthat these improvements are made across the dataset distribution. The code for\nour work is open source.",
      "pdf_url": "http://arxiv.org/pdf/2509.13914v1",
      "published": "2025-09-17T11:18:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13914v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Do Large Language Models Understand Word Senses?",
      "authors": [
        "Domenico Meconi",
        "Simone Stirpe",
        "Federico Martelli",
        "Leonardo Lavalle",
        "Roberto Navigli"
      ],
      "abstract": "Understanding the meaning of words in context is a fundamental capability for\nLarge Language Models (LLMs). Despite extensive evaluation efforts, the extent\nto which LLMs show evidence that they truly grasp word senses remains\nunderexplored. In this paper, we address this gap by evaluating both i) the\nWord Sense Disambiguation (WSD) capabilities of instruction-tuned LLMs,\ncomparing their performance to state-of-the-art systems specifically designed\nfor the task, and ii) the ability of two top-performing open- and closed-source\nLLMs to understand word senses in three generative settings: definition\ngeneration, free-form explanation, and example generation. Notably, we find\nthat, in the WSD task, leading models such as GPT-4o and DeepSeek-V3 achieve\nperformance on par with specialized WSD systems, while also demonstrating\ngreater robustness across domains and levels of difficulty. In the generation\ntasks, results reveal that LLMs can explain the meaning of words in context up\nto 98\\% accuracy, with the highest performance observed in the free-form\nexplanation task, which best aligns with their generative capabilities.",
      "pdf_url": "http://arxiv.org/pdf/2509.13905v1",
      "published": "2025-09-17T11:11:27+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13905v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "FedSSG: Expectation-Gated and History-Aware Drift Alignment for Federated Learning",
      "authors": [
        "Zhanting Zhou",
        "Jinshan Lai",
        "Fengchun Zhang",
        "Zeqin Wu",
        "Fengli Zhang"
      ],
      "abstract": "Non-IID data and partial participation induce client drift and inconsistent\nlocal optima in federated learning, causing unstable convergence and accuracy\nloss. We present FedSSG, a stochastic sampling-guided, history-aware drift\nalignment method. FedSSG maintains a per-client drift memory that accumulates\nlocal model differences as a lightweight sketch of historical gradients;\ncrucially, it gates both the memory update and the local alignment term by a\nsmooth function of the observed/expected participation ratio (a\nphase-by-expectation signal derived from the server sampler). This\nstatistically grounded gate stays weak and smooth when sampling noise dominates\nearly, then strengthens once participation statistics stabilize, contracting\nthe local-global gap without extra communication. Across CIFAR-10/100 with\n100/500 clients and 2-15 percent participation, FedSSG consistently outperforms\nstrong drift-aware baselines and accelerates convergence; on our benchmarks it\nimproves test accuracy by up to a few points (e.g., about +0.9 on CIFAR-10 and\nabout +2.7 on CIFAR-100 on average over the top-2 baseline) and yields about\n4.5x faster target-accuracy convergence on average. The method adds only O(d)\nclient memory and a constant-time gate, and degrades gracefully to a mild\nregularizer under near-IID or uniform sampling. FedSSG shows that sampling\nstatistics can be turned into a principled, history-aware phase control to\nstabilize and speed up federated training.",
      "pdf_url": "http://arxiv.org/pdf/2509.13895v1",
      "published": "2025-09-17T10:43:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13895v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Synthetic Data Generation for Screen Time and App Usage",
      "authors": [
        "Gustavo Kruger",
        "Nikhil Sachdeva",
        "Michael Sobolev"
      ],
      "abstract": "Smartphone usage data can provide valuable insights for understanding\ninteraction with technology and human behavior. However, collecting\nlarge-scale, in-the-wild smartphone usage logs is challenging due to high\ncosts, privacy concerns, under representative user samples and biases like\nnon-response that can skew results. These challenges call for exploring\nalternative approaches to obtain smartphone usage datasets. In this context,\nlarge language models (LLMs) such as Open AI's ChatGPT present a novel approach\nfor synthetic smartphone usage data generation, addressing limitations of\nreal-world data collection. We describe a case study on how four prompt\nstrategies influenced the quality of generated smartphone usage data. We\ncontribute with insights on prompt design and measures of data quality,\nreporting a prompting strategy comparison combining two factors, prompt level\nof detail (describing a user persona, describing the expected results\ncharacteristics) and seed data inclusion (with versus without an initial real\nusage example). Our findings suggest that using LLMs to generate structured and\nbehaviorally plausible smartphone use datasets is feasible for some use cases,\nespecially when using detailed prompts. Challenges remain in capturing diverse\nnuances of human behavioral patterns in a single synthetic dataset, and\nevaluating tradeoffs between data fidelity and diversity, suggesting the need\nfor use-case-specific evaluation metrics and future research with more diverse\nseed data and different LLM models.",
      "pdf_url": "http://arxiv.org/pdf/2509.13892v1",
      "published": "2025-09-17T10:42:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13892v1",
      "categories": [
        "cs.HC",
        "cs.AI",
        "I.2; J.4"
      ]
    },
    {
      "title": "Combating Biomedical Misinformation through Multi-modal Claim Detection and Evidence-based Verification",
      "authors": [
        "Mariano Barone",
        "Antonio Romano",
        "Giuseppe Riccio",
        "Marco Postiglione",
        "Vincenzo Moscato"
      ],
      "abstract": "Misinformation in healthcare, from vaccine hesitancy to unproven treatments,\nposes risks to public health and trust in medical systems. While machine\nlearning and natural language processing have advanced automated fact-checking,\nvalidating biomedical claims remains uniquely challenging due to complex\nterminology, the need for domain expertise, and the critical importance of\ngrounding in scientific evidence. We introduce CER (Combining Evidence and\nReasoning), a novel framework for biomedical fact-checking that integrates\nscientific evidence retrieval, reasoning via large language models, and\nsupervised veracity prediction. By integrating the text-generation capabilities\nof large language models with advanced retrieval techniques for high-quality\nbiomedical scientific evidence, CER effectively mitigates the risk of\nhallucinations, ensuring that generated outputs are grounded in verifiable,\nevidence-based sources. Evaluations on expert-annotated datasets (HealthFC,\nBioASQ-7b, SciFact) demonstrate state-of-the-art performance and promising\ncross-dataset generalization. Code and data are released for transparency and\nreproducibility: https://github.com/PRAISELab-PicusLab/CER",
      "pdf_url": "http://arxiv.org/pdf/2509.13888v1",
      "published": "2025-09-17T10:31:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13888v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ]
    },
    {
      "title": "An Exhaustive DPLL Approach to Model Counting over Integer Linear Constraints with Simplification Techniques",
      "authors": [
        "Mingwei Zhang",
        "Zhenhao Gu",
        "Liangda Fang",
        "Cunjing Ge",
        "Ziliang Chen",
        "Zhao-Rong Lai",
        "Quanlong Guan"
      ],
      "abstract": "Linear constraints are one of the most fundamental constraints in fields such\nas computer science, operations research and optimization. Many applications\nreduce to the task of model counting over integer linear constraints (MCILC).\nIn this paper, we design an exact approach to MCILC based on an exhaustive DPLL\narchitecture. To improve the efficiency, we integrate several effective\nsimplification techniques from mixed integer programming into the architecture.\nWe compare our approach to state-of-the-art MCILC counters and propositional\nmodel counters on 2840 random and 4131 application benchmarks. Experimental\nresults show that our approach significantly outperforms all exact methods in\nrandom benchmarks solving 1718 instances while the state-of-the-art approach\nonly computes 1470 instances. In addition, our approach is the only approach to\nsolve all 4131 application instances.",
      "pdf_url": "http://arxiv.org/pdf/2509.13880v1",
      "published": "2025-09-17T10:19:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13880v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Combining Evidence and Reasoning for Biomedical Fact-Checking",
      "authors": [
        "Mariano Barone",
        "Antonio Romano",
        "Giuseppe Riccio",
        "Marco Postiglione",
        "Vincenzo Moscato"
      ],
      "abstract": "Misinformation in healthcare, from vaccine hesitancy to unproven treatments,\nposes risks to public health and trust in medical systems. While machine\nlearning and natural language processing have advanced automated fact-checking,\nvalidating biomedical claims remains uniquely challenging due to complex\nterminology, the need for domain expertise, and the critical importance of\ngrounding in scientific evidence. We introduce CER (Combining Evidence and\nReasoning), a novel framework for biomedical fact-checking that integrates\nscientific evidence retrieval, reasoning via large language models, and\nsupervised veracity prediction. By integrating the text-generation capabilities\nof large language models with advanced retrieval techniques for high-quality\nbiomedical scientific evidence, CER effectively mitigates the risk of\nhallucinations, ensuring that generated outputs are grounded in verifiable,\nevidence-based sources. Evaluations on expert-annotated datasets (HealthFC,\nBioASQ-7b, SciFact) demonstrate state-of-the-art performance and promising\ncross-dataset generalization. Code and data are released for transparency and\nreproducibility: https: //github.com/PRAISELab-PicusLab/CER.",
      "pdf_url": "http://arxiv.org/pdf/2509.13879v1",
      "published": "2025-09-17T10:14:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13879v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ]
    },
    {
      "title": "Masked Diffusion Models as Energy Minimization",
      "authors": [
        "Sitong Chen",
        "Shen Nie",
        "Jiacheng Sun",
        "Zijin Feng",
        "Zhenguo Li",
        "Ji-Rong Wen",
        "Chongxuan Li"
      ],
      "abstract": "We present a systematic theoretical framework that interprets masked\ndiffusion models (MDMs) as solutions to energy minimization problems in\ndiscrete optimal transport. Specifically, we prove that three distinct energy\nformulations--kinetic, conditional kinetic, and geodesic energy--are\nmathematically equivalent under the structure of MDMs, and that MDMs minimize\nall three when the mask schedule satisfies a closed-form optimality condition.\nThis unification not only clarifies the theoretical foundations of MDMs, but\nalso motivates practical improvements in sampling. By parameterizing\ninterpolation schedules via Beta distributions, we reduce the schedule design\nspace to a tractable 2D search, enabling efficient post-training tuning without\nmodel modification. Experiments on synthetic and real-world benchmarks\ndemonstrate that our energy-inspired schedules outperform hand-crafted\nbaselines, particularly in low-step sampling settings.",
      "pdf_url": "http://arxiv.org/pdf/2509.13866v1",
      "published": "2025-09-17T09:57:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13866v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Understanding the Process of Human-AI Value Alignment",
      "authors": [
        "Jack McKinlay",
        "Marina De Vos",
        "Janina A. Hoffmann",
        "Andreas Theodorou"
      ],
      "abstract": "Background: Value alignment in computer science research is often used to\nrefer to the process of aligning artificial intelligence with humans, but the\nway the phrase is used often lacks precision. Objectives: In this paper, we\nconduct a systematic literature review to advance the understanding of value\nalignment in artificial intelligence by characterising the topic in the context\nof its research literature. We use this to suggest a more precise definition of\nthe term. Methods: We analyse 172 value alignment research articles that have\nbeen published in recent years and synthesise their content using thematic\nanalyses. Results: Our analysis leads to six themes: value alignment drivers &\napproaches; challenges in value alignment; values in value alignment; cognitive\nprocesses in humans and AI; human-agent teaming; and designing and developing\nvalue-aligned systems. Conclusions: By analysing these themes in the context of\nthe literature we define value alignment as an ongoing process between humans\nand autonomous agents that aims to express and implement abstract values in\ndiverse contexts, while managing the cognitive limits of both humans and AI\nagents and also balancing the conflicting ethical and political demands\ngenerated by the values in different groups. Our analysis gives rise to a set\nof research challenges and opportunities in the field of value alignment for\nfuture work.",
      "pdf_url": "http://arxiv.org/pdf/2509.13854v1",
      "published": "2025-09-17T09:39:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13854v1",
      "categories": [
        "cs.CY",
        "cs.AI"
      ]
    },
    {
      "title": "Towards a Physics Foundation Model",
      "authors": [
        "Florian Wiesner",
        "Matthias Wessling",
        "Stephen Baek"
      ],
      "abstract": "Foundation models have revolutionized natural language processing through a\n``train once, deploy anywhere'' paradigm, where a single pre-trained model\nadapts to countless downstream tasks without retraining. Access to a Physics\nFoundation Model (PFM) would be transformative -- democratizing access to\nhigh-fidelity simulations, accelerating scientific discovery, and eliminating\nthe need for specialized solver development. Yet current physics-aware machine\nlearning approaches remain fundamentally limited to single, narrow domains and\nrequire retraining for each new system. We present the General Physics\nTransformer (GPhyT), trained on 1.8 TB of diverse simulation data, that\ndemonstrates foundation model capabilities are achievable for physics. Our key\ninsight is that transformers can learn to infer governing dynamics from\ncontext, enabling a single model to simulate fluid-solid interactions, shock\nwaves, thermal convection, and multi-phase dynamics without being told the\nunderlying equations. GPhyT achieves three critical breakthroughs: (1) superior\nperformance across multiple physics domains, outperforming specialized\narchitectures by up to 29x, (2) zero-shot generalization to entirely unseen\nphysical systems through in-context learning, and (3) stable long-term\npredictions through 50-timestep rollouts. By establishing that a single model\ncan learn generalizable physical principles from data alone, this work opens\nthe path toward a universal PFM that could transform computational science and\nengineering.",
      "pdf_url": "http://arxiv.org/pdf/2509.13805v1",
      "published": "2025-09-17T08:19:57+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13805v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ]
    },
    {
      "title": "Bridging the Synthetic-Real Gap: Supervised Domain Adaptation for Robust Spacecraft 6-DoF Pose Estimation",
      "authors": [
        "Inder Pal Singh",
        "Nidhal Eddine Chenni",
        "Abd El Rahman Shabayek",
        "Arunkumar Rathinam",
        "Djamila Aouada"
      ],
      "abstract": "Spacecraft Pose Estimation (SPE) is a fundamental capability for autonomous\nspace operations such as rendezvous, docking, and in-orbit servicing. Hybrid\npipelines that combine object detection, keypoint regression, and\nPerspective-n-Point (PnP) solvers have recently achieved strong results on\nsynthetic datasets, yet their performance deteriorates sharply on real or\nlab-generated imagery due to the persistent synthetic-to-real domain gap.\nExisting unsupervised domain adaptation approaches aim to mitigate this issue\nbut often underperform when a modest number of labeled target samples are\navailable. In this work, we propose the first Supervised Domain Adaptation\n(SDA) framework tailored for SPE keypoint regression. Building on the Learning\nInvariant Representation and Risk (LIRR) paradigm, our method jointly optimizes\ndomain-invariant representations and task-specific risk using both labeled\nsynthetic and limited labeled real data, thereby reducing generalization error\nunder domain shift. Extensive experiments on the SPEED+ benchmark demonstrate\nthat our approach consistently outperforms source-only, fine-tuning, and oracle\nbaselines. Notably, with only 5% labeled target data, our method matches or\nsurpasses oracle performance trained on larger fractions of labeled data. The\nframework is lightweight, backbone-agnostic, and computationally efficient,\noffering a practical pathway toward robust and deployable spacecraft pose\nestimation in real-world space environments.",
      "pdf_url": "http://arxiv.org/pdf/2509.13792v1",
      "published": "2025-09-17T08:03:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13792v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Teaching According to Talents! Instruction Tuning LLMs with Competence-Aware Curriculum Learning",
      "authors": [
        "Yangning Li",
        "Tingwei Lu",
        "Yinghui Li",
        "Yankai Chen",
        "Wei-Chieh Huang",
        "Wenhao Jiang",
        "Hui Wang",
        "Hai-Tao Zheng",
        "Philip S. Yu"
      ],
      "abstract": "Efficient instruction tuning aims to enhance the ultimate performance of\nlarge language models (LLMs) trained on a given instruction dataset. Curriculum\nlearning as a typical data organization strategy has shown preliminary\neffectiveness in instruction tuning. However, current curriculum tuning methods\nsuffer from the curriculum rigidity, since they rely solely on static heuristic\ndifficulty metrics. These methods fail to adapt to the evolving capabilities of\nmodels during training, resulting in a fixed and potentially sub-optimal\nlearning trajectory. To address the issue, Competence-Aware Multi-Perspective\ncUrriculum inStruction tuning framework termed CAMPUS is proposed. CAMPUS\noffers several advantages: (1) Dynamic selection for sub-curriculum. (2)\nCompetency-aware adjustment to the curriculum schedule. (3) Multiple\ndifficulty-based scheduling. Extensive experiments prove the superior\nperformance of CAMPUS, compared to other state-of-the-art baselines for\nefficient instruction tuning.",
      "pdf_url": "http://arxiv.org/pdf/2509.13790v1",
      "published": "2025-09-17T07:58:59+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13790v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "BWCache: Accelerating Video Diffusion Transformers through Block-Wise Caching",
      "authors": [
        "Hanshuai Cui",
        "Zhiqing Tang",
        "Zhifei Xu",
        "Zhi Yao",
        "Wenyi Zeng",
        "Weijia Jia"
      ],
      "abstract": "Recent advancements in Diffusion Transformers (DiTs) have established them as\nthe state-of-the-art method for video generation. However, their inherently\nsequential denoising process results in inevitable latency, limiting real-world\napplicability. Existing acceleration methods either compromise visual quality\ndue to architectural modifications or fail to reuse intermediate features at\nproper granularity. Our analysis reveals that DiT blocks are the primary\ncontributors to inference latency. Across diffusion timesteps, the feature\nvariations of DiT blocks exhibit a U-shaped pattern with high similarity during\nintermediate timesteps, which suggests substantial computational redundancy. In\nthis paper, we propose Block-Wise Caching (BWCache), a training-free method to\naccelerate DiT-based video generation. BWCache dynamically caches and reuses\nfeatures from DiT blocks across diffusion timesteps. Furthermore, we introduce\na similarity indicator that triggers feature reuse only when the differences\nbetween block features at adjacent timesteps fall below a threshold, thereby\nminimizing redundant computations while maintaining visual fidelity. Extensive\nexperiments on several video diffusion models demonstrate that BWCache achieves\nup to 2.24$\\times$ speedup with comparable visual quality.",
      "pdf_url": "http://arxiv.org/pdf/2509.13789v2",
      "published": "2025-09-17T07:58:36+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13789v2",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Who is Introducing the Failure? Automatically Attributing Failures of Multi-Agent Systems via Spectrum Analysis",
      "authors": [
        "Yu Ge",
        "Linna Xie",
        "Zhong Li",
        "Yu Pei",
        "Tian Zhang"
      ],
      "abstract": "Large Language Model Powered Multi-Agent Systems (MASs) are increasingly\nemployed to automate complex real-world problems, such as programming and\nscientific discovery. Despite their promising, MASs are not without their\nflaws. However, failure attribution in MASs - pinpointing the specific agent\nactions responsible for failures - remains underexplored and labor-intensive,\nposing significant challenges for debugging and system improvement. To bridge\nthis gap, we propose FAMAS, the first spectrum-based failure attribution\napproach for MASs, which operates through systematic trajectory replay and\nabstraction, followed by spectrum analysis.The core idea of FAMAS is to\nestimate, from variations across repeated MAS executions, the likelihood that\neach agent action is responsible for the failure. In particular, we propose a\nnovel suspiciousness formula tailored to MASs, which integrates two key factor\ngroups, namely the agent behavior group and the action behavior group, to\naccount for the agent activation patterns and the action activation patterns\nwithin the execution trajectories of MASs. Through expensive evaluations\nagainst 12 baselines on the Who and When benchmark, FAMAS demonstrates superior\nperformance by outperforming all the methods in comparison.",
      "pdf_url": "http://arxiv.org/pdf/2509.13782v1",
      "published": "2025-09-17T07:50:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13782v1",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.MA",
        "D.2.2; I.2.1"
      ]
    },
    {
      "title": "Exploring Data and Parameter Efficient Strategies for Arabic Dialect Identifications",
      "authors": [
        "Vani Kanjirangat",
        "Ljiljana Dolamic",
        "Fabio Rinaldi"
      ],
      "abstract": "This paper discusses our exploration of different data-efficient and\nparameter-efficient approaches to Arabic Dialect Identification (ADI). In\nparticular, we investigate various soft-prompting strategies, including\nprefix-tuning, prompt-tuning, P-tuning, and P-tuning V2, as well as LoRA\nreparameterizations. For the data-efficient strategy, we analyze hard prompting\nwith zero-shot and few-shot inferences to analyze the dialect identification\ncapabilities of Large Language Models (LLMs). For the parameter-efficient PEFT\napproaches, we conducted our experiments using Arabic-specific encoder models\non several major datasets. We also analyzed the n-shot inferences on\nopen-source decoder-only models, a general multilingual model (Phi-3.5), and an\nArabic-specific one(SILMA). We observed that the LLMs generally struggle to\ndifferentiate the dialectal nuances in the few-shot or zero-shot setups. The\nsoft-prompted encoder variants perform better, while the LoRA-based fine-tuned\nmodels perform best, even surpassing full fine-tuning.",
      "pdf_url": "http://arxiv.org/pdf/2509.13775v2",
      "published": "2025-09-17T07:45:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13775v2",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "MIRA: Empowering One-Touch AI Services on Smartphones with MLLM-based Instruction Recommendation",
      "authors": [
        "Zhipeng Bian",
        "Jieming Zhu",
        "Xuyang Xie",
        "Quanyu Dai",
        "Zhou Zhao",
        "Zhenhua Dong"
      ],
      "abstract": "The rapid advancement of generative AI technologies is driving the\nintegration of diverse AI-powered services into smartphones, transforming how\nusers interact with their devices. To simplify access to predefined AI\nservices, this paper introduces MIRA, a pioneering framework for task\ninstruction recommendation that enables intuitive one-touch AI tasking on\nsmartphones. With MIRA, users can long-press on images or text objects to\nreceive contextually relevant instruction recommendations for executing AI\ntasks. Our work introduces three key innovations: 1) A multimodal large\nlanguage model (MLLM)-based recommendation pipeline with structured reasoning\nto extract key entities, infer user intent, and generate precise instructions;\n2) A template-augmented reasoning mechanism that integrates high-level\nreasoning templates, enhancing task inference accuracy; 3) A prefix-tree-based\nconstrained decoding strategy that restricts outputs to predefined instruction\ncandidates, ensuring coherent and intent-aligned suggestions. Through\nevaluation using a real-world annotated datasets and a user study, MIRA has\ndemonstrated substantial improvements in the accuracy of instruction\nrecommendation. The encouraging results highlight MIRA's potential to\nrevolutionize the way users engage with AI services on their smartphones,\noffering a more seamless and efficient experience.",
      "pdf_url": "http://arxiv.org/pdf/2509.13773v1",
      "published": "2025-09-17T07:43:14+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13773v1",
      "categories": [
        "cs.AI",
        "cs.IR",
        "I.2.7; I.2.10"
      ]
    },
    {
      "title": "THOR: Tool-Integrated Hierarchical Optimization via RL for Mathematical Reasoning",
      "authors": [
        "Qikai Chang",
        "Zhenrong Zhang",
        "Pengfei Hu",
        "Jiefeng Ma",
        "Yicheng Pan",
        "Jianshu Zhang",
        "Jun Du",
        "Quan Liu",
        "Jianqing Gao"
      ],
      "abstract": "Large Language Models (LLMs) have made remarkable progress in mathematical\nreasoning, but still continue to struggle with high-precision tasks like\nnumerical computation and formal symbolic manipulation. Integrating external\ntools has emerged as a promising approach to bridge this gap. Despite recent\nadvances, existing methods struggle with three key challenges: constructing\ntool-integrated reasoning data, performing fine-grained optimization, and\nenhancing inference. To overcome these limitations, we propose THOR\n(Tool-Integrated Hierarchical Optimization via RL). First, we introduce TIRGen,\na multi-agent actor-critic-based pipeline for constructing high-quality\ndatasets of tool-integrated reasoning paths, aligning with the policy and\ngeneralizing well across diverse models. Second, to perform fine-grained\nhierarchical optimization, we introduce an RL strategy that jointly optimizes\nfor both trajectory-level problem solving and step-level code generation. This\nis motivated by our key insight that the success of an intermediate tool call\nis a strong predictor of the final answer's correctness. Finally, THOR\nincorporates a self-correction mechanism that leverages immediate tool feedback\nto dynamically revise erroneous reasoning paths during inference. Our approach\ndemonstrates strong generalization across diverse models, performing\neffectively in both reasoning and non-reasoning models. It further achieves\nstate-of-the-art performance for models of a similar scale on multiple\nmathematical benchmarks, while also delivering consistent improvements on code\nbenchmarks. Our code will be publicly available at\nhttps://github.com/JingMog/THOR.",
      "pdf_url": "http://arxiv.org/pdf/2509.13761v1",
      "published": "2025-09-17T07:16:12+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13761v1",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Scrub It Out! Erasing Sensitive Memorization in Code Language Models via Machine Unlearning",
      "authors": [
        "Zhaoyang Chu",
        "Yao Wan",
        "Zhikun Zhang",
        "Di Wang",
        "Zhou Yang",
        "Hongyu Zhang",
        "Pan Zhou",
        "Xuanhua Shi",
        "Hai Jin",
        "David Lo"
      ],
      "abstract": "While Code Language Models (CLMs) have demonstrated superior performance in\nsoftware engineering tasks such as code generation and summarization, recent\nempirical studies reveal a critical privacy vulnerability: these models exhibit\nunintended memorization of sensitive training data, enabling verbatim\nreproduction of confidential information when specifically prompted. To address\nthis issue, several approaches, including training data de-duplication and\ndifferential privacy augmentation, have been proposed. However, these methods\nrequire full-model retraining for deployed CLMs, which incurs substantial\ncomputational costs. In this paper, we aim to answer the following research\nquestion: Can sensitive information memorized by CLMs be erased effectively and\nefficiently?\n  We conduct a pioneering investigation into erasing sensitive memorization in\nCLMs through machine unlearning - a post-hoc modification method that removes\nspecific information from trained models without requiring full retraining.\nSpecifically, we first quantify the memorization risks of sensitive data within\nCLM training datasets and curate a high-risk dataset of 50,000 sensitive\nmemorized samples as unlearning targets. We study two widely used gradient\nascent-based unlearning approaches: the vanilla and constraint-based methods,\nand introduce CodeEraser, an advanced variant that selectively unlearns\nsensitive memorized segments in code while preserving the structural integrity\nand functional correctness of the surrounding code. Extensive experiments on\nthree families of CLMs, i.e., CodeParrot, CodeGen-Mono, and Qwen2.5-Coder,\nvalidate the effectiveness and efficiency of CodeEraser in erasing targeted\nsensitive memorization while maintaining model utility.",
      "pdf_url": "http://arxiv.org/pdf/2509.13755v1",
      "published": "2025-09-17T07:12:35+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13755v1",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CR"
      ]
    },
    {
      "title": "State Space Models over Directed Graphs",
      "authors": [
        "Junzhi She",
        "Xunkai Li",
        "Rong-Hua Li",
        "Guoren Wang"
      ],
      "abstract": "Directed graphs are ubiquitous across numerous domains, where the\ndirectionality of edges encodes critical causal dependencies. However, existing\nGNNs and graph Transformers tailored for directed graphs face two major\nchallenges: (1) effectively capturing long-range causal dependencies derived\nfrom directed edges; (2) balancing accuracy and training efficiency when\nprocessing large-scale graph datasets. In recent years, state space models\n(SSMs) have achieved substantial progress in causal sequence tasks, and their\nvariants designed for graphs have demonstrated state-of-the-art accuracy while\nmaintaining high efficiency across various graph learning benchmarks. However,\nexisting graph state space models are exclusively designed for undirected\ngraphs, which limits their performance in directed graph learning. To this end,\nwe propose an innovative approach DirEgo2Token which sequentializes directed\ngraphs via k-hop ego graphs. This marks the first systematic extension of state\nspace models to the field of directed graph learning. Building upon this, we\ndevelop DirGraphSSM, a novel directed graph neural network architecture that\nimplements state space models on directed graphs via the message-passing\nmechanism. Experimental results demonstrate that DirGraphSSM achieves\nstate-of-the-art performance on three representative directed graph learning\ntasks while attaining competitive performance on two additional tasks with\n1.5$\\times $ to 2$\\times $ training speed improvements compared to existing\nstate-of-the-art models.",
      "pdf_url": "http://arxiv.org/pdf/2509.13735v1",
      "published": "2025-09-17T06:39:18+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13735v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Mitigating Query Selection Bias in Referring Video Object Segmentation",
      "authors": [
        "Dingwei Zhang",
        "Dong Zhang",
        "Jinhui Tang"
      ],
      "abstract": "Recently, query-based methods have achieved remarkable performance in\nReferring Video Object Segmentation (RVOS) by using textual static object\nqueries to drive cross-modal alignment. However, these static queries are\neasily misled by distractors with similar appearance or motion, resulting in\n\\emph{query selection bias}. To address this issue, we propose Triple Query\nFormer (TQF), which factorizes the referring query into three specialized\ncomponents: an appearance query for static attributes, an intra-frame\ninteraction query for spatial relations, and an inter-frame motion query for\ntemporal association. Instead of relying solely on textual embeddings, our\nqueries are dynamically constructed by integrating both linguistic cues and\nvisual guidance. Furthermore, we introduce two motion-aware aggregation modules\nthat enhance object token representations: Intra-frame Interaction Aggregation\nincorporates position-aware interactions among objects within a single frame,\nwhile Inter-frame Motion Aggregation leverages trajectory-guided alignment\nacross frames to ensure temporal coherence. Extensive experiments on multiple\nRVOS benchmarks demonstrate the advantages of TQF and the effectiveness of our\nstructured query design and motion-aware aggregation modules.",
      "pdf_url": "http://arxiv.org/pdf/2509.13722v1",
      "published": "2025-09-17T06:17:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13722v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Automated Triaging and Transfer Learning of Incident Learning Safety Reports Using Large Language Representational Models",
      "authors": [
        "Peter Beidler",
        "Mark Nguyen",
        "Kevin Lybarger",
        "Ola Holmberg",
        "Eric Ford",
        "John Kang"
      ],
      "abstract": "PURPOSE: Incident reports are an important tool for safety and quality\nimprovement in healthcare, but manual review is time-consuming and requires\nsubject matter expertise. Here we present a natural language processing (NLP)\nscreening tool to detect high-severity incident reports in radiation oncology\nacross two institutions.\n  METHODS AND MATERIALS: We used two text datasets to train and evaluate our\nNLP models: 7,094 reports from our institution (Inst.), and 571 from IAEA\nSAFRON (SF), all of which had severity scores labeled by clinical content\nexperts. We trained and evaluated two types of models: baseline support vector\nmachines (SVM) and BlueBERT which is a large language model pretrained on\nPubMed abstracts and hospitalized patient data. We assessed for\ngeneralizability of our model in two ways. First, we evaluated models trained\nusing Inst.-train on SF-test. Second, we trained a BlueBERT_TRANSFER model that\nwas first fine-tuned on Inst.-train then on SF-train before testing on SF-test\nset. To further analyze model performance, we also examined a subset of 59\nreports from our Inst. dataset, which were manually edited for clarity.\n  RESULTS Classification performance on the Inst. test achieved AUROC 0.82\nusing SVM and 0.81 using BlueBERT. Without cross-institution transfer learning,\nperformance on the SF test was limited to an AUROC of 0.42 using SVM and 0.56\nusing BlueBERT. BlueBERT_TRANSFER, which was fine-tuned on both datasets,\nimproved the performance on SF test to AUROC 0.78. Performance of SVM, and\nBlueBERT_TRANSFER models on the manually curated Inst. reports (AUROC 0.85 and\n0.74) was similar to human performance (AUROC 0.81).\n  CONCLUSION: In summary, we successfully developed cross-institution NLP\nmodels on incident report text from radiation oncology centers. These models\nwere able to detect high-severity reports similarly to humans on a curated\ndataset.",
      "pdf_url": "http://arxiv.org/pdf/2509.13706v1",
      "published": "2025-09-17T05:29:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13706v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "InfraMind: A Novel Exploration-based GUI Agentic Framework for Mission-critical Industrial Management",
      "authors": [
        "Liangtao Lin",
        "Zhaomeng Zhu",
        "Tianwei Zhang",
        "Yonggang Wen"
      ],
      "abstract": "Mission-critical industrial infrastructure, such as data centers,\nincreasingly depends on complex management software. Its operations, however,\npose significant challenges due to the escalating system complexity,\nmulti-vendor integration, and a shortage of expert operators. While Robotic\nProcess Automation (RPA) offers partial automation through handcrafted scripts,\nit suffers from limited flexibility and high maintenance costs. Recent advances\nin Large Language Model (LLM)-based graphical user interface (GUI) agents have\nenabled more flexible automation, yet these general-purpose agents face five\ncritical challenges when applied to industrial management, including unfamiliar\nelement understanding, precision and efficiency, state localization, deployment\nconstraints, and safety requirements. To address these issues, we propose\nInfraMind, a novel exploration-based GUI agentic framework specifically\ntailored for industrial management systems. InfraMind integrates five\ninnovative modules to systematically resolve different challenges in industrial\nmanagement: (1) systematic search-based exploration with virtual machine\nsnapshots for autonomous understanding of complex GUIs; (2) memory-driven\nplanning to ensure high-precision and efficient task execution; (3) advanced\nstate identification for robust localization in hierarchical interfaces; (4)\nstructured knowledge distillation for efficient deployment with lightweight\nmodels; and (5) comprehensive, multi-layered safety mechanisms to safeguard\nsensitive operations. Extensive experiments on both open-source and commercial\nDCIM platforms demonstrate that our approach consistently outperforms existing\nframeworks in terms of task success rate and operational efficiency, providing\na rigorous and scalable solution for industrial management automation.",
      "pdf_url": "http://arxiv.org/pdf/2509.13704v1",
      "published": "2025-09-17T05:14:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.13704v1",
      "categories": [
        "cs.AI",
        "cs.SE"
      ]
    }
  ]
}