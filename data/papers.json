{
  "last_updated": "2025-06-03T00:53:34.398291",
  "papers": [
    {
      "title": "Open CaptchaWorld: A Comprehensive Web-based Platform for Testing and Benchmarking Multimodal LLM Agents",
      "authors": [
        "Yaxin Luo",
        "Zhaoyi Li",
        "Jiacheng Liu",
        "Jiacheng Cui",
        "Xiaohan Zhao",
        "Zhiqiang Shen"
      ],
      "abstract": "CAPTCHAs have been a critical bottleneck for deploying web agents in\nreal-world applications, often blocking them from completing end-to-end\nautomation tasks. While modern multimodal LLM agents have demonstrated\nimpressive performance in static perception tasks, their ability to handle\ninteractive, multi-step reasoning challenges like CAPTCHAs is largely untested.\nTo address this gap, we introduce Open CaptchaWorld, the first web-based\nbenchmark and platform specifically designed to evaluate the visual reasoning\nand interaction capabilities of MLLM-powered agents through diverse and dynamic\nCAPTCHA puzzles. Our benchmark spans 20 modern CAPTCHA types, totaling 225\nCAPTCHAs, annotated with a new metric we propose: CAPTCHA Reasoning Depth,\nwhich quantifies the number of cognitive and motor steps required to solve each\npuzzle. Experimental results show that humans consistently achieve near-perfect\nscores, state-of-the-art MLLM agents struggle significantly, with success rates\nat most 40.0% by Browser-Use Openai-o3, far below human-level performance,\n93.3%. This highlights Open CaptchaWorld as a vital benchmark for diagnosing\nthe limits of current multimodal agents and guiding the development of more\nrobust multimodal reasoning systems. Code and Data are available at this https\nURL.",
      "pdf_url": "http://arxiv.org/pdf/2505.24878v1",
      "published": "2025-05-30T17:59:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.24878v1",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG"
      ]
    },
    {
      "title": "ProxyThinker: Test-Time Guidance through Small Visual Reasoners",
      "authors": [
        "Zilin Xiao",
        "Jaywon Koo",
        "Siru Ouyang",
        "Jefferson Hernandez",
        "Yu Meng",
        "Vicente Ordonez"
      ],
      "abstract": "Recent advancements in reinforcement learning with verifiable rewards have\npushed the boundaries of the visual reasoning capabilities in large\nvision-language models (LVLMs). However, training LVLMs with reinforcement\nfine-tuning (RFT) is computationally expensive, posing a significant challenge\nto scaling model size. In this work, we propose ProxyThinker, an inference-time\ntechnique that enables large models to inherit the visual reasoning\ncapabilities from small, slow-thinking visual reasoners without any training.\nBy subtracting the output distributions of base models from those of RFT\nreasoners, ProxyThinker modifies the decoding dynamics and successfully elicits\nthe slow-thinking reasoning demonstrated by the emerged sophisticated behaviors\nsuch as self-verification and self-correction. ProxyThinker consistently boosts\nperformance on challenging visual benchmarks on spatial, mathematical, and\nmulti-disciplinary reasoning, enabling untuned base models to compete with the\nperformance of their full-scale RFT counterparts. Furthermore, our\nimplementation efficiently coordinates multiple language models with\nparallelism techniques and achieves up to 38 $\\times$ faster inference compared\nto previous decoding-time methods, paving the way for the practical deployment\nof ProxyThinker. Code is available at\nhttps://github.com/MrZilinXiao/ProxyThinker.",
      "pdf_url": "http://arxiv.org/pdf/2505.24872v1",
      "published": "2025-05-30T17:59:43+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.24872v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Time Blindness: Why Video-Language Models Can't See What Humans Can?",
      "authors": [
        "Ujjwal Upadhyay",
        "Mukul Ranjan",
        "Zhiqiang Shen",
        "Mohamed Elhoseiny"
      ],
      "abstract": "Recent advances in vision-language models (VLMs) have made impressive strides\nin understanding spatio-temporal relationships in videos. However, when spatial\ninformation is obscured, these models struggle to capture purely temporal\npatterns. We introduce $\\textbf{SpookyBench}$, a benchmark where information is\nencoded solely in temporal sequences of noise-like frames, mirroring natural\nphenomena from biological signaling to covert communication. Interestingly,\nwhile humans can recognize shapes, text, and patterns in these sequences with\nover 98% accuracy, state-of-the-art VLMs achieve 0% accuracy. This performance\ngap highlights a critical limitation: an over-reliance on frame-level spatial\nfeatures and an inability to extract meaning from temporal cues. Furthermore,\nwhen trained in data sets with low spatial signal-to-noise ratios (SNR),\ntemporal understanding of models degrades more rapidly than human perception,\nespecially in tasks requiring fine-grained temporal reasoning. Overcoming this\nlimitation will require novel architectures or training paradigms that decouple\nspatial dependencies from temporal processing. Our systematic analysis shows\nthat this issue persists across model scales and architectures. We release\nSpookyBench to catalyze research in temporal pattern recognition and bridge the\ngap between human and machine video understanding. Dataset and code has been\nmade available on our project website: https://timeblindness.github.io/.",
      "pdf_url": "http://arxiv.org/pdf/2505.24867v1",
      "published": "2025-05-30T17:59:12+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.24867v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "ProRL: Prolonged Reinforcement Learning Expands Reasoning Boundaries in Large Language Models",
      "authors": [
        "Mingjie Liu",
        "Shizhe Diao",
        "Ximing Lu",
        "Jian Hu",
        "Xin Dong",
        "Yejin Choi",
        "Jan Kautz",
        "Yi Dong"
      ],
      "abstract": "Recent advances in reasoning-centric language models have highlighted\nreinforcement learning (RL) as a promising method for aligning models with\nverifiable rewards. However, it remains contentious whether RL truly expands a\nmodel's reasoning capabilities or merely amplifies high-reward outputs already\nlatent in the base model's distribution, and whether continually scaling up RL\ncompute reliably leads to improved reasoning performance. In this work, we\nchallenge prevailing assumptions by demonstrating that prolonged RL (ProRL)\ntraining can uncover novel reasoning strategies that are inaccessible to base\nmodels, even under extensive sampling. We introduce ProRL, a novel training\nmethodology that incorporates KL divergence control, reference policy\nresetting, and a diverse suite of tasks. Our empirical analysis reveals that\nRL-trained models consistently outperform base models across a wide range of\npass@k evaluations, including scenarios where base models fail entirely\nregardless of the number of attempts. We further show that reasoning boundary\nimprovements correlates strongly with task competence of base model and\ntraining duration, suggesting that RL can explore and populate new regions of\nsolution space over time. These findings offer new insights into the conditions\nunder which RL meaningfully expands reasoning boundaries in language models and\nestablish a foundation for future work on long-horizon RL for reasoning. We\nrelease model weights to support further research:\nhttps://huggingface.co/nvidia/Nemotron-Research-Reasoning-Qwen-1.5B",
      "pdf_url": "http://arxiv.org/pdf/2505.24864v1",
      "published": "2025-05-30T17:59:01+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.24864v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "DexMachina: Functional Retargeting for Bimanual Dexterous Manipulation",
      "authors": [
        "Zhao Mandi",
        "Yifan Hou",
        "Dieter Fox",
        "Yashraj Narang",
        "Ajay Mandlekar",
        "Shuran Song"
      ],
      "abstract": "We study the problem of functional retargeting: learning dexterous\nmanipulation policies to track object states from human hand-object\ndemonstrations. We focus on long-horizon, bimanual tasks with articulated\nobjects, which is challenging due to large action space, spatiotemporal\ndiscontinuities, and embodiment gap between human and robot hands. We propose\nDexMachina, a novel curriculum-based algorithm: the key idea is to use virtual\nobject controllers with decaying strength: an object is first driven\nautomatically towards its target states, such that the policy can gradually\nlearn to take over under motion and contact guidance. We release a simulation\nbenchmark with a diverse set of tasks and dexterous hands, and show that\nDexMachina significantly outperforms baseline methods. Our algorithm and\nbenchmark enable a functional comparison for hardware designs, and we present\nkey findings informed by quantitative and qualitative results. With the recent\nsurge in dexterous hand development, we hope this work will provide a useful\nplatform for identifying desirable hardware capabilities and lower the barrier\nfor contributing to future research. Videos and more at\nhttps://project-dexmachina.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2505.24853v1",
      "published": "2025-05-30T17:50:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.24853v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Harnessing Negative Signals: Reinforcement Distillation from Teacher Data for LLM Reasoning",
      "authors": [
        "Shuyao Xu",
        "Cheng Peng",
        "Jiangxuan Long",
        "Weidi Xu",
        "Wei Chu",
        "Yuan Qi"
      ],
      "abstract": "Recent advances in model distillation demonstrate that data from advanced\nreasoning models (e.g., DeepSeek-R1, OpenAI's o1) can effectively transfer\ncomplex reasoning abilities to smaller, efficient student models. However,\nstandard practices employ rejection sampling, discarding incorrect reasoning\nexamples -- valuable, yet often underutilized data. This paper addresses the\ncritical question: How can both positive and negative distilled reasoning\ntraces be effectively leveraged to maximize LLM reasoning performance in an\noffline setting? To this end, We propose Reinforcement Distillation (REDI), a\ntwo-stage framework. Stage 1 learns from positive traces via Supervised\nFine-Tuning (SFT). Stage 2 further refines the model using both positive and\nnegative traces through our proposed REDI objective. This novel objective is a\nsimple, reference-free loss function that outperforms established methods like\nDPO and SimPO in this distillation context. Our empirical evaluations\ndemonstrate REDI's superiority over baseline Rejection Sampling SFT or SFT\ncombined with DPO/SimPO on mathematical reasoning tasks. Notably, the\nQwen-REDI-1.5B model, post-trained on just 131k positive and negative examples\nfrom the open Open-R1 dataset, achieves an 83.1% score on MATH-500 (pass@1).\nIts performance matches or surpasses that of DeepSeek-R1-Distill-Qwen-1.5B (a\nmodel post-trained on 800k proprietary data) across various mathematical\nreasoning benchmarks, establishing a new state-of-the-art for 1.5B models\npost-trained offline with openly available data.",
      "pdf_url": "http://arxiv.org/pdf/2505.24850v1",
      "published": "2025-05-30T17:47:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.24850v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "I.2.6; I.2.7"
      ]
    },
    {
      "title": "MiCRo: Mixture Modeling and Context-aware Routing for Personalized Preference Learning",
      "authors": [
        "Jingyan Shen",
        "Jiarui Yao",
        "Rui Yang",
        "Yifan Sun",
        "Feng Luo",
        "Rui Pan",
        "Tong Zhang",
        "Han Zhao"
      ],
      "abstract": "Reward modeling is a key step in building safe foundation models when\napplying reinforcement learning from human feedback (RLHF) to align Large\nLanguage Models (LLMs). However, reward modeling based on the Bradley-Terry\n(BT) model assumes a global reward function, failing to capture the inherently\ndiverse and heterogeneous human preferences. Hence, such oversimplification\nlimits LLMs from supporting personalization and pluralistic alignment.\nTheoretically, we show that when human preferences follow a mixture\ndistribution of diverse subgroups, a single BT model has an irreducible error.\nWhile existing solutions, such as multi-objective learning with fine-grained\nannotations, help address this issue, they are costly and constrained by\npredefined attributes, failing to fully capture the richness of human values.\nIn this work, we introduce MiCRo, a two-stage framework that enhances\npersonalized preference learning by leveraging large-scale binary preference\ndatasets without requiring explicit fine-grained annotations. In the first\nstage, MiCRo introduces context-aware mixture modeling approach to capture\ndiverse human preferences. In the second stage, MiCRo integrates an online\nrouting strategy that dynamically adapts mixture weights based on specific\ncontext to resolve ambiguity, allowing for efficient and scalable preference\nadaptation with minimal additional supervision. Experiments on multiple\npreference datasets demonstrate that MiCRo effectively captures diverse human\npreferences and significantly improves downstream personalization.",
      "pdf_url": "http://arxiv.org/pdf/2505.24846v1",
      "published": "2025-05-30T17:44:28+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.24846v1",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Vision LLMs Are Bad at Hierarchical Visual Understanding, and LLMs Are the Bottleneck",
      "authors": [
        "Yuwen Tan",
        "Yuan Qing",
        "Boqing Gong"
      ],
      "abstract": "This paper reveals that many state-of-the-art large language models (LLMs)\nlack hierarchical knowledge about our visual world, unaware of even\nwell-established biology taxonomies. This shortcoming makes LLMs a bottleneck\nfor vision LLMs' hierarchical visual understanding (e.g., recognizing Anemone\nFish but not Vertebrate). We arrive at these findings using about one million\nfour-choice visual question answering (VQA) tasks constructed from six\ntaxonomies and four image datasets. Interestingly, finetuning a vision LLM\nusing our VQA tasks reaffirms LLMs' bottleneck effect to some extent because\nthe VQA tasks improve the LLM's hierarchical consistency more than the vision\nLLM's. We conjecture that one cannot make vision LLMs understand visual\nconcepts fully hierarchical until LLMs possess corresponding taxonomy\nknowledge.",
      "pdf_url": "http://arxiv.org/pdf/2505.24840v1",
      "published": "2025-05-30T17:40:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.24840v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    },
    {
      "title": "VideoCAD: A Large-Scale Video Dataset for Learning UI Interactions and 3D Reasoning from CAD Software",
      "authors": [
        "Brandon Man",
        "Ghadi Nehme",
        "Md Ferdous Alam",
        "Faez Ahmed"
      ],
      "abstract": "Computer-Aided Design (CAD) is a time-consuming and complex process,\nrequiring precise, long-horizon user interactions with intricate 3D interfaces.\nWhile recent advances in AI-driven user interface (UI) agents show promise,\nmost existing datasets and methods focus on short, low-complexity tasks in\nmobile or web applications, failing to capture the demands of professional\nengineering tools. In this work, we introduce VideoCAD, the first attempt at\nengineering UI interaction learning for precision tasks. Specifically, VideoCAD\nis a large-scale synthetic dataset consisting of over 41K annotated video\nrecordings of CAD operations, generated using an automated framework for\ncollecting high-fidelity UI action data from human-made CAD designs. Compared\nto existing datasets, VideoCAD offers an order of magnitude higher complexity\nin UI interaction learning for real-world engineering tasks, having up to a 20x\nlonger time horizon than other datasets. We show two important downstream\napplications of VideoCAD: learning UI interactions from professional precision\n3D CAD tools and a visual question-answering (VQA) benchmark designed to\nevaluate multimodal large language models' (LLM) spatial reasoning and video\nunderstanding abilities. To learn the UI interactions, we propose\nVideoCADFormer - a state-of-the-art model in learning CAD interactions directly\nfrom video, which outperforms multiple behavior cloning baselines. Both\nVideoCADFormer and the VQA benchmark derived from VideoCAD reveal key\nchallenges in the current state of video-based UI understanding, including the\nneed for precise action grounding, multi-modal and spatial reasoning, and\nlong-horizon dependencies.",
      "pdf_url": "http://arxiv.org/pdf/2505.24838v1",
      "published": "2025-05-30T17:39:52+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.24838v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Improving Reliability and Explainability of Medical Question Answering through Atomic Fact Checking in Retrieval-Augmented LLMs",
      "authors": [
        "Juraj Vladika",
        "Annika Domres",
        "Mai Nguyen",
        "Rebecca Moser",
        "Jana Nano",
        "Felix Busch",
        "Lisa C. Adams",
        "Keno K. Bressem",
        "Denise Bernhardt",
        "Stephanie E. Combs",
        "Kai J. Borm",
        "Florian Matthes",
        "Jan C. Peeken"
      ],
      "abstract": "Large language models (LLMs) exhibit extensive medical knowledge but are\nprone to hallucinations and inaccurate citations, which pose a challenge to\ntheir clinical adoption and regulatory compliance. Current methods, such as\nRetrieval Augmented Generation, partially address these issues by grounding\nanswers in source documents, but hallucinations and low fact-level\nexplainability persist. In this work, we introduce a novel atomic fact-checking\nframework designed to enhance the reliability and explainability of LLMs used\nin medical long-form question answering. This method decomposes LLM-generated\nresponses into discrete, verifiable units called atomic facts, each of which is\nindependently verified against an authoritative knowledge base of medical\nguidelines. This approach enables targeted correction of errors and direct\ntracing to source literature, thereby improving the factual accuracy and\nexplainability of medical Q&A. Extensive evaluation using multi-reader\nassessments by medical experts and an automated open Q&A benchmark demonstrated\nsignificant improvements in factual accuracy and explainability. Our framework\nachieved up to a 40% overall answer improvement and a 50% hallucination\ndetection rate. The ability to trace each atomic fact back to the most relevant\nchunks from the database provides a granular, transparent explanation of the\ngenerated responses, addressing a major gap in current medical AI applications.\nThis work represents a crucial step towards more trustworthy and reliable\nclinical applications of LLMs, addressing key prerequisites for clinical\napplication and fostering greater confidence in AI-assisted healthcare.",
      "pdf_url": "http://arxiv.org/pdf/2505.24830v1",
      "published": "2025-05-30T17:33:07+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.24830v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "PhySense: Principle-Based Physics Reasoning Benchmarking for Large Language Models",
      "authors": [
        "Yinggan Xu",
        "Yue Liu",
        "Zhiqiang Gao",
        "Changnan Peng",
        "Di Luo"
      ],
      "abstract": "Large language models (LLMs) have rapidly advanced and are increasingly\ncapable of tackling complex scientific problems, including those in physics.\nDespite this progress, current LLMs often fail to emulate the concise,\nprinciple-based reasoning characteristic of human experts, instead generating\nlengthy and opaque solutions. This discrepancy highlights a crucial gap in\ntheir ability to apply core physical principles for efficient and interpretable\nproblem solving. To systematically investigate this limitation, we introduce\nPhySense, a novel principle-based physics reasoning benchmark designed to be\neasily solvable by experts using guiding principles, yet deceptively difficult\nfor LLMs without principle-first reasoning. Our evaluation across multiple\nstate-of-the-art LLMs and prompt types reveals a consistent failure to align\nwith expert-like reasoning paths, providing insights for developing AI systems\nwith efficient, robust and interpretable principle-based scientific reasoning.",
      "pdf_url": "http://arxiv.org/pdf/2505.24823v1",
      "published": "2025-05-30T17:25:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.24823v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "RealDrive: Retrieval-Augmented Driving with Diffusion Models",
      "authors": [
        "Wenhao Ding",
        "Sushant Veer",
        "Yuxiao Chen",
        "Yulong Cao",
        "Chaowei Xiao",
        "Marco Pavone"
      ],
      "abstract": "Learning-based planners generate natural human-like driving behaviors by\nlearning to reason about nuanced interactions from data, overcoming the rigid\nbehaviors that arise from rule-based planners. Nonetheless, data-driven\napproaches often struggle with rare, safety-critical scenarios and offer\nlimited controllability over the generated trajectories. To address these\nchallenges, we propose RealDrive, a Retrieval-Augmented Generation (RAG)\nframework that initializes a diffusion-based planning policy by retrieving the\nmost relevant expert demonstrations from the training dataset. By interpolating\nbetween current observations and retrieved examples through a denoising\nprocess, our approach enables fine-grained control and safe behavior across\ndiverse scenarios, leveraging the strong prior provided by the retrieved\nscenario. Another key insight we produce is that a task-relevant retrieval\nmodel trained with planning-based objectives results in superior planning\nperformance in our framework compared to a task-agnostic retriever.\nExperimental results demonstrate improved generalization to long-tail events\nand enhanced trajectory diversity compared to standard learning-based planners\n-- we observe a 40% reduction in collision rate on the Waymo Open Motion\ndataset with RAG.",
      "pdf_url": "http://arxiv.org/pdf/2505.24808v1",
      "published": "2025-05-30T17:15:03+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.24808v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "Inference Acceleration of Autoregressive Normalizing Flows by Selective Jacobi Decoding",
      "authors": [
        "Jiaru Zhang",
        "Juanwu Lu",
        "Ziran Wang",
        "Ruqi Zhang"
      ],
      "abstract": "Normalizing flows are promising generative models with advantages such as\ntheoretical rigor, analytical log-likelihood computation, and end-to-end\ntraining. However, the architectural constraints to ensure invertibility and\ntractable Jacobian computation limit their expressive power and practical\nusability. Recent advancements utilize autoregressive modeling, significantly\nenhancing expressive power and generation quality. However, such sequential\nmodeling inherently restricts parallel computation during inference, leading to\nslow generation that impedes practical deployment. In this paper, we first\nidentify that strict sequential dependency in inference is unnecessary to\ngenerate high-quality samples. We observe that patches in sequential modeling\ncan also be approximated without strictly conditioning on all preceding\npatches. Moreover, the models tend to exhibit low dependency redundancy in the\ninitial layer and higher redundancy in subsequent layers. Leveraging these\nobservations, we propose a selective Jacobi decoding (SeJD) strategy that\naccelerates autoregressive inference through parallel iterative optimization.\nTheoretical analyses demonstrate the method's superlinear convergence rate and\nguarantee that the number of iterations required is no greater than the\noriginal sequential approach. Empirical evaluations across multiple datasets\nvalidate the generality and effectiveness of our acceleration technique.\nExperiments demonstrate substantial speed improvements up to 4.7 times faster\ninference while keeping the generation quality and fidelity.",
      "pdf_url": "http://arxiv.org/pdf/2505.24791v1",
      "published": "2025-05-30T16:53:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.24791v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Drop Dropout on Single-Epoch Language Model Pretraining",
      "authors": [
        "Houjun Liu",
        "John Bauer",
        "Christopher D. Manning"
      ],
      "abstract": "Originally, dropout was seen as a breakthrough regularization technique that\nreduced overfitting and improved performance in almost all applications of deep\nlearning by reducing overfitting. Yet, single-epoch pretraining tasks common to\nmodern LLMs yield minimal overfitting, leading to dropout not being used for\nlarge LLMs. Nevertheless, no thorough empirical investigation has been done on\nthe role of dropout in LM pretraining. Through experiments in single-epoch\npretraining of both masked (BERT) and autoregressive (Pythia 160M and 1.4B) LMs\nwith varying levels of dropout, we find that downstream performance in language\nmodeling, morpho-syntax (BLiMP), question answering (SQuAD), and\nnatural-language inference (MNLI) improves when dropout is not applied during\npretraining. We additionally find that the recently-introduced \"early dropout\"\nalso degrades performance over applying no dropout at all. We further\ninvestigate the models' editability, and find that models trained without\ndropout are more successful in gradient-based model editing (MEND) and\nequivalent in representation-based model editing (ReFT). Therefore, we advocate\nto drop dropout during single-epoch pretraining.",
      "pdf_url": "http://arxiv.org/pdf/2505.24788v1",
      "published": "2025-05-30T16:48:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.24788v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "DiG-Net: Enhancing Quality of Life through Hyper-Range Dynamic Gesture Recognition in Assistive Robotics",
      "authors": [
        "Eran Bamani Beeri",
        "Eden Nissinman",
        "Avishai Sintov"
      ],
      "abstract": "Dynamic hand gestures play a pivotal role in assistive human-robot\ninteraction (HRI), facilitating intuitive, non-verbal communication,\nparticularly for individuals with mobility constraints or those operating\nrobots remotely. Current gesture recognition methods are mostly limited to\nshort-range interactions, reducing their utility in scenarios demanding robust\nassistive communication from afar. In this paper, we introduce a novel approach\ndesigned specifically for assistive robotics, enabling dynamic gesture\nrecognition at extended distances of up to 30 meters, thereby significantly\nimproving accessibility and quality of life. Our proposed Distance-aware\nGesture Network (DiG-Net) effectively combines Depth-Conditioned Deformable\nAlignment (DADA) blocks with Spatio-Temporal Graph modules, enabling robust\nprocessing and classification of gesture sequences captured under challenging\nconditions, including significant physical attenuation, reduced resolution, and\ndynamic gesture variations commonly experienced in real-world assistive\nenvironments. We further introduce the Radiometric Spatio-Temporal Depth\nAttenuation Loss (RSTDAL), shown to enhance learning and strengthen model\nrobustness across varying distances. Our model demonstrates significant\nperformance improvement over state-of-the-art gesture recognition frameworks,\nachieving a recognition accuracy of 97.3% on a diverse dataset with challenging\nhyper-range gestures. By effectively interpreting gestures from considerable\ndistances, DiG-Net significantly enhances the usability of assistive robots in\nhome healthcare, industrial safety, and remote assistance scenarios, enabling\nseamless and intuitive interactions for users regardless of physical\nlimitations",
      "pdf_url": "http://arxiv.org/pdf/2505.24786v1",
      "published": "2025-05-30T16:47:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.24786v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "EXP-Bench: Can AI Conduct AI Research Experiments?",
      "authors": [
        "Patrick Tser Jern Kon",
        "Jiachen Liu",
        "Xinyi Zhu",
        "Qiuyi Ding",
        "Jingjia Peng",
        "Jiarong Xing",
        "Yibo Huang",
        "Yiming Qiu",
        "Jayanth Srinivasa",
        "Myungjin Lee",
        "Mosharaf Chowdhury",
        "Matei Zaharia",
        "Ang Chen"
      ],
      "abstract": "Automating AI research holds immense potential for accelerating scientific\nprogress, yet current AI agents struggle with the complexities of rigorous,\nend-to-end experimentation. We introduce EXP-Bench, a novel benchmark designed\nto systematically evaluate AI agents on complete research experiments sourced\nfrom influential AI publications. Given a research question and incomplete\nstarter code, EXP-Bench challenges AI agents to formulate hypotheses, design\nand implement experimental procedures, execute them, and analyze results. To\nenable the creation of such intricate and authentic tasks with high-fidelity,\nwe design a semi-autonomous pipeline to extract and structure crucial\nexperimental details from these research papers and their associated\nopen-source code. With the pipeline, EXP-Bench curated 461 AI research tasks\nfrom 51 top-tier AI research papers. Evaluations of leading LLM-based agents,\nsuch as OpenHands and IterativeAgent on EXP-Bench demonstrate partial\ncapabilities: while scores on individual experimental aspects such as design or\nimplementation correctness occasionally reach 20-35%, the success rate for\ncomplete, executable experiments was a mere 0.5%. By identifying these\nbottlenecks and providing realistic step-by-step experiment procedures,\nEXP-Bench serves as a vital tool for future AI agents to improve their ability\nto conduct AI research experiments. EXP-Bench is open-sourced at\nhttps://github.com/Just-Curieous/Curie/tree/main/benchmark/exp_bench.",
      "pdf_url": "http://arxiv.org/pdf/2505.24785v1",
      "published": "2025-05-30T16:46:29+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.24785v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "AXIOM: Learning to Play Games in Minutes with Expanding Object-Centric Models",
      "authors": [
        "Conor Heins",
        "Toon Van de Maele",
        "Alexander Tschantz",
        "Hampus Linander",
        "Dimitrije Markovic",
        "Tommaso Salvatori",
        "Corrado Pezzato",
        "Ozan Catal",
        "Ran Wei",
        "Magnus Koudahl",
        "Marco Perin",
        "Karl Friston",
        "Tim Verbelen",
        "Christopher Buckley"
      ],
      "abstract": "Current deep reinforcement learning (DRL) approaches achieve state-of-the-art\nperformance in various domains, but struggle with data efficiency compared to\nhuman learning, which leverages core priors about objects and their\ninteractions. Active inference offers a principled framework for integrating\nsensory information with prior knowledge to learn a world model and quantify\nthe uncertainty of its own beliefs and predictions. However, active inference\nmodels are usually crafted for a single task with bespoke knowledge, so they\nlack the domain flexibility typical of DRL approaches. To bridge this gap, we\npropose a novel architecture that integrates a minimal yet expressive set of\ncore priors about object-centric dynamics and interactions to accelerate\nlearning in low-data regimes. The resulting approach, which we call AXIOM,\ncombines the usual data efficiency and interpretability of Bayesian approaches\nwith the across-task generalization usually associated with DRL. AXIOM\nrepresents scenes as compositions of objects, whose dynamics are modeled as\npiecewise linear trajectories that capture sparse object-object interactions.\nThe structure of the generative model is expanded online by growing and\nlearning mixture models from single events and periodically refined through\nBayesian model reduction to induce generalization. AXIOM masters various games\nwithin only 10,000 interaction steps, with both a small number of parameters\ncompared to DRL, and without the computational expense of gradient-based\noptimization.",
      "pdf_url": "http://arxiv.org/pdf/2505.24784v1",
      "published": "2025-05-30T16:46:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.24784v1",
      "categories": [
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ]
    },
    {
      "title": "A survey of using EHR as real-world evidence for discovering and validating new drug indications",
      "authors": [
        "Nabasmita Talukdar",
        "Xiaodan Zhang",
        "Shreya Paithankar",
        "Hui Wang",
        "Bin Chen"
      ],
      "abstract": "Electronic Health Records (EHRs) have been increasingly used as real-world\nevidence (RWE) to support the discovery and validation of new drug indications.\nThis paper surveys current approaches to EHR-based drug repurposing, covering\ndata sources, processing methodologies, and representation techniques. It\ndiscusses study designs and statistical frameworks for evaluating drug\nefficacy. Key challenges in validation are discussed, with emphasis on the role\nof large language models (LLMs) and target trial emulation. By synthesizing\nrecent developments and methodological advances, this work provides a\nfoundational resource for researchers aiming to translate real-world data into\nactionable drug-repurposing evidence.",
      "pdf_url": "http://arxiv.org/pdf/2505.24767v1",
      "published": "2025-05-30T16:30:54+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.24767v1",
      "categories": [
        "stat.AP",
        "cs.AI"
      ]
    },
    {
      "title": "Supervised Quantum Machine Learning: A Future Outlook from Qubits to Enterprise Applications",
      "authors": [
        "Srikanth Thudumu",
        "Jason Fisher",
        "Hung Du"
      ],
      "abstract": "Supervised Quantum Machine Learning (QML) represents an intersection of\nquantum computing and classical machine learning, aiming to use quantum\nresources to support model training and inference. This paper reviews recent\ndevelopments in supervised QML, focusing on methods such as variational quantum\ncircuits, quantum neural networks, and quantum kernel methods, along with\nhybrid quantum-classical workflows. We examine recent experimental studies that\nshow partial indications of quantum advantage and describe current limitations\nincluding noise, barren plateaus, scalability issues, and the lack of formal\nproofs of performance improvement over classical methods. The main contribution\nis a ten-year outlook (2025-2035) that outlines possible developments in\nsupervised QML, including a roadmap describing conditions under which QML may\nbe used in applied research and enterprise systems over the next decade.",
      "pdf_url": "http://arxiv.org/pdf/2505.24765v1",
      "published": "2025-05-30T16:29:12+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.24765v1",
      "categories": [
        "quant-ph",
        "cs.AI"
      ]
    },
    {
      "title": "REASONING GYM: Reasoning Environments for Reinforcement Learning with Verifiable Rewards",
      "authors": [
        "Zafir Stojanovski",
        "Oliver Stanley",
        "Joe Sharratt",
        "Richard Jones",
        "Abdulhakeem Adefioye",
        "Jean Kaddour",
        "Andreas Köpf"
      ],
      "abstract": "We introduce Reasoning Gym (RG), a library of reasoning environments for\nreinforcement learning with verifiable rewards. It provides over 100 data\ngenerators and verifiers spanning multiple domains including algebra,\narithmetic, computation, cognition, geometry, graph theory, logic, and various\ncommon games. Its key innovation is the ability to generate virtually infinite\ntraining data with adjustable complexity, unlike most previous reasoning\ndatasets, which are typically fixed. This procedural generation approach allows\nfor continuous evaluation across varying difficulty levels. Our experimental\nresults demonstrate the efficacy of RG in both evaluating and reinforcement\nlearning of reasoning models.",
      "pdf_url": "http://arxiv.org/pdf/2505.24760v1",
      "published": "2025-05-30T16:20:18+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.24760v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Unsupervised Evolutionary Cell Type Matching via Entropy-Minimized Optimal Transport",
      "authors": [
        "Mu Qiao"
      ],
      "abstract": "Identifying evolutionary correspondences between cell types across species is\na fundamental challenge in comparative genomics and evolutionary biology.\nExisting approaches often rely on either reference-based matching, which\nimposes asymmetry by designating one species as the reference, or\nprojection-based matching, which may increase computational complexity and\nobscure biological interpretability at the cell-type level. Here, we present\nOT-MESH, an unsupervised computational framework leveraging entropy-regularized\noptimal transport (OT) to systematically determine cross-species cell type\nhomologies. Our method uniquely integrates the Minimize Entropy of Sinkhorn\n(MESH) technique to refine the OT plan. It begins by selecting genes with high\nSignal-to-Noise Ratio (SNR) to capture the most informative features, from\nwhich a cost matrix is constructed using cosine distances between cell-type\ncentroids. Importantly, the MESH procedure iteratively refines the cost matrix,\nleading to a transport plan with significantly enhanced sparsity and\ninterpretability of the resulting correspondence matrices. Applied to retinal\nbipolar cells (BCs) and retinal ganglion cells (RGCs) from mouse and macaque,\nOT-MESH accurately recovers known evolutionary relationships and uncovers novel\ncorrespondences, one of which was independently validated experimentally. Thus,\nour framework offers a principled, scalable, symmetric, and interpretable\nsolution for evolutionary cell type mapping, facilitating deeper insights into\ncellular specialization and conservation across species.",
      "pdf_url": "http://arxiv.org/pdf/2505.24759v1",
      "published": "2025-05-30T16:20:00+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.24759v1",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Don't Reinvent the Wheel: Efficient Instruction-Following Text Embedding based on Guided Space Transformation",
      "authors": [
        "Yingchaojie Feng",
        "Yiqun Sun",
        "Yandong Sun",
        "Minfeng Zhu",
        "Qiang Huang",
        "Anthony K. H. Tung",
        "Wei Chen"
      ],
      "abstract": "In this work, we investigate an important task named instruction-following\ntext embedding, which generates dynamic text embeddings that adapt to user\ninstructions, highlighting specific attributes of text. Despite recent\nadvancements, existing approaches suffer from significant computational\noverhead, as they require re-encoding the entire corpus for each new\ninstruction. To address this challenge, we propose GSTransform, a novel\ninstruction-following text embedding framework based on Guided Space\nTransformation. Our key observation is that instruction-relevant information is\ninherently encoded in generic embeddings but remains underutilized. Instead of\nrepeatedly encoding the corpus for each instruction, GSTransform is a\nlightweight transformation mechanism that adapts pre-computed embeddings in\nreal time to align with user instructions, guided by a small amount of text\ndata with instruction-focused label annotation. We conduct extensive\nexperiments on three instruction-awareness downstream tasks across nine\nreal-world datasets, demonstrating that GSTransform improves\ninstruction-following text embedding quality over state-of-the-art methods\nwhile achieving dramatic speedups of 6~300x in real-time processing on\nlarge-scale datasets. The source code is available at\nhttps://github.com/YingchaojieFeng/GSTransform.",
      "pdf_url": "http://arxiv.org/pdf/2505.24754v1",
      "published": "2025-05-30T16:16:22+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.24754v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ]
    },
    {
      "title": "HELM: Hyperbolic Large Language Models via Mixture-of-Curvature Experts",
      "authors": [
        "Neil He",
        "Rishabh Anand",
        "Hiren Madhu",
        "Ali Maatouk",
        "Smita Krishnaswamy",
        "Leandros Tassiulas",
        "Menglin Yang",
        "Rex Ying"
      ],
      "abstract": "Large language models (LLMs) have shown great success in text modeling tasks\nacross domains. However, natural language exhibits inherent semantic\nhierarchies and nuanced geometric structure, which current LLMs do not capture\ncompletely owing to their reliance on Euclidean operations. Recent studies have\nalso shown that not respecting the geometry of token embeddings leads to\ntraining instabilities and degradation of generative capabilities. These\nfindings suggest that shifting to non-Euclidean geometries can better align\nlanguage models with the underlying geometry of text. We thus propose to\noperate fully in Hyperbolic space, known for its expansive, scale-free, and\nlow-distortion properties. We thus introduce HELM, a family of HypErbolic Large\nLanguage Models, offering a geometric rethinking of the Transformer-based LLM\nthat addresses the representational inflexibility, missing set of necessary\noperations, and poor scalability of existing hyperbolic LMs. We additionally\nintroduce a Mixture-of-Curvature Experts model, HELM-MICE, where each expert\noperates in a distinct curvature space to encode more fine-grained geometric\nstructure from text, as well as a dense model, HELM-D. For HELM-MICE, we\nfurther develop hyperbolic Multi-Head Latent Attention (HMLA) for efficient,\nreduced-KV-cache training and inference. For both models, we develop essential\nhyperbolic equivalents of rotary positional encodings and RMS normalization. We\nare the first to train fully hyperbolic LLMs at billion-parameter scale, and\nevaluate them on well-known benchmarks such as MMLU and ARC, spanning STEM\nproblem-solving, general knowledge, and commonsense reasoning. Our results show\nconsistent gains from our HELM architectures -- up to 4% -- over popular\nEuclidean architectures used in LLaMA and DeepSeek, highlighting the efficacy\nand enhanced reasoning afforded by hyperbolic geometry in large-scale LM\npretraining.",
      "pdf_url": "http://arxiv.org/pdf/2505.24722v1",
      "published": "2025-05-30T15:42:42+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.24722v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Towards Scalable Schema Mapping using Large Language Models",
      "authors": [
        "Christopher Buss",
        "Mahdis Safari",
        "Arash Termehchy",
        "Stefan Lee",
        "David Maier"
      ],
      "abstract": "The growing need to integrate information from a large number of diverse\nsources poses significant scalability challenges for data integration systems.\nThese systems often rely on manually written schema mappings, which are\ncomplex, source-specific, and costly to maintain as sources evolve. While\nrecent advances suggest that large language models (LLMs) can assist in\nautomating schema matching by leveraging both structural and natural language\ncues, key challenges remain. In this paper, we identify three core issues with\nusing LLMs for schema mapping: (1) inconsistent outputs due to sensitivity to\ninput phrasing and structure, which we propose methods to address through\nsampling and aggregation techniques; (2) the need for more expressive mappings\n(e.g., GLaV), which strain the limited context windows of LLMs; and (3) the\ncomputational cost of repeated LLM calls, which we propose to mitigate through\nstrategies like data type prefiltering.",
      "pdf_url": "http://arxiv.org/pdf/2505.24716v1",
      "published": "2025-05-30T15:36:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.24716v1",
      "categories": [
        "cs.DB",
        "cs.AI"
      ]
    },
    {
      "title": "CoRet: Improved Retriever for Code Editing",
      "authors": [
        "Fabio Fehr",
        "Prabhu Teja Sivaprasad",
        "Luca Franceschi",
        "Giovanni Zappella"
      ],
      "abstract": "In this paper, we introduce CoRet, a dense retrieval model designed for\ncode-editing tasks that integrates code semantics, repository structure, and\ncall graph dependencies. The model focuses on retrieving relevant portions of a\ncode repository based on natural language queries such as requests to implement\nnew features or fix bugs. These retrieved code chunks can then be presented to\na user or to a second code-editing model or agent. To train CoRet, we propose a\nloss function explicitly designed for repository-level retrieval. On SWE-bench\nand Long Code Arena's bug localisation datasets, we show that our model\nsubstantially improves retrieval recall by at least 15 percentage points over\nexisting models, and ablate the design choices to show their importance in\nachieving these results.",
      "pdf_url": "http://arxiv.org/pdf/2505.24715v1",
      "published": "2025-05-30T15:36:37+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.24715v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Causal-aware Large Language Models: Enhancing Decision-Making Through Learning, Adapting and Acting",
      "authors": [
        "Wei Chen",
        "Jiahao Zhang",
        "Haipeng Zhu",
        "Boyan Xu",
        "Zhifeng Hao",
        "Keli Zhang",
        "Junjian Ye",
        "Ruichu Cai"
      ],
      "abstract": "Large language models (LLMs) have shown great potential in decision-making\ndue to the vast amount of knowledge stored within the models. However, these\npre-trained models are prone to lack reasoning abilities and are difficult to\nadapt to new environments, further hindering their application to complex\nreal-world tasks. To address these challenges, inspired by the human cognitive\nprocess, we propose Causal-aware LLMs, which integrate the structural causal\nmodel (SCM) into the decision-making process to model, update, and utilize\nstructured knowledge of the environment in a ``learning-adapting-acting\"\nparadigm. Specifically, in the learning stage, we first utilize an LLM to\nextract the environment-specific causal entities and their causal relations to\ninitialize a structured causal model of the environment. Subsequently,in the\nadapting stage, we update the structured causal model through external feedback\nabout the environment, via an idea of causal intervention. Finally, in the\nacting stage, Causal-aware LLMs exploit structured causal knowledge for more\nefficient policy-making through the reinforcement learning agent. The above\nprocesses are performed iteratively to learn causal knowledge, ultimately\nenabling the causal-aware LLMs to achieve a more accurate understanding of the\nenvironment and make more efficient decisions. Experimental results across 22\ndiverse tasks within the open-world game ``Crafter\" validate the effectiveness\nof our proposed method.",
      "pdf_url": "http://arxiv.org/pdf/2505.24710v1",
      "published": "2025-05-30T15:30:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.24710v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "On Symmetric Losses for Robust Policy Optimization with Noisy Preferences",
      "authors": [
        "Soichiro Nishimori",
        "Yu-Jie Zhang",
        "Thanawat Lodkaew",
        "Masashi Sugiyama"
      ],
      "abstract": "Optimizing policies based on human preferences is key to aligning language\nmodels with human intent. This work focuses on reward modeling, a core\ncomponent in reinforcement learning from human feedback (RLHF), and offline\npreference optimization, such as direct preference optimization. Conventional\napproaches typically assume accurate annotations. However, real-world\npreference data often contains noise due to human errors or biases. We propose\na principled framework for robust policy optimization under noisy preferences,\nviewing reward modeling as a classification problem. This allows us to leverage\nsymmetric losses, known for their robustness to label noise in classification,\nleading to our Symmetric Preference Optimization (SymPO) method. We prove that\nsymmetric losses enable successful policy optimization even under noisy labels,\nas the resulting reward remains rank-preserving -- a property sufficient for\npolicy improvement. Experiments on synthetic and real-world tasks demonstrate\nthe effectiveness of SymPO.",
      "pdf_url": "http://arxiv.org/pdf/2505.24709v1",
      "published": "2025-05-30T15:30:43+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.24709v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Multi-Domain ABSA Conversation Dataset Generation via LLMs for Real-World Evaluation and Model Comparison",
      "authors": [
        "Tejul Pandit",
        "Meet Raval",
        "Dhvani Upadhyay"
      ],
      "abstract": "Aspect-Based Sentiment Analysis (ABSA) offers granular insights into opinions\nbut often suffers from the scarcity of diverse, labeled datasets that reflect\nreal-world conversational nuances. This paper presents an approach for\ngenerating synthetic ABSA data using Large Language Models (LLMs) to address\nthis gap. We detail the generation process aimed at producing data with\nconsistent topic and sentiment distributions across multiple domains using\nGPT-4o. The quality and utility of the generated data were evaluated by\nassessing the performance of three state-of-the-art LLMs (Gemini 1.5 Pro,\nClaude 3.5 Sonnet, and DeepSeek-R1) on topic and sentiment classification\ntasks. Our results demonstrate the effectiveness of the synthetic data,\nrevealing distinct performance trade-offs among the models: DeepSeekR1 showed\nhigher precision, Gemini 1.5 Pro and Claude 3.5 Sonnet exhibited strong recall,\nand Gemini 1.5 Pro offered significantly faster inference. We conclude that\nLLM-based synthetic data generation is a viable and flexible method for\ncreating valuable ABSA resources, facilitating research and model evaluation\nwithout reliance on limited or inaccessible real-world labeled data.",
      "pdf_url": "http://arxiv.org/pdf/2505.24701v1",
      "published": "2025-05-30T15:24:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.24701v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Disentangling Granularity: An Implicit Inductive Bias in Factorized VAEs",
      "authors": [
        "Zihao Chen",
        "Yu Xiang",
        "Wenyong Wang"
      ],
      "abstract": "Despite the success in learning semantically meaningful, unsupervised\ndisentangled representations, variational autoencoders (VAEs) and their\nvariants face a fundamental theoretical challenge: substantial evidence\nindicates that unsupervised disentanglement is unattainable without implicit\ninductive bias, yet such bias remains elusive. In this work, we focus on\nexploring the implicit inductive bias that drive disentanglement in VAEs with\nfactorization priors. By analyzing the total correlation in \\b{eta}-TCVAE, we\nuncover a crucial implicit inductive bias called disentangling granularity,\nwhich leads to the discovery of an interesting \"V\"-shaped optimal Evidence\nLower Bound (ELBO) trajectory within the parameter space. This finding is\nvalidated through over 100K experiments using factorized VAEs and our newly\nproposed model, \\b{eta}-STCVAE. Notably, experimental results reveal that\nconventional factorized VAEs, constrained by fixed disentangling granularity,\ninherently tend to disentangle low-complexity feature. Whereas, appropriately\ntuning disentangling granularity, as enabled by \\b{eta}-STCVAE, broadens the\nrange of disentangled representations, allowing for the disentanglement of\nhigh-complexity features. Our findings unveil that disentangling granularity as\nan implicit inductive bias in factorized VAEs influence both disentanglement\nperformance and the inference of the ELBO, offering fresh insights into the\ninterpretability and inherent biases of VAEs.",
      "pdf_url": "http://arxiv.org/pdf/2505.24684v1",
      "published": "2025-05-30T15:08:50+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.24684v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Should I Share this Translation? Evaluating Quality Feedback for User Reliance on Machine Translation",
      "authors": [
        "Dayeon Ki",
        "Kevin Duh",
        "Marine Carpuat"
      ],
      "abstract": "As people increasingly use AI systems in work and daily life, feedback\nmechanisms that help them use AI responsibly are urgently needed, particularly\nin settings where users are not equipped to assess the quality of AI\npredictions. We study a realistic Machine Translation (MT) scenario where\nmonolingual users decide whether to share an MT output, first without and then\nwith quality feedback. We compare four types of quality feedback: explicit\nfeedback that directly give users an assessment of translation quality using 1)\nerror highlights and 2) LLM explanations, and implicit feedback that helps\nusers compare MT inputs and outputs through 3) backtranslation and 4)\nquestion-answer (QA) tables. We find that all feedback types, except error\nhighlights, significantly improve both decision accuracy and appropriate\nreliance. Notably, implicit feedback, especially QA tables, yields\nsignificantly greater gains than explicit feedback in terms of decision\naccuracy, appropriate reliance, and user perceptions, receiving the highest\nratings for helpfulness and trust, and the lowest for mental burden.",
      "pdf_url": "http://arxiv.org/pdf/2505.24683v1",
      "published": "2025-05-30T15:08:10+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.24683v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Generative Knowledge Production Pipeline Driven by Academic Influencers",
      "authors": [
        "Katalin Feher",
        "Marton Demeter"
      ],
      "abstract": "Generative AI transforms knowledge production, validation, and dissemination,\nraising academic integrity and credibility concerns. This study examines 53\nacademic influencer videos that reached 5.3 million viewers to identify an\nemerging, structured, implementation-ready pipeline balancing originality,\nethical compliance, and human-AI collaboration despite the disruptive impacts.\nFindings highlight generative AI's potential to automate publication workflows\nand democratize participation in knowledge production while challenging\ntraditional scientific norms. Academic influencers emerge as key intermediaries\nin this paradigm shift, connecting bottom-up practices with institutional\npolicies to improve adaptability. Accordingly, the study proposes a generative\npublication production pipeline and a policy framework for co-intelligence\nadaptation and reinforcing credibility-centered standards in AI-powered\nresearch. These insights support scholars, educators, and policymakers in\nunderstanding AI's transformative impact by advocating responsible and\ninnovation-driven knowledge production. Additionally, they reveal pathways for\nautomating best practices, optimizing scholarly workflows, and fostering\ncreativity in academic research and publication.",
      "pdf_url": "http://arxiv.org/pdf/2505.24681v1",
      "published": "2025-05-30T15:07:01+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.24681v1",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC",
        "cs.SI",
        "1.2, J.4, K.4"
      ]
    },
    {
      "title": "Multiple LLM Agents Debate for Equitable Cultural Alignment",
      "authors": [
        "Dayeon Ki",
        "Rachel Rudinger",
        "Tianyi Zhou",
        "Marine Carpuat"
      ],
      "abstract": "Large Language Models (LLMs) need to adapt their predictions to diverse\ncultural contexts to benefit diverse communities across the world. While\nprevious efforts have focused on single-LLM, single-turn approaches, we propose\nto exploit the complementary strengths of multiple LLMs to promote cultural\nadaptability. We introduce a Multi-Agent Debate framework, where two LLM-based\nagents debate over a cultural scenario and collaboratively reach a final\ndecision. We propose two variants: one where either LLM agents exclusively\ndebate and another where they dynamically choose between self-reflection and\ndebate during their turns. We evaluate these approaches on 7 open-weight LLMs\n(and 21 LLM combinations) using the NormAd-ETI benchmark for social etiquette\nnorms in 75 countries. Experiments show that debate improves both overall\naccuracy and cultural group parity over single-LLM baselines. Notably,\nmulti-agent debate enables relatively small LLMs (7-9B) to achieve accuracies\ncomparable to that of a much larger model (27B parameters).",
      "pdf_url": "http://arxiv.org/pdf/2505.24671v1",
      "published": "2025-05-30T15:01:52+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.24671v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Adaptable Cardiovascular Disease Risk Prediction from Heterogeneous Data using Large Language Models",
      "authors": [
        "Frederike Lübeck",
        "Jonas Wildberger",
        "Frederik Träuble",
        "Maximilian Mordig",
        "Sergios Gatidis",
        "Andreas Krause",
        "Bernhard Schölkopf"
      ],
      "abstract": "Cardiovascular disease (CVD) risk prediction models are essential for\nidentifying high-risk individuals and guiding preventive actions. However,\nexisting models struggle with the challenges of real-world clinical practice as\nthey oversimplify patient profiles, rely on rigid input schemas, and are\nsensitive to distribution shifts. We developed AdaCVD, an adaptable CVD risk\nprediction framework built on large language models extensively fine-tuned on\nover half a million participants from the UK Biobank. In benchmark comparisons,\nAdaCVD surpasses established risk scores and standard machine learning\napproaches, achieving state-of-the-art performance. Crucially, for the first\ntime, it addresses key clinical challenges across three dimensions: it flexibly\nincorporates comprehensive yet variable patient information; it seamlessly\nintegrates both structured data and unstructured text; and it rapidly adapts to\nnew patient populations using minimal additional data. In stratified analyses,\nit demonstrates robust performance across demographic, socioeconomic, and\nclinical subgroups, including underrepresented cohorts. AdaCVD offers a\npromising path toward more flexible, AI-driven clinical decision support tools\nsuited to the realities of heterogeneous and dynamic healthcare environments.",
      "pdf_url": "http://arxiv.org/pdf/2505.24655v1",
      "published": "2025-05-30T14:42:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.24655v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "BIMA: Bijective Maximum Likelihood Learning Approach to Hallucination Prediction and Mitigation in Large Vision-Language Models",
      "authors": [
        "Huu-Thien Tran",
        "Thanh-Dat Truong",
        "Khoa Luu"
      ],
      "abstract": "Large vision-language models have become widely adopted to advance in various\ndomains. However, developing a trustworthy system with minimal interpretable\ncharacteristics of large-scale models presents a significant challenge. One of\nthe most prevalent terms associated with the fallacy functions caused by these\nsystems is hallucination, where the language model generates a response that\ndoes not correspond to the visual content. To mitigate this problem, several\napproaches have been developed, and one prominent direction is to ameliorate\nthe decoding process. In this paper, we propose a new Bijective Maximum\nLikelihood Learning (BIMA) approach to hallucination mitigation using\nnormalizing flow theories. The proposed BIMA method can efficiently mitigate\nthe hallucination problem in prevailing vision-language models, resulting in\nsignificant improvements. Notably, BIMA achieves the average F1 score of 85.06%\non POPE benchmark and remarkably reduce CHAIRS and CHAIRI by 7.6% and 2.6%,\nrespectively. To the best of our knowledge, this is one of the first studies\nthat contemplates the bijection means to reduce hallucination induced by large\nvision-language models.",
      "pdf_url": "http://arxiv.org/pdf/2505.24649v1",
      "published": "2025-05-30T14:38:07+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.24649v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Efficient Text Encoders for Labor Market Analysis",
      "authors": [
        "Jens-Joris Decorte",
        "Jeroen Van Hautte",
        "Chris Develder",
        "Thomas Demeester"
      ],
      "abstract": "Labor market analysis relies on extracting insights from job advertisements,\nwhich provide valuable yet unstructured information on job titles and\ncorresponding skill requirements. While state-of-the-art methods for skill\nextraction achieve strong performance, they depend on large language models\n(LLMs), which are computationally expensive and slow. In this paper, we propose\n\\textbf{ConTeXT-match}, a novel contrastive learning approach with token-level\nattention that is well-suited for the extreme multi-label classification task\nof skill classification. \\textbf{ConTeXT-match} significantly improves skill\nextraction efficiency and performance, achieving state-of-the-art results with\na lightweight bi-encoder model. To support robust evaluation, we introduce\n\\textbf{Skill-XL}, a new benchmark with exhaustive, sentence-level skill\nannotations that explicitly address the redundancy in the large label space.\nFinally, we present \\textbf{JobBERT V2}, an improved job title normalization\nmodel that leverages extracted skills to produce high-quality job title\nrepresentations. Experiments demonstrate that our models are efficient,\naccurate, and scalable, making them ideal for large-scale, real-time labor\nmarket analysis.",
      "pdf_url": "http://arxiv.org/pdf/2505.24640v1",
      "published": "2025-05-30T14:27:25+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.24640v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Cloud Optical Thickness Retrievals Using Angle Invariant Attention Based Deep Learning Models",
      "authors": [
        "Zahid Hassan Tushar",
        "Adeleke Ademakinwa",
        "Jianwu Wang",
        "Zhibo Zhang",
        "Sanjay Purushotham"
      ],
      "abstract": "Cloud Optical Thickness (COT) is a critical cloud property influencing\nEarth's climate, weather, and radiation budget. Satellite radiance measurements\nenable global COT retrieval, but challenges like 3D cloud effects, viewing\nangles, and atmospheric interference must be addressed to ensure accurate\nestimation. Traditionally, the Independent Pixel Approximation (IPA) method,\nwhich treats individual pixels independently, has been used for COT estimation.\nHowever, IPA introduces significant bias due to its simplified assumptions.\nRecently, deep learning-based models have shown improved performance over IPA\nbut lack robustness, as they are sensitive to variations in radiance intensity,\ndistortions, and cloud shadows. These models also introduce substantial errors\nin COT estimation under different solar and viewing zenith angles. To address\nthese challenges, we propose a novel angle-invariant, attention-based deep\nmodel called Cloud-Attention-Net with Angle Coding (CAAC). Our model leverages\nattention mechanisms and angle embeddings to account for satellite viewing\ngeometry and 3D radiative transfer effects, enabling more accurate retrieval of\nCOT. Additionally, our multi-angle training strategy ensures angle invariance.\nThrough comprehensive experiments, we demonstrate that CAAC significantly\noutperforms existing state-of-the-art deep learning models, reducing cloud\nproperty retrieval errors by at least a factor of nine.",
      "pdf_url": "http://arxiv.org/pdf/2505.24638v1",
      "published": "2025-05-30T14:26:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.24638v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "The Hallucination Dilemma: Factuality-Aware Reinforcement Learning for Large Reasoning Models",
      "authors": [
        "Junyi Li",
        "Hwee Tou Ng"
      ],
      "abstract": "Large language models (LLMs) have significantly advanced in reasoning tasks\nthrough reinforcement learning (RL) optimization, achieving impressive\ncapabilities across various challenging benchmarks. However, our empirical\nanalysis reveals a critical drawback: reasoning-oriented RL fine-tuning\nsignificantly increases the prevalence of hallucinations. We theoretically\nanalyze the RL training dynamics, identifying high-variance gradient,\nentropy-induced randomness, and susceptibility to spurious local optima as key\nfactors leading to hallucinations. To address this drawback, we propose\nFactuality-aware Step-wise Policy Optimization (FSPO), an innovative RL\nfine-tuning algorithm incorporating explicit factuality verification at each\nreasoning step. FSPO leverages automated verification against given evidence to\ndynamically adjust token-level advantage values, incentivizing factual\ncorrectness throughout the reasoning process. Experiments across mathematical\nreasoning and hallucination benchmarks using Qwen2.5 and Llama models\ndemonstrate that FSPO effectively reduces hallucinations while enhancing\nreasoning accuracy, substantially improving both reliability and performance.",
      "pdf_url": "http://arxiv.org/pdf/2505.24630v1",
      "published": "2025-05-30T14:23:32+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.24630v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Learning from Videos for 3D World: Enhancing MLLMs with 3D Vision Geometry Priors",
      "authors": [
        "Duo Zheng",
        "Shijia Huang",
        "Yanyang Li",
        "Liwei Wang"
      ],
      "abstract": "Previous research has investigated the application of Multimodal Large\nLanguage Models (MLLMs) in understanding 3D scenes by interpreting them as\nvideos. These approaches generally depend on comprehensive 3D data inputs, such\nas point clouds or reconstructed Bird's-Eye View (BEV) maps. In our research,\nwe advance this field by enhancing the capability of MLLMs to understand and\nreason in 3D spaces directly from video data, without the need for additional\n3D input. We propose a novel and efficient method, the Video-3D Geometry Large\nLanguage Model (VG LLM). Our approach employs a 3D visual geometry encoder that\nextracts 3D prior information from video sequences. This information is\nintegrated with visual tokens and fed into the MLLM. Extensive experiments have\nshown that our method has achieved substantial improvements in various tasks\nrelated to 3D scene understanding and spatial reasoning, all directly learned\nfrom video sources. Impressively, our 4B model, which does not rely on explicit\n3D data inputs, achieves competitive results compared to existing\nstate-of-the-art methods, and even surpasses the Gemini-1.5-Pro in the\nVSI-Bench evaluations.",
      "pdf_url": "http://arxiv.org/pdf/2505.24625v1",
      "published": "2025-05-30T14:16:41+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.24625v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Hyperbolic Dataset Distillation",
      "authors": [
        "Wenyuan Li",
        "Guang Li",
        "Keisuke Maeda",
        "Takahiro Ogawa",
        "Miki Haseyama"
      ],
      "abstract": "To address the computational and storage challenges posed by large-scale\ndatasets in deep learning, dataset distillation has been proposed to synthesize\na compact dataset that replaces the original while maintaining comparable model\nperformance. Unlike optimization-based approaches that require costly bi-level\noptimization, distribution matching (DM) methods improve efficiency by aligning\nthe distributions of synthetic and original data, thereby eliminating nested\noptimization. DM achieves high computational efficiency and has emerged as a\npromising solution. However, existing DM methods, constrained to Euclidean\nspace, treat data as independent and identically distributed points,\noverlooking complex geometric and hierarchical relationships. To overcome this\nlimitation, we propose a novel hyperbolic dataset distillation method, termed\nHDD. Hyperbolic space, characterized by negative curvature and exponential\nvolume growth with distance, naturally models hierarchical and tree-like\nstructures. HDD embeds features extracted by a shallow network into the Lorentz\nhyperbolic space, where the discrepancy between synthetic and original data is\nmeasured by the hyperbolic (geodesic) distance between their centroids. By\noptimizing this distance, the hierarchical structure is explicitly integrated\ninto the distillation process, guiding synthetic samples to gravitate towards\nthe root-centric regions of the original data distribution while preserving\ntheir underlying geometric characteristics. Furthermore, we find that pruning\nin hyperbolic space requires only 20% of the distilled core set to retain model\nperformance, while significantly improving training stability. Notably, HDD is\nseamlessly compatible with most existing DM methods, and extensive experiments\non different datasets validate its effectiveness.",
      "pdf_url": "http://arxiv.org/pdf/2505.24623v1",
      "published": "2025-05-30T14:14:00+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.24623v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Random Rule Forest (RRF): Interpretable Ensembles of LLM-Generated Questions for Predicting Startup Success",
      "authors": [
        "Ben Griffin",
        "Joseph Ternasky",
        "Fuat Alican",
        "Yigit Ihlamur"
      ],
      "abstract": "Predicting startup success requires models that are both accurate and\ninterpretable. We present a lightweight ensemble framework that combines YES/NO\nquestions generated by large language models (LLMs), forming a transparent\ndecision-making system. Each question acts as a weak heuristic, and by\nfiltering, ranking, and aggregating them through a threshold-based voting\nmechanism, we construct a strong ensemble predictor. On a test set where 10% of\nstartups are classified as successful, our approach achieves a precision rate\nof 50%, representing a 5x improvement over random selection, while remaining\nfully transparent. When we incorporate expert-guided heuristics into the\ngeneration process, performance improves further to 54% precision. These\nresults highlight the value of combining LLM reasoning with human insight and\ndemonstrate that simple, interpretable ensembles can support high-stakes\ndecisions in domains such as venture capital (VC).",
      "pdf_url": "http://arxiv.org/pdf/2505.24622v1",
      "published": "2025-05-30T14:13:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.24622v1",
      "categories": [
        "cs.AI",
        "cs.LG",
        "I.2.7"
      ]
    },
    {
      "title": "Eye of Judgement: Dissecting the Evaluation of Russian-speaking LLMs with POLLUX",
      "authors": [
        "Nikita Martynov",
        "Anastasia Mordasheva",
        "Dmitriy Gorbetskiy",
        "Danil Astafurov",
        "Ulyana Isaeva",
        "Elina Basyrova",
        "Sergey Skachkov",
        "Victoria Berestova",
        "Nikolay Ivanov",
        "Valeriia Zanina",
        "Alena Fenogenova"
      ],
      "abstract": "We introduce POLLUX, a comprehensive open-source benchmark designed to\nevaluate the generative capabilities of large language models (LLMs) in\nRussian. Our main contribution is a novel evaluation methodology that enhances\nthe interpretability of LLM assessment. For each task type, we define a set of\ndetailed criteria and develop a scoring protocol where models evaluate\nresponses and provide justifications for their ratings. This enables\ntransparent, criteria-driven evaluation beyond traditional resource-consuming,\nside-by-side human comparisons. POLLUX includes a detailed, fine-grained\ntaxonomy of 35 task types covering diverse generative domains such as code\ngeneration, creative writing, and practical assistant use cases, totaling 2,100\nmanually crafted and professionally authored prompts. Each task is categorized\nby difficulty (easy/medium/hard), with experts constructing the dataset\nentirely from scratch. We also release a family of LLM-as-a-Judge (7B and 32B)\nevaluators trained for nuanced assessment of generative outputs. This approach\nprovides scalable, interpretable evaluation and annotation tools for model\ndevelopment, effectively replacing costly and less precise human judgments.",
      "pdf_url": "http://arxiv.org/pdf/2505.24616v1",
      "published": "2025-05-30T14:08:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.24616v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Taxonomic Networks: A Representation for Neuro-Symbolic Pairing",
      "authors": [
        "Zekun Wang",
        "Ethan L. Haarer",
        "Nicki Barari",
        "Christopher J. MacLellan"
      ],
      "abstract": "We introduce the concept of a \\textbf{neuro-symbolic pair} -- neural and\nsymbolic approaches that are linked through a common knowledge representation.\nNext, we present \\textbf{taxonomic networks}, a type of discrimination network\nin which nodes represent hierarchically organized taxonomic concepts. Using\nthis representation, we construct a novel neuro-symbolic pair and evaluate its\nperformance. We show that our symbolic method learns taxonomic nets more\nefficiently with less data and compute, while the neural method finds\nhigher-accuracy taxonomic nets when provided with greater resources. As a\nneuro-symbolic pair, these approaches can be used interchangeably based on\nsituational needs, with seamless translation between them when necessary. This\nwork lays the foundation for future systems that more fundamentally integrate\nneural and symbolic computation.",
      "pdf_url": "http://arxiv.org/pdf/2505.24601v1",
      "published": "2025-05-30T13:48:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.24601v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Mixture-of-Experts for Personalized and Semantic-Aware Next Location Prediction",
      "authors": [
        "Shuai Liu",
        "Ning Cao",
        "Yile Chen",
        "Yue Jiang",
        "Gao Cong"
      ],
      "abstract": "Next location prediction plays a critical role in understanding human\nmobility patterns. However, existing approaches face two core limitations: (1)\nthey fall short in capturing the complex, multi-functional semantics of\nreal-world locations; and (2) they lack the capacity to model heterogeneous\nbehavioral dynamics across diverse user groups. To tackle these challenges, we\nintroduce NextLocMoE, a novel framework built upon large language models (LLMs)\nand structured around a dual-level Mixture-of-Experts (MoE) design. Our\narchitecture comprises two specialized modules: a Location Semantics MoE that\noperates at the embedding level to encode rich functional semantics of\nlocations, and a Personalized MoE embedded within the Transformer backbone to\ndynamically adapt to individual user mobility patterns. In addition, we\nincorporate a history-aware routing mechanism that leverages long-term\ntrajectory data to enhance expert selection and ensure prediction stability.\nEmpirical evaluations across several real-world urban datasets show that\nNextLocMoE achieves superior performance in terms of predictive accuracy,\ncross-domain generalization, and interpretability",
      "pdf_url": "http://arxiv.org/pdf/2505.24597v1",
      "published": "2025-05-30T13:45:19+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.24597v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Binary Cumulative Encoding meets Time Series Forecasting",
      "authors": [
        "Andrei Chernov",
        "Vitaliy Pozdnyakov",
        "Ilya Makarov"
      ],
      "abstract": "Recent studies in time series forecasting have explored formulating\nregression via classification task. By discretizing the continuous target space\ninto bins and predicting over a fixed set of classes, these approaches benefit\nfrom stable training, robust uncertainty modeling, and compatibility with\nmodern deep learning architectures. However, most existing methods rely on\none-hot encoding that ignores the inherent ordinal structure of the underlying\nvalues. As a result, they fail to provide information about the relative\ndistance between predicted and true values during training. In this paper, we\npropose to address this limitation by introducing binary cumulative encoding\n(BCE), that represents scalar targets into monotonic binary vectors. This\nencoding implicitly preserves order and magnitude information, allowing the\nmodel to learn distance-aware representations while still operating within a\nclassification framework. We propose a convolutional neural network\narchitecture specifically designed for BCE, incorporating residual and dilated\nconvolutions to enable fast and expressive temporal modeling. Through extensive\nexperiments on benchmark forecasting datasets, we show that our approach\noutperforms widely used methods in both point and probabilistic forecasting,\nwhile requiring fewer parameters and enabling faster training.",
      "pdf_url": "http://arxiv.org/pdf/2505.24595v1",
      "published": "2025-05-30T13:41:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.24595v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ]
    },
    {
      "title": "Decoding Knowledge Attribution in Mixture-of-Experts: A Framework of Basic-Refinement Collaboration and Efficiency Analysis",
      "authors": [
        "Junzhuo Li",
        "Bo Wang",
        "Xiuze Zhou",
        "Peijie Jiang",
        "Jia Liu",
        "Xuming Hu"
      ],
      "abstract": "The interpretability of Mixture-of-Experts (MoE) models, especially those\nwith heterogeneous designs, remains underexplored. Existing attribution methods\nfor dense models fail to capture dynamic routing-expert interactions in sparse\nMoE architectures. To address this issue, we propose a cross-level attribution\nalgorithm to analyze sparse MoE architectures (Qwen 1.5-MoE, OLMoE,\nMixtral-8x7B) against dense models (Qwen 1.5-7B, Llama-7B, Mixtral-7B). Results\nshow MoE models achieve 37% higher per-layer efficiency via a \"mid-activation,\nlate-amplification\" pattern: early layers screen experts, while late layers\nrefine knowledge collaboratively. Ablation studies reveal a \"basic-refinement\"\nframework--shared experts handle general tasks (entity recognition), while\nrouted experts specialize in domain-specific processing (geographic\nattributes). Semantic-driven routing is evidenced by strong correlations\nbetween attention heads and experts (r=0.68), enabling task-aware coordination.\nNotably, architectural depth dictates robustness: deep Qwen 1.5-MoE mitigates\nexpert failures (e.g., 43% MRR drop in geographic tasks when blocking top-10\nexperts) through shared expert redundancy, whereas shallow OLMoE suffers severe\ndegradation (76% drop). Task sensitivity further guides design: core-sensitive\ntasks (geography) require concentrated expertise, while distributed-tolerant\ntasks (object attributes) leverage broader participation. These insights\nadvance MoE interpretability, offering principles to balance efficiency,\nspecialization, and robustness.",
      "pdf_url": "http://arxiv.org/pdf/2505.24593v1",
      "published": "2025-05-30T13:40:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.24593v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "A Flat Minima Perspective on Understanding Augmentations and Model Robustness",
      "authors": [
        "Weebum Yoo",
        "Sung Whan Yoon"
      ],
      "abstract": "Model robustness indicates a model's capability to generalize well on\nunforeseen distributional shifts, including data corruption, adversarial\nattacks, and domain shifts. Data augmentation is one of the prevalent and\neffective ways to enhance robustness. Despite the great success of\naugmentations in different fields, a general theoretical understanding of their\nefficacy in improving model robustness is lacking. We offer a unified\ntheoretical framework to clarify how augmentations can enhance model robustness\nthrough the lens of loss surface flatness and PAC generalization bound. Our\nwork diverges from prior studies in that our analysis i) broadly encompasses\nmuch of the existing augmentation methods, and ii) is not limited to specific\ntypes of distribution shifts like adversarial attacks. We confirm our theories\nthrough simulations on the existing common corruption and adversarial\nrobustness benchmarks based on the CIFAR and ImageNet datasets, as well as\ndomain generalization benchmarks including PACS and OfficeHome.",
      "pdf_url": "http://arxiv.org/pdf/2505.24592v1",
      "published": "2025-05-30T13:40:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.24592v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "AutoChemSchematic AI: A Closed-Loop, Physics-Aware Agentic Framework for Auto-Generating Chemical Process and Instrumentation Diagrams",
      "authors": [
        "Sakhinana Sagar Srinivas",
        "Shivam Gupta",
        "Venkataramana Runkana"
      ],
      "abstract": "Recent advancements in generative AI have accelerated the discovery of novel\nchemicals and materials; however, transitioning these discoveries to\nindustrial-scale production remains a critical bottleneck, as it requires the\ndevelopment of entirely new chemical manufacturing processes. Current AI\nmethods cannot auto-generate PFDs or PIDs, despite their critical role in\nscaling chemical processes, while adhering to engineering constraints. We\npresent a closed loop, physics aware framework for the automated generation of\nindustrially viable PFDs and PIDs. The framework integrates domain specialized\nsmall scale language models (SLMs) (trained for chemical process QA tasks) with\nfirst principles simulation, leveraging three key components: (1) a\nhierarchical knowledge graph of process flow and instrumentation descriptions\nfor 1,020+ chemicals, (2) a multi-stage training pipeline that fine tunes\ndomain specialized SLMs on synthetic datasets via Supervised Fine-Tuning (SFT),\nDirect Preference Optimization (DPO), and Retrieval-Augmented Instruction\nTuning (RAIT), and (3) DWSIM based simulator in the loop validation to ensure\nfeasibility. To improve both runtime efficiency and model compactness, the\nframework incorporates advanced inference time optimizations including\nFlashAttention, Lookahead Decoding, PagedAttention with KV-cache quantization,\nand Test Time Inference Scaling and independently applies structural pruning\ntechniques (width and depth) guided by importance heuristics to reduce model\nsize with minimal accuracy loss. Experiments demonstrate that the framework\ngenerates simulator-validated process descriptions with high fidelity,\noutperforms baseline methods in correctness, and generalizes to unseen\nchemicals. By bridging AI-driven design with industrial-scale feasibility, this\nwork significantly reduces R&D timelines from lab discovery to plant\ndeployment.",
      "pdf_url": "http://arxiv.org/pdf/2505.24584v1",
      "published": "2025-05-30T13:32:00+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.24584v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR"
      ]
    },
    {
      "title": "NexusSum: Hierarchical LLM Agents for Long-Form Narrative Summarization",
      "authors": [
        "Hyuntak Kim",
        "Byung-Hak Kim"
      ],
      "abstract": "Summarizing long-form narratives--such as books, movies, and TV\nscripts--requires capturing intricate plotlines, character interactions, and\nthematic coherence, a task that remains challenging for existing LLMs. We\nintroduce NexusSum, a multi-agent LLM framework for narrative summarization\nthat processes long-form text through a structured, sequential\npipeline--without requiring fine-tuning. Our approach introduces two key\ninnovations: (1) Dialogue-to-Description Transformation: A narrative-specific\npreprocessing method that standardizes character dialogue and descriptive text\ninto a unified format, improving coherence. (2) Hierarchical Multi-LLM\nSummarization: A structured summarization pipeline that optimizes chunk\nprocessing and controls output length for accurate, high-quality summaries. Our\nmethod establishes a new state-of-the-art in narrative summarization, achieving\nup to a 30.0% improvement in BERTScore (F1) across books, movies, and TV\nscripts. These results demonstrate the effectiveness of multi-agent LLMs in\nhandling long-form content, offering a scalable approach for structured\nsummarization in diverse storytelling domains.",
      "pdf_url": "http://arxiv.org/pdf/2505.24575v1",
      "published": "2025-05-30T13:26:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.24575v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Bench4KE: Benchmarking Automated Competency Question Generation",
      "authors": [
        "Anna Sofia Lippolis",
        "Minh Davide Ragagni",
        "Paolo Ciancarini",
        "Andrea Giovanni Nuzzolese",
        "Valentina Presutti"
      ],
      "abstract": "The availability of Large Language Models (LLMs) presents a unique\nopportunity to reinvigorate research on Knowledge Engineering (KE) automation,\na trend already evident in recent efforts developing LLM-based methods and\ntools for the automatic generation of Competency Questions (CQs). However, the\nevaluation of these tools lacks standardisation. This undermines the\nmethodological rigour and hinders the replication and comparison of results. To\naddress this gap, we introduce Bench4KE, an extensible API-based benchmarking\nsystem for KE automation. Its first release focuses on evaluating tools that\ngenerate CQs automatically. CQs are natural language questions used by ontology\nengineers to define the functional requirements of an ontology. Bench4KE\nprovides a curated gold standard consisting of CQ datasets from four real-world\nontology projects. It uses a suite of similarity metrics to assess the quality\nof the CQs generated. We present a comparative analysis of four recent CQ\ngeneration systems, which are based on LLMs, establishing a baseline for future\nresearch. Bench4KE is also designed to accommodate additional KE automation\ntasks, such as SPARQL query generation, ontology testing and drafting. Code and\ndatasets are publicly available under the Apache 2.0 license.",
      "pdf_url": "http://arxiv.org/pdf/2505.24554v1",
      "published": "2025-05-30T13:03:42+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.24554v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "CREFT: Sequential Multi-Agent LLM for Character Relation Extraction",
      "authors": [
        "Ye Eun Chun",
        "Taeyoon Hwang",
        "Seung-won Hwang",
        "Byung-Hak Kim"
      ],
      "abstract": "Understanding complex character relations is crucial for narrative analysis\nand efficient script evaluation, yet existing extraction methods often fail to\nhandle long-form narratives with nuanced interactions. To address this\nchallenge, we present CREFT, a novel sequential framework leveraging\nspecialized Large Language Model (LLM) agents. First, CREFT builds a base\ncharacter graph through knowledge distillation, then iteratively refines\ncharacter composition, relation extraction, role identification, and group\nassignments. Experiments on a curated Korean drama dataset demonstrate that\nCREFT significantly outperforms single-agent LLM baselines in both accuracy and\ncompleteness. By systematically visualizing character networks, CREFT\nstreamlines narrative comprehension and accelerates script review -- offering\nsubstantial benefits to the entertainment, publishing, and educational sectors.",
      "pdf_url": "http://arxiv.org/pdf/2505.24553v1",
      "published": "2025-05-30T13:01:36+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.24553v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    }
  ]
}