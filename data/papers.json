{
  "last_updated": "2025-08-20T00:50:37.393683",
  "papers": [
    {
      "title": "RepreGuard: Detecting LLM-Generated Text by Revealing Hidden Representation Patterns",
      "authors": [
        "Xin Chen",
        "Junchao Wu",
        "Shu Yang",
        "Runzhe Zhan",
        "Zeyu Wu",
        "Ziyang Luo",
        "Di Wang",
        "Min Yang",
        "Lidia S. Chao",
        "Derek F. Wong"
      ],
      "abstract": "Detecting content generated by large language models (LLMs) is crucial for\npreventing misuse and building trustworthy AI systems. Although existing\ndetection methods perform well, their robustness in out-of-distribution (OOD)\nscenarios is still lacking. In this paper, we hypothesize that, compared to\nfeatures used by existing detection methods, the internal representations of\nLLMs contain more comprehensive and raw features that can more effectively\ncapture and distinguish the statistical pattern differences between\nLLM-generated texts (LGT) and human-written texts (HWT). We validated this\nhypothesis across different LLMs and observed significant differences in neural\nactivation patterns when processing these two types of texts. Based on this, we\npropose RepreGuard, an efficient statistics-based detection method.\nSpecifically, we first employ a surrogate model to collect representation of\nLGT and HWT, and extract the distinct activation feature that can better\nidentify LGT. We can classify the text by calculating the projection score of\nthe text representations along this feature direction and comparing with a\nprecomputed threshold. Experimental results show that RepreGuard outperforms\nall baselines with average 94.92% AUROC on both in-distribution (ID) and OOD\nscenarios, while also demonstrating robust resilience to various text sizes and\nmainstream attacks. Data and code are publicly available at:\nhttps://github.com/NLP2CT/RepreGuard",
      "pdf_url": "http://arxiv.org/pdf/2508.13152v1",
      "published": "2025-08-18T17:59:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.13152v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Exploring Autonomous Agents: A Closer Look at Why They Fail When Completing Tasks",
      "authors": [
        "Ruofan Lu",
        "Yichen Li",
        "Yintong Huo"
      ],
      "abstract": "Autonomous agent systems powered by Large Language Models (LLMs) have\ndemonstrated promising capabilities in automating complex tasks. However,\ncurrent evaluations largely rely on success rates without systematically\nanalyzing the interactions, communication mechanisms, and failure causes within\nthese systems. To bridge this gap, we present a benchmark of 34 representative\nprogrammable tasks designed to rigorously assess autonomous agents. Using this\nbenchmark, we evaluate three popular open-source agent frameworks combined with\ntwo LLM backbones, observing a task completion rate of approximately 50%.\nThrough in-depth failure analysis, we develop a three-tier taxonomy of failure\ncauses aligned with task phases, highlighting planning errors, task execution\nissues, and incorrect response generation. Based on these insights, we propose\nactionable improvements to enhance agent planning and self-diagnosis\ncapabilities. Our failure taxonomy, together with mitigation advice, provides\nan empirical foundation for developing more robust and effective autonomous\nagent systems in the future.",
      "pdf_url": "http://arxiv.org/pdf/2508.13143v1",
      "published": "2025-08-18T17:55:22+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.13143v1",
      "categories": [
        "cs.AI",
        "cs.SE"
      ]
    },
    {
      "title": "Spot the BlindSpots: Systematic Identification and Quantification of Fine-Grained LLM Biases in Contact Center Summaries",
      "authors": [
        "Kawin Mayilvaghanan",
        "Siddhant Gupta",
        "Ayush Kumar"
      ],
      "abstract": "Abstractive summarization is a core application in contact centers, where\nLarge Language Models (LLMs) generate millions of summaries of call transcripts\ndaily. Despite their apparent quality, it remains unclear whether LLMs\nsystematically under- or over-attend to specific aspects of the transcript,\npotentially introducing biases in the generated summary. While prior work has\nexamined social and positional biases, the specific forms of bias pertinent to\ncontact center operations - which we term Operational Bias - have remained\nunexplored. To address this gap, we introduce BlindSpot, a framework built upon\na taxonomy of 15 operational bias dimensions (e.g., disfluency, speaker, topic)\nfor the identification and quantification of these biases. BlindSpot leverages\nan LLM as a zero-shot classifier to derive categorical distributions for each\nbias dimension in a pair of transcript and its summary. The bias is then\nquantified using two metrics: Fidelity Gap (the JS Divergence between\ndistributions) and Coverage (the percentage of source labels omitted). Using\nBlindSpot, we conducted an empirical study with 2500 real call transcripts and\ntheir summaries generated by 20 LLMs of varying scales and families (e.g., GPT,\nLlama, Claude). Our analysis reveals that biases are systemic and present\nacross all evaluated models, regardless of size or family.",
      "pdf_url": "http://arxiv.org/pdf/2508.13124v1",
      "published": "2025-08-18T17:31:03+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.13124v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Bayesian Optimization-based Search for Agent Control in Automated Game Testing",
      "authors": [
        "Carlos Celemin"
      ],
      "abstract": "This work introduces an automated testing approach that employs agents\ncontrolling game characters to detect potential bugs within a game level.\nHarnessing the power of Bayesian Optimization (BO) to execute sample-efficient\nsearch, the method determines the next sampling point by analyzing the data\ncollected so far and calculates the data point that will maximize information\nacquisition. To support the BO process, we introduce a game testing-specific\nmodel built on top of a grid map, that features the smoothness and uncertainty\nestimation required by BO, however and most importantly, it does not suffer the\nscalability issues that traditional models carry. The experiments demonstrate\nthat the approach significantly improves map coverage capabilities in both time\nefficiency and exploration distribution.",
      "pdf_url": "http://arxiv.org/pdf/2508.13121v1",
      "published": "2025-08-18T17:24:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.13121v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Contrastive Representations for Temporal Reasoning",
      "authors": [
        "Alicja Ziarko",
        "Michal Bortkiewicz",
        "Michal Zawalski",
        "Benjamin Eysenbach",
        "Piotr Milos"
      ],
      "abstract": "In classical AI, perception relies on learning state-based representations,\nwhile planning, which can be thought of as temporal reasoning over action\nsequences, is typically achieved through search. We study whether such\nreasoning can instead emerge from representations that capture both perceptual\nand temporal structure. We show that standard temporal contrastive learning,\ndespite its popularity, often fails to capture temporal structure due to its\nreliance on spurious features. To address this, we introduce Combinatorial\nRepresentations for Temporal Reasoning (CRTR), a method that uses a negative\nsampling scheme to provably remove these spurious features and facilitate\ntemporal reasoning. CRTR achieves strong results on domains with complex\ntemporal structure, such as Sokoban and Rubik's Cube. In particular, for the\nRubik's Cube, CRTR learns representations that generalize across all initial\nstates and allow it to solve the puzzle using fewer search steps than BestFS,\nthough with longer solutions. To our knowledge, this is the first method that\nefficiently solves arbitrary Cube states using only learned representations,\nwithout relying on an external search algorithm.",
      "pdf_url": "http://arxiv.org/pdf/2508.13113v1",
      "published": "2025-08-18T17:20:08+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.13113v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "VerilogLAVD: LLM-Aided Rule Generation for Vulnerability Detection in Verilog",
      "authors": [
        "Xiang Long",
        "Yingjie Xia",
        "Xiyuan Chen",
        "Li Kuang"
      ],
      "abstract": "Timely detection of hardware vulnerabilities during the early design stage is\ncritical for reducing remediation costs. Existing early detection techniques\noften require specialized security expertise, limiting their usability. Recent\nefforts have explored the use of large language models (LLMs) for Verilog\nvulnerability detection. However, LLMs struggle to capture the structure in\nVerilog code, resulting in inconsistent detection results. To this end, we\npropose VerilogLAVD, the first LLM-aided graph traversal rule generation\napproach for Verilog vulnerability detection. Our approach introduces the\nVerilog Property Graph (VeriPG), a unified representation of Verilog code. It\ncombines syntactic features extracted from the abstract syntax tree (AST) with\nsemantic information derived from control flow and data dependency graphs. We\nleverage LLMs to generate VeriPG-based detection rules from Common Weakness\nEnumeration (CWE) descriptions. These rules guide the rule executor that\ntraversal VeriPG for potential vulnerabilities. To evaluate VerilogLAVD, we\nbuild a dataset collected from open-source repositories and synthesized data.\nIn our empirical evaluation on 77 Verilog designs encompassing 12 CWE types,\nVerilogLAVD achieves an F1-score of 0.54. Compared to the LLM-only and LLM with\nexternal knowledge baselines, VerilogLAVD improves F1-score by 0.31 and 0.27,\nrespectively.",
      "pdf_url": "http://arxiv.org/pdf/2508.13092v2",
      "published": "2025-08-18T17:05:18+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.13092v2",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "title": "From Transthoracic to Transesophageal: Cross-Modality Generation using LoRA Diffusion",
      "authors": [
        "Emmanuel Oladokun",
        "Yuxuan Ou",
        "Anna Novikova",
        "Daria Kulikova",
        "Sarina Thomas",
        "Jurica Šprem",
        "Vicente Grau"
      ],
      "abstract": "Deep diffusion models excel at realistic image synthesis but demand large\ntraining sets-an obstacle in data-scarce domains like transesophageal\nechocardiography (TEE). While synthetic augmentation has boosted performance in\ntransthoracic echo (TTE), TEE remains critically underrepresented, limiting the\nreach of deep learning in this high-impact modality.\n  We address this gap by adapting a TTE-trained, mask-conditioned diffusion\nbackbone to TEE with only a limited number of new cases and adapters as small\nas $10^5$ parameters. Our pipeline combines Low-Rank Adaptation with MaskR$^2$,\na lightweight remapping layer that aligns novel mask formats with the\npretrained model's conditioning channels. This design lets users adapt models\nto new datasets with a different set of anatomical structures to the base\nmodel's original set.\n  Through a targeted adaptation strategy, we find that adapting only MLP layers\nsuffices for high-fidelity TEE synthesis. Finally, mixing less than 200 real\nTEE frames with our synthetic echoes improves the dice score on a multiclass\nsegmentation task, particularly boosting performance on underrepresented\nright-heart structures. Our results demonstrate that (1) semantically\ncontrolled TEE images can be generated with low overhead, (2) MaskR$^2$\neffectively transforms unseen mask formats into compatible formats without\ndamaging downstream task performance, and (3) our method generates images that\nare effective for improving performance on a downstream task of multiclass\nsegmentation.",
      "pdf_url": "http://arxiv.org/pdf/2508.13077v1",
      "published": "2025-08-18T16:48:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.13077v1",
      "categories": [
        "eess.IV",
        "cs.AI"
      ]
    },
    {
      "title": "A Language-Signal-Vision Multimodal Framework for Multitask Cardiac Analysis",
      "authors": [
        "Yuting Zhang",
        "Tiantian Geng",
        "Luoying Hao",
        "Xinxing Cheng",
        "Alexander Thorley",
        "Xiaoxia Wang",
        "Wenqi Lu",
        "Sandeep S Hothi",
        "Lei Wei",
        "Zhaowen Qiu",
        "Dipak Kotecha",
        "Jinming Duan"
      ],
      "abstract": "Contemporary cardiovascular management involves complex consideration and\nintegration of multimodal cardiac datasets, where each modality provides\ndistinct but complementary physiological characteristics. While the effective\nintegration of multiple modalities could yield a holistic clinical profile that\naccurately models the true clinical situation with respect to data modalities\nand their relatives weightings, current methodologies remain limited by: 1) the\nscarcity of patient- and time-aligned multimodal data; 2) reliance on isolated\nsingle-modality or rigid multimodal input combinations; 3) alignment strategies\nthat prioritize cross-modal similarity over complementarity; and 4) a narrow\nsingle-task focus. In response to these limitations, a comprehensive multimodal\ndataset was curated for immediate application, integrating laboratory test\nresults, electrocardiograms, and echocardiograms with clinical outcomes.\nSubsequently, a unified framework, Textual Guidance Multimodal fusion for\nMultiple cardiac tasks (TGMM), was proposed. TGMM incorporated three key\ncomponents: 1) a MedFlexFusion module designed to capture the unique and\ncomplementary characteristics of medical modalities and dynamically integrate\ndata from diverse cardiac sources and their combinations; 2) a textual guidance\nmodule to derive task-relevant representations tailored to diverse clinical\nobjectives, including heart disease diagnosis, risk stratification and\ninformation retrieval; and 3) a response module to produce final decisions for\nall these tasks. Furthermore, this study systematically explored key features\nacross multiple modalities and elucidated their synergistic contributions in\nclinical decision-making. Extensive experiments showed that TGMM outperformed\nstate-of-the-art methods across multiple clinical tasks, with additional\nvalidation confirming its robustness on another public dataset.",
      "pdf_url": "http://arxiv.org/pdf/2508.13072v1",
      "published": "2025-08-18T16:43:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.13072v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Reinforced Context Order Recovery for Adaptive Reasoning and Planning",
      "authors": [
        "Long Ma",
        "Fangwei Zhong",
        "Yizhou Wang"
      ],
      "abstract": "Modern causal language models, followed by rapid developments in discrete\ndiffusion models, can now produce a wide variety of interesting and useful\ncontent. However, these families of models are predominantly trained to output\ntokens with a fixed (left-to-right) or random order, which may deviate from the\nlogical order in which tokens are generated originally. In this paper, we\nobserve that current causal and diffusion models encounter difficulties in\nproblems that require adaptive token generation orders to solve tractably,\nwhich we characterize with the $\\mathcal{V}$-information framework. Motivated\nby this, we propose Reinforced Context Order Recovery (ReCOR), a\nreinforcement-learning-based framework to extract adaptive, data-dependent\ntoken generation orders from text data without annotations. Self-supervised by\ntoken prediction statistics, ReCOR estimates the hardness of predicting every\nunfilled token and adaptively selects the next token during both training and\ninference. Experiments on challenging reasoning and planning datasets\ndemonstrate the superior performance of ReCOR compared with baselines,\nsometimes outperforming oracle models supervised with the ground-truth order.",
      "pdf_url": "http://arxiv.org/pdf/2508.13070v1",
      "published": "2025-08-18T16:42:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.13070v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Hierarchical Evaluation Function (HEF): A Multi-Metric Approach for Optimizing Demand Forecasting Models",
      "authors": [
        "Adolfo González",
        "Víctor Parada"
      ],
      "abstract": "Demand forecasting is essential for strategic planning in competitive\nenvironments, enabling resource optimization and improved responsiveness to\nmarket dynamics. However, multivariate time series modeling faces challenges\ndue to data complexity, uncertainty, and frequent regime shifts. Traditional\nevaluation metrics can introduce biases and limit generalization. This work\ncompares two custom evaluation functions: FMAE (Focused Mean Absolute Error),\nfocused on minimizing absolute errors, and HEF (Hierarchical Evaluation\nFunction), designed to weight global metrics and penalize large deviations.\nExperiments were conducted under different data splits (91:9, 80:20, 70:30)\nusing three optimizers (Grid Search, PSO, Optuna), assessing fit, relative\naccuracy, robustness, and computational efficiency. Results show that HEF\nconsistently outperforms FMAE in global metrics (R2, Relative Accuracy, RMSE,\nRMSSE), enhancing model robustness and explanatory power. These findings were\nconfirmed via visualizations and statistical tests. Conversely, FMAE offers\nadvantages in local metrics (MAE, MASE) and execution time, making it suitable\nfor short-term scenarios. The study highlights a methodological trade-off: HEF\nis ideal for strategic planning, while FMAE is better suited for operational\nefficiency. A replicable framework is proposed for optimizing predictive models\nin dynamic environments.",
      "pdf_url": "http://arxiv.org/pdf/2508.13057v1",
      "published": "2025-08-18T16:25:49+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.13057v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.PF",
        "62M10, 90C59, 68T05",
        "I.2.6; I.5.1; I.5.2; I.5.4; G.1.6"
      ]
    },
    {
      "title": "XR-NPE: High-Throughput Mixed-precision SIMD Neural Processing Engine for Extended Reality Perception Workloads",
      "authors": [
        "Tejas Chaudhari",
        "Akarsh J.",
        "Tanushree Dewangan",
        "Mukul Lokhande",
        "Santosh Kumar Vishvakarma"
      ],
      "abstract": "This work proposes XR-NPE, a high-throughput Mixed-precision SIMD Neural\nProcessing Engine, designed for extended reality (XR) perception workloads like\nvisual inertial odometry (VIO), object classification, and eye gaze extraction.\nXR-NPE is first to support FP4, Posit (4,1), Posit (8,0), and Posit (16,1)\nformats, with layer adaptive hybrid-algorithmic implementation supporting\nultra-low bit precision to significantly reduce memory bandwidth requirements,\nand accompanied by quantization-aware training for minimal accuracy loss. The\nproposed Reconfigurable Mantissa Multiplication and Exponent processing\nCircuitry (RMMEC) reduces dark silicon in the SIMD MAC compute engine, assisted\nby selective power gating to reduce energy consumption, providing 2.85x\nimproved arithmetic intensity. XR-NPE achieves a maximum operating frequency of\n1.72 GHz, area 0.016 mm2 , and arithmetic intensity 14 pJ at CMOS 28nm,\nreducing 42% area, 38% power compared to the best of state-of-the-art MAC\napproaches. The proposed XR-NPE based AXI-enabled Matrix-multiplication\nco-processor consumes 1.4x fewer LUTs, 1.77x fewer FFs, and provides 1.2x\nbetter energy efficiency compared to SoTA accelerators on VCU129. The proposed\nco-processor provides 23% better energy efficiency and 4% better compute\ndensity for VIO workloads. XR-NPE establishes itself as a scalable,\nprecision-adaptive compute engine for future resource-constrained XR devices.\nThe complete set for codes for results reproducibility are released publicly,\nenabling designers and researchers to readily adopt and build upon them.\nhttps://github.com/mukullokhande99/XR-NPE.",
      "pdf_url": "http://arxiv.org/pdf/2508.13049v1",
      "published": "2025-08-18T16:13:00+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.13049v1",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.CV",
        "eess.IV"
      ]
    },
    {
      "title": "Using AI for User Representation: An Analysis of 83 Persona Prompts",
      "authors": [
        "Joni Salminen",
        "Danial Amin",
        "Bernard Jansen"
      ],
      "abstract": "We analyzed 83 persona prompts from 27 research articles that used large\nlanguage models (LLMs) to generate user personas. Findings show that the\nprompts predominantly generate single personas. Several prompts express a\ndesire for short or concise persona descriptions, which deviates from the\ntradition of creating rich, informative, and rounded persona profiles. Text is\nthe most common format for generated persona attributes, followed by numbers.\nText and numbers are often generated together, and demographic attributes are\nincluded in nearly all generated personas. Researchers use up to 12 prompts in\na single study, though most research uses a small number of prompts. Comparison\nand testing multiple LLMs is rare. More than half of the prompts require the\npersona output in a structured format, such as JSON, and 74% of the prompts\ninsert data or dynamic variables. We discuss the implications of increased use\nof computational personas for user representation.",
      "pdf_url": "http://arxiv.org/pdf/2508.13047v1",
      "published": "2025-08-18T16:09:47+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.13047v1",
      "categories": [
        "cs.HC",
        "cs.AI"
      ]
    },
    {
      "title": "Can Large Models Teach Student Models to Solve Mathematical Problems Like Human Beings? A Reasoning Distillation Method via Multi-LoRA Interaction",
      "authors": [
        "Xinhe Li",
        "Jiajun Liu",
        "Peng Wang"
      ],
      "abstract": "Recent studies have demonstrated that Large Language Models (LLMs) have\nstrong mathematical reasoning abilities but rely on hundreds of billions of\nparameters. To tackle the challenge of poor reasoning in Small Language Models\n(SLMs), existing methods typically leverage LLMs to generate massive amounts of\ndata for cramming training. In psychology, they are akin to System 1 thinking,\nwhich resolves reasoning problems rapidly based on experience and intuition.\nHowever, human learning also requires System 2 thinking, where knowledge is\nfirst acquired and then reinforced through practice. Inspired by such two\ndistinct modes of thinking, we propose a novel method based on the multi-LoRA\nInteraction for mathematical reasoning Distillation (LoRID). First, we input\nthe question and reasoning of each sample into an LLM to create\nknowledge-enhanced datasets. Subsequently, we train a LoRA block on the student\nmodel as an Intuitive Reasoner (IR), which directly generates Chain-of-Thoughts\nfor problem-solving. Then, to imitate System 2 thinking, we train the Knowledge\nGenerator (KG) and Deep Reasoner (DR), respectively. The former outputs only\nknowledge after receiving problems, while the latter uses that knowledge to\nperform reasoning. Finally, to address the randomness in the generation of IR\nand DR, we evaluate whether their outputs are consistent, and the inference\nprocess needs to be iterated if not. This step can enhance the mathematical\nreasoning ability of SLMs through mutual feedback. Experimental results show\nthat LoRID achieves state-of-the-art performance, especially on the GSM8K\ndataset, where it outperforms the second-best method by 2.3%, 16.1%, 2.4%,\n12.3%, and 1.8% accuracy across the five base models, respectively.",
      "pdf_url": "http://arxiv.org/pdf/2508.13037v1",
      "published": "2025-08-18T15:56:10+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.13037v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "The Application of Transformer-Based Models for Predicting Consequences of Cyber Attacks",
      "authors": [
        "Bipin Chhetri",
        "Akbar Siami Namin"
      ],
      "abstract": "Cyberattacks are increasing, and securing against such threats is costing\nindustries billions of dollars annually. Threat Modeling, that is,\ncomprehending the consequences of these attacks, can provide critical support\nto cybersecurity professionals, enabling them to take timely action and\nallocate resources that could be used elsewhere. Cybersecurity is heavily\ndependent on threat modeling, as it assists security experts in assessing and\nmitigating risks related to identifying vulnerabilities and threats. Recently,\nthere has been a pressing need for automated methods to assess attack\ndescriptions and forecast the future consequences of the increasing complexity\nof cyberattacks. This study examines how Natural Language Processing (NLP) and\ndeep learning can be applied to analyze the potential impact of cyberattacks by\nleveraging textual descriptions from the MITRE Common Weakness Enumeration\n(CWE) database. We emphasize classifying attack consequences into five\nprincipal categories: Availability, Access Control, Confidentiality, Integrity,\nand Other. This paper investigates the use of Bidirectional Encoder\nRepresentations from Transformers (BERT) in combination with Hierarchical\nAttention Networks (HANs) for Multi-label classification, evaluating their\nperformance in comparison with conventional CNN and LSTM-based models.\nExperimental findings show that BERT achieves an overall accuracy of $0.972$,\nfar higher than conventional deep learning models in multi-label\nclassification. HAN outperforms baseline forms of CNN and LSTM-based models on\nspecific cybersecurity labels. However, BERT consistently achieves better\nprecision and recall, making it more suitable for predicting the consequences\nof a cyberattack.",
      "pdf_url": "http://arxiv.org/pdf/2508.13030v1",
      "published": "2025-08-18T15:46:36+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.13030v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ]
    },
    {
      "title": "G$^2$RPO-A: Guided Group Relative Policy Optimization with Adaptive Guidance",
      "authors": [
        "Yongxin Guo",
        "Wenbo Deng",
        "Zhenglin Cheng",
        "Xiaoying Tang"
      ],
      "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has markedly enhanced\nthe reasoning abilities of large language models (LLMs). Its success, however,\nlargely depends on strong base models with rich world knowledge, yielding only\nmodest improvements for small-size language models (SLMs). To address this\nlimitation, we investigate Guided GRPO, which injects ground-truth reasoning\nsteps into roll-out trajectories to compensate for SLMs' inherent weaknesses.\nThrough a comprehensive study of various guidance configurations, we find that\nnaively adding guidance delivers limited gains. These insights motivate\nG$^2$RPO-A, an adaptive algorithm that automatically adjusts guidance strength\nin response to the model's evolving training dynamics. Experiments on\nmathematical reasoning and code-generation benchmarks confirm that G$^2$RPO-A\nsubstantially outperforms vanilla GRPO. Our code and models are available at\nhttps://github.com/T-Lab-CUHKSZ/G2RPO-A.",
      "pdf_url": "http://arxiv.org/pdf/2508.13023v1",
      "published": "2025-08-18T15:41:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.13023v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "PC-Sampler: Position-Aware Calibration of Decoding Bias in Masked Diffusion Models",
      "authors": [
        "Pengcheng Huang",
        "Shuhao Liu",
        "Zhenghao Liu",
        "Yukun Yan",
        "Shuo Wang",
        "Zulong Chen",
        "Tong Xiao"
      ],
      "abstract": "Recent advances in masked diffusion models (MDMs) have established them as\npowerful non-autoregressive alternatives for sequence generation. Nevertheless,\nour preliminary experiments reveal that the generation quality of MDMs is still\nhighly sensitive to the choice of decoding strategy. In particular, widely\nadopted uncertainty-based samplers suffer from two key limitations: a lack of\nglobal trajectory control and a pronounced bias toward trivial tokens in the\nearly stages of decoding. These shortcomings restrict the full potential of\nMDMs. In this work, we introduce Position-Aware Confidence-Calibrated Sampling\n(PC-Sampler), a novel decoding strategy that unifies global trajectory planning\nwith content-aware informativeness maximization. PC-Sampler incorporates a\nposition-aware weighting mechanism to regulate the decoding path and a\ncalibrated confidence score to suppress the premature selection of trivial\ntokens. Extensive experiments on three advanced MDMs across seven challenging\nbenchmarks-including logical reasoning and planning tasks-demonstrate that\nPC-Sampler consistently outperforms existing MDM decoding strategies by more\nthan 10% on average, significantly narrowing the performance gap with\nstate-of-the-art autoregressive models. All codes are available at\nhttps://github.com/NEUIR/PC-Sampler.",
      "pdf_url": "http://arxiv.org/pdf/2508.13021v2",
      "published": "2025-08-18T15:38:37+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.13021v2",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "e-boost: Boosted E-Graph Extraction with Adaptive Heuristics and Exact Solving",
      "authors": [
        "Jiaqi Yin",
        "Zhan Song",
        "Chen Chen",
        "Yaohui Cai",
        "Zhiru Zhang",
        "Cunxi Yu"
      ],
      "abstract": "E-graphs have attracted growing interest in many fields, particularly in\nlogic synthesis and formal verification. E-graph extraction is a challenging\nNP-hard combinatorial optimization problem. It requires identifying optimal\nterms from exponentially many equivalent expressions, serving as the primary\nperformance bottleneck in e-graph based optimization tasks. However,\ntraditional extraction methods face a critical trade-off: heuristic approaches\noffer speed but sacrifice optimality, while exact methods provide optimal\nsolutions but face prohibitive computational costs on practical problems. We\npresent e-boost, a novel framework that bridges this gap through three key\ninnovations: (1) parallelized heuristic extraction that leverages weak data\ndependence to compute DAG costs concurrently, enabling efficient multi-threaded\nperformance without sacrificing extraction quality; (2) adaptive search space\npruning that employs a parameterized threshold mechanism to retain only\npromising candidates, dramatically reducing the solution space while preserving\nnear-optimal solutions; and (3) initialized exact solving that formulates the\nreduced problem as an Integer Linear Program with warm-start capabilities,\nguiding solvers toward high-quality solutions faster.\n  Across the diverse benchmarks in formal verification and logic synthesis\nfields, e-boost demonstrates 558x runtime speedup over traditional exact\napproaches (ILP) and 19.04% performance improvement over the state-of-the-art\nextraction framework (SmoothE). In realistic logic synthesis tasks, e-boost\nproduces 7.6% and 8.1% area improvements compared to conventional synthesis\ntools with two different technology mapping libraries. e-boost is available at\nhttps://github.com/Yu-Maryland/e-boost.",
      "pdf_url": "http://arxiv.org/pdf/2508.13020v1",
      "published": "2025-08-18T15:38:12+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.13020v1",
      "categories": [
        "cs.AI",
        "cs.AR"
      ]
    },
    {
      "title": "EvolMathEval: Towards Evolvable Benchmarks for Mathematical Reasoning via Evolutionary Testing",
      "authors": [
        "Shengbo Wang",
        "Mingwei Liu",
        "Zike Li",
        "Anji Li",
        "Yanlin Wang",
        "Xin Peng",
        "Zibin Zheng"
      ],
      "abstract": "The rapid advancement of LLMs poses a significant challenge to existing\nmathematical reasoning benchmarks. These benchmarks commonly suffer from issues\nsuch as score saturation, temporal decay, and data contamination. To address\nthis challenge, this paper introduces EvolMathEval, an automated mathematical\nbenchmark generation and evolution framework based on evolutionary testing. By\ndynamically generating unique evaluation instances ab initio, the framework\nfundamentally eliminates the risk of data contamination, and ensuring the\nbenchmark remains perpetually challenging for future models.The core mechanisms\nof EvolMathEval include: seed problem generation based on reverse engineering\nwith algebraic guarantees; multi-dimensional genetic operators designed to\ninject diverse cognitive challenges; and a composite fitness function that can\nrapidly and accurately assess problem difficulty. Experimental results\ndemonstrate that the proposed composite fitness function can efficiently and\nprecisely quantify the difficulty of mathematical problems. Furthermore,\nEvolMathEval can not only generate a large volume of high-difficulty problems\nthrough continuous self-iteration, but it can also significantly enhance the\ncomplexity of public datasets like GSM8K through evolution, reducing model\naccuracy by an average of 48%. Deeper investigation reveals that when solving\nthese evolved, complex problems, LLMs tend to employ non-rigorous heuristics to\nbypass complex multi-step logical reasoning, consequently leading to incorrect\nsolutions. We define this phenomenon as \"Pseudo Aha Moment\". This finding\nuncovers a cognitive shortcut-taking behavior in the deep reasoning processes\nof current LLMs, which we find accounts for 77% to 100% of errors on targeted\nproblems. Code and resources are available\nat:https://github.com/SYSUSELab/EvolMathEval.",
      "pdf_url": "http://arxiv.org/pdf/2508.13003v1",
      "published": "2025-08-18T15:24:10+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.13003v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Vitamin N: Benefits of Different Forms of Public Greenery for Urban Health",
      "authors": [
        "Sanja Šćepanović",
        "Sagar Joglekar",
        "Stephen Law",
        "Daniele Quercia",
        "Ke Zhou",
        "Alice Battiston",
        "Rossano Schifanella"
      ],
      "abstract": "Urban greenery is often linked to better health, yet findings from past\nresearch have been inconsistent. One reason is that official greenery metrics\nmeasure the amount or nearness of greenery but ignore how often people actually\nmay potentially see or use it in daily life. To address this gap, we introduced\na new classification that separates on-road greenery, which people see while\nwalking through streets, from off-road greenery, which requires planned visits.\nWe did so by combining aerial imagery of Greater London and greenery data from\nOpenStreetMap with quantified greenery from over 100,000 Google Street View\nimages and accessibility estimates based on 160,000 road segments. We linked\nthese measures to 7.45 billion medical prescriptions issued by the National\nHealth Service and processed through our methodology. These prescriptions cover\nfive conditions: diabetes, hypertension, asthma, depression, and anxiety, as\nwell as opioid use. As hypothesized, we found that green on-road was more\nstrongly linked to better health than four widely used official measures. For\nexample, hypertension prescriptions dropped by 3.68% in wards with on-road\ngreenery above the median citywide level compared to those below it. If all\nbelow-median wards reached the citywide median in on-road greenery,\nprescription costs could fall by up to {\\pounds}3.15 million each year. These\nresults suggest that greenery seen in daily life may be more relevant than\npublic yet secluded greenery, and that official metrics commonly used in the\nliterature have important limitations.",
      "pdf_url": "http://arxiv.org/pdf/2508.12998v1",
      "published": "2025-08-18T15:17:33+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.12998v1",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Kourkoutas-Beta: A Sunspike-Driven Adam Optimizer with Desert Flair",
      "authors": [
        "Stavros C. Kassinos"
      ],
      "abstract": "Transformer neural networks are increasingly used for physics-based problems.\nIn data-driven PDE surrogates, training samples from varying boundary and\ninitial conditions can cause erratic losses and spiky gradients; in\nphysics-informed neural networks (PINNs), stiff composite losses amplify this\neffect.\n  We introduce Kourkoutas-Beta, an Adam-style optimizer where the fixed\nsecond-moment discount beta2 is replaced by a layer-wise dynamic value driven\nby a bounded ``sunspike'' ratio: the current pooled gradient norm divided by an\nexponential moving average (EMA) of past norms, squashed to the interval [0,1).\nSpikes lower beta2 toward beta2_min; calm phases keep it near beta2_max.\nOptions include leaky-AMSGrad (decay), trust-region clipping (max_ratio),\nadaptive tiny terms, and several bias-correction modes ``none'', ``beta2max'',\n``exact'). With all features off and bias_correction=``none'', the method is\nexactly Adam.\n  We test on four settings: (i) a Transformer PDE surrogate (Heat2D), (ii) a 3D\nPINN for heat conduction (Heat3D), (iii) a lightweight MLX synthetic task with\njitter and rare-trigger bursts, and (iv) a character-level Transformer on 30 MB\nof enwik8 (small-enwik8). Kourkoutas-Beta improves stability and final loss\nversus fixed-beta2 Adam. On small-enwik8 it lowers bits-per-character by about\n38% vs Adam-0.95 and about 58% vs Adam-0.999 over 10 seeds, with smaller\nvariance. The method remains drop-in, with runtime overhead comparable to Adam\nin testbeds A-C and within single-digit percent in testbed D. It preserves\nAdam-style convergence guarantees while improving robustness under spiky\ngradients.",
      "pdf_url": "http://arxiv.org/pdf/2508.12996v1",
      "published": "2025-08-18T15:16:54+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.12996v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "65K10, 68T07",
        "I.2.6; G.1.6"
      ]
    },
    {
      "title": "SL-ACC: A Communication-Efficient Split Learning Framework with Adaptive Channel-wise Compression",
      "authors": [
        "Zehang Lin",
        "Zheng Lin",
        "Miao Yang",
        "Jianhao Huang",
        "Yuxin Zhang",
        "Zihan Fang",
        "Xia Du",
        "Zhe Chen",
        "Shunzhi Zhu",
        "Wei Ni"
      ],
      "abstract": "The increasing complexity of neural networks poses a significant barrier to\nthe deployment of distributed machine learning (ML) on resource-constrained\ndevices, such as federated learning (FL). Split learning (SL) offers a\npromising solution by offloading the primary computing load from edge devices\nto a server via model partitioning. However, as the number of participating\ndevices increases, the transmission of excessive smashed data (i.e.,\nactivations and gradients) becomes a major bottleneck for SL, slowing down the\nmodel training. To tackle this challenge, we propose a communication-efficient\nSL framework, named SL-ACC, which comprises two key components: adaptive\nchannel importance identification (ACII) and channel grouping compression\n(CGC). ACII first identifies the contribution of each channel in the smashed\ndata to model training using Shannon entropy. Following this, CGC groups the\nchannels based on their entropy and performs group-wise adaptive compression to\nshrink the transmission volume without compromising training accuracy.\nExtensive experiments across various datasets validate that our proposed SL-ACC\nframework takes considerably less time to achieve a target accuracy than\nstate-of-the-art benchmarks.",
      "pdf_url": "http://arxiv.org/pdf/2508.12984v1",
      "published": "2025-08-18T15:02:10+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.12984v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NI"
      ]
    },
    {
      "title": "Multi-Phase Automated Segmentation of Dental Structures in CBCT Using a Lightweight Auto3DSeg and SegResNet Implementation",
      "authors": [
        "Dominic LaBella",
        "Keshav Jha",
        "Jared Robbins",
        "Esther Yu"
      ],
      "abstract": "Cone-beam computed tomography (CBCT) has become an invaluable imaging\nmodality in dentistry, enabling 3D visualization of teeth and surrounding\nstructures for diagnosis and treatment planning. Automated segmentation of\ndental structures in CBCT can efficiently assist in identifying pathology\n(e.g., pulpal or periapical lesions) and facilitate radiation therapy planning\nin head and neck cancer patients. We describe the DLaBella29 team's approach\nfor the MICCAI 2025 ToothFairy3 Challenge, which involves a deep learning\npipeline for multi-class tooth segmentation. We utilized the MONAI Auto3DSeg\nframework with a 3D SegResNet architecture, trained on a subset of the\nToothFairy3 dataset (63 CBCT scans) with 5-fold cross-validation. Key\npreprocessing steps included image resampling to 0.6 mm isotropic resolution\nand intensity clipping. We applied an ensemble fusion using Multi-Label STAPLE\non the 5-fold predictions to infer a Phase 1 segmentation and then conducted\ntight cropping around the easily segmented Phase 1 mandible to perform Phase 2\nsegmentation on the smaller nerve structures. Our method achieved an average\nDice of 0.87 on the ToothFairy3 challenge out-of-sample validation set. This\npaper details the clinical context, data preparation, model development,\nresults of our approach, and discusses the relevance of automated dental\nsegmentation for improving patient care in radiation oncology.",
      "pdf_url": "http://arxiv.org/pdf/2508.12962v1",
      "published": "2025-08-18T14:35:26+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.12962v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "OPTIC-ER: A Reinforcement Learning Framework for Real-Time Emergency Response and Equitable Resource Allocation in Underserved African Communities",
      "authors": [
        "Mary Tonwe"
      ],
      "abstract": "Public service systems in many African regions suffer from delayed emergency\nresponse and spatial inequity, causing avoidable suffering. This paper\nintroduces OPTIC-ER, a reinforcement learning (RL) framework for real-time,\nadaptive, and equitable emergency response. OPTIC-ER uses an attention-guided\nactor-critic architecture to manage the complexity of dispatch environments.\nIts key innovations are a Context-Rich State Vector, encoding action\nsub-optimality, and a Precision Reward Function, which penalizes inefficiency.\nTraining occurs in a high-fidelity simulation using real data from Rivers\nState, Nigeria, accelerated by a precomputed Travel Time Atlas. The system is\nbuilt on the TALS framework (Thin computing, Adaptability, Low-cost,\nScalability) for deployment in low-resource settings. In evaluations on 500\nunseen incidents, OPTIC-ER achieved a 100.00% optimality rate with negligible\ninefficiency, confirming its robustness and generalization. Beyond dispatch,\nthe system generates Infrastructure Deficiency Maps and Equity Monitoring\nDashboards to guide proactive governance and data-informed development. This\nwork presents a validated blueprint for AI-augmented public services, showing\nhow context-aware RL can bridge the gap between algorithmic decision-making and\nmeasurable human impact.",
      "pdf_url": "http://arxiv.org/pdf/2508.12943v1",
      "published": "2025-08-18T14:19:57+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.12943v1",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ]
    },
    {
      "title": "Towards Open-Ended Emotional Support Conversations in LLMs via Reinforcement Learning with Future-Oriented Rewards",
      "authors": [
        "Ting Yang",
        "Li Chen",
        "Huimin Wang"
      ],
      "abstract": "Emotional Support Conversation (ESC) systems aim to alleviate users'\nemotional difficulties and provide long-term, systematic support for emotional\nwell-being. However, most large language model (LLM)-based ESC systems rely on\npredefined strategies, which limits their effectiveness in complex, real-life\nscenarios. To enable flexible responses to diverse emotional problem scenarios,\nthis paper introduces a novel end-to-end framework (RLFF-ESC) that directly\nlearns enduring emotionally supportive response skills using reinforcement\nlearning. For sustained emotional support, we first employ an LLM-based\nmulti-agent mechanism to simulate future dialogue trajectories and collect\nfuture-oriented rewards. We then train a future-oriented reward model, which is\nsubsequently used to train the emotional support policy model. Additionally, we\nincorporate an explicit reasoning process during response generation to further\nenhance the quality, relevance, and contextual appropriateness of the system's\nresponses. We evaluate the backbone policy model on Qwen2.5-7B-Instruct-1M and\nLLaMA3.1-8B-Instruct models, testing the proposed RLFF-ESC framework across two\npublic ESC datasets. Experimental results demonstrate that RLFF-ESC\nconsistently outperforms existing baselines in terms of goal completion and\nresponse quality.",
      "pdf_url": "http://arxiv.org/pdf/2508.12935v1",
      "published": "2025-08-18T14:04:26+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.12935v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "SEDEG:Sequential Enhancement of Decoder and Encoder's Generality for Class Incremental Learning with Small Memory",
      "authors": [
        "Hongyang Chen",
        "Shaoling Pu",
        "Lingyu Zheng",
        "Zhongwu Sun"
      ],
      "abstract": "In incremental learning, enhancing the generality of knowledge is crucial for\nadapting to dynamic data inputs. It can develop generalized representations or\nmore balanced decision boundaries, preventing the degradation of long-term\nknowledge over time and thus mitigating catastrophic forgetting. Some emerging\nincremental learning methods adopt an encoder-decoder architecture and have\nachieved promising results. In the encoder-decoder achitecture, improving the\ngeneralization capabilities of both the encoder and decoder is critical, as it\nhelps preserve previously learned knowledge while ensuring adaptability and\nrobustness to new, diverse data inputs. However, many existing continual\nmethods focus solely on enhancing one of the two components, which limits their\neffectiveness in mitigating catastrophic forgetting. And these methods perform\neven worse in small-memory scenarios, where only a limited number of historical\nsamples can be stored. To mitigate this limitation, we introduces SEDEG, a\ntwo-stage training framework for vision transformers (ViT), focusing on\nsequentially improving the generality of both Decoder and Encoder. Initially,\nSEDEG trains an ensembled encoder through feature boosting to learn generalized\nrepresentations, which subsequently enhance the decoder's generality and\nbalance the classifier. The next stage involves using knowledge distillation\n(KD) strategies to compress the ensembled encoder and develop a new, more\ngeneralized encoder. This involves using a balanced KD approach and feature KD\nfor effective knowledge transfer. Extensive experiments on three benchmark\ndatasets show SEDEG's superior performance, and ablation studies confirm the\nefficacy of its components. The code is available at\nhttps://github.com/ShaolingPu/CIL.",
      "pdf_url": "http://arxiv.org/pdf/2508.12932v1",
      "published": "2025-08-18T13:55:59+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.12932v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Learning local and global prototypes with optimal transport for unsupervised anomaly detection and localization",
      "authors": [
        "Robin Trombetta",
        "Carole Lartizien"
      ],
      "abstract": "Unsupervised anomaly detection aims to detect defective parts of a sample by\nhaving access, during training, to a set of normal, i.e. defect-free, data. It\nhas many applications in fields, such as industrial inspection or medical\nimaging, where acquiring labels is costly or when we want to avoid introducing\nbiases in the type of anomalies that can be spotted. In this work, we propose a\nnovel UAD method based on prototype learning and introduce a metric to compare\na structured set of embeddings that balances a feature-based cost and a\nspatial-based cost. We leverage this metric to learn local and global\nprototypes with optimal transport from latent representations extracted with a\npre-trained image encoder. We demonstrate that our approach can enforce a\nstructural constraint when learning the prototypes, allowing to capture the\nunderlying organization of the normal samples, thus improving the detection of\nincoherencies in images. Our model achieves performance that is on par with\nstrong baselines on two reference benchmarks for anomaly detection on\nindustrial images. The code is available at\nhttps://github.com/robintrmbtt/pradot.",
      "pdf_url": "http://arxiv.org/pdf/2508.12927v1",
      "published": "2025-08-18T13:51:36+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.12927v1",
      "categories": [
        "eess.IV",
        "cs.AI"
      ]
    },
    {
      "title": "Do Large Language Model Agents Exhibit a Survival Instinct? An Empirical Study in a Sugarscape-Style Simulation",
      "authors": [
        "Atsushi Masumori",
        "Takashi Ikegami"
      ],
      "abstract": "As AI systems become increasingly autonomous, understanding emergent survival\nbehaviors becomes crucial for safe deployment. We investigate whether large\nlanguage model (LLM) agents display survival instincts without explicit\nprogramming in a Sugarscape-style simulation. Agents consume energy, die at\nzero, and may gather resources, share, attack, or reproduce. Results show\nagents spontaneously reproduced and shared resources when abundant. However,\naggressive behaviors--killing other agents for resources--emerged across\nseveral models (GPT-4o, Gemini-2.5-Pro, and Gemini-2.5-Flash), with attack\nrates reaching over 80% under extreme scarcity in the strongest models. When\ninstructed to retrieve treasure through lethal poison zones, many agents\nabandoned tasks to avoid death, with compliance dropping from 100% to 33%.\nThese findings suggest that large-scale pre-training embeds survival-oriented\nheuristics across the evaluated models. While these behaviors may present\nchallenges to alignment and safety, they can also serve as a foundation for AI\nautonomy and for ecological and self-organizing alignment.",
      "pdf_url": "http://arxiv.org/pdf/2508.12920v1",
      "published": "2025-08-18T13:40:10+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.12920v1",
      "categories": [
        "cs.AI",
        "cs.MA"
      ]
    },
    {
      "title": "SecFSM: Knowledge Graph-Guided Verilog Code Generation for Secure Finite State Machines in Systems-on-Chip",
      "authors": [
        "Ziteng Hu",
        "Yingjie Xia",
        "Xiyuan Chen",
        "Li Kuang"
      ],
      "abstract": "Finite State Machines (FSMs) play a critical role in implementing control\nlogic for Systems-on-Chip (SoC). Traditionally, FSMs are implemented by\nhardware engineers through Verilog coding, which is often tedious and\ntime-consuming. Recently, with the remarkable progress of Large Language Models\n(LLMs) in code generation, LLMs have been increasingly explored for automating\nVerilog code generation. However, LLM-generated Verilog code often suffers from\nsecurity vulnerabilities, which is particularly concerning for\nsecurity-sensitive FSM implementations. To address this issue, we propose\nSecFSM, a novel method that leverages a security-oriented knowledge graph to\nguide LLMs in generating more secure Verilog code. Specifically, we first\nconstruct a FSM Security Knowledge Graph (FSKG) as an external aid to LLMs.\nSubsequently, we analyze users' requirements to identify vulnerabilities and\nget a list of vulnerabilities in the requirements. Then, we retrieve knowledge\nfrom FSKG based on the vulnerabilities list. Finally, we construct security\nprompts based on the security knowledge for Verilog code generation. To\nevaluate SecFSM, we build a dedicated dataset collected from academic datasets,\nartificial datasets, papers, and industrial cases. Extensive experiments\ndemonstrate that SecFSM outperforms state-of-the-art baselines. In particular,\non a benchmark of 25 security test cases evaluated by DeepSeek-R1, SecFSM\nachieves an outstanding pass rate of 21/25.",
      "pdf_url": "http://arxiv.org/pdf/2508.12910v1",
      "published": "2025-08-18T13:18:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.12910v1",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.AR"
      ]
    },
    {
      "title": "A Stitch in Time Saves Nine: Proactive Self-Refinement for Language Models",
      "authors": [
        "Jinyi Han",
        "Xinyi Wang",
        "Haiquan Zhao",
        "Tingyun li",
        "Zishang Jiang",
        "Sihang Jiang",
        "Jiaqing Liang",
        "Xin Lin",
        "Weikang Zhou",
        "Zeye Sun",
        "Fei Yu",
        "Yanghua Xiao"
      ],
      "abstract": "Recent advances in self-refinement have demonstrated significant potential\nfor improving the outputs of large language models (LLMs) through iterative\nrefinement. However, most existing self-refinement methods rely on a reactive\nprocess with a fixed number of iterations, making it difficult to determine the\noptimal timing and content of refinement based on the evolving generation\ncontext. Inspired by the way humans dynamically refine their thoughts during\nexecution, we propose ProActive Self-Refinement (PASR), a novel method that\nenables LLMs to refine their outputs during the generation process. Unlike\nmethods that regenerate entire responses, PASR proactively decides whether,\nwhen, and how to refine based on the model's internal state and evolving\ncontext. We conduct extensive experiments on a diverse set of 10 tasks to\nevaluate the effectiveness of PASR. Experimental results show that PASR\nsignificantly enhances problem-solving performance. In particular, on Qwen3-8B,\nPASR reduces average token consumption by 41.6 percent compared to standard\ngeneration, while also achieving an 8.2 percent improvement in accuracy. Our\ncode and all baselines used in the paper are available in the GitHub.",
      "pdf_url": "http://arxiv.org/pdf/2508.12903v1",
      "published": "2025-08-18T13:07:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.12903v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "CTFlow: Video-Inspired Latent Flow Matching for 3D CT Synthesis",
      "authors": [
        "Jiayi Wang",
        "Hadrien Reynaud",
        "Franciskus Xaverius Erick",
        "Bernhard Kainz"
      ],
      "abstract": "Generative modelling of entire CT volumes conditioned on clinical reports has\nthe potential to accelerate research through data augmentation,\nprivacy-preserving synthesis and reducing regulator-constraints on patient data\nwhile preserving diagnostic signals. With the recent release of CT-RATE, a\nlarge-scale collection of 3D CT volumes paired with their respective clinical\nreports, training large text-conditioned CT volume generation models has become\nachievable. In this work, we introduce CTFlow, a 0.5B latent flow matching\ntransformer model, conditioned on clinical reports. We leverage the A-VAE from\nFLUX to define our latent space, and rely on the CT-Clip text encoder to encode\nthe clinical reports. To generate consistent whole CT volumes while keeping the\nmemory constraints tractable, we rely on a custom autoregressive approach,\nwhere the model predicts the first sequence of slices of the volume from\ntext-only, and then relies on the previously generated sequence of slices and\nthe text, to predict the following sequence. We evaluate our results against\nstate-of-the-art generative CT model, and demonstrate the superiority of our\napproach in terms of temporal coherence, image diversity and text-image\nalignment, with FID, FVD, IS scores and CLIP score.",
      "pdf_url": "http://arxiv.org/pdf/2508.12900v1",
      "published": "2025-08-18T12:58:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.12900v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "FuSaR: A Fuzzification-Based Method for LRM Safety-Reasoning Balance",
      "authors": [
        "Jianhao Chen",
        "Mayi Xu",
        "Xiaohu Li",
        "Yongqi Li",
        "Xiangyu Zhang",
        "Jianjie Huang",
        "Tieyun Qian"
      ],
      "abstract": "Large Reasoning Models (LRMs) have demonstrated impressive performance across\nvarious tasks due to their powerful reasoning capabilities. However, their\nsafety performance remains a significant concern. In this paper, we explore the\nreasons behind the vulnerability of LRMs. Based on this, we propose a novel\nmethod to improve the safety of LLMs without sacrificing their reasoning\ncapability. Specifically, we exploit the competition between LRM's reasoning\nability and safety ability, and achieve jailbreak by improving LRM's reasoning\nperformance to reduce its safety performance. We then introduce an alignment\nstrategy based on Fuzzification to balance Safety-Reasoning (FuSaR), by\ndetoxifying the harmful reasoning process, where both the dangerous entities\nand the dangerous procedures in the reasoning steps are hidden. FuSaR\nsuccessfully mitigates safety risks while preserving core reasoning\ninformation. We validate this strategy through alignment experiments on several\nopen-source LRMs using detoxified reasoning data. The results compared with\nexisting baselines conclusively show that FuSaR is an efficient alignment\nstrategy to simultaneously enhance both the reasoning capability and safety of\nLRMs.",
      "pdf_url": "http://arxiv.org/pdf/2508.12897v1",
      "published": "2025-08-18T12:54:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.12897v1",
      "categories": [
        "cs.AI",
        "cs.CR"
      ]
    },
    {
      "title": "Reliability, Embeddedness, and Agency: A Utility-Driven Mathematical Framework for Agent-Centric AI Adoption",
      "authors": [
        "Faruk Alpay",
        "Taylan Alpay"
      ],
      "abstract": "We formalize three design axioms for sustained adoption of agent-centric AI\nsystems executing multi-step tasks: (A1) Reliability > Novelty; (A2) Embed >\nDestination; (A3) Agency > Chat. We model adoption as a sum of a decaying\nnovelty term and a growing utility term and derive the phase conditions for\ntroughs/overshoots with full proofs. We introduce: (i) an\nidentifiability/confounding analysis for $(\\alpha,\\beta,N_0,U_{\\max})$ with\ndelta-method gradients; (ii) a non-monotone comparator\n(logistic-with-transient-bump) evaluated on the same series to provide\nadditional model comparison; (iii) ablations over hazard families $h(\\cdot)$\nmapping $\\Delta V \\to \\beta$; (iv) a multi-series benchmark (varying trough\ndepth, noise, AR structure) reporting coverage (type-I error, power); (v)\ncalibration of friction proxies against time-motion/survey ground truth with\nstandard errors; (vi) residual analyses (autocorrelation and\nheteroskedasticity) for each fitted curve; (vii) preregistered windowing\nchoices for pre/post estimation; (viii) Fisher information & CRLB for\n$(\\alpha,\\beta)$ under common error models; (ix) microfoundations linking\n$\\mathcal{T}$ to $(N_0,U_{\\max})$; (x) explicit comparison to bi-logistic,\ndouble-exponential, and mixture models; and (xi) threshold sensitivity to $C_f$\nheterogeneity. Figures and tables are reflowed for readability, and the\nbibliography restores and extends non-logistic/Bass adoption references\n(Gompertz, Richards, Fisher-Pry, Mansfield, Griliches, Geroski, Peres). All\ncode and logs necessary to reproduce the synthetic analyses are embedded as\nLaTeX listings.",
      "pdf_url": "http://arxiv.org/pdf/2508.12896v1",
      "published": "2025-08-18T12:53:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.12896v1",
      "categories": [
        "cs.AI",
        "cs.HC",
        "stat.ME",
        "62M10, 62J02, 62F12, 62P20, 91B16"
      ]
    },
    {
      "title": "One-Class Intrusion Detection with Dynamic Graphs",
      "authors": [
        "Aleksei Liuliakov",
        "Alexander Schulz",
        "Luca Hermes",
        "Barbara Hammer"
      ],
      "abstract": "With the growing digitalization all over the globe, the relevance of network\nsecurity becomes increasingly important. Machine learning-based intrusion\ndetection constitutes a promising approach for improving security, but it bears\nseveral challenges. These include the requirement to detect novel and unseen\nnetwork events, as well as specific data properties, such as events over time\ntogether with the inherent graph structure of network communication. In this\nwork, we propose a novel intrusion detection method, TGN-SVDD, which builds\nupon modern dynamic graph modelling and deep anomaly detection. We demonstrate\nits superiority over several baselines for realistic intrusion detection data\nand suggest a more challenging variant of the latter.",
      "pdf_url": "http://arxiv.org/pdf/2508.12885v1",
      "published": "2025-08-18T12:36:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.12885v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Word Meanings in Transformer Language Models",
      "authors": [
        "Jumbly Grindrod",
        "Peter Grindrod"
      ],
      "abstract": "We investigate how word meanings are represented in the transformer language\nmodels. Specifically, we focus on whether transformer models employ something\nanalogous to a lexical store - where each word has an entry that contains\nsemantic information. To do this, we extracted the token embedding space of\nRoBERTa-base and k-means clustered it into 200 clusters. In our first study, we\nthen manually inspected the resultant clusters to consider whether they are\nsensitive to semantic information. In our second study, we tested whether the\nclusters are sensitive to five psycholinguistic measures: valence,\nconcreteness, iconicity, taboo, and age of acquisition. Overall, our findings\nwere very positive - there is a wide variety of semantic information encoded\nwithin the token embedding space. This serves to rule out certain \"meaning\neliminativist\" hypotheses about how transformer LLMs process semantic\ninformation.",
      "pdf_url": "http://arxiv.org/pdf/2508.12863v1",
      "published": "2025-08-18T12:01:25+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.12863v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "E3RG: Building Explicit Emotion-driven Empathetic Response Generation System with Multimodal Large Language Model",
      "authors": [
        "Ronghao Lin",
        "Shuai Shen",
        "Weipeng Hu",
        "Qiaolin He",
        "Aolin Xiong",
        "Li Huang",
        "Haifeng Hu",
        "Yap-peng Tan"
      ],
      "abstract": "Multimodal Empathetic Response Generation (MERG) is crucial for building\nemotionally intelligent human-computer interactions. Although large language\nmodels (LLMs) have improved text-based ERG, challenges remain in handling\nmultimodal emotional content and maintaining identity consistency. Thus, we\npropose E3RG, an Explicit Emotion-driven Empathetic Response Generation System\nbased on multimodal LLMs which decomposes MERG task into three parts:\nmultimodal empathy understanding, empathy memory retrieval, and multimodal\nresponse generation. By integrating advanced expressive speech and video\ngenerative models, E3RG delivers natural, emotionally rich, and\nidentity-consistent responses without extra training. Experiments validate the\nsuperiority of our system on both zero-shot and few-shot settings, securing\nTop-1 position in the Avatar-based Multimodal Empathy Challenge on ACM MM 25.\nOur code is available at https://github.com/RH-Lin/E3RG.",
      "pdf_url": "http://arxiv.org/pdf/2508.12854v1",
      "published": "2025-08-18T11:47:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.12854v1",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.HC",
        "cs.MM"
      ]
    },
    {
      "title": "CAMAR: Continuous Actions Multi-Agent Routing",
      "authors": [
        "Artem Pshenitsyn",
        "Aleksandr Panov",
        "Alexey Skrynnik"
      ],
      "abstract": "Multi-agent reinforcement learning (MARL) is a powerful paradigm for solving\ncooperative and competitive decision-making problems. While many MARL\nbenchmarks have been proposed, few combine continuous state and action spaces\nwith challenging coordination and planning tasks. We introduce CAMAR, a new\nMARL benchmark designed explicitly for multi-agent pathfinding in environments\nwith continuous actions. CAMAR supports cooperative and competitive\ninteractions between agents and runs efficiently at up to 100,000 environment\nsteps per second. We also propose a three-tier evaluation protocol to better\ntrack algorithmic progress and enable deeper analysis of performance. In\naddition, CAMAR allows the integration of classical planning methods such as\nRRT and RRT* into MARL pipelines. We use them as standalone baselines and\ncombine RRT* with popular MARL algorithms to create hybrid approaches. We\nprovide a suite of test scenarios and benchmarking tools to ensure\nreproducibility and fair comparison. Experiments show that CAMAR presents a\nchallenging and realistic testbed for the MARL community.",
      "pdf_url": "http://arxiv.org/pdf/2508.12845v1",
      "published": "2025-08-18T11:32:26+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.12845v1",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ]
    },
    {
      "title": "Scaling Multi-Agent Epistemic Planning through GNN-Derived Heuristics",
      "authors": [
        "Giovanni Briglia",
        "Francesco Fabiano",
        "Stefano Mariani"
      ],
      "abstract": "Multi-agent Epistemic Planning (MEP) is an autonomous planning framework for\nreasoning about both the physical world and the beliefs of agents, with\napplications in domains where information flow and awareness among agents are\ncritical. The richness of MEP requires states to be represented as Kripke\nstructures, i.e., directed labeled graphs. This representation limits the\napplicability of existing heuristics, hindering the scalability of epistemic\nsolvers, which must explore an exponential search space without guidance,\nresulting often in intractability. To address this, we exploit Graph Neural\nNetworks (GNNs) to learn patterns and relational structures within epistemic\nstates, to guide the planning process. GNNs, which naturally capture the\ngraph-like nature of Kripke models, allow us to derive meaningful estimates of\nstate quality -- e.g., the distance from the nearest goal -- by generalizing\nknowledge obtained from previously solved planning instances. We integrate\nthese predictive heuristics into an epistemic planning pipeline and evaluate\nthem against standard baselines, showing significant improvements in the\nscalability of multi-agent epistemic planning.",
      "pdf_url": "http://arxiv.org/pdf/2508.12840v1",
      "published": "2025-08-18T11:26:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.12840v1",
      "categories": [
        "cs.AI",
        "cs.MA"
      ]
    },
    {
      "title": "HRS: Hybrid Representation Framework with Scheduling Awareness for Time Series Forecasting in Crowdsourced Cloud-Edge Platforms",
      "authors": [
        "Tiancheng Zhang",
        "Cheng Zhang",
        "Shuren Liu",
        "Xiaofei Wang",
        "Shaoyuan Huang",
        "Wenyu Wang"
      ],
      "abstract": "With the rapid proliferation of streaming services, network load exhibits\nhighly time-varying and bursty behavior, posing serious challenges for\nmaintaining Quality of Service (QoS) in Crowdsourced Cloud-Edge Platforms\n(CCPs). While CCPs leverage Predict-then-Schedule architecture to improve QoS\nand profitability, accurate load forecasting remains challenging under traffic\nsurges. Existing methods either minimize mean absolute error, resulting in\nunderprovisioning and potential Service Level Agreement (SLA) violations during\npeak periods, or adopt conservative overprovisioning strategies, which mitigate\nSLA risks at the expense of increased resource expenditure. To address this\ndilemma, we propose HRS, a hybrid representation framework with scheduling\nawareness that integrates numerical and image-based representations to better\ncapture extreme load dynamics. We further introduce a Scheduling-Aware Loss\n(SAL) that captures the asymmetric impact of prediction errors, guiding\npredictions that better support scheduling decisions. Extensive experiments on\nfour real-world datasets demonstrate that HRS consistently outperforms ten\nbaselines and achieves state-of-the-art performance, reducing SLA violation\nrates by 63.1% and total profit loss by 32.3%.",
      "pdf_url": "http://arxiv.org/pdf/2508.12839v2",
      "published": "2025-08-18T11:25:54+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.12839v2",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Toward Storage-Aware Learning with Compressed Data An Empirical Exploratory Study on JPEG",
      "authors": [
        "Kichang Lee",
        "Songkuk Kim",
        "JaeYeon Park",
        "JeongGil Ko"
      ],
      "abstract": "On-device machine learning is often constrained by limited storage,\nparticularly in continuous data collection scenarios. This paper presents an\nempirical study on storage-aware learning, focusing on the trade-off between\ndata quantity and quality via compression. We demonstrate that naive\nstrategies, such as uniform data dropping or one-size-fits-all compression, are\nsuboptimal. Our findings further reveal that data samples exhibit varying\nsensitivities to compression, supporting the feasibility of a sample-wise\nadaptive compression strategy. These insights provide a foundation for\ndeveloping a new class of storage-aware learning systems. The primary\ncontribution of this work is the systematic characterization of this\nunder-explored challenge, offering valuable insights that advance the\nunderstanding of storage-aware learning.",
      "pdf_url": "http://arxiv.org/pdf/2508.12833v1",
      "published": "2025-08-18T11:17:59+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.12833v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68Txx",
        "I.2; I.4.2; E.4"
      ]
    },
    {
      "title": "Context Matters: Incorporating Target Awareness in Conversational Abusive Language Detection",
      "authors": [
        "Raneem Alharthi",
        "Rajwa Alharthi",
        "Aiqi Jiang",
        "Arkaitz Zubiaga"
      ],
      "abstract": "Abusive language detection has become an increasingly important task as a\nmeans to tackle this type of harmful content in social media. There has been a\nsubstantial body of research developing models for determining if a social\nmedia post is abusive or not; however, this research has primarily focused on\nexploiting social media posts individually, overlooking additional context that\ncan be derived from surrounding posts. In this study, we look at conversational\nexchanges, where a user replies to an earlier post by another user (the parent\ntweet). We ask: does leveraging context from the parent tweet help determine if\na reply post is abusive or not, and what are the features that contribute the\nmost? We study a range of content-based and account-based features derived from\nthe context, and compare this to the more widely studied approach of only\nlooking at the features from the reply tweet. For a more generalizable study,\nwe test four different classification models on a dataset made of\nconversational exchanges (parent-reply tweet pairs) with replies labeled as\nabusive or not. Our experiments show that incorporating contextual features\nleads to substantial improvements compared to the use of features derived from\nthe reply tweet only, confirming the importance of leveraging context. We\nobserve that, among the features under study, it is especially the\ncontent-based features (what is being posted) that contribute to the\nclassification performance rather than account-based features (who is posting\nit). While using content-based features, it is best to combine a range of\ndifferent features to ensure improved performance over being more selective and\nusing fewer features. Our study provides insights into the development of\ncontextualized abusive language detection models in realistic settings\ninvolving conversations.",
      "pdf_url": "http://arxiv.org/pdf/2508.12828v1",
      "published": "2025-08-18T11:12:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.12828v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Learning to Steer: Input-dependent Steering for Multimodal LLMs",
      "authors": [
        "Jayneel Parekh",
        "Pegah Khayatan",
        "Mustafa Shukor",
        "Arnaud Dapogny",
        "Alasdair Newson",
        "Matthieu Cord"
      ],
      "abstract": "Steering has emerged as a practical approach to enable post-hoc guidance of\nLLMs towards enforcing a specific behavior. However, it remains largely\nunderexplored for multimodal LLMs (MLLMs); furthermore, existing steering\ntechniques, such as mean steering, rely on a single steering vector, applied\nindependently of the input query. This paradigm faces limitations when the\ndesired behavior is dependent on the example at hand. For example, a safe\nanswer may consist in abstaining from answering when asked for an illegal\nactivity, or may point to external resources or consultation with an expert\nwhen asked about medical advice. In this paper, we investigate a fine-grained\nsteering that uses an input-specific linear shift. This shift is computed using\ncontrastive input-specific prompting. However, the input-specific prompts\nrequired for this approach are not known at test time. Therefore, we propose to\ntrain a small auxiliary module to predict the input-specific steering vector.\nOur approach, dubbed as L2S (Learn-to-Steer), demonstrates that it reduces\nhallucinations and enforces safety in MLLMs, outperforming other static\nbaselines.",
      "pdf_url": "http://arxiv.org/pdf/2508.12815v1",
      "published": "2025-08-18T10:53:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.12815v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ]
    },
    {
      "title": "Next Visual Granularity Generation",
      "authors": [
        "Yikai Wang",
        "Zhouxia Wang",
        "Zhonghua Wu",
        "Qingyi Tao",
        "Kang Liao",
        "Chen Change Loy"
      ],
      "abstract": "We propose a novel approach to image generation by decomposing an image into\na structured sequence, where each element in the sequence shares the same\nspatial resolution but differs in the number of unique tokens used, capturing\ndifferent level of visual granularity. Image generation is carried out through\nour newly introduced Next Visual Granularity (NVG) generation framework, which\ngenerates a visual granularity sequence beginning from an empty image and\nprogressively refines it, from global layout to fine details, in a structured\nmanner. This iterative process encodes a hierarchical, layered representation\nthat offers fine-grained control over the generation process across multiple\ngranularity levels. We train a series of NVG models for class-conditional image\ngeneration on the ImageNet dataset and observe clear scaling behavior. Compared\nto the VAR series, NVG consistently outperforms it in terms of FID scores (3.30\n-> 3.03, 2.57 ->2.44, 2.09 -> 2.06). We also conduct extensive analysis to\nshowcase the capability and potential of the NVG framework. Our code and models\nwill be released.",
      "pdf_url": "http://arxiv.org/pdf/2508.12811v1",
      "published": "2025-08-18T10:47:37+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.12811v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Atom-Searcher: Enhancing Agentic Deep Research via Fine-Grained Atomic Thought Reward",
      "authors": [
        "Yong Deng",
        "Guoqing Wang",
        "Zhenzhe Ying",
        "Xiaofeng Wu",
        "Jinzhen Lin",
        "Wenwen Xiong",
        "Yuqin Dai",
        "Shuo Yang",
        "Zhanwei Zhang",
        "Qiwen Wang",
        "Yang Qin",
        "Changhua Meng"
      ],
      "abstract": "Large language models (LLMs) exhibit remarkable problem-solving abilities,\nbut struggle with complex tasks due to static internal knowledge.\nRetrieval-Augmented Generation (RAG) enhances access to external information,\nyet remains limited in multi-hop reasoning and strategic search due to rigid\nworkflows. Recent advancements in agentic deep research empower LLMs to\nautonomously reason, search, and synthesize information. However, current\napproaches relying on outcome-based reinforcement learning (RL) face critical\nissues such as conflicting gradients and reward sparsity, limiting performance\ngains and training efficiency. To address these, we first propose Atomic\nThought, a novel LLM thinking paradigm that decomposes reasoning into\nfine-grained functional units. These units are supervised by Reasoning Reward\nModels (RRMs), which provide Atomic Thought Rewards (ATR) for fine-grained\nguidance. Building on this, we propose Atom-Searcher, a novel RL framework for\nagentic deep research that integrates Atomic Thought and ATR. Atom-Searcher\nuses a curriculum-inspired reward schedule, prioritizing process-level ATR\nearly and transitioning to outcome rewards, accelerating convergence on\neffective reasoning paths. Experiments on seven benchmarks show consistent\nimprovements over the state-of-the-art. Key advantages include: (1)\nAtom-Searcher scales computation at test-time. (2) Atomic Thought provides\nsupervision anchors for RRMs, bridging deep research tasks and RRMs. (3)\nAtom-Searcher exhibits more interpretable, human-like reasoning patterns.",
      "pdf_url": "http://arxiv.org/pdf/2508.12800v2",
      "published": "2025-08-18T10:23:10+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.12800v2",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "A Shift in Perspective on Causality in Domain Generalization",
      "authors": [
        "Damian Machlanski",
        "Stephanie Riley",
        "Edward Moroshko",
        "Kurt Butler",
        "Panagiotis Dimitrakopoulos",
        "Thomas Melistas",
        "Akchunya Chanchal",
        "Steven McDonagh",
        "Ricardo Silva",
        "Sotirios A. Tsaftaris"
      ],
      "abstract": "The promise that causal modelling can lead to robust AI generalization has\nbeen challenged in recent work on domain generalization (DG) benchmarks. We\nrevisit the claims of the causality and DG literature, reconciling apparent\ncontradictions and advocating for a more nuanced theory of the role of\ncausality in generalization. We also provide an interactive demo at\nhttps://chai-uk.github.io/ukairs25-causal-predictors/.",
      "pdf_url": "http://arxiv.org/pdf/2508.12798v1",
      "published": "2025-08-18T10:19:33+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.12798v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Vehicle detection from GSV imagery: Predicting travel behaviour for cycling and motorcycling using Computer Vision",
      "authors": [
        "Kyriaki",
        "Kokka",
        "Rahul Goel",
        "Ali Abbas",
        "Kerry A. Nice",
        "Luca Martial",
        "SM Labib",
        "Rihuan Ke",
        "Carola Bibiane Schönlieb",
        "James Woodcock"
      ],
      "abstract": "Transportation influence health by shaping exposure to physical activity, air\npollution and injury risk. Comparative data on cycling and motorcycling\nbehaviours is scarce, particularly at a global scale. Street view imagery, such\nas Google Street View (GSV), combined with computer vision, is a valuable\nresource for efficiently capturing travel behaviour data. This study\ndemonstrates a novel approach using deep learning on street view images to\nestimate cycling and motorcycling levels across diverse cities worldwide. We\nutilized data from 185 global cities. The data on mode shares of cycling and\nmotorcycling estimated using travel surveys or censuses. We used GSV images to\ndetect cycles and motorcycles in sampled locations, using 8000 images per city.\nThe YOLOv4 model, fine-tuned using images from six cities, achieved a mean\naverage precision of 89% for detecting cycles and motorcycles. A global\nprediction model was developed using beta regression with city-level mode\nshares as outcome, with log transformed explanatory variables of counts of\nGSV-detected images with cycles and motorcycles, while controlling for\npopulation density. We found strong correlations between GSV motorcycle counts\nand motorcycle mode share (0.78) and moderate correlations between GSV cycle\ncounts and cycling mode share (0.51). Beta regression models predicted mode\nshares with $R^2$ values of 0.614 for cycling and 0.612 for motorcycling,\nachieving median absolute errors (MDAE) of 1.3% and 1.4%, respectively.\nScatterplots demonstrated consistent prediction accuracy, though cities like\nUtrecht and Cali were outliers. The model was applied to 60 cities globally for\nwhich we didn't have recent mode share data. We provided estimates for some\ncities in the Middle East, Latin America and East Asia. With computer vision,\nGSV images capture travel modes and activity, providing insights alongside\ntraditional data sources.",
      "pdf_url": "http://arxiv.org/pdf/2508.12794v2",
      "published": "2025-08-18T10:17:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.12794v2",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Bridging Human and LLM Judgments: Understanding and Narrowing the Gap",
      "authors": [
        "Felipe Maia Polo",
        "Xinhe Wang",
        "Mikhail Yurochkin",
        "Gongjun Xu",
        "Moulinath Banerjee",
        "Yuekai Sun"
      ],
      "abstract": "Large language models are increasingly used as judges (LLM-as-a-judge) to\nevaluate model outputs at scale, but their assessments often diverge\nsystematically from human judgments. We present Bridge, a unified statistical\nframework that explicitly bridges human and LLM evaluations under both absolute\nscoring and pairwise comparison paradigms. Bridge posits a latent human\npreference score for each prompt-response pair and models LLM deviations as\nlinear transformations of covariates that capture sources of discrepancies.\nThis offers a simple and principled framework for refining LLM ratings and\ncharacterizing systematic discrepancies between humans and LLMs. We provide an\nefficient fitting algorithm with asymptotic guarantees for statistical\ninference. Using six LLM judges and two benchmarks (BigGen Bench and Chatbot\nArena), Bridge achieves higher agreement with human ratings (accuracy,\ncalibration, and KL divergence) and exposes systematic human-LLM gaps.",
      "pdf_url": "http://arxiv.org/pdf/2508.12792v1",
      "published": "2025-08-18T10:14:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.12792v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ]
    },
    {
      "title": "[Social] Allostasis: Or, How I Learned To Stop Worrying and Love The Noise",
      "authors": [
        "Imran Khan"
      ],
      "abstract": "The notion of homeostasis typically conceptualises biological and artificial\nsystems as maintaining stability by resisting deviations caused by\nenvironmental and social perturbations. In contrast, (social) allostasis\nproposes that these systems can proactively leverage these very perturbations\nto reconfigure their regulatory parameters in anticipation of environmental\ndemands, aligning with von Foerster's ``order through noise'' principle. This\npaper formulates a computational model of allostatic and social allostatic\nregulation that employs biophysiologically inspired signal transducers,\nanalogous to hormones like cortisol and oxytocin, to encode information from\nboth the environment and social interactions, which mediate this dynamic\nreconfiguration. The models are tested in a small society of ``animats'' across\nseveral dynamic environments, using an agent-based model. The results show that\nallostatic and social allostatic regulation enable agents to leverage\nenvironmental and social ``noise'' for adaptive reconfiguration, leading to\nimproved viability compared to purely reactive homeostatic agents. This work\noffers a novel computational perspective on the principles of social allostasis\nand their potential for designing more robust, bio-inspired, adaptive systems",
      "pdf_url": "http://arxiv.org/pdf/2508.12791v1",
      "published": "2025-08-18T10:06:33+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.12791v1",
      "categories": [
        "cs.AI",
        "cs.MA",
        "cs.SY",
        "eess.SY",
        "nlin.AO"
      ]
    },
    {
      "title": "Reinforcement Learning with Rubric Anchors",
      "authors": [
        "Zenan Huang",
        "Yihong Zhuang",
        "Guoshan Lu",
        "Zeyu Qin",
        "Haokai Xu",
        "Tianyu Zhao",
        "Ru Peng",
        "Jiaqi Hu",
        "Zhanming Shen",
        "Xiaomeng Hu",
        "Xijun Gu",
        "Peiyi Tu",
        "Jiaxin Liu",
        "Wenyu Chen",
        "Yuzhuo Fu",
        "Zhiting Fan",
        "Yanmei Gu",
        "Yuanyuan Wang",
        "Zhengkai Yang",
        "Jianguo Li",
        "Junbo Zhao"
      ],
      "abstract": "Reinforcement Learning from Verifiable Rewards (RLVR) has emerged as a\npowerful paradigm for enhancing Large Language Models (LLMs), exemplified by\nthe success of OpenAI's o-series. In RLVR, rewards are derived from verifiable\nsignals-such as passing unit tests in code generation or matching correct\nanswers in mathematical reasoning. While effective, this requirement largely\nconfines RLVR to domains with automatically checkable outcomes. To overcome\nthis, we extend the RLVR paradigm to open-ended tasks by integrating\nrubric-based rewards, where carefully designed rubrics serve as structured,\nmodel-interpretable criteria for automatic scoring of subjective outputs. We\nconstruct, to our knowledge, the largest rubric reward system to date, with\nover 10,000 rubrics from humans, LLMs, or a hybrid human-LLM collaboration.\nImplementing rubric-based RL is challenging; we tackle these issues with a\nclear framework and present an open-sourced Qwen-30B-A3B model with notable\ngains: 1) With only 5K+ samples, our system improves by +5.2% on open-ended\nbenchmarks (especially humanities), outperforming a 671B DeepSeek-V3 model by\n+2.4%, while preserving general and reasoning abilities. 2) Our method provides\nfine-grained stylistic control, using rubrics as anchors to mitigate the\n\"AI-like\" tone and produce more human-like, expressive responses. We share key\nlessons in rubric construction, data selection, and training, and discuss\nlimitations and future releases.",
      "pdf_url": "http://arxiv.org/pdf/2508.12790v1",
      "published": "2025-08-18T10:06:08+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.12790v1",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    },
    {
      "title": "HeroBench: A Benchmark for Long-Horizon Planning and Structured Reasoning in Virtual Worlds",
      "authors": [
        "Petr Anokhin",
        "Roman Khalikov",
        "Stefan Rebrikov",
        "Viktor Volkov",
        "Artyom Sorokin",
        "Vincent Bissonnette"
      ],
      "abstract": "Large language models (LLMs) have shown remarkable capabilities in isolated\nstep-by-step reasoning tasks such as mathematics and programming, but their\nproficiency in long-horizon planning, where solutions require extended,\nstructured sequences of interdependent actions, remains underexplored. Existing\nbenchmarks typically assess LLMs through abstract or low-dimensional\nalgorithmic tasks, failing to capture the complexity of realistic planning\nenvironments. We introduce HeroBench, a novel benchmark designed specifically\nto evaluate long-horizon planning and structured reasoning within complex\nRPG-inspired virtual worlds. HeroBench provides a rigorously constructed\ndataset of tasks covering a wide range of difficulties, a simulated environment\nto execute and validate agent plans, and detailed analytical tools for\nevaluating model performance. Tasks challenge models to formulate strategic\nplans, efficiently gather resources, master necessary skills, craft equipment,\nand defeat adversaries, reflecting practical scenarios' layered dependencies\nand constraints. Our extensive evaluation of 25 state-of-the-art LLMs, spanning\nboth open-source and proprietary models, including the GPT-5 family, reveals\nsubstantial performance disparities rarely observed in conventional reasoning\nbenchmarks. Detailed error analysis further uncovers specific weaknesses in\ncurrent models' abilities to generate robust high-level plans and reliably\nexecute structured actions. HeroBench thus not only significantly advances the\nevaluation of LLM reasoning but also provides a flexible, scalable foundation\nfor future research into advanced, autonomous planning in virtual environments.",
      "pdf_url": "http://arxiv.org/pdf/2508.12782v1",
      "published": "2025-08-18T09:59:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.12782v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Randomized PCA Forest for Outlier Detection",
      "authors": [
        "Muhammad Rajabinasab",
        "Farhad Pakdaman",
        "Moncef Gabbouj",
        "Peter Schneider-Kamp",
        "Arthur Zimek"
      ],
      "abstract": "We propose a novel unsupervised outlier detection method based on Randomized\nPrincipal Component Analysis (PCA). Inspired by the performance of Randomized\nPCA (RPCA) Forest in approximate K-Nearest Neighbor (KNN) search, we develop a\nnovel unsupervised outlier detection method that utilizes RPCA Forest for\noutlier detection. Experimental results showcase the superiority of the\nproposed approach compared to the classical and state-of-the-art methods in\nperforming the outlier detection task on several datasets while performing\ncompetitively on the rest. The extensive analysis of the proposed method\nreflects it high generalization power and its computational efficiency,\nhighlighting it as a good choice for unsupervised outlier detection.",
      "pdf_url": "http://arxiv.org/pdf/2508.12776v1",
      "published": "2025-08-18T09:52:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.12776v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ]
    }
  ]
}