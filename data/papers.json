{
  "last_updated": "2025-08-16T00:51:51.898287",
  "papers": [
    {
      "title": "Empirical Investigation into Configuring Echo State Networks for Representative Benchmark Problem Domains",
      "authors": [
        "Brooke R. Weborg",
        "Gursel Serpen"
      ],
      "abstract": "This paper examines Echo State Network, a reservoir computer, performance\nusing four different benchmark problems, then proposes heuristics or rules of\nthumb for configuring the architecture, as well as the selection of parameters\nand their values, which are applicable to problems within the same domain, to\nhelp serve to fill the experience gap needed by those entering this field of\nstudy. The influence of various parameter selections and their value\nadjustments, as well as architectural changes made to an Echo State Network, a\npowerful recurrent neural network configured as a reservoir computer, can be\nchallenging to fully comprehend without experience in the field, and even some\nhyperparameter optimization algorithms may have difficulty adjusting parameter\nvalues without proper manual selections made first. Therefore, it is imperative\nto understand the effects of parameters and their value selection on Echo State\nNetwork architecture performance for a successful build. Thus, to address the\nrequirement for an extensive background in Echo State Network architecture, as\nwell as examine how Echo State Network performance is affected with respect to\nvariations in architecture, design, and parameter selection and values, a\nseries of benchmark tasks representing different problem domains, including\ntime series prediction, pattern generation, chaotic system prediction, and time\nseries classification, were modeled and experimented on to show the impact on\nthe performance of Echo State Network.",
      "pdf_url": "http://arxiv.org/pdf/2508.10887v1",
      "published": "2025-08-14T17:55:47+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.10887v1",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "ToonComposer: Streamlining Cartoon Production with Generative Post-Keyframing",
      "authors": [
        "Lingen Li",
        "Guangzhi Wang",
        "Zhaoyang Zhang",
        "Yaowei Li",
        "Xiaoyu Li",
        "Qi Dou",
        "Jinwei Gu",
        "Tianfan Xue",
        "Ying Shan"
      ],
      "abstract": "Traditional cartoon and anime production involves keyframing, inbetweening,\nand colorization stages, which require intensive manual effort. Despite recent\nadvances in AI, existing methods often handle these stages separately, leading\nto error accumulation and artifacts. For instance, inbetweening approaches\nstruggle with large motions, while colorization methods require dense per-frame\nsketches. To address this, we introduce ToonComposer, a generative model that\nunifies inbetweening and colorization into a single post-keyframing stage.\nToonComposer employs a sparse sketch injection mechanism to provide precise\ncontrol using keyframe sketches. Additionally, it uses a cartoon adaptation\nmethod with the spatial low-rank adapter to tailor a modern video foundation\nmodel to the cartoon domain while keeping its temporal prior intact. Requiring\nas few as a single sketch and a colored reference frame, ToonComposer excels\nwith sparse inputs, while also supporting multiple sketches at any temporal\nlocation for more precise motion control. This dual capability reduces manual\nworkload and improves flexibility, empowering artists in real-world scenarios.\nTo evaluate our model, we further created PKBench, a benchmark featuring\nhuman-drawn sketches that simulate real-world use cases. Our evaluation\ndemonstrates that ToonComposer outperforms existing methods in visual quality,\nmotion consistency, and production efficiency, offering a superior and more\nflexible solution for AI-assisted cartoon production.",
      "pdf_url": "http://arxiv.org/pdf/2508.10881v1",
      "published": "2025-08-14T17:50:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.10881v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Searching for Privacy Risks in LLM Agents via Simulation",
      "authors": [
        "Yanzhe Zhang",
        "Diyi Yang"
      ],
      "abstract": "The widespread deployment of LLM-based agents is likely to introduce a\ncritical privacy threat: malicious agents that proactively engage others in\nmulti-turn interactions to extract sensitive information. These dynamic\ndialogues enable adaptive attack strategies that can cause severe privacy\nviolations, yet their evolving nature makes it difficult to anticipate and\ndiscover sophisticated vulnerabilities manually. To tackle this problem, we\npresent a search-based framework that alternates between improving attacker and\ndefender instructions by simulating privacy-critical agent interactions. Each\nsimulation involves three roles: data subject, data sender, and data recipient.\nWhile the data subject's behavior is fixed, the attacker (data recipient)\nattempts to extract sensitive information from the defender (data sender)\nthrough persistent and interactive exchanges. To explore this interaction space\nefficiently, our search algorithm employs LLMs as optimizers, using parallel\nsearch with multiple threads and cross-thread propagation to analyze simulation\ntrajectories and iteratively propose new instructions. Through this process, we\nfind that attack strategies escalate from simple direct requests to\nsophisticated multi-turn tactics such as impersonation and consent forgery,\nwhile defenses advance from rule-based constraints to identity-verification\nstate machines. The discovered attacks and defenses transfer across diverse\nscenarios and backbone models, demonstrating strong practical utility for\nbuilding privacy-aware agents.",
      "pdf_url": "http://arxiv.org/pdf/2508.10880v1",
      "published": "2025-08-14T17:49:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.10880v1",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "A Survey on Diffusion Language Models",
      "authors": [
        "Tianyi Li",
        "Mingda Chen",
        "Bowei Guo",
        "Zhiqiang Shen"
      ],
      "abstract": "Diffusion Language Models (DLMs) are rapidly emerging as a powerful and\npromising alternative to the dominant autoregressive (AR) paradigm. By\ngenerating tokens in parallel through an iterative denoising process, DLMs\npossess inherent advantages in reducing inference latency and capturing\nbidirectional context, thereby enabling fine-grained control over the\ngeneration process. While achieving a several-fold speed-up, recent\nadvancements have allowed DLMs to show performance comparable to their\nautoregressive counterparts, making them a compelling choice for various\nnatural language processing tasks. In this survey, we provide a holistic\noverview of the current DLM landscape. We trace its evolution and relationship\nwith other paradigms, such as autoregressive and masked language models, and\ncover both foundational principles and state-of-the-art models. Our work offers\nan up-to-date, comprehensive taxonomy and an in-depth analysis of current\ntechniques, from pre-training strategies to advanced post-training methods.\nAnother contribution of this survey is a thorough review of DLM inference\nstrategies and optimizations, including improvements in decoding parallelism,\ncaching mechanisms, and generation quality. We also highlight the latest\napproaches to multimodal extensions of DLMs and delineate their applications\nacross various practical scenarios. Furthermore, our discussion addresses the\nlimitations and challenges of DLMs, including efficiency, long-sequence\nhandling, and infrastructure requirements, while outlining future research\ndirections to sustain progress in this rapidly evolving field. Project GitHub\nis available at https://github.com/VILA-Lab/Awesome-DLMs.",
      "pdf_url": "http://arxiv.org/pdf/2508.10875v1",
      "published": "2025-08-14T17:47:22+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.10875v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "TLE-Based A2C Agent for Terrestrial Coverage Orbital Path Planning",
      "authors": [
        "Anantha Narayanan",
        "Battu Bhanu Teja",
        "Pruthwik Mishra"
      ],
      "abstract": "The increasing congestion of Low Earth Orbit (LEO) poses persistent\nchallenges to the efficient deployment and safe operation of Earth observation\nsatellites. Mission planners must now account not only for mission-specific\nrequirements but also for the increasing collision risk with active satellites\nand space debris. This work presents a reinforcement learning framework using\nthe Advantage Actor-Critic (A2C) algorithm to optimize satellite orbital\nparameters for precise terrestrial coverage within predefined surface radii. By\nformulating the problem as a Markov Decision Process (MDP) within a custom\nOpenAI Gymnasium environment, our method simulates orbital dynamics using\nclassical Keplerian elements. The agent progressively learns to adjust five of\nthe orbital parameters - semi-major axis, eccentricity, inclination, right\nascension of ascending node, and the argument of perigee-to achieve targeted\nterrestrial coverage. Comparative evaluation against Proximal Policy\nOptimization (PPO) demonstrates A2C's superior performance, achieving 5.8x\nhigher cumulative rewards (10.0 vs 9.263025) while converging in 31.5x fewer\ntimesteps (2,000 vs 63,000). The A2C agent consistently meets mission\nobjectives across diverse target coordinates while maintaining computational\nefficiency suitable for real-time mission planning applications. Key\ncontributions include: (1) a TLE-based orbital simulation environment\nincorporating physics constraints, (2) validation of actor-critic methods'\nsuperiority over trust region approaches in continuous orbital control, and (3)\ndemonstration of rapid convergence enabling adaptive satellite deployment. This\napproach establishes reinforcement learning as a computationally efficient\nalternative for scalable and intelligent LEO mission planning.",
      "pdf_url": "http://arxiv.org/pdf/2508.10872v1",
      "published": "2025-08-14T17:44:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.10872v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "Medico 2025: Visual Question Answering for Gastrointestinal Imaging",
      "authors": [
        "Sushant Gautam",
        "Vajira Thambawita",
        "Michael Riegler",
        "Pål Halvorsen",
        "Steven Hicks"
      ],
      "abstract": "The Medico 2025 challenge addresses Visual Question Answering (VQA) for\nGastrointestinal (GI) imaging, organized as part of the MediaEval task series.\nThe challenge focuses on developing Explainable Artificial Intelligence (XAI)\nmodels that answer clinically relevant questions based on GI endoscopy images\nwhile providing interpretable justifications aligned with medical reasoning. It\nintroduces two subtasks: (1) answering diverse types of visual questions using\nthe Kvasir-VQA-x1 dataset, and (2) generating multimodal explanations to\nsupport clinical decision-making. The Kvasir-VQA-x1 dataset, created from 6,500\nimages and 159,549 complex question-answer (QA) pairs, serves as the benchmark\nfor the challenge. By combining quantitative performance metrics and\nexpert-reviewed explainability assessments, this task aims to advance\ntrustworthy Artificial Intelligence (AI) in medical image analysis.\nInstructions, data access, and an updated guide for participation are available\nin the official competition repository:\nhttps://github.com/simula/MediaEval-Medico-2025",
      "pdf_url": "http://arxiv.org/pdf/2508.10869v1",
      "published": "2025-08-14T17:43:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.10869v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "68T45, 92C55",
        "I.2.10; I.4.9"
      ]
    },
    {
      "title": "Performance of GPT-5 in Brain Tumor MRI Reasoning",
      "authors": [
        "Mojtaba Safari",
        "Shansong Wang",
        "Mingzhe Hu",
        "Zach Eidex",
        "Qiang Li",
        "Xiaofeng Yang"
      ],
      "abstract": "Accurate differentiation of brain tumor types on magnetic resonance imaging\n(MRI) is critical for guiding treatment planning in neuro-oncology. Recent\nadvances in large language models (LLMs) have enabled visual question answering\n(VQA) approaches that integrate image interpretation with natural language\nreasoning. In this study, we evaluated GPT-4o, GPT-5-nano, GPT-5-mini, and\nGPT-5 on a curated brain tumor VQA benchmark derived from 3 Brain Tumor\nSegmentation (BraTS) datasets - glioblastoma (GLI), meningioma (MEN), and brain\nmetastases (MET). Each case included multi-sequence MRI triplanar mosaics and\nstructured clinical features transformed into standardized VQA items. Models\nwere assessed in a zero-shot chain-of-thought setting for accuracy on both\nvisual and reasoning tasks. Results showed that GPT-5-mini achieved the highest\nmacro-average accuracy (44.19%), followed by GPT-5 (43.71%), GPT-4o (41.49%),\nand GPT-5-nano (35.85%). Performance varied by tumor subtype, with no single\nmodel dominating across all cohorts. These findings suggest that GPT-5 family\nmodels can achieve moderate accuracy in structured neuro-oncological VQA tasks,\nbut not at a level acceptable for clinical use.",
      "pdf_url": "http://arxiv.org/pdf/2508.10865v1",
      "published": "2025-08-14T17:35:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.10865v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "From Black Box to Transparency: Enhancing Automated Interpreting Assessment with Explainable AI in College Classrooms",
      "authors": [
        "Zhaokun Jiang",
        "Ziyin Zhang"
      ],
      "abstract": "Recent advancements in machine learning have spurred growing interests in\nautomated interpreting quality assessment. Nevertheless, existing research\nsuffers from insufficient examination of language use quality, unsatisfactory\nmodeling effectiveness due to data scarcity and imbalance, and a lack of\nefforts to explain model predictions. To address these gaps, we propose a\nmulti-dimensional modeling framework that integrates feature engineering, data\naugmentation, and explainable machine learning. This approach prioritizes\nexplainability over ``black box'' predictions by utilizing only\nconstruct-relevant, transparent features and conducting Shapley Value (SHAP)\nanalysis. Our results demonstrate strong predictive performance on a novel\nEnglish-Chinese consecutive interpreting dataset, identifying BLEURT and\nCometKiwi scores to be the strongest predictive features for fidelity,\npause-related features for fluency, and Chinese-specific phraseological\ndiversity metrics for language use. Overall, by placing particular emphasis on\nexplainability, we present a scalable, reliable, and transparent alternative to\ntraditional human evaluation, facilitating the provision of detailed diagnostic\nfeedback for learners and supporting self-regulated learning advantages not\nafforded by automated scores in isolation.",
      "pdf_url": "http://arxiv.org/pdf/2508.10860v1",
      "published": "2025-08-14T17:31:18+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.10860v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Reinforced Language Models for Sequential Decision Making",
      "authors": [
        "Jim Dilkes",
        "Vahid Yazdanpanah",
        "Sebastian Stein"
      ],
      "abstract": "Large Language Models (LLMs) show potential as sequential decision-making\nagents, but their application is often limited due to a reliance on large,\ncomputationally expensive models. This creates a need to improve smaller\nmodels, yet existing post-training methods are designed for single-turn\ninteractions and cannot handle credit assignment in multi-step agentic tasks.\nTo address this, we introduce Multi-Step Group-Relative Policy Optimization\n(MS-GRPO), a new algorithm for post-training LLM agents, grounded in formal\nText-Mediated Stochastic Game (TSMG) and Language-Agent Policy (LAP)\nframeworks. For credit assignment, MS-GRPO attributes the entire cumulative\nepisode reward to each individual episode step. We supplement this algorithm\nwith a novel absolute-advantage-weighted episode sampling strategy that we show\nimproves training performance. We evaluate our approach by post-training a\n3-billion parameter model on Snake and Frozen Lake. Our experiments demonstrate\nthat the method is effective in improving decision-making performance: our\npost-trained 3B parameter model outperforms a 72B parameter baseline by 50% on\nthe Frozen Lake task. This work demonstrates that targeted post-training is a\npractical and efficient alternative to relying on model scale for creating\nsequential decision-making agents using LLMs.",
      "pdf_url": "http://arxiv.org/pdf/2508.10839v1",
      "published": "2025-08-14T17:05:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.10839v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "I.2.7; I.2.8"
      ]
    },
    {
      "title": "A Multimodal Neural Network for Recognizing Subjective Self-Disclosure Towards Social Robots",
      "authors": [
        "Henry Powell",
        "Guy Laban",
        "Emily S. Cross"
      ],
      "abstract": "Subjective self-disclosure is an important feature of human social\ninteraction. While much has been done in the social and behavioural literature\nto characterise the features and consequences of subjective self-disclosure,\nlittle work has been done thus far to develop computational systems that are\nable to accurately model it. Even less work has been done that attempts to\nmodel specifically how human interactants self-disclose with robotic partners.\nIt is becoming more pressing as we require social robots to work in conjunction\nwith and establish relationships with humans in various social settings. In\nthis paper, our aim is to develop a custom multimodal attention network based\non models from the emotion recognition literature, training this model on a\nlarge self-collected self-disclosure video corpus, and constructing a new loss\nfunction, the scale preserving cross entropy loss, that improves upon both\nclassification and regression versions of this problem. Our results show that\nthe best performing model, trained with our novel loss function, achieves an F1\nscore of 0.83, an improvement of 0.48 from the best baseline model. This result\nmakes significant headway in the aim of allowing social robots to pick up on an\ninteraction partner's self-disclosures, an ability that will be essential in\nsocial robots with social cognition.",
      "pdf_url": "http://arxiv.org/pdf/2508.10828v1",
      "published": "2025-08-14T16:50:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.10828v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "Who Benefits from AI Explanations? Towards Accessible and Interpretable Systems",
      "authors": [
        "Maria J. P. Peixoto",
        "Akriti Pandey",
        "Ahsan Zaman",
        "Peter R. Lewis"
      ],
      "abstract": "As AI systems are increasingly deployed to support decision-making in\ncritical domains, explainability has become a means to enhance the\nunderstandability of these outputs and enable users to make more informed and\nconscious choices. However, despite growing interest in the usability of\neXplainable AI (XAI), the accessibility of these methods, particularly for\nusers with vision impairments, remains underexplored. This paper investigates\naccessibility gaps in XAI through a two-pronged approach. First, a literature\nreview of 79 studies reveals that evaluations of XAI techniques rarely include\ndisabled users, with most explanations relying on inherently visual formats.\nSecond, we present a four-part methodological proof of concept that\noperationalizes inclusive XAI design: (1) categorization of AI systems, (2)\npersona definition and contextualization, (3) prototype design and\nimplementation, and (4) expert and user assessment of XAI techniques for\naccessibility. Preliminary findings suggest that simplified explanations are\nmore comprehensible for non-visual users than detailed ones, and that\nmultimodal presentation is required for more equitable interpretability.",
      "pdf_url": "http://arxiv.org/pdf/2508.10806v1",
      "published": "2025-08-14T16:26:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.10806v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "The SET Perceptual Factors Framework: Towards Assured Perception for Autonomous Systems",
      "authors": [
        "Troi Williams"
      ],
      "abstract": "Future autonomous systems promise significant societal benefits, yet their\ndeployment raises concerns about safety and trustworthiness. A key concern is\nassuring the reliability of robot perception, as perception seeds safe\ndecision-making. Failures in perception are often due to complex yet common\nenvironmental factors and can lead to accidents that erode public trust. To\naddress this concern, we introduce the SET (Self, Environment, and Target)\nPerceptual Factors Framework. We designed the framework to systematically\nanalyze how factors such as weather, occlusion, or sensor limitations\nnegatively impact perception. To achieve this, the framework employs SET State\nTrees to categorize where such factors originate and SET Factor Trees to model\nhow these sources and factors impact perceptual tasks like object detection or\npose estimation. Next, we develop Perceptual Factor Models using both trees to\nquantify the uncertainty for a given task. Our framework aims to promote\nrigorous safety assurances and cultivate greater public understanding and trust\nin autonomous systems by offering a transparent and standardized method for\nidentifying, modeling, and communicating perceptual risks.",
      "pdf_url": "http://arxiv.org/pdf/2508.10798v1",
      "published": "2025-08-14T16:22:01+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.10798v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "Enhancing Fairness in Autoencoders for Node-Level Graph Anomaly Detection",
      "authors": [
        "Shouju Wang",
        "Yuchen Song",
        "Sheng'en Li",
        "Dongmian Zou"
      ],
      "abstract": "Graph anomaly detection (GAD) has become an increasingly important task\nacross various domains. With the rapid development of graph neural networks\n(GNNs), GAD methods have achieved significant performance improvements.\nHowever, fairness considerations in GAD remain largely underexplored. Indeed,\nGNN-based GAD models can inherit and amplify biases present in training data,\npotentially leading to unfair outcomes. While existing efforts have focused on\ndeveloping fair GNNs, most approaches target node classification tasks, where\nmodels often rely on simple layer architectures rather than autoencoder-based\nstructures, which are the most widely used architecturs for anomaly detection.\nTo address fairness in autoencoder-based GAD models, we propose\n\\textbf{D}is\\textbf{E}ntangled \\textbf{C}ounterfactual \\textbf{A}dversarial\n\\textbf{F}air (DECAF)-GAD, a framework that alleviates bias while preserving\nGAD performance. Specifically, we introduce a structural causal model (SCM) to\ndisentangle sensitive attributes from learned representations. Based on this\ncausal framework, we formulate a specialized autoencoder architecture along\nwith a fairness-guided loss function. Through extensive experiments on both\nsynthetic and real-world datasets, we demonstrate that DECAF-GAD not only\nachieves competitive anomaly detection performance but also significantly\nenhances fairness metrics compared to baseline GAD methods. Our code is\navailable at https://github.com/Tlhey/decaf_code.",
      "pdf_url": "http://arxiv.org/pdf/2508.10785v1",
      "published": "2025-08-14T16:12:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.10785v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ]
    },
    {
      "title": "Ultra-High-Definition Reference-Based Landmark Image Super-Resolution with Generative Diffusion Prior",
      "authors": [
        "Zhenning Shi",
        "Zizheng Yan",
        "Yuhang Yu",
        "Clara Xue",
        "Jingyu Zhuang",
        "Qi Zhang",
        "Jinwei Chen",
        "Tao Li",
        "Qingnan Fan"
      ],
      "abstract": "Reference-based Image Super-Resolution (RefSR) aims to restore a\nlow-resolution (LR) image by utilizing the semantic and texture information\nfrom an additional reference high-resolution (reference HR) image. Existing\ndiffusion-based RefSR methods are typically built upon ControlNet, which\nstruggles to effectively align the information between the LR image and the\nreference HR image. Moreover, current RefSR datasets suffer from limited\nresolution and poor image quality, resulting in the reference images lacking\nsufficient fine-grained details to support high-quality restoration. To\novercome the limitations above, we propose TriFlowSR, a novel framework that\nexplicitly achieves pattern matching between the LR image and the reference HR\nimage. Meanwhile, we introduce Landmark-4K, the first RefSR dataset for\nUltra-High-Definition (UHD) landmark scenarios. Considering the UHD scenarios\nwith real-world degradation, in TriFlowSR, we design a Reference Matching\nStrategy to effectively match the LR image with the reference HR image.\nExperimental results show that our approach can better utilize the semantic and\ntexture information of the reference HR image compared to previous methods. To\nthe best of our knowledge, we propose the first diffusion-based RefSR pipeline\nfor ultra-high definition landmark scenarios under real-world degradation. Our\ncode and model will be available at https://github.com/nkicsl/TriFlowSR.",
      "pdf_url": "http://arxiv.org/pdf/2508.10779v1",
      "published": "2025-08-14T16:04:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.10779v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "The Knowledge-Reasoning Dissociation: Fundamental Limitations of LLMs in Clinical Natural Language Inference",
      "authors": [
        "Maël Jullien",
        "Marco Valentino",
        "André Freitas"
      ],
      "abstract": "Large language models are often assumed to acquire increasingly structured,\ngeneralizable internal representations simply by scaling data and parameters.\nWe interrogate this assumption by introducing a Clinical Trial Natural Language\nInference benchmark comprising four reasoning families, Causal Attribution,\nCompositional Grounding, Epistemic Verification, and Risk State Abstraction.\nEach item is paired with a targeted Ground Knowledge and Meta-Level Reasoning\nVerification (GKMRV) probe, allowing us to dissociate failures of factual\naccess from failures of inference. We evaluate six contemporary LLMs under both\ndirect and chain of thought prompting.\n  Models achieve near-ceiling GKMRV accuracy (mean accuracy 0.918) yet perform\npoorly on the main reasoning tasks (mean accuracy 0.25). Despite low accuracy,\noutput inferences are highly consistent across samples (mean 0.87), indicating\na systematic application of underlying heuristics and shortcuts.\n  These results reveal fundamental structural and representational limitations:\ncurrent LLMs often possess the relevant clinical knowledge but lack the\nstructured, composable internal representations needed to deploy it reliably\n(e.g., integrating constraints, weighing evidence, or simulating\ncounterfactuals). Decoupling knowledge from reasoning with GKMRV makes this\ndissociation explicit and measurable, providing an effective framework for\nprobing the reliability of LLMs in high-stakes domains.",
      "pdf_url": "http://arxiv.org/pdf/2508.10777v1",
      "published": "2025-08-14T16:01:10+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.10777v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Estimating Covariance for Global Minimum Variance Portfolio: A Decision-Focused Learning Approach",
      "authors": [
        "Juchan Kim",
        "Inwoo Tae",
        "Yongjae Lee"
      ],
      "abstract": "Portfolio optimization constitutes a cornerstone of risk management by\nquantifying the risk-return trade-off. Since it inherently depends on accurate\nparameter estimation under conditions of future uncertainty, the selection of\nappropriate input parameters is critical for effective portfolio construction.\nHowever, most conventional statistical estimators and machine learning\nalgorithms determine these parameters by minimizing mean-squared error (MSE), a\ncriterion that can yield suboptimal investment decisions. In this paper, we\nadopt decision-focused learning (DFL) - an approach that directly optimizes\ndecision quality rather than prediction error such as MSE - to derive the\nglobal minimum-variance portfolio (GMVP). Specifically, we theoretically derive\nthe gradient of decision loss using the analytic solution of GMVP and its\nproperties regarding the principal components of itself. Through extensive\nempirical evaluation, we show that prediction-focused estimation methods may\nfail to produce optimal allocations in practice, whereas DFL-based methods\nconsistently deliver superior decision performance. Furthermore, we provide a\ncomprehensive analysis of DFL's mechanism in GMVP construction, focusing on its\nvolatility reduction capability, decision-driving features, and estimation\ncharacteristics.",
      "pdf_url": "http://arxiv.org/pdf/2508.10776v1",
      "published": "2025-08-14T16:00:52+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.10776v1",
      "categories": [
        "q-fin.PM",
        "cs.AI"
      ]
    },
    {
      "title": "Video-BLADE: Block-Sparse Attention Meets Step Distillation for Efficient Video Generation",
      "authors": [
        "Youping Gu",
        "Xiaolong Li",
        "Yuhao Hu",
        "Bohan Zhuang"
      ],
      "abstract": "Diffusion transformers currently lead the field in high-quality video\ngeneration, but their slow iterative denoising process and prohibitive\nquadratic attention costs for long sequences create significant inference\nbottlenecks. While both step distillation and sparse attention mechanisms have\nshown promise as independent acceleration strategies, effectively combining\nthese approaches presents critical challenges -- training-free integration\nyields suboptimal results, while separately training sparse attention after\nstep distillation requires prohibitively expensive high-quality video data. To\novercome these limitations, we propose BLADE, an innovative data-free joint\ntraining framework that introduces: (1) an Adaptive Block-Sparse Attention\n(ASA) mechanism for dynamically generating content-aware sparsity masks to\nfocus computation on salient spatiotemporal features, and (2) a sparsity-aware\nstep distillation paradigm built upon Trajectory Distribution Matching (TDM)\nthat directly incorporates sparsity into the distillation process rather than\ntreating it as a separate compression step, with fast convergence. We validate\nBLADE on text-to-video models like CogVideoX-5B and Wan2.1-1.3B. Our framework\ndemonstrates remarkable efficiency gains across different scales. On\nWan2.1-1.3B, BLADE achieves a 14.10x end-to-end inference acceleration over a\n50-step baseline. Moreover, on models such as CogVideoX-5B with short video\nsequence lengths, our framework delivers a robust 8.89x speedup. Crucially, the\nacceleration is accompanied by a consistent quality improvement. On the\nVBench-2.0 benchmark, BLADE boosts the score of CogVideoX-5B to 0.569 (from\n0.534) and Wan2.1-1.3B to 0.570 (from 0.563), results that are further\ncorroborated by superior ratings in human evaluations. Our code and model\nweights are publicly available at: http://ziplab.co/BLADE-Homepage/.",
      "pdf_url": "http://arxiv.org/pdf/2508.10774v1",
      "published": "2025-08-14T15:58:59+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.10774v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "AEGIS: Authenticity Evaluation Benchmark for AI-Generated Video Sequences",
      "authors": [
        "Jieyu Li",
        "Xin Zhang",
        "Joey Tianyi Zhou"
      ],
      "abstract": "Recent advances in AI-generated content have fueled the rise of highly\nrealistic synthetic videos, posing severe risks to societal trust and digital\nintegrity. Existing benchmarks for video authenticity detection typically\nsuffer from limited realism, insufficient scale, and inadequate complexity,\nfailing to effectively evaluate modern vision-language models against\nsophisticated forgeries. To address this critical gap, we introduce AEGIS, a\nnovel large-scale benchmark explicitly targeting the detection of\nhyper-realistic and semantically nuanced AI-generated videos. AEGIS comprises\nover 10,000 rigorously curated real and synthetic videos generated by diverse,\nstate-of-the-art generative models, including Stable Video Diffusion,\nCogVideoX-5B, KLing, and Sora, encompassing open-source and proprietary\narchitectures. In particular, AEGIS features specially constructed challenging\nsubsets enhanced with robustness evaluation. Furthermore, we provide multimodal\nannotations spanning Semantic-Authenticity Descriptions, Motion Features, and\nLow-level Visual Features, facilitating authenticity detection and supporting\ndownstream tasks such as multimodal fusion and forgery localization. Extensive\nexperiments using advanced vision-language models demonstrate limited detection\ncapabilities on the most challenging subsets of AEGIS, highlighting the\ndataset's unique complexity and realism beyond the current generalization\ncapabilities of existing models. In essence, AEGIS establishes an indispensable\nevaluation benchmark, fundamentally advancing research toward developing\ngenuinely robust, reliable, broadly generalizable video authenticity detection\nmethodologies capable of addressing real-world forgery threats. Our dataset is\navailable on https://huggingface.co/datasets/Clarifiedfish/AEGIS.",
      "pdf_url": "http://arxiv.org/pdf/2508.10771v1",
      "published": "2025-08-14T15:55:49+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.10771v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Modeling Human Responses to Multimodal AI Content",
      "authors": [
        "Zhiqi Shen",
        "Shaojing Fan",
        "Danni Xu",
        "Terence Sim",
        "Mohan Kankanhalli"
      ],
      "abstract": "As AI-generated content becomes widespread, so does the risk of\nmisinformation. While prior research has primarily focused on identifying\nwhether content is authentic, much less is known about how such content\ninfluences human perception and behavior. In domains like trading or the stock\nmarket, predicting how people react (e.g., whether a news post will go viral),\ncan be more critical than verifying its factual accuracy. To address this, we\ntake a human-centered approach and introduce the MhAIM Dataset, which contains\n154,552 online posts (111,153 of them AI-generated), enabling large-scale\nanalysis of how people respond to AI-generated content. Our human study reveals\nthat people are better at identifying AI content when posts include both text\nand visuals, particularly when inconsistencies exist between the two. We\npropose three new metrics: trustworthiness, impact, and openness, to quantify\nhow users judge and engage with online content. We present T-Lens, an LLM-based\nagent system designed to answer user queries by incorporating predicted human\nresponses to multimodal information. At its core is HR-MCP (Human Response\nModel Context Protocol), built on the standardized Model Context Protocol\n(MCP), enabling seamless integration with any LLM. This integration allows\nT-Lens to better align with human reactions, enhancing both interpretability\nand interaction capabilities. Our work provides empirical insights and\npractical tools to equip LLMs with human-awareness capabilities. By\nhighlighting the complex interplay among AI, human cognition, and information\nreception, our findings suggest actionable strategies for mitigating the risks\nof AI-driven misinformation.",
      "pdf_url": "http://arxiv.org/pdf/2508.10769v1",
      "published": "2025-08-14T15:55:19+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.10769v1",
      "categories": [
        "cs.AI",
        "cs.MM"
      ]
    },
    {
      "title": "FROGENT: An End-to-End Full-process Drug Design Agent",
      "authors": [
        "Qihua Pan",
        "Dong Xu",
        "Jenna Xinyi Yao",
        "Lijia Ma",
        "Zexuan Zhu",
        "Junkai Ji"
      ],
      "abstract": "Powerful AI tools for drug discovery reside in isolated web apps, desktop\nprograms, and code libraries. Such fragmentation forces scientists to manage\nincompatible interfaces and specialized scripts, which can be a cumbersome and\nrepetitive process. To address this issue, a Full-pROcess druG dEsign ageNT,\nnamed FROGENT, has been proposed. Specifically, FROGENT utilizes a Large\nLanguage Model and the Model Context Protocol to integrate multiple dynamic\nbiochemical databases, extensible tool libraries, and task-specific AI models.\nThis agentic framework allows FROGENT to execute complicated drug discovery\nworkflows dynamically, including component tasks such as target identification,\nmolecule generation and retrosynthetic planning. FROGENT has been evaluated on\neight benchmarks that cover various aspects of drug discovery, such as\nknowledge retrieval, property prediction, virtual screening, mechanistic\nanalysis, molecular design, and synthesis. It was compared against six\nincreasingly advanced ReAct-style agents that support code execution and\nliterature searches. Empirical results demonstrated that FROGENT triples the\nbest baseline performance in hit-finding and doubles it in interaction\nprofiling, significantly outperforming both the open-source model Qwen3-32B and\nthe commercial model GPT-4o. In addition, real-world cases have been utilized\nto validate the practicability and generalization of FROGENT. This development\nsuggests that streamlining the agentic drug discovery pipeline can\nsignificantly enhance researcher productivity.",
      "pdf_url": "http://arxiv.org/pdf/2508.10760v1",
      "published": "2025-08-14T15:45:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.10760v1",
      "categories": [
        "q-bio.BM",
        "cs.AI"
      ]
    },
    {
      "title": "Natively Trainable Sparse Attention for Hierarchical Point Cloud Datasets",
      "authors": [
        "Nicolas Lapautre",
        "Maria Marchenko",
        "Carlos Miguel Patiño",
        "Xin Zhou"
      ],
      "abstract": "Unlocking the potential of transformers on datasets of large physical systems\ndepends on overcoming the quadratic scaling of the attention mechanism. This\nwork explores combining the Erwin architecture with the Native Sparse Attention\n(NSA) mechanism to improve the efficiency and receptive field of transformer\nmodels for large-scale physical systems, addressing the challenge of quadratic\nattention complexity. We adapt the NSA mechanism for non-sequential data,\nimplement the Erwin NSA model, and evaluate it on three datasets from the\nphysical sciences -- cosmology simulations, molecular dynamics, and air\npressure modeling -- achieving performance that matches or exceeds that of the\noriginal Erwin model. Additionally, we reproduce the experimental results from\nthe Erwin paper to validate their implementation.",
      "pdf_url": "http://arxiv.org/pdf/2508.10758v1",
      "published": "2025-08-14T15:39:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.10758v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Pass@k Training for Adaptively Balancing Exploration and Exploitation of Large Reasoning Models",
      "authors": [
        "Zhipeng Chen",
        "Xiaobo Qin",
        "Youbin Wu",
        "Yue Ling",
        "Qinghao Ye",
        "Wayne Xin Zhao",
        "Guang Shi"
      ],
      "abstract": "Reinforcement learning with verifiable rewards (RLVR), which typically adopts\nPass@1 as the reward, has faced the issues in balancing exploration and\nexploitation, causing policies to prefer conservative actions, converging to a\nlocal optimum. Identifying an appropriate reward metric is therefore crucial.\nRegarding the prior work, although Pass@k has been used in evaluation, its\nconnection to LLM exploration ability in RLVR remains largely overlooked. To\ninvestigate this, we first use Pass@k as the reward to train the policy model\n(i.e., $\\textbf{Pass@k Training}$), and observe the improvement on its\nexploration ability. Next, we derive an analytical solution for the advantage\nof Pass@k Training, leading to an efficient and effective process. Building on\nthis, our analysis reveals that exploration and exploitation are not inherently\nconflicting objectives, while they can mutually enhance each other. Moreover,\nPass@k Training with analytical derivation essentially involves directly\ndesigning the advantage function. Inspired by this, we preliminarily explore\nthe advantage design for RLVR, showing promising results and highlighting a\npotential future direction.",
      "pdf_url": "http://arxiv.org/pdf/2508.10751v1",
      "published": "2025-08-14T15:34:47+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.10751v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Scaling Up without Fading Out: Goal-Aware Sparse GNN for RL-based Generalized Planning",
      "authors": [
        "Sangwoo Jeon",
        "Juchul Shin",
        "Gyeong-Tae Kim",
        "YeonJe Cho",
        "Seongwoo Kim"
      ],
      "abstract": "Generalized planning using deep reinforcement learning (RL) combined with\ngraph neural networks (GNNs) has shown promising results in various symbolic\nplanning domains described by PDDL. However, existing approaches typically\nrepresent planning states as fully connected graphs, leading to a combinatorial\nexplosion in edge information and substantial sparsity as problem scales grow,\nespecially evident in large grid-based environments. This dense representation\nresults in diluted node-level information, exponentially increases memory\nrequirements, and ultimately makes learning infeasible for larger-scale\nproblems. To address these challenges, we propose a sparse, goal-aware GNN\nrepresentation that selectively encodes relevant local relationships and\nexplicitly integrates spatial features related to the goal. We validate our\napproach by designing novel drone mission scenarios based on PDDL within a grid\nworld, effectively simulating realistic mission execution environments. Our\nexperimental results demonstrate that our method scales effectively to larger\ngrid sizes previously infeasible with dense graph representations and\nsubstantially improves policy generalization and success rates. Our findings\nprovide a practical foundation for addressing realistic, large-scale\ngeneralized planning tasks.",
      "pdf_url": "http://arxiv.org/pdf/2508.10747v1",
      "published": "2025-08-14T15:30:28+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.10747v1",
      "categories": [
        "cs.AI",
        "cs.RO"
      ]
    },
    {
      "title": "Agentic Design Review System",
      "authors": [
        "Sayan Nag",
        "K J Joseph",
        "Koustava Goswami",
        "Vlad I Morariu",
        "Balaji Vasan Srinivasan"
      ],
      "abstract": "Evaluating graphic designs involves assessing it from multiple facets like\nalignment, composition, aesthetics and color choices. Evaluating designs in a\nholistic way involves aggregating feedback from individual expert reviewers.\nTowards this, we propose an Agentic Design Review System (AgenticDRS), where\nmultiple agents collaboratively analyze a design, orchestrated by a meta-agent.\nA novel in-context exemplar selection approach based on graph matching and a\nunique prompt expansion method plays central role towards making each agent\ndesign aware. Towards evaluating this framework, we propose DRS-BENCH\nbenchmark. Thorough experimental evaluation against state-of-the-art baselines\nadapted to the problem setup, backed-up with critical ablation experiments\nbrings out the efficacy of Agentic-DRS in evaluating graphic designs and\ngenerating actionable feedback. We hope that this work will attract attention\nto this pragmatic, yet under-explored research direction.",
      "pdf_url": "http://arxiv.org/pdf/2508.10745v1",
      "published": "2025-08-14T15:29:24+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.10745v1",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.MA",
        "cs.MM"
      ]
    },
    {
      "title": "APFL: Analytic Personalized Federated Learning via Dual-Stream Least Squares",
      "authors": [
        "Kejia Fan",
        "Jianheng Tang",
        "Zhirui Yang",
        "Feijiang Han",
        "Jiaxu Li",
        "Run He",
        "Yajiang Huang",
        "Anfeng Liu",
        "Houbing Herbert Song",
        "Yunhuai Liu",
        "Huiping Zhuang"
      ],
      "abstract": "Personalized Federated Learning (PFL) has presented a significant challenge\nto deliver personalized models to individual clients through collaborative\ntraining. Existing PFL methods are often vulnerable to non-IID data, which\nseverely hinders collective generalization and then compromises the subsequent\npersonalization efforts. In this paper, to address this non-IID issue in PFL,\nwe propose an Analytic Personalized Federated Learning (APFL) approach via\ndual-stream least squares. In our APFL, we use a foundation model as a frozen\nbackbone for feature extraction. Subsequent to the feature extractor, we\ndevelop dual-stream analytic models to achieve both collective generalization\nand individual personalization. Specifically, our APFL incorporates a shared\nprimary stream for global generalization across all clients, and a dedicated\nrefinement stream for local personalization of each individual client. The\nanalytical solutions of our APFL enable its ideal property of heterogeneity\ninvariance, theoretically meaning that each personalized model remains\nidentical regardless of how heterogeneous the data are distributed across all\nother clients. Empirical results across various datasets also validate the\nsuperiority of our APFL over state-of-the-art baselines, with advantages of at\nleast 1.10%-15.45% in accuracy.",
      "pdf_url": "http://arxiv.org/pdf/2508.10732v1",
      "published": "2025-08-14T15:12:50+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.10732v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "EgoCross: Benchmarking Multimodal Large Language Models for Cross-Domain Egocentric Video Question Answering",
      "authors": [
        "Yanjun Li",
        "Yuqian Fu",
        "Tianwen Qian",
        "Qi'ao Xu",
        "Silong Dai",
        "Danda Pani Paudel",
        "Luc Van Gool",
        "Xiaoling Wang"
      ],
      "abstract": "Recent advances in Multimodal Large Language Models (MLLMs) have\nsignificantly pushed the frontier of egocentric video question answering\n(EgocentricQA). However, existing benchmarks and studies are mainly limited to\ncommon daily activities such as cooking and cleaning. In contrast, real-world\ndeployment inevitably encounters domain shifts, where target domains differ\nsubstantially in both visual style and semantic content. To bridge this gap, we\nintroduce \\textbf{EgoCross}, a comprehensive benchmark designed to evaluate the\ncross-domain generalization of MLLMs in EgocentricQA. EgoCross covers four\ndiverse and challenging domains, including surgery, industry, extreme sports,\nand animal perspective, representing realistic and high-impact application\nscenarios. It comprises approximately 1,000 QA pairs across 798 video clips,\nspanning four key QA tasks: prediction, recognition, localization, and\ncounting. Each QA pair provides both OpenQA and CloseQA formats to support\nfine-grained evaluation. Extensive experiments show that most existing MLLMs,\nwhether general-purpose or egocentric-specialized, struggle to generalize to\ndomains beyond daily life, highlighting the limitations of current models.\nFurthermore, we conduct several pilot studies, \\eg, fine-tuning and\nreinforcement learning, to explore potential improvements. We hope EgoCross and\nour accompanying analysis will serve as a foundation for advancing\ndomain-adaptive, robust egocentric video understanding. Data and codes will be\nreleased at:\n\\href{https://github.com/MyUniverse0726/EgoCross}{https://github.com/MyUniverse0726/EgoCross.}",
      "pdf_url": "http://arxiv.org/pdf/2508.10729v1",
      "published": "2025-08-14T15:11:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.10729v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Electromagnetic Simulations of Antennas on GPUs for Machine Learning Applications",
      "authors": [
        "Murat Temiz",
        "Vemund Bakken"
      ],
      "abstract": "This study proposes an antenna simulation framework powered by graphics\nprocessing units (GPUs) based on an open-source electromagnetic (EM) simulation\nsoftware (gprMax) for machine learning applications of antenna design and\noptimization. Furthermore, it compares the simulation results with those\nobtained through commercial EM software. The proposed software framework for\nmachine learning and surrogate model applications will produce antenna data\nsets consisting of a large number of antenna simulation results using GPUs.\nAlthough machine learning methods can attain the optimum solutions for many\nproblems, they are known to be data-hungry and require a great deal of samples\nfor the training stage of the algorithms. However, producing a sufficient\nnumber of training samples in EM applications within a limited time is\nchallenging due to the high computational complexity of EM simulations.\nTherefore, GPUs are utilized in this study to simulate a large number of\nantennas with predefined or random antenna shape parameters to produce data\nsets. Moreover, this study also compares various machine learning and deep\nlearning models in terms of antenna parameter estimation performance. This\nstudy demonstrates that an entry-level GPU substantially outperforms a high-end\nCPU in terms of computational performance, while a high-end gaming GPU can\nachieve around 18 times more computational performance compared to a high-end\nCPU. Moreover, it is shown that the open-source EM simulation software can\ndeliver similar results to those obtained via commercial software in the\nsimulation of microstrip antennas when the spatial resolution of the\nsimulations is sufficiently fine.",
      "pdf_url": "http://arxiv.org/pdf/2508.10713v1",
      "published": "2025-08-14T14:56:04+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.10713v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "GenOM: Ontology Matching with Description Generation and Large Language Model",
      "authors": [
        "Yiping Song",
        "Jiaoyan Chen",
        "Renate A. Schmidt"
      ],
      "abstract": "Ontology matching (OM) plays an essential role in enabling semantic\ninteroperability and integration across heterogeneous knowledge sources,\nparticularly in the biomedical domain which contains numerous complex concepts\nrelated to diseases and pharmaceuticals. This paper introduces GenOM, a large\nlanguage model (LLM)-based ontology alignment framework, which enriches the\nsemantic representations of ontology concepts via generating textual\ndefinitions, retrieves alignment candidates with an embedding model, and\nincorporates exact matching-based tools to improve precision. Extensive\nexperiments conducted on the OAEI Bio-ML track demonstrate that GenOM can often\nachieve competitive performance, surpassing many baselines including\ntraditional OM systems and recent LLM-based methods. Further ablation studies\nconfirm the effectiveness of semantic enrichment and few-shot prompting,\nhighlighting the framework's robustness and adaptability.",
      "pdf_url": "http://arxiv.org/pdf/2508.10703v1",
      "published": "2025-08-14T14:48:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.10703v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "REFN: A Reinforcement-Learning-From-Network Framework against 1-day/n-day Exploitations",
      "authors": [
        "Tianlong Yu",
        "Lihong Liu",
        "Ziyi Zhou",
        "Fudu Xing",
        "Kailong Wang",
        "Yang Yang"
      ],
      "abstract": "The exploitation of 1 day or n day vulnerabilities poses severe threats to\nnetworked devices due to massive deployment scales and delayed patching\n(average Mean Time To Patch exceeds 60 days). Existing defenses, including host\nbased patching and network based filtering, are inadequate due to limited\nscalability across diverse devices, compatibility issues especially with\nembedded or legacy systems, and error prone deployment process (manual patch\nvalidation). To address these issues, we introduce REFN (Reinforcement Learning\nFrom Network), a novel framework that trains Large Language Models (LLMs) to\nautonomously generate network filters to prevent 1 day or n day exploitations.\nREFN ensures scalability by uniquely employs Reinforcement Learning (RL) driven\nby online network rewards instead of traditional Human Feedback (RLHF). REFN\nguarantees compatibility via unified deployment on edge security gateways\n(Amazon Eero). REFN provides robustness via online validation using real\nnetwork traffic. Crucially, REFN addresses three core challenges in training\nLLMs for exploit prevention: 1) expanding current LLMs limited vulnerability\nfixing expertise via Agentic RAG based Knowledge Distillation, 2) bridging\ncurrent LLMs language to network gaps through an RL From VNF Pipeline that\ntranslates language context (vulnerability description) into network\nenforcement, 3) addressing the LLM hallucination and non determinism via the\nOnline Agentic Validation that penalizes erroneous outputs. Evaluated across 22\nfamilies of 1 day or n day exploits, REFN demonstrates effectiveness (21.1\npercent higher accuracy than alternatives), efficiency (Mean Time To Patch of\n3.65 hours) and scalability (easily scale to 10K devices). REFN serves as an\ninitial step toward training LLMs to rapidly prevent massive scale 1 day or n\nday exploitations.",
      "pdf_url": "http://arxiv.org/pdf/2508.10701v1",
      "published": "2025-08-14T14:45:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.10701v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Learning from Natural Language Feedback for Personalized Question Answering",
      "authors": [
        "Alireza Salemi",
        "Hamed Zamani"
      ],
      "abstract": "Personalization is crucial for enhancing both the effectiveness and user\nsatisfaction of language technologies, particularly in information-seeking\ntasks like question answering. Current approaches for personalizing large\nlanguage models (LLMs) often rely on retrieval-augmented generation (RAG),\nfollowed by reinforcement learning with scalar reward signals to teach models\nhow to use retrieved personal context. We believe that these scalar rewards\nsometimes provide weak, non-instructive feedback, limiting learning efficiency\nand personalization quality. We introduce VAC, a novel framework for\npersonalized response generation that replaces scalar rewards with natural\nlanguage feedback (NLF) that are generated conditioned on the user profiles and\nthe question narratives. NLF serves as a rich and actionable supervision\nsignal, allowing the policy model to iteratively refine its outputs and\ninternalize effective personalization strategies. Training alternates between\noptimizing the feedback model and fine-tuning the policy model on the improved\nresponses, resulting in a policy model that no longer requires feedback at\ninference. Evaluation on the LaMP-QA benchmark that consists of three diverse\ndomains demonstrates consistent and significant improvements over the\nstate-of-the-art results. Human evaluations further confirm the superior\nquality of the generated responses. These results demonstrate that NLF provides\nmore effective signals for optimizing personalized question answering.",
      "pdf_url": "http://arxiv.org/pdf/2508.10695v1",
      "published": "2025-08-14T14:36:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.10695v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ]
    },
    {
      "title": "Continuous Bangla Sign Language Translation: Mitigating the Expense of Gloss Annotation with the Assistance of Graph",
      "authors": [
        "Safaeid Hossain Arib",
        "Rabeya Akter",
        "Sejuti Rahman"
      ],
      "abstract": "Millions of individuals worldwide are affected by deafness and hearing\nimpairment. Sign language serves as a sophisticated means of communication for\nthe deaf and hard of hearing. However, in societies that prioritize spoken\nlanguages, sign language often faces underestimation, leading to communication\nbarriers and social exclusion. The Continuous Bangla Sign Language Translation\nproject aims to address this gap by enhancing translation methods. While recent\napproaches leverage transformer architecture for state-of-the-art results, our\nmethod integrates graph-based methods with the transformer architecture. This\nfusion, combining transformer and STGCN-LSTM architectures, proves more\neffective in gloss-free translation. Our contributions include architectural\nfusion, exploring various fusion strategies, and achieving a new\nstate-of-the-art performance on diverse sign language datasets, namely\nRWTH-PHOENIX-2014T, CSL-Daily, How2Sign, and BornilDB v1.0. Our approach\ndemonstrates superior performance compared to current translation outcomes\nacross all datasets, showcasing notable improvements of BLEU-4 scores of 4.01,\n2.07, and 0.5, surpassing those of GASLT, GASLT and slt_how2sign in\nRWTH-PHOENIX-2014T, CSL-Daily, and How2Sign, respectively. Also, we introduce\nbenchmarking on the BornilDB v1.0 dataset for the first time. Our method sets a\nbenchmark for future research, emphasizing the importance of gloss-free\ntranslation to improve communication accessibility for the deaf and hard of\nhearing.",
      "pdf_url": "http://arxiv.org/pdf/2508.10687v1",
      "published": "2025-08-14T14:32:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.10687v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Hybrid Generative Fusion for Efficient and Privacy-Preserving Face Recognition Dataset Generation",
      "authors": [
        "Feiran Li",
        "Qianqian Xu",
        "Shilong Bao",
        "Boyu Han",
        "Zhiyong Yang",
        "Qingming Huang"
      ],
      "abstract": "In this paper, we present our approach to the DataCV ICCV Challenge, which\ncenters on building a high-quality face dataset to train a face recognition\nmodel. The constructed dataset must not contain identities overlapping with any\nexisting public face datasets. To handle this challenge, we begin with a\nthorough cleaning of the baseline HSFace dataset, identifying and removing\nmislabeled or inconsistent identities through a Mixture-of-Experts (MoE)\nstrategy combining face embedding clustering and GPT-4o-assisted verification.\nWe retain the largest consistent identity cluster and apply data augmentation\nup to a fixed number of images per identity. To further diversify the dataset,\nwe generate synthetic identities using Stable Diffusion with prompt\nengineering. As diffusion models are computationally intensive, we generate\nonly one reference image per identity and efficiently expand it using Vec2Face,\nwhich rapidly produces 49 identity-consistent variants. This hybrid approach\nfuses GAN-based and diffusion-based samples, enabling efficient construction of\na diverse and high-quality dataset. To address the high visual similarity among\nsynthetic identities, we adopt a curriculum learning strategy by placing them\nearly in the training schedule, allowing the model to progress from easier to\nharder samples. Our final dataset contains 50 images per identity, and all\nnewly generated identities are checked with mainstream face datasets to ensure\nno identity leakage. Our method achieves \\textbf{1st place} in the competition,\nand experimental results show that our dataset improves model performance\nacross 10K, 20K, and 100K identity scales. Code is available at\nhttps://github.com/Ferry-Li/datacv_fr.",
      "pdf_url": "http://arxiv.org/pdf/2508.10672v1",
      "published": "2025-08-14T14:14:18+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.10672v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "STEP: Stepwise Curriculum Learning for Context-Knowledge Fusion in Conversational Recommendation",
      "authors": [
        "Zhenye Yang",
        "Jinpeng Chen",
        "Huan Li",
        "Xiongnan Jin",
        "Xuanyang Li",
        "Junwei Zhang",
        "Hongbo Gao",
        "Kaimin Wei",
        "Senzhang Wang"
      ],
      "abstract": "Conversational recommender systems (CRSs) aim to proactively capture user\npreferences through natural language dialogue and recommend high-quality items.\nTo achieve this, CRS gathers user preferences via a dialog module and builds\nuser profiles through a recommendation module to generate appropriate\nrecommendations. However, existing CRS faces challenges in capturing the deep\nsemantics of user preferences and dialogue context. In particular, the\nefficient integration of external knowledge graph (KG) information into\ndialogue generation and recommendation remains a pressing issue. Traditional\napproaches typically combine KG information directly with dialogue content,\nwhich often struggles with complex semantic relationships, resulting in\nrecommendations that may not align with user expectations.\n  To address these challenges, we introduce STEP, a conversational recommender\ncentered on pre-trained language models that combines curriculum-guided\ncontext-knowledge fusion with lightweight task-specific prompt tuning. At its\nheart, an F-Former progressively aligns the dialogue context with\nknowledge-graph entities through a three-stage curriculum, thus resolving\nfine-grained semantic mismatches. The fused representation is then injected\ninto the frozen language model via two minimal yet adaptive prefix prompts: a\nconversation prefix that steers response generation toward user intent and a\nrecommendation prefix that biases item ranking toward knowledge-consistent\ncandidates. This dual-prompt scheme allows the model to share cross-task\nsemantics while respecting the distinct objectives of dialogue and\nrecommendation. Experimental results show that STEP outperforms mainstream\nmethods in the precision of recommendation and dialogue quality in two public\ndatasets.",
      "pdf_url": "http://arxiv.org/pdf/2508.10669v1",
      "published": "2025-08-14T14:08:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.10669v1",
      "categories": [
        "cs.AI",
        "cs.IR",
        "H.3.3; I.2.7; H.2.8"
      ]
    },
    {
      "title": "AddressVLM: Cross-view Alignment Tuning for Image Address Localization using Large Vision-Language Models",
      "authors": [
        "Shixiong Xu",
        "Chenghao Zhang",
        "Lubin Fan",
        "Yuan Zhou",
        "Bin Fan",
        "Shiming Xiang",
        "Gaofeng Meng",
        "Jieping Ye"
      ],
      "abstract": "Large visual language models (LVLMs) have demonstrated impressive performance\nin coarse-grained geo-localization at the country or city level, but they\nstruggle with fine-grained street-level localization within urban areas. In\nthis paper, we explore integrating city-wide address localization capabilities\ninto LVLMs, facilitating flexible address-related question answering using\nstreet-view images. A key challenge is that the street-view visual\nquestion-and-answer (VQA) data provides only microscopic visual cues, leading\nto subpar performance in fine-tuned models. To tackle this issue, we\nincorporate perspective-invariant satellite images as macro cues and propose\ncross-view alignment tuning including a satellite-view and street-view image\ngrafting mechanism, along with an automatic label generation mechanism. Then\nLVLM's global understanding of street distribution is enhanced through\ncross-view matching. Our proposed model, named AddressVLM, consists of\ntwo-stage training protocols: cross-view alignment tuning and address\nlocalization tuning. Furthermore, we have constructed two street-view VQA\ndatasets based on image address localization datasets from Pittsburgh and San\nFrancisco. Qualitative and quantitative evaluations demonstrate that AddressVLM\noutperforms counterpart LVLMs by over 9% and 12% in average address\nlocalization accuracy on these two datasets, respectively.",
      "pdf_url": "http://arxiv.org/pdf/2508.10667v1",
      "published": "2025-08-14T14:06:28+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.10667v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Deep Learning in Classical and Quantum Physics",
      "authors": [
        "Timothy Heightman",
        "Marcin Płodzień"
      ],
      "abstract": "Scientific progress is tightly coupled to the emergence of new research\ntools. Today, machine learning (ML)-especially deep learning (DL)-has become a\ntransformative instrument for quantum science and technology. Owing to the\nintrinsic complexity of quantum systems, DL enables efficient exploration of\nlarge parameter spaces, extraction of patterns from experimental data, and\ndata-driven guidance for research directions. These capabilities already\nsupport tasks such as refining quantum control protocols and accelerating the\ndiscovery of materials with targeted quantum properties, making ML/DL literacy\nan essential skill for the next generation of quantum scientists. At the same\ntime, DL's power brings risks: models can overfit noisy data, obscure causal\nstructure, and yield results with limited physical interpretability.\nRecognizing these limitations and deploying mitigation strategies is crucial\nfor scientific rigor. These lecture notes provide a comprehensive,\ngraduate-level introduction to DL for quantum applications, combining\nconceptual exposition with hands-on examples. Organized as a progressive\nsequence, they aim to equip readers to decide when and how to apply DL\neffectively, to understand its practical constraints, and to adapt AI methods\nresponsibly to problems across quantum physics, chemistry, and engineering.",
      "pdf_url": "http://arxiv.org/pdf/2508.10666v1",
      "published": "2025-08-14T14:05:12+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.10666v1",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.NE",
        "physics.comp-ph"
      ]
    },
    {
      "title": "Serial Over Parallel: Learning Continual Unification for Multi-Modal Visual Object Tracking and Benchmarking",
      "authors": [
        "Zhangyong Tang",
        "Tianyang Xu",
        "Xuefeng Zhu",
        "Chunyang Cheng",
        "Tao Zhou",
        "Xiaojun Wu",
        "Josef Kittler"
      ],
      "abstract": "Unifying multiple multi-modal visual object tracking (MMVOT) tasks draws\nincreasing attention due to the complementary nature of different modalities in\nbuilding robust tracking systems. Existing practices mix all data sensor types\nin a single training procedure, structuring a parallel paradigm from the\ndata-centric perspective and aiming for a global optimum on the joint\ndistribution of the involved tasks. However, the absence of a unified benchmark\nwhere all types of data coexist forces evaluations on separated benchmarks,\ncausing \\textit{inconsistency} between training and testing, thus leading to\nperformance \\textit{degradation}. To address these issues, this work advances\nin two aspects: \\ding{182} A unified benchmark, coined as UniBench300, is\nintroduced to bridge the inconsistency by incorporating multiple task data,\nreducing inference passes from three to one and cutting time consumption by\n27\\%. \\ding{183} The unification process is reformulated in a serial format,\nprogressively integrating new tasks. In this way, the performance degradation\ncan be specified as knowledge forgetting of previous tasks, which naturally\naligns with the philosophy of continual learning (CL), motivating further\nexploration of injecting CL into the unification process. Extensive experiments\nconducted on two baselines and four benchmarks demonstrate the significance of\nUniBench300 and the superiority of CL in supporting a stable unification\nprocess. Moreover, while conducting dedicated analyses, the performance\ndegradation is found to be negatively correlated with network capacity.\nAdditionally, modality discrepancies contribute to varying degradation levels\nacross tasks (RGBT > RGBD > RGBE in MMVOT), offering valuable insights for\nfuture multi-modal vision research. Source codes and the proposed benchmark is\navailable at \\textit{https://github.com/Zhangyong-Tang/UniBench300}.",
      "pdf_url": "http://arxiv.org/pdf/2508.10655v1",
      "published": "2025-08-14T13:54:04+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.10655v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "SPHENIC: Topology-Informed Multi-View Clustering for Spatial Transcriptomics",
      "authors": [
        "Chenkai Guo",
        "Yikai Zhu",
        "Jing Yangum",
        "Renxiang Guan",
        "Por Lip Yee",
        "Guangdun Peng",
        "Dayu Hu"
      ],
      "abstract": "By incorporating spatial location information, spatial-transcriptomics\nclustering yields more comprehensive insights into cell subpopulation\nidentification. Despite recent progress, existing methods have at least two\nlimitations: (i) topological learning typically considers only representations\nof individual cells or their interaction graphs; however, spatial\ntranscriptomic profiles are often noisy, making these approaches vulnerable to\nlow-quality topological signals, and (ii) insufficient modeling of spatial\nneighborhood information leads to low-quality spatial embeddings. To address\nthese limitations, we propose SPHENIC, a novel Spatial Persistent Homology\nEnhanced Neighborhood Integrative Clustering method. Specifically, SPHENIC\nincorporates invariant topological features into the clustering network to\nachieve stable representation learning. Additionally, to construct high-quality\nspatial embeddings that reflect the true cellular distribution, we design the\nSpatial Constraint and Distribution Optimization Module (SCDOM). This module\nincreases the similarity between a cell's embedding and those of its spatial\nneighbors, decreases similarity with non-neighboring cells, and thereby\nproduces clustering-friendly spatial embeddings. Extensive experiments on 14\nbenchmark spatial transcriptomic slices demonstrate that SPHENIC achieves\nsuperior performance on the spatial clustering task, outperforming existing\nstate-of-the-art methods by 3.31%-6.54% over the best alternative.",
      "pdf_url": "http://arxiv.org/pdf/2508.10646v1",
      "published": "2025-08-14T13:43:28+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.10646v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Fourier-Guided Attention Upsampling for Image Super-Resolution",
      "authors": [
        "Daejune Choi",
        "Youchan No",
        "Jinhyung Lee",
        "Duksu Kim"
      ],
      "abstract": "We propose Frequency-Guided Attention (FGA), a lightweight upsampling module\nfor single image super-resolution. Conventional upsamplers, such as Sub-Pixel\nConvolution, are efficient but frequently fail to reconstruct high-frequency\ndetails and introduce aliasing artifacts. FGA addresses these issues by\nintegrating (1) a Fourier feature-based Multi-Layer Perceptron (MLP) for\npositional frequency encoding, (2) a cross-resolution Correlation Attention\nLayer for adaptive spatial alignment, and (3) a frequency-domain L1 loss for\nspectral fidelity supervision. Adding merely 0.3M parameters, FGA consistently\nenhances performance across five diverse super-resolution backbones in both\nlightweight and full-capacity scenarios. Experimental results demonstrate\naverage PSNR gains of 0.12~0.14 dB and improved frequency-domain consistency by\nup to 29%, particularly evident on texture-rich datasets. Visual and spectral\nevaluations confirm FGA's effectiveness in reducing aliasing and preserving\nfine details, establishing it as a practical, scalable alternative to\ntraditional upsampling methods.",
      "pdf_url": "http://arxiv.org/pdf/2508.10616v1",
      "published": "2025-08-14T13:13:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.10616v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "MSRS: Adaptive Multi-Subspace Representation Steering for Attribute Alignment in Large Language Models",
      "authors": [
        "Xinyan Jiang",
        "Lin Zhang",
        "Jiayi Zhang",
        "Qingsong Yang",
        "Guimin Hu",
        "Di Wang",
        "Lijie Hu"
      ],
      "abstract": "Activation steering offers a promising approach to controlling the behavior\nof Large Language Models by directly manipulating their internal activations.\nHowever, most existing methods struggle to jointly steer multiple attributes,\noften resulting in interference and undesirable trade-offs. To address this\nchallenge, we propose Multi-Subspace Representation Steering (MSRS), a novel\nframework for effective multi-attribute steering via subspace representation\nfine-tuning. MSRS reduces inter-attribute interference by allocating orthogonal\nsubspaces to each attribute, isolating their influence within the model's\nrepresentation space. MSRS also incorporates a hybrid subspace composition\nstrategy: it combines attribute-specific subspaces for unique steering\ndirections with a shared subspace for common steering directions. A dynamic\nweighting function learns to efficiently integrate these components for precise\ncontrol. During inference, MSRS introduces a token-level steering mechanism\nthat dynamically identifies and intervenes on the most semantically relevant\ntokens, enabling fine-grained behavioral modulation. Experimental results show\nthat MSRS significantly reduces attribute conflicts, surpasses existing methods\nacross a range of attributes, and generalizes effectively to diverse downstream\ntasks.",
      "pdf_url": "http://arxiv.org/pdf/2508.10599v1",
      "published": "2025-08-14T12:40:19+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.10599v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "On Spectral Properties of Gradient-based Explanation Methods",
      "authors": [
        "Amir Mehrpanah",
        "Erik Englesson",
        "Hossein Azizpour"
      ],
      "abstract": "Understanding the behavior of deep networks is crucial to increase our\nconfidence in their results. Despite an extensive body of work for explaining\ntheir predictions, researchers have faced reliability issues, which can be\nattributed to insufficient formalism. In our research, we adopt novel\nprobabilistic and spectral perspectives to formally analyze explanation\nmethods. Our study reveals a pervasive spectral bias stemming from the use of\ngradient, and sheds light on some common design choices that have been\ndiscovered experimentally, in particular, the use of squared gradient and input\nperturbation. We further characterize how the choice of perturbation\nhyperparameters in explanation methods, such as SmoothGrad, can lead to\ninconsistent explanations and introduce two remedies based on our proposed\nformalism: (i) a mechanism to determine a standard perturbation scale, and (ii)\nan aggregation method which we call SpectralLens. Finally, we substantiate our\ntheoretical results through quantitative evaluations.",
      "pdf_url": "http://arxiv.org/pdf/2508.10595v1",
      "published": "2025-08-14T12:37:22+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.10595v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "FreeGAD: A Training-Free yet Effective Approach for Graph Anomaly Detection",
      "authors": [
        "Yunfeng Zhao",
        "Yixin Liu",
        "Shiyuan Li",
        "Qingfeng Chen",
        "Yu Zheng",
        "Shirui Pan"
      ],
      "abstract": "Graph Anomaly Detection (GAD) aims to identify nodes that deviate from the\nmajority within a graph, playing a crucial role in applications such as social\nnetworks and e-commerce. Despite the current advancements in deep\nlearning-based GAD, existing approaches often suffer from high deployment costs\nand poor scalability due to their complex and resource-intensive training\nprocesses. Surprisingly, our empirical findings suggest that the training phase\nof deep GAD methods, commonly perceived as crucial, may actually contribute\nless to anomaly detection performance than expected. Inspired by this, we\npropose FreeGAD, a novel training-free yet effective GAD method. Specifically,\nit leverages an affinity-gated residual encoder to generate anomaly-aware\nrepresentations. Meanwhile, FreeGAD identifies anchor nodes as pseudo-normal\nand anomalous guides, followed by calculating anomaly scores through\nanchor-guided statistical deviations. Extensive experiments demonstrate that\nFreeGAD achieves superior anomaly detection performance, efficiency, and\nscalability on multiple benchmark datasets from diverse domains, without any\ntraining or iterative optimization.",
      "pdf_url": "http://arxiv.org/pdf/2508.10594v1",
      "published": "2025-08-14T12:37:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.10594v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Fake Speech Wild: Detecting Deepfake Speech on Social Media Platform",
      "authors": [
        "Yuankun Xie",
        "Ruibo Fu",
        "Xiaopeng Wang",
        "Zhiyong Wang",
        "Ya Li",
        "Zhengqi Wen",
        "Haonnan Cheng",
        "Long Ye"
      ],
      "abstract": "The rapid advancement of speech generation technology has led to the\nwidespread proliferation of deepfake speech across social media platforms.\nWhile deepfake audio countermeasures (CMs) achieve promising results on public\ndatasets, their performance degrades significantly in cross-domain scenarios.\nTo advance CMs for real-world deepfake detection, we first propose the Fake\nSpeech Wild (FSW) dataset, which includes 254 hours of real and deepfake audio\nfrom four different media platforms, focusing on social media. As CMs, we\nestablish a benchmark using public datasets and advanced selfsupervised\nlearning (SSL)-based CMs to evaluate current CMs in real-world scenarios. We\nalso assess the effectiveness of data augmentation strategies in enhancing CM\nrobustness for detecting deepfake speech on social media. Finally, by\naugmenting public datasets and incorporating the FSW training set, we\nsignificantly advanced real-world deepfake audio detection performance,\nachieving an average equal error rate (EER) of 3.54% across all evaluation\nsets.",
      "pdf_url": "http://arxiv.org/pdf/2508.10559v1",
      "published": "2025-08-14T11:56:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.10559v1",
      "categories": [
        "cs.SD",
        "cs.AI"
      ]
    },
    {
      "title": "PTQAT: A Hybrid Parameter-Efficient Quantization Algorithm for 3D Perception Tasks",
      "authors": [
        "Xinhao Wang",
        "Zhiwei Lin",
        "Zhongyu Xia",
        "Yongtao Wang"
      ],
      "abstract": "Post-Training Quantization (PTQ) and Quantization-Aware Training (QAT)\nrepresent two mainstream model quantization approaches. However, PTQ often\nleads to unacceptable performance degradation in quantized models, while QAT\nimposes substantial GPU memory requirements and extended training time due to\nweight fine-tuning.In this paper, we propose PTQAT, a novel general hybrid\nquantization algorithm for the efficient deployment of 3D perception networks.\nTo address the speed accuracy trade-off between PTQ and QAT, our method selects\ncritical layers for QAT fine-tuning and performs PTQ on the remaining layers.\nContrary to intuition, fine-tuning the layers with smaller output discrepancies\nbefore and after quantization, rather than those with larger discrepancies,\nactually leads to greater improvements in the model's quantization accuracy.\nThis means we better compensate for quantization errors during their\npropagation, rather than addressing them at the point where they occur. The\nproposed PTQAT achieves similar performance to QAT with more efficiency by\nfreezing nearly 50% of quantifiable layers. Additionally, PTQAT is a universal\nquantization method that supports various quantization bit widths (4 bits) as\nwell as different model architectures, including CNNs and Transformers. The\nexperimental results on nuScenes across diverse 3D perception tasks, including\nobject detection, semantic segmentation, and occupancy prediction, show that\nour method consistently outperforms QAT-only baselines. Notably, it achieves\n0.2%-0.9% NDS and 0.3%-1.0% mAP gains in object detection, 0.3%-2.0% mIoU gains\nin semantic segmentation and occupancy prediction while fine-tuning fewer\nweights.",
      "pdf_url": "http://arxiv.org/pdf/2508.10557v1",
      "published": "2025-08-14T11:55:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.10557v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Retrieval-Augmented Prompt for OOD Detection",
      "authors": [
        "Ruisong Han",
        "Zongbo Han",
        "Jiahao Zhang",
        "Mingyue Cheng",
        "Changqing Zhang"
      ],
      "abstract": "Out-of-Distribution (OOD) detection is crucial for the reliable deployment of\nmachine learning models in-the-wild, enabling accurate identification of test\nsamples that differ from the training data distribution. Existing methods rely\non auxiliary outlier samples or in-distribution (ID) data to generate outlier\ninformation for training, but due to limited outliers and their mismatch with\nreal test OOD samples, they often fail to provide sufficient semantic\nsupervision, leading to suboptimal performance. To address this, we propose a\nnovel OOD detection method called Retrieval-Augmented Prompt (RAP). RAP\naugments a pre-trained vision-language model's prompts by retrieving external\nknowledge, offering enhanced semantic supervision for OOD detection. During\ntraining, RAP retrieves descriptive words for outliers based on joint\nsimilarity with external textual knowledge and uses them to augment the model's\nOOD prompts. During testing, RAP dynamically updates OOD prompts in real-time\nbased on the encountered OOD samples, enabling the model to rapidly adapt to\nthe test environment. Our extensive experiments demonstrate that RAP achieves\nstate-of-the-art performance on large-scale OOD detection benchmarks. For\nexample, in 1-shot OOD detection on the ImageNet-1k dataset, RAP reduces the\naverage FPR95 by 7.05% and improves the AUROC by 1.71% compared to previous\nmethods. Additionally, comprehensive ablation studies validate the\neffectiveness of each module and the underlying motivations of our approach.",
      "pdf_url": "http://arxiv.org/pdf/2508.10556v1",
      "published": "2025-08-14T11:52:43+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.10556v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "When Language Overrules: Revealing Text Dominance in Multimodal Large Language Models",
      "authors": [
        "Huyu Wu",
        "Meng Tang",
        "Xinhan Zheng",
        "Haiyun Jiang"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) have demonstrated remarkable\ncapabilities across a diverse range of multimodal tasks. However, these models\nsuffer from a core problem known as text dominance: they depend heavily on text\nfor their inference, while underutilizing other modalities. While prior work\nhas acknowledged this phenomenon in vision-language tasks, often attributing it\nto data biases or model architectures. In this paper, we conduct the first\nsystematic investigation of text dominance across diverse data modalities,\nincluding images, videos, audio, time-series, and graphs. To measure this\nimbalance, we propose two evaluation metrics: the Modality Dominance Index\n(MDI) and the Attention Efficiency Index (AEI). Our comprehensive analysis\nreveals that text dominance is both significant and pervasive across all tested\nmodalities. Our in-depth analysis identifies three underlying causes: attention\ndilution from severe token redundancy in non-textual modalities, the influence\nof fusion architecture design, and task formulations that implicitly favor\ntextual inputs. Furthermore, we propose a simple token compression method that\neffectively rebalances model attention. Applying this method to LLaVA-7B, for\ninstance, drastically reduces its MDI from 10.23 to a well-balanced value of\n0.86. Our analysis and methodological framework offer a foundation for the\ndevelopment of more equitable and comprehensive multimodal language models.",
      "pdf_url": "http://arxiv.org/pdf/2508.10552v1",
      "published": "2025-08-14T11:44:52+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.10552v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Stabilizing Long-term Multi-turn Reinforcement Learning with Gated Rewards",
      "authors": [
        "Zetian Sun",
        "Dongfang Li",
        "Zhuoen Chen",
        "Yuhuai Qin",
        "Baotian Hu"
      ],
      "abstract": "Reward sparsity in long-horizon reinforcement learning (RL) tasks remains a\nsignificant challenge, while existing outcome-based reward shaping struggles to\ndefine meaningful immediate rewards without introducing bias or requiring\nexplicit task decomposition. Alternatively, verification-based reward shaping\nuses stepwise critics, but misalignment between immediate rewards and long-term\nobjectives can lead to reward hacking and suboptimal policies. In this work, we\naddress this problem in the context of software engineering (SWE) tasks, where\nmulti-turn reasoning and rule-based verification are critical. We introduce the\nSWE-oriented RL Framework, a unified system supporting multi-turn interaction,\ndocker-based execution, and customizable reward functions. Additionally, we\npropose Gated Reward Accumulation (G-RA), a novel method that accumulates\nimmediate rewards only when high-level (long-term) rewards meet a predefined\nthreshold, ensuring stable RL optimization. Experiments on SWE-bench Verified\nand kBench demonstrate that G-RA leads to an increase in completion rates\n(47.6\\% \\rightarrow 93.8\\% and 22.0\\% \\rightarrow 86.0\\%) and modification\nrates (19.6\\% \\rightarrow 23.8\\% and 12.0\\% \\rightarrow 42.0\\%), while avoiding\npolicy degradation caused by reward misalignment. Our findings highlight the\nimportance of balanced reward accumulation in long-horizon RL and provide a\npractical solution.",
      "pdf_url": "http://arxiv.org/pdf/2508.10548v1",
      "published": "2025-08-14T11:37:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.10548v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Improving Value-based Process Verifier via Low-Cost Variance Reduction",
      "authors": [
        "Zetian Sun",
        "Dongfang Li",
        "Baotian Hu",
        "Min Zhang"
      ],
      "abstract": "Large language models (LLMs) have achieved remarkable success in a wide range\nof tasks. However, their reasoning capabilities, particularly in complex\ndomains like mathematics, remain a significant challenge. Value-based process\nverifiers, which estimate the probability of a partial reasoning chain leading\nto a correct solution, are a promising approach for improving reasoning.\nNevertheless, their effectiveness is often hindered by estimation error in\ntheir training annotations, a consequence of the limited number of Monte Carlo\n(MC) samples feasible due to the high cost of LLM inference. In this paper, we\nidentify that the estimation error primarily arises from high variance rather\nthan bias, and the MC estimator is a Minimum Variance Unbiased Estimator\n(MVUE). To address the problem, we propose the \\textsc{Com}pound \\textsc{M}onte\n\\textsc{C}arlo \\textsc{S}ampling (ComMCS) method, which constructs an unbiased\nestimator by linearly combining the MC estimators from the current and\nsubsequent steps. Theoretically, we show that our method leads to a predictable\nreduction in variance, while maintaining an unbiased estimation without\nadditional LLM inference cost. We also perform empirical experiments on the\nMATH-500 and GSM8K benchmarks to demonstrate the effectiveness of our method.\nNotably, ComMCS outperforms regression-based optimization method by 2.8 points,\nthe non-variance-reduced baseline by 2.2 points on MATH-500 on Best-of-32\nsampling experiment.",
      "pdf_url": "http://arxiv.org/pdf/2508.10539v1",
      "published": "2025-08-14T11:22:29+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.10539v1",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Diversity First, Quality Later: A Two-Stage Assumption for Language Model Alignment",
      "authors": [
        "Zetian Sun",
        "Dongfang Li",
        "Baotian Hu"
      ],
      "abstract": "The alignment of language models (LMs) with human preferences is critical for\nbuilding reliable AI systems. The problem is typically framed as optimizing an\nLM policy to maximize the expected reward that reflects human preferences.\nRecently, Direct Preference Optimization (DPO) was proposed as a LM alignment\nmethod that directly optimize the policy from static preference data, and\nfurther improved by incorporating on-policy sampling (i.e., preference\ncandidates generated during the training loop) for better LM alignment.\nHowever, we show on-policy data is not always optimal, with systematic\neffectiveness difference emerging between static and on-policy preference\ncandidates. For example, on-policy data can result in a 3$\\times$ effectiveness\ncompared with static data for Llama-3, and a 0.4$\\times$ effectiveness for\nZephyr. To explain the phenomenon, we propose the alignment stage assumption,\nwhich divides the alignment process into two distinct stages: the preference\ninjection stage, which benefits from diverse data, and the preference\nfine-tuning stage, which favors high-quality data. Through theoretical and\nempirical analysis, we characterize these stages and propose an effective\nalgorithm to identify the boundaries between them. We perform experiments on 5\nmodels (Llama, Zephyr, Phi-2, Qwen, Pythia) and 2 alignment methods (DPO,\nSLiC-HF) to show the generalizability of alignment stage assumption and\nboundary measurement.",
      "pdf_url": "http://arxiv.org/pdf/2508.10530v1",
      "published": "2025-08-14T11:05:18+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.10530v1",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Med-GLIP: Advancing Medical Language-Image Pre-training with Large-scale Grounded Dataset",
      "authors": [
        "Ziye Deng",
        "Ruihan He",
        "Jiaxiang Liu",
        "Yuan Wang",
        "Zijie Meng",
        "Songtao Jiang",
        "Yong Xie",
        "Zuozhu Liu"
      ],
      "abstract": "Medical image grounding aims to align natural language phrases with specific\nregions in medical images, serving as a foundational task for intelligent\ndiagnosis, visual question answering (VQA), and automated report generation\n(MRG). However, existing research is constrained by limited modality coverage,\ncoarse-grained annotations, and the absence of a unified, generalizable\ngrounding framework. To address these challenges, we construct a large-scale\nmedical grounding dataset Med-GLIP-5M comprising over 5.3 million region-level\nannotations across seven imaging modalities, covering diverse anatomical\nstructures and pathological findings. The dataset supports both segmentation\nand grounding tasks with hierarchical region labels, ranging from organ-level\nboundaries to fine-grained lesions. Based on this foundation, we propose\nMed-GLIP, a modality-aware grounding framework trained on Med-GLIP-5M. Rather\nthan relying on explicitly designed expert modules, Med-GLIP implicitly\nacquires hierarchical semantic understanding from diverse training data --\nenabling it to recognize multi-granularity structures, such as distinguishing\nlungs from pneumonia lesions. Extensive experiments demonstrate that Med-GLIP\nconsistently outperforms state-of-the-art baselines across multiple grounding\nbenchmarks. Furthermore, integrating its spatial outputs into downstream tasks,\nincluding medical VQA and report generation, leads to substantial performance\ngains. Our dataset will be released soon.",
      "pdf_url": "http://arxiv.org/pdf/2508.10528v1",
      "published": "2025-08-14T11:02:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.10528v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Multi-Sample Anti-Aliasing and Constrained Optimization for 3D Gaussian Splatting",
      "authors": [
        "Zheng Zhou",
        "Jia-Chen Zhang",
        "Yu-Jie Xiong",
        "Chun-Ming Xia"
      ],
      "abstract": "Recent advances in 3D Gaussian splatting have significantly improved\nreal-time novel view synthesis, yet insufficient geometric constraints during\nscene optimization often result in blurred reconstructions of fine-grained\ndetails, particularly in regions with high-frequency textures and sharp\ndiscontinuities. To address this, we propose a comprehensive optimization\nframework integrating multisample anti-aliasing (MSAA) with dual geometric\nconstraints. Our system computes pixel colors through adaptive blending of\nquadruple subsamples, effectively reducing aliasing artifacts in high-frequency\ncomponents. The framework introduces two constraints: (a) an adaptive weighting\nstrategy that prioritizes under-reconstructed regions through dynamic gradient\nanalysis, and (b) gradient differential constraints enforcing geometric\nregularization at object boundaries. This targeted optimization enables the\nmodel to allocate computational resources preferentially to critical regions\nrequiring refinement while maintaining global consistency. Extensive\nexperimental evaluations across multiple benchmarks demonstrate that our method\nachieves state-of-the-art performance in detail preservation, particularly in\npreserving high-frequency textures and sharp discontinuities, while maintaining\nreal-time rendering efficiency. Quantitative metrics and perceptual studies\nconfirm statistically significant improvements over baseline approaches in both\nstructural similarity (SSIM) and perceptual quality (LPIPS).",
      "pdf_url": "http://arxiv.org/pdf/2508.10507v1",
      "published": "2025-08-14T10:14:36+00:00",
      "arxiv_url": "http://arxiv.org/abs/2508.10507v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    }
  ]
}