{
  "last_updated": "2025-03-18T00:46:21.399769",
  "papers": [
    {
      "title": "Centaur: Robust End-to-End Autonomous Driving with Test-Time Training",
      "authors": [
        "Chonghao Sima",
        "Kashyap Chitta",
        "Zhiding Yu",
        "Shiyi Lan",
        "Ping Luo",
        "Andreas Geiger",
        "Hongyang Li",
        "Jose M. Alvarez"
      ],
      "abstract": "How can we rely on an end-to-end autonomous vehicle's complex decision-making\nsystem during deployment? One common solution is to have a ``fallback layer''\nthat checks the planned trajectory for rule violations and replaces it with a\npre-defined safe action if necessary. Another approach involves adjusting the\nplanner's decisions to minimize a pre-defined ``cost function'' using\nadditional system predictions such as road layouts and detected obstacles.\nHowever, these pre-programmed rules or cost functions cannot learn and improve\nwith new training data, often resulting in overly conservative behaviors. In\nthis work, we propose Centaur (Cluster Entropy for Test-time trAining using\nUncertainty) which updates a planner's behavior via test-time training, without\nrelying on hand-engineered rules or cost functions. Instead, we measure and\nminimize the uncertainty in the planner's decisions. For this, we develop a\nnovel uncertainty measure, called Cluster Entropy, which is simple,\ninterpretable, and compatible with state-of-the-art planning algorithms. Using\ndata collected at prior test-time time-steps, we perform an update to the\nmodel's parameters using a gradient that minimizes the Cluster Entropy. With\nonly this sole gradient update prior to inference, Centaur exhibits significant\nimprovements, ranking first on the navtest leaderboard with notable gains in\nsafety-critical metrics such as time to collision. To provide detailed insights\non a per-scenario basis, we also introduce navsafe, a challenging new\nbenchmark, which highlights previously undiscovered failure modes of driving\nmodels.",
      "pdf_url": "http://arxiv.org/pdf/2503.11650v1",
      "published": "2025-03-14T17:59:41+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.11650v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ]
    },
    {
      "title": "Enhancing Deep Learning Based Structured Illumination Microscopy Reconstruction with Light Field Awareness",
      "authors": [
        "Long-Kun Shan",
        "Ze-Hao Wang",
        "Tong-Tian Weng",
        "Xiang-Dong Chen",
        "Fang-Wen Sun"
      ],
      "abstract": "Structured illumination microscopy (SIM) is a pivotal technique for dynamic\nsubcellular imaging in live cells. Conventional SIM reconstruction algorithms\ndepend on accurately estimating the illumination pattern and can introduce\nartefacts when this estimation is imprecise. Although recent deep\nlearning-based SIM reconstruction methods have improved speed, accuracy, and\nrobustness, they often struggle with out-of-distribution data. To address this\nlimitation, we propose an Awareness-of-Light-field SIM (AL-SIM) reconstruction\napproach that directly estimates the actual light field to correct for errors\narising from data distribution shifts. Through comprehensive experiments on\nboth simulated filament structures and live BSC1 cells, our method demonstrates\na 7% reduction in the normalized root mean square error (NRMSE) and\nsubstantially lowers reconstruction artefacts. By minimizing these artefacts\nand improving overall accuracy, AL-SIM broadens the applicability of SIM for\ncomplex biological systems.",
      "pdf_url": "http://arxiv.org/pdf/2503.11640v1",
      "published": "2025-03-14T17:56:49+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.11640v1",
      "categories": [
        "physics.optics",
        "cs.AI"
      ]
    },
    {
      "title": "ASMA-Tune: Unlocking LLMs' Assembly Code Comprehension via Structural-Semantic Instruction Tuning",
      "authors": [
        "Xinyi Wang",
        "Jiashui Wang",
        "Peng Chen",
        "Jinbo Su",
        "Yanming Liu",
        "Long Liu",
        "Yangdong Wang",
        "Qiyuan Chen",
        "Kai Yun",
        "Chunfu Jia"
      ],
      "abstract": "Analysis and comprehension of assembly code are crucial in various\napplications, such as reverse engineering. However, the low information density\nand lack of explicit syntactic structures in assembly code pose significant\nchallenges. Pioneering approaches with masked language modeling (MLM)-based\nmethods have been limited by facilitating natural language interaction. While\nrecent methods based on decoder-focused large language models (LLMs) have\nsignificantly enhanced semantic representation, they still struggle to capture\nthe nuanced and sparse semantics in assembly code. In this paper, we propose\nAssembly Augmented Tuning (ASMA-Tune), an end-to-end structural-semantic\ninstruction-tuning framework. Our approach synergizes encoder architectures\nwith decoder-based LLMs through projector modules to enable comprehensive code\nunderstanding. Experiments show that ASMA-Tune outperforms existing benchmarks,\nsignificantly enhancing assembly code comprehension and instruction-following\nabilities. Our model and dataset are public at\nhttps://github.com/wxy3596/ASMA-Tune.",
      "pdf_url": "http://arxiv.org/pdf/2503.11617v1",
      "published": "2025-03-14T17:36:08+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.11617v1",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "Broaden your SCOPE! Efficient Multi-turn Conversation Planning for LLMs using Semantic Space",
      "authors": [
        "Zhiliang Chen",
        "Xinyuan Niu",
        "Chuan-Sheng Foo",
        "Bryan Kian Hsiang Low"
      ],
      "abstract": "Large language models (LLMs) are used in chatbots or AI assistants to hold\nconversations with a human user. In such applications, the quality (e.g., user\nengagement, safety) of a conversation is important and can only be exactly\nknown at the end of the conversation. To maximize its expected quality,\nconversation planning reasons about the stochastic transitions within a\nconversation to select the optimal LLM response at each turn. Existing\nsimulation-based conversation planning algorithms typically select the optimal\nresponse by simulating future conversations with a large number of LLM queries\nat every turn. However, this process is extremely time-consuming and hence\nimpractical for real-time conversations. This paper presents a novel approach\ncalled Semantic space COnversation Planning with improved Efficiency (SCOPE)\nthat exploits the dense semantic representation of conversations to perform\nconversation planning efficiently. In particular, SCOPE models the stochastic\ntransitions in conversation semantics and their associated rewards to plan\nentirely within the semantic space. This allows us to select the optimal LLM\nresponse at every conversation turn without needing additional LLM queries for\nsimulation. As a result, SCOPE can perform conversation planning 70 times\nfaster than conventional simulation-based planning algorithms when applied to a\nwide variety of conversation starters and two reward functions seen in the real\nworld, yet achieving a higher reward within a practical planning budget. Our\ncode can be found at: https://github.com/chenzhiliang94/convo-plan-SCOPE.",
      "pdf_url": "http://arxiv.org/pdf/2503.11586v1",
      "published": "2025-03-14T16:55:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.11586v1",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Synthesizing Access Control Policies using Large Language Models",
      "authors": [
        "Adarsh Vatsa",
        "Pratyush Patel",
        "William Eiers"
      ],
      "abstract": "Cloud compute systems allow administrators to write access control policies\nthat govern access to private data. While policies are written in convenient\nlanguages, such as AWS Identity and Access Management Policy Language, manually\nwritten policies often become complex and error prone. In this paper, we\ninvestigate whether and how well Large Language Models (LLMs) can be used to\nsynthesize access control policies. Our investigation focuses on the task of\ntaking an access control request specification and zero-shot prompting LLMs to\nsynthesize a well-formed access control policy which correctly adheres to the\nrequest specification. We consider two scenarios, one which the request\nspecification is given as a concrete list of requests to be allowed or denied,\nand another in which a natural language description is used to specify sets of\nrequests to be allowed or denied. We then argue that for zero-shot prompting,\nmore precise and structured prompts using a syntax based approach are necessary\nand experimentally show preliminary results validating our approach.",
      "pdf_url": "http://arxiv.org/pdf/2503.11573v1",
      "published": "2025-03-14T16:40:25+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.11573v1",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CR",
        "68P25"
      ]
    },
    {
      "title": "Implicit Bias-Like Patterns in Reasoning Models",
      "authors": [
        "Messi H. J. Lee",
        "Calvin K. Lai"
      ],
      "abstract": "Implicit bias refers to automatic or spontaneous mental processes that shape\nperceptions, judgments, and behaviors. Previous research examining `implicit\nbias' in large language models (LLMs) has often approached the phenomenon\ndifferently than how it is studied in humans by focusing primarily on model\noutputs rather than on model processing. To examine model processing, we\npresent a method called the Reasoning Model Implicit Association Test (RM-IAT)\nfor studying implicit bias-like patterns in reasoning models: LLMs that employ\nstep-by-step reasoning to solve complex tasks. Using this method, we find that\nreasoning models require more tokens when processing association-incompatible\ninformation compared to association-compatible information. These findings\nsuggest AI systems harbor patterns in processing information that are analogous\nto human implicit bias. We consider the implications of these implicit\nbias-like patterns for their deployment in real-world applications.",
      "pdf_url": "http://arxiv.org/pdf/2503.11572v1",
      "published": "2025-03-14T16:40:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.11572v1",
      "categories": [
        "cs.CY",
        "cs.AI"
      ]
    },
    {
      "title": "RASA: Replace Anyone, Say Anything -- A Training-Free Framework for Audio-Driven and Universal Portrait Video Editing",
      "authors": [
        "Tianrui Pan",
        "Lin Liu",
        "Jie Liu",
        "Xiaopeng Zhang",
        "Jie Tang",
        "Gangshan Wu",
        "Qi Tian"
      ],
      "abstract": "Portrait video editing focuses on modifying specific attributes of portrait\nvideos, guided by audio or video streams. Previous methods typically either\nconcentrate on lip-region reenactment or require training specialized models to\nextract keypoints for motion transfer to a new identity. In this paper, we\nintroduce a training-free universal portrait video editing framework that\nprovides a versatile and adaptable editing strategy. This framework supports\nportrait appearance editing conditioned on the changed first reference frame,\nas well as lip editing conditioned on varied speech, or a combination of both.\nIt is based on a Unified Animation Control (UAC) mechanism with source\ninversion latents to edit the entire portrait, including visual-driven shape\ncontrol, audio-driven speaking control, and inter-frame temporal control.\nFurthermore, our method can be adapted to different scenarios by adjusting the\ninitial reference frame, enabling detailed editing of portrait videos with\nspecific head rotations and facial expressions. This comprehensive approach\nensures a holistic and flexible solution for portrait video editing. The\nexperimental results show that our model can achieve more accurate and\nsynchronized lip movements for the lip editing task, as well as more flexible\nmotion transfer for the appearance editing task. Demo is available at\nhttps://alice01010101.github.io/RASA/.",
      "pdf_url": "http://arxiv.org/pdf/2503.11571v1",
      "published": "2025-03-14T16:39:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.11571v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Designing Neural Synthesizers for Low Latency Interaction",
      "authors": [
        "Franco Caspe",
        "Jordie Shier",
        "Mark Sandler",
        "Charalampos Saitis",
        "Andrew McPherson"
      ],
      "abstract": "Neural Audio Synthesis (NAS) models offer interactive musical control over\nhigh-quality, expressive audio generators. While these models can operate in\nreal-time, they often suffer from high latency, making them unsuitable for\nintimate musical interaction. The impact of architectural choices in deep\nlearning models on audio latency remains largely unexplored in the NAS\nliterature. In this work, we investigate the sources of latency and jitter\ntypically found in interactive NAS models. We then apply this analysis to the\ntask of timbre transfer using RAVE, a convolutional variational autoencoder for\naudio waveforms introduced by Caillon et al. in 2021. Finally, we present an\niterative design approach for optimizing latency. This culminates with a model\nwe call BRAVE (Bravely Realtime Audio Variational autoEncoder), which is\nlow-latency and exhibits better pitch and loudness replication while showing\ntimbre modification capabilities similar to RAVE. We implement it in a\nspecialized inference framework for low-latency, real-time inference and\npresent a proof-of-concept audio plugin compatible with audio signals from\nmusical instruments. We expect the challenges and guidelines described in this\ndocument to support NAS researchers in designing models for low-latency\ninference from the ground up, enriching the landscape of possibilities for\nmusicians.",
      "pdf_url": "http://arxiv.org/pdf/2503.11562v1",
      "published": "2025-03-14T16:30:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.11562v1",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ]
    },
    {
      "title": "FLASHμ: Fast Localizing And Sizing of Holographic Microparticles",
      "authors": [
        "Ayush Paliwal",
        "Oliver Schlenczek",
        "Birte Thiede",
        "Manuel Santos Pereira",
        "Katja Stieger",
        "Eberhard Bodenschatz",
        "Gholamhossein Bagheri",
        "Alexander Ecker"
      ],
      "abstract": "Reconstructing the 3D location and size of microparticles from diffraction\nimages - holograms - is a computationally expensive inverse problem that has\ntraditionally been solved using physics-based reconstruction methods. More\nrecently, researchers have used machine learning methods to speed up the\nprocess. However, for small particles in large sample volumes the performance\nof these methods falls short of standard physics-based reconstruction methods.\nHere we designed a two-stage neural network architecture, FLASH$\\mu$, to detect\nsmall particles (6-100$\\mu$m) from holograms with large sample depths up to\n20cm. Trained only on synthetic data with added physical noise, our method\nreliably detects particles of at least 9$\\mu$m diameter in real holograms,\ncomparable to the standard reconstruction-based approaches while operating on\nsmaller crops, at quarter of the original resolution and providing roughly a\n600-fold speedup. In addition to introducing a novel approach to a non-local\nobject detection or signal demixing problem, our work could enable low-cost,\nreal-time holographic imaging setups.",
      "pdf_url": "http://arxiv.org/pdf/2503.11538v1",
      "published": "2025-03-14T16:04:10+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.11538v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "physics.ao-ph",
        "physics.optics"
      ]
    },
    {
      "title": "Potential of large language model-powered nudges for promoting daily water and energy conservation",
      "authors": [
        "Zonghan Li",
        "Song Tong",
        "Yi Liu",
        "Kaiping Peng",
        "Chunyan Wang"
      ],
      "abstract": "The increasing amount of pressure related to water and energy shortages has\nincreased the urgency of cultivating individual conservation behaviors. While\nthe concept of nudging, i.e., providing usage-based feedback, has shown promise\nin encouraging conservation behaviors, its efficacy is often constrained by the\nlack of targeted and actionable content. This study investigates the impact of\nthe use of large language models (LLMs) to provide tailored conservation\nsuggestions for conservation intentions and their rationale. Through a survey\nexperiment with 1,515 university participants, we compare three virtual nudging\nscenarios: no nudging, traditional nudging with usage statistics, and\nLLM-powered nudging with usage statistics and personalized conservation\nsuggestions. The results of statistical analyses and causal forest modeling\nreveal that nudging led to an increase in conservation intentions among\n86.9%-98.0% of the participants. LLM-powered nudging achieved a maximum\nincrease of 18.0% in conservation intentions, surpassing traditional nudging by\n88.6%. Furthermore, structural equation modeling results reveal that exposure\nto LLM-powered nudges enhances self-efficacy and outcome expectations while\ndiminishing dependence on social norms, thereby increasing intrinsic motivation\nto conserve. These findings highlight the transformative potential of LLMs in\npromoting individual water and energy conservation, representing a new frontier\nin the design of sustainable behavioral interventions and resource management.",
      "pdf_url": "http://arxiv.org/pdf/2503.11531v1",
      "published": "2025-03-14T15:58:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.11531v1",
      "categories": [
        "cs.CY",
        "cs.AI"
      ]
    },
    {
      "title": "Prompt Injection Detection and Mitigation via AI Multi-Agent NLP Frameworks",
      "authors": [
        "Diego Gosmar",
        "Deborah A. Dahl",
        "Dario Gosmar"
      ],
      "abstract": "Prompt injection constitutes a significant challenge for generative AI\nsystems by inducing unintended outputs. We introduce a multi-agent NLP\nframework specifically designed to address prompt injection vulnerabilities\nthrough layered detection and enforcement mechanisms. The framework\norchestrates specialized agents for generating responses, sanitizing outputs,\nand enforcing policy compliance. Evaluation on 500 engineered injection prompts\ndemonstrates a marked reduction in injection success and policy breaches. Novel\nmetrics, including Injection Success Rate (ISR), Policy Override Frequency\n(POF), Prompt Sanitization Rate (PSR), and Compliance Consistency Score (CCS),\nare proposed to derive a composite Total Injection Vulnerability Score (TIVS).\nThe system utilizes the OVON (Open Voice Network) framework for inter-agent\ncommunication via structured JSON messages, extending a previously established\nmulti-agent architecture from hallucination mitigation to address the unique\nchallenges of prompt injection.",
      "pdf_url": "http://arxiv.org/pdf/2503.11517v1",
      "published": "2025-03-14T15:41:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.11517v1",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.MA"
      ]
    },
    {
      "title": "HiTVideo: Hierarchical Tokenizers for Enhancing Text-to-Video Generation with Autoregressive Large Language Models",
      "authors": [
        "Ziqin Zhou",
        "Yifan Yang",
        "Yuqing Yang",
        "Tianyu He",
        "Houwen Peng",
        "Kai Qiu",
        "Qi Dai",
        "Lili Qiu",
        "Chong Luo",
        "Lingqiao Liu"
      ],
      "abstract": "Text-to-video generation poses significant challenges due to the inherent\ncomplexity of video data, which spans both temporal and spatial dimensions. It\nintroduces additional redundancy, abrupt variations, and a domain gap between\nlanguage and vision tokens while generation. Addressing these challenges\nrequires an effective video tokenizer that can efficiently encode video data\nwhile preserving essential semantic and spatiotemporal information, serving as\na critical bridge between text and vision. Inspired by the observation in\nVQ-VAE-2 and workflows of traditional animation, we propose HiTVideo for\ntext-to-video generation with hierarchical tokenizers. It utilizes a 3D causal\nVAE with a multi-layer discrete token framework, encoding video content into\nhierarchically structured codebooks. Higher layers capture semantic information\nwith higher compression, while lower layers focus on fine-grained\nspatiotemporal details, striking a balance between compression efficiency and\nreconstruction quality. Our approach efficiently encodes longer video sequences\n(e.g., 8 seconds, 64 frames), reducing bits per pixel (bpp) by approximately\n70\\% compared to baseline tokenizers, while maintaining competitive\nreconstruction quality. We explore the trade-offs between compression and\nreconstruction, while emphasizing the advantages of high-compressed semantic\ntokens in text-to-video tasks. HiTVideo aims to address the potential\nlimitations of existing video tokenizers in text-to-video generation tasks,\nstriving for higher compression ratios and simplify LLMs modeling under\nlanguage guidance, offering a scalable and promising framework for advancing\ntext to video generation. Demo page:\nhttps://ziqinzhou66.github.io/project/HiTVideo.",
      "pdf_url": "http://arxiv.org/pdf/2503.11513v1",
      "published": "2025-03-14T15:36:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.11513v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Alzheimer's Disease Classification Using Retinal OCT: TransnetOCT and Swin Transformer Models",
      "authors": [
        "Siva Manohar Reddy Kesu",
        "Neelam Sinha",
        "Hariharan Ramasangu",
        "Thomas Gregor Issac"
      ],
      "abstract": "Retinal optical coherence tomography (OCT) images are the biomarkers for\nneurodegenerative diseases, which are rising in prevalence. Early detection of\nAlzheimer's disease using retinal OCT is a primary challenging task. This work\nutilizes advanced deep learning techniques to classify retinal OCT images of\nsubjects with Alzheimer's disease (AD) and healthy controls (CO). The goal is\nto enhance diagnostic capabilities through efficient image analysis. In the\nproposed model, Raw OCT images have been preprocessed with ImageJ and given to\nvarious deep-learning models to evaluate the accuracy. The best classification\narchitecture is TransNetOCT, which has an average accuracy of 98.18% for input\nOCT images and 98.91% for segmented OCT images for five-fold cross-validation\ncompared to other models, and the Swin Transformer model has achieved an\naccuracy of 93.54%. The evaluation accuracy metric demonstrated TransNetOCT and\nSwin transformer models capability to classify AD and CO subjects reliably,\ncontributing to the potential for improved diagnostic processes in clinical\nsettings.",
      "pdf_url": "http://arxiv.org/pdf/2503.11511v1",
      "published": "2025-03-14T15:34:37+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.11511v1",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Unicorn: A Universal and Collaborative Reinforcement Learning Approach Towards Generalizable Network-Wide Traffic Signal Control",
      "authors": [
        "Yifeng Zhang",
        "Yilin Liu",
        "Ping Gong",
        "Peizhuo Li",
        "Mingfeng Fan",
        "Guillaume Sartoretti"
      ],
      "abstract": "Adaptive traffic signal control (ATSC) is crucial in reducing congestion,\nmaximizing throughput, and improving mobility in rapidly growing urban areas.\nRecent advancements in parameter-sharing multi-agent reinforcement learning\n(MARL) have greatly enhanced the scalable and adaptive optimization of complex,\ndynamic flows in large-scale homogeneous networks. However, the inherent\nheterogeneity of real-world traffic networks, with their varied intersection\ntopologies and interaction dynamics, poses substantial challenges to achieving\nscalable and effective ATSC across different traffic scenarios. To address\nthese challenges, we present Unicorn, a universal and collaborative MARL\nframework designed for efficient and adaptable network-wide ATSC. Specifically,\nwe first propose a unified approach to map the states and actions of\nintersections with varying topologies into a common structure based on traffic\nmovements. Next, we design a Universal Traffic Representation (UTR) module with\na decoder-only network for general feature extraction, enhancing the model's\nadaptability to diverse traffic scenarios. Additionally, we incorporate an\nIntersection Specifics Representation (ISR) module, designed to identify key\nlatent vectors that represent the unique intersection's topology and traffic\ndynamics through variational inference techniques. To further refine these\nlatent representations, we employ a contrastive learning approach in a\nself-supervised manner, which enables better differentiation of\nintersection-specific features. Moreover, we integrate the state-action\ndependencies of neighboring agents into policy optimization, which effectively\ncaptures dynamic agent interactions and facilitates efficient regional\ncollaboration. Our results show that Unicorn outperforms other methods across\nvarious evaluation metrics, highlighting its potential in complex, dynamic\ntraffic networks.",
      "pdf_url": "http://arxiv.org/pdf/2503.11488v1",
      "published": "2025-03-14T15:13:42+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.11488v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ]
    },
    {
      "title": "Heterogeneous Causal Discovery of Repeated Undesirable Health Outcomes",
      "authors": [
        "Shishir Adhikari",
        "Guido Muscioni",
        "Mark Shapiro",
        "Plamen Petrov",
        "Elena Zheleva"
      ],
      "abstract": "Understanding factors triggering or preventing undesirable health outcomes\nacross patient subpopulations is essential for designing targeted\ninterventions. While randomized controlled trials and expert-led patient\ninterviews are standard methods for identifying these factors, they can be\ntime-consuming and infeasible. Causal discovery offers an alternative to\nconventional approaches by generating cause-and-effect hypotheses from\nobservational data. However, it often relies on strong or untestable\nassumptions, which can limit its practical application. This work aims to make\ncausal discovery more practical by considering multiple assumptions and\nidentifying heterogeneous effects. We formulate the problem of discovering\ncauses and effect modifiers of an outcome, where effect modifiers are contexts\n(e.g., age groups) with heterogeneous causal effects. Then, we present a novel,\nend-to-end framework that incorporates an ensemble of causal discovery\nalgorithms and estimation of heterogeneous effects to discover causes and\neffect modifiers that trigger or inhibit the outcome. We demonstrate that the\nensemble approach improves robustness by enhancing recall of causal factors\nwhile maintaining precision. Our study examines the causes of repeat emergency\nroom visits for diabetic patients and hospital readmissions for ICU patients.\nOur framework generates causal hypotheses consistent with existing literature\nand can help practitioners identify potential interventions and patient\nsubpopulations to focus on.",
      "pdf_url": "http://arxiv.org/pdf/2503.11477v1",
      "published": "2025-03-14T15:05:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.11477v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Research Vision: Multi-Agent Path Planning for Cops And Robbers Via Reactive Synthesis",
      "authors": [
        "William Fishell",
        "Andoni Rodriguez",
        "Mark Santolucito"
      ],
      "abstract": "We propose the problem of multi-agent path planning for a generalization of\nthe classic Cops and Robbers game via reactive synthesis. Specifically, through\nthe application of LTLt and Coordination Synthesis, we aim to check whether\nvarious Cops and Robbers games are realizable (a strategy exists for the cops\nwhich guarantees they catch the robbers). Additionally, we construct this\nstrategy as an executable program for the multiple system players in our games.\nIn this paper we formalize the problem space, and propose potential directions\nfor solutions. We also show how our formalization of this generalized cops and\nrobbers game can be mapped to a broad range of other problems in the reactive\nprogram synthesis space.",
      "pdf_url": "http://arxiv.org/pdf/2503.11475v1",
      "published": "2025-03-14T15:03:32+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.11475v1",
      "categories": [
        "cs.LO",
        "cs.AI"
      ]
    },
    {
      "title": "Integrating LLMs in Gamified Systems",
      "authors": [
        "Carlos J. Costa"
      ],
      "abstract": "In this work, a thorough mathematical framework for incorporating Large\nLanguage Models (LLMs) into gamified systems is presented with an emphasis on\nimproving task dynamics, user engagement, and reward systems. Personalized\nfeedback, adaptive learning, and dynamic content creation are all made possible\nby integrating LLMs and are crucial for improving user engagement and system\nperformance. A simulated environment tests the framework's adaptability and\ndemonstrates its potential for real-world applications in various industries,\nincluding business, healthcare, and education. The findings demonstrate how\nLLMs can offer customized experiences that raise system effectiveness and user\nretention. This study also examines the difficulties this framework aims to\nsolve, highlighting its importance in maximizing involvement and encouraging\nsustained behavioral change in a range of sectors.",
      "pdf_url": "http://arxiv.org/pdf/2503.11458v1",
      "published": "2025-03-14T14:47:04+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.11458v1",
      "categories": [
        "cs.AI",
        "cs.CY"
      ]
    },
    {
      "title": "Cerebrum (AIOS SDK): A Platform for Agent Development, Deployment, Distribution, and Discovery",
      "authors": [
        "Balaji Rama",
        "Kai Mei",
        "Yongfeng Zhang"
      ],
      "abstract": "Autonomous LLM-based agents have emerged as a powerful paradigm for complex\ntask execution, yet the field lacks standardized tools for development,\ndeployment, distribution and discovery of agents. We present Cerebrum, an Agent\nSDK for AIOS that addresses this gap through three key components: (1) a\ncomprehensive SDK featuring a modular four-layer architecture for agent\ndevelopment, encompassing LLM, memory, storage, and tool management; (2) a\ncommunity-driven Agent Hub for sharing and discovering agents, complete with\nversion control and dependency management; (3) an interactive web interface for\ntesting and evaluating agents. The platform's effectiveness is demonstrated\nthrough implementations of various agent architectures, including Chain of\nThought (CoT), ReAct, and tool-use agents. Cerebrum advances the field by\nproviding a unified framework that standardizes agent development while\nmaintaining flexibility for researchers and developers to innovate and\ndistribute their agents. The live website is at https://app.aios.foundation,\nthe code is at https://github.com/agiresearch/Cerebrum, and video is at\nhttps://app.aios.foundation/video-demo.",
      "pdf_url": "http://arxiv.org/pdf/2503.11444v1",
      "published": "2025-03-14T14:29:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.11444v1",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.CL",
        "cs.OS"
      ]
    },
    {
      "title": "Preference Elicitation for Multi-objective Combinatorial Optimization with Active Learning and Maximum Likelihood Estimation",
      "authors": [
        "Marianne Defresne",
        "Jayanta Mandi",
        "Tias Guns"
      ],
      "abstract": "Real-life combinatorial optimization problems often involve several\nconflicting objectives, such as price, product quality and sustainability. A\ncomputationally-efficient way to tackle multiple objectives is to aggregate\nthem into a single-objective function, such as a linear combination. However,\ndefining the weights of the linear combination upfront is hard; alternatively,\nthe use of interactive learning methods that ask users to compare candidate\nsolutions is highly promising. The key challenges are to generate candidates\nquickly, to learn an objective function that leads to high-quality solutions\nand to do so with few user interactions. We build upon the Constructive\nPreference Elicitation framework and show how each of the three properties can\nbe improved: to increase the interaction speed we investigate using pools of\n(relaxed) solutions, to improve the learning we adopt Maximum Likelihood\nEstimation of a Bradley-Terry preference model; and to reduce the number of\nuser interactions, we select the pair of candidates to compare with an\nensemble-based acquisition function inspired from Active Learning. Our careful\nexperimentation demonstrates each of these improvements: on a PC configuration\ntask and a realistic multi-instance routing problem, our method selects queries\nfaster, needs fewer queries and synthesizes higher-quality combinatorial\nsolutions than previous CPE methods.",
      "pdf_url": "http://arxiv.org/pdf/2503.11435v1",
      "published": "2025-03-14T14:24:27+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.11435v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Adaptive Torque Control of Exoskeletons under Spasticity Conditions via Reinforcement Learning",
      "authors": [
        "Andrés Chavarrías",
        "David Rodriguez-Cianca",
        "Pablo Lanillos"
      ],
      "abstract": "Spasticity is a common movement disorder symptom in individuals with cerebral\npalsy, hereditary spastic paraplegia, spinal cord injury and stroke, being one\nof the most disabling features in the progression of these diseases. Despite\nthe potential benefit of using wearable robots to treat spasticity, their use\nis not currently recommended to subjects with a level of spasticity above\n${1^+}$ on the Modified Ashworth Scale. The varying dynamics of this\nvelocity-dependent tonic stretch reflex make it difficult to deploy safe\npersonalized controllers. Here, we describe a novel adaptive torque controller\nvia deep reinforcement learning (RL) for a knee exoskeleton under joint\nspasticity conditions, which accounts for task performance and interaction\nforces reduction. To train the RL agent, we developed a digital twin, including\na musculoskeletal-exoskeleton system with joint misalignment and a\ndifferentiable spastic reflexes model for the muscles activation. Results for a\nsimulated knee extension movement showed that the agent learns to control the\nexoskeleton for individuals with different levels of spasticity. The proposed\ncontroller was able to reduce maximum torques applied to the human joint under\nspastic conditions by an average of 10.6\\% and decreases the root mean square\nuntil the settling time by 8.9\\% compared to a conventional compliant\ncontroller.",
      "pdf_url": "http://arxiv.org/pdf/2503.11433v1",
      "published": "2025-03-14T14:22:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.11433v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ]
    },
    {
      "title": "Combining Causal Models for More Accurate Abstractions of Neural Networks",
      "authors": [
        "Theodora-Mara Pîslar",
        "Sara Magliacane",
        "Atticus Geiger"
      ],
      "abstract": "Mechanistic interpretability aims to reverse engineer neural networks by\nuncovering which high-level algorithms they implement. Causal abstraction\nprovides a precise notion of when a network implements an algorithm, i.e., a\ncausal model of the network contains low-level features that realize the\nhigh-level variables in a causal model of the algorithm. A typical problem in\npractical settings is that the algorithm is not an entirely faithful\nabstraction of the network, meaning it only partially captures the true\nreasoning process of a model. We propose a solution where we combine different\nsimple high-level models to produce a more faithful representation of the\nnetwork. Through learning this combination, we can model neural networks as\nbeing in different computational states depending on the input provided, which\nwe show is more accurate to GPT 2-small fine-tuned on two toy tasks. We observe\na trade-off between the strength of an interpretability hypothesis, which we\ndefine in terms of the number of inputs explained by the high-level models, and\nits faithfulness, which we define as the interchange intervention accuracy. Our\nmethod allows us to modulate between the two, providing the most accurate\ncombination of models that describe the behavior of a neural network given a\nfaithfulness level.",
      "pdf_url": "http://arxiv.org/pdf/2503.11429v1",
      "published": "2025-03-14T14:14:43+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.11429v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "From Generative AI to Innovative AI: An Evolutionary Roadmap",
      "authors": [
        "Seyed Mahmoud Sajjadi Mohammadabadi"
      ],
      "abstract": "This paper explores the critical transition from Generative Artificial\nIntelligence (GenAI) to Innovative Artificial Intelligence (InAI). While recent\nadvancements in GenAI have enabled systems to produce high-quality content\nacross various domains, these models often lack the capacity for true\ninnovation. In this context, innovation is defined as the ability to generate\nnovel and useful outputs that go beyond mere replication of learned data. The\npaper examines this shift and proposes a roadmap for developing AI systems that\ncan generate content and engage in autonomous problem-solving and creative\nideation. The work provides both theoretical insights and practical strategies\nfor advancing AI to a stage where it can genuinely innovate, contributing\nmeaningfully to science, technology, and the arts.",
      "pdf_url": "http://arxiv.org/pdf/2503.11419v1",
      "published": "2025-03-14T14:03:28+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.11419v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "A Neural Network Architecture Based on Attention Gate Mechanism for 3D Magnetotelluric Forward Modeling",
      "authors": [
        "Xin Zhong",
        "Weiwei Ling",
        "Kejia Pan",
        "Pinxia Wu",
        "Jiajing Zhang",
        "Zhiliang Zhan",
        "Wenbo Xiao"
      ],
      "abstract": "Traditional three-dimensional magnetotelluric (MT) numerical forward modeling\nmethods, such as the finite element method (FEM) and finite volume method\n(FVM), suffer from high computational costs and low efficiency due to\nlimitations in mesh refinement and computational resources. We propose a novel\nneural network architecture named MTAGU-Net, which integrates an attention\ngating mechanism for 3D MT forward modeling. Specifically, a dual-path\nattention gating module is designed based on forward response data images and\nembedded in the skip connections between the encoder and decoder. This module\nenables the fusion of critical anomaly information from shallow feature maps\nduring the decoding of deep feature maps, significantly enhancing the network's\ncapability to extract features from anomalous regions. Furthermore, we\nintroduce a synthetic model generation method utilizing 3D Gaussian random\nfield (GRF), which accurately replicates the electrical structures of\nreal-world geological scenarios with high fidelity. Numerical experiments\ndemonstrate that MTAGU-Net outperforms conventional 3D U-Net in terms of\nconvergence stability and prediction accuracy, with the structural similarity\nindex (SSIM) of the forward response data consistently exceeding 0.98.\nMoreover, the network can accurately predict forward response data on\npreviously unseen datasets models, demonstrating its strong generalization\nability and validating the feasibility and effectiveness of this method in\npractical applications.",
      "pdf_url": "http://arxiv.org/pdf/2503.11408v1",
      "published": "2025-03-14T13:48:25+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.11408v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Towards A Correct Usage of Cryptography in Semantic Watermarks for Diffusion Models",
      "authors": [
        "Jonas Thietke",
        "Andreas Müller",
        "Denis Lukovnikov",
        "Asja Fischer",
        "Erwin Quiring"
      ],
      "abstract": "Semantic watermarking methods enable the direct integration of watermarks\ninto the generation process of latent diffusion models by only modifying the\ninitial latent noise. One line of approaches building on Gaussian Shading\nrelies on cryptographic primitives to steer the sampling process of the latent\nnoise. However, we identify several issues in the usage of cryptographic\ntechniques in Gaussian Shading, particularly in its proof of lossless\nperformance and key management, causing ambiguity in follow-up works, too. In\nthis work, we therefore revisit the cryptographic primitives for semantic\nwatermarking. We introduce a novel, general proof of lossless performance based\non IND\\$-CPA security for semantic watermarks. We then discuss the\nconfiguration of the cryptographic primitives in semantic watermarks with\nrespect to security, efficiency, and generation quality.",
      "pdf_url": "http://arxiv.org/pdf/2503.11404v1",
      "published": "2025-03-14T13:45:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.11404v1",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Hierarchical Information-Guided Spatio-Temporal Mamba for Stock Time Series Forecasting",
      "authors": [
        "Wenbo Yan",
        "Shurui Wang",
        "Ying Tan"
      ],
      "abstract": "Mamba has demonstrated excellent performance in various time series\nforecasting tasks due to its superior selection mechanism. Nevertheless,\nconventional Mamba-based models encounter significant challenges in accurately\npredicting stock time series, as they fail to adequately capture both the\noverarching market dynamics and the intricate interdependencies among\nindividual stocks. To overcome these constraints, we introduce the Hierarchical\nInformation-Guided Spatio-Temporal Mamba (HIGSTM) framework. HIGSTM introduces\nIndex-Guided Frequency Filtering Decomposition to extract commonality and\nspecificity from time series. The model architecture features a meticulously\ndesigned hierarchical framework that systematically captures both temporal\ndynamic patterns and global static relationships within the stock market.\nFurthermore, we propose an Information-Guided Mamba that integrates macro\ninformations into the sequence selection process, thereby facilitating more\nmarket-conscious decision-making. Comprehensive experimental evaluations\nconducted on the CSI500, CSI800 and CSI1000 datasets demonstrate that HIGSTM\nachieves state-of-the-art performance.",
      "pdf_url": "http://arxiv.org/pdf/2503.11387v1",
      "published": "2025-03-14T13:30:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.11387v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Optimizing Large Language Models for Detecting Symptoms of Comorbid Depression or Anxiety in Chronic Diseases: Insights from Patient Messages",
      "authors": [
        "Jiyeong Kim",
        "Stephen P. Ma",
        "Michael L. Chen",
        "Isaac R. Galatzer-Levy",
        "John Torous",
        "Peter J. van Roessel",
        "Christopher Sharp",
        "Michael A. Pfeffer",
        "Carolyn I. Rodriguez",
        "Eleni Linos",
        "Jonathan H. Chen"
      ],
      "abstract": "Patients with diabetes are at increased risk of comorbid depression or\nanxiety, complicating their management. This study evaluated the performance of\nlarge language models (LLMs) in detecting these symptoms from secure patient\nmessages. We applied multiple approaches, including engineered prompts,\nsystemic persona, temperature adjustments, and zero-shot and few-shot learning,\nto identify the best-performing model and enhance performance. Three out of\nfive LLMs demonstrated excellent performance (over 90% of F-1 and accuracy),\nwith Llama 3.1 405B achieving 93% in both F-1 and accuracy using a zero-shot\napproach. While LLMs showed promise in binary classification and handling\ncomplex metrics like Patient Health Questionnaire-4, inconsistencies in\nchallenging cases warrant further real-life assessment. The findings highlight\nthe potential of LLMs to assist in timely screening and referrals, providing\nvaluable empirical knowledge for real-world triage systems that could improve\nmental health care for patients with chronic diseases.",
      "pdf_url": "http://arxiv.org/pdf/2503.11384v1",
      "published": "2025-03-14T13:27:35+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.11384v1",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Annotating Scientific Uncertainty: A comprehensive model using linguistic patterns and comparison with existing approaches",
      "authors": [
        "Panggih Kusuma Ningrum",
        "Philipp Mayr",
        "Nina Smirnova",
        "Iana Atanassova"
      ],
      "abstract": "UnScientify, a system designed to detect scientific uncertainty in scholarly\nfull text. The system utilizes a weakly supervised technique to identify\nverbally expressed uncertainty in scientific texts and their authorial\nreferences. The core methodology of UnScientify is based on a multi-faceted\npipeline that integrates span pattern matching, complex sentence analysis and\nauthor reference checking. This approach streamlines the labeling and\nannotation processes essential for identifying scientific uncertainty, covering\na variety of uncertainty expression types to support diverse applications\nincluding information retrieval, text mining and scientific document\nprocessing. The evaluation results highlight the trade-offs between modern\nlarge language models (LLMs) and the UnScientify system. UnScientify, which\nemploys more traditional techniques, achieved superior performance in the\nscientific uncertainty detection task, attaining an accuracy score of 0.808.\nThis finding underscores the continued relevance and efficiency of\nUnScientify's simple rule-based and pattern matching strategy for this specific\napplication. The results demonstrate that in scenarios where resource\nefficiency, interpretability, and domain-specific adaptability are critical,\ntraditional methods can still offer significant advantages.",
      "pdf_url": "http://arxiv.org/pdf/2503.11376v1",
      "published": "2025-03-14T13:21:59+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.11376v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DL"
      ]
    },
    {
      "title": "PARIC: Probabilistic Attention Regularization for Language Guided Image Classification from Pre-trained Vison Language Models",
      "authors": [
        "Mayank Nautiyal",
        "Stela Arranz Gheorghe",
        "Kristiana Stefa",
        "Li Ju",
        "Ida-Maria Sintorn",
        "Prashant Singh"
      ],
      "abstract": "Language-guided attention frameworks have significantly enhanced both\ninterpretability and performance in image classification; however, the reliance\non deterministic embeddings from pre-trained vision-language foundation models\nto generate reference attention maps frequently overlooks the intrinsic\nmultivaluedness and ill-posed characteristics of cross-modal mappings. To\naddress these limitations, we introduce PARIC, a probabilistic framework for\nguiding visual attention via language specifications. Our approach enables\npre-trained vision-language models to generate probabilistic reference\nattention maps, which align textual and visual modalities more effectively\nwhile incorporating uncertainty estimates, as compared to their deterministic\ncounterparts. Experiments on benchmark test problems demonstrate that PARIC\nenhances prediction accuracy, mitigates bias, ensures consistent predictions,\nand improves robustness across various datasets.",
      "pdf_url": "http://arxiv.org/pdf/2503.11360v1",
      "published": "2025-03-14T12:53:37+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.11360v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "An experimental approach on Few Shot Class Incremental Learning",
      "authors": [
        "Marinela Adam"
      ],
      "abstract": "Few-Shot Class-Incremental Learning (FSCIL) represents a cutting-edge\nparadigm within the broader scope of machine learning, designed to empower\nmodels with the ability to assimilate new classes of data with limited examples\nwhile safeguarding existing knowledge. The paper will present different\nsolutions which contain extensive experiments across large-scale datasets,\ndomain shifts, and network architectures to evaluate and compare the selected\nmethods. We highlight their advantages and then present an experimental\napproach with the purpose of improving the most promising one by replacing the\nvisual-language (V-L) model (CLIP) with another V-L model (CLOOB) that seem to\noutperform it on zero-shot learning tasks. The aim of this report is to present\nan experimental method for FSCIL that would improve its performance. We also\nplan to offer an overview followed by an analysis of the recent advancements in\nFSCIL domain, focusing on various strategies to mitigate catastrophic\nforgetting and improve the adaptability of models to evolving tasks and\ndatasets.",
      "pdf_url": "http://arxiv.org/pdf/2503.11349v1",
      "published": "2025-03-14T12:36:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.11349v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "AIstorian lets AI be a historian: A KG-powered multi-agent system for accurate biography generation",
      "authors": [
        "Fengyu Li",
        "Yilin Li",
        "Junhao Zhu",
        "Lu Chen",
        "Yanfei Zhang",
        "Jia Zhou",
        "Hui Zu",
        "Jingwen Zhao",
        "Yunjun Gao"
      ],
      "abstract": "Huawei has always been committed to exploring the AI application in\nhistorical research. Biography generation, as a specialized form of abstractive\nsummarization, plays a crucial role in historical research but faces unique\nchallenges that existing large language models (LLMs) struggle to address.\nThese challenges include maintaining stylistic adherence to historical writing\nconventions, ensuring factual fidelity, and handling fragmented information\nacross multiple documents. We present AIstorian, a novel end-to-end agentic\nsystem featured with a knowledge graph (KG)-powered retrieval-augmented\ngeneration (RAG) and anti-hallucination multi-agents. Specifically, AIstorian\nintroduces an in-context learning based chunking strategy and a KG-based index\nfor accurate and efficient reference retrieval. Meanwhile, AIstorian\norchestrates multi-agents to conduct on-the-fly hallucination detection and\nerror-type-aware correction. Additionally, to teach LLMs a certain language\nstyle, we finetune LLMs based on a two-step training approach combining data\naugmentation-enhanced supervised fine-tuning with stylistic preference\noptimization. Extensive experiments on a real-life historical Jinshi dataset\ndemonstrate that AIstorian achieves a 3.8x improvement in factual accuracy and\na 47.6% reduction in hallucination rate compared to existing baselines. The\ndata and code are available at: https://github.com/ZJU-DAILY/AIstorian.",
      "pdf_url": "http://arxiv.org/pdf/2503.11346v1",
      "published": "2025-03-14T12:23:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.11346v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Contextual Similarity Distillation: Ensemble Uncertainties with a Single Model",
      "authors": [
        "Moritz A. Zanger",
        "Pascal R. Van der Vaart",
        "Wendelin Böhmer",
        "Matthijs T. J. Spaan"
      ],
      "abstract": "Uncertainty quantification is a critical aspect of reinforcement learning and\ndeep learning, with numerous applications ranging from efficient exploration\nand stable offline reinforcement learning to outlier detection in medical\ndiagnostics. The scale of modern neural networks, however, complicates the use\nof many theoretically well-motivated approaches such as full Bayesian\ninference. Approximate methods like deep ensembles can provide reliable\nuncertainty estimates but still remain computationally expensive. In this work,\nwe propose contextual similarity distillation, a novel approach that explicitly\nestimates the variance of an ensemble of deep neural networks with a single\nmodel, without ever learning or evaluating such an ensemble in the first place.\nOur method builds on the predictable learning dynamics of wide neural networks,\ngoverned by the neural tangent kernel, to derive an efficient approximation of\nthe predictive variance of an infinite ensemble. Specifically, we reinterpret\nthe computation of ensemble variance as a supervised regression problem with\nkernel similarities as regression targets. The resulting model can estimate\npredictive variance at inference time with a single forward pass, and can make\nuse of unlabeled target-domain data or data augmentations to refine its\nuncertainty estimates. We empirically validate our method across a variety of\nout-of-distribution detection benchmarks and sparse-reward reinforcement\nlearning environments. We find that our single-model method performs\ncompetitively and sometimes superior to ensemble-based baselines and serves as\na reliable signal for efficient exploration. These results, we believe,\nposition contextual similarity distillation as a principled and scalable\nalternative for uncertainty quantification in reinforcement learning and\ngeneral deep learning.",
      "pdf_url": "http://arxiv.org/pdf/2503.11339v1",
      "published": "2025-03-14T12:09:58+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.11339v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ]
    },
    {
      "title": "Cardiomyopathy Diagnosis Model from Endomyocardial Biopsy Specimens: Appropriate Feature Space and Class Boundary in Small Sample Size Data",
      "authors": [
        "Masaya Mori",
        "Yuto Omae",
        "Yutaka Koyama",
        "Kazuyuki Hara",
        "Jun Toyotani",
        "Yasuo Okumura",
        "Hiroyuki Hao"
      ],
      "abstract": "As the number of patients with heart failure increases, machine learning (ML)\nhas garnered attention in cardiomyopathy diagnosis, driven by the shortage of\npathologists. However, endomyocardial biopsy specimens are often small sample\nsize and require techniques such as feature extraction and dimensionality\nreduction. This study aims to determine whether texture features are effective\nfor feature extraction in the pathological diagnosis of cardiomyopathy.\nFurthermore, model designs that contribute toward improving generalization\nperformance are examined by applying feature selection (FS) and dimensional\ncompression (DC) to several ML models. The obtained results were verified by\nvisualizing the inter-class distribution differences and conducting statistical\nhypothesis testing based on texture features. Additionally, they were evaluated\nusing predictive performance across different model designs with varying\ncombinations of FS and DC (applied or not) and decision boundaries. The\nobtained results confirmed that texture features may be effective for the\npathological diagnosis of cardiomyopathy. Moreover, when the ratio of features\nto the sample size is high, a multi-step process involving FS and DC improved\nthe generalization performance, with the linear kernel support vector machine\nachieving the best results. This process was demonstrated to be potentially\neffective for models with reduced complexity, regardless of whether the\ndecision boundaries were linear, curved, perpendicular, or parallel to the\naxes. These findings are expected to facilitate the development of an effective\ncardiomyopathy diagnostic model for its rapid adoption in medical practice.",
      "pdf_url": "http://arxiv.org/pdf/2503.11331v1",
      "published": "2025-03-14T11:59:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.11331v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Learning to reset in target search problems",
      "authors": [
        "Gorka Muñoz-Gil",
        "Hans J. Briegel",
        "Michele Caraglio"
      ],
      "abstract": "Target search problems are central to a wide range of fields, from biological\nforaging to the optimization algorithms. Recently, the ability to reset the\nsearch has been shown to significantly improve the searcher's efficiency.\nHowever, the optimal resetting strategy depends on the specific properties of\nthe search problem and can often be challenging to determine. In this work, we\npropose a reinforcement learning (RL)-based framework to train agents capable\nof optimizing their search efficiency in environments by learning how to reset.\nFirst, we validate the approach in a well-established benchmark: the Brownian\nsearch with resetting. There, RL agents consistently recover strategies closely\nresembling the sharp resetting distribution, known to be optimal in this\nscenario. We then extend the framework by allowing agents to control not only\nwhen to reset, but also their spatial dynamics through turning actions. In this\nmore complex setting, the agents discover strategies that adapt both resetting\nand turning to the properties of the environment, outperforming the proposed\nbenchmarks. These results demonstrate how reinforcement learning can serve both\nas an optimization tool and a mechanism for uncovering new, interpretable\nstrategies in stochastic search processes with resetting.",
      "pdf_url": "http://arxiv.org/pdf/2503.11330v1",
      "published": "2025-03-14T11:57:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.11330v1",
      "categories": [
        "cond-mat.stat-mech",
        "cs.AI",
        "cs.LG",
        "physics.bio-ph",
        "physics.comp-ph"
      ]
    },
    {
      "title": "BriLLM: Brain-inspired Large Language Model",
      "authors": [
        "Hai Zhao",
        "Hongqiu Wu",
        "Dongjie Yang",
        "Anni Zou",
        "Jiale Hong"
      ],
      "abstract": "This paper reports the first brain-inspired large language model (BriLLM).\nThis is a non-Transformer, non-GPT, non-traditional machine learning\ninput-output controlled generative language model. The model is based on the\nSignal Fully-connected flowing (SiFu) definition on the directed graph in terms\nof the neural network, and has the interpretability of all nodes on the graph\nof the whole model, instead of the traditional machine learning model that only\nhas limited interpretability at the input and output ends. In the language\nmodel scenario, the token is defined as a node in the graph. A randomly shaped\nor user-defined signal flow flows between nodes on the principle of \"least\nresistance\" along paths. The next token or node to be predicted or generated is\nthe target of the signal flow. As a language model, BriLLM theoretically\nsupports infinitely long $n$-gram models when the model size is independent of\nthe input and predicted length of the model. The model's working signal flow\nprovides the possibility of recall activation and innate multi-modal support\nsimilar to the cognitive patterns of the human brain. At present, we released\nthe first BriLLM version in Chinese, with 4000 tokens, 32-dimensional node\nwidth, 16-token long sequence prediction ability, and language model prediction\nperformance comparable to GPT-1. More computing power will help us explore the\ninfinite possibilities depicted above.",
      "pdf_url": "http://arxiv.org/pdf/2503.11299v1",
      "published": "2025-03-14T11:08:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.11299v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "AI and Deep Learning for Automated Segmentation and Quantitative Measurement of Spinal Structures in MRI",
      "authors": [
        "Praveen Shastry",
        "Bhawana Sonawane",
        "Kavya Mohan",
        "Naveen Kumarasami",
        "Anandakumar D",
        "Keerthana R",
        "Mounigasri M",
        "Kaviya SP",
        "Kishore Prasath Venkatesh",
        "Bargava Subramanian",
        "Kalyan Sivasailam"
      ],
      "abstract": "Background: Accurate spinal structure measurement is crucial for assessing\nspine health and diagnosing conditions like spondylosis, disc herniation, and\nstenosis. Manual methods for measuring intervertebral disc height and spinal\ncanal diameter are subjective and time-consuming. Automated solutions are\nneeded to improve accuracy, efficiency, and reproducibility in clinical\npractice.\n  Purpose: This study develops an autonomous AI system for segmenting and\nmeasuring key spinal structures in MRI scans, focusing on intervertebral disc\nheight and spinal canal anteroposterior (AP) diameter in the cervical, lumbar,\nand thoracic regions. The goal is to reduce clinician workload, enhance\ndiagnostic consistency, and improve assessments.\n  Methods: The AI model leverages deep learning architectures, including UNet,\nnnU-Net, and CNNs. Trained on a large proprietary MRI dataset, it was validated\nagainst expert annotations. Performance was evaluated using Dice coefficients\nand segmentation accuracy.\n  Results: The AI model achieved Dice coefficients of 0.94 for lumbar, 0.91 for\ncervical, and 0.90 for dorsal spine segmentation (D1-D12). It precisely\nmeasured spinal parameters like disc height and canal diameter, demonstrating\nrobustness and clinical applicability.\n  Conclusion: The AI system effectively automates MRI-based spinal\nmeasurements, improving accuracy and reducing clinician workload. Its\nconsistent performance across spinal regions supports clinical decision-making,\nparticularly in high-demand settings, enhancing spinal assessments and patient\noutcomes.",
      "pdf_url": "http://arxiv.org/pdf/2503.11281v1",
      "published": "2025-03-14T10:39:52+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.11281v1",
      "categories": [
        "eess.IV",
        "cs.AI",
        "92C55, 68T07, 68U10, 62P10, 65D18"
      ]
    },
    {
      "title": "Financial Fraud Detection with Entropy Computing",
      "authors": [
        "Babak Emami",
        "Wesley Dyk",
        "David Haycraft",
        "Carrie Spear",
        "Lac Nguyen",
        "Nicholas Chancellor"
      ],
      "abstract": "We introduce CVQBoost, a novel classification algorithm that leverages early\nhardware implementing Quantum Computing Inc's Entropy Quantum Computing (EQC)\nparadigm, Dirac-3 [Nguyen et. al. arXiv:2407.04512]. We apply CVQBoost to a\nfraud detection test case and benchmark its performance against XGBoost, a\nwidely utilized ML method. Running on Dirac-3, CVQBoost demonstrates a\nsignificant runtime advantage over XGBoost, which we evaluate on\nhigh-performance hardware comprising up to 48 CPUs and four NVIDIA L4 GPUs\nusing the RAPIDS AI framework. Our results show that CVQBoost maintains\ncompetitive accuracy (measured by AUC) while significantly reducing training\ntime, particularly as dataset size and feature complexity increase. To assess\nscalability, we extend our study to large synthetic datasets ranging from 1M to\n70M samples, demonstrating that CVQBoost on Dirac-3 is well-suited for\nlarge-scale classification tasks. These findings position CVQBoost as a\npromising alternative to gradient boosting methods, offering superior\nscalability and efficiency for high-dimensional ML applications such as fraud\ndetection.",
      "pdf_url": "http://arxiv.org/pdf/2503.11273v1",
      "published": "2025-03-14T10:30:43+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.11273v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.optics",
        "quant-ph"
      ]
    },
    {
      "title": "Line of Duty: Evaluating LLM Self-Knowledge via Consistency in Feasibility Boundaries",
      "authors": [
        "Sahil Kale",
        "Vijaykant Nadadur"
      ],
      "abstract": "As LLMs grow more powerful, their most profound achievement may be\nrecognising when to say \"I don't know\". Existing studies on LLM self-knowledge\nhave been largely constrained by human-defined notions of feasibility, often\nneglecting the reasons behind unanswerability by LLMs and failing to study\ndeficient types of self-knowledge. This study aims to obtain intrinsic insights\ninto different types of LLM self-knowledge with a novel methodology: allowing\nthem the flexibility to set their own feasibility boundaries and then analysing\nthe consistency of these limits. We find that even frontier models like GPT-4o\nand Mistral Large are not sure of their own capabilities more than 80% of the\ntime, highlighting a significant lack of trustworthiness in responses. Our\nanalysis of confidence balance in LLMs indicates that models swing between\noverconfidence and conservatism in feasibility boundaries depending on task\ncategories and that the most significant self-knowledge weaknesses lie in\ntemporal awareness and contextual understanding. These difficulties in\ncontextual comprehension additionally lead models to question their operational\nboundaries, resulting in considerable confusion within the self-knowledge of\nLLMs. We make our code and results available publicly at\nhttps://github.com/knowledge-verse-ai/LLM-Self_Knowledge_Eval",
      "pdf_url": "http://arxiv.org/pdf/2503.11256v1",
      "published": "2025-03-14T10:07:07+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.11256v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Spherical Tree-Sliced Wasserstein Distance",
      "authors": [
        "Hoang V. Tran",
        "Thanh T. Chu",
        "Khoi N. M. Nguyen",
        "Trang Pham",
        "Tam Le",
        "Tan M. Nguyen"
      ],
      "abstract": "Sliced Optimal Transport (OT) simplifies the OT problem in high-dimensional\nspaces by projecting supports of input measures onto one-dimensional lines and\nthen exploiting the closed-form expression of the univariate OT to reduce the\ncomputational burden of OT. Recently, the Tree-Sliced method has been\nintroduced to replace these lines with more intricate structures, known as tree\nsystems. This approach enhances the ability to capture topological information\nof integration domains in Sliced OT while maintaining low computational cost.\nInspired by this approach, in this paper, we present an adaptation of tree\nsystems on OT problems for measures supported on a sphere. As a counterpart to\nthe Radon transform variant on tree systems, we propose a novel spherical Radon\ntransform with a new integration domain called spherical trees. By leveraging\nthis transform and exploiting the spherical tree structures, we derive\nclosed-form expressions for OT problems on the sphere. Consequently, we obtain\nan efficient metric for measures on the sphere, named Spherical Tree-Sliced\nWasserstein (STSW) distance. We provide an extensive theoretical analysis to\ndemonstrate the topology of spherical trees and the well-definedness and\ninjectivity of our Radon transform variant, which leads to an orthogonally\ninvariant distance between spherical measures. Finally, we conduct a wide range\nof numerical experiments, including gradient flows and self-supervised\nlearning, to assess the performance of our proposed metric, comparing it to\nrecent benchmarks.",
      "pdf_url": "http://arxiv.org/pdf/2503.11249v1",
      "published": "2025-03-14T10:00:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.11249v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Compound Expression Recognition via Large Vision-Language Models",
      "authors": [
        "Jun Yu",
        "Xilong Lu"
      ],
      "abstract": "Compound Expression Recognition (CER) is crucial for understanding human\nemotions and improving human-computer interaction. However, CER faces\nchallenges due to the complexity of facial expressions and the difficulty of\ncapturing subtle emotional cues. To address these issues, we propose a novel\napproach leveraging Large Vision-Language Models (LVLMs). Our method employs a\ntwo-stage fine-tuning process: first, pre-trained LVLMs are fine-tuned on basic\nfacial expressions to establish foundational patterns; second, the model is\nfurther optimized on a compound-expression dataset to refine visual-language\nfeature interactions. Our approach achieves advanced accuracy on the RAF-DB\ndataset and demonstrates strong zero-shot generalization on the C-EXPR-DB\ndataset, showcasing its potential for real-world applications in emotion\nanalysis and human-computer interaction.",
      "pdf_url": "http://arxiv.org/pdf/2503.11241v1",
      "published": "2025-03-14T09:46:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.11241v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Collaboration is all you need: LLM Assisted Safe Code Translation",
      "authors": [
        "Rabimba Karanjai",
        "Sam Blackshear",
        "Lei Xu",
        "Weidong Shi"
      ],
      "abstract": "This paper introduces UniTranslator, a visionary framework that re-imagines\ncode translation as a collaborative endeavor among multiple, compact LLMs. By\norchestrating the interaction of specialized agents, each focused on different\naspects of the translation process and grounded in a deep understanding of\nprogramming concepts, UniTranslator achieves a level of accuracy and efficiency\nthat rivals larger, monolithic models. Our preliminary evaluation demonstrates\nthe potential of UniTranslator to overcome the limitations of existing\napproaches and unlock the power of smaller LLMs for complex code translation\ntasks. We explore the effectiveness of this dynamic multi-agent paradigm in\nhandling diverse language pairs, including low-resource languages, and in\nmitigating common issues such as code artifacts and hallucinations through the\nuse of Natural Language Inference (NLI) grounding and iterative feedback\nmechanisms",
      "pdf_url": "http://arxiv.org/pdf/2503.11237v1",
      "published": "2025-03-14T09:42:07+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.11237v1",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.SE"
      ]
    },
    {
      "title": "GKG-LLM: A Unified Framework for Generalized Knowledge Graph Construction",
      "authors": [
        "Jian Zhang",
        "Bifan Wei",
        "Shihao Qi",
        "haiping Zhu",
        "Jun Liu",
        "Qika Lin"
      ],
      "abstract": "The construction of Generalized Knowledge Graph (GKG), including knowledge\ngraph, event knowledge graph and commonsense knowledge graph, is fundamental\nfor various natural language processing tasks. Current studies typically\nconstruct these types of graph separately, overlooking holistic insights and\npotential unification that could be beneficial in computing resources and usage\nperspectives. However, a key challenge in developing a unified framework for\nGKG is obstacles arising from task-specific differences. In this study, we\npropose a unified framework for constructing generalized knowledge graphs to\naddress this challenge. First, we collect data from 15 sub-tasks in 29 datasets\nacross the three types of graphs, categorizing them into in-sample,\ncounter-task, and out-of-distribution (OOD) data. Then, we propose a\nthree-stage curriculum learning fine-tuning framework, by iteratively injecting\nknowledge from the three types of graphs into the Large Language Models.\nExtensive experiments show that our proposed model improves the construction of\nall three graph types across in-domain, OOD and counter-task data.",
      "pdf_url": "http://arxiv.org/pdf/2503.11227v1",
      "published": "2025-03-14T09:23:22+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.11227v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Technologies on Effectiveness and Efficiency: A Survey of State Spaces Models",
      "authors": [
        "Xingtai Lv",
        "Youbang Sun",
        "Kaiyan Zhang",
        "Shang Qu",
        "Xuekai Zhu",
        "Yuchen Fan",
        "Yi Wu",
        "Ermo Hua",
        "Xinwei Long",
        "Ning Ding",
        "Bowen Zhou"
      ],
      "abstract": "State Space Models (SSMs) have emerged as a promising alternative to the\npopular transformer-based models and have been increasingly gaining attention.\nCompared to transformers, SSMs excel at tasks with sequential data or longer\ncontexts, demonstrating comparable performances with significant efficiency\ngains. In this survey, we provide a coherent and systematic overview for SSMs,\nincluding their theoretical motivations, mathematical formulations, comparison\nwith existing model classes, and various applications. We divide the SSM series\ninto three main sections, providing a detailed introduction to the original\nSSM, the structured SSM represented by S4, and the selective SSM typified by\nMamba. We put an emphasis on technicality, and highlight the various key\ntechniques introduced to address the effectiveness and efficiency of SSMs. We\nhope this manuscript serves as an introduction for researchers to explore the\ntheoretical foundations of SSMs.",
      "pdf_url": "http://arxiv.org/pdf/2503.11224v1",
      "published": "2025-03-14T09:20:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.11224v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "MEET: A Million-Scale Dataset for Fine-Grained Geospatial Scene Classification with Zoom-Free Remote Sensing Imagery",
      "authors": [
        "Yansheng Li",
        "Yuning Wu",
        "Gong Cheng",
        "Chao Tao",
        "Bo Dang",
        "Yu Wang",
        "Jiahao Zhang",
        "Chuge Zhang",
        "Yiting Liu",
        "Xu Tang",
        "Jiayi Ma",
        "Yongjun Zhang"
      ],
      "abstract": "Accurate fine-grained geospatial scene classification using remote sensing\nimagery is essential for a wide range of applications. However, existing\napproaches often rely on manually zooming remote sensing images at different\nscales to create typical scene samples. This approach fails to adequately\nsupport the fixed-resolution image interpretation requirements in real-world\nscenarios. To address this limitation, we introduce the Million-scale\nfinE-grained geospatial scEne classification dataseT (MEET), which contains\nover 1.03 million zoom-free remote sensing scene samples, manually annotated\ninto 80 fine-grained categories. In MEET, each scene sample follows a\nscene-inscene layout, where the central scene serves as the reference, and\nauxiliary scenes provide crucial spatial context for finegrained\nclassification. Moreover, to tackle the emerging challenge of scene-in-scene\nclassification, we present the Context-Aware Transformer (CAT), a model\nspecifically designed for this task, which adaptively fuses spatial context to\naccurately classify the scene samples. CAT adaptively fuses spatial context to\naccurately classify the scene samples by learning attentional features that\ncapture the relationships between the center and auxiliary scenes. Based on\nMEET, we establish a comprehensive benchmark for fine-grained geospatial scene\nclassification, evaluating CAT against 11 competitive baselines. The results\ndemonstrate that CAT significantly outperforms these baselines, achieving a\n1.88% higher balanced accuracy (BA) with the Swin-Large backbone, and a notable\n7.87% improvement with the Swin-Huge backbone. Further experiments validate the\neffectiveness of each module in CAT and show the practical applicability of CAT\nin the urban functional zone mapping. The source code and dataset will be\npublicly available at https://jerrywyn.github.io/project/MEET.html.",
      "pdf_url": "http://arxiv.org/pdf/2503.11219v1",
      "published": "2025-03-14T09:10:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.11219v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Can Large Reasoning Models do Analogical Reasoning under Perceptual Uncertainty?",
      "authors": [
        "Giacomo Camposampiero",
        "Michael Hersche",
        "Roger Wattenhofer",
        "Abu Sebastian",
        "Abbas Rahimi"
      ],
      "abstract": "This work presents a first evaluation of two state-of-the-art Large Reasoning\nModels (LRMs), OpenAI's o3-mini and DeepSeek R1, on analogical reasoning,\nfocusing on well-established nonverbal human IQ tests based on Raven's\nprogressive matrices. We benchmark with the I-RAVEN dataset and its more\ndifficult extension, I-RAVEN-X, which tests the ability to generalize to longer\nreasoning rules and ranges of the attribute values. To assess the influence of\nvisual uncertainties on these nonverbal analogical reasoning tests, we extend\nthe I-RAVEN-X dataset, which otherwise assumes an oracle perception. We adopt a\ntwo-fold strategy to simulate this imperfect visual perception: 1) we introduce\nconfounding attributes which, being sampled at random, do not contribute to the\nprediction of the correct answer of the puzzles and 2) smoothen the\ndistributions of the input attributes' values. We observe a sharp decline in\nOpenAI's o3-mini task accuracy, dropping from 86.6% on the original I-RAVEN to\njust 17.0% -- approaching random chance -- on the more challenging I-RAVEN-X,\nwhich increases input length and range and emulates perceptual uncertainty.\nThis drop occurred despite spending 3.4x more reasoning tokens. A similar trend\nis also observed for DeepSeek R1: from 80.6% to 23.2%. On the other hand, a\nneuro-symbolic probabilistic abductive model, ARLC, that achieves\nstate-of-the-art performances on I-RAVEN, can robustly reason under all these\nout-of-distribution tests, maintaining strong accuracy with only a modest\nreduction from 98.6% to 88.0%. Our code is available at\nhttps://github.com/IBM/raven-large-language-models.",
      "pdf_url": "http://arxiv.org/pdf/2503.11207v1",
      "published": "2025-03-14T08:52:25+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.11207v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Reinforcement Learning Outperforms Supervised Fine-Tuning: A Case Study on Audio Question Answering",
      "authors": [
        "Gang Li",
        "Jizhong Liu",
        "Heinrich Dinkel",
        "Yadong Niu",
        "Junbo Zhang",
        "Jian Luan"
      ],
      "abstract": "Recently, reinforcement learning (RL) has been shown to greatly enhance the\nreasoning capabilities of large language models (LLMs), and RL-based approaches\nhave been progressively applied to visual multimodal tasks. However, the audio\nmodality has largely been overlooked in these developments. Thus, we conduct a\nseries of RL explorations in audio understanding and reasoning, specifically\nfocusing on the audio question answering (AQA) task. We leverage the group\nrelative policy optimization (GRPO) algorithm to Qwen2-Audio-7B-Instruct, and\nour experiments demonstrated state-of-the-art performance on the MMAU Test-mini\nbenchmark, achieving an accuracy rate of 64.5%. The main findings in this\ntechnical report are as follows: 1) The GRPO algorithm can be effectively\napplied to large audio language models (LALMs), even when the model has only\n8.2B parameters; 2) With only 38k post-training samples, RL significantly\noutperforms supervised fine-tuning (SFT), indicating that RL-based approaches\ncan be effective without large datasets; 3) The explicit reasoning process has\nnot shown significant benefits for AQA tasks, and how to efficiently utilize\ndeep thinking remains an open question for further research; 4) LALMs still lag\nfar behind humans auditory-language reasoning, suggesting that the RL-based\napproaches warrant further exploration. Our project is available at\nhttps://github.com/xiaomi/r1-aqa and https://huggingface.co/mispeech/r1-aqa.",
      "pdf_url": "http://arxiv.org/pdf/2503.11197v1",
      "published": "2025-03-14T08:43:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.11197v1",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "eess.AS"
      ]
    },
    {
      "title": "Cross-Modal Learning for Music-to-Music-Video Description Generation",
      "authors": [
        "Zhuoyuan Mao",
        "Mengjie Zhao",
        "Qiyu Wu",
        "Zhi Zhong",
        "Wei-Hsiang Liao",
        "Hiromi Wakaki",
        "Yuki Mitsufuji"
      ],
      "abstract": "Music-to-music-video generation is a challenging task due to the intrinsic\ndifferences between the music and video modalities. The advent of powerful\ntext-to-video diffusion models has opened a promising pathway for music-video\n(MV) generation by first addressing the music-to-MV description task and\nsubsequently leveraging these models for video generation. In this study, we\nfocus on the MV description generation task and propose a comprehensive\npipeline encompassing training data construction and multimodal model\nfine-tuning. We fine-tune existing pre-trained multimodal models on our newly\nconstructed music-to-MV description dataset based on the Music4All dataset,\nwhich integrates both musical and visual information. Our experimental results\ndemonstrate that music representations can be effectively mapped to textual\ndomains, enabling the generation of meaningful MV description directly from\nmusic inputs. We also identify key components in the dataset construction\npipeline that critically impact the quality of MV description and highlight\nspecific musical attributes that warrant greater focus for improved MV\ndescription generation.",
      "pdf_url": "http://arxiv.org/pdf/2503.11190v1",
      "published": "2025-03-14T08:34:28+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.11190v1",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "cs.MM",
        "eess.AS"
      ]
    },
    {
      "title": "Align in Depth: Defending Jailbreak Attacks via Progressive Answer Detoxification",
      "authors": [
        "Yingjie Zhang",
        "Tong Liu",
        "Zhe Zhao",
        "Guozhu Meng",
        "Kai Chen"
      ],
      "abstract": "Large Language Models (LLMs) are vulnerable to jailbreak attacks, which use\ncrafted prompts to elicit toxic responses. These attacks exploit LLMs'\ndifficulty in dynamically detecting harmful intents during the generation\nprocess. Traditional safety alignment methods, often relying on the initial few\ngeneration steps, are ineffective due to limited computational budget. This\npaper proposes DEEPALIGN, a robust defense framework that fine-tunes LLMs to\nprogressively detoxify generated content, significantly improving both the\ncomputational budget and effectiveness of mitigating harmful generation. Our\napproach uses a hybrid loss function operating on hidden states to directly\nimprove LLMs' inherent awareness of toxity during generation. Furthermore, we\nredefine safe responses by generating semantically relevant answers to harmful\nqueries, thereby increasing robustness against representation-mutation attacks.\nEvaluations across multiple LLMs demonstrate state-of-the-art defense\nperformance against six different attack types, reducing Attack Success Rates\nby up to two orders of magnitude compared to previous state-of-the-art defense\nwhile preserving utility. This work advances LLM safety by addressing\nlimitations of conventional alignment through dynamic, context-aware\nmitigation.",
      "pdf_url": "http://arxiv.org/pdf/2503.11185v1",
      "published": "2025-03-14T08:32:12+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.11185v1",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "title": "Multi-Stage Generative Upscaler: Reconstructing Football Broadcast Images via Diffusion Models",
      "authors": [
        "Luca Martini",
        "Daniele Zolezzi",
        "Saverio Iacono",
        "Gianni Viardo Vercelli"
      ],
      "abstract": "The reconstruction of low-resolution football broadcast images presents a\nsignificant challenge in sports broadcasting, where detailed visuals are\nessential for analysis and audience engagement. This study introduces a\nmulti-stage generative upscaling framework leveraging Diffusion Models to\nenhance degraded images, transforming inputs as small as $64 \\times 64$ pixels\ninto high-fidelity $1024 \\times 1024$ outputs. By integrating an image-to-image\npipeline, ControlNet conditioning, and LoRA fine-tuning, our approach surpasses\ntraditional upscaling methods in restoring intricate textures and\ndomain-specific elements such as player details and jersey logos. The custom\nLoRA is trained on a custom football dataset, ensuring adaptability to sports\nbroadcast needs. Experimental results demonstrate substantial improvements over\nconventional models, with ControlNet refining fine details and LoRA enhancing\ntask-specific elements. These findings highlight the potential of\ndiffusion-based image reconstruction in sports media, paving the way for future\napplications in automated video enhancement and real-time sports analytics.",
      "pdf_url": "http://arxiv.org/pdf/2503.11181v1",
      "published": "2025-03-14T08:28:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.11181v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Zero-TIG: Temporal Consistency-Aware Zero-Shot Illumination-Guided Low-light Video Enhancement",
      "authors": [
        "Yini Li",
        "Nantheera Anantrasirichai"
      ],
      "abstract": "Low-light and underwater videos suffer from poor visibility, low contrast,\nand high noise, necessitating enhancements in visual quality. However, existing\napproaches typically rely on paired ground truth, which limits their\npracticality and often fails to maintain temporal consistency. To overcome\nthese obstacles, this paper introduces a novel zero-shot learning approach\nnamed Zero-TIG, leveraging the Retinex theory and optical flow techniques. The\nproposed network consists of an enhancement module and a temporal feedback\nmodule. The enhancement module comprises three subnetworks: low-light image\ndenoising, illumination estimation, and reflection denoising. The temporal\nenhancement module ensures temporal consistency by incorporating histogram\nequalization, optical flow computation, and image warping to align the enhanced\nprevious frame with the current frame, thereby maintaining continuity.\nAdditionally, we address color distortion in underwater data by adaptively\nbalancing RGB channels. The experimental results demonstrate that our method\nachieves low-light video enhancement without the need for paired training data,\nmaking it a promising and applicable method for real-world scenario\nenhancement.",
      "pdf_url": "http://arxiv.org/pdf/2503.11175v1",
      "published": "2025-03-14T08:22:26+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.11175v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Neurons: Emulating the Human Visual Cortex Improves Fidelity and Interpretability in fMRI-to-Video Reconstruction",
      "authors": [
        "Haonan Wang",
        "Qixiang Zhang",
        "Lehan Wang",
        "Xuanqi Huang",
        "Xiaomeng Li"
      ],
      "abstract": "Decoding visual stimuli from neural activity is essential for understanding\nthe human brain. While fMRI methods have successfully reconstructed static\nimages, fMRI-to-video reconstruction faces challenges due to the need for\ncapturing spatiotemporal dynamics like motion and scene transitions. Recent\napproaches have improved semantic and perceptual alignment but struggle to\nintegrate coarse fMRI data with detailed visual features. Inspired by the\nhierarchical organization of the visual system, we propose NEURONS, a novel\nframework that decouples learning into four correlated sub-tasks: key object\nsegmentation, concept recognition, scene description, and blurry video\nreconstruction. This approach simulates the visual cortex's functional\nspecialization, allowing the model to capture diverse video content. In the\ninference stage, NEURONS generates robust conditioning signals for a\npre-trained text-to-video diffusion model to reconstruct the videos. Extensive\nexperiments demonstrate that NEURONS outperforms state-of-the-art baselines,\nachieving solid improvements in video consistency (26.6%) and semantic-level\naccuracy (19.1%). Notably, NEURONS shows a strong functional correlation with\nthe visual cortex, highlighting its potential for brain-computer interfaces and\nclinical applications. Code and model weights will be available at:\nhttps://github.com/xmed-lab/NEURONS.",
      "pdf_url": "http://arxiv.org/pdf/2503.11167v1",
      "published": "2025-03-14T08:12:28+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.11167v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    }
  ]
}