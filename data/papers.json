{
  "last_updated": "2025-06-26T00:53:36.467641",
  "papers": [
    {
      "title": "Radial Attention: $O(n\\log n)$ Sparse Attention with Energy Decay for Long Video Generation",
      "authors": [
        "Xingyang Li",
        "Muyang Li",
        "Tianle Cai",
        "Haocheng Xi",
        "Shuo Yang",
        "Yujun Lin",
        "Lvmin Zhang",
        "Songlin Yang",
        "Jinbo Hu",
        "Kelly Peng",
        "Maneesh Agrawala",
        "Ion Stoica",
        "Kurt Keutzer",
        "Song Han"
      ],
      "abstract": "Recent advances in diffusion models have enabled high-quality video\ngeneration, but the additional temporal dimension significantly increases\ncomputational costs, making training and inference on long videos prohibitively\nexpensive. In this paper, we identify a phenomenon we term Spatiotemporal\nEnergy Decay in video diffusion models: post-softmax attention scores diminish\nas spatial and temporal distance between tokens increase, akin to the physical\ndecay of signal or waves over space and time in nature. Motivated by this, we\npropose Radial Attention, a scalable sparse attention mechanism with $O(n \\log\nn)$ complexity that translates energy decay into exponentially decaying compute\ndensity, which is significantly more efficient than standard $O(n^2)$ dense\nattention and more expressive than linear attention. Specifically, Radial\nAttention employs a simple, static attention mask where each token attends to\nspatially nearby tokens, with the attention window size shrinking with temporal\ndistance. Moreover, it allows pre-trained video diffusion models to extend\ntheir generation length with efficient LoRA-based fine-tuning. Extensive\nexperiments show that Radial Attention maintains video quality across\nWan2.1-14B, HunyuanVideo, and Mochi 1, achieving up to a 1.9$\\times$ speedup\nover the original dense attention. With minimal tuning, it enables video\ngeneration up to 4$\\times$ longer while reducing training costs by up to\n4.4$\\times$ compared to direct fine-tuning and accelerating inference by up to\n3.7$\\times$ compared to dense attention inference.",
      "pdf_url": "http://arxiv.org/pdf/2506.19852v1",
      "published": "2025-06-24T17:59:59+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.19852v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Orthogonal Finetuning Made Scalable",
      "authors": [
        "Zeju Qiu",
        "Weiyang Liu",
        "Adrian Weller",
        "Bernhard Schölkopf"
      ],
      "abstract": "Orthogonal finetuning (OFT) offers highly parameter-efficient adaptation\nwhile preventing catastrophic forgetting, but its high runtime and memory\ndemands limit practical deployment. We identify the core computational\nbottleneck in OFT as its weight-centric implementation, which relies on costly\nmatrix-matrix multiplications with cubic complexity. To overcome this, we\npropose OFTv2, an input-centric reformulation that instead uses matrix-vector\nmultiplications (i.e., matrix-free computation), reducing the computational\ncost to quadratic. We further introduce the Cayley-Neumann parameterization, an\nefficient orthogonal parameterization that approximates the matrix inversion in\nCayley transform via a truncated Neumann series. These modifications allow\nOFTv2 to achieve up to 10x faster training and 3x lower GPU memory usage\nwithout compromising performance. In addition, we extend OFTv2 to support\nfinetuning quantized foundation models and show that it outperforms the popular\nQLoRA in training stability, efficiency, and memory usage.",
      "pdf_url": "http://arxiv.org/pdf/2506.19847v1",
      "published": "2025-06-24T17:59:49+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.19847v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ]
    },
    {
      "title": "JoyAgents-R1: Joint Evolution Dynamics for Versatile Multi-LLM Agents with Reinforcement Learning",
      "authors": [
        "Ai Han",
        "Junxing Hu",
        "Pu Wei",
        "Zhiqian Zhang",
        "Yuhang Guo",
        "Jiawei Lu",
        "Zicheng Zhang"
      ],
      "abstract": "Multi-agent reinforcement learning (MARL) has emerged as a prominent paradigm\nfor increasingly complex tasks. However, joint evolution across heterogeneous\nagents remains challenging due to cooperative inefficiency and training\ninstability. In this paper, we propose the joint evolution dynamics for MARL\ncalled JoyAgents-R1, which first applies Group Relative Policy Optimization\n(GRPO) to the joint training of heterogeneous multi-agents. By iteratively\nrefining agents' large language models (LLMs) and memories, the method achieves\nholistic equilibrium with optimal decision-making and memory capabilities.\nSpecifically, JoyAgents-R1 first implements node-wise Monte Carlo sampling on\nthe behavior of each agent across entire reasoning trajectories to enhance GRPO\nsampling efficiency while maintaining policy diversity. Then, our marginal\nbenefit-driven selection strategy identifies top-$K$ sampling groups with\nmaximal reward fluctuations, enabling targeted agent model updates that improve\ntraining stability and maximize joint benefits through cost-effective parameter\nadjustments. Meanwhile, JoyAgents-R1 introduces an adaptive memory evolution\nmechanism that repurposes GRPO rewards as cost-free supervisory signals to\neliminate repetitive reasoning and accelerate convergence. Experiments across\ngeneral and domain-specific scenarios demonstrate that JoyAgents-R1 achieves\nperformance comparable to that of larger LLMs while built on smaller\nopen-source models.",
      "pdf_url": "http://arxiv.org/pdf/2506.19846v1",
      "published": "2025-06-24T17:59:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.19846v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Temporal-IRL: Modeling Port Congestion and Berth Scheduling with Inverse Reinforcement Learning",
      "authors": [
        "Guo Li",
        "Zixiang Xu",
        "Wei Zhang",
        "Yikuan Hu",
        "Xinyu Yang",
        "Nikolay Aristov",
        "Mingjie Tang",
        "Elenna R Dugundji"
      ],
      "abstract": "Predicting port congestion is crucial for maintaining reliable global supply\nchains. Accurate forecasts enableimprovedshipment planning, reducedelaysand\ncosts, and optimizeinventoryanddistributionstrategies, thereby ensuring timely\ndeliveries and enhancing supply chain resilience. To achieve accurate\npredictions, analyzing vessel behavior and their stay times at specific port\nterminals is essential, focusing particularly on berth scheduling under various\nconditions. Crucially, the model must capture and learn the underlying\npriorities and patterns of berth scheduling. Berth scheduling and planning are\ninfluenced by a range of factors, including incoming vessel size, waiting\ntimes, and the status of vessels within the port terminal. By observing\nhistorical Automatic Identification System (AIS) positions of vessels, we\nreconstruct berth schedules, which are subsequently utilized to determine the\nreward function via Inverse Reinforcement Learning (IRL). For this purpose, we\nmodeled a specific terminal at the Port of New York/New Jersey and developed\nTemporal-IRL. This Temporal-IRL model learns berth scheduling to predict vessel\nsequencing at the terminal and estimate vessel port stay, encompassing both\nwaiting and berthing times, to forecast port congestion. Utilizing data from\nMaher Terminal spanning January 2015 to September 2023, we trained and tested\nthe model, achieving demonstrably excellent results.",
      "pdf_url": "http://arxiv.org/pdf/2506.19843v1",
      "published": "2025-06-24T17:59:12+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.19843v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Improving Progressive Generation with Decomposable Flow Matching",
      "authors": [
        "Moayed Haji-Ali",
        "Willi Menapace",
        "Ivan Skorokhodov",
        "Arpit Sahni",
        "Sergey Tulyakov",
        "Vicente Ordonez",
        "Aliaksandr Siarohin"
      ],
      "abstract": "Generating high-dimensional visual modalities is a computationally intensive\ntask. A common solution is progressive generation, where the outputs are\nsynthesized in a coarse-to-fine spectral autoregressive manner. While diffusion\nmodels benefit from the coarse-to-fine nature of denoising, explicit\nmulti-stage architectures are rarely adopted. These architectures have\nincreased the complexity of the overall approach, introducing the need for a\ncustom diffusion formulation, decomposition-dependent stage transitions,\nadd-hoc samplers, or a model cascade. Our contribution, Decomposable Flow\nMatching (DFM), is a simple and effective framework for the progressive\ngeneration of visual media. DFM applies Flow Matching independently at each\nlevel of a user-defined multi-scale representation (such as Laplacian pyramid).\nAs shown by our experiments, our approach improves visual quality for both\nimages and videos, featuring superior results compared to prior multistage\nframeworks. On Imagenet-1k 512px, DFM achieves 35.2% improvements in FDD scores\nover the base architecture and 26.4% over the best-performing baseline, under\nthe same training compute. When applied to finetuning of large models, such as\nFLUX, DFM shows faster convergence speed to the training distribution.\nCrucially, all these advantages are achieved with a single model, architectural\nsimplicity, and minimal modifications to existing training pipelines.",
      "pdf_url": "http://arxiv.org/pdf/2506.19839v1",
      "published": "2025-06-24T17:58:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.19839v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "A standard transformer and attention with linear biases for molecular conformer generation",
      "authors": [
        "Viatcheslav Gurev",
        "Timothy Rumbell"
      ],
      "abstract": "Sampling low-energy molecular conformations, spatial arrangements of atoms in\na molecule, is a critical task for many different calculations performed in the\ndrug discovery and optimization process. Numerous specialized equivariant\nnetworks have been designed to generate molecular conformations from 2D\nmolecular graphs. Recently, non-equivariant transformer models have emerged as\na viable alternative due to their capability to scale to improve\ngeneralization. However, the concern has been that non-equivariant models\nrequire a large model size to compensate the lack of equivariant bias. In this\npaper, we demonstrate that a well-chosen positional encoding effectively\naddresses these size limitations. A standard transformer model incorporating\nrelative positional encoding for molecular graphs when scaled to 25 million\nparameters surpasses the current state-of-the-art non-equivariant base model\nwith 64 million parameters on the GEOM-DRUGS benchmark. We implemented relative\npositional encoding as a negative attention bias that linearly increases with\nthe shortest path distances between graph nodes at varying slopes for different\nattention heads, similar to ALiBi, a widely adopted relative positional\nencoding technique in the NLP domain. This architecture has the potential to\nserve as a foundation for a novel class of generative models for molecular\nconformations.",
      "pdf_url": "http://arxiv.org/pdf/2506.19834v1",
      "published": "2025-06-24T17:50:49+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.19834v1",
      "categories": [
        "q-bio.BM",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Evaluating Compliance with Visualization Guidelines in Diagrams for Scientific Publications Using Large Vision Language Models",
      "authors": [
        "Johannes Rückert",
        "Louise Bloch",
        "Christoph M. Friedrich"
      ],
      "abstract": "Diagrams are widely used to visualize data in publications. The research\nfield of data visualization deals with defining principles and guidelines for\nthe creation and use of these diagrams, which are often not known or adhered to\nby researchers, leading to misinformation caused by providing inaccurate or\nincomplete information.\n  In this work, large Vision Language Models (VLMs) are used to analyze\ndiagrams in order to identify potential problems in regards to selected data\nvisualization principles and guidelines. To determine the suitability of VLMs\nfor these tasks, five open source VLMs and five prompting strategies are\ncompared using a set of questions derived from selected data visualization\nguidelines.\n  The results show that the employed VLMs work well to accurately analyze\ndiagram types (F1-score 82.49 %), 3D effects (F1-score 98.55 %), axes labels\n(F1-score 76.74 %), lines (RMSE 1.16), colors (RMSE 1.60) and legends (F1-score\n96.64 %, RMSE 0.70), while they cannot reliably provide feedback about the\nimage quality (F1-score 0.74 %) and tick marks/labels (F1-score 46.13 %). Among\nthe employed VLMs, Qwen2.5VL performs best, and the summarizing prompting\nstrategy performs best for most of the experimental questions.\n  It is shown that VLMs can be used to automatically identify a number of\npotential issues in diagrams, such as missing axes labels, missing legends, and\nunnecessary 3D effects. The approach laid out in this work can be extended for\nfurther aspects of data visualization.",
      "pdf_url": "http://arxiv.org/pdf/2506.19825v1",
      "published": "2025-06-24T17:42:36+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.19825v1",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Persona Features Control Emergent Misalignment",
      "authors": [
        "Miles Wang",
        "Tom Dupré la Tour",
        "Olivia Watkins",
        "Alex Makelov",
        "Ryan A. Chi",
        "Samuel Miserendino",
        "Johannes Heidecke",
        "Tejal Patwardhan",
        "Dan Mossing"
      ],
      "abstract": "Understanding how language models generalize behaviors from their training to\na broader deployment distribution is an important problem in AI safety. Betley\net al. discovered that fine-tuning GPT-4o on intentionally insecure code causes\n\"emergent misalignment,\" where models give stereotypically malicious responses\nto unrelated prompts. We extend this work, demonstrating emergent misalignment\nacross diverse conditions, including reinforcement learning on reasoning\nmodels, fine-tuning on various synthetic datasets, and in models without safety\ntraining. To investigate the mechanisms behind this generalized misalignment,\nwe apply a \"model diffing\" approach using sparse autoencoders to compare\ninternal model representations before and after fine-tuning. This approach\nreveals several \"misaligned persona\" features in activation space, including a\ntoxic persona feature which most strongly controls emergent misalignment and\ncan be used to predict whether a model will exhibit such behavior.\nAdditionally, we investigate mitigation strategies, discovering that\nfine-tuning an emergently misaligned model on just a few hundred benign samples\nefficiently restores alignment.",
      "pdf_url": "http://arxiv.org/pdf/2506.19823v1",
      "published": "2025-06-24T17:38:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.19823v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.6; I.2.7"
      ]
    },
    {
      "title": "KnowRL: Exploring Knowledgeable Reinforcement Learning for Factuality",
      "authors": [
        "Baochang Ren",
        "Shuofei Qiao",
        "Wenhao Yu",
        "Huajun Chen",
        "Ningyu Zhang"
      ],
      "abstract": "Large Language Models (LLMs), particularly slow-thinking models, often\nexhibit severe hallucination, outputting incorrect content due to an inability\nto accurately recognize knowledge boundaries during reasoning. While\nReinforcement Learning (RL) can enhance complex reasoning abilities, its\noutcome-oriented reward mechanism often lacks factual supervision over the\nthinking process, further exacerbating the hallucination problem. To address\nthe high hallucination in slow-thinking models, we propose Knowledge-enhanced\nRL, KnowRL. KnowRL guides models to perform fact-based slow thinking by\nintegrating a factuality reward, based on knowledge verification, into the RL\ntraining process, helping them recognize their knowledge boundaries. KnowRL\nguides models to perform fact-based slow thinking by integrating a factuality\nreward, based on knowledge verification, into the RL training process, helping\nthem recognize their knowledge boundaries. This targeted factual input during\nRL training enables the model to learn and internalize fact-based reasoning\nstrategies. By directly rewarding adherence to facts within the reasoning\nsteps, KnowRL fosters a more reliable thinking process. Experimental results on\nthree hallucination evaluation datasets and two reasoning evaluation datasets\ndemonstrate that KnowRL effectively mitigates hallucinations in slow-thinking\nmodels while maintaining their original strong reasoning capabilities. Our code\nis available at https://github.com/zjunlp/KnowRL.",
      "pdf_url": "http://arxiv.org/pdf/2506.19807v1",
      "published": "2025-06-24T17:17:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.19807v1",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG",
        "cs.MA"
      ]
    },
    {
      "title": "Why Do Open-Source LLMs Struggle with Data Analysis? A Systematic Empirical Study",
      "authors": [
        "Yuqi Zhu",
        "Yi Zhong",
        "Jintian Zhang",
        "Ziheng Zhang",
        "Shuofei Qiao",
        "Yujie Luo",
        "Lun Du",
        "Da Zheng",
        "Huajun Chen",
        "Ningyu Zhang"
      ],
      "abstract": "Large Language Models (LLMs) hold promise in automating data analysis tasks,\nyet open-source models face significant limitations in these kinds of\nreasoning-intensive scenarios. In this work, we investigate strategies to\nenhance the data analysis capabilities of open-source LLMs. By curating a seed\ndataset of diverse, realistic scenarios, we evaluate models across three\ndimensions: data understanding, code generation, and strategic planning. Our\nanalysis reveals three key findings: (1) Strategic planning quality serves as\nthe primary determinant of model performance; (2) Interaction design and task\ncomplexity significantly influence reasoning capabilities; (3) Data quality\ndemonstrates a greater impact than diversity in achieving optimal performance.\nWe leverage these insights to develop a data synthesis methodology,\ndemonstrating significant improvements in open-source LLMs' analytical\nreasoning capabilities.",
      "pdf_url": "http://arxiv.org/pdf/2506.19794v1",
      "published": "2025-06-24T17:04:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.19794v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG",
        "cs.MA"
      ]
    },
    {
      "title": "Learning Task Belief Similarity with Latent Dynamics for Meta-Reinforcement Learning",
      "authors": [
        "Menglong Zhang",
        "Fuyuan Qian"
      ],
      "abstract": "Meta-reinforcement learning requires utilizing prior task distribution\ninformation obtained during exploration to rapidly adapt to unknown tasks. The\nefficiency of an agent's exploration hinges on accurately identifying the\ncurrent task. Recent Bayes-Adaptive Deep RL approaches often rely on\nreconstructing the environment's reward signal, which is challenging in sparse\nreward settings, leading to suboptimal exploitation. Inspired by bisimulation\nmetrics, which robustly extracts behavioral similarity in continuous MDPs, we\npropose SimBelief-a novel meta-RL framework via measuring similarity of task\nbelief in Bayes-Adaptive MDP (BAMDP). SimBelief effectively extracts common\nfeatures of similar task distributions, enabling efficient task identification\nand exploration in sparse reward environments. We introduce latent task belief\nmetric to learn the common structure of similar tasks and incorporate it into\nthe specific task belief. By learning the latent dynamics across task\ndistributions, we connect shared latent task belief features with specific task\nfeatures, facilitating rapid task identification and adaptation. Our method\noutperforms state-of-the-art baselines on sparse reward MuJoCo and panda-gym\ntasks.",
      "pdf_url": "http://arxiv.org/pdf/2506.19785v1",
      "published": "2025-06-24T16:52:00+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.19785v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "SAGE: Strategy-Adaptive Generation Engine for Query Rewriting",
      "authors": [
        "Teng Wang",
        "Hailei Gong",
        "Changwang Zhang",
        "Jun Wang"
      ],
      "abstract": "Query rewriting is pivotal for enhancing dense retrieval, yet current methods\ndemand large-scale supervised data or suffer from inefficient reinforcement\nlearning (RL) exploration. In this work, we first establish that guiding Large\nLanguage Models (LLMs) with a concise set of expert-crafted strategies, such as\nsemantic expansion and entity disambiguation, substantially improves retrieval\neffectiveness on challenging benchmarks, including HotpotQA, FEVER, NFCorpus,\nand SciFact. Building on this insight, we introduce the Strategy-Adaptive\nGeneration Engine (SAGE), which operationalizes these strategies in an RL\nframework. SAGE introduces two novel reward shaping mechanisms-Strategic Credit\nShaping (SCS) and Contrastive Reward Shaping (CRS)-to deliver more informative\nlearning signals. This strategy-guided approach not only achieves new\nstate-of-the-art NDCG@10 results, but also uncovers a compelling emergent\nbehavior: the agent learns to select optimal strategies, reduces unnecessary\nexploration, and generates concise rewrites, lowering inference cost without\nsacrificing performance. Our findings demonstrate that strategy-guided RL,\nenhanced with nuanced reward shaping, offers a scalable, efficient, and more\ninterpretable paradigm for developing the next generation of robust information\nretrieval systems.",
      "pdf_url": "http://arxiv.org/pdf/2506.19783v1",
      "published": "2025-06-24T16:50:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.19783v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Alleviating User-Sensitive bias with Fair Generative Sequential Recommendation Model",
      "authors": [
        "Yang Liu",
        "Feng Wu",
        "Xuefang Zhu"
      ],
      "abstract": "Recommendation fairness has recently attracted much attention. In the real\nworld, recommendation systems are driven by user behavior, and since users with\nthe same sensitive feature (e.g., gender and age) tend to have the same\npatterns, recommendation models can easily capture the strong correlation\npreference of sensitive features and thus cause recommendation unfairness.\nDiffusion model (DM) as a new generative model paradigm has achieved great\nsuccess in recommendation systems. DM's ability to model uncertainty and\nrepresent diversity, and its modeling mechanism has a high degree of\nadaptability with the real-world recommendation process with bias. Therefore,\nwe use DM to effectively model the fairness of recommendation and enhance the\ndiversity. This paper proposes a FairGENerative sequential Recommendation model\nbased on DM, FairGENRec. In the training phase, we inject random noise into the\noriginal distribution under the guidance of the sensitive feature recognition\nmodel, and a sequential denoise model is designed for the reverse\nreconstruction of items. Simultaneously, recommendation fairness modeling is\ncompleted by injecting multi-interests representational information that\neliminates the bias of sensitive user features into the generated results. In\nthe inference phase, the model obtains the noise in the form of noise addition\nby using the history interactions which is followed by reverse iteration to\nreconstruct the target item representation. Finally, our extensive experiments\non three datasets demonstrate the dual enhancement effect of FairGENRec on\naccuracy and fairness, while the statistical analysis of the cases visualizes\nthe degree of improvement on the fairness of the recommendation.",
      "pdf_url": "http://arxiv.org/pdf/2506.19777v1",
      "published": "2025-06-24T16:42:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.19777v1",
      "categories": [
        "cs.IR",
        "cs.AI"
      ]
    },
    {
      "title": "Kling-Foley: Multimodal Diffusion Transformer for High-Quality Video-to-Audio Generation",
      "authors": [
        "Jun Wang",
        "Xijuan Zeng",
        "Chunyu Qiang",
        "Ruilong Chen",
        "Shiyao Wang",
        "Le Wang",
        "Wangjing Zhou",
        "Pengfei Cai",
        "Jiahui Zhao",
        "Nan Li",
        "Zihan Li",
        "Yuzhe Liang",
        "Xiaopeng Wang",
        "Haorui Zheng",
        "Ming Wen",
        "Kang Yin",
        "Yiran Wang",
        "Nan Li",
        "Feng Deng",
        "Liang Dong",
        "Chen Zhang",
        "Di Zhang",
        "Kun Gai"
      ],
      "abstract": "We propose Kling-Foley, a large-scale multimodal Video-to-Audio generation\nmodel that synthesizes high-quality audio synchronized with video content. In\nKling-Foley, we introduce multimodal diffusion transformers to model the\ninteractions between video, audio, and text modalities, and combine it with a\nvisual semantic representation module and an audio-visual synchronization\nmodule to enhance alignment capabilities. Specifically, these modules align\nvideo conditions with latent audio elements at the frame level, thereby\nimproving semantic alignment and audio-visual synchronization. Together with\ntext conditions, this integrated approach enables precise generation of\nvideo-matching sound effects. In addition, we propose a universal latent audio\ncodec that can achieve high-quality modeling in various scenarios such as sound\neffects, speech, singing, and music. We employ a stereo rendering method that\nimbues synthesized audio with a spatial presence. At the same time, in order to\nmake up for the incomplete types and annotations of the open-source benchmark,\nwe also open-source an industrial-level benchmark Kling-Audio-Eval. Our\nexperiments show that Kling-Foley trained with the flow matching objective\nachieves new audio-visual SOTA performance among public models in terms of\ndistribution matching, semantic alignment, temporal alignment and audio\nquality.",
      "pdf_url": "http://arxiv.org/pdf/2506.19774v1",
      "published": "2025-06-24T16:39:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.19774v1",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.SD"
      ]
    },
    {
      "title": "Automatic Prompt Optimization for Knowledge Graph Construction: Insights from an Empirical Study",
      "authors": [
        "Nandana Mihindukulasooriya",
        "Niharika S. D'Souza",
        "Faisal Chowdhury",
        "Horst Samulowitz"
      ],
      "abstract": "A KG represents a network of entities and illustrates relationships between\nthem. KGs are used for various applications, including semantic search and\ndiscovery, reasoning, decision-making, natural language processing, machine\nlearning, and recommendation systems. Triple (subject-relation-object)\nextraction from text is the fundamental building block of KG construction and\nhas been widely studied, for example, in early benchmarks such as ACE 2002 to\nmore recent ones, such as WebNLG 2020, REBEL and SynthIE. While the use of LLMs\nis explored for KG construction, handcrafting reasonable task-specific prompts\nfor LLMs is a labour-intensive exercise and can be brittle due to subtle\nchanges in the LLM models employed. Recent work in NLP tasks (e.g. autonomy\ngeneration) uses automatic prompt optimization/engineering to address this\nchallenge by generating optimal or near-optimal task-specific prompts given\ninput-output examples.\n  This empirical study explores the application of automatic prompt\noptimization for the triple extraction task using experimental benchmarking. We\nevaluate different settings by changing (a) the prompting strategy, (b) the LLM\nbeing used for prompt optimization and task execution, (c) the number of\ncanonical relations in the schema (schema complexity), (d) the length and\ndiversity of input text, (e) the metric used to drive the prompt optimization,\nand (f) the dataset being used for training and testing. We evaluate three\ndifferent automatic prompt optimizers, namely, DSPy, APE, and TextGrad and use\ntwo different triple extraction datasets, SynthIE and REBEL. Through rigorous\nempirical evaluation, our main contribution highlights that automatic prompt\noptimization techniques can generate reasonable prompts similar to humans for\ntriple extraction. In turn, these optimized prompts achieve improved results,\nparticularly with increasing schema complexity and text size.",
      "pdf_url": "http://arxiv.org/pdf/2506.19773v1",
      "published": "2025-06-24T16:38:49+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.19773v1",
      "categories": [
        "cs.AI",
        "I.2.7; I.2.4"
      ]
    },
    {
      "title": "A Survey of Multi-sensor Fusion Perception for Embodied AI: Background, Methods, Challenges and Prospects",
      "authors": [
        "Shulan Ruan",
        "Rongwei Wang",
        "Xuchen Shen",
        "Huijie Liu",
        "Baihui Xiao",
        "Jun Shi",
        "Kun Zhang",
        "Zhenya Huang",
        "Yu Liu",
        "Enhong Chen",
        "You He"
      ],
      "abstract": "Multi-sensor fusion perception (MSFP) is a key technology for embodied AI,\nwhich can serve a variety of downstream tasks (e.g., 3D object detection and\nsemantic segmentation) and application scenarios (e.g., autonomous driving and\nswarm robotics). Recently, impressive achievements on AI-based MSFP methods\nhave been reviewed in relevant surveys. However, we observe that the existing\nsurveys have some limitations after a rigorous and detailed investigation. For\none thing, most surveys are oriented to a single task or research field, such\nas 3D object detection or autonomous driving. Therefore, researchers in other\nrelated tasks often find it difficult to benefit directly. For another, most\nsurveys only introduce MSFP from a single perspective of multi-modal fusion,\nwhile lacking consideration of the diversity of MSFP methods, such as\nmulti-view fusion and time-series fusion. To this end, in this paper, we hope\nto organize MSFP research from a task-agnostic perspective, where methods are\nreported from various technical views. Specifically, we first introduce the\nbackground of MSFP. Next, we review multi-modal and multi-agent fusion methods.\nA step further, time-series fusion methods are analyzed. In the era of LLM, we\nalso investigate multimodal LLM fusion methods. Finally, we discuss open\nchallenges and future directions for MSFP. We hope this survey can help\nresearchers understand the important progress in MSFP and provide possible\ninsights for future research.",
      "pdf_url": "http://arxiv.org/pdf/2506.19769v1",
      "published": "2025-06-24T16:34:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.19769v1",
      "categories": [
        "cs.MM",
        "cs.AI"
      ]
    },
    {
      "title": "SRFT: A Single-Stage Method with Supervised and Reinforcement Fine-Tuning for Reasoning",
      "authors": [
        "Yuqian Fu",
        "Tinghong Chen",
        "Jiajun Chai",
        "Xihuai Wang",
        "Songjun Tu",
        "Guojun Yin",
        "Wei Lin",
        "Qichao Zhang",
        "Yuanheng Zhu",
        "Dongbin Zhao"
      ],
      "abstract": "Large language models (LLMs) have achieved remarkable progress in reasoning\ntasks, yet the optimal integration of Supervised Fine-Tuning (SFT) and\nReinforcement Learning (RL) remains a fundamental challenge. Through\ncomprehensive analysis of token distributions, learning dynamics, and\nintegration mechanisms from entropy-based perspectives, we reveal key\ndifferences between these paradigms: SFT induces coarse-grained global changes\nto LLM policy distributions, while RL performs fine-grained selective\noptimizations, with entropy serving as a critical indicator of training\neffectiveness. Building on these observations, we propose Supervised\nReinforcement Fine-Tuning (SRFT), a single-stage method that unifies both\nfine-tuning paradigms through entropy-aware weighting mechanisms. Our approach\nsimultaneously applies SFT and RL to directly optimize the LLM using\ndemonstrations and self-exploration rollouts rather than through two-stage\nsequential methods. Extensive experiments show that SRFT achieves 59.1% average\naccuracy, outperforming zero-RL methods by 9.0% on five mathematical reasoning\nbenchmarks and 10.9% on three out-of-distribution benchmarks.",
      "pdf_url": "http://arxiv.org/pdf/2506.19767v1",
      "published": "2025-06-24T16:31:37+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.19767v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Cross-regularization: Adaptive Model Complexity through Validation Gradients",
      "authors": [
        "Carlos Stein Brito"
      ],
      "abstract": "Model regularization requires extensive manual tuning to balance complexity\nagainst overfitting. Cross-regularization resolves this tradeoff by directly\nadapting regularization parameters through validation gradients during\ntraining. The method splits parameter optimization - training data guides\nfeature learning while validation data shapes complexity controls - converging\nprovably to cross-validation optima. When implemented through noise injection\nin neural networks, this approach reveals striking patterns: unexpectedly high\nnoise tolerance and architecture-specific regularization that emerges\norganically during training. Beyond complexity control, the framework\nintegrates seamlessly with data augmentation, uncertainty calibration and\ngrowing datasets while maintaining single-run efficiency through a simple\ngradient-based approach.",
      "pdf_url": "http://arxiv.org/pdf/2506.19755v1",
      "published": "2025-06-24T16:15:50+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.19755v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.ST",
        "stat.ML",
        "stat.TH"
      ]
    },
    {
      "title": "Arabic Dialect Classification using RNNs, Transformers, and Large Language Models: A Comparative Analysis",
      "authors": [
        "Omar A. Essameldin",
        "Ali O. Elbeih",
        "Wael H. Gomaa",
        "Wael F. Elsersy"
      ],
      "abstract": "The Arabic language is among the most popular languages in the world with a\nhuge variety of dialects spoken in 22 countries. In this study, we address the\nproblem of classifying 18 Arabic dialects of the QADI dataset of Arabic tweets.\nRNN models, Transformer models, and large language models (LLMs) via prompt\nengineering are created and tested. Among these, MARBERTv2 performed best with\n65% accuracy and 64% F1-score. Through the use of state-of-the-art\npreprocessing techniques and the latest NLP models, this paper identifies the\nmost significant linguistic issues in Arabic dialect identification. The\nresults corroborate applications like personalized chatbots that respond in\nusers' dialects, social media monitoring, and greater accessibility for Arabic\ncommunities.",
      "pdf_url": "http://arxiv.org/pdf/2506.19753v1",
      "published": "2025-06-24T16:06:58+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.19753v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "NeRF-based CBCT Reconstruction needs Normalization and Initialization",
      "authors": [
        "Zhuowei Xu",
        "Han Li",
        "Dai Sun",
        "Zhicheng Li",
        "Yujia Li",
        "Qingpeng Kong",
        "Zhiwei Cheng",
        "Nassir Navab",
        "S. Kevin Zhou"
      ],
      "abstract": "Cone Beam Computed Tomography (CBCT) is widely used in medical imaging.\nHowever, the limited number and intensity of X-ray projections make\nreconstruction an ill-posed problem with severe artifacts. NeRF-based methods\nhave achieved great success in this task. However, they suffer from a\nlocal-global training mismatch between their two key components: the hash\nencoder and the neural network. Specifically, in each training step, only a\nsubset of the hash encoder's parameters is used (local sparse), whereas all\nparameters in the neural network participate (global dense). Consequently, hash\nfeatures generated in each step are highly misaligned, as they come from\ndifferent subsets of the hash encoder. These misalignments from different\ntraining steps are then fed into the neural network, causing repeated\ninconsistent global updates in training, which leads to unstable training,\nslower convergence, and degraded reconstruction quality. Aiming to alleviate\nthe impact of this local-global optimization mismatch, we introduce a\nNormalized Hash Encoder, which enhances feature consistency and mitigates the\nmismatch. Additionally, we propose a Mapping Consistency Initialization(MCI)\nstrategy that initializes the neural network before training by leveraging the\nglobal mapping property from a well-trained model. The initialized neural\nnetwork exhibits improved stability during early training, enabling faster\nconvergence and enhanced reconstruction performance. Our method is simple yet\neffective, requiring only a few lines of code while substantially improving\ntraining efficiency on 128 CT cases collected from 4 different datasets,\ncovering 7 distinct anatomical regions.",
      "pdf_url": "http://arxiv.org/pdf/2506.19742v1",
      "published": "2025-06-24T16:01:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.19742v1",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Who Does What in Deep Learning? Multidimensional Game-Theoretic Attribution of Function of Neural Units",
      "authors": [
        "Shrey Dixit",
        "Kayson Fakhar",
        "Fatemeh Hadaeghi",
        "Patrick Mineault",
        "Konrad P. Kording",
        "Claus C. Hilgetag"
      ],
      "abstract": "Neural networks now generate text, images, and speech with billions of\nparameters, producing a need to know how each neural unit contributes to these\nhigh-dimensional outputs. Existing explainable-AI methods, such as SHAP,\nattribute importance to inputs, but cannot quantify the contributions of neural\nunits across thousands of output pixels, tokens, or logits. Here we close that\ngap with Multiperturbation Shapley-value Analysis (MSA), a model-agnostic\ngame-theoretic framework. By systematically lesioning combinations of units,\nMSA yields Shapley Modes, unit-wise contribution maps that share the exact\ndimensionality of the model's output. We apply MSA across scales, from\nmulti-layer perceptrons to the 56-billion-parameter Mixtral-8x7B and Generative\nAdversarial Networks (GAN). The approach demonstrates how regularisation\nconcentrates computation in a few hubs, exposes language-specific experts\ninside the LLM, and reveals an inverted pixel-generation hierarchy in GANs.\nTogether, these results showcase MSA as a powerful approach for interpreting,\nediting, and compressing deep neural networks.",
      "pdf_url": "http://arxiv.org/pdf/2506.19732v1",
      "published": "2025-06-24T15:50:35+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.19732v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Geometric-Aware Variational Inference: Robust and Adaptive Regularization with Directional Weight Uncertainty",
      "authors": [
        "Carlos Stein Brito"
      ],
      "abstract": "Deep neural networks require principled uncertainty quantification, yet\nexisting variational inference methods often employ isotropic Gaussian\napproximations in weight space that poorly match the network's inherent\ngeometry. We address this mismatch by introducing Concentration-Adapted\nPerturbations (CAP), a variational framework that models weight uncertainties\ndirectly on the unit hypersphere using von Mises-Fisher distributions. Building\non recent work in radial-directional posterior decompositions and spherical\nweight constraints, CAP provides the first complete theoretical framework\nconnecting directional statistics to practical noise regularization in neural\nnetworks. Our key contribution is an analytical derivation linking vMF\nconcentration parameters to activation noise variance, enabling each layer to\nlearn its optimal uncertainty level through a novel closed-form KL divergence\nregularizer. In experiments on CIFAR-10, CAP significantly improves model\ncalibration - reducing Expected Calibration Error by 5.6x - while providing\ninterpretable layer-wise uncertainty profiles. CAP requires minimal\ncomputational overhead and integrates seamlessly into standard architectures,\noffering a theoretically grounded yet practical approach to uncertainty\nquantification in deep learning.",
      "pdf_url": "http://arxiv.org/pdf/2506.19726v1",
      "published": "2025-06-24T15:42:00+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.19726v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ]
    },
    {
      "title": "From Reproduction to Replication: Evaluating Research Agents with Progressive Code Masking",
      "authors": [
        "Gyeongwon James Kim",
        "Alex Wilf",
        "Louis-Philippe Morency",
        "Daniel Fried"
      ],
      "abstract": "Recent progress in autonomous code generation has fueled excitement around AI\nagents capable of accelerating scientific discovery by running experiments.\nHowever, there is currently no benchmark that evaluates whether such agents can\nimplement scientific ideas when given varied amounts of code as a starting\npoint, interpolating between reproduction (running code) and from-scratch\nreplication (fully re-implementing and running code). We introduce\nAutoExperiment, a benchmark that evaluates AI agents' ability to implement and\nrun machine learning experiments based on natural language descriptions in\nresearch papers. In each task, agents are given a research paper, a codebase\nwith key functions masked out, and a command to run the experiment. The goal is\nto generate the missing code, execute the experiment in a sandboxed\nenvironment, and reproduce the results. AutoExperiment scales in difficulty by\nvarying the number of missing functions $n$, ranging from partial reproduction\nto full replication. We evaluate state-of-the-art agents and find that\nperformance degrades rapidly as $n$ increases. Agents that can dynamically\ninteract with the environment (e.g. to debug their code) can outperform agents\nin fixed \"agentless\" harnesses, and there exists a significant gap between\nsingle-shot and multi-trial success rates (Pass@1 vs. Pass@5), motivating\nverifier approaches to our benchmark. Our findings highlight critical\nchallenges in long-horizon code generation, context retrieval, and autonomous\nexperiment execution, establishing AutoExperiment as a new benchmark for\nevaluating progress in AI-driven scientific experimentation. Our data and code\nare open-sourced at https://github.com/j1mk1m/AutoExperiment .",
      "pdf_url": "http://arxiv.org/pdf/2506.19724v1",
      "published": "2025-06-24T15:39:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.19724v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Uncovering Conceptual Blindspots in Generative Image Models Using Sparse Autoencoders",
      "authors": [
        "Matyas Bohacek",
        "Thomas Fel",
        "Maneesh Agrawala",
        "Ekdeep Singh Lubana"
      ],
      "abstract": "Despite their impressive performance, generative image models trained on\nlarge-scale datasets frequently fail to produce images with seemingly simple\nconcepts -- e.g., human hands or objects appearing in groups of four -- that\nare reasonably expected to appear in the training data. These failure modes\nhave largely been documented anecdotally, leaving open the question of whether\nthey reflect idiosyncratic anomalies or more structural limitations of these\nmodels. To address this, we introduce a systematic approach for identifying and\ncharacterizing \"conceptual blindspots\" -- concepts present in the training data\nbut absent or misrepresented in a model's generations. Our method leverages\nsparse autoencoders (SAEs) to extract interpretable concept embeddings,\nenabling a quantitative comparison of concept prevalence between real and\ngenerated images. We train an archetypal SAE (RA-SAE) on DINOv2 features with\n32,000 concepts -- the largest such SAE to date -- enabling fine-grained\nanalysis of conceptual disparities. Applied to four popular generative models\n(Stable Diffusion 1.5/2.1, PixArt, and Kandinsky), our approach reveals\nspecific suppressed blindspots (e.g., bird feeders, DVD discs, and whitespaces\non documents) and exaggerated blindspots (e.g., wood background texture and\npalm trees). At the individual datapoint level, we further isolate memorization\nartifacts -- instances where models reproduce highly specific visual templates\nseen during training. Overall, we propose a theoretically grounded framework\nfor systematically identifying conceptual blindspots in generative models by\nassessing their conceptual fidelity with respect to the underlying\ndata-generating process.",
      "pdf_url": "http://arxiv.org/pdf/2506.19708v1",
      "published": "2025-06-24T15:15:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.19708v1",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "LLM-Driven Medical Document Analysis: Enhancing Trustworthy Pathology and Differential Diagnosis",
      "authors": [
        "Lei Kang",
        "Xuanshuo Fu",
        "Oriol Ramos Terrades",
        "Javier Vazquez-Corral",
        "Ernest Valveny",
        "Dimosthenis Karatzas"
      ],
      "abstract": "Medical document analysis plays a crucial role in extracting essential\nclinical insights from unstructured healthcare records, supporting critical\ntasks such as differential diagnosis. Determining the most probable condition\namong overlapping symptoms requires precise evaluation and deep medical\nexpertise. While recent advancements in large language models (LLMs) have\nsignificantly enhanced performance in medical document analysis, privacy\nconcerns related to sensitive patient data limit the use of online LLMs\nservices in clinical settings. To address these challenges, we propose a\ntrustworthy medical document analysis platform that fine-tunes a LLaMA-v3 using\nlow-rank adaptation, specifically optimized for differential diagnosis tasks.\nOur approach utilizes DDXPlus, the largest benchmark dataset for differential\ndiagnosis, and demonstrates superior performance in pathology prediction and\nvariable-length differential diagnosis compared to existing methods. The\ndeveloped web-based platform allows users to submit their own unstructured\nmedical documents and receive accurate, explainable diagnostic results. By\nincorporating advanced explainability techniques, the system ensures\ntransparent and reliable predictions, fostering user trust and confidence.\nExtensive evaluations confirm that the proposed method surpasses current\nstate-of-the-art models in predictive accuracy while offering practical utility\nin clinical settings. This work addresses the urgent need for reliable,\nexplainable, and privacy-preserving artificial intelligence solutions,\nrepresenting a significant advancement in intelligent medical document analysis\nfor real-world healthcare applications. The code can be found at\n\\href{https://github.com/leitro/Differential-Diagnosis-LoRA}{https://github.com/leitro/Differential-Diagnosis-LoRA}.",
      "pdf_url": "http://arxiv.org/pdf/2506.19702v1",
      "published": "2025-06-24T15:12:42+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.19702v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Toward Decision-Oriented Prognostics: An Integrated Estimate-Optimize Framework for Predictive Maintenance",
      "authors": [
        "Zhuojun Xie",
        "Adam Abdin",
        "Yiping Fang"
      ],
      "abstract": "Recent research increasingly integrates machine learning (ML) into predictive\nmaintenance (PdM) to reduce operational and maintenance costs in data-rich\noperational settings. However, uncertainty due to model misspecification\ncontinues to limit widespread industrial adoption. This paper proposes a PdM\nframework in which sensor-driven prognostics inform decision-making under\neconomic trade-offs within a finite decision space. We investigate two key\nquestions: (1) Does higher predictive accuracy necessarily lead to better\nmaintenance decisions? (2) If not, how can the impact of prediction errors on\ndownstream maintenance decisions be mitigated? We first demonstrate that in the\ntraditional estimate-then-optimize (ETO) framework, errors in probabilistic\nprediction can result in inconsistent and suboptimal maintenance decisions. To\naddress this, we propose an integrated estimate-optimize (IEO) framework that\njointly tunes predictive models while directly optimizing for maintenance\noutcomes. We establish theoretical finite-sample guarantees on decision\nconsistency under standard assumptions. Specifically, we develop a stochastic\nperturbation gradient descent algorithm suitable for small run-to-failure\ndatasets. Empirical evaluations on a turbofan maintenance case study show that\nthe IEO framework reduces average maintenance regret up to 22% compared to ETO.\nThis study provides a principled approach to managing prediction errors in\ndata-driven PdM. By aligning prognostic model training with maintenance\nobjectives, the IEO framework improves robustness under model misspecification\nand improves decision quality. The improvement is particularly pronounced when\nthe decision-making policy is misaligned with the decision-maker's target.\nThese findings support more reliable maintenance planning in uncertain\noperational environments.",
      "pdf_url": "http://arxiv.org/pdf/2506.19698v1",
      "published": "2025-06-24T15:10:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.19698v1",
      "categories": [
        "cs.AI",
        "math.OC"
      ]
    },
    {
      "title": "Outlier-Safe Pre-Training for Robust 4-Bit Quantization of Large Language Models",
      "authors": [
        "Jungwoo Park",
        "Taewhoo Lee",
        "Chanwoong Yoon",
        "Hyeon Hwang",
        "Jaewoo Kang"
      ],
      "abstract": "Extreme activation outliers in Large Language Models (LLMs) critically\ndegrade quantization performance, hindering efficient on-device deployment.\nWhile channel-wise operations and adaptive gradient scaling are recognized\ncauses, practical mitigation remains challenging. We introduce Outlier-Safe\nPre-Training (OSP), a practical guideline that proactively prevents outlier\nformation rather than relying on post-hoc mitigation. OSP combines three key\ninnovations: (1) the Muon optimizer, eliminating privileged bases while\nmaintaining training efficiency; (2) Single-Scale RMSNorm, preventing\nchannel-wise amplification; and (3) a learnable embedding projection,\nredistributing activation magnitudes originating from embedding matrices. We\nvalidate OSP by training a 1.4B-parameter model on 1 trillion tokens, which is\nthe first production-scale LLM trained without such outliers. Under aggressive\n4-bit quantization, our OSP model achieves a 35.7 average score across 10\nbenchmarks (compared to 26.5 for an Adam-trained model), with only a 2%\ntraining overhead. Remarkably, OSP models exhibit near-zero excess kurtosis\n(0.04) compared to extreme values (1818.56) in standard models, fundamentally\naltering LLM quantization behavior. Our work demonstrates that outliers are not\ninherent to LLMs but are consequences of training strategies, paving the way\nfor more efficient LLM deployment. The source code and pretrained checkpoints\nare available at https://github.com/dmis-lab/Outlier-Safe-Pre-Training.",
      "pdf_url": "http://arxiv.org/pdf/2506.19697v1",
      "published": "2025-06-24T15:03:57+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.19697v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "When Can We Reuse a Calibration Set for Multiple Conformal Predictions?",
      "authors": [
        "A. A. Balinsky",
        "A. D. Balinsky"
      ],
      "abstract": "Reliable uncertainty quantification is crucial for the trustworthiness of\nmachine learning applications. Inductive Conformal Prediction (ICP) offers a\ndistribution-free framework for generating prediction sets or intervals with\nuser-specified confidence. However, standard ICP guarantees are marginal and\ntypically require a fresh calibration set for each new prediction to maintain\ntheir validity. This paper addresses this practical limitation by demonstrating\nhow e-conformal prediction, in conjunction with Hoeffding's inequality, can\nenable the repeated use of a single calibration set with a high probability of\npreserving the desired coverage. Through a case study on the CIFAR-10 dataset,\nwe train a deep neural network and utilise a calibration set to estimate a\nHoeffding correction. This correction allows us to apply a modified Markov's\ninequality, leading to the construction of prediction sets with quantifiable\nconfidence. Our results illustrate the feasibility of maintaining provable\nperformance in conformal prediction while enhancing its practicality by\nreducing the need for repeated calibration. The code for this work is publicly\navailable.",
      "pdf_url": "http://arxiv.org/pdf/2506.19689v1",
      "published": "2025-06-24T14:57:25+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.19689v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.ST",
        "stat.TH"
      ]
    },
    {
      "title": "From memories to maps: Mechanisms of in context reinforcement learning in transformers",
      "authors": [
        "Ching Fang",
        "Kanaka Rajan"
      ],
      "abstract": "Humans and animals show remarkable learning efficiency, adapting to new\nenvironments with minimal experience. This capability is not well captured by\nstandard reinforcement learning algorithms that rely on incremental value\nupdates. Rapid adaptation likely depends on episodic memory -- the ability to\nretrieve specific past experiences to guide decisions in novel contexts.\nTransformers provide a useful setting for studying these questions because of\ntheir ability to learn rapidly in-context and because their key-value\narchitecture resembles episodic memory systems in the brain. We train a\ntransformer to in-context reinforcement learn in a distribution of planning\ntasks inspired by rodent behavior. We then characterize the learning algorithms\nthat emerge in the model. We first find that representation learning is\nsupported by in-context structure learning and cross-context alignment, where\nrepresentations are aligned across environments with different sensory stimuli.\nWe next demonstrate that the reinforcement learning strategies developed by the\nmodel are not interpretable as standard model-free or model-based planning.\nInstead, we show that in-context reinforcement learning is supported by caching\nintermediate computations within the model's memory tokens, which are then\naccessed at decision time. Overall, we find that memory may serve as a\ncomputational resource, storing both raw experience and cached computations to\nsupport flexible behavior. Furthermore, the representations developed in the\nmodel resemble computations associated with the hippocampal-entorhinal system\nin the brain, suggesting that our findings may be relevant for natural\ncognition. Taken together, our work offers a mechanistic hypothesis for the\nrapid adaptation that underlies in-context learning in artificial and natural\nsettings.",
      "pdf_url": "http://arxiv.org/pdf/2506.19686v1",
      "published": "2025-06-24T14:55:43+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.19686v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Semantic Scene Graph for Ultrasound Image Explanation and Scanning Guidance",
      "authors": [
        "Xuesong Li",
        "Dianye Huang",
        "Yameng Zhang",
        "Nassir Navab",
        "Zhongliang Jiang"
      ],
      "abstract": "Understanding medical ultrasound imaging remains a long-standing challenge\ndue to significant visual variability caused by differences in imaging and\nacquisition parameters. Recent advancements in large language models (LLMs)\nhave been used to automatically generate terminology-rich summaries orientated\nto clinicians with sufficient physiological knowledge. Nevertheless, the\nincreasing demand for improved ultrasound interpretability and basic scanning\nguidance among non-expert users, e.g., in point-of-care settings, has not yet\nbeen explored. In this study, we first introduce the scene graph (SG) for\nultrasound images to explain image content to ordinary and provide guidance for\nultrasound scanning. The ultrasound SG is first computed using a\ntransformer-based one-stage method, eliminating the need for explicit object\ndetection. To generate a graspable image explanation for ordinary, the user\nquery is then used to further refine the abstract SG representation through\nLLMs. Additionally, the predicted SG is explored for its potential in guiding\nultrasound scanning toward missing anatomies within the current imaging view,\nassisting ordinary users in achieving more standardized and complete anatomical\nexploration. The effectiveness of this SG-based image explanation and scanning\nguidance has been validated on images from the left and right neck regions,\nincluding the carotid and thyroid, across five volunteers. The results\ndemonstrate the potential of the method to maximally democratize ultrasound by\nenhancing its interpretability and usability for ordinaries.",
      "pdf_url": "http://arxiv.org/pdf/2506.19683v1",
      "published": "2025-06-24T14:49:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.19683v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "eess.IV"
      ]
    },
    {
      "title": "Tailored Conversations beyond LLMs: A RL-Based Dialogue Manager",
      "authors": [
        "Lucie Galland",
        "Catherine Pelachaud",
        "Florian Pecune"
      ],
      "abstract": "In this work, we propose a novel framework that integrates large language\nmodels (LLMs) with an RL-based dialogue manager for open-ended dialogue with a\nspecific goal. By leveraging hierarchical reinforcement learning to model the\nstructured phases of dialogue and employ meta-learning to enhance adaptability\nacross diverse user profiles, our approach enhances adaptability and\nefficiency, enabling the system to learn from limited data, transition fluidly\nbetween dialogue phases, and personalize responses to heterogeneous patient\nneeds. We apply our framework to Motivational Interviews, aiming to foster\nbehavior change, and demonstrate that the proposed dialogue manager outperforms\na state-of-the-art LLM baseline in terms of reward, showing a potential benefit\nof conditioning LLMs to create open-ended dialogue systems with specific goals.",
      "pdf_url": "http://arxiv.org/pdf/2506.19652v1",
      "published": "2025-06-24T14:15:26+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.19652v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Identifying Macro Causal Effects in C-DMGs over DMGs",
      "authors": [
        "Simon Ferreira",
        "Charles K. Assaad"
      ],
      "abstract": "The do-calculus is a sound and complete tool for identifying causal effects\nin acyclic directed mixed graphs (ADMGs) induced by structural causal models\n(SCMs). However, in many real-world applications, especially in\nhigh-dimensional setting, constructing a fully specified ADMG is often\ninfeasible. This limitation has led to growing interest in partially specified\ncausal representations, particularly through cluster-directed mixed graphs\n(C-DMGs), which group variables into clusters and offer a more abstract yet\npractical view of causal dependencies. While these representations can include\ncycles, recent work has shown that the do-calculus remains sound and complete\nfor identifying macro-level causal effects in C-DMGs over ADMGs under the\nassumption that all clusters size are greater than 1. Nevertheless, real-world\nsystems often exhibit cyclic causal dynamics at the structural level. To\naccount for this, input-output structural causal models (ioSCMs) have been\nintroduced as a generalization of SCMs that allow for cycles. ioSCMs induce\nanother type of graph structure known as a directed mixed graph (DMG).\nAnalogous to the ADMG setting, one can define C-DMGs over DMGs as high-level\nrepresentations of causal relations among clusters of variables. In this paper,\nwe prove that, unlike in the ADMG setting, the do-calculus is unconditionally\nsound and complete for identifying macro causal effects in C-DMGs over DMGs.\nFurthermore, we show that the graphical criteria for non-identifiability of\nmacro causal effects previously established C-DMGs over ADMGs naturally extends\nto a subset of C-DMGs over DMGs.",
      "pdf_url": "http://arxiv.org/pdf/2506.19650v1",
      "published": "2025-06-24T14:14:43+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.19650v1",
      "categories": [
        "cs.AI",
        "stat.ME"
      ]
    },
    {
      "title": "The receptron is a nonlinear threshold logic gate with intrinsic multi-dimensional selective capabilities for analog inputs",
      "authors": [
        "B. Paroli",
        "F. Borghi",
        "M. A. C. Potenza",
        "P. Milani"
      ],
      "abstract": "Threshold logic gates (TLGs) have been proposed as artificial counterparts of\nbiological neurons with classification capabilities based on a linear predictor\nfunction combining a set of weights with the feature vector. The linearity of\nTLGs limits their classification capabilities requiring the use of networks for\nthe accomplishment of complex tasks. A generalization of the TLG model called\nreceptron, characterized by input-dependent weight functions allows for a\nsignificant enhancement of classification performances even with the use of a\nsingle unit. Here we formally demonstrate that a receptron, characterized by\nnonlinear input-dependent weight functions, exhibit intrinsic selective\nactivation properties for analog inputs, when the input vector is within cubic\ndomains in a 3D space. The proposed model can be extended to the n-dimensional\ncase for multidimensional applications. Our results suggest that\nreceptron-based networks can represent a new class of devices capable to manage\na large number of analog inputs, for edge applications requiring high\nselectivity and classification capabilities without the burden of complex\ntraining.",
      "pdf_url": "http://arxiv.org/pdf/2506.19642v1",
      "published": "2025-06-24T14:04:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.19642v1",
      "categories": [
        "cs.ET",
        "cs.AI"
      ]
    },
    {
      "title": "On the efficacy of old features for the detection of new bots",
      "authors": [
        "Rocco De Nicola",
        "Marinella Petrocchi",
        "Manuel Pratelli"
      ],
      "abstract": "For more than a decade now, academicians and online platform administrators\nhave been studying solutions to the problem of bot detection. Bots are computer\nalgorithms whose use is far from being benign: malicious bots are purposely\ncreated to distribute spam, sponsor public characters and, ultimately, induce a\nbias within the public opinion. To fight the bot invasion on our online\necosystem, several approaches have been implemented, mostly based on\n(supervised and unsupervised) classifiers, which adopt the most varied account\nfeatures, from the simplest to the most expensive ones to be extracted from the\nraw data obtainable through the Twitter public APIs. In this exploratory study,\nusing Twitter as a benchmark, we compare the performances of four state-of-art\nfeature sets in detecting novel bots: one of the output scores of the popular\nbot detector Botometer, which considers more than 1,000 features of an account\nto take a decision; two feature sets based on the account profile and timeline;\nand the information about the Twitter client from which the user tweets. The\nresults of our analysis, conducted on six recently released datasets of Twitter\naccounts, hint at the possible use of general-purpose classifiers and\ncheap-to-compute account features for the detection of evolved bots.",
      "pdf_url": "http://arxiv.org/pdf/2506.19635v1",
      "published": "2025-06-24T13:56:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.19635v1",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.SI"
      ]
    },
    {
      "title": "Hierarchical Time Series Forecasting Via Latent Mean Encoding",
      "authors": [
        "Alessandro Salatiello",
        "Stefan Birr",
        "Manuel Kunz"
      ],
      "abstract": "Coherently forecasting the behaviour of a target variable across both coarse\nand fine temporal scales is crucial for profit-optimized decision-making in\nseveral business applications, and remains an open research problem in temporal\nhierarchical forecasting. Here, we propose a new hierarchical architecture that\ntackles this problem by leveraging modules that specialize in forecasting the\ndifferent temporal aggregation levels of interest. The architecture, which\nlearns to encode the average behaviour of the target variable within its hidden\nlayers, makes accurate and coherent forecasts across the target temporal\nhierarchies. We validate our architecture on the challenging, real-world M5\ndataset and show that it outperforms established methods, such as the TSMixer\nmodel.",
      "pdf_url": "http://arxiv.org/pdf/2506.19633v1",
      "published": "2025-06-24T13:54:47+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.19633v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Why Uncertainty Calibration Matters for Reliable Perturbation-based Explanations",
      "authors": [
        "Thomas Decker",
        "Volker Tresp",
        "Florian Buettner"
      ],
      "abstract": "Perturbation-based explanations are widely utilized to enhance the\ntransparency of modern machine-learning models. However, their reliability is\noften compromised by the unknown model behavior under the specific\nperturbations used. This paper investigates the relationship between\nuncertainty calibration - the alignment of model confidence with actual\naccuracy - and perturbation-based explanations. We show that models frequently\nproduce unreliable probability estimates when subjected to\nexplainability-specific perturbations and theoretically prove that this\ndirectly undermines explanation quality. To address this, we introduce ReCalX,\na novel approach to recalibrate models for improved perturbation-based\nexplanations while preserving their original predictions. Experiments on\npopular computer vision models demonstrate that our calibration strategy\nproduces explanations that are more aligned with human perception and actual\nobject locations.",
      "pdf_url": "http://arxiv.org/pdf/2506.19630v1",
      "published": "2025-06-24T13:54:12+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.19630v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "VideoPCDNet: Video Parsing and Prediction with Phase Correlation Networks",
      "authors": [
        "Noel José Rodrigues Vicente",
        "Enrique Lehner",
        "Angel Villar-Corrales",
        "Jan Nogga",
        "Sven Behnke"
      ],
      "abstract": "Understanding and predicting video content is essential for planning and\nreasoning in dynamic environments. Despite advancements, unsupervised learning\nof object representations and dynamics remains challenging. We present\nVideoPCDNet, an unsupervised framework for object-centric video decomposition\nand prediction. Our model uses frequency-domain phase correlation techniques to\nrecursively parse videos into object components, which are represented as\ntransformed versions of learned object prototypes, enabling accurate and\ninterpretable tracking. By explicitly modeling object motion through a\ncombination of frequency domain operations and lightweight learned modules,\nVideoPCDNet enables accurate unsupervised object tracking and prediction of\nfuture video frames. In our experiments, we demonstrate that VideoPCDNet\noutperforms multiple object-centric baseline models for unsupervised tracking\nand prediction on several synthetic datasets, while learning interpretable\nobject and motion representations.",
      "pdf_url": "http://arxiv.org/pdf/2506.19621v1",
      "published": "2025-06-24T13:39:47+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.19621v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Position: Intelligent Science Laboratory Requires the Integration of Cognitive and Embodied AI",
      "authors": [
        "Sha Zhang",
        "Suorong Yang",
        "Tong Xie",
        "Xiangyuan Xue",
        "Zixuan Hu",
        "Rui Li",
        "Wenxi Qu",
        "Zhenfei Yin",
        "Tianfan Fu",
        "Di Hu",
        "Andres M Bran",
        "Nian Ran",
        "Bram Hoex",
        "Wangmeng Zuo",
        "Philippe Schwaller",
        "Wanli Ouyang",
        "Lei Bai",
        "Yanyong Zhang",
        "Lingyu Duan",
        "Shixiang Tang",
        "Dongzhan Zhou"
      ],
      "abstract": "Scientific discovery has long been constrained by human limitations in\nexpertise, physical capability, and sleep cycles. The recent rise of AI\nscientists and automated laboratories has accelerated both the cognitive and\noperational aspects of research. However, key limitations persist: AI systems\nare often confined to virtual environments, while automated laboratories lack\nthe flexibility and autonomy to adaptively test new hypotheses in the physical\nworld. Recent advances in embodied AI, such as generalist robot foundation\nmodels, diffusion-based action policies, fine-grained manipulation learning,\nand sim-to-real transfer, highlight the promise of integrating cognitive and\nembodied intelligence. This convergence opens the door to closed-loop systems\nthat support iterative, autonomous experimentation and the possibility of\nserendipitous discovery. In this position paper, we propose the paradigm of\nIntelligent Science Laboratories (ISLs): a multi-layered, closed-loop framework\nthat deeply integrates cognitive and embodied intelligence. ISLs unify\nfoundation models for scientific reasoning, agent-based workflow orchestration,\nand embodied agents for robust physical experimentation. We argue that such\nsystems are essential for overcoming the current limitations of scientific\ndiscovery and for realizing the full transformative potential of AI-driven\nscience.",
      "pdf_url": "http://arxiv.org/pdf/2506.19613v1",
      "published": "2025-06-24T13:31:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.19613v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "ChordPrompt: Orchestrating Cross-Modal Prompt Synergy for Multi-Domain Incremental Learning in CLIP",
      "authors": [
        "Zhiyuan Wang",
        "Bokui Chen"
      ],
      "abstract": "Continual learning (CL) empowers pre-trained vision-language models to adapt\neffectively to novel or previously underrepresented data distributions without\ncomprehensive retraining, enhancing their adaptability and efficiency. While\nvision-language models like CLIP show great promise, they struggle to maintain\nperformance across domains in incremental learning scenarios. Existing prompt\nlearning methods face two main limitations: 1) they primarily focus on\nclass-incremental learning scenarios, lacking specific strategies for\nmulti-domain task incremental learning; 2) most current approaches employ\nsingle-modal prompts, neglecting the potential benefits of cross-modal\ninformation exchange. To address these challenges, we propose the \\ChordPrompt\nframework, which facilitates a harmonious interplay between visual and textual\nprompts. \\ChordPrompt introduces cross-modal prompts to leverage interactions\nbetween visual and textual information. Our approach also employs\ndomain-adaptive text prompts to select appropriate prompts for continual\nadaptation across multiple domains. Comprehensive experiments on multi-domain\nincremental learning benchmarks demonstrate that \\ChordPrompt outperforms\nstate-of-the-art methods in zero-shot generalization and downstream task\nperformance.",
      "pdf_url": "http://arxiv.org/pdf/2506.19608v1",
      "published": "2025-06-24T13:22:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.19608v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "ECCoT: A Framework for Enhancing Effective Cognition via Chain of Thought in Large Language Model",
      "authors": [
        "Zhenke Duan",
        "Jiqun Pan",
        "Jiani Tu",
        "Xiaoyi Wang",
        "Yanqing Wang"
      ],
      "abstract": "In the era of large-scale artificial intelligence, Large Language Models\n(LLMs) have made significant strides in natural language processing. However,\nthey often lack transparency and generate unreliable outputs, raising concerns\nabout their interpretability. To address this, the Chain of Thought (CoT)\nprompting method structures reasoning into step-by-step deductions. Yet, not\nall reasoning chains are valid, and errors can lead to unreliable conclusions.\nWe propose ECCoT, an End-to-End Cognitive Chain of Thought Validation\nFramework, to evaluate and refine reasoning chains in LLMs. ECCoT integrates\nthe Markov Random Field-Embedded Topic Model (MRF-ETM) for topic-aware CoT\ngeneration and Causal Sentence-BERT (CSBert) for causal reasoning alignment. By\nfiltering ineffective chains using structured ordering statistics, ECCoT\nimproves interpretability, reduces biases, and enhances the trustworthiness of\nLLM-based decision-making. Key contributions include the introduction of ECCoT,\nMRF-ETM for topic-driven CoT generation, and CSBert for causal reasoning\nenhancement. Code is released at: https://github.com/erwinmsmith/ECCoT.git.",
      "pdf_url": "http://arxiv.org/pdf/2506.19599v1",
      "published": "2025-06-24T13:09:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.19599v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Robotics Under Construction: Challenges on Job Sites",
      "authors": [
        "Haruki Uchiito",
        "Akhilesh Bhat",
        "Koji Kusaka",
        "Xiaoya Zhang",
        "Hiraku Kinjo",
        "Honoka Uehara",
        "Motoki Koyama",
        "Shinji Natsume"
      ],
      "abstract": "As labor shortages and productivity stagnation increasingly challenge the\nconstruction industry, automation has become essential for sustainable\ninfrastructure development. This paper presents an autonomous payload\ntransportation system as an initial step toward fully unmanned construction\nsites. Our system, based on the CD110R-3 crawler carrier, integrates autonomous\nnavigation, fleet management, and GNSS-based localization to facilitate\nmaterial transport in construction site environments. While the current system\ndoes not yet incorporate dynamic environment adaptation algorithms, we have\nbegun fundamental investigations into external-sensor based perception and\nmapping system. Preliminary results highlight the potential challenges,\nincluding navigation in evolving terrain, environmental perception under\nconstruction-specific conditions, and sensor placement optimization for\nimproving autonomy and efficiency. Looking forward, we envision a construction\necosystem where collaborative autonomous agents dynamically adapt to site\nconditions, optimizing workflow and reducing human intervention. This paper\nprovides foundational insights into the future of robotics-driven construction\nautomation and identifies critical areas for further technological development.",
      "pdf_url": "http://arxiv.org/pdf/2506.19597v1",
      "published": "2025-06-24T13:07:43+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.19597v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.AR",
        "cs.ET",
        "cs.SY",
        "eess.SY"
      ]
    },
    {
      "title": "Adaptive Domain Modeling with Language Models: A Multi-Agent Approach to Task Planning",
      "authors": [
        "Harisankar Babu",
        "Philipp Schillinger",
        "Tamim Asfour"
      ],
      "abstract": "We introduce TAPAS (Task-based Adaptation and Planning using AgentS), a\nmulti-agent framework that integrates Large Language Models (LLMs) with\nsymbolic planning to solve complex tasks without the need for manually defined\nenvironment models. TAPAS employs specialized LLM-based agents that\ncollaboratively generate and adapt domain models, initial states, and goal\nspecifications as needed using structured tool-calling mechanisms. Through this\ntool-based interaction, downstream agents can request modifications from\nupstream agents, enabling adaptation to novel attributes and constraints\nwithout manual domain redefinition. A ReAct (Reason+Act)-style execution agent,\ncoupled with natural language plan translation, bridges the gap between\ndynamically generated plans and real-world robot capabilities. TAPAS\ndemonstrates strong performance in benchmark planning domains and in the\nVirtualHome simulated real-world environment.",
      "pdf_url": "http://arxiv.org/pdf/2506.19592v1",
      "published": "2025-06-24T13:02:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.19592v1",
      "categories": [
        "cs.AI",
        "cs.RO"
      ]
    },
    {
      "title": "Vision Transformer-Based Time-Series Image Reconstruction for Cloud-Filling Applications",
      "authors": [
        "Lujun Li",
        "Yiqun Wang",
        "Radu State"
      ],
      "abstract": "Cloud cover in multispectral imagery (MSI) poses significant challenges for\nearly season crop mapping, as it leads to missing or corrupted spectral\ninformation. Synthetic aperture radar (SAR) data, which is not affected by\ncloud interference, offers a complementary solution, but lack sufficient\nspectral detail for precise crop mapping. To address this, we propose a novel\nframework, Time-series MSI Image Reconstruction using Vision Transformer (ViT),\nto reconstruct MSI data in cloud-covered regions by leveraging the temporal\ncoherence of MSI and the complementary information from SAR from the attention\nmechanism. Comprehensive experiments, using rigorous reconstruction evaluation\nmetrics, demonstrate that Time-series ViT framework significantly outperforms\nbaselines that use non-time-series MSI and SAR or time-series MSI without SAR,\neffectively enhancing MSI image reconstruction in cloud-covered regions.",
      "pdf_url": "http://arxiv.org/pdf/2506.19591v1",
      "published": "2025-06-24T13:00:36+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.19591v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "eess.IV"
      ]
    },
    {
      "title": "Fake or Real, Can Robots Tell? Evaluating Embodied Vision-Language Models on Real and 3D-Printed Objects",
      "authors": [
        "Federico Tavella",
        "Kathryn Mearns",
        "Angelo Cangelosi"
      ],
      "abstract": "Robotic scene understanding increasingly relies on vision-language models\n(VLMs) to generate natural language descriptions of the environment. In this\nwork, we present a comparative study of captioning strategies for tabletop\nscenes captured by a robotic arm equipped with an RGB camera. The robot\ncollects images of objects from multiple viewpoints, and we evaluate several\nmodels that generate scene descriptions. We compare the performance of various\ncaptioning models, like BLIP and VLMs. Our experiments examine the trade-offs\nbetween single-view and multi-view captioning, and difference between\nrecognising real-world and 3D printed objects. We quantitatively evaluate\nobject identification accuracy, completeness, and naturalness of the generated\ncaptions. Results show that VLMs can be used in robotic settings where common\nobjects need to be recognised, but fail to generalise to novel representations.\nOur findings provide practical insights into deploying foundation models for\nembodied agents in real-world settings.",
      "pdf_url": "http://arxiv.org/pdf/2506.19579v1",
      "published": "2025-06-24T12:45:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.19579v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG"
      ]
    },
    {
      "title": "Towards an Introspective Dynamic Model of Globally Distributed Computing Infrastructures",
      "authors": [
        "Ozgur O. Kilic",
        "David K. Park",
        "Yihui Ren",
        "Tatiana Korchuganova",
        "Sairam Sri Vatsavai",
        "Joseph Boudreau",
        "Tasnuva Chowdhury",
        "Shengyu Feng",
        "Raees Khan",
        "Jaehyung Kim",
        "Scott Klasky",
        "Tadashi Maeno",
        "Paul Nilsson",
        "Verena Ingrid Martinez Outschoorn",
        "Norbert Podhorszki",
        "Frédéric Suter",
        "Wei Yang",
        "Yiming Yang",
        "Shinjae Yoo",
        "Alexei Klimentov",
        "Adolfy Hoisie"
      ],
      "abstract": "Large-scale scientific collaborations like ATLAS, Belle II, CMS, DUNE, and\nothers involve hundreds of research institutes and thousands of researchers\nspread across the globe. These experiments generate petabytes of data, with\nvolumes soon expected to reach exabytes. Consequently, there is a growing need\nfor computation, including structured data processing from raw data to\nconsumer-ready derived data, extensive Monte Carlo simulation campaigns, and a\nwide range of end-user analysis. To manage these computational and storage\ndemands, centralized workflow and data management systems are implemented.\nHowever, decisions regarding data placement and payload allocation are often\nmade disjointly and via heuristic means. A significant obstacle in adopting\nmore effective heuristic or AI-driven solutions is the absence of a quick and\nreliable introspective dynamic model to evaluate and refine alternative\napproaches. In this study, we aim to develop such an interactive system using\nreal-world data. By examining job execution records from the PanDA workflow\nmanagement system, we have pinpointed key performance indicators such as\nqueuing time, error rate, and the extent of remote data access. The dataset\nincludes five months of activity. Additionally, we are creating a generative AI\nmodel to simulate time series of payloads, which incorporate visible features\nlike category, event count, and submitting group, as well as hidden features\nlike the total computational load-derived from existing PanDA records and\ncomputing site capabilities. These hidden features, which are not visible to\njob allocators, whether heuristic or AI-driven, influence factors such as\nqueuing times and data movement.",
      "pdf_url": "http://arxiv.org/pdf/2506.19578v1",
      "published": "2025-06-24T12:42:36+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.19578v1",
      "categories": [
        "cs.DC",
        "cs.AI"
      ]
    },
    {
      "title": "Interpretable Hybrid Machine Learning Models Using FOLD-R++ and Answer Set Programming",
      "authors": [
        "Sanne Wielinga",
        "Jesse Heyninck"
      ],
      "abstract": "Machine learning (ML) techniques play a pivotal role in high-stakes domains\nsuch as healthcare, where accurate predictions can greatly enhance\ndecision-making. However, most high-performing methods such as neural networks\nand ensemble methods are often opaque, limiting trust and broader adoption. In\nparallel, symbolic methods like Answer Set Programming (ASP) offer the\npossibility of interpretable logical rules but do not always match the\npredictive power of ML models. This paper proposes a hybrid approach that\nintegrates ASP-derived rules from the FOLD-R++ algorithm with black-box ML\nclassifiers to selectively correct uncertain predictions and provide\nhuman-readable explanations. Experiments on five medical datasets reveal\nstatistically significant performance gains in accuracy and F1 score. This\nstudy underscores the potential of combining symbolic reasoning with\nconventional ML to achieve high interpretability without sacrificing accuracy.",
      "pdf_url": "http://arxiv.org/pdf/2506.19573v1",
      "published": "2025-06-24T12:37:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.19573v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Has Machine Translation Evaluation Achieved Human Parity? The Human Reference and the Limits of Progress",
      "authors": [
        "Lorenzo Proietti",
        "Stefano Perrella",
        "Roberto Navigli"
      ],
      "abstract": "In Machine Translation (MT) evaluation, metric performance is assessed based\non agreement with human judgments. In recent years, automatic metrics have\ndemonstrated increasingly high levels of agreement with humans. To gain a\nclearer understanding of metric performance and establish an upper bound, we\nincorporate human baselines in the MT meta-evaluation, that is, the assessment\nof MT metrics' capabilities. Our results show that human annotators are not\nconsistently superior to automatic metrics, with state-of-the-art metrics often\nranking on par with or higher than human baselines. Despite these findings\nsuggesting human parity, we discuss several reasons for caution. Finally, we\nexplore the broader implications of our results for the research field, asking:\nCan we still reliably measure improvements in MT evaluation? With this work, we\naim to shed light on the limits of our ability to measure progress in the\nfield, fostering discussion on an issue that we believe is crucial to the\nentire MT evaluation community.",
      "pdf_url": "http://arxiv.org/pdf/2506.19571v1",
      "published": "2025-06-24T12:35:00+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.19571v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "FAF: A Feature-Adaptive Framework for Few-Shot Time Series Forecasting",
      "authors": [
        "Pengpeng Ouyang",
        "Dong Chen",
        "Tong Yang",
        "Shuo Feng",
        "Zhao Jin",
        "Mingliang Xu"
      ],
      "abstract": "Multi-task and few-shot time series forecasting tasks are commonly\nencountered in scenarios such as the launch of new products in different\ncities. However, traditional time series forecasting methods suffer from\ninsufficient historical data, which stems from a disregard for the generalized\nand specific features among different tasks. For the aforementioned challenges,\nwe propose the Feature-Adaptive Time Series Forecasting Framework (FAF), which\nconsists of three key components: the Generalized Knowledge Module (GKM), the\nTask-Specific Module (TSM), and the Rank Module (RM). During training phase,\nthe GKM is updated through a meta-learning mechanism that enables the model to\nextract generalized features across related tasks. Meanwhile, the TSM is\ntrained to capture diverse local dynamics through multiple functional regions,\neach of which learns specific features from individual tasks. During testing\nphase, the RM dynamically selects the most relevant functional region from the\nTSM based on input sequence features, which is then combined with the\ngeneralized knowledge learned by the GKM to generate accurate forecasts. This\ndesign enables FAF to achieve robust and personalized forecasting even with\nsparse historical observations We evaluate FAF on five diverse real-world\ndatasets under few-shot time series forecasting settings. Experimental results\ndemonstrate that FAF consistently outperforms baselines that include three\ncategories of time series forecasting methods. In particular, FAF achieves a\n41.81\\% improvement over the best baseline, iTransformer, on the CO$_2$\nemissions dataset.",
      "pdf_url": "http://arxiv.org/pdf/2506.19567v1",
      "published": "2025-06-24T12:28:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.19567v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "PrivacyXray: Detecting Privacy Breaches in LLMs through Semantic Consistency and Probability Certainty",
      "authors": [
        "Jinwen He",
        "Yiyang Lu",
        "Zijin Lin",
        "Kai Chen",
        "Yue Zhao"
      ],
      "abstract": "Large Language Models (LLMs) are widely used in sensitive domains, including\nhealthcare, finance, and legal services, raising concerns about potential\nprivate information leaks during inference. Privacy extraction attacks, such as\njailbreaking, expose vulnerabilities in LLMs by crafting inputs that force the\nmodels to output sensitive information. However, these attacks cannot verify\nwhether the extracted private information is accurate, as no public datasets\nexist for cross-validation, leaving a critical gap in private information\ndetection during inference. To address this, we propose PrivacyXray, a novel\nframework detecting privacy breaches by analyzing LLM inner states. Our\nanalysis reveals that LLMs exhibit higher semantic coherence and probabilistic\ncertainty when generating correct private outputs. Based on this, PrivacyXray\ndetects privacy breaches using four metrics: intra-layer and inter-layer\nsemantic similarity, token-level and sentence-level probability distributions.\nPrivacyXray addresses critical challenges in private information detection by\novercoming the lack of open-source private datasets and eliminating reliance on\nexternal data for validation. It achieves this through the synthesis of\nrealistic private data and a detection mechanism based on the inner states of\nLLMs. Experiments show that PrivacyXray achieves consistent performance, with\nan average accuracy of 92.69% across five LLMs. Compared to state-of-the-art\nmethods, PrivacyXray achieves significant improvements, with an average\naccuracy increase of 20.06%, highlighting its stability and practical utility\nin real-world applications.",
      "pdf_url": "http://arxiv.org/pdf/2506.19563v1",
      "published": "2025-06-24T12:22:59+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.19563v1",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "title": "MambaOutRS: A Hybrid CNN-Fourier Architecture for Remote Sensing Image Classification",
      "authors": [
        "Minjong Cheon",
        "Changbae Mun"
      ],
      "abstract": "Recent advances in deep learning for vision tasks have seen the rise of State\nSpace Models (SSMs) like Mamba, celebrated for their linear scalability.\nHowever, their adaptation to 2D visual data often necessitates complex\nmodifications that may diminish efficiency. In this paper, we introduce\nMambaOutRS, a novel hybrid convolutional architecture for remote sensing image\nclassification that re-evaluates the necessity of recurrent SSMs. MambaOutRS\nbuilds upon stacked Gated CNN blocks for local feature extraction and\nintroduces a novel Fourier Filter Gate (FFG) module that operates in the\nfrequency domain to capture global contextual information efficiently. Our\narchitecture employs a four-stage hierarchical design and was extensively\nevaluated on challenging remote sensing datasets: UC Merced, AID,\nNWPU-RESISC45, and EuroSAT. MambaOutRS consistently achieved state-of-the-art\n(SOTA) performance across these benchmarks. Notably, our MambaOutRS-t variant\n(24.0M parameters) attained the highest F1-scores of 98.41\\% on UC Merced and\n95.99\\% on AID, significantly outperforming existing baselines, including\nlarger transformer models and Mamba-based architectures, despite using\nconsiderably fewer parameters. An ablation study conclusively demonstrates the\ncritical role of the Fourier Filter Gate in enhancing the model's ability to\ncapture global spatial patterns, leading to robust and accurate classification.\nThese results strongly suggest that the complexities of recurrent SSMs can be\neffectively superseded by a judicious combination of gated convolutions for\nspatial mixing and frequency-based gates for spectral global context. Thus,\nMambaOutRS provides a compelling and efficient paradigm for developing\nhigh-performance deep learning models in remote sensing and other vision\ndomains, particularly where computational efficiency is paramount.",
      "pdf_url": "http://arxiv.org/pdf/2506.19561v1",
      "published": "2025-06-24T12:20:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.19561v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    }
  ]
}