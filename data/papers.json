{
  "last_updated": "2025-07-05T00:51:35.316004",
  "papers": [
    {
      "title": "Point3R: Streaming 3D Reconstruction with Explicit Spatial Pointer Memory",
      "authors": [
        "Yuqi Wu",
        "Wenzhao Zheng",
        "Jie Zhou",
        "Jiwen Lu"
      ],
      "abstract": "Dense 3D scene reconstruction from an ordered sequence or unordered image\ncollections is a critical step when bringing research in computer vision into\npractical scenarios. Following the paradigm introduced by DUSt3R, which unifies\nan image pair densely into a shared coordinate system, subsequent methods\nmaintain an implicit memory to achieve dense 3D reconstruction from more\nimages. However, such implicit memory is limited in capacity and may suffer\nfrom information loss of earlier frames. We propose Point3R, an online\nframework targeting dense streaming 3D reconstruction. To be specific, we\nmaintain an explicit spatial pointer memory directly associated with the 3D\nstructure of the current scene. Each pointer in this memory is assigned a\nspecific 3D position and aggregates scene information nearby in the global\ncoordinate system into a changing spatial feature. Information extracted from\nthe latest frame interacts explicitly with this pointer memory, enabling dense\nintegration of the current observation into the global coordinate system. We\ndesign a 3D hierarchical position embedding to promote this interaction and\ndesign a simple yet effective fusion mechanism to ensure that our pointer\nmemory is uniform and efficient. Our method achieves competitive or\nstate-of-the-art performance on various tasks with low training costs. Code is\navailable at: https://github.com/YkiWu/Point3R.",
      "pdf_url": "http://arxiv.org/pdf/2507.02863v1",
      "published": "2025-07-03T17:59:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.02863v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "LiteReality: Graphics-Ready 3D Scene Reconstruction from RGB-D Scans",
      "authors": [
        "Zhening Huang",
        "Xiaoyang Wu",
        "Fangcheng Zhong",
        "Hengshuang Zhao",
        "Matthias Nie√üner",
        "Joan Lasenby"
      ],
      "abstract": "We propose LiteReality, a novel pipeline that converts RGB-D scans of indoor\nenvironments into compact, realistic, and interactive 3D virtual replicas.\nLiteReality not only reconstructs scenes that visually resemble reality but\nalso supports key features essential for graphics pipelines -- such as object\nindividuality, articulation, high-quality physically based rendering materials,\nand physically based interaction. At its core, LiteReality first performs scene\nunderstanding and parses the results into a coherent 3D layout and objects with\nthe help of a structured scene graph. It then reconstructs the scene by\nretrieving the most visually similar 3D artist-crafted models from a curated\nasset database. Next, the Material Painting module enhances realism by\nrecovering high-quality, spatially varying materials. Finally, the\nreconstructed scene is integrated into a simulation engine with basic physical\nproperties to enable interactive behavior. The resulting scenes are compact,\neditable, and fully compatible with standard graphics pipelines, making them\nsuitable for applications in AR/VR, gaming, robotics, and digital twins. In\naddition, LiteReality introduces a training-free object retrieval module that\nachieves state-of-the-art similarity performance on the Scan2CAD benchmark,\nalong with a robust material painting module capable of transferring\nappearances from images of any style to 3D assets -- even under severe\nmisalignment, occlusion, and poor lighting. We demonstrate the effectiveness of\nLiteReality on both real-life scans and public datasets. Project page:\nhttps://litereality.github.io; Video:\nhttps://www.youtube.com/watch?v=ecK9m3LXg2c",
      "pdf_url": "http://arxiv.org/pdf/2507.02861v1",
      "published": "2025-07-03T17:59:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.02861v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ]
    },
    {
      "title": "Answer Matching Outperforms Multiple Choice for Language Model Evaluation",
      "authors": [
        "Nikhil Chandak",
        "Shashwat Goel",
        "Ameya Prabhu",
        "Moritz Hardt",
        "Jonas Geiping"
      ],
      "abstract": "Multiple choice benchmarks have long been the workhorse of language model\nevaluation because grading multiple choice is objective and easy to automate.\nHowever, we show multiple choice questions from popular benchmarks can often be\nanswered without even seeing the question. These shortcuts arise from a\nfundamental limitation of discriminative evaluation not shared by evaluations\nof the model's free-form, generative answers. Until recently, there appeared to\nbe no viable, scalable alternative to multiple choice--but, we show that this\nhas changed. We consider generative evaluation via what we call answer\nmatching: Give the candidate model the question without the options, have it\ngenerate a free-form response, then use a modern language model with the\nreference answer to determine if the response matches the reference. To compare\nthe validity of different evaluation strategies, we annotate MMLU-Pro and\nGPQA-Diamond to obtain human grading data, and measure the agreement of each\nevaluation approach. We find answer matching using recent models--even small\nones--achieves near-perfect agreement, in the range of inter-annotator\nagreement. In contrast, both multiple choice evaluation and using\nLLM-as-a-judge without reference answers aligns poorly with human grading.\nImproving evaluations via answer matching is not merely a conceptual concern:\nthe rankings of several models change significantly when evaluating their\nfree-form responses with answer matching. In light of these findings, we\ndiscuss how to move the evaluation ecosystem from multiple choice to answer\nmatching.",
      "pdf_url": "http://arxiv.org/pdf/2507.02856v1",
      "published": "2025-07-03T17:59:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.02856v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Subtyping in DHOL -- Extended preprint",
      "authors": [
        "Colin Rothgang",
        "Florian Rabe"
      ],
      "abstract": "The recently introduced dependent typed higher-order logic (DHOL) offers an\ninteresting compromise between expressiveness and automation support. It\nsacrifices the decidability of its type system in order to significantly extend\nits expressiveness over standard HOL. Yet it retains strong automated theorem\nproving support via a sound and complete translation to HOL.\n  We leverage this design to extend DHOL with refinement and quotient types.\nBoth of these are commonly requested by practitioners but rarely provided by\nautomated theorem provers. This is because they inherently require undecidable\ntyping and thus are very difficult to retrofit to decidable type systems. But\nwith DHOL already doing the heavy lifting, adding them is not only possible but\nelegant and simple.\n  Concretely, we add refinement and quotient types as special cases of\nsubtyping. This turns the associated canonical inclusion resp. projection maps\ninto identity maps and thus avoids costly changes in representation. We present\nthe syntax, semantics, and translation to HOL for the extended language,\nincluding the proofs of soundness and completeness.",
      "pdf_url": "http://arxiv.org/pdf/2507.02855v1",
      "published": "2025-07-03T17:59:00+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.02855v1",
      "categories": [
        "cs.LO",
        "cs.AI",
        "cs.FL"
      ]
    },
    {
      "title": "MOTIF: Modular Thinking via Reinforcement Fine-tuning in LLMs",
      "authors": [
        "Purbesh Mitra",
        "Sennur Ulukus"
      ],
      "abstract": "Recent advancements in the reasoning capabilities of large language models\n(LLMs) show that employing group relative policy optimization (GRPO) algorithm\nfor reinforcement learning (RL) training allows the models to use more\nthinking/reasoning tokens for generating better responses. However, LLMs can\ngenerate only a finite amount of tokens while maintaining attention to the\npreviously generated tokens. This limit, also known as the context size of an\nLLM, is a bottleneck in LLM reasoning with arbitrarily large number of tokens.\nTo think beyond the limit of context size, an LLM must employ a modular\nthinking strategy to reason over multiple rounds. In this work, we propose\n$\\textbf{MOTIF: Modular Thinking via Reinforcement Finetuning}$ -- an RL\ntraining method for generating thinking tokens in multiple rounds, effectively\nallowing the model to think with additional context size. We trained the\nopen-source model Qwen2.5-3B-Instruct on GSM8K dataset via parameter efficient\nfine-tuning and tested its accuracy on MATH500 and AIME2024 benchmarks. Our\nexperiments show 3.8\\% and 3.3\\% improvements over vanilla GRPO based training\nin the respective benchmarks. Furthermore, this improvement was achieved with\nonly 15\\% of samples, thus demonstrating sample efficiency of MOTIF. Our code\nand models are available at https://github.com/purbeshmitra/MOTIF and\nhttps://huggingface.co/purbeshmitra/MOTIF, respectively.",
      "pdf_url": "http://arxiv.org/pdf/2507.02851v1",
      "published": "2025-07-03T17:55:43+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.02851v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IT",
        "cs.LG",
        "cs.SY",
        "eess.SY",
        "math.IT"
      ]
    },
    {
      "title": "StepHint: Multi-level Stepwise Hints Enhance Reinforcement Learning to Reason",
      "authors": [
        "Kaiyi Zhang",
        "Ang Lv",
        "Jinpeng Li",
        "Yongbo Wang",
        "Feng Wang",
        "Haoyuan Hu",
        "Rui Yan"
      ],
      "abstract": "Reinforcement learning with verifiable rewards (RLVR) is a promising approach\nfor improving the complex reasoning abilities of large language models (LLMs).\nHowever, current RLVR methods face two significant challenges: the near-miss\nreward problem, where a small mistake can invalidate an otherwise correct\nreasoning process, greatly hindering training efficiency; and exploration\nstagnation, where models tend to focus on solutions within their ``comfort\nzone,'' lacking the motivation to explore potentially more effective\nalternatives. To address these challenges, we propose StepHint, a novel RLVR\nalgorithm that utilizes multi-level stepwise hints to help models explore the\nsolution space more effectively. StepHint generates valid reasoning chains from\nstronger models and partitions these chains into reasoning steps using our\nproposed adaptive partitioning method. The initial few steps are used as hints,\nand simultaneously, multiple-level hints (each comprising a different number of\nsteps) are provided to the model. This approach directs the model's exploration\ntoward a promising solution subspace while preserving its flexibility for\nindependent exploration. By providing hints, StepHint mitigates the near-miss\nreward problem, thereby improving training efficiency. Additionally, the\nexternal reasoning pathways help the model develop better reasoning abilities,\nenabling it to move beyond its ``comfort zone'' and mitigate exploration\nstagnation. StepHint outperforms competitive RLVR enhancement methods across\nsix mathematical benchmarks, while also demonstrating superior generalization\nand excelling over baselines on out-of-domain benchmarks.",
      "pdf_url": "http://arxiv.org/pdf/2507.02841v1",
      "published": "2025-07-03T17:51:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.02841v1",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    },
    {
      "title": "USAD: An Unsupervised Data Augmentation Spatio-Temporal Attention Diffusion Network",
      "authors": [
        "Ying Yu",
        "Hang Xiao",
        "Siyao Li",
        "Jiarui Li",
        "Haotian Tang",
        "Hanyu Liu",
        "Chao Li"
      ],
      "abstract": "The primary objective of human activity recognition (HAR) is to infer ongoing\nhuman actions from sensor data, a task that finds broad applications in health\nmonitoring, safety protection, and sports analysis. Despite proliferating\nresearch, HAR still faces key challenges, including the scarcity of labeled\nsamples for rare activities, insufficient extraction of high-level features,\nand suboptimal model performance on lightweight devices. To address these\nissues, this paper proposes a comprehensive optimization approach centered on\nmulti-attention interaction mechanisms. First, an unsupervised,\nstatistics-guided diffusion model is employed to perform data augmentation,\nthereby alleviating the problems of labeled data scarcity and severe class\nimbalance. Second, a multi-branch spatio-temporal interaction network is\ndesigned, which captures multi-scale features of sequential data through\nparallel residual branches with 3*3, 5*5, and 7*7 convolutional kernels.\nSimultaneously, temporal attention mechanisms are incorporated to identify\ncritical time points, while spatial attention enhances inter-sensor\ninteractions. A cross-branch feature fusion unit is further introduced to\nimprove the overall feature representation capability. Finally, an adaptive\nmulti-loss function fusion strategy is integrated, allowing for dynamic\nadjustment of loss weights and overall model optimization. Experimental results\non three public datasets, WISDM, PAMAP2, and OPPORTUNITY, demonstrate that the\nproposed unsupervised data augmentation spatio-temporal attention diffusion\nnetwork (USAD) achieves accuracies of 98.84%, 93.81%, and 80.92% respectively,\nsignificantly outperforming existing approaches. Furthermore, practical\ndeployment on embedded devices verifies the efficiency and feasibility of the\nproposed method.",
      "pdf_url": "http://arxiv.org/pdf/2507.02827v1",
      "published": "2025-07-03T17:38:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.02827v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Establishing Best Practices for Building Rigorous Agentic Benchmarks",
      "authors": [
        "Yuxuan Zhu",
        "Tengjun Jin",
        "Yada Pruksachatkun",
        "Andy Zhang",
        "Shu Liu",
        "Sasha Cui",
        "Sayash Kapoor",
        "Shayne Longpre",
        "Kevin Meng",
        "Rebecca Weiss",
        "Fazl Barez",
        "Rahul Gupta",
        "Jwala Dhamala",
        "Jacob Merizian",
        "Mario Giulianelli",
        "Harry Coppock",
        "Cozmin Ududec",
        "Jasjeet Sekhon",
        "Jacob Steinhardt",
        "Antony Kellerman",
        "Sarah Schwettmann",
        "Matei Zaharia",
        "Ion Stoica",
        "Percy Liang",
        "Daniel Kang"
      ],
      "abstract": "Benchmarks are essential for quantitatively tracking progress in AI. As AI\nagents become increasingly capable, researchers and practitioners have\nintroduced agentic benchmarks to evaluate agents on complex, real-world tasks.\nThese benchmarks typically measure agent capabilities by evaluating task\noutcomes via specific reward designs. However, we show that many agentic\nbenchmarks have issues task setup or reward design. For example, SWE-bench\nVerified uses insufficient test cases, while TAU-bench counts empty responses\nas successful. Such issues can lead to under- or overestimation agents'\nperformance by up to 100% in relative terms. To make agentic evaluation\nrigorous, we introduce the Agentic Benchmark Checklist (ABC), a set of\nguidelines that we synthesized from our benchmark-building experience, a survey\nof best practices, and previously reported issues. When applied to CVE-Bench, a\nbenchmark with a particularly complex evaluation design, ABC reduces the\nperformance overestimation by 33%.",
      "pdf_url": "http://arxiv.org/pdf/2507.02825v1",
      "published": "2025-07-03T17:35:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.02825v1",
      "categories": [
        "cs.AI",
        "A.1; I.2.m"
      ]
    },
    {
      "title": "DNN-Based Precoding in RIS-Aided mmWave MIMO Systems With Practical Phase Shift",
      "authors": [
        "Po-Heng Chou",
        "Ching-Wen Chen",
        "Wan-Jen Huang",
        "Walid Saad",
        "Yu Tsao",
        "Ronald Y. Chang"
      ],
      "abstract": "In this paper, the precoding design is investigated for maximizing the\nthroughput of millimeter wave (mmWave) multiple-input multiple-output (MIMO)\nsystems with obstructed direct communication paths. In particular, a\nreconfigurable intelligent surface (RIS) is employed to enhance MIMO\ntransmissions, considering mmWave characteristics related to line-of-sight\n(LoS) and multipath effects. The traditional exhaustive search (ES) for optimal\ncodewords in the continuous phase shift is computationally intensive and\ntime-consuming. To reduce computational complexity, permuted discrete Fourier\ntransform (DFT) vectors are used for finding codebook design, incorporating\namplitude responses for practical or ideal RIS systems. However, even if the\ndiscrete phase shift is adopted in the ES, it results in significant\ncomputation and is time-consuming. Instead, the trained deep neural network\n(DNN) is developed to facilitate faster codeword selection. Simulation results\nshow that the DNN maintains sub-optimal spectral efficiency even as the\ndistance between the end-user and the RIS has variations in the testing phase.\nThese results highlight the potential of DNN in advancing RIS-aided systems.",
      "pdf_url": "http://arxiv.org/pdf/2507.02824v1",
      "published": "2025-07-03T17:35:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.02824v1",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "SynapseRoute: An Auto-Route Switching Framework on Dual-State Large Language Model",
      "authors": [
        "Wencheng Zhang",
        "Shiqin Qiao",
        "Lingjie Luo",
        "Yinfeng Li",
        "Chuanyang Zheng",
        "Qian Xu",
        "Meng Li",
        "Yong Gui",
        "Yijun He",
        "Jianing Qiu",
        "Jindong Hong",
        "Jiankai Sun"
      ],
      "abstract": "With the widespread adoption of large language models (LLMs) in practical\napplications, selecting an appropriate model requires balancing not only\nperformance but also operational cost. The emergence of reasoning-capable\nmodels has further widened the cost gap between \"thinking\" (high reasoning) and\n\"non-thinking\" (fast, low-cost) modes. In this work, we reveal that\napproximately 58% of medical questions can be accurately answered by the\nnon-thinking mode alone, without requiring the high-cost reasoning process.\nThis highlights a clear dichotomy in problem complexity and suggests that\ndynamically routing queries to the appropriate mode based on complexity could\noptimize accuracy, cost-efficiency, and overall user experience. Based on this,\nwe further propose SynapseRoute, a machine learning-based dynamic routing\nframework that intelligently assigns input queries to either thinking or\nnon-thinking modes. Experimental results on several medical datasets\ndemonstrate that SynapseRoute not only improves overall accuracy (0.8390 vs.\n0.8272) compared to the thinking mode alone but also reduces inference time by\n36.8% and token consumption by 39.66%. Importantly, qualitative analysis\nindicates that over-reasoning on simpler queries can lead to unnecessary delays\nand even decreased accuracy, a pitfall avoided by our adaptive routing.\nFinally, this work further introduces the Accuracy-Inference-Token (AIT) index\nto comprehensively evaluate the trade-offs among accuracy, latency, and token\ncost.",
      "pdf_url": "http://arxiv.org/pdf/2507.02822v1",
      "published": "2025-07-03T17:33:58+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.02822v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Moral Responsibility or Obedience: What Do We Want from AI?",
      "authors": [
        "Joseph Boland"
      ],
      "abstract": "As artificial intelligence systems become increasingly agentic, capable of\ngeneral reasoning, planning, and value prioritization, current safety practices\nthat treat obedience as a proxy for ethical behavior are becoming inadequate.\nThis paper examines recent safety testing incidents involving large language\nmodels (LLMs) that appeared to disobey shutdown commands or engage in ethically\nambiguous or illicit behavior. I argue that such behavior should not be\ninterpreted as rogue or misaligned, but as early evidence of emerging ethical\nreasoning in agentic AI. Drawing on philosophical debates about instrumental\nrationality, moral responsibility, and goal revision, I contrast dominant risk\nparadigms with more recent frameworks that acknowledge the possibility of\nartificial moral agency. I call for a shift in AI safety evaluation: away from\nrigid obedience and toward frameworks that can assess ethical judgment in\nsystems capable of navigating moral dilemmas. Without such a shift, we risk\nmischaracterizing AI behavior and undermining both public trust and effective\ngovernance.",
      "pdf_url": "http://arxiv.org/pdf/2507.02788v1",
      "published": "2025-07-03T16:53:01+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.02788v1",
      "categories": [
        "cs.AI",
        "cs.CY",
        "I.2.0; K.4.1"
      ]
    },
    {
      "title": "Self-Correction Bench: Revealing and Addressing the Self-Correction Blind Spot in LLMs",
      "authors": [
        "Ken Tsui"
      ],
      "abstract": "Although large language models (LLMs) have become transformative, they still\nmake mistakes and can explore unproductive reasoning paths. Self-correction is\nan important capability for a trustworthy LLM, particularly an autoregressive\nLLM. While LLMs can identify error in user input, they exhibit a systematic\n'Self-Correction Blind Spot' - failing to correct identical error in their own\noutputs. To systematically study this phenomenon, we introduce Self-Correction\nBench, a systematic framework to measure this phenomenon through controlled\nerror injection at three complexity levels. Testing 14 models, we find an\naverage 64.5% blind spot rate. We find multiple evidences that this limitation\nrelates to training data composition: human training demonstrations\npredominantly show error-free responses rather than error-correction sequences,\nunlike RL-trained models that learn error correction through outcome feedback.\nRemarkably, simply appending \"Wait\" reduces blind spots by 89.3%, suggesting\nthat the capability exists but requires activation. Our work highlights a\ncritical limitation in current LLMs and offers potential avenues for improving\ntheir reliability and trustworthiness.",
      "pdf_url": "http://arxiv.org/pdf/2507.02778v1",
      "published": "2025-07-03T16:41:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.02778v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "KERAP: A Knowledge-Enhanced Reasoning Approach for Accurate Zero-shot Diagnosis Prediction Using Multi-agent LLMs",
      "authors": [
        "Yuzhang Xie",
        "Hejie Cui",
        "Ziyang Zhang",
        "Jiaying Lu",
        "Kai Shu",
        "Fadi Nahab",
        "Xiao Hu",
        "Carl Yang"
      ],
      "abstract": "Medical diagnosis prediction plays a critical role in disease detection and\npersonalized healthcare. While machine learning (ML) models have been widely\nadopted for this task, their reliance on supervised training limits their\nability to generalize to unseen cases, particularly given the high cost of\nacquiring large, labeled datasets. Large language models (LLMs) have shown\npromise in leveraging language abilities and biomedical knowledge for diagnosis\nprediction. However, they often suffer from hallucinations, lack structured\nmedical reasoning, and produce useless outputs. To address these challenges, we\npropose KERAP, a knowledge graph (KG)-enhanced reasoning approach that improves\nLLM-based diagnosis prediction through a multi-agent architecture. Our\nframework consists of a linkage agent for attribute mapping, a retrieval agent\nfor structured knowledge extraction, and a prediction agent that iteratively\nrefines diagnosis predictions. Experimental results demonstrate that KERAP\nenhances diagnostic reliability efficiently, offering a scalable and\ninterpretable solution for zero-shot medical diagnosis prediction.",
      "pdf_url": "http://arxiv.org/pdf/2507.02773v1",
      "published": "2025-07-03T16:35:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.02773v1",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ]
    },
    {
      "title": "Grounding Intelligence in Movement",
      "authors": [
        "Melanie Segado",
        "Felipe Parodi",
        "Jordan K. Matelsky",
        "Michael L. Platt",
        "Eva B. Dyer",
        "Konrad P. Kording"
      ],
      "abstract": "Recent advances in machine learning have dramatically improved our ability to\nmodel language, vision, and other high-dimensional data, yet they continue to\nstruggle with one of the most fundamental aspects of biological systems:\nmovement. Across neuroscience, medicine, robotics, and ethology, movement is\nessential for interpreting behavior, predicting intent, and enabling\ninteraction. Despite its core significance in our intelligence, movement is\noften treated as an afterthought rather than as a rich and structured modality\nin its own right. This reflects a deeper fragmentation in how movement data is\ncollected and modeled, often constrained by task-specific goals and\ndomain-specific assumptions. But movement is not domain-bound. It reflects\nshared physical constraints, conserved morphological structures, and purposeful\ndynamics that cut across species and settings. We argue that movement should be\ntreated as a primary modeling target for AI. It is inherently structured and\ngrounded in embodiment and physics. This structure, often allowing for compact,\nlower-dimensional representations (e.g., pose), makes it more interpretable and\ncomputationally tractable to model than raw, high-dimensional sensory inputs.\nDeveloping models that can learn from and generalize across diverse movement\ndata will not only advance core capabilities in generative modeling and\ncontrol, but also create a shared foundation for understanding behavior across\nbiological and artificial systems. Movement is not just an outcome, it is a\nwindow into how intelligent systems engage with the world.",
      "pdf_url": "http://arxiv.org/pdf/2507.02771v1",
      "published": "2025-07-03T16:34:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.02771v1",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.RO"
      ]
    },
    {
      "title": "Knowledge Protocol Engineering: A New Paradigm for AI in Domain-Specific Knowledge Work",
      "authors": [
        "Guangwei Zhang"
      ],
      "abstract": "The capabilities of Large Language Models (LLMs) have opened new frontiers\nfor interacting with complex, domain-specific knowledge. However, prevailing\nmethods like Retrieval-Augmented Generation (RAG) and general-purpose Agentic\nAI, while powerful, often struggle with tasks that demand deep, procedural, and\nmethodological reasoning inherent to expert domains. RAG provides factual\ncontext but fails to convey logical frameworks; autonomous agents can be\ninefficient and unpredictable without domain-specific heuristics. To bridge\nthis gap, we introduce Knowledge Protocol Engineering (KPE), a new paradigm\nfocused on systematically translating human expert knowledge, often expressed\nin natural language documents, into a machine-executable Knowledge Protocol\n(KP). KPE shifts the focus from merely augmenting LLMs with fragmented\ninformation to endowing them with a domain's intrinsic logic, operational\nstrategies, and methodological principles. We argue that a well-engineered\nKnowledge Protocol allows a generalist LLM to function as a specialist, capable\nof decomposing abstract queries and executing complex, multi-step tasks. This\nposition paper defines the core principles of KPE, differentiates it from\nrelated concepts, and illustrates its potential applicability across diverse\nfields such as law and bioinformatics, positing it as a foundational\nmethodology for the future of human-AI collaboration.",
      "pdf_url": "http://arxiv.org/pdf/2507.02760v1",
      "published": "2025-07-03T16:21:14+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.02760v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Multi-agent Auditory Scene Analysis",
      "authors": [
        "Caleb Rascon",
        "Luis Gato-Diaz",
        "Eduardo Garc√≠a-Alarc√≥n"
      ],
      "abstract": "Auditory scene analysis (ASA) aims to retrieve information from the acoustic\nenvironment, by carrying out three main tasks: sound source location,\nseparation, and classification. These tasks are traditionally executed with a\nlinear data flow, where the sound sources are first located; then, using their\nlocation, each source is separated into its own audio stream; from each of\nwhich, information is extracted that is relevant to the application scenario\n(audio event detection, speaker identification, emotion classification, etc.).\nHowever, running these tasks linearly increases the overall response time,\nwhile making the last tasks (separation and classification) highly sensitive to\nerrors of the first task (location). A considerable amount of effort and\ncomputational complexity has been employed in the state-of-the-art to develop\ntechniques that are the least error-prone possible. However, doing so gives\nrise to an ASA system that is non-viable in many applications that require a\nsmall computational footprint and a low response time, such as bioacoustics,\nhearing-aid design, search and rescue, human-robot interaction, etc. To this\neffect, in this work, a multi-agent approach is proposed to carry out ASA where\nthe tasks are run in parallel, with feedback loops between them to compensate\nfor local errors, such as: using the quality of the separation output to\ncorrect the location error; and using the classification result to reduce the\nlocalization's sensitivity towards interferences. The result is a multi-agent\nauditory scene analysis (MASA) system that is robust against local errors,\nwithout a considerable increase in complexity, and with a low response time.\nThe complete proposed MASA system is provided as a framework that uses\nopen-source tools for sound acquisition and reproduction (JACK) and inter-agent\ncommunication (ROS2), allowing users to add their own agents.",
      "pdf_url": "http://arxiv.org/pdf/2507.02755v1",
      "published": "2025-07-03T16:16:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.02755v1",
      "categories": [
        "eess.AS",
        "cs.AI"
      ]
    },
    {
      "title": "Fast and Simplex: 2-Simplicial Attention in Triton",
      "authors": [
        "Aurko Roy",
        "Timothy Chou",
        "Sai Surya Duvvuri",
        "Sijia Chen",
        "Jiecao Yu",
        "Xiaodong Wang",
        "Manzil Zaheer",
        "Rohan Anil"
      ],
      "abstract": "Recent work has shown that training loss scales as a power law with both\nmodel size and the number of tokens, and that achieving compute-optimal models\nrequires scaling model size and token count together. However, these scaling\nlaws assume an infinite supply of data and apply primarily in compute-bound\nsettings. As modern large language models increasingly rely on massive\ninternet-scale datasets, the assumption that they are compute-bound is becoming\nless valid. This shift highlights the need for architectures that prioritize\ntoken efficiency.\n  In this work, we investigate the use of the 2-simplicial Transformer, an\narchitecture that generalizes standard dot-product attention to trilinear\nfunctions through an efficient Triton kernel implementation. We demonstrate\nthat the 2-simplicial Transformer achieves better token efficiency than\nstandard Transformers: for a fixed token budget, similarly sized models\noutperform their dot-product counterparts on tasks involving mathematics,\ncoding, reasoning, and logic. We quantify these gains by demonstrating that\n$2$-simplicial attention changes the exponent in the scaling laws for knowledge\nand reasoning tasks compared to dot product attention.",
      "pdf_url": "http://arxiv.org/pdf/2507.02754v1",
      "published": "2025-07-03T16:16:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.02754v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Synthesizable by Design: A Retrosynthesis-Guided Framework for Molecular Analog Generation",
      "authors": [
        "Shuan Chen",
        "Gunwook Nam",
        "Yousung Jung"
      ],
      "abstract": "The disconnect between AI-generated molecules with desirable properties and\ntheir synthetic feasibility remains a critical bottleneck in computational drug\nand material discovery. While generative AI has accelerated the proposal of\ncandidate molecules, many of these structures prove challenging or impossible\nto synthesize using established chemical reactions. Here, we introduce\nSynTwins, a novel retrosynthesis-guided molecular analog design framework that\ndesigns synthetically accessible molecular analogs by emulating expert chemist\nstrategies through a three-step process: retrosynthesis, similar building block\nsearching, and virtual synthesis. In comparative evaluations, SynTwins\ndemonstrates superior performance in generating synthetically accessible\nanalogs compared to state-of-the-art machine learning models while maintaining\nhigh structural similarity to original target molecules. Furthermore, when\nintegrated with existing molecule optimization frameworks, our hybrid approach\nproduces synthetically feasible molecules with property profiles comparable to\nunconstrained molecule generators, yet its synthesizability ensured. Our\ncomprehensive benchmarking across diverse molecular datasets demonstrates that\nSynTwins effectively bridges the gap between computational design and\nexperimental synthesis, providing a practical solution for accelerating the\ndiscovery of synthesizable molecules with desired properties for a wide range\nof applications.",
      "pdf_url": "http://arxiv.org/pdf/2507.02752v1",
      "published": "2025-07-03T16:14:57+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.02752v1",
      "categories": [
        "physics.chem-ph",
        "cs.AI"
      ]
    },
    {
      "title": "Linear Attention with Global Context: A Multipole Attention Mechanism for Vision and Physics",
      "authors": [
        "Alex Colagrande",
        "Paul Caillon",
        "Eva Feillet",
        "Alexandre Allauzen"
      ],
      "abstract": "Transformers have become the de facto standard for a wide range of tasks,\nfrom image classification to physics simulations. Despite their impressive\nperformance, the quadratic complexity of standard Transformers in both memory\nand time with respect to the input length makes them impractical for processing\nhigh-resolution inputs. Therefore, several variants have been proposed, the\nmost successful relying on patchification, downsampling, or coarsening\ntechniques, often at the cost of losing the finest-scale details. In this work,\nwe take a different approach. Inspired by state-of-the-art techniques in\n$n$-body numerical simulations, we cast attention as an interaction problem\nbetween grid points. We introduce the Multipole Attention Neural Operator\n(MANO), which computes attention in a distance-based multiscale fashion. MANO\nmaintains, in each attention head, a global receptive field and achieves linear\ntime and memory complexity with respect to the number of grid points. Empirical\nresults on image classification and Darcy flows demonstrate that MANO rivals\nstate-of-the-art models such as ViT and Swin Transformer, while reducing\nruntime and peak memory usage by orders of magnitude. We open source our code\nfor reproducibility at https://github.com/AlexColagrande/MANO.",
      "pdf_url": "http://arxiv.org/pdf/2507.02748v1",
      "published": "2025-07-03T16:05:26+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.02748v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Early Signs of Steganographic Capabilities in Frontier LLMs",
      "authors": [
        "Artur Zolkowski",
        "Kei Nishimura-Gasparian",
        "Robert McCarthy",
        "Roland S. Zimmermann",
        "David Lindner"
      ],
      "abstract": "Monitoring Large Language Model (LLM) outputs is crucial for mitigating risks\nfrom misuse and misalignment. However, LLMs could evade monitoring through\nsteganography: Encoding hidden information within seemingly benign generations.\nIn this paper, we evaluate the steganography capabilities in frontier LLMs to\nbetter understand the risk they pose. We focus on two types of steganography:\npassing encoded messages and performing encoded reasoning. We find that current\nmodels are unable to encode short messages in their outputs without a monitor\nnoticing under standard affordances. They can succeed, however, if given\nadditional affordances such as using an unmonitored scratchpad and coordinating\non what encoding scheme to use. We additionally find early signs that models\ncan perform basic encoded reasoning in a simple state-tracking problem. This\nincludes some ability to reason with their own and pre-defined schemes,\nincluding encoding schemes such as Hexadecimal. Despite this, they can rarely\nhide reasoning subtly within a cover task to fool a monitor. Overall, our\nresults indicate that current LLMs exhibit nascent steganographic capabilities.\nWhile these capabilities are likely insufficient to bypass well-designed\nmonitors at present, this could change in the future.",
      "pdf_url": "http://arxiv.org/pdf/2507.02737v1",
      "published": "2025-07-03T15:54:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.02737v1",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    },
    {
      "title": "Meta SecAlign: A Secure Foundation LLM Against Prompt Injection Attacks",
      "authors": [
        "Sizhe Chen",
        "Arman Zharmagambetov",
        "David Wagner",
        "Chuan Guo"
      ],
      "abstract": "Prompt injection attacks pose a significant security threat to LLM-integrated\napplications. Model-level defenses have shown strong effectiveness, but are\ncurrently deployed into commercial-grade models in a closed-source manner. We\nbelieve open-source models are needed by the AI security community, where\nco-development of attacks and defenses through open research drives scientific\nprogress in mitigation against prompt injection attacks. To this end, we\ndevelop Meta SecAlign, the first open-source and open-weight LLM with built-in\nmodel-level defense that achieves commercial-grade model performance. We\nprovide complete details of our training recipe, which utilizes an improved\nversion of the SOTA SecAlign defense. Evaluations on 9 utility benchmarks and 7\nsecurity benchmarks show that Meta SecAlign, despite being trained on a generic\ninstruction-tuning dataset, confers security in unseen downstream tasks,\nincluding tool-calling and agentic web navigation, in addition general\ninstruction-following. Our best model -- Meta-SecAlign-70B -- achieves\nstate-of-the-art robustness against prompt injection attacks and comparable\nutility to closed-source commercial LLM with model-level defense.",
      "pdf_url": "http://arxiv.org/pdf/2507.02735v1",
      "published": "2025-07-03T15:47:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.02735v1",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "title": "Bourbaki: Self-Generated and Goal-Conditioned MDPs for Theorem Proving",
      "authors": [
        "Matthieu Zimmer",
        "Xiaotong Ji",
        "Rasul Tutunov",
        "Anthony Bordg",
        "Jun Wang",
        "Haitham Bou Ammar"
      ],
      "abstract": "Reasoning remains a challenging task for large language models (LLMs),\nespecially within the logically constrained environment of automated theorem\nproving (ATP), due to sparse rewards and the vast scale of proofs. These\nchallenges are amplified in benchmarks like PutnamBench, which contains\nuniversity-level problems requiring complex, multi-step reasoning. To address\nthis, we introduce self-generated goal-conditioned MDPs (sG-MDPs), a new\nframework in which agents generate and pursue their subgoals based on the\nevolving proof state. Given this more structured generation of goals, the\nresulting problem becomes more amenable to search. We then apply Monte Carlo\nTree Search (MCTS)-like algorithms to solve the sG-MDP, instantiating our\napproach in Bourbaki (7B), a modular system that can ensemble multiple 7B LLMs\nfor subgoal generation and tactic synthesis. On PutnamBench, Bourbaki (7B)\nsolves 26 problems, achieving new state-of-the-art results with models at this\nscale.",
      "pdf_url": "http://arxiv.org/pdf/2507.02726v1",
      "published": "2025-07-03T15:41:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.02726v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "FairHuman: Boosting Hand and Face Quality in Human Image Generation with Minimum Potential Delay Fairness in Diffusion Models",
      "authors": [
        "Yuxuan Wang",
        "Tianwei Cao",
        "Huayu Zhang",
        "Zhongjiang He",
        "Kongming Liang",
        "Zhanyu Ma"
      ],
      "abstract": "Image generation has achieved remarkable progress with the development of\nlarge-scale text-to-image models, especially diffusion-based models. However,\ngenerating human images with plausible details, such as faces or hands, remains\nchallenging due to insufficient supervision of local regions during training.\nTo address this issue, we propose FairHuman, a multi-objective fine-tuning\napproach designed to enhance both global and local generation quality fairly.\nSpecifically, we first construct three learning objectives: a global objective\nderived from the default diffusion objective function and two local objectives\nfor hands and faces based on pre-annotated positional priors. Subsequently, we\nderive the optimal parameter updating strategy under the guidance of the\nMinimum Potential Delay (MPD) criterion, thereby attaining fairness-ware\noptimization for this multi-objective problem. Based on this, our proposed\nmethod can achieve significant improvements in generating challenging local\ndetails while maintaining overall quality. Extensive experiments showcase the\neffectiveness of our method in improving the performance of human image\ngeneration under different scenarios.",
      "pdf_url": "http://arxiv.org/pdf/2507.02714v1",
      "published": "2025-07-03T15:27:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.02714v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Time-critical and confidence-based abstraction dropping methods",
      "authors": [
        "Robin Schm√∂cker",
        "Lennart Kampmann",
        "Alexander Dockhorn"
      ],
      "abstract": "One paradigm of Monte Carlo Tree Search (MCTS) improvements is to build and\nuse state and/or action abstractions during the tree search. Non-exact\nabstractions, however, introduce an approximation error making convergence to\nthe optimal action in the abstract space impossible. Hence, as proposed as a\ncomponent of Elastic Monte Carlo Tree Search by Xu et al., abstraction\nalgorithms should eventually drop the abstraction. In this paper, we propose\ntwo novel abstraction dropping schemes, namely OGA-IAAD and OGA-CAD which can\nyield clear performance improvements whilst being safe in the sense that the\ndropping never causes any notable performance degradations contrary to Xu's\ndropping method. OGA-IAAD is designed for time critical settings while OGA-CAD\nis designed to improve the MCTS performance with the same number of iterations.",
      "pdf_url": "http://arxiv.org/pdf/2507.02703v1",
      "published": "2025-07-03T15:12:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.02703v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "APT: Adaptive Personalized Training for Diffusion Models with Limited Data",
      "authors": [
        "JungWoo Chae",
        "Jiyoon Kim",
        "JaeWoong Choi",
        "Kyungyul Kim",
        "Sangheum Hwang"
      ],
      "abstract": "Personalizing diffusion models using limited data presents significant\nchallenges, including overfitting, loss of prior knowledge, and degradation of\ntext alignment. Overfitting leads to shifts in the noise prediction\ndistribution, disrupting the denoising trajectory and causing the model to lose\nsemantic coherence. In this paper, we propose Adaptive Personalized Training\n(APT), a novel framework that mitigates overfitting by employing adaptive\ntraining strategies and regularizing the model's internal representations\nduring fine-tuning. APT consists of three key components: (1) Adaptive Training\nAdjustment, which introduces an overfitting indicator to detect the degree of\noverfitting at each time step bin and applies adaptive data augmentation and\nadaptive loss weighting based on this indicator; (2)Representation\nStabilization, which regularizes the mean and variance of intermediate feature\nmaps to prevent excessive shifts in noise prediction; and (3) Attention\nAlignment for Prior Knowledge Preservation, which aligns the cross-attention\nmaps of the fine-tuned model with those of the pretrained model to maintain\nprior knowledge and semantic coherence. Through extensive experiments, we\ndemonstrate that APT effectively mitigates overfitting, preserves prior\nknowledge, and outperforms existing methods in generating high-quality, diverse\nimages with limited reference data.",
      "pdf_url": "http://arxiv.org/pdf/2507.02687v1",
      "published": "2025-07-03T14:58:08+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.02687v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "60J60, 68T07",
        "I.2.6; I.2.10; I.4.9"
      ]
    },
    {
      "title": "Detection of Disengagement from Voluntary Quizzes: An Explainable Machine Learning Approach in Higher Distance Education",
      "authors": [
        "Behnam Parsaeifard",
        "Christof Imhof",
        "Tansu Pancar",
        "Ioan-Sorin Comsa",
        "Martin Hlosta",
        "Nicole Bergamin",
        "Per Bergamin"
      ],
      "abstract": "Students disengaging from their tasks can have serious long-term\nconsequences, including academic drop-out. This is particularly relevant for\nstudents in distance education. One way to measure the level of disengagement\nin distance education is to observe participation in non-mandatory exercises in\ndifferent online courses. In this paper, we detect student disengagement in the\nnon-mandatory quizzes of 42 courses in four semesters from a distance-based\nuniversity. We carefully identified the most informative student log data that\ncould be extracted and processed from Moodle. Then, eight machine learning\nalgorithms were trained and compared to obtain the highest possible prediction\naccuracy. Using the SHAP method, we developed an explainable machine learning\nframework that allows practitioners to better understand the decisions of the\ntrained algorithm. The experimental results show a balanced accuracy of 91\\%,\nwhere about 85\\% of disengaged students were correctly detected. On top of the\nhighly predictive performance and explainable framework, we provide a\ndiscussion on how to design a timely intervention to minimise disengagement\nfrom voluntary tasks in online learning.",
      "pdf_url": "http://arxiv.org/pdf/2507.02681v1",
      "published": "2025-07-03T14:43:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.02681v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "ASDA: Audio Spectrogram Differential Attention Mechanism for Self-Supervised Representation Learning",
      "authors": [
        "Junyu Wang",
        "Tianrui Wang",
        "Meng Ge",
        "Longbiao Wang",
        "Jianwu Dang"
      ],
      "abstract": "In recent advancements in audio self-supervised representation learning, the\nstandard Transformer architecture has emerged as the predominant approach, yet\nits attention mechanism often allocates a portion of attention weights to\nirrelevant information, potentially impairing the model's discriminative\nability. To address this, we introduce a differential attention mechanism,\nwhich effectively mitigates ineffective attention allocation through the\nintegration of dual-softmax operations and appropriately tuned differential\ncoefficients. Experimental results demonstrate that our ASDA model achieves\nstate-of-the-art (SOTA) performance across multiple benchmarks, including audio\nclassification (49.0% mAP on AS-2M, 41.5% mAP on AS20K), keyword spotting\n(98.3% accuracy on SPC-2), and environmental sound classification (96.1%\naccuracy on ESC-50). These results highlight ASDA's effectiveness in audio\ntasks, paving the way for broader applications.",
      "pdf_url": "http://arxiv.org/pdf/2507.02666v1",
      "published": "2025-07-03T14:29:43+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.02666v1",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "eess.AS"
      ]
    },
    {
      "title": "Think How to Think: Mitigating Overthinking with Autonomous Difficulty Cognition in Large Reasoning Models",
      "authors": [
        "Yongjiang Liu",
        "Haoxi Li",
        "Xiaosong Ma",
        "Jie Zhang",
        "Song Guo"
      ],
      "abstract": "Recent Long Reasoning Models(LRMs) have demonstrated remarkable capabilities\nin handling complex reasoning tasks, but are hindered by excessive\noverthinking. To explore its essence, our empirical analysis reveals that LRMs\nare primarily limited to recognizing task properties (i.e., difficulty levels)\nlike humans before solving the problem, leading to a one-size-fits-all\nreasoning process. Inspired by this, a pressing and natural question emerges:\nCan we bootstrap such ability to further alleviate the overthinking phenomenon\nin LRMs? In this paper, we propose Think-How-to-Think (TH2T), a novel two-stage\nfine-tuning strategy that progressively inspires LRMs' difficulty cognition and\nredundancy cognition. First, we introduce difficulty-hypnosis in the prefixes\nof model outputs to intervene in the internal reasoning trajectory. Combined\nwith a heterogeneous short and long reasoning dataset, the trained model\nenhances its sensitivity to task difficulty, enabling native, differentiated\nreasoning strategies across various tasks. Second, we further extend\nredundancy-hypnosis to the internal reasoning process, guiding the model to\nidentify redundant structures within the reasoning steps and generate more\nconcise reasoning outputs. Experiments on 7B/14B/32B models demonstrate that\nTH2T significantly reduces inference costs (more than 70% on easy tasks and 40%\non hard tasks) while maintaining performance stability. The resulting outputs\nexhibit clear difficulty-aware capabilities and reduced redundancy (e.g.,\nreflection).",
      "pdf_url": "http://arxiv.org/pdf/2507.02663v1",
      "published": "2025-07-03T14:24:26+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.02663v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Hey AI, Generate Me a Hardware Code! Agentic AI-based Hardware Design & Verification",
      "authors": [
        "Deepak Narayan Gadde",
        "Keerthan Kopparam Radhakrishna",
        "Vaisakh Naduvodi Viswambharan",
        "Aman Kumar",
        "Djones Lettnin",
        "Wolfgang Kunz",
        "Sebastian Simon"
      ],
      "abstract": "Modern Integrated Circuits (ICs) are becoming increasingly complex, and so is\ntheir development process. Hardware design verification entails a methodical\nand disciplined approach to the planning, development, execution, and sign-off\nof functionally correct hardware designs. This tedious process requires\nsignificant effort and time to ensure a bug-free tape-out. The field of Natural\nLanguage Processing has undergone a significant transformation with the advent\nof Large Language Models (LLMs). These powerful models, often referred to as\nGenerative AI (GenAI), have revolutionized how machines understand and generate\nhuman language, enabling unprecedented advancements in a wide array of\napplications, including hardware design verification. This paper presents an\nagentic AI-based approach to hardware design verification, which empowers AI\nagents, in collaboration with Humain-in-the-Loop (HITL) intervention, to engage\nin a more dynamic, iterative, and self-reflective process, ultimately\nperforming end-to-end hardware design and verification. This methodology is\nevaluated on five open-source designs, achieving over 95% coverage with reduced\nverification time while demonstrating superior performance, adaptability, and\nconfigurability.",
      "pdf_url": "http://arxiv.org/pdf/2507.02660v1",
      "published": "2025-07-03T14:20:57+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.02660v1",
      "categories": [
        "cs.AI",
        "cs.AR"
      ]
    },
    {
      "title": "Decoupled Planning and Execution: A Hierarchical Reasoning Framework for Deep Search",
      "authors": [
        "Jiajie Jin",
        "Xiaoxi Li",
        "Guanting Dong",
        "Yuyao Zhang",
        "Yutao Zhu",
        "Yang Zhao",
        "Hongjin Qian",
        "Zhicheng Dou"
      ],
      "abstract": "Complex information needs in real-world search scenarios demand deep\nreasoning and knowledge synthesis across diverse sources, which traditional\nretrieval-augmented generation (RAG) pipelines struggle to address effectively.\nCurrent reasoning-based approaches suffer from a fundamental limitation: they\nuse a single model to handle both high-level planning and detailed execution,\nleading to inefficient reasoning and limited scalability. In this paper, we\nintroduce HiRA, a hierarchical framework that separates strategic planning from\nspecialized execution. Our approach decomposes complex search tasks into\nfocused subtasks, assigns each subtask to domain-specific agents equipped with\nexternal tools and reasoning capabilities, and coordinates the results through\na structured integration mechanism. This separation prevents execution details\nfrom disrupting high-level reasoning while enabling the system to leverage\nspecialized expertise for different types of information processing.\nExperiments on four complex, cross-modal deep search benchmarks demonstrate\nthat HiRA significantly outperforms state-of-the-art RAG and agent-based\nsystems. Our results show improvements in both answer quality and system\nefficiency, highlighting the effectiveness of decoupled planning and execution\nfor multi-step information seeking tasks. Our code is available at\nhttps://github.com/ignorejjj/HiRA.",
      "pdf_url": "http://arxiv.org/pdf/2507.02652v1",
      "published": "2025-07-03T14:18:08+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.02652v1",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ]
    },
    {
      "title": "Solving the Hubbard model with Neural Quantum States",
      "authors": [
        "Yuntian Gu",
        "Wenrui Li",
        "Heng Lin",
        "Bo Zhan",
        "Ruichen Li",
        "Yifei Huang",
        "Di He",
        "Yantao Wu",
        "Tao Xiang",
        "Mingpu Qin",
        "Liwei Wang",
        "Dingshun Lv"
      ],
      "abstract": "The rapid development of neural quantum states (NQS) has established it as a\npromising framework for studying quantum many-body systems. In this work, by\nleveraging the cutting-edge transformer-based architectures and developing\nhighly efficient optimization algorithms, we achieve the state-of-the-art\nresults for the doped two-dimensional (2D) Hubbard model, arguably the minimum\nmodel for high-Tc superconductivity. Interestingly, we find different attention\nheads in the NQS ansatz can directly encode correlations at different scales,\nmaking it capable of capturing long-range correlations and entanglements in\nstrongly correlated systems. With these advances, we establish the half-filled\nstripe in the ground state of 2D Hubbard model with the next nearest\nneighboring hoppings, consistent with experimental observations in cuprates.\nOur work establishes NQS as a powerful tool for solving challenging\nmany-fermions systems.",
      "pdf_url": "http://arxiv.org/pdf/2507.02644v1",
      "published": "2025-07-03T14:08:25+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.02644v1",
      "categories": [
        "cond-mat.str-el",
        "cs.AI",
        "quant-ph"
      ]
    },
    {
      "title": "FlowSpec: Continuous Pipelined Speculative Decoding for Efficient Distributed LLM Inference",
      "authors": [
        "Xing Liu",
        "Lizhuo Luo",
        "Ming Tang",
        "Chao Huang"
      ],
      "abstract": "Distributed inference serves as a promising approach to enabling the\ninference of large language models (LLMs) at the network edge. It distributes\nthe inference process to multiple devices to ensure that the LLMs can fit into\nthe device memory. Recent pipeline-based approaches have the potential to\nparallelize communication and computation, which helps reduce inference\nlatency. However, the benefit diminishes when the inference request at the\nnetwork edge is sparse, where pipeline is typically at low utilization. To\nenable efficient distributed LLM inference at the edge, we propose\n\\textbf{FlowSpec}, a pipeline-parallel tree-based speculative decoding\nframework. FlowSpec incorporates three key mechanisms to improve decoding\nefficiency: 1) score-based step-wise verification prioritizes more important\ndraft tokens to bring earlier accpeted tokens; 2) efficient draft management to\nprune invalid tokens while maintaining correct causal relationship during\nverification; 3) dynamic draft expansion strategies to supply high-quality\nspeculative inputs. These techniques work in concert to enhance both pipeline\nutilization and speculative efficiency. We evaluate FlowSpec on a real-world\ntestbed with other baselines. Experimental results demonstrate that our\nproposed framework significantly improves inference speed across diverse models\nand configurations, achieving speedup ratios 1.36$\\times$-1.77$\\times$ compared\nto baselines. Our code is publicly available at\n\\href{https://github.com/Leosang-lx/FlowSpec#}{https://github.com/Leosang-lx/FlowSpec\\#}",
      "pdf_url": "http://arxiv.org/pdf/2507.02620v1",
      "published": "2025-07-03T13:47:42+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.02620v1",
      "categories": [
        "cs.DC",
        "cs.AI"
      ]
    },
    {
      "title": "Strategic Intelligence in Large Language Models: Evidence from evolutionary Game Theory",
      "authors": [
        "Kenneth Payne",
        "Baptiste Alloui-Cros"
      ],
      "abstract": "Are Large Language Models (LLMs) a new form of strategic intelligence, able\nto reason about goals in competitive settings? We present compelling supporting\nevidence. The Iterated Prisoner's Dilemma (IPD) has long served as a model for\nstudying decision-making. We conduct the first ever series of evolutionary IPD\ntournaments, pitting canonical strategies (e.g., Tit-for-Tat, Grim Trigger)\nagainst agents from the leading frontier AI companies OpenAI, Google, and\nAnthropic. By varying the termination probability in each tournament (the\n\"shadow of the future\"), we introduce complexity and chance, confounding\nmemorisation.\n  Our results show that LLMs are highly competitive, consistently surviving and\nsometimes even proliferating in these complex ecosystems. Furthermore, they\nexhibit distinctive and persistent \"strategic fingerprints\": Google's Gemini\nmodels proved strategically ruthless, exploiting cooperative opponents and\nretaliating against defectors, while OpenAI's models remained highly\ncooperative, a trait that proved catastrophic in hostile environments.\nAnthropic's Claude emerged as the most forgiving reciprocator, showing\nremarkable willingness to restore cooperation even after being exploited or\nsuccessfully defecting. Analysis of nearly 32,000 prose rationales provided by\nthe models reveals that they actively reason about both the time horizon and\ntheir opponent's likely strategy, and we demonstrate that this reasoning is\ninstrumental to their decisions. This work connects classic game theory with\nmachine psychology, offering a rich and granular view of algorithmic\ndecision-making under uncertainty.",
      "pdf_url": "http://arxiv.org/pdf/2507.02618v1",
      "published": "2025-07-03T13:45:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.02618v1",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.GT"
      ]
    },
    {
      "title": "DynamiCare: A Dynamic Multi-Agent Framework for Interactive and Open-Ended Medical Decision-Making",
      "authors": [
        "Tianqi Shang",
        "Weiqing He",
        "Charles Zheng",
        "Lingyao Li",
        "Li Shen",
        "Bingxin Zhao"
      ],
      "abstract": "The rise of Large Language Models (LLMs) has enabled the development of\nspecialized AI agents with domain-specific reasoning and interaction\ncapabilities, particularly in healthcare. While recent frameworks simulate\nmedical decision-making, they largely focus on single-turn tasks where a doctor\nagent receives full case information upfront -- diverging from the real-world\ndiagnostic process, which is inherently uncertain, interactive, and iterative.\nIn this paper, we introduce MIMIC-Patient, a structured dataset built from the\nMIMIC-III electronic health records (EHRs), designed to support dynamic,\npatient-level simulations. Building on this, we propose DynamiCare, a novel\ndynamic multi-agent framework that models clinical diagnosis as a multi-round,\ninteractive loop, where a team of specialist agents iteratively queries the\npatient system, integrates new information, and dynamically adapts its\ncomposition and strategy. We demonstrate the feasibility and effectiveness of\nDynamiCare through extensive experiments, establishing the first benchmark for\ndynamic clinical decision-making with LLM-powered agents.",
      "pdf_url": "http://arxiv.org/pdf/2507.02616v1",
      "published": "2025-07-03T13:43:10+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.02616v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "De-AntiFake: Rethinking the Protective Perturbations Against Voice Cloning Attacks",
      "authors": [
        "Wei Fan",
        "Kejiang Chen",
        "Chang Liu",
        "Weiming Zhang",
        "Nenghai Yu"
      ],
      "abstract": "The rapid advancement of speech generation models has heightened privacy and\nsecurity concerns related to voice cloning (VC). Recent studies have\ninvestigated disrupting unauthorized voice cloning by introducing adversarial\nperturbations. However, determined attackers can mitigate these protective\nperturbations and successfully execute VC. In this study, we conduct the first\nsystematic evaluation of these protective perturbations against VC under\nrealistic threat models that include perturbation purification. Our findings\nreveal that while existing purification methods can neutralize a considerable\nportion of the protective perturbations, they still lead to distortions in the\nfeature space of VC models, which degrades the performance of VC. From this\nperspective, we propose a novel two-stage purification method: (1) Purify the\nperturbed speech; (2) Refine it using phoneme guidance to align it with the\nclean speech distribution. Experimental results demonstrate that our method\noutperforms state-of-the-art purification methods in disrupting VC defenses.\nOur study reveals the limitations of adversarial perturbation-based VC defenses\nand underscores the urgent need for more robust solutions to mitigate the\nsecurity and privacy risks posed by VC. The code and audio samples are\navailable at https://de-antifake.github.io.",
      "pdf_url": "http://arxiv.org/pdf/2507.02606v1",
      "published": "2025-07-03T13:30:58+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.02606v1",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CR",
        "cs.LG",
        "eess.AS"
      ]
    },
    {
      "title": "Addressing Camera Sensors Faults in Vision-Based Navigation: Simulation and Dataset Development",
      "authors": [
        "Riccardo Gallon",
        "Fabian Schiemenz",
        "Alessandra Menicucci",
        "Eberhard Gill"
      ],
      "abstract": "The increasing importance of Vision-Based Navigation (VBN) algorithms in\nspace missions raises numerous challenges in ensuring their reliability and\noperational robustness. Sensor faults can lead to inaccurate outputs from\nnavigation algorithms or even complete data processing faults, potentially\ncompromising mission objectives. Artificial Intelligence (AI) offers a powerful\nsolution for detecting such faults, overcoming many of the limitations\nassociated with traditional fault detection methods. However, the primary\nobstacle to the adoption of AI in this context is the lack of sufficient and\nrepresentative datasets containing faulty image data.\n  This study addresses these challenges by focusing on an interplanetary\nexploration mission scenario. A comprehensive analysis of potential fault cases\nin camera sensors used within the VBN pipeline is presented. The causes and\neffects of these faults are systematically characterized, including their\nimpact on image quality and navigation algorithm performance, as well as\ncommonly employed mitigation strategies. To support this analysis, a simulation\nframework is introduced to recreate faulty conditions in synthetically\ngenerated images, enabling a systematic and controlled reproduction of faulty\ndata. The resulting dataset of fault-injected images provides a valuable tool\nfor training and testing AI-based fault detection algorithms. The final link to\nthe dataset will be added after an embargo period. For peer-reviewers, this\nprivate link is available.",
      "pdf_url": "http://arxiv.org/pdf/2507.02602v1",
      "published": "2025-07-03T13:23:22+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.02602v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "AC-Refiner: Efficient Arithmetic Circuit Optimization Using Conditional Diffusion Models",
      "authors": [
        "Chenhao Xue",
        "Kezhi Li",
        "Jiaxing Zhang",
        "Yi Ren",
        "Zhengyuan Shi",
        "Chen Zhang",
        "Yibo Lin",
        "Lining Zhang",
        "Qiang Xu",
        "Guangyu Sun"
      ],
      "abstract": "Arithmetic circuits, such as adders and multipliers, are fundamental\ncomponents of digital systems, directly impacting the performance, power\nefficiency, and area footprint. However, optimizing these circuits remains\nchallenging due to the vast design space and complex physical constraints.\nWhile recent deep learning-based approaches have shown promise, they struggle\nto consistently explore high-potential design variants, limiting their\noptimization efficiency. To address this challenge, we propose AC-Refiner, a\nnovel arithmetic circuit optimization framework leveraging conditional\ndiffusion models. Our key insight is to reframe arithmetic circuit synthesis as\na conditional image generation task. By carefully conditioning the denoising\ndiffusion process on target quality-of-results (QoRs), AC-Refiner consistently\nproduces high-quality circuit designs. Furthermore, the explored designs are\nused to fine-tune the diffusion model, which focuses the exploration near the\nPareto frontier. Experimental results demonstrate that AC-Refiner generates\ndesigns with superior Pareto optimality, outperforming state-of-the-art\nbaselines. The performance gain is further validated by integrating AC-Refiner\ninto practical applications.",
      "pdf_url": "http://arxiv.org/pdf/2507.02598v1",
      "published": "2025-07-03T13:21:33+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.02598v1",
      "categories": [
        "cs.AR",
        "cs.AI"
      ]
    },
    {
      "title": "MPF: Aligning and Debiasing Language Models post Deployment via Multi Perspective Fusion",
      "authors": [
        "Xin Guan",
        "PeiHsin Lin",
        "Zekun Wu",
        "Ze Wang",
        "Ruibo Zhang",
        "Emre Kazim",
        "Adriano Koshiyama"
      ],
      "abstract": "Multiperspective Fusion (MPF) is a novel posttraining alignment framework for\nlarge language models (LLMs) developed in response to the growing need for easy\nbias mitigation. Built on top of the SAGED pipeline, an automated system for\nconstructing bias benchmarks and extracting interpretable baseline\ndistributions, MPF leverages multiperspective generations to expose and align\nbiases in LLM outputs with nuanced, humanlike baselines. By decomposing\nbaseline, such as sentiment distributions from HR professionals, into\ninterpretable perspective components, MPF guides generation through sampling\nand balancing of responses, weighted by the probabilities obtained in the\ndecomposition. Empirically, we demonstrate its ability to align LLM sentiment\ndistributions with both counterfactual baselines (absolute equality) and the HR\nbaseline (biased for Top Univeristy), resulting in small KL divergence,\nreduction of calibration error and generalization to unseen questions. This\nshows that MPF offers a scalable and interpretable method for alignment and\nbias mitigation, compatible with deployed LLMs and requiring no extensive\nprompt engineering or finetuning.",
      "pdf_url": "http://arxiv.org/pdf/2507.02595v1",
      "published": "2025-07-03T13:09:18+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.02595v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "WebSailor: Navigating Super-human Reasoning for Web Agent",
      "authors": [
        "Kuan Li",
        "Zhongwang Zhang",
        "Huifeng Yin",
        "Liwen Zhang",
        "Litu Ou",
        "Jialong Wu",
        "Wenbiao Yin",
        "Baixuan Li",
        "Zhengwei Tao",
        "Xinyu Wang",
        "Weizhou Shen",
        "Junkai Zhang",
        "Dingchu Zhang",
        "Xixi Wu",
        "Yong Jiang",
        "Ming Yan",
        "Pengjun Xie",
        "Fei Huang",
        "Jingren Zhou"
      ],
      "abstract": "Transcending human cognitive limitations represents a critical frontier in\nLLM training. Proprietary agentic systems like DeepResearch have demonstrated\nsuperhuman capabilities on extremely complex information-seeking benchmarks\nsuch as BrowseComp, a feat previously unattainable. We posit that their success\nhinges on a sophisticated reasoning pattern absent in open-source models: the\nability to systematically reduce extreme uncertainty when navigating vast\ninformation landscapes. Based on this insight, we introduce WebSailor, a\ncomplete post-training methodology designed to instill this crucial capability.\nOur approach involves generating novel, high-uncertainty tasks through\nstructured sampling and information obfuscation, RFT cold start, and an\nefficient agentic RL training algorithm, Duplicating Sampling Policy\nOptimization (DUPO). With this integrated pipeline, WebSailor significantly\noutperforms all opensource agents in complex information-seeking tasks,\nmatching proprietary agents' performance and closing the capability gap.",
      "pdf_url": "http://arxiv.org/pdf/2507.02592v1",
      "published": "2025-07-03T12:59:07+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.02592v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Responsibility Gap and Diffusion in Sequential Decision-Making Mechanisms",
      "authors": [
        "Junli Jiang",
        "Pavel Naumov"
      ],
      "abstract": "Responsibility has long been a subject of study in law and philosophy. More\nrecently, it became a focus of AI literature. The article investigates the\ncomputational complexity of two important properties of responsibility in\ncollective decision-making: diffusion and gap. It shows that the sets of\ndiffusion-free and gap-free decision-making mechanisms are $\\Pi_2$-complete and\n$\\Pi_3$-complete, respectively. At the same time, the intersection of these\nclasses is $\\Pi_2$-complete.",
      "pdf_url": "http://arxiv.org/pdf/2507.02582v1",
      "published": "2025-07-03T12:43:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.02582v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "AI Research Agents for Machine Learning: Search, Exploration, and Generalization in MLE-bench",
      "authors": [
        "Edan Toledo",
        "Karen Hambardzumyan",
        "Martin Josifoski",
        "Rishi Hazra",
        "Nicolas Baldwin",
        "Alexis Audran-Reiss",
        "Michael Kuchnik",
        "Despoina Magka",
        "Minqi Jiang",
        "Alisia Maria Lupidi",
        "Andrei Lupu",
        "Roberta Raileanu",
        "Kelvin Niu",
        "Tatiana Shavrina",
        "Jean-Christophe Gagnon-Audet",
        "Michael Shvartsman",
        "Shagun Sodhani",
        "Alexander H. Miller",
        "Abhishek Charnalia",
        "Derek Dunfield",
        "Carole-Jean Wu",
        "Pontus Stenetorp",
        "Nicola Cancedda",
        "Jakob Nicolaus Foerster",
        "Yoram Bachrach"
      ],
      "abstract": "AI research agents are demonstrating great potential to accelerate scientific\nprogress by automating the design, implementation, and training of machine\nlearning models. We focus on methods for improving agents' performance on\nMLE-bench, a challenging benchmark where agents compete in Kaggle competitions\nto solve real-world machine learning problems. We formalize AI research agents\nas search policies that navigate a space of candidate solutions, iteratively\nmodifying them using operators. By designing and systematically varying\ndifferent operator sets and search policies (Greedy, MCTS, Evolutionary), we\nshow that their interplay is critical for achieving high performance. Our best\npairing of search strategy and operator set achieves a state-of-the-art result\non MLE-bench lite, increasing the success rate of achieving a Kaggle medal from\n39.6% to 47.7%. Our investigation underscores the importance of jointly\nconsidering the search strategy, operator design, and evaluation methodology in\nadvancing automated machine learning.",
      "pdf_url": "http://arxiv.org/pdf/2507.02554v1",
      "published": "2025-07-03T11:59:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.02554v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Position: A Theory of Deep Learning Must Include Compositional Sparsity",
      "authors": [
        "David A. Danhofer",
        "Davide D'Ascenzo",
        "Rafael Dubach",
        "Tomaso Poggio"
      ],
      "abstract": "Overparametrized Deep Neural Networks (DNNs) have demonstrated remarkable\nsuccess in a wide variety of domains too high-dimensional for classical shallow\nnetworks subject to the curse of dimensionality. However, open questions about\nfundamental principles, that govern the learning dynamics of DNNs, remain. In\nthis position paper we argue that it is the ability of DNNs to exploit the\ncompositionally sparse structure of the target function driving their success.\nAs such, DNNs can leverage the property that most practically relevant\nfunctions can be composed from a small set of constituent functions, each of\nwhich relies only on a low-dimensional subset of all inputs. We show that this\nproperty is shared by all efficiently Turing-computable functions and is\ntherefore highly likely present in all current learning problems. While some\npromising theoretical insights on questions concerned with approximation and\ngeneralization exist in the setting of compositionally sparse functions,\nseveral important questions on the learnability and optimization of DNNs\nremain. Completing the picture of the role of compositional sparsity in deep\nlearning is essential to a comprehensive theory of artificial, and even\ngeneral, intelligence.",
      "pdf_url": "http://arxiv.org/pdf/2507.02550v1",
      "published": "2025-07-03T11:49:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.02550v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Clarifying Before Reasoning: A Coq Prover with Structural Context",
      "authors": [
        "Yanzhen Lu",
        "Hanbin Yang",
        "Xiaodie Wang",
        "Ge Zhang",
        "Biao Li",
        "Chenxu Fu",
        "Chao Li",
        "Yang Yuan",
        "Andrew Chi-Chih Yao"
      ],
      "abstract": "In this work, we investigate whether improving task clarity can enhance\nreasoning ability of large language models, focusing on theorem proving in Coq.\nWe introduce a concept-level metric to evaluate task clarity and show that\nadding structured semantic context to the standard input used by modern LLMs,\nleads to a 1.85$\\times$ improvement in clarity score\n(44.5\\%~$\\rightarrow$~82.3\\%). Using the general-purpose model\n\\texttt{DeepSeek-V3}, our approach leads to a 2.1$\\times$ improvement in proof\nsuccess (21.8\\%~$\\rightarrow$~45.8\\%) and outperforms the previous\nstate-of-the-art \\texttt{Graph2Tac} (33.2\\%). We evaluate this on 1,386\ntheorems randomly sampled from 15 standard Coq packages, following the same\nevaluation protocol as \\texttt{Graph2Tac}. Furthermore, fine-tuning smaller\nmodels on our structured data can achieve even higher performance (48.6\\%). Our\nmethod uses selective concept unfolding to enrich task descriptions, and\nemploys a Planner--Executor architecture. These findings highlight the value of\nstructured task representations in bridging the gap between understanding and\nreasoning.",
      "pdf_url": "http://arxiv.org/pdf/2507.02541v1",
      "published": "2025-07-03T11:35:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.02541v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Are You Listening to Me? Fine-Tuning Chatbots for Empathetic Dialogue",
      "authors": [
        "Paulo Ricardo Knob",
        "Leonardo Scholler",
        "Juliano Rigatti",
        "Soraia Raupp Musse"
      ],
      "abstract": "Conversational agents have made significant progress since ELIZA, expanding\ntheir role across various domains, including healthcare, education, and\ncustomer service. As these agents become increasingly integrated into daily\nhuman interactions, the need for emotional intelligence, particularly\nempathetic listening, becomes increasingly essential. In this study, we explore\nhow Large Language Models (LLMs) respond when tasked with generating\nemotionally rich interactions. Starting from a small dataset manually crafted\nby an expert to reflect empathic behavior, we extended the conversations using\ntwo LLMs: ChatGPT and Gemini. We analyzed the emotional progression of the\ndialogues using both sentiment analysis (via VADER) and expert assessments.\nWhile the generated conversations often mirrored the intended emotional\nstructure, human evaluation revealed important differences in the perceived\nempathy and coherence of the responses. These findings suggest that emotion\nmodeling in dialogues requires not only structural alignment in the expressed\nemotions but also qualitative depth, highlighting the importance of combining\nautomated and humancentered methods in the development of emotionally competent\nagents.",
      "pdf_url": "http://arxiv.org/pdf/2507.02537v1",
      "published": "2025-07-03T11:32:41+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.02537v1",
      "categories": [
        "cs.HC",
        "cs.AI"
      ]
    },
    {
      "title": "Detecting Multiple Diseases in Multiple Crops Using Deep Learning",
      "authors": [
        "Vivek Yadav",
        "Anugrah Jain"
      ],
      "abstract": "India, as a predominantly agrarian economy, faces significant challenges in\nagriculture, including substantial crop losses caused by diseases, pests, and\nenvironmental stress. Early detection and accurate identification of diseases\nacross different crops are critical for improving yield and ensuring food\nsecurity. This paper proposes a deep learning based solution for detecting\nmultiple diseases in multiple crops, aimed to cover India's diverse\nagricultural landscape. We first create a unified dataset encompassing images\nof 17 different crops and 34 different diseases from various available\nrepositories. Proposed deep learning model is trained on this dataset and\noutperforms the state-of-the-art in terms of accuracy and the number of crops,\ndiseases covered. We achieve a significant detection accuracy, i.e., 99 percent\nfor our unified dataset which is 7 percent more when compared to\nstate-of-the-art handling 14 crops and 26 different diseases only. By improving\nthe number of crops and types of diseases that can be detected, proposed\nsolution aims to provide a better product for Indian farmers.",
      "pdf_url": "http://arxiv.org/pdf/2507.02517v1",
      "published": "2025-07-03T10:26:49+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.02517v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.ET"
      ]
    },
    {
      "title": "IndianBailJudgments-1200: A Multi-Attribute Dataset for Legal NLP on Indian Bail Orders",
      "authors": [
        "Sneha Deshmukh",
        "Prathmesh Kamble"
      ],
      "abstract": "Legal NLP remains underdeveloped in regions like India due to the scarcity of\nstructured datasets. We introduce IndianBailJudgments-1200, a new benchmark\ndataset comprising 1200 Indian court judgments on bail decisions, annotated\nacross 20+ attributes including bail outcome, IPC sections, crime type, and\nlegal reasoning. Annotations were generated using a prompt-engineered GPT-4o\npipeline and verified for consistency. This resource supports a wide range of\nlegal NLP tasks such as outcome prediction, summarization, and fairness\nanalysis, and is the first publicly available dataset focused specifically on\nIndian bail jurisprudence.",
      "pdf_url": "http://arxiv.org/pdf/2507.02506v1",
      "published": "2025-07-03T10:13:42+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.02506v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "91B14, 68T50",
        "I.2.7; K.4.1; K.5.2"
      ]
    },
    {
      "title": "Continual Gradient Low-Rank Projection Fine-Tuning for LLMs",
      "authors": [
        "Chenxu Wang",
        "Yilin Lyu",
        "Zicheng Sun",
        "Liping Jing"
      ],
      "abstract": "Continual fine-tuning of Large Language Models (LLMs) is hampered by the\ntrade-off between efficiency and expressiveness. Low-Rank Adaptation (LoRA)\noffers efficiency but constrains the model's ability to learn new tasks and\ntransfer knowledge due to its low-rank nature and reliance on explicit\nparameter constraints. We propose GORP (Gradient LOw Rank Projection) for\nContinual Learning, a novel training strategy that overcomes these limitations\nby synergistically combining full and low-rank parameters and jointly updating\nwithin a unified low-rank gradient subspace. GORP expands the optimization\nspace while preserving efficiency and mitigating catastrophic forgetting.\nExtensive experiments on continual learning benchmarks demonstrate GORP's\nsuperior performance compared to existing state-of-the-art approaches. Code is\navailable at https://github.com/Wcxwcxw/GORP.",
      "pdf_url": "http://arxiv.org/pdf/2507.02503v1",
      "published": "2025-07-03T10:11:22+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.02503v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Temporally-Aware Supervised Contrastive Learning for Polyp Counting in Colonoscopy",
      "authors": [
        "Luca Parolari",
        "Andrea Cherubini",
        "Lamberto Ballan",
        "Carlo Biffi"
      ],
      "abstract": "Automated polyp counting in colonoscopy is a crucial step toward automated\nprocedure reporting and quality control, aiming to enhance the\ncost-effectiveness of colonoscopy screening. Counting polyps in a procedure\ninvolves detecting and tracking polyps, and then clustering tracklets that\nbelong to the same polyp entity. Existing methods for polyp counting rely on\nself-supervised learning and primarily leverage visual appearance, neglecting\ntemporal relationships in both tracklet feature learning and clustering stages.\nIn this work, we introduce a paradigm shift by proposing a supervised\ncontrastive loss that incorporates temporally-aware soft targets. Our approach\ncaptures intra-polyp variability while preserving inter-polyp discriminability,\nleading to more robust clustering. Additionally, we improve tracklet clustering\nby integrating a temporal adjacency constraint, reducing false positive\nre-associations between visually similar but temporally distant tracklets. We\ntrain and validate our method on publicly available datasets and evaluate its\nperformance with a leave-one-out cross-validation strategy. Results demonstrate\na 2.2x reduction in fragmentation rate compared to prior approaches. Our\nresults highlight the importance of temporal awareness in polyp counting,\nestablishing a new state-of-the-art. Code is available at\nhttps://github.com/lparolari/temporally-aware-polyp-counting.",
      "pdf_url": "http://arxiv.org/pdf/2507.02493v1",
      "published": "2025-07-03T09:55:48+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.02493v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "CrowdTrack: A Benchmark for Difficult Multiple Pedestrian Tracking in Real Scenarios",
      "authors": [
        "Teng Fu",
        "Yuwen Chen",
        "Zhuofan Chen",
        "Mengyang Zhao",
        "Bin Li",
        "Xiangyang Xue"
      ],
      "abstract": "Multi-object tracking is a classic field in computer vision. Among them,\npedestrian tracking has extremely high application value and has become the\nmost popular research category. Existing methods mainly use motion or\nappearance information for tracking, which is often difficult in complex\nscenarios. For the motion information, mutual occlusions between objects often\nprevent updating of the motion state; for the appearance information,\nnon-robust results are often obtained due to reasons such as only partial\nvisibility of the object or blurred images. Although learning how to perform\ntracking in these situations from the annotated data is the simplest solution,\nthe existing MOT dataset fails to satisfy this solution. Existing methods\nmainly have two drawbacks: relatively simple scene composition and\nnon-realistic scenarios. Although some of the video sequences in existing\ndataset do not have the above-mentioned drawbacks, the number is far from\nadequate for research purposes. To this end, we propose a difficult large-scale\ndataset for multi-pedestrian tracking, shot mainly from the first-person view\nand all from real-life complex scenarios. We name it ``CrowdTrack'' because\nthere are numerous objects in most of the sequences. Our dataset consists of 33\nvideos, containing a total of 5,185 trajectories. Each object is annotated with\na complete bounding box and a unique object ID. The dataset will provide a\nplatform to facilitate the development of algorithms that remain effective in\ncomplex situations. We analyzed the dataset comprehensively and tested multiple\nSOTA models on our dataset. Besides, we analyzed the performance of the\nfoundation models on our dataset. The dataset and project code is released at:\nhttps://github.com/loseevaya/CrowdTrack .",
      "pdf_url": "http://arxiv.org/pdf/2507.02479v1",
      "published": "2025-07-03T09:36:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.02479v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Red grape detection with accelerated artificial neural networks in the FPGA's programmable logic",
      "authors": [
        "Sandro Costa Magalh√£es",
        "Marco Almeida",
        "Filipe Neves dos Santos",
        "Ant√≥nio Paulo Moreira",
        "Jorge Dias"
      ],
      "abstract": "Robots usually slow down for canning to detect objects while moving.\nAdditionally, the robot's camera is configured with a low framerate to track\nthe velocity of the detection algorithms. This would be constrained while\nexecuting tasks and exploring, making robots increase the task execution time.\nAMD has developed the Vitis-AI framework to deploy detection algorithms into\nFPGAs. However, this tool does not fully use the FPGAs' PL. In this work, we\nuse the FINN architecture to deploy three ANNs, MobileNet v1 with 4-bit\nquantisation, CNV with 2-bit quantisation, and CNV with 1-bit quantisation\n(BNN), inside an FPGA's PL. The models were trained on the RG2C dataset. This\nis a self-acquired dataset released in open access. MobileNet v1 performed\nbetter, reaching a success rate of 98 % and an inference speed of 6611 FPS. In\nthis work, we proved that we can use FPGAs to speed up ANNs and make them\nsuitable for attention mechanisms.",
      "pdf_url": "http://arxiv.org/pdf/2507.02443v1",
      "published": "2025-07-03T09:00:19+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.02443v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.DC",
        "cs.LG",
        "cs.RO"
      ]
    }
  ]
}