{
  "last_updated": "2025-10-16T00:49:52.278066",
  "papers": [
    {
      "title": "DriveVLA-W0: World Models Amplify Data Scaling Law in Autonomous Driving",
      "authors": [
        "Yingyan Li",
        "Shuyao Shang",
        "Weisong Liu",
        "Bing Zhan",
        "Haochen Wang",
        "Yuqi Wang",
        "Yuntao Chen",
        "Xiaoman Wang",
        "Yasong An",
        "Chufeng Tang",
        "Lu Hou",
        "Lue Fan",
        "Zhaoxiang Zhang"
      ],
      "abstract": "Scaling Vision-Language-Action (VLA) models on large-scale data offers a\npromising path to achieving a more generalized driving intelligence. However,\nVLA models are limited by a ``supervision deficit'': the vast model capacity is\nsupervised by sparse, low-dimensional actions, leaving much of their\nrepresentational power underutilized. To remedy this, we propose\n\\textbf{DriveVLA-W0}, a training paradigm that employs world modeling to\npredict future images. This task generates a dense, self-supervised signal that\ncompels the model to learn the underlying dynamics of the driving environment.\nWe showcase the paradigm's versatility by instantiating it for two dominant VLA\narchetypes: an autoregressive world model for VLAs that use discrete visual\ntokens, and a diffusion world model for those operating on continuous visual\nfeatures. Building on the rich representations learned from world modeling, we\nintroduce a lightweight action expert to address the inference latency for\nreal-time deployment. Extensive experiments on the NAVSIM v1/v2 benchmark and a\n680x larger in-house dataset demonstrate that DriveVLA-W0 significantly\noutperforms BEV and VLA baselines. Crucially, it amplifies the data scaling\nlaw, showing that performance gains accelerate as the training dataset size\nincreases.",
      "pdf_url": "http://arxiv.org/pdf/2510.12796v1",
      "published": "2025-10-14T17:59:47+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.12796v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "CuMPerLay: Learning Cubical Multiparameter Persistence Vectorizations",
      "authors": [
        "Caner Korkmaz",
        "Brighton Nuwagira",
        "Barış Coşkunuzer",
        "Tolga Birdal"
      ],
      "abstract": "We present CuMPerLay, a novel differentiable vectorization layer that enables\nthe integration of Cubical Multiparameter Persistence (CMP) into deep learning\npipelines. While CMP presents a natural and powerful way to topologically work\nwith images, its use is hindered by the complexity of multifiltration\nstructures as well as the vectorization of CMP. In face of these challenges, we\nintroduce a new algorithm for vectorizing MP homologies of cubical complexes.\nOur CuMPerLay decomposes the CMP into a combination of individual, learnable\nsingle-parameter persistence, where the bifiltration functions are jointly\nlearned. Thanks to the differentiability, its robust topological feature\nvectors can be seamlessly used within state-of-the-art architectures such as\nSwin Transformers. We establish theoretical guarantees for the stability of our\nvectorization under generalized Wasserstein metrics. Our experiments on\nbenchmark medical imaging and computer vision datasets show the benefit\nCuMPerLay on classification and segmentation performance, particularly in\nlimited-data scenarios. Overall, CuMPerLay offers a promising direction for\nintegrating global structural information into deep networks for structured\nimage analysis.",
      "pdf_url": "http://arxiv.org/pdf/2510.12795v1",
      "published": "2025-10-14T17:59:01+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.12795v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "math.AT",
        "stat.ML"
      ]
    },
    {
      "title": "UniFusion: Vision-Language Model as Unified Encoder in Image Generation",
      "authors": [
        "Kevin Li",
        "Manuel Brack",
        "Sudeep Katakol",
        "Hareesh Ravi",
        "Ajinkya Kale"
      ],
      "abstract": "Although recent advances in visual generation have been remarkable, most\nexisting architectures still depend on distinct encoders for images and text.\nThis separation constrains diffusion models' ability to perform cross-modal\nreasoning and knowledge transfer. Prior attempts to bridge this gap often use\nthe last layer information from VLM, employ multiple visual encoders, or train\nlarge unified models jointly for text and image generation, which demands\nsubstantial computational resources and large-scale data, limiting its\naccessibility.We present UniFusion, a diffusion-based generative model\nconditioned on a frozen large vision-language model (VLM) that serves as a\nunified multimodal encoder. At the core of UniFusion is the Layerwise Attention\nPooling (LAP) mechanism that extracts both high level semantics and low level\ndetails from text and visual tokens of a frozen VLM to condition a diffusion\ngenerative model. We demonstrate that LAP outperforms other shallow fusion\narchitectures on text-image alignment for generation and faithful transfer of\nvisual information from VLM to the diffusion model which is key for editing. We\npropose VLM-Enabled Rewriting Injection with Flexibile Inference (VERIFI),\nwhich conditions a diffusion transformer (DiT) only on the text tokens\ngenerated by the VLM during in-model prompt rewriting. VERIFI combines the\nalignment of the conditioning distribution with the VLM's reasoning\ncapabilities for increased capabilities and flexibility at inference. In\naddition, finetuning on editing task not only improves text-image alignment for\ngeneration, indicative of cross-modality knowledge transfer, but also exhibits\ntremendous generalization capabilities. Our model when trained on single image\nediting, zero-shot generalizes to multiple image references further motivating\nthe unified encoder design of UniFusion.",
      "pdf_url": "http://arxiv.org/pdf/2510.12789v1",
      "published": "2025-10-14T17:57:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.12789v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Ax-Prover: A Deep Reasoning Agentic Framework for Theorem Proving in Mathematics and Quantum Physics",
      "authors": [
        "Marco Del Tredici",
        "Jacob McCarran",
        "Benjamin Breen",
        "Javier Aspuru Mijares",
        "Weichen Winston Yin",
        "Jacob M. Taylor",
        "Frank Koppens",
        "Dirk Englund"
      ],
      "abstract": "We present Ax-Prover, a multi-agent system for automated theorem proving in\nLean that can solve problems across diverse scientific domains and operate\neither autonomously or collaboratively with human experts. To achieve this,\nAx-Prover approaches scientific problem solving through formal proof\ngeneration, a process that demands both creative reasoning and strict syntactic\nrigor. Ax-Prover meets this challenge by equipping Large Language Models\n(LLMs), which provide knowledge and reasoning, with Lean tools via the Model\nContext Protocol (MCP), which ensure formal correctness. To evaluate its\nperformance as an autonomous prover, we benchmark our approach against frontier\nLLMs and specialized prover models on two public math benchmarks and on two\nLean benchmarks we introduce in the fields of abstract algebra and quantum\ntheory. On public datasets, Ax-Prover is competitive with state-of-the-art\nprovers, while it largely outperform them on the new benchmarks. This shows\nthat, unlike specialized systems that struggle to generalize, our tool-based\nagentic theorem prover approach offers a generalizable methodology for formal\nverification across diverse scientific domains. Furthermore, we demonstrate\nAx-Prover's assistant capabilities in a practical use case, showing how it\nenabled an expert mathematician to formalize the proof of a complex\ncryptography theorem.",
      "pdf_url": "http://arxiv.org/pdf/2510.12787v1",
      "published": "2025-10-14T17:57:04+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.12787v1",
      "categories": [
        "cs.AI",
        "cs.MA"
      ]
    },
    {
      "title": "MVP4D: Multi-View Portrait Video Diffusion for Animatable 4D Avatars",
      "authors": [
        "Felix Taubner",
        "Ruihang Zhang",
        "Mathieu Tuli",
        "Sherwin Bahmani",
        "David B. Lindell"
      ],
      "abstract": "Digital human avatars aim to simulate the dynamic appearance of humans in\nvirtual environments, enabling immersive experiences across gaming, film,\nvirtual reality, and more. However, the conventional process for creating and\nanimating photorealistic human avatars is expensive and time-consuming,\nrequiring large camera capture rigs and significant manual effort from\nprofessional 3D artists. With the advent of capable image and video generation\nmodels, recent methods enable automatic rendering of realistic animated avatars\nfrom a single casually captured reference image of a target subject. While\nthese techniques significantly lower barriers to avatar creation and offer\ncompelling realism, they lack constraints provided by multi-view information or\nan explicit 3D representation. So, image quality and realism degrade when\nrendered from viewpoints that deviate strongly from the reference image. Here,\nwe build a video model that generates animatable multi-view videos of digital\nhumans based on a single reference image and target expressions. Our model,\nMVP4D, is based on a state-of-the-art pre-trained video diffusion model and\ngenerates hundreds of frames simultaneously from viewpoints varying by up to\n360 degrees around a target subject. We show how to distill the outputs of this\nmodel into a 4D avatar that can be rendered in real-time. Our approach\nsignificantly improves the realism, temporal consistency, and 3D consistency of\ngenerated avatars compared to previous methods.",
      "pdf_url": "http://arxiv.org/pdf/2510.12785v1",
      "published": "2025-10-14T17:56:14+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.12785v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ]
    },
    {
      "title": "Dr.LLM: Dynamic Layer Routing in LLMs",
      "authors": [
        "Ahmed Heakl",
        "Martin Gubri",
        "Salman Khan",
        "Sangdoo Yun",
        "Seong Joon Oh"
      ],
      "abstract": "Large Language Models (LLMs) process every token through all layers of a\ntransformer stack, causing wasted computation on simple queries and\ninsufficient flexibility for harder ones that need deeper reasoning.\nAdaptive-depth methods can improve efficiency, but prior approaches rely on\ncostly inference-time search, architectural changes, or large-scale retraining,\nand in practice often degrade accuracy despite efficiency gains. We introduce\nDr.LLM, Dynamic routing of Layers for LLMs, a retrofittable framework that\nequips pretrained models with lightweight per-layer routers deciding to skip,\nexecute, or repeat a block. Routers are trained with explicit supervision:\nusing Monte Carlo Tree Search (MCTS), we derive high-quality layer\nconfigurations that preserve or improve accuracy under a compute budget. Our\ndesign, windowed pooling for stable routing, focal loss with class balancing,\nand bottleneck MLP routers, ensures robustness under class imbalance and long\nsequences. On ARC (logic) and DART (math), Dr.LLM improves accuracy by up to\n+3.4%p while saving 5 layers per example on average. Routers generalize to\nout-of-domain tasks (MMLU, GSM8k, AIME, TruthfulQA, SQuADv2, GPQA, PIQA,\nAGIEval) with only 0.85% accuracy drop while retaining efficiency, and\noutperform prior routing methods by up to +7.7%p. Overall, Dr.LLM shows that\nexplicitly supervised routers retrofit frozen LLMs for budget-aware,\naccuracy-driven inference without altering base weights.",
      "pdf_url": "http://arxiv.org/pdf/2510.12773v1",
      "published": "2025-10-14T17:51:26+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.12773v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Uncertainty Matters in Dynamic Gaussian Splatting for Monocular 4D Reconstruction",
      "authors": [
        "Fengzhi Guo",
        "Chih-Chuan Hsu",
        "Sihao Ding",
        "Cheng Zhang"
      ],
      "abstract": "Reconstructing dynamic 3D scenes from monocular input is fundamentally\nunder-constrained, with ambiguities arising from occlusion and extreme novel\nviews. While dynamic Gaussian Splatting offers an efficient representation,\nvanilla models optimize all Gaussian primitives uniformly, ignoring whether\nthey are well or poorly observed. This limitation leads to motion drifts under\nocclusion and degraded synthesis when extrapolating to unseen views. We argue\nthat uncertainty matters: Gaussians with recurring observations across views\nand time act as reliable anchors to guide motion, whereas those with limited\nvisibility are treated as less reliable. To this end, we introduce USplat4D, a\nnovel Uncertainty-aware dynamic Gaussian Splatting framework that propagates\nreliable motion cues to enhance 4D reconstruction. Our key insight is to\nestimate time-varying per-Gaussian uncertainty and leverages it to construct a\nspatio-temporal graph for uncertainty-aware optimization. Experiments on\ndiverse real and synthetic datasets show that explicitly modeling uncertainty\nconsistently improves dynamic Gaussian Splatting models, yielding more stable\ngeometry under occlusion and high-quality synthesis at extreme viewpoints.",
      "pdf_url": "http://arxiv.org/pdf/2510.12768v1",
      "published": "2025-10-14T17:47:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.12768v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ]
    },
    {
      "title": "Disentangling Neurodegeneration with Brain Age Gap Prediction Models: A Graph Signal Processing Perspective",
      "authors": [
        "Saurabh Sihag",
        "Gonzalo Mateos",
        "Alejandro Ribeiro"
      ],
      "abstract": "Neurodegeneration, characterized by the progressive loss of neuronal\nstructure or function, is commonly assessed in clinical practice through\nreductions in cortical thickness or brain volume, as visualized by structural\nMRI. While informative, these conventional approaches lack the statistical\nsophistication required to fully capture the spatially correlated and\nheterogeneous nature of neurodegeneration, which manifests both in healthy\naging and in neurological disorders. To address these limitations, brain age\ngap has emerged as a promising data-driven biomarker of brain health. The brain\nage gap prediction (BAGP) models estimate the difference between a person's\npredicted brain age from neuroimaging data and their chronological age. The\nresulting brain age gap serves as a compact biomarker of brain health, with\nrecent studies demonstrating its predictive utility for disease progression and\nseverity. However, practical adoption of BAGP models is hindered by their\nmethodological obscurities and limited generalizability across diverse clinical\npopulations. This tutorial article provides an overview of BAGP and introduces\na principled framework for this application based on recent advancements in\ngraph signal processing (GSP). In particular, we focus on graph neural networks\n(GNNs) and introduce the coVariance neural network (VNN), which leverages the\nanatomical covariance matrices derived from structural MRI. VNNs offer strong\ntheoretical grounding and operational interpretability, enabling robust\nestimation of brain age gap predictions. By integrating perspectives from GSP,\nmachine learning, and network neuroscience, this work clarifies the path\nforward for reliable and interpretable BAGP models and outlines future research\ndirections in personalized medicine.",
      "pdf_url": "http://arxiv.org/pdf/2510.12763v1",
      "published": "2025-10-14T17:44:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.12763v1",
      "categories": [
        "eess.SP",
        "cs.AI",
        "q-bio.QM"
      ]
    },
    {
      "title": "VQArt-Bench: A semantically rich VQA Benchmark for Art and Cultural Heritage",
      "authors": [
        "A. Alfarano",
        "L. Venturoli",
        "D. Negueruela del Castillo"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) have demonstrated significant\ncapabilities in joint visual and linguistic tasks. However, existing Visual\nQuestion Answering (VQA) benchmarks often fail to evaluate deep semantic\nunderstanding, particularly in complex domains like visual art analysis.\nConfined to simple syntactic structures and surface-level attributes, these\nquestions fail to capture the diversity and depth of human visual inquiry. This\nlimitation incentivizes models to exploit statistical shortcuts rather than\nengage in visual reasoning. To address this gap, we introduce VQArt-Bench, a\nnew, large-scale VQA benchmark for the cultural heritage domain. This benchmark\nis constructed using a novel multi-agent pipeline where specialized agents\ncollaborate to generate nuanced, validated, and linguistically diverse\nquestions. The resulting benchmark is structured along relevant visual\nunderstanding dimensions that probe a model's ability to interpret symbolic\nmeaning, narratives, and complex visual relationships. Our evaluation of 14\nstate-of-the-art MLLMs on this benchmark reveals significant limitations in\ncurrent models, including a surprising weakness in simple counting tasks and a\nclear performance gap between proprietary and open-source models.",
      "pdf_url": "http://arxiv.org/pdf/2510.12750v1",
      "published": "2025-10-14T17:29:52+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.12750v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "CTRL-Rec: Controlling Recommender Systems With Natural Language",
      "authors": [
        "Micah Carroll",
        "Adeline Foote",
        "Kevin Feng",
        "Marcus Williams",
        "Anca Dragan",
        "W. Bradley Knox",
        "Smitha Milli"
      ],
      "abstract": "When users are dissatisfied with recommendations from a recommender system,\nthey often lack fine-grained controls for changing them. Large language models\n(LLMs) offer a solution by allowing users to guide their recommendations\nthrough natural language requests (e.g., \"I want to see respectful posts with a\ndifferent perspective than mine\"). We propose a method, CTRL-Rec, that allows\nfor natural language control of traditional recommender systems in real-time\nwith computational efficiency. Specifically, at training time, we use an LLM to\nsimulate whether users would approve of items based on their language requests,\nand we train embedding models that approximate such simulated judgments. We\nthen integrate these user-request-based predictions into the standard weighting\nof signals that traditional recommender systems optimize. At deployment time,\nwe require only a single LLM embedding computation per user request, allowing\nfor real-time control of recommendations. In experiments with the MovieLens\ndataset, our method consistently allows for fine-grained control across a\ndiversity of requests. In a study with 19 Letterboxd users, we find that\nCTRL-Rec was positively received by users and significantly enhanced users'\nsense of control and satisfaction with recommendations compared to traditional\ncontrols.",
      "pdf_url": "http://arxiv.org/pdf/2510.12742v1",
      "published": "2025-10-14T17:20:04+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.12742v1",
      "categories": [
        "cs.AI",
        "cs.IR"
      ]
    },
    {
      "title": "Hey, wait a minute: on at-issue sensitivity in Language Models",
      "authors": [
        "Sanghee J. Kim",
        "Kanishka Misra"
      ],
      "abstract": "Evaluating the naturalness of dialogue in language models (LMs) is not\ntrivial: notions of 'naturalness' vary, and scalable quantitative metrics\nremain limited. This study leverages the linguistic notion of 'at-issueness' to\nassess dialogue naturalness and introduces a new method: Divide, Generate,\nRecombine, and Compare (DGRC). DGRC (i) divides a dialogue as a prompt, (ii)\ngenerates continuations for subparts using LMs, (iii) recombines the dialogue\nand continuations, and (iv) compares the likelihoods of the recombined\nsequences. This approach mitigates bias in linguistic analyses of LMs and\nenables systematic testing of discourse-sensitive behavior. Applying DGRC, we\nfind that LMs prefer to continue dialogue on at-issue content, with this effect\nenhanced in instruct-tuned models. They also reduce their at-issue preference\nwhen relevant cues (e.g., \"Hey, wait a minute\") are present. Although\ninstruct-tuning does not further amplify this modulation, the pattern reflects\na hallmark of successful dialogue dynamics.",
      "pdf_url": "http://arxiv.org/pdf/2510.12740v1",
      "published": "2025-10-14T17:17:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.12740v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "HYPE: Hybrid Planning with Ego Proposal-Conditioned Predictions",
      "authors": [
        "Hang Yu",
        "Julian Jordan",
        "Julian Schmidt",
        "Silvan Lindner",
        "Alessandro Canevaro",
        "Wilhelm Stork"
      ],
      "abstract": "Safe and interpretable motion planning in complex urban environments needs to\nreason about bidirectional multi-agent interactions. This reasoning requires to\nestimate the costs of potential ego driving maneuvers. Many existing planners\ngenerate initial trajectories with sampling-based methods and refine them by\noptimizing on learned predictions of future environment states, which requires\na cost function that encodes the desired vehicle behavior. Designing such a\ncost function can be very challenging, especially if a wide range of complex\nurban scenarios has to be considered. We propose HYPE: HYbrid Planning with Ego\nproposal-conditioned predictions, a planner that integrates multimodal\ntrajectory proposals from a learned proposal model as heuristic priors into a\nMonte Carlo Tree Search (MCTS) refinement. To model bidirectional interactions,\nwe introduce an ego-conditioned occupancy prediction model, enabling\nconsistent, scene-aware reasoning. Our design significantly simplifies cost\nfunction design in refinement by considering proposal-driven guidance,\nrequiring only minimalistic grid-based cost terms. Evaluations on large-scale\nreal-world benchmarks nuPlan and DeepUrban show that HYPE effectively achieves\nstate-of-the-art performance, especially in safety and adaptability.",
      "pdf_url": "http://arxiv.org/pdf/2510.12733v1",
      "published": "2025-10-14T17:11:04+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.12733v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Clutch Control: An Attention-based Combinatorial Bandit for Efficient Mutation in JavaScript Engine Fuzzing",
      "authors": [
        "Myles Foley",
        "Sergio Maffeis",
        "Muhammad Fakhrur Rozi",
        "Takeshi Takahashi"
      ],
      "abstract": "JavaScript engines are widely used in web browsers, PDF readers, and\nserver-side applications. The rise in concern over their security has led to\nthe development of several targeted fuzzing techniques. However, existing\napproaches use random selection to determine where to perform mutations in\nJavaScript code. We postulate that the problem of selecting better mutation\ntargets is suitable for combinatorial bandits with a volatile number of arms.\nThus, we propose CLUTCH, a novel deep combinatorial bandit that can observe\nvariable length JavaScript test case representations, using an attention\nmechanism from deep learning. Furthermore, using Concrete Dropout, CLUTCH can\ndynamically adapt its exploration. We show that CLUTCH increases efficiency in\nJavaScript fuzzing compared to three state-of-the-art solutions by increasing\nthe number of valid test cases and coverage-per-testcase by, respectively,\n20.3% and 8.9% on average. In volatile and combinatorial settings we show that\nCLUTCH outperforms state-of-the-art bandits, achieving at least 78.1% and 4.1%\nless regret in volatile and combinatorial settings, respectively.",
      "pdf_url": "http://arxiv.org/pdf/2510.12732v1",
      "published": "2025-10-14T17:10:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.12732v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Hierarchical Federated Learning for Crop Yield Prediction in Smart Agricultural Production Systems",
      "authors": [
        "Anas Abouaomar",
        "Mohammed El hanjri",
        "Abdellatif Kobbane",
        "Anis Laouiti",
        "Khalid Nafil"
      ],
      "abstract": "In this paper, we presents a novel hierarchical federated learning\narchitecture specifically designed for smart agricultural production systems\nand crop yield prediction. Our approach introduces a seasonal subscription\nmechanism where farms join crop-specific clusters at the beginning of each\nagricultural season. The proposed three-layer architecture consists of\nindividual smart farms at the client level, crop-specific aggregators at the\nmiddle layer, and a global model aggregator at the top level. Within each crop\ncluster, clients collaboratively train specialized models tailored to specific\ncrop types, which are then aggregated to produce a higher-level global model\nthat integrates knowledge across multiple crops. This hierarchical design\nenables both local specialization for individual crop types and global\ngeneralization across diverse agricultural contexts while preserving data\nprivacy and reducing communication overhead. Experiments demonstrate the\neffectiveness of the proposed system, showing that local and crop-layer models\nclosely follow actual yield patterns with consistent alignment, significantly\noutperforming standard machine learning models. The results validate the\nadvantages of hierarchical federated learning in the agricultural context,\nparticularly for scenarios involving heterogeneous farming environments and\nprivacy-sensitive agricultural data.",
      "pdf_url": "http://arxiv.org/pdf/2510.12727v1",
      "published": "2025-10-14T17:06:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.12727v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ]
    },
    {
      "title": "Artificial intelligence for simplified patient-centered dosimetry in radiopharmaceutical therapies",
      "authors": [
        "Alejandro Lopez-Montes",
        "Fereshteh Yousefirizi",
        "Yizhou Chen",
        "Yazdan Salimi",
        "Robert Seifert",
        "Ali Afshar-Oromieh",
        "Carlos Uribe",
        "Axel Rominger",
        "Habib Zaidi",
        "Arman Rahmim",
        "Kuangyu Shi"
      ],
      "abstract": "KEY WORDS: Artificial Intelligence (AI), Theranostics, Dosimetry,\nRadiopharmaceutical Therapy (RPT), Patient-friendly dosimetry KEY POINTS - The\nrapid evolution of radiopharmaceutical therapy (RPT) highlights the growing\nneed for personalized and patient-centered dosimetry. - Artificial Intelligence\n(AI) offers solutions to the key limitations in current dosimetry calculations.\n- The main advances on AI for simplified dosimetry toward patient-friendly RPT\nare reviewed. - Future directions on the role of AI in RPT dosimetry are\ndiscussed.",
      "pdf_url": "http://arxiv.org/pdf/2510.12714v1",
      "published": "2025-10-14T16:55:36+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.12714v1",
      "categories": [
        "physics.med-ph",
        "cs.AI",
        "physics.app-ph"
      ]
    },
    {
      "title": "Towards Robust Artificial Intelligence: Self-Supervised Learning Approach for Out-of-Distribution Detection",
      "authors": [
        "Wissam Salhab",
        "Darine Ameyed",
        "Hamid Mcheick",
        "Fehmi Jaafar"
      ],
      "abstract": "Robustness in AI systems refers to their ability to maintain reliable and\naccurate performance under various conditions, including out-of-distribution\n(OOD) samples, adversarial attacks, and environmental changes. This is crucial\nin safety-critical systems, such as autonomous vehicles, transportation, or\nhealthcare, where malfunctions could have severe consequences. This paper\nproposes an approach to improve OOD detection without the need of labeled data,\nthereby increasing the AI systems' robustness. The proposed approach leverages\nthe principles of self-supervised learning, allowing the model to learn useful\nrepresentations from unlabeled data. Combined with graph-theoretical\ntechniques, this enables the more efficient identification and categorization\nof OOD samples. Compared to existing state-of-the-art methods, this approach\nachieved an Area Under the Receiver Operating Characteristic Curve (AUROC) =\n0.99.",
      "pdf_url": "http://arxiv.org/pdf/2510.12713v1",
      "published": "2025-10-14T16:55:25+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.12713v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Beyond Seeing: Evaluating Multimodal LLMs on Tool-Enabled Image Perception, Transformation, and Reasoning",
      "authors": [
        "Xingang Guo",
        "Utkarsh Tyagi",
        "Advait Gosai",
        "Paula Vergara",
        "Ernesto Gabriel Hernández Montoya",
        "Chen Bo Calvin Zhang",
        "Bin Hu",
        "Yunzhong He",
        "Bing Liu",
        "Rakshith Sharma Srinivasa"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) are increasingly applied in\nreal-world scenarios where user-provided images are often imperfect, requiring\nactive image manipulations such as cropping, editing, or enhancement to uncover\nsalient visual cues. Beyond static visual perception, MLLMs must also think\nwith images: dynamically transforming visual content and integrating it with\nother tools to solve complex tasks. However, this shift from treating vision as\npassive context to a manipulable cognitive workspace remains underexplored.\nMost existing benchmarks still follow a think about images paradigm, where\nimages are regarded as static inputs. To address this gap, we introduce IRIS,\nan Interactive Reasoning with Images and Systems that evaluates MLLMs' ability\nto perceive, transform, and reason across complex visual-textual tasks under\nthe think with images paradigm. IRIS comprises 1,204 challenging, open-ended\nvision tasks (603 single-turn, 601 multi-turn) spanning across five diverse\ndomains, each paired with detailed rubrics to enable systematic evaluation. Our\nevaluation shows that current MLLMs struggle with tasks requiring effective\nintegration of vision and general-purpose tools. Even the strongest model\n(GPT-5-think) reaches only 18.68% pass rate. We further observe divergent\ntool-use behaviors, with OpenAI models benefiting from diverse image\nmanipulations while Gemini-2.5-pro shows no improvement. By introducing the\nfirst benchmark centered on think with images, IRIS offers critical insights\nfor advancing visual intelligence in MLLMs.",
      "pdf_url": "http://arxiv.org/pdf/2510.12712v1",
      "published": "2025-10-14T16:50:49+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.12712v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Hybrid Explanation-Guided Learning for Transformer-Based Chest X-Ray Diagnosis",
      "authors": [
        "Shelley Zixin Shu",
        "Haozhe Luo",
        "Alexander Poellinger",
        "Mauricio Reyes"
      ],
      "abstract": "Transformer-based deep learning models have demonstrated exceptional\nperformance in medical imaging by leveraging attention mechanisms for feature\nrepresentation and interpretability. However, these models are prone to\nlearning spurious correlations, leading to biases and limited generalization.\nWhile human-AI attention alignment can mitigate these issues, it often depends\non costly manual supervision. In this work, we propose a Hybrid\nExplanation-Guided Learning (H-EGL) framework that combines self-supervised and\nhuman-guided constraints to enhance attention alignment and improve\ngeneralization. The self-supervised component of H-EGL leverages\nclass-distinctive attention without relying on restrictive priors, promoting\nrobustness and flexibility. We validate our approach on chest X-ray\nclassification using the Vision Transformer (ViT), where H-EGL outperforms two\nstate-of-the-art Explanation-Guided Learning (EGL) methods, demonstrating\nsuperior classification accuracy and generalization capability. Additionally,\nit produces attention maps that are better aligned with human expertise.",
      "pdf_url": "http://arxiv.org/pdf/2510.12704v1",
      "published": "2025-10-14T16:39:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.12704v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "CAMNet: Leveraging Cooperative Awareness Messages for Vehicle Trajectory Prediction",
      "authors": [
        "Mattia Grasselli",
        "Angelo Porrello",
        "Carlo Augusto Grazia"
      ],
      "abstract": "Autonomous driving remains a challenging task, particularly due to safety\nconcerns. Modern vehicles are typically equipped with expensive sensors such as\nLiDAR, cameras, and radars to reduce the risk of accidents. However, these\nsensors face inherent limitations: their field of view and line of sight can be\nobstructed by other vehicles, thereby reducing situational awareness. In this\ncontext, vehicle-to-vehicle communication plays a crucial role, as it enables\ncars to share information and remain aware of each other even when sensors are\noccluded. One way to achieve this is through the use of Cooperative Awareness\nMessages (CAMs). In this paper, we investigate the use of CAM data for vehicle\ntrajectory prediction. Specifically, we design and train a neural network,\nCooperative Awareness Message-based Graph Neural Network (CAMNet), on a widely\nused motion forecasting dataset. We then evaluate the model on a second dataset\nthat we created from scratch using Cooperative Awareness Messages, in order to\nassess whether this type of data can be effectively exploited. Our approach\ndemonstrates promising results, showing that CAMs can indeed support vehicle\ntrajectory prediction. At the same time, we discuss several limitations of the\napproach, which highlight opportunities for future research.",
      "pdf_url": "http://arxiv.org/pdf/2510.12703v1",
      "published": "2025-10-14T16:37:52+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.12703v1",
      "categories": [
        "cs.AI",
        "cs.NI"
      ]
    },
    {
      "title": "Beyond Postconditions: Can Large Language Models infer Formal Contracts for Automatic Software Verification?",
      "authors": [
        "Cedric Richter",
        "Heike Wehrheim"
      ],
      "abstract": "Automatic software verifiers have become increasingly effective at the task\nof checking software against (formal) specifications. Yet, their adoption in\npractice has been hampered by the lack of such specifications in real world\ncode. Large Language Models (LLMs) have shown promise in inferring formal\npostconditions from natural language hints embedded in code such as function\nnames, comments or documentation. Using the generated postconditions as\nspecifications in a subsequent verification, however, often leads verifiers to\nsuggest invalid inputs, hinting at potential issues that ultimately turn out to\nbe false alarms.\n  To address this, we revisit the problem of specification inference from\nnatural language in the context of automatic software verification. In the\nprocess, we introduce NL2Contract, the task of employing LLMs to translate\ninformal natural language into formal functional contracts, consisting of\npostconditions as well as preconditions. We introduce metrics to validate and\ncompare different NL2Contract approaches, using soundness, bug discriminative\npower of the generated contracts and their usability in the context of\nautomatic software verification as key metrics. We evaluate NL2Contract with\ndifferent LLMs and compare it to the task of postcondition generation\nnl2postcond. Our evaluation shows that (1) LLMs are generally effective at\ngenerating functional contracts sound for all possible inputs, (2) the\ngenerated contracts are sufficiently expressive for discriminating buggy from\ncorrect behavior, and (3) verifiers supplied with LLM inferred functional\ncontracts produce fewer false alarms than when provided with postconditions\nalone. Further investigations show that LLM inferred preconditions generally\nalign well with developers intentions which allows us to use automatic software\nverifiers to catch real-world bugs.",
      "pdf_url": "http://arxiv.org/pdf/2510.12702v1",
      "published": "2025-10-14T16:37:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.12702v1",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.PL"
      ]
    },
    {
      "title": "Topological Signatures of ReLU Neural Network Activation Patterns",
      "authors": [
        "Vicente Bosca",
        "Tatum Rask",
        "Sunia Tanweer",
        "Andrew R. Tawfeek",
        "Branden Stone"
      ],
      "abstract": "This paper explores the topological signatures of ReLU neural network\nactivation patterns. We consider feedforward neural networks with ReLU\nactivation functions and analyze the polytope decomposition of the feature\nspace induced by the network. Mainly, we investigate how the Fiedler partition\nof the dual graph and show that it appears to correlate with the decision\nboundary -- in the case of binary classification. Additionally, we compute the\nhomology of the cellular decomposition -- in a regression task -- to draw\nsimilar patterns in behavior between the training loss and polyhedral\ncell-count, as the model is trained.",
      "pdf_url": "http://arxiv.org/pdf/2510.12700v1",
      "published": "2025-10-14T16:36:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.12700v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CG",
        "math.AT",
        "stat.ML"
      ]
    },
    {
      "title": "Generation Space Size: Understanding and Calibrating Open-Endedness of LLM Generations",
      "authors": [
        "Sunny Yu",
        "Ahmad Jabbar",
        "Robert Hawkins",
        "Dan Jurafsky",
        "Myra Cheng"
      ],
      "abstract": "Different open-ended generation tasks require different degrees of output\ndiversity. However, current LLMs are often miscalibrated. They collapse to\noverly homogeneous outputs for creative tasks and hallucinate diverse but\nincorrect responses for factual tasks. We argue that these two failure modes\nare unified by, and can both be addressed by, the notion of effective\ngeneration space size (GSS) -- the set of semantically distinct outputs a model\nconsiders for a prompt. We present GSSBench, a task suite of prompt pairs with\nground-truth GSS relationships to assess different metrics and understand where\nmodels diverge from desired behavior. We find that hallucination detection\nmetrics, particularly EigenScore, consistently outperform standard diversity\nand uncertainty quantification metrics, while using only model internals,\nproviding interpretable insights into a model's internal task representations.\nWe demonstrate three applications of GSS: (1) detecting prompt ambiguity and\npredicting clarification questions for better grounding, (2) interpreting\noverthinking and underthinking in reasoning models, and (3) steering models to\nexpand their generation space to yield high-quality and diverse outputs.",
      "pdf_url": "http://arxiv.org/pdf/2510.12699v1",
      "published": "2025-10-14T16:31:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.12699v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Multi-Agent Debate for LLM Judges with Adaptive Stability Detection",
      "authors": [
        "Tianyu Hu",
        "Zhen Tan",
        "Song Wang",
        "Huaizhi Qu",
        "Tianlong Chen"
      ],
      "abstract": "With advancements in reasoning capabilities, Large Language Models (LLMs) are\nincreasingly employed for automated judgment tasks. While LLMs-as-Judges offer\npromise in automating evaluations, current approaches often rely on simplistic\naggregation methods (e.g., majority voting), which can fail even when\nindividual agents provide correct answers. To address this, we propose a\nmulti-agent debate judge framework where agents collaboratively reason and\niteratively refine their responses. We formalize the debate process\nmathematically, analyzing agent interactions and proving that debate amplifies\ncorrectness compared to static ensembles. To enhance efficiency, we introduce a\nstability detection mechanism that models judge consensus dynamics via a\ntime-varying Beta-Binomial mixture, with adaptive stopping based on\ndistributional similarity (Kolmogorov-Smirnov test). This mechanism models the\njudges' collective correct rate dynamics using a time-varying mixture of\nBeta-Binomial distributions and employs an adaptive stopping criterion based on\ndistributional similarity (Kolmogorov-Smirnov statistic). Experiments across\nmultiple benchmarks and models demonstrate that our framework improves judgment\naccuracy over majority voting while maintaining computational efficiency.",
      "pdf_url": "http://arxiv.org/pdf/2510.12697v1",
      "published": "2025-10-14T16:30:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.12697v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "ERA: Transforming VLMs into Embodied Agents via Embodied Prior Learning and Online Reinforcement Learning",
      "authors": [
        "Hanyang Chen",
        "Mark Zhao",
        "Rui Yang",
        "Qinwei Ma",
        "Ke Yang",
        "Jiarui Yao",
        "Kangrui Wang",
        "Hao Bai",
        "Zhenhailong Wang",
        "Rui Pan",
        "Mengchao Zhang",
        "Jose Barreiros",
        "Aykut Onol",
        "ChengXiang Zhai",
        "Heng Ji",
        "Manling Li",
        "Huan Zhang",
        "Tong Zhang"
      ],
      "abstract": "Recent advances in embodied AI highlight the potential of vision language\nmodels (VLMs) as agents capable of perception, reasoning, and interaction in\ncomplex environments. However, top-performing systems rely on large-scale\nmodels that are costly to deploy, while smaller VLMs lack the necessary\nknowledge and skills to succeed. To bridge this gap, we present\n\\textit{Embodied Reasoning Agent (ERA)}, a two-stage framework that integrates\nprior knowledge learning and online reinforcement learning (RL). The first\nstage, \\textit{Embodied Prior Learning}, distills foundational knowledge from\nthree types of data: (1) Trajectory-Augmented Priors, which enrich existing\ntrajectory data with structured reasoning generated by stronger models; (2)\nEnvironment-Anchored Priors, which provide in-environment knowledge and\ngrounding supervision; and (3) External Knowledge Priors, which transfer\ngeneral knowledge from out-of-environment datasets. In the second stage, we\ndevelop an online RL pipeline that builds on these priors to further enhance\nagent performance. To overcome the inherent challenges in agent RL, including\nlong horizons, sparse rewards, and training instability, we introduce three key\ndesigns: self-summarization for context management, dense reward shaping, and\nturn-level policy optimization. Extensive experiments on both high-level\nplanning (EB-ALFRED) and low-level control (EB-Manipulation) tasks demonstrate\nthat ERA-3B surpasses both prompting-based large models and previous\ntraining-based baselines. Specifically, it achieves overall improvements of\n8.4\\% on EB-ALFRED and 19.4\\% on EB-Manipulation over GPT-4o, and exhibits\nstrong generalization to unseen tasks. Overall, ERA offers a practical path\ntoward scalable embodied intelligence, providing methodological insights for\nfuture embodied AI systems.",
      "pdf_url": "http://arxiv.org/pdf/2510.12693v1",
      "published": "2025-10-14T16:25:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.12693v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Who is a Better Matchmaker? Human vs. Algorithmic Judge Assignment in a High-Stakes Startup Competition",
      "authors": [
        "Sarina Xi",
        "Orelia Pi",
        "Miaomiao Zhang",
        "Becca Xiong",
        "Jacqueline Ng Lane",
        "Nihar B. Shah"
      ],
      "abstract": "There is growing interest in applying artificial intelligence (AI) to\nautomate and support complex decision-making tasks. However, it remains unclear\nhow algorithms compare to human judgment in contexts requiring semantic\nunderstanding and domain expertise. We examine this in the context of the judge\nassignment problem, matching submissions to suitably qualified judges.\nSpecifically, we tackled this problem at the Harvard President's Innovation\nChallenge, the university's premier venture competition awarding over \\$500,000\nto student and alumni startups. This represents a real-world environment where\nhigh-quality judge assignment is essential. We developed an AI-based\njudge-assignment algorithm, Hybrid Lexical-Semantic Similarity Ensemble (HLSE),\nand deployed it at the competition. We then evaluated its performance against\nhuman expert assignments using blinded match-quality scores from judges on\n$309$ judge-venture pairs. Using a Mann-Whitney U statistic based test, we\nfound no statistically significant difference in assignment quality between the\ntwo approaches ($AUC=0.48, p=0.40$); on average, algorithmic matches are rated\n$3.90$ and manual matches $3.94$ on a 5-point scale, where 5 indicates an\nexcellent match. Furthermore, manual assignments that previously required a\nfull week could be automated in several hours by the algorithm during\ndeployment. These results demonstrate that HLSE achieves human-expert-level\nmatching quality while offering greater scalability and efficiency,\nunderscoring the potential of AI-driven solutions to support and enhance human\ndecision-making for judge assignment in high-stakes settings.",
      "pdf_url": "http://arxiv.org/pdf/2510.12692v1",
      "published": "2025-10-14T16:25:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.12692v1",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.LG"
      ]
    },
    {
      "title": "DiffEM: Learning from Corrupted Data with Diffusion Models via Expectation Maximization",
      "authors": [
        "Danial Hosseintabar",
        "Fan Chen",
        "Giannis Daras",
        "Antonio Torralba",
        "Constantinos Daskalakis"
      ],
      "abstract": "Diffusion models have emerged as powerful generative priors for\nhigh-dimensional inverse problems, yet learning them when only corrupted or\nnoisy observations are available remains challenging. In this work, we propose\na new method for training diffusion models with Expectation-Maximization (EM)\nfrom corrupted data. Our proposed method, DiffEM, utilizes conditional\ndiffusion models to reconstruct clean data from observations in the E-step, and\nthen uses the reconstructed data to refine the conditional diffusion model in\nthe M-step. Theoretically, we provide monotonic convergence guarantees for the\nDiffEM iteration, assuming appropriate statistical conditions. We demonstrate\nthe effectiveness of our approach through experiments on various image\nreconstruction tasks.",
      "pdf_url": "http://arxiv.org/pdf/2510.12691v1",
      "published": "2025-10-14T16:25:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.12691v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "From Delegates to Trustees: How Optimizing for Long-Term Interests Shapes Bias and Alignment in LLM",
      "authors": [
        "Suyash Fulay",
        "Jocelyn Zhu",
        "Michiel Bakker"
      ],
      "abstract": "Large language models (LLMs) have shown promising accuracy in predicting\nsurvey responses and policy preferences, which has increased interest in their\npotential to represent human interests in various domains. Most existing\nresearch has focused on behavioral cloning, effectively evaluating how well\nmodels reproduce individuals' expressed preferences. Drawing on theories of\npolitical representation, we highlight an underexplored design trade-off:\nwhether AI systems should act as delegates, mirroring expressed preferences, or\nas trustees, exercising judgment about what best serves an individual's\ninterests. This trade-off is closely related to issues of LLM sycophancy, where\nmodels can encourage behavior or validate beliefs that may be aligned with a\nuser's short-term preferences, but is detrimental to their long-term interests.\nThrough a series of experiments simulating votes on various policy issues in\nthe U.S. context, we apply a temporal utility framework that weighs short and\nlong-term interests (simulating a trustee role) and compare voting outcomes to\nbehavior-cloning models (simulating a delegate). We find that trustee-style\npredictions weighted toward long-term interests produce policy decisions that\nalign more closely with expert consensus on well-understood issues, but also\nshow greater bias toward models' default stances on topics lacking clear\nagreement. These findings reveal a fundamental trade-off in designing AI\nsystems to represent human interests. Delegate models better preserve user\nautonomy but may diverge from well-supported policy positions, while trustee\nmodels can promote welfare on well-understood issues yet risk paternalism and\nbias on subjective topics.",
      "pdf_url": "http://arxiv.org/pdf/2510.12689v1",
      "published": "2025-10-14T16:24:19+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.12689v1",
      "categories": [
        "cs.CY",
        "cs.AI"
      ]
    },
    {
      "title": "Demystifying Hybrid Thinking: Can LLMs Truly Switch Between Think and No-Think?",
      "authors": [
        "Shouren Wang",
        "Wang Yang",
        "Xianxuan Long",
        "Qifan Wang",
        "Vipin Chaudhary",
        "Xiaotian Han"
      ],
      "abstract": "Hybrid thinking enables LLMs to switch between reasoning and direct\nanswering, offering a balance between efficiency and reasoning capability. Yet\nour experiments reveal that current hybrid thinking LLMs only achieve partial\nmode separation: reasoning behaviors often leak into the no-think mode. To\nunderstand and mitigate this, we analyze the factors influencing\ncontrollability and identify four that matter most: (1) larger data scale, (2)\nusing think and no-think answers from different questions rather than the same\nquestion, (3) a moderate increase in no-think data number, and (4) a two-phase\nstrategy that first trains reasoning ability and then applies hybrid think\ntraining. Building on these findings, we propose a practical recipe that,\ncompared to standard training, can maintain accuracy in both modes while\nsignificantly reducing no-think output length (from $1085$ to $585$ on MATH500)\nand occurrences of reasoning-supportive tokens such as ``\\texttt{wait}'' (from\n$5917$ to $522$ on MATH500). Our findings highlight the limitations of current\nhybrid thinking and offer directions for strengthening its controllability.",
      "pdf_url": "http://arxiv.org/pdf/2510.12680v1",
      "published": "2025-10-14T16:19:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.12680v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "SG-XDEAT: Sparsity-Guided Cross-Dimensional and Cross-Encoding Attention with Target-Aware Conditioning in Tabular Learning",
      "authors": [
        "Chih-Chuan Cheng",
        "Yi-Ju Tseng"
      ],
      "abstract": "We propose SG-XDEAT (Sparsity-Guided Cross Dimensional and Cross-Encoding\nAttention with Target Aware Conditioning), a novel framework designed for\nsupervised learning on tabular data. At its core, SG-XDEAT employs a\ndual-stream encoder that decomposes each input feature into two parallel\nrepresentations: a raw value stream and a target-conditioned (label-aware)\nstream. These dual representations are then propagated through a hierarchical\nstack of attention-based modules. SG-XDEAT integrates three key components: (i)\nCross-Dimensional self-attention, which captures intra-view dependencies among\nfeatures within each stream; (ii) Cross-Encoding self-attention, which enables\nbidirectional interaction between raw and target-aware representations; and\n(iii) an Adaptive Sparse Self-Attention (ASSA) mechanism, which dynamically\nsuppresses low-utility tokens by driving their attention weights toward\nzero--thereby mitigating the impact of noise. Empirical results on multiple\npublic benchmarks show consistent gains over strong baselines, confirming that\njointly modeling raw and target-aware views--while adaptively filtering\nnoise--yields a more robust deep tabular learner.",
      "pdf_url": "http://arxiv.org/pdf/2510.12659v1",
      "published": "2025-10-14T15:56:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.12659v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Reasoning Pattern Matters: Learning to Reason without Human Rationales",
      "authors": [
        "Chaoxu Pang",
        "Yixuan Cao",
        "Ping Luo"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable reasoning\ncapabilities under the widely adopted SFT+RLVR paradigm, which first performs\nSupervised Fine-Tuning (SFT) on human-annotated reasoning trajectories\n(rationales) to establish initial reasoning behaviors, then applies\nReinforcement Learning with Verifiable Rewards (RLVR) to optimize the model\nusing verifiable signals without golden rationales. However, annotating\nhigh-quality rationales for the SFT stage remains prohibitively expensive. This\npaper investigates when and how rationale annotation costs can be substantially\nreduced without compromising reasoning performance. We identify a broad class\nof problems, termed patterned reasoning tasks, where reasoning follows a fixed,\nprocedural strategy consistent across instances. Although instances vary in\ncontent such as domain knowledge, factual information, or numeric values, the\nsolution derives from applying a shared reasoning pattern. We argue that the\nsuccess of SFT+RLVR on such tasks primarily stems from its ability to enable\nmodels to internalize these reasoning patterns. Using numerical semantic\nmatching as a representative task, we provide both causal and behavioral\nevidence showing that reasoning patterns rather than the quantity or quality of\nrationales are the key determinant of performance. Building on these insights,\nwe propose Pattern-Aware LLMs as Rationale AnnOtators (PARO), a simple yet\neffective framework that enables LLMs to generate rationales aligned with\ntask-specific reasoning patterns without requiring human rationale annotations.\nExperiments show that PARO-generated rationales achieve comparable SFT+RLVR\nperformance to human rationales that are 10 times larger. These results suggest\nthat large-scale human rationale annotations can be replaced with LLM-based\nautomatic annotations requiring only limited human supervision over reasoning\npatterns.",
      "pdf_url": "http://arxiv.org/pdf/2510.12643v1",
      "published": "2025-10-14T15:34:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.12643v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Aixel: A Unified, Adaptive and Extensible System for AI-powered Data Analysis",
      "authors": [
        "Meihui Zhang",
        "Liming Wang",
        "Chi Zhang",
        "Zhaojing Luo"
      ],
      "abstract": "A growing trend in modern data analysis is the integration of data management\nwith learning, guided by accuracy, latency, and cost requirements. In practice,\napplications draw data of different formats from many sources. In the\nmeanwhile, the objectives and budgets change over time. Existing systems handle\nthese applications across databases, analysis libraries, and tuning services.\nSuch fragmentation leads to complex user interaction, limited adaptability,\nsuboptimal performance, and poor extensibility across components. To address\nthese challenges, we present Aixel, a unified, adaptive, and extensible system\nfor AI-powered data analysis. The system organizes work across four layers:\napplication, task, model, and data. The task layer provides a declarative\ninterface to capture user intent, which is parsed into an executable operator\nplan. An optimizer compiles and schedules this plan to meet specified goals in\naccuracy, latency, and cost. The task layer coordinates the execution of data\nand model operators, with built-in support for reuse and caching to improve\nefficiency. The model layer offers versioned storage for index, metadata,\ntensors, and model artifacts. It supports adaptive construction, task-aligned\ndrift detection, and safe updates that reuse shared components. The data layer\nprovides unified data management capabilities, including indexing,\nconstraint-aware discovery, task-aligned selection, and comprehensive feature\nmanagement. With the above designed layers, Aixel delivers a user friendly,\nadaptive, efficient, and extensible system.",
      "pdf_url": "http://arxiv.org/pdf/2510.12642v1",
      "published": "2025-10-14T15:34:35+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.12642v1",
      "categories": [
        "cs.DB",
        "cs.AI"
      ]
    },
    {
      "title": "Memory as Action: Autonomous Context Curation for Long-Horizon Agentic Tasks",
      "authors": [
        "Yuxiang Zhang",
        "Jiangming Shu",
        "Ye Ma",
        "Xueyuan Lin",
        "Shangxi Wu",
        "Jitao Sang"
      ],
      "abstract": "Large Language Models face challenges in long-horizon agentic tasks as their\nconstrained memory is easily overwhelmed by distracting or irrelevant context.\nExisting working memory methods typically rely on external, heuristic\nmechanisms that are decoupled from the agent's core policy. In this work, we\nreframe working memory management as a learnable, intrinsic capability. We\npropose a novel framework, Memory-as-Action, where an agent actively manages\nits working memory by executing explicit editing operations as part of a\nunified policy. This formulation allows an agent, trained via reinforcement\nlearning, to balance memory curation against long-term task objectives under\ngiven resource constraints. However, such memory editing actions break the\nstandard assumption of a continuously growing prefix in LLM interactions,\nleading to what we call trajectory fractures. These non-prefix changes disrupt\nthe causal continuity required by standard policy gradient methods, making\nthose methods inapplicable. To address this, we propose a new algorithm,\nDynamic Context Policy Optimization, which enables stable end-to-end\nreinforcement learning by segmenting trajectories at memory action points and\napplying trajectory-level advantages to the resulting action segments. Our\nresults demonstrate that jointly optimizing for task reasoning and memory\nmanagement in an end-to-end fashion not only reduces overall computational\nconsumption but also improves task performance, driven by adaptive context\ncuration strategies tailored to the model's intrinsic capabilities.",
      "pdf_url": "http://arxiv.org/pdf/2510.12635v1",
      "published": "2025-10-14T15:29:57+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.12635v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Laminar: A Scalable Asynchronous RL Post-Training Framework",
      "authors": [
        "Guangming Sheng",
        "Yuxuan Tong",
        "Borui Wan",
        "Wang Zhang",
        "Chaobo Jia",
        "Xibin Wu",
        "Yuqi Wu",
        "Xiang Li",
        "Chi Zhang",
        "Yanghua Peng",
        "Haibin Lin",
        "Xin Liu",
        "Chuan Wu"
      ],
      "abstract": "Reinforcement learning (RL) post-training for Large Language Models (LLMs) is\nnow scaling to large clusters and running for extended durations to enhance\nmodel reasoning performance. However, the scalability of existing RL frameworks\nis limited, as extreme long-tail skewness in RL trajectory generation causes\nsevere GPU underutilization. Current asynchronous RL systems attempt to\nmitigate this, but they rely on global weight synchronization between the actor\nand all rollouts, which creates a rigid model update schedule. This global\nsynchronization is ill-suited for the highly skewed and evolving distribution\nof trajectory generation latency in RL training, crippling training efficiency.\nOur key insight is that efficient scaling requires breaking this lockstep\nthrough trajectory-level asynchrony, which generates and consumes each\ntrajectory independently. We propose Laminar, a scalable and robust RL\npost-training system built on a fully decoupled architecture. First, we replace\nglobal updates with a tier of relay workers acting as a distributed parameter\nservice. This enables asynchronous and fine-grained weight synchronization,\nallowing rollouts to pull the latest weight anytime without stalling the\nactor's training loop. Second, a dynamic repack mechanism consolidates\nlong-tail trajectories onto a few dedicated rollouts, maximizing generation\nthroughput. The fully decoupled design also isolates failures, ensuring\nrobustness for long-running jobs. Our evaluation on a 1024-GPU cluster shows\nthat Laminar achieves up to 5.48$\\times$ training throughput speedup over\nstate-of-the-art systems, while reducing model convergence time.",
      "pdf_url": "http://arxiv.org/pdf/2510.12633v1",
      "published": "2025-10-14T15:29:14+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.12633v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ]
    },
    {
      "title": "Designing Tools with Control Confidence",
      "authors": [
        "Ajith Anil Meera",
        "Abian Torres",
        "Pablo Lanillos"
      ],
      "abstract": "Prehistoric humans invented stone tools for specialized tasks by not just\nmaximizing the tool's immediate goal-completion accuracy, but also increasing\ntheir confidence in the tool for later use under similar settings. This factor\ncontributed to the increased robustness of the tool, i.e., the least\nperformance deviations under environmental uncertainties. However, the current\nautonomous tool design frameworks solely rely on performance optimization,\nwithout considering the agent's confidence in tool use for repeated use. Here,\nwe take a step towards filling this gap by i) defining an optimization\nframework for task-conditioned autonomous hand tool design for robots, where\nii) we introduce a neuro-inspired control confidence term into the optimization\nroutine that helps the agent to design tools with higher robustness. Through\nrigorous simulations using a robotic arm, we show that tools designed with\ncontrol confidence as the objective function are more robust to environmental\nuncertainties during tool use than a pure accuracy-driven objective. We further\nshow that adding control confidence to the objective function for tool design\nprovides a balance between the robustness and goal accuracy of the designed\ntools under control perturbations. Finally, we show that our CMAES-based\nevolutionary optimization strategy for autonomous tool design outperforms other\nstate-of-the-art optimizers by designing the optimal tool within the fewest\niterations. Code: https://github.com/ajitham123/Tool_design_control_confidence.",
      "pdf_url": "http://arxiv.org/pdf/2510.12630v1",
      "published": "2025-10-14T15:27:27+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.12630v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "Learning-To-Measure: In-context Active Feature Acquisition",
      "authors": [
        "Yuta Kobayashi",
        "Zilin Jing",
        "Jiayu Yao",
        "Hongseok Namkoong",
        "Shalmali Joshi"
      ],
      "abstract": "Active feature acquisition (AFA) is a sequential decision-making problem\nwhere the goal is to improve model performance for test instances by adaptively\nselecting which features to acquire. In practice, AFA methods often learn from\nretrospective data with systematic missingness in the features and limited\ntask-specific labels. Most prior work addresses acquisition for a single\npredetermined task, limiting scalability. To address this limitation, we\nformalize the meta-AFA problem, where the goal is to learn acquisition policies\nacross various tasks. We introduce Learning-to-Measure (L2M), which consists of\ni) reliable uncertainty quantification over unseen tasks, and ii) an\nuncertainty-guided greedy feature acquisition agent that maximizes conditional\nmutual information. We demonstrate a sequence-modeling or autoregressive\npre-training approach that underpins reliable uncertainty quantification for\ntasks with arbitrary missingness. L2M operates directly on datasets with\nretrospective missingness and performs the meta-AFA task in-context,\neliminating per-task retraining. Across synthetic and real-world tabular\nbenchmarks, L2M matches or surpasses task-specific baselines, particularly\nunder scarce labels and high missingness.",
      "pdf_url": "http://arxiv.org/pdf/2510.12624v1",
      "published": "2025-10-14T15:23:32+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.12624v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Rethinking Knowledge Distillation: A Data Dependent Regulariser With a Negative Asymmetric Payoff",
      "authors": [
        "Israel Mason-Williams",
        "Gabryel Mason-Williams",
        "Helen Yannakoudakis"
      ],
      "abstract": "Knowledge distillation is often considered a compression mechanism when\njudged on the resulting student's accuracy and loss, yet its functional impact\nis poorly understood. In this work, we quantify the compression capacity of\nknowledge distillation and the resulting knowledge transfer from a functional\nperspective, decoupling compression from architectural reduction, which\nprovides an improved understanding of knowledge distillation. We employ\nhypothesis testing, controls, and random control distillation to understand\nknowledge transfer mechanisms across data modalities. To rigorously test the\nbreadth and limits of our analyses, we explore multiple distillation variants\nand analyse distillation scaling laws across model sizes. Our findings\ndemonstrate that, while there is statistically significant knowledge transfer\nin some modalities and architectures, the extent of this transfer is less\npronounced than anticipated, even under conditions designed to maximise\nknowledge sharing. Notably, in cases of significant knowledge transfer, we\nidentify a consistent and severe asymmetric transfer of negative knowledge to\nthe student, raising safety concerns in knowledge distillation applications.\nAcross 12 experimental setups, 9 architectures, and 7 datasets, our findings\nshow that knowledge distillation functions less as a compression mechanism and\nmore as a data-dependent regulariser with a negative asymmetric payoff.",
      "pdf_url": "http://arxiv.org/pdf/2510.12615v1",
      "published": "2025-10-14T15:14:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.12615v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "StyleDecipher: Robust and Explainable Detection of LLM-Generated Texts with Stylistic Analysis",
      "authors": [
        "Siyuan Li",
        "Aodu Wulianghai",
        "Xi Lin",
        "Guangyan Li",
        "Xiang Chen",
        "Jun Wu",
        "Jianhua Li"
      ],
      "abstract": "With the increasing integration of large language models (LLMs) into\nopen-domain writing, detecting machine-generated text has become a critical\ntask for ensuring content authenticity and trust. Existing approaches rely on\nstatistical discrepancies or model-specific heuristics to distinguish between\nLLM-generated and human-written text. However, these methods struggle in\nreal-world scenarios due to limited generalization, vulnerability to\nparaphrasing, and lack of explainability, particularly when facing stylistic\ndiversity or hybrid human-AI authorship. In this work, we propose\nStyleDecipher, a robust and explainable detection framework that revisits\nLLM-generated text detection using combined feature extractors to quantify\nstylistic differences. By jointly modeling discrete stylistic indicators and\ncontinuous stylistic representations derived from semantic embeddings,\nStyleDecipher captures distinctive style-level divergences between human and\nLLM outputs within a unified representation space. This framework enables\naccurate, explainable, and domain-agnostic detection without requiring access\nto model internals or labeled segments. Extensive experiments across five\ndiverse domains, including news, code, essays, reviews, and academic abstracts,\ndemonstrate that StyleDecipher consistently achieves state-of-the-art in-domain\naccuracy. Moreover, in cross-domain evaluations, it surpasses existing\nbaselines by up to 36.30%, while maintaining robustness against adversarial\nperturbations and mixed human-AI content. Further qualitative and quantitative\nanalysis confirms that stylistic signals provide explainable evidence for\ndistinguishing machine-generated text. Our source code can be accessed at\nhttps://github.com/SiyuanLi00/StyleDecipher.",
      "pdf_url": "http://arxiv.org/pdf/2510.12608v1",
      "published": "2025-10-14T15:07:27+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.12608v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "SMILE: SeMantic Ids Enhanced CoLd Item Representation for Click-through Rate Prediction in E-commerce SEarch",
      "authors": [
        "Qihang Zhao",
        "Zhongbo Sun",
        "Xiaoyang Zheng",
        "Xian Guo",
        "Siyuan Wang",
        "Zihan Liang",
        "Mingcan Peng",
        "Ben Chen",
        "Chenyi Lei"
      ],
      "abstract": "With the rise of modern search and recommendation platforms, insufficient\ncollaborative information of cold-start items exacerbates the Matthew effect of\nexisting platform items, challenging platform diversity and becoming a\nlongstanding issue. Existing methods align items' side content with\ncollaborative information to transfer collaborative signals from\nhigh-popularity items to cold-start items. However, these methods fail to\naccount for the asymmetry between collaboration and content, nor the\nfine-grained differences among items. To address these issues, we propose\nSMILE, an item representation enhancement approach based on fused alignment of\nsemantic IDs. Specifically, we use RQ-OPQ encoding to quantize item content and\ncollaborative information, followed by a two-step alignment: RQ encoding\ntransfers shared collaborative signals across items, while OPQ encoding learns\ndifferentiated information of items. Comprehensive offline experiments on\nlarge-scale industrial datasets demonstrate superiority of SMILE, and rigorous\nonline A/B tests confirm statistically significant improvements: item CTR\n+1.66%, buyers +1.57%, and order volume +2.17%.",
      "pdf_url": "http://arxiv.org/pdf/2510.12604v1",
      "published": "2025-10-14T14:58:50+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.12604v1",
      "categories": [
        "cs.IR",
        "cs.AI"
      ]
    },
    {
      "title": "Reasoning in the Dark: Interleaved Vision-Text Reasoning in Latent Space",
      "authors": [
        "Chao Chen",
        "Zhixin Ma",
        "Yongqi Li",
        "Yupeng Hu",
        "Yinwei Wei",
        "Wenjie Li",
        "Liqiang Nie"
      ],
      "abstract": "Multimodal reasoning aims to enhance the capabilities of MLLMs by\nincorporating intermediate reasoning steps before reaching the final answer. It\nhas evolved from text-only reasoning to the integration of visual information,\nenabling the thought process to be conveyed through both images and text.\nDespite its effectiveness, current multimodal reasoning methods depend on\nexplicit reasoning steps that require labor-intensive vision-text annotations\nand inherently introduce significant inference latency. To address these\nissues, we introduce multimodal latent reasoning with the advantages of\nmultimodal representation, reduced annotation, and inference efficiency. To\nfacilicate it, we propose Interleaved Vision-Text Latent Reasoning (IVT-LR),\nwhich injects both visual and textual information in the reasoning process\nwithin the latent space. Specifically, IVT-LR represents each reasoning step by\ncombining two implicit parts: latent text (the hidden states from the previous\nstep) and latent vision (a set of selected image embeddings). We further\nintroduce a progressive multi-stage training strategy to enable MLLMs to\nperform the above multimodal latent reasoning steps. Experiments on M3CoT and\nScienceQA demonstrate that our IVT-LR method achieves an average performance\nincrease of 5.45% in accuracy, while simultaneously achieving a speed increase\nof over 5 times compared to existing approaches. Code available at\nhttps://github.com/FYYDCC/IVT-LR.",
      "pdf_url": "http://arxiv.org/pdf/2510.12603v1",
      "published": "2025-10-14T14:58:25+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.12603v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "HardcoreLogic: Challenging Large Reasoning Models with Long-tail Logic Puzzle Games",
      "authors": [
        "Jingcong Liang",
        "Shijun Wan",
        "Xuehai Wu",
        "Yitong Li",
        "Qianglong Chen",
        "Duyu Tang",
        "Siyuan Wang",
        "Zhongyu Wei"
      ],
      "abstract": "Large Reasoning Models (LRMs) have demonstrated impressive performance on\ncomplex tasks, including logical puzzle games that require deriving solutions\nsatisfying all constraints. However, whether they can flexibly apply\nappropriate rules to varying conditions, particularly when faced with\nnon-canonical game variants, remains an open question. Existing corpora focus\non popular puzzles like 9x9 Sudoku, risking overfitting to canonical formats\nand memorization of solution patterns, which can mask deficiencies in\nunderstanding novel rules or adapting strategies to new variants. To address\nthis, we introduce HardcoreLogic, a challenging benchmark of over 5,000 puzzles\nacross 10 games, designed to test the robustness of LRMs on the \"long-tail\" of\nlogical games. HardcoreLogic systematically transforms canonical puzzles\nthrough three dimensions: Increased Complexity (IC), Uncommon Elements (UE),\nand Unsolvable Puzzles (UP), reducing reliance on shortcut memorization.\nEvaluations on a diverse set of LRMs reveal significant performance drops, even\nfor models achieving top scores on existing benchmarks, indicating heavy\nreliance on memorized stereotypes. While increased complexity is the dominant\nsource of difficulty, models also struggle with subtle rule variations that do\nnot necessarily increase puzzle difficulty. Our systematic error analysis on\nsolvable and unsolvable puzzles further highlights gaps in genuine reasoning.\nOverall, HardcoreLogic exposes the limitations of current LRMs and establishes\na benchmark for advancing high-level logical reasoning.",
      "pdf_url": "http://arxiv.org/pdf/2510.12563v2",
      "published": "2025-10-14T14:23:24+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.12563v2",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Inclusive Fitness as a Key Step Towards More Advanced Social Behaviors in Multi-Agent Reinforcement Learning Settings",
      "authors": [
        "Andries Rosseau",
        "Raphaël Avalos",
        "Ann Nowé"
      ],
      "abstract": "The competitive and cooperative forces of natural selection have driven the\nevolution of intelligence for millions of years, culminating in nature's vast\nbiodiversity and the complexity of human minds. Inspired by this process, we\npropose a novel multi-agent reinforcement learning framework where each agent\nis assigned a genotype and where reward functions are modelled after the\nconcept of inclusive fitness. An agent's genetic material may be shared with\nother agents, and our inclusive reward function naturally accounts for this. We\nstudy the resulting social dynamics in two types of network games with\nprisoner's dilemmas and find that our results align with well-established\nprinciples from biology, such as Hamilton's rule. Furthermore, we outline how\nthis framework can extend to more open-ended environments with spatial and\ntemporal structure, finite resources, and evolving populations. We hypothesize\nthe emergence of an arms race of strategies, where each new strategy is a\ngradual improvement over earlier adaptations of other agents, effectively\nproducing a multi-agent autocurriculum analogous to biological evolution. In\ncontrast to the binary team-based structures prevalent in earlier research, our\ngene-based reward structure introduces a spectrum of cooperation ranging from\nfull adversity to full cooperativeness based on genetic similarity, enabling\nunique non team-based social dynamics. For example, one agent having a mutual\ncooperative relationship with two other agents, while the two other agents\nbehave adversarially towards each other. We argue that incorporating inclusive\nfitness in agents provides a foundation for the emergence of more strategically\nadvanced and socially intelligent agents.",
      "pdf_url": "http://arxiv.org/pdf/2510.12555v1",
      "published": "2025-10-14T14:20:01+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.12555v1",
      "categories": [
        "cs.AI",
        "cs.MA",
        "cs.SI"
      ]
    },
    {
      "title": "Evaluation of Real-Time Preprocessing Methods in AI-Based ECG Signal Analysis",
      "authors": [
        "Jasmin Freudenberg",
        "Kai Hahn",
        "Christian Weber",
        "Madjid Fathi"
      ],
      "abstract": "The increasing popularity of portable ECG systems and the growing demand for\nprivacy-compliant, energy-efficient real-time analysis require new approaches\nto signal processing at the point of data acquisition. In this context, the\nedge domain is acquiring increasing importance, as it not only reduces latency\ntimes, but also enables an increased level of data security. The FACE project\naims to develop an innovative machine learning solution for analysing long-term\nelectrocardiograms that synergistically combines the strengths of edge and\ncloud computing. In this thesis, various pre-processing steps of ECG signals\nare analysed with regard to their applicability in the project. The selection\nof suitable methods in the edge area is based in particular on criteria such as\nenergy efficiency, processing capability and real-time capability.",
      "pdf_url": "http://arxiv.org/pdf/2510.12541v1",
      "published": "2025-10-14T14:04:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.12541v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Unconditional Human Motion and Shape Generation via Balanced Score-Based Diffusion",
      "authors": [
        "David Björkstrand",
        "Tiesheng Wang",
        "Lars Bretzner",
        "Josephine Sullivan"
      ],
      "abstract": "Recent work has explored a range of model families for human motion\ngeneration, including Variational Autoencoders (VAEs), Generative Adversarial\nNetworks (GANs), and diffusion-based models. Despite their differences, many\nmethods rely on over-parameterized input features and auxiliary losses to\nimprove empirical results. These strategies should not be strictly necessary\nfor diffusion models to match the human motion distribution. We show that on\npar with state-of-the-art results in unconditional human motion generation are\nachievable with a score-based diffusion model using only careful feature-space\nnormalization and analytically derived weightings for the standard L2\nscore-matching loss, while generating both motion and shape directly, thereby\navoiding slow post hoc shape recovery from joints. We build the method step by\nstep, with a clear theoretical motivation for each component, and provide\ntargeted ablations demonstrating the effectiveness of each proposed addition in\nisolation.",
      "pdf_url": "http://arxiv.org/pdf/2510.12537v1",
      "published": "2025-10-14T14:02:22+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.12537v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "ProtoSiTex: Learning Semi-Interpretable Prototypes for Multi-label Text Classification",
      "authors": [
        "Utsav Kumar Nareti",
        "Suraj Kumar",
        "Soumya Pandey",
        "Soumi Chattopadhyay",
        "Chandranath Adak"
      ],
      "abstract": "The surge in user-generated reviews has amplified the need for interpretable\nmodels that can provide fine-grained insights. Existing prototype-based models\noffer intuitive explanations but typically operate at coarse granularity\n(sentence or document level) and fail to address the multi-label nature of\nreal-world text classification. We propose ProtoSiTex, a semi-interpretable\nframework designed for fine-grained multi-label text classification. ProtoSiTex\nemploys a dual-phase alternating training strategy: an unsupervised prototype\ndiscovery phase that learns semantically coherent and diverse prototypes, and a\nsupervised classification phase that maps these prototypes to class labels. A\nhierarchical loss function enforces consistency across sub-sentence, sentence,\nand document levels, enhancing interpretability and alignment. Unlike prior\napproaches, ProtoSiTex captures overlapping and conflicting semantics using\nadaptive prototypes and multi-head attention. We also introduce a benchmark\ndataset of hotel reviews annotated at the sub-sentence level with multiple\nlabels. Experiments on this dataset and two public benchmarks (binary and\nmulti-class) show that ProtoSiTex achieves state-of-the-art performance while\ndelivering faithful, human-aligned explanations, establishing it as a robust\nsolution for semi-interpretable multi-label text classification.",
      "pdf_url": "http://arxiv.org/pdf/2510.12534v1",
      "published": "2025-10-14T13:59:28+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.12534v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "BoN Appetit Team at LeWiDi-2025: Best-of-N Test-time Scaling Can Not Stomach Annotation Disagreements (Yet)",
      "authors": [
        "Tomas Ruiz",
        "Siyao Peng",
        "Barbara Plank",
        "Carsten Schwemmer"
      ],
      "abstract": "Test-time scaling is a family of techniques to improve LLM outputs at\ninference time by performing extra computation. To the best of our knowledge,\ntest-time scaling has been limited to domains with verifiably correct answers,\nlike mathematics and coding. We transfer test-time scaling to the LeWiDi-2025\ntasks to evaluate annotation disagreements. We experiment with three test-time\nscaling methods: two benchmark algorithms (Model Averaging and Majority\nVoting), and a Best-of-N sampling method. The two benchmark methods improve LLM\nperformance consistently on the LeWiDi tasks, but the Best-of-N method does\nnot. Our experiments suggest that the Best-of-N method does not currently\ntransfer from mathematics to LeWiDi tasks, and we analyze potential reasons for\nthis gap.",
      "pdf_url": "http://arxiv.org/pdf/2510.12516v1",
      "published": "2025-10-14T13:43:08+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.12516v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "The Robustness of Differentiable Causal Discovery in Misspecified Scenarios",
      "authors": [
        "Huiyang Yi",
        "Yanyan He",
        "Duxin Chen",
        "Mingyu Kang",
        "He Wang",
        "Wenwu Yu"
      ],
      "abstract": "Causal discovery aims to learn causal relationships between variables from\ntargeted data, making it a fundamental task in machine learning. However,\ncausal discovery algorithms often rely on unverifiable causal assumptions,\nwhich are usually difficult to satisfy in real-world data, thereby limiting the\nbroad application of causal discovery in practical scenarios. Inspired by these\nconsiderations, this work extensively benchmarks the empirical performance of\nvarious mainstream causal discovery algorithms, which assume i.i.d. data, under\neight model assumption violations. Our experimental results show that\ndifferentiable causal discovery methods exhibit robustness under the metrics of\nStructural Hamming Distance and Structural Intervention Distance of the\ninferred graphs in commonly used challenging scenarios, except for scale\nvariation. We also provide the theoretical explanations for the performance of\ndifferentiable causal discovery methods. Finally, our work aims to\ncomprehensively benchmark the performance of recent differentiable causal\ndiscovery methods under model assumption violations, and provide the standard\nfor reasonable evaluation of causal discovery, as well as to further promote\nits application in real-world scenarios.",
      "pdf_url": "http://arxiv.org/pdf/2510.12503v1",
      "published": "2025-10-14T13:33:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.12503v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME",
        "stat.ML"
      ]
    },
    {
      "title": "Artificial Intelligence Virtual Cells: From Measurements to Decisions across Modality, Scale, Dynamics, and Evaluation",
      "authors": [
        "Chengpeng Hu",
        "Calvin Yu-Chian Chen"
      ],
      "abstract": "Artificial Intelligence Virtual Cells (AIVCs) aim to learn executable,\ndecision-relevant models of cell state from multimodal, multiscale\nmeasurements. Recent studies have introduced single-cell and spatial foundation\nmodels, improved cross-modality alignment, scaled perturbation atlases, and\nexplored pathway-level readouts. Nevertheless, although held-out validation is\nstandard practice, evaluations remain predominantly within single datasets and\nsettings; evidence indicates that transport across laboratories and platforms\nis often limited, that some data splits are vulnerable to leakage and coverage\nbias, and that dose, time and combination effects are not yet systematically\nhandled. Cross-scale coupling also remains constrained, as anchors linking\nmolecular, cellular and tissue levels are sparse, and alignment to scientific\nor clinical readouts varies across studies. We propose a model-agnostic\nCell-State Latent (CSL) perspective that organizes learning via an operator\ngrammar: measurement, lift/project for cross-scale coupling, and intervention\nfor dosing and scheduling. This view motivates a decision-aligned evaluation\nblueprint across modality, scale, context and intervention, and emphasizes\nfunction-space readouts such as pathway activity, spatial neighborhoods and\nclinically relevant endpoints. We recommend operator-aware data design,\nleakage-resistant partitions, and transparent calibration and reporting to\nenable reproducible, like-for-like comparisons.",
      "pdf_url": "http://arxiv.org/pdf/2510.12498v1",
      "published": "2025-10-14T13:31:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.12498v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "PubSub-VFL: Towards Efficient Two-Party Split Learning in Heterogeneous Environments via Publisher/Subscriber Architecture",
      "authors": [
        "Yi Liu",
        "Yang Liu",
        "Leqian Zheng",
        "Jue Hong",
        "Junjie Shi",
        "Qingyou Yang",
        "Ye Wu",
        "Cong Wang"
      ],
      "abstract": "With the rapid advancement of the digital economy, data collaboration between\norganizations has become a well-established business model, driving the growth\nof various industries. However, privacy concerns make direct data sharing\nimpractical. To address this, Two-Party Split Learning (a.k.a. Vertical\nFederated Learning (VFL)) has emerged as a promising solution for secure\ncollaborative learning. Despite its advantages, this architecture still suffers\nfrom low computational resource utilization and training efficiency.\nSpecifically, its synchronous dependency design increases training latency,\nwhile resource and data heterogeneity among participants further hinder\nefficient computation. To overcome these challenges, we propose PubSub-VFL, a\nnovel VFL paradigm with a Publisher/Subscriber architecture optimized for\ntwo-party collaborative learning with high computational efficiency. PubSub-VFL\nleverages the decoupling capabilities of the Pub/Sub architecture and the data\nparallelism of the parameter server architecture to design a hierarchical\nasynchronous mechanism, reducing training latency and improving system\nefficiency. Additionally, to mitigate the training imbalance caused by resource\nand data heterogeneity, we formalize an optimization problem based on\nparticipants' system profiles, enabling the selection of optimal\nhyperparameters while preserving privacy. We conduct a theoretical analysis to\ndemonstrate that PubSub-VFL achieves stable convergence and is compatible with\nsecurity protocols such as differential privacy. Extensive case studies on five\nbenchmark datasets further validate its effectiveness, showing that, compared\nto state-of-the-art baselines, PubSub-VFL not only accelerates training by $2\n\\sim 7\\times$ without compromising accuracy, but also achieves a computational\nresource utilization rate of up to 91.07%.",
      "pdf_url": "http://arxiv.org/pdf/2510.12494v1",
      "published": "2025-10-14T13:27:33+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.12494v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ]
    },
    {
      "title": "Using Medical Algorithms for Task-Oriented Dialogue in LLM-Based Medical Interviews",
      "authors": [
        "Rui Reis",
        "Pedro Rangel Henriques",
        "João Ferreira-Coimbra",
        "Eva Oliveira",
        "Nuno F. Rodrigues"
      ],
      "abstract": "We developed a task-oriented dialogue framework structured as a Directed\nAcyclic Graph (DAG) of medical questions. The system integrates: (1) a\nsystematic pipeline for transforming medical algorithms and guidelines into a\nclinical question corpus; (2) a cold-start mechanism based on hierarchical\nclustering to generate efficient initial questioning without prior patient\ninformation; (3) an expand-and-prune mechanism enabling adaptive branching and\nbacktracking based on patient responses; (4) a termination logic to ensure\ninterviews end once sufficient information is gathered; and (5) automated\nsynthesis of doctor-friendly structured reports aligned with clinical\nworkflows. Human-computer interaction principles guided the design of both the\npatient and physician applications. Preliminary evaluation involved five\nphysicians using standardized instruments: NASA-TLX (cognitive workload), the\nSystem Usability Scale (SUS), and the Questionnaire for User Interface\nSatisfaction (QUIS). The patient application achieved low workload scores\n(NASA-TLX = 15.6), high usability (SUS = 86), and strong satisfaction (QUIS =\n8.1/9), with particularly high ratings for ease of learning and interface\ndesign. The physician application yielded moderate workload (NASA-TLX = 26) and\nexcellent usability (SUS = 88.5), with satisfaction scores of 8.3/9. Both\napplications demonstrated effective integration into clinical workflows,\nreducing cognitive demand and supporting efficient report generation.\nLimitations included occasional system latency and a small, non-diverse\nevaluation sample.",
      "pdf_url": "http://arxiv.org/pdf/2510.12490v1",
      "published": "2025-10-14T13:24:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.12490v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "A Text-Image Fusion Method with Data Augmentation Capabilities for Referring Medical Image Segmentation",
      "authors": [
        "Shurong Chai",
        "Rahul Kumar JAIN",
        "Rui Xu",
        "Shaocong Mo",
        "Ruibo Hou",
        "Shiyu Teng",
        "Jiaqing Liu",
        "Lanfen Lin",
        "Yen-Wei Chen"
      ],
      "abstract": "Deep learning relies heavily on data augmentation to mitigate limited data,\nespecially in medical imaging. Recent multimodal learning integrates text and\nimages for segmentation, known as referring or text-guided image segmentation.\nHowever, common augmentations like rotation and flipping disrupt spatial\nalignment between image and text, weakening performance. To address this, we\npropose an early fusion framework that combines text and visual features before\naugmentation, preserving spatial consistency. We also design a lightweight\ngenerator that projects text embeddings into visual space, bridging semantic\ngaps. Visualization of generated pseudo-images shows accurate region\nlocalization. Our method is evaluated on three medical imaging tasks and four\nsegmentation frameworks, achieving state-of-the-art results. Code is publicly\navailable on GitHub: https://github.com/11yxk/MedSeg_EarlyFusion.",
      "pdf_url": "http://arxiv.org/pdf/2510.12482v1",
      "published": "2025-10-14T13:18:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.12482v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    }
  ]
}