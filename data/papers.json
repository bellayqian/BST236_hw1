{
  "last_updated": "2025-03-04T00:45:51.838262",
  "papers": [
    {
      "title": "FANformer: Improving Large Language Models Through Effective Periodicity Modeling",
      "authors": [
        "Yihong Dong",
        "Ge Li",
        "Xue Jiang",
        "Yongding Tao",
        "Kechi Zhang",
        "Hao Zhu",
        "Huanyu Liu",
        "Jiazheng Ding",
        "Jia Li",
        "Jinliang Deng",
        "Hong Mei"
      ],
      "abstract": "Periodicity, as one of the most important basic characteristics, lays the\nfoundation for facilitating structured knowledge acquisition and systematic\ncognitive processes within human learning paradigms. However, the potential\nflaws of periodicity modeling in Transformer affect the learning efficiency and\nestablishment of underlying principles from data for large language models\n(LLMs) built upon it. In this paper, we demonstrate that integrating effective\nperiodicity modeling can improve the learning efficiency and performance of\nLLMs. We introduce FANformer, which integrates Fourier Analysis Network (FAN)\ninto attention mechanism to achieve efficient periodicity modeling, by\nmodifying the feature projection process of attention mechanism. Extensive\nexperimental results on language modeling show that FANformer consistently\noutperforms Transformer when scaling up model size and training tokens,\nunderscoring its superior learning efficiency. To further validate the\neffectiveness of FANformer, we pretrain a FANformer-1B on 1 trillion tokens.\nFANformer-1B exhibits marked improvements on downstream tasks compared to\nopen-source LLMs with similar model parameters or training tokens. The results\nposition FANformer as an effective and promising architecture for advancing\nLLMs.",
      "pdf_url": "http://arxiv.org/pdf/2502.21309v1",
      "published": "2025-02-28T18:52:24+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.21309v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Clustering Context in Off-Policy Evaluation",
      "authors": [
        "Daniel Guzman-Olivares",
        "Philipp Schmidt",
        "Jacek Golebiowski",
        "Artur Bekasov"
      ],
      "abstract": "Off-policy evaluation can leverage logged data to estimate the effectiveness\nof new policies in e-commerce, search engines, media streaming services, or\nautomatic diagnostic tools in healthcare. However, the performance of baseline\noff-policy estimators like IPS deteriorates when the logging policy\nsignificantly differs from the evaluation policy. Recent work proposes sharing\ninformation across similar actions to mitigate this problem. In this work, we\npropose an alternative estimator that shares information across similar\ncontexts using clustering. We study the theoretical properties of the proposed\nestimator, characterizing its bias and variance under different conditions. We\nalso compare the performance of the proposed estimator and existing approaches\nin various synthetic problems, as well as a real-world recommendation dataset.\nOur experimental results confirm that clustering contexts improves estimation\naccuracy, especially in deficient information settings.",
      "pdf_url": "http://arxiv.org/pdf/2502.21304v1",
      "published": "2025-02-28T18:40:41+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.21304v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ]
    },
    {
      "title": "Contextualizing biological perturbation experiments through language",
      "authors": [
        "Menghua Wu",
        "Russell Littman",
        "Jacob Levine",
        "Lin Qiu",
        "Tommaso Biancalani",
        "David Richmond",
        "Jan-Christian Huetter"
      ],
      "abstract": "High-content perturbation experiments allow scientists to probe biomolecular\nsystems at unprecedented resolution, but experimental and analysis costs pose\nsignificant barriers to widespread adoption. Machine learning has the potential\nto guide efficient exploration of the perturbation space and extract novel\ninsights from these data. However, current approaches neglect the semantic\nrichness of the relevant biology, and their objectives are misaligned with\ndownstream biological analyses. In this paper, we hypothesize that large\nlanguage models (LLMs) present a natural medium for representing complex\nbiological relationships and rationalizing experimental outcomes. We propose\nPerturbQA, a benchmark for structured reasoning over perturbation experiments.\nUnlike current benchmarks that primarily interrogate existing knowledge,\nPerturbQA is inspired by open problems in perturbation modeling: prediction of\ndifferential expression and change of direction for unseen perturbations, and\ngene set enrichment. We evaluate state-of-the-art machine learning and\nstatistical approaches for modeling perturbations, as well as standard LLM\nreasoning strategies, and we find that current methods perform poorly on\nPerturbQA. As a proof of feasibility, we introduce Summer (SUMMarize, retrievE,\nand answeR, a simple, domain-informed LLM framework that matches or exceeds the\ncurrent state-of-the-art. Our code and data are publicly available at\nhttps://github.com/genentech/PerturbQA.",
      "pdf_url": "http://arxiv.org/pdf/2502.21290v1",
      "published": "2025-02-28T18:15:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.21290v1",
      "categories": [
        "cs.AI",
        "cs.LG",
        "q-bio.QM"
      ]
    },
    {
      "title": "L-Lipschitz Gershgorin ResNet Network",
      "authors": [
        "Marius F. R. Juston",
        "William R. Norris",
        "Dustin Nottage",
        "Ahmet Soylemezoglu"
      ],
      "abstract": "Deep residual networks (ResNets) have demonstrated outstanding success in\ncomputer vision tasks, attributed to their ability to maintain gradient flow\nthrough deep architectures. Simultaneously, controlling the Lipschitz bound in\nneural networks has emerged as an essential area of research for enhancing\nadversarial robustness and network certifiability. This paper uses a rigorous\napproach to design $\\mathcal{L}$-Lipschitz deep residual networks using a\nLinear Matrix Inequality (LMI) framework. The ResNet architecture was\nreformulated as a pseudo-tri-diagonal LMI with off-diagonal elements and\nderived closed-form constraints on network parameters to ensure\n$\\mathcal{L}$-Lipschitz continuity. To address the lack of explicit eigenvalue\ncomputations for such matrix structures, the Gershgorin circle theorem was\nemployed to approximate eigenvalue locations, guaranteeing the LMI's negative\nsemi-definiteness. Our contributions include a provable parameterization\nmethodology for constructing Lipschitz-constrained networks and a compositional\nframework for managing recursive systems within hierarchical architectures.\nThese findings enable robust network designs applicable to adversarial\nrobustness, certified training, and control systems. However, a limitation was\nidentified in the Gershgorin-based approximations, which over-constrain the\nsystem, suppressing non-linear dynamics and diminishing the network's\nexpressive capacity.",
      "pdf_url": "http://arxiv.org/pdf/2502.21279v1",
      "published": "2025-02-28T17:57:57+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.21279v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "BAnG: Bidirectional Anchored Generation for Conditional RNA Design",
      "authors": [
        "Roman Klypa",
        "Alberto Bietti",
        "Sergei Grudinin"
      ],
      "abstract": "Designing RNA molecules that interact with specific proteins is a critical\nchallenge in experimental and computational biology. Existing computational\napproaches require a substantial amount of experimentally determined RNA\nsequences for each specific protein or a detailed knowledge of RNA structure,\nrestricting their utility in practice. To address this limitation, we develop\nRNA-BAnG, a deep learning-based model designed to generate RNA sequences for\nprotein interactions without these requirements. Central to our approach is a\nnovel generative method, Bidirectional Anchored Generation (BAnG), which\nleverages the observation that protein-binding RNA sequences often contain\nfunctional binding motifs embedded within broader sequence contexts. We first\nvalidate our method on generic synthetic tasks involving similar localized\nmotifs to those appearing in RNAs, demonstrating its benefits over existing\ngenerative approaches. We then evaluate our model on biological sequences,\nshowing its effectiveness for conditional RNA sequence design given a binding\nprotein.",
      "pdf_url": "http://arxiv.org/pdf/2502.21274v1",
      "published": "2025-02-28T17:51:00+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.21274v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.BM"
      ]
    },
    {
      "title": "Adaptive Keyframe Sampling for Long Video Understanding",
      "authors": [
        "Xi Tang",
        "Jihao Qiu",
        "Lingxi Xie",
        "Yunjie Tian",
        "Jianbin Jiao",
        "Qixiang Ye"
      ],
      "abstract": "Multimodal large language models (MLLMs) have enabled open-world visual\nunderstanding by injecting visual input as extra tokens into large language\nmodels (LLMs) as contexts. However, when the visual input changes from a single\nimage to a long video, the above paradigm encounters difficulty because the\nvast amount of video tokens has significantly exceeded the maximal capacity of\nMLLMs. Therefore, existing video-based MLLMs are mostly established upon\nsampling a small portion of tokens from input data, which can cause key\ninformation to be lost and thus produce incorrect answers. This paper presents\na simple yet effective algorithm named Adaptive Keyframe Sampling (AKS). It\ninserts a plug-and-play module known as keyframe selection, which aims to\nmaximize the useful information with a fixed number of video tokens. We\nformulate keyframe selection as an optimization involving (1) the relevance\nbetween the keyframes and the prompt, and (2) the coverage of the keyframes\nover the video, and present an adaptive algorithm to approximate the best\nsolution. Experiments on two long video understanding benchmarks validate that\nAdaptive Keyframe Sampling improves video QA accuracy (beyond strong baselines)\nupon selecting informative keyframes. Our study reveals the importance of\ninformation pre-filtering in video-based MLLMs. Code is available at\nhttps://github.com/ncTimTang/AKS.",
      "pdf_url": "http://arxiv.org/pdf/2502.21271v1",
      "published": "2025-02-28T17:46:29+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.21271v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Supporting the development of Machine Learning for fundamental science in a federated Cloud with the AI_INFN platform",
      "authors": [
        "Lucio Anderlini",
        "Matteo Barbetti",
        "Giulio Bianchini",
        "Diego Ciangottini",
        "Stefano Dal Pra",
        "Diego Michelotto",
        "Carmelo Pellegrino",
        "Rosa Petrini",
        "Alessandro Pascolini",
        "Daniele Spiga"
      ],
      "abstract": "Machine Learning (ML) is driving a revolution in the way scientists design,\ndevelop, and deploy data-intensive software. However, the adoption of ML\npresents new challenges for the computing infrastructure, particularly in terms\nof provisioning and orchestrating access to hardware accelerators for\ndevelopment, testing, and production. The INFN-funded project AI_INFN\n(\"Artificial Intelligence at INFN\") aims at fostering the adoption of ML\ntechniques within INFN use cases by providing support on multiple aspects,\nincluding the provision of AI-tailored computing resources. It leverages\ncloud-native solutions in the context of INFN Cloud, to share hardware\naccelerators as effectively as possible, ensuring the diversity of the\nInstitute's research activities is not compromised. In this contribution, we\nprovide an update on the commissioning of a Kubernetes platform designed to\nease the development of GPU-powered data analysis workflows and their\nscalability on heterogeneous, distributed computing resources, possibly\nfederated as Virtual Kubelets with the interLink provider.",
      "pdf_url": "http://arxiv.org/pdf/2502.21266v1",
      "published": "2025-02-28T17:42:58+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.21266v1",
      "categories": [
        "cs.DC",
        "cs.AI",
        "physics.data-an"
      ]
    },
    {
      "title": "ReaLJam: Real-Time Human-AI Music Jamming with Reinforcement Learning-Tuned Transformers",
      "authors": [
        "Alexander Scarlatos",
        "Yusong Wu",
        "Ian Simon",
        "Adam Roberts",
        "Tim Cooijmans",
        "Natasha Jaques",
        "Cassie Tarakajian",
        "Cheng-Zhi Anna Huang"
      ],
      "abstract": "Recent advances in generative artificial intelligence (AI) have created\nmodels capable of high-quality musical content generation. However, little\nconsideration is given to how to use these models for real-time or cooperative\njamming musical applications because of crucial required features: low latency,\nthe ability to communicate planned actions, and the ability to adapt to user\ninput in real-time. To support these needs, we introduce ReaLJam, an interface\nand protocol for live musical jamming sessions between a human and a\nTransformer-based AI agent trained with reinforcement learning. We enable\nreal-time interactions using the concept of anticipation, where the agent\ncontinually predicts how the performance will unfold and visually conveys its\nplan to the user. We conduct a user study where experienced musicians jam in\nreal-time with the agent through ReaLJam. Our results demonstrate that ReaLJam\nenables enjoyable and musically interesting sessions, and we uncover important\ntakeaways for future work.",
      "pdf_url": "http://arxiv.org/pdf/2502.21267v1",
      "published": "2025-02-28T17:42:58+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.21267v1",
      "categories": [
        "cs.HC",
        "cs.AI"
      ]
    },
    {
      "title": "Foundation Models -- A Panacea for Artificial Intelligence in Pathology?",
      "authors": [
        "Nita Mulliqi",
        "Anders Blilie",
        "Xiaoyi Ji",
        "Kelvin Szolnoky",
        "Henrik Olsson",
        "Sol Erika Boman",
        "Matteo Titus",
        "Geraldine Martinez Gonzalez",
        "Julia Anna Mielcarz",
        "Masi Valkonen",
        "Einar Gudlaugsson",
        "Svein R. Kjosavik",
        "José Asenjo",
        "Marcello Gambacorta",
        "Paolo Libretti",
        "Marcin Braun",
        "Radzislaw Kordek",
        "Roman Łowicki",
        "Kristina Hotakainen",
        "Päivi Väre",
        "Bodil Ginnerup Pedersen",
        "Karina Dalsgaard Sørensen",
        "Benedicte Parm Ulhøi",
        "Pekka Ruusuvuori",
        "Brett Delahunt",
        "Hemamali Samaratunga",
        "Toyonori Tsuzuki",
        "Emilius A. M. Janssen",
        "Lars Egevad",
        "Martin Eklund",
        "Kimmo Kartasalo"
      ],
      "abstract": "The role of artificial intelligence (AI) in pathology has evolved from aiding\ndiagnostics to uncovering predictive morphological patterns in whole slide\nimages (WSIs). Recently, foundation models (FMs) leveraging self-supervised\npre-training have been widely advocated as a universal solution for diverse\ndownstream tasks. However, open questions remain about their clinical\napplicability and generalization advantages over end-to-end learning using\ntask-specific (TS) models. Here, we focused on AI with clinical-grade\nperformance for prostate cancer diagnosis and Gleason grading. We present the\nlargest validation of AI for this task, using over 100,000 core needle biopsies\nfrom 7,342 patients across 15 sites in 11 countries. We compared two FMs with a\nfully end-to-end TS model in a multiple instance learning framework. Our\nfindings challenge assumptions that FMs universally outperform TS models. While\nFMs demonstrated utility in data-scarce scenarios, their performance converged\nwith - and was in some cases surpassed by - TS models when sufficient labeled\ntraining data were available. Notably, extensive task-specific training\nmarkedly reduced clinically significant misgrading, misdiagnosis of challenging\nmorphologies, and variability across different WSI scanners. Additionally, FMs\nused up to 35 times more energy than the TS model, raising concerns about their\nsustainability. Our results underscore that while FMs offer clear advantages\nfor rapid prototyping and research, their role as a universal solution for\nclinically applicable medical AI remains uncertain. For high-stakes clinical\napplications, rigorous validation and consideration of task-specific training\nremain critically important. We advocate for integrating the strengths of FMs\nand end-to-end learning to achieve robust and resource-efficient AI pathology\nsolutions fit for clinical use.",
      "pdf_url": "http://arxiv.org/pdf/2502.21264v1",
      "published": "2025-02-28T17:40:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.21264v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "RuCCoD: Towards Automated ICD Coding in Russian",
      "authors": [
        "Aleksandr Nesterov",
        "Andrey Sakhovskiy",
        "Ivan Sviridov",
        "Airat Valiev",
        "Vladimir Makharev",
        "Petr Anokhin",
        "Galina Zubkova",
        "Elena Tutubalina"
      ],
      "abstract": "This study investigates the feasibility of automating clinical coding in\nRussian, a language with limited biomedical resources. We present a new dataset\nfor ICD coding, which includes diagnosis fields from electronic health records\n(EHRs) annotated with over 10,000 entities and more than 1,500 unique ICD\ncodes. This dataset serves as a benchmark for several state-of-the-art models,\nincluding BERT, LLaMA with LoRA, and RAG, with additional experiments examining\ntransfer learning across domains (from PubMed abstracts to medical diagnosis)\nand terminologies (from UMLS concepts to ICD codes). We then apply the\nbest-performing model to label an in-house EHR dataset containing patient\nhistories from 2017 to 2021. Our experiments, conducted on a carefully curated\ntest set, demonstrate that training with the automated predicted codes leads to\na significant improvement in accuracy compared to manually annotated data from\nphysicians. We believe our findings offer valuable insights into the potential\nfor automating clinical coding in resource-limited languages like Russian,\nwhich could enhance clinical efficiency and data accuracy in these contexts.",
      "pdf_url": "http://arxiv.org/pdf/2502.21263v1",
      "published": "2025-02-28T17:40:24+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.21263v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DB"
      ]
    },
    {
      "title": "Modeling Human Beliefs about AI Behavior for Scalable Oversight",
      "authors": [
        "Leon Lang",
        "Patrick Forré"
      ],
      "abstract": "Contemporary work in AI alignment often relies on human feedback to teach AI\nsystems human preferences and values. Yet as AI systems grow more capable,\nhuman feedback becomes increasingly unreliable. This raises the problem of\nscalable oversight: How can we supervise AI systems that exceed human\ncapabilities? In this work, we propose to model the human evaluator's beliefs\nabout the AI system's behavior to better interpret the human's feedback. We\nformalize human belief models and theoretically analyze their role in inferring\nhuman values. We then characterize the remaining ambiguity in this inference\nand conditions for which the ambiguity disappears. To mitigate reliance on\nexact belief models, we then introduce the relaxation of human belief model\ncovering. Finally, we propose using foundation models to construct covering\nbelief models, providing a new potential approach to scalable oversight.",
      "pdf_url": "http://arxiv.org/pdf/2502.21262v1",
      "published": "2025-02-28T17:39:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.21262v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Towards Developing Ethical Reasoners: Integrating Probabilistic Reasoning and Decision-Making for Complex AI Systems",
      "authors": [
        "Nijesh Upreti",
        "Jessica Ciupa",
        "Vaishak Belle"
      ],
      "abstract": "A computational ethics framework is essential for AI and autonomous systems\noperating in complex, real-world environments. Existing approaches often lack\nthe adaptability needed to integrate ethical principles into dynamic and\nambiguous contexts, limiting their effectiveness across diverse scenarios. To\naddress these challenges, we outline the necessary ingredients for building a\nholistic, meta-level framework that combines intermediate representations,\nprobabilistic reasoning, and knowledge representation. The specifications\ntherein emphasize scalability, supporting ethical reasoning at both individual\ndecision-making levels and within the collective dynamics of multi-agent\nsystems. By integrating theoretical principles with contextual factors, it\nfacilitates structured and context-aware decision-making, ensuring alignment\nwith overarching ethical standards. We further explore proposed theorems\noutlining how ethical reasoners should operate, offering a foundation for\npractical implementation. These constructs aim to support the development of\nrobust and ethically reliable AI systems capable of navigating the complexities\nof real-world moral decision-making scenarios.",
      "pdf_url": "http://arxiv.org/pdf/2502.21250v1",
      "published": "2025-02-28T17:25:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.21250v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Transforming Tuberculosis Care: Optimizing Large Language Models For Enhanced Clinician-Patient Communication",
      "authors": [
        "Daniil Filienko",
        "Mahek Nizar",
        "Javier Roberti",
        "Denise Galdamez",
        "Haroon Jakher",
        "Sarah Iribarren",
        "Weichao Yuwen",
        "Martine De Cock"
      ],
      "abstract": "Tuberculosis (TB) is the leading cause of death from an infectious disease\nglobally, with the highest burden in low- and middle-income countries. In these\nregions, limited healthcare access and high patient-to-provider ratios impede\neffective patient support, communication, and treatment completion. To bridge\nthis gap, we propose integrating a specialized Large Language Model into an\nefficacious digital adherence technology to augment interactive communication\nwith treatment supporters. This AI-powered approach, operating within a\nhuman-in-the-loop framework, aims to enhance patient engagement and improve TB\ntreatment outcomes.",
      "pdf_url": "http://arxiv.org/pdf/2502.21236v1",
      "published": "2025-02-28T17:05:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.21236v1",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ]
    },
    {
      "title": "ByteScale: Efficient Scaling of LLM Training with a 2048K Context Length on More Than 12,000 GPUs",
      "authors": [
        "Hao Ge",
        "Junda Feng",
        "Qi Huang",
        "Fangcheng Fu",
        "Xiaonan Nie",
        "Lei Zuo",
        "Haibin Lin",
        "Bin Cui",
        "Xin Liu"
      ],
      "abstract": "Scaling long-context ability is essential for Large Language Models (LLMs).\nTo amortize the memory consumption across multiple devices in long-context\ntraining, inter-data partitioning (a.k.a. Data Parallelism) and intra-data\npartitioning (a.k.a. Context Parallelism) are commonly used. Current training\nframeworks predominantly treat the two techniques as orthogonal, and establish\nstatic communication groups to organize the devices as a static mesh (e.g., a\n2D mesh). However, the sequences for LLM training typically vary in lengths, no\nmatter for texts, multi-modalities or reinforcement learning. The mismatch\nbetween data heterogeneity and static mesh causes redundant communication and\nimbalanced computation, degrading the training efficiency.\n  In this work, we introduce ByteScale, an efficient, flexible, and scalable\nLLM training framework for large-scale mixed training of long and short\nsequences. The core of ByteScale is a novel parallelism strategy, namely Hybrid\nData Parallelism (HDP), which unifies the inter- and intra-data partitioning\nwith a dynamic mesh design. In particular, we build a communication optimizer,\nwhich eliminates the redundant communication for short sequences by data-aware\nsharding and dynamic communication, and further compresses the communication\ncost for long sequences by selective offloading. Besides, we also develop a\nbalance scheduler to mitigate the imbalanced computation by parallelism-aware\ndata assignment. We evaluate ByteScale with the model sizes ranging from 7B to\n141B, context lengths from 256K to 2048K, on a production cluster with more\nthan 12,000 GPUs. Experiment results show that ByteScale outperforms the\nstate-of-the-art training system by up to 7.89x.",
      "pdf_url": "http://arxiv.org/pdf/2502.21231v1",
      "published": "2025-02-28T17:01:03+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.21231v1",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "ECLeKTic: a Novel Challenge Set for Evaluation of Cross-Lingual Knowledge Transfer",
      "authors": [
        "Omer Goldman",
        "Uri Shaham",
        "Dan Malkin",
        "Sivan Eiger",
        "Avinatan Hassidim",
        "Yossi Matias",
        "Joshua Maynez",
        "Adi Mayrav Gilady",
        "Jason Riesa",
        "Shruti Rijhwani",
        "Laura Rimell",
        "Idan Szpektor",
        "Reut Tsarfaty",
        "Matan Eyal"
      ],
      "abstract": "To achieve equitable performance across languages, multilingual large\nlanguage models (LLMs) must be able to abstract knowledge beyond the language\nin which it was acquired. However, the current literature lacks reliable ways\nto measure LLMs' capability of cross-lingual knowledge transfer. To that end,\nwe present ECLeKTic, a multilingual closed-book QA (CBQA) dataset that\nEvaluates Cross-Lingual Knowledge Transfer in a simple, black-box manner. We\ndetected information with uneven coverage across languages by controlling for\npresence and absence of Wikipedia articles in 12 languages. We generated\nknowledge-seeking questions in a source language, for which the answer appears\nin a relevant Wikipedia article and translated them to all other 11 languages,\nfor which the respective Wikipedias lack equivalent articles. Assuming that\nWikipedia reflects the prominent knowledge in the LLM's training data, to solve\nECLeKTic's CBQA task the model is required to transfer knowledge between\nlanguages. Experimenting with 8 LLMs, we show that SOTA models struggle to\neffectively share knowledge across, languages even if they can predict the\nanswer well for queries in the same language the knowledge was acquired in.",
      "pdf_url": "http://arxiv.org/pdf/2502.21228v1",
      "published": "2025-02-28T16:59:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.21228v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "XAIxArts Manifesto: Explainable AI for the Arts",
      "authors": [
        "Nick Bryan-Kinns",
        "Shuoyang Jasper Zheng",
        "Francisco Castro",
        "Makayla Lewis",
        "Jia-Rey Chang",
        "Gabriel Vigliensoni",
        "Terence Broad",
        "Michael Clemens",
        "Elizabeth Wilson"
      ],
      "abstract": "Explainable AI (XAI) is concerned with how to make AI models more\nunderstandable to people. To date these explanations have predominantly been\ntechnocentric - mechanistic or productivity oriented. This paper introduces the\nExplainable AI for the Arts (XAIxArts) manifesto to provoke new ways of\nthinking about explainability and AI beyond technocentric discourses.\nManifestos offer a means to communicate ideas, amplify unheard voices, and\nfoster reflection on practice. To supports the co-creation and revision of the\nXAIxArts manifesto we combine a World Caf\\'e style discussion format with a\nliving manifesto to question four core themes: 1) Empowerment, Inclusion, and\nFairness; 2) Valuing Artistic Practice; 3) Hacking and Glitches; and 4)\nOpenness. Through our interactive living manifesto experience we invite\nparticipants to actively engage in shaping this XIAxArts vision within the CHI\ncommunity and beyond.",
      "pdf_url": "http://arxiv.org/pdf/2502.21220v1",
      "published": "2025-02-28T16:50:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.21220v1",
      "categories": [
        "cs.HC",
        "cs.AI"
      ]
    },
    {
      "title": "An Algebraic Framework for Hierarchical Probabilistic Abstraction",
      "authors": [
        "Nijesh Upreti",
        "Vaishak Belle"
      ],
      "abstract": "Abstraction is essential for reducing the complexity of systems across\ndiverse fields, yet designing effective abstraction methodology for\nprobabilistic models is inherently challenging due to stochastic behaviors and\nuncertainties. Current approaches often distill detailed probabilistic data\ninto higher-level summaries to support tractable and interpretable analyses,\nthough they typically struggle to fully represent the relational and\nprobabilistic hierarchies through single-layered abstractions. We introduce a\nhierarchical probabilistic abstraction framework aimed at addressing these\nchallenges by extending a measure-theoretic foundation for hierarchical\nabstraction. The framework enables modular problem-solving via layered\nmappings, facilitating both detailed layer-specific analysis and a cohesive\nsystem-wide understanding. This approach bridges high-level conceptualization\nwith low-level perceptual data, enhancing interpretability and allowing layered\nanalysis. Our framework provides a robust foundation for abstraction analysis\nacross AI subfields, particularly in aligning System 1 and System 2 thinking,\nthereby supporting the development of diverse abstraction methodologies.",
      "pdf_url": "http://arxiv.org/pdf/2502.21216v1",
      "published": "2025-02-28T16:47:42+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.21216v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Transformers Learn to Implement Multi-step Gradient Descent with Chain of Thought",
      "authors": [
        "Jianhao Huang",
        "Zixuan Wang",
        "Jason D. Lee"
      ],
      "abstract": "Chain of Thought (CoT) prompting has been shown to significantly improve the\nperformance of large language models (LLMs), particularly in arithmetic and\nreasoning tasks, by instructing the model to produce intermediate reasoning\nsteps. Despite the remarkable empirical success of CoT and its theoretical\nadvantages in enhancing expressivity, the mechanisms underlying CoT training\nremain largely unexplored. In this paper, we study the training dynamics of\ntransformers over a CoT objective on an in-context weight prediction task for\nlinear regression. We prove that while a one-layer linear transformer without\nCoT can only implement a single step of gradient descent (GD) and fails to\nrecover the ground-truth weight vector, a transformer with CoT prompting can\nlearn to perform multi-step GD autoregressively, achieving near-exact recovery.\nFurthermore, we show that the trained transformer effectively generalizes on\nthe unseen data. With our technique, we also show that looped transformers\nsignificantly improve final performance compared to transformers without\nlooping in the in-context learning of linear regression. Empirically, we\ndemonstrate that CoT prompting yields substantial performance improvements.",
      "pdf_url": "http://arxiv.org/pdf/2502.21212v1",
      "published": "2025-02-28T16:40:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.21212v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "ARIES: Autonomous Reasoning with LLMs on Interactive Thought Graph Environments",
      "authors": [
        "Pedro Gimenes",
        "Zeyu Cao",
        "Jeffrey Wong",
        "Yiren Zhao"
      ],
      "abstract": "Recent research has shown that LLM performance on reasoning tasks can be\nenhanced by scaling test-time compute. One promising approach, particularly\nwith decomposable problems, involves arranging intermediate solutions as a\ngraph on which transformations are performed to explore the solution space.\nHowever, prior works rely on pre-determined, task-specific transformation\nschedules which are subject to a set of searched hyperparameters. In this work,\nwe view thought graph transformations as actions in a Markov decision process,\nand implement policy agents to drive effective action policies for the\nunderlying reasoning LLM agent. In particular, we investigate the ability for\nanother LLM to act as a policy agent on thought graph environments and\nintroduce ARIES, a multi-agent architecture for reasoning with LLMs. In ARIES,\nreasoning LLM agents solve decomposed subproblems, while policy LLM agents\nmaintain visibility of the thought graph states, and dynamically adapt the\nproblem-solving strategy. Through extensive experiments, we observe that using\noff-the-shelf LLMs as policy agents with no supervised fine-tuning (SFT) can\nyield up to $29\\%$ higher accuracy on HumanEval relative to static\ntransformation schedules, as well as reducing inference costs by $35\\%$ and\navoid any search requirements. We also conduct a thorough analysis of observed\nfailure modes, highlighting that limitations on LLM sizes and the depth of\nproblem decomposition can be seen as challenges to scaling LLM-guided\nreasoning.",
      "pdf_url": "http://arxiv.org/pdf/2502.21208v1",
      "published": "2025-02-28T16:28:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.21208v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "The PanAf-FGBG Dataset: Understanding the Impact of Backgrounds in Wildlife Behaviour Recognition",
      "authors": [
        "Otto Brookes",
        "Maksim Kukushkin",
        "Majid Mirmehdi",
        "Colleen Stephens",
        "Paula Dieguez",
        "Thurston C. Hicks",
        "Sorrel Jones",
        "Kevin Lee",
        "Maureen S. McCarthy",
        "Amelia Meier",
        "Emmanuelle Normand",
        "Erin G. Wessling",
        "Roman M. Wittig",
        "Kevin Langergraber",
        "Klaus Zuberbühler",
        "Lukas Boesch",
        "Thomas Schmid",
        "Mimi Arandjelovic",
        "Hjalmar Kühl",
        "Tilo Burghardt"
      ],
      "abstract": "Computer vision analysis of camera trap video footage is essential for\nwildlife conservation, as captured behaviours offer some of the earliest\nindicators of changes in population health. Recently, several high-impact\nanimal behaviour datasets and methods have been introduced to encourage their\nuse; however, the role of behaviour-correlated background information and its\nsignificant effect on out-of-distribution generalisation remain unexplored. In\nresponse, we present the PanAf-FGBG dataset, featuring 20 hours of wild\nchimpanzee behaviours, recorded at over 350 individual camera locations.\nUniquely, it pairs every video with a chimpanzee (referred to as a foreground\nvideo) with a corresponding background video (with no chimpanzee) from the same\ncamera location. We present two views of the dataset: one with overlapping\ncamera locations and one with disjoint locations. This setup enables, for the\nfirst time, direct evaluation of in-distribution and out-of-distribution\nconditions, and for the impact of backgrounds on behaviour recognition models\nto be quantified. All clips come with rich behavioural annotations and metadata\nincluding unique camera IDs and detailed textual scene descriptions.\nAdditionally, we establish several baselines and present a highly effective\nlatent-space normalisation technique that boosts out-of-distribution\nperformance by +5.42% mAP for convolutional and +3.75% mAP for\ntransformer-based models. Finally, we provide an in-depth analysis on the role\nof backgrounds in out-of-distribution behaviour recognition, including the so\nfar unexplored impact of background durations (i.e., the count of background\nframes within foreground videos).",
      "pdf_url": "http://arxiv.org/pdf/2502.21201v1",
      "published": "2025-02-28T16:18:57+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.21201v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "AMPLE: Event-Driven Accelerator for Mixed-Precision Inference of Graph Neural Networks",
      "authors": [
        "Pedro Gimenes",
        "Yiren Zhao",
        "George Constantinides"
      ],
      "abstract": "Graph Neural Networks (GNNs) have recently gained attention due to their\nperformance on non-Euclidean data. The use of custom hardware architectures\nproves particularly beneficial for GNNs due to their irregular memory access\npatterns, resulting from the sparse structure of graphs. However, existing FPGA\naccelerators are limited by their double buffering mechanism, which doesn't\naccount for the irregular node distribution in typical graph datasets. To\naddress this, we introduce \\textbf{AMPLE} (Accelerated Message Passing Logic\nEngine), an FPGA accelerator leveraging a new event-driven programming flow. We\ndevelop a mixed-arithmetic architecture, enabling GNN inference to be quantized\nat a node-level granularity. Finally, prefetcher for data and instructions is\nimplemented to optimize off-chip memory access and maximize node parallelism.\nEvaluation on citation and social media graph datasets ranging from $2$K to\n$700$K nodes showed a mean speedup of $243\\times$ and $7.2\\times$ against CPU\nand GPU counterparts, respectively.",
      "pdf_url": "http://arxiv.org/pdf/2502.21196v1",
      "published": "2025-02-28T16:14:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.21196v1",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Scalable Decision-Making in Stochastic Environments through Learned Temporal Abstraction",
      "authors": [
        "Baiting Luo",
        "Ava Pettet",
        "Aron Laszka",
        "Abhishek Dubey",
        "Ayan Mukhopadhyay"
      ],
      "abstract": "Sequential decision-making in high-dimensional continuous action spaces,\nparticularly in stochastic environments, faces significant computational\nchallenges. We explore this challenge in the traditional offline RL setting,\nwhere an agent must learn how to make decisions based on data collected through\na stochastic behavior policy. We present \\textit{Latent Macro Action Planner}\n(L-MAP), which addresses this challenge by learning a set of temporally\nextended macro-actions through a state-conditional Vector Quantized Variational\nAutoencoder (VQ-VAE), effectively reducing action dimensionality. L-MAP employs\na (separate) learned prior model that acts as a latent transition model and\nallows efficient sampling of plausible actions. During planning, our approach\naccounts for stochasticity in both the environment and the behavior policy by\nusing Monte Carlo tree search (MCTS). In offline RL settings, including\nstochastic continuous control tasks, L-MAP efficiently searches over discrete\nlatent actions to yield high expected returns. Empirical results demonstrate\nthat L-MAP maintains low decision latency despite increased action\ndimensionality. Notably, across tasks ranging from continuous control with\ninherently stochastic dynamics to high-dimensional robotic hand manipulation,\nL-MAP significantly outperforms existing model-based methods and performs\non-par with strong model-free actor-critic baselines, highlighting the\neffectiveness of the proposed approach in planning in complex and stochastic\nenvironments with high-dimensional action spaces.",
      "pdf_url": "http://arxiv.org/pdf/2502.21186v1",
      "published": "2025-02-28T16:02:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.21186v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ]
    },
    {
      "title": "A Survey of Link Prediction in Temporal Networks",
      "authors": [
        "Jiafeng Xiong",
        "Ahmad Zareie",
        "Rizos Sakellariou"
      ],
      "abstract": "Temporal networks have gained significant prominence in the past decade for\nmodelling dynamic interactions within complex systems. A key challenge in this\ndomain is Temporal Link Prediction (TLP), which aims to forecast future\nconnections by analysing historical network structures across various\napplications including social network analysis. While existing surveys have\naddressed specific aspects of TLP, they typically lack a comprehensive\nframework that distinguishes between representation and inference methods. This\nsurvey bridges this gap by introducing a novel taxonomy that explicitly\nexamines representation and inference from existing methods, providing a novel\nclassification of approaches for TLP. We analyse how different representation\ntechniques capture temporal and structural dynamics, examining their\ncompatibility with various inference methods for both transductive and\ninductive prediction tasks. Our taxonomy not only clarifies the methodological\nlandscape but also reveals promising unexplored combinations of existing\ntechniques. This taxonomy provides a systematic foundation for emerging\nchallenges in TLP, including model explainability and scalable architectures\nfor complex temporal networks.",
      "pdf_url": "http://arxiv.org/pdf/2502.21185v1",
      "published": "2025-02-28T16:00:57+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.21185v1",
      "categories": [
        "cs.AI",
        "cs.SI"
      ]
    },
    {
      "title": "Multimodal Dreaming: A Global Workspace Approach to World Model-Based Reinforcement Learning",
      "authors": [
        "Léopold Maytié",
        "Roland Bertin Johannet",
        "Rufin VanRullen"
      ],
      "abstract": "Humans leverage rich internal models of the world to reason about the future,\nimagine counterfactuals, and adapt flexibly to new situations. In Reinforcement\nLearning (RL), world models aim to capture how the environment evolves in\nresponse to the agent's actions, facilitating planning and generalization.\nHowever, typical world models directly operate on the environment variables\n(e.g. pixels, physical attributes), which can make their training slow and\ncumbersome; instead, it may be advantageous to rely on high-level latent\ndimensions that capture relevant multimodal variables. Global Workspace (GW)\nTheory offers a cognitive framework for multimodal integration and information\nbroadcasting in the brain, and recent studies have begun to introduce efficient\ndeep learning implementations of GW. Here, we evaluate the capabilities of an\nRL system combining GW with a world model. We compare our GW-Dreamer with\nvarious versions of the standard PPO and the original Dreamer algorithms. We\nshow that performing the dreaming process (i.e., mental simulation) inside the\nGW latent space allows for training with fewer environment steps. As an\nadditional emergent property, the resulting model (but not its comparison\nbaselines) displays strong robustness to the absence of one of its observation\nmodalities (images or simulation attributes). We conclude that the combination\nof GW with World Models holds great potential for improving decision-making in\nRL agents.",
      "pdf_url": "http://arxiv.org/pdf/2502.21142v1",
      "published": "2025-02-28T15:24:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.21142v1",
      "categories": [
        "cs.AI",
        "cs.LG",
        "q-bio.NC"
      ]
    },
    {
      "title": "Predicting clinical outcomes from patient care pathways represented with temporal knowledge graphs",
      "authors": [
        "Jong Ho Jhee",
        "Alberto Megina",
        "Pacôme Constant Dit Beaufils",
        "Matilde Karakachoff",
        "Richard Redon",
        "Alban Gaignard",
        "Adrien Coulet"
      ],
      "abstract": "Background: With the increasing availability of healthcare data, predictive\nmodeling finds many applications in the biomedical domain, such as the\nevaluation of the level of risk for various conditions, which in turn can guide\nclinical decision making. However, it is unclear how knowledge graph data\nrepresentations and their embedding, which are competitive in some settings,\ncould be of interest in biomedical predictive modeling. Method: We simulated\nsynthetic but realistic data of patients with intracranial aneurysm and\nexperimented on the task of predicting their clinical outcome. We compared the\nperformance of various classification approaches on tabular data versus a\ngraph-based representation of the same data. Next, we investigated how the\nadopted schema for representing first individual data and second temporal data\nimpacts predictive performances. Results: Our study illustrates that in our\ncase, a graph representation and Graph Convolutional Network (GCN) embeddings\nreach the best performance for a predictive task from observational data. We\nemphasize the importance of the adopted schema and of the consideration of\nliteral values in the representation of individual data. Our study also\nmoderates the relative impact of various time encoding on GCN performance.",
      "pdf_url": "http://arxiv.org/pdf/2502.21138v1",
      "published": "2025-02-28T15:20:41+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.21138v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Dynamically Local-Enhancement Planner for Large-Scale Autonomous Driving",
      "authors": [
        "Nanshan Deng",
        "Weitao Zhou",
        "Bo Zhang",
        "Junze Wen",
        "Kun Jiang",
        "Zhong Cao",
        "Diange Yang"
      ],
      "abstract": "Current autonomous vehicles operate primarily within limited regions, but\nthere is increasing demand for broader applications. However, as models scale,\ntheir limited capacity becomes a significant challenge for adapting to novel\nscenarios. It is increasingly difficult to improve models for new situations\nusing a single monolithic model. To address this issue, we introduce the\nconcept of dynamically enhancing a basic driving planner with local driving\ndata, without permanently modifying the planner itself. This approach, termed\nthe Dynamically Local-Enhancement (DLE) Planner, aims to improve the\nscalability of autonomous driving systems without significantly expanding the\nplanner's size. Our approach introduces a position-varying Markov Decision\nProcess formulation coupled with a graph neural network that extracts\nregion-specific driving features from local observation data. The learned\nfeatures describe the local behavior of the surrounding objects, which is then\nleveraged to enhance a basic reinforcement learning-based policy. We evaluated\nour approach in multiple scenarios and compared it with a one-for-all driving\nmodel. The results show that our method outperforms the baseline policy in both\nsafety (collision rate) and average reward, while maintaining a lighter scale.\nThis approach has the potential to benefit large-scale autonomous vehicles\nwithout the need for largely expanding on-device driving models.",
      "pdf_url": "http://arxiv.org/pdf/2502.21134v1",
      "published": "2025-02-28T15:17:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.21134v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "Einleitung [Introduction]",
      "authors": [
        "Vincent C. Müller"
      ],
      "abstract": "Hilary Putnam's biography and philosophical development reflect the history\nof Anglo-Saxon philosophy over the last 40 years. Putnam has influenced this\nhistory significantly for almost as long. In this introduction, the main aim is\nto present the context in which Putnam stands and from which his philosophical\ncontributions can be understood. In the context of a sketch of Putnam's\nphilosophical development, a preliminary historical classification of his work\nwill also be attempted, even if this is not the place for a comprehensive\ncritique or presentation: The introduction must remain at a fairly elementary\nlevel and of course cannot replace a reading of the texts. Since Putnam's work\nis certainly part of a rapprochement between 'analytic' and 'continental'\nphilosophy, the introduction to the texts translated here should finally make\nclear what Putnam has to offer non-analytically oriented readers.\n  Hilary Putnams Biographie und philosophische Entwicklung spiegeln die\nGeschichte der angels\\\"achsischen Philosophie in den letzten 40 Jahren. Beinahe\nebenso lange hat Putnam diese Geschichte wesentlich beeinflu{\\ss}t. In der\nvorliegenden Einleitung soll vor allem der Kontext dargestellt werden, in dem\nPutnam steht und aus dem heraus verst\\\"andlich wird, was er philosophisch zu\nsagen hat. Im Rahmen einer Skizze von Putnams philosophischer Entwicklung soll\nzudem eine vorl\\\"aufige philosophiehistorische Einordnung versucht werden, auch\nwenn hier nicht der Ort f\\\"ur eine umfassende Kritik oder Darstellung sein\nkann: Die Einleitung mu{\\ss} auf recht elementarem Niveau bleiben und kann eine\nLekt\\\"ure der Texte nat\\\"urlich nicht ersetzen. Da Putnams Werk sicherlich Teil\neiner Ann\\\"aherung von 'analytischer' und 'kontinentaler' Philosophie ist, soll\nbei der Einf\\\"uhrung in die hier \\\"ubersetzten Texte schlie{\\ss}lich deutlich\nwerden, was Putnam nicht analytisch orientierten Lesern zu bieten hat.",
      "pdf_url": "http://arxiv.org/pdf/2502.21131v1",
      "published": "2025-02-28T15:10:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.21131v1",
      "categories": [
        "physics.hist-ph",
        "cs.AI"
      ]
    },
    {
      "title": "Causality Is Key to Understand and Balance Multiple Goals in Trustworthy ML and Foundation Models",
      "authors": [
        "Ruta Binkyte",
        "Ivaxi Sheth",
        "Zhijing Jin",
        "Muhammad Havaei",
        "Bernhardt Schölkopf",
        "Mario Fritz"
      ],
      "abstract": "Ensuring trustworthiness in machine learning (ML) systems is crucial as they\nbecome increasingly embedded in high-stakes domains. This paper advocates for\nthe integration of causal methods into machine learning to navigate the\ntrade-offs among key principles of trustworthy ML, including fairness, privacy,\nrobustness, accuracy, and explainability. While these objectives should ideally\nbe satisfied simultaneously, they are often addressed in isolation, leading to\nconflicts and suboptimal solutions. Drawing on existing applications of\ncausality in ML that successfully align goals such as fairness and accuracy or\nprivacy and robustness, this paper argues that a causal approach is essential\nfor balancing multiple competing objectives in both trustworthy ML and\nfoundation models. Beyond highlighting these trade-offs, we examine how\ncausality can be practically integrated into ML and foundation models, offering\nsolutions to enhance their reliability and interpretability. Finally, we\ndiscuss the challenges, limitations, and opportunities in adopting causal\nframeworks, paving the way for more accountable and ethically sound AI systems.",
      "pdf_url": "http://arxiv.org/pdf/2502.21123v1",
      "published": "2025-02-28T14:57:33+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.21123v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Optimizing Large Language Models for ESG Activity Detection in Financial Texts",
      "authors": [
        "Mattia Birti",
        "Francesco Osborne",
        "Andrea Maurino"
      ],
      "abstract": "The integration of Environmental, Social, and Governance (ESG) factors into\ncorporate decision-making is a fundamental aspect of sustainable finance.\nHowever, ensuring that business practices align with evolving regulatory\nframeworks remains a persistent challenge. AI-driven solutions for\nautomatically assessing the alignment of sustainability reports and\nnon-financial disclosures with specific ESG activities could greatly support\nthis process. Yet, this task remains complex due to the limitations of\ngeneral-purpose Large Language Models (LLMs) in domain-specific contexts and\nthe scarcity of structured, high-quality datasets. In this paper, we\ninvestigate the ability of current-generation LLMs to identify text related to\nenvironmental activities. Furthermore, we demonstrate that their performance\ncan be significantly enhanced through fine-tuning on a combination of original\nand synthetically generated data. To this end, we introduce ESG-Activities, a\nbenchmark dataset containing 1,325 labelled text segments classified according\nto the EU ESG taxonomy. Our experimental results show that fine-tuning on\nESG-Activities significantly enhances classification accuracy, with open models\nsuch as Llama 7B and Gemma 7B outperforming large proprietary solutions in\nspecific configurations. These findings have important implications for\nfinancial analysts, policymakers, and AI researchers seeking to enhance ESG\ntransparency and compliance through advanced natural language processing\ntechniques.",
      "pdf_url": "http://arxiv.org/pdf/2502.21112v1",
      "published": "2025-02-28T14:52:25+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.21112v1",
      "categories": [
        "cs.AI",
        "cs.CE",
        "cs.CL",
        "cs.CY",
        "cs.IR"
      ]
    },
    {
      "title": "AuthSim: Towards Authentic and Effective Safety-critical Scenario Generation for Autonomous Driving Tests",
      "authors": [
        "Yukuan Yang",
        "Xucheng Lu",
        "Zhili Zhang",
        "Zepeng Wu",
        "Guoqi Li",
        "Lingzhong Meng",
        "Yunzhi Xue"
      ],
      "abstract": "Generating adversarial safety-critical scenarios is a pivotal method for\ntesting autonomous driving systems, as it identifies potential weaknesses and\nenhances system robustness and reliability. However, existing approaches\npredominantly emphasize unrestricted collision scenarios, prompting non-player\ncharacter (NPC) vehicles to attack the ego vehicle indiscriminately. These\nworks overlook these scenarios' authenticity, rationality, and relevance,\nresulting in numerous extreme, contrived, and largely unrealistic collision\nevents involving aggressive NPC vehicles. To rectify this issue, we propose a\nthree-layer relative safety region model, which partitions the area based on\ndanger levels and increases the likelihood of NPC vehicles entering relative\nboundary regions. This model directs NPC vehicles to engage in adversarial\nactions within relatively safe boundary regions, thereby augmenting the\nscenarios' authenticity. We introduce AuthSim, a comprehensive platform for\ngenerating authentic and effective safety-critical scenarios by integrating the\nthree-layer relative safety region model with reinforcement learning. To our\nknowledge, this is the first attempt to address the authenticity and\neffectiveness of autonomous driving system test scenarios comprehensively.\nExtensive experiments demonstrate that AuthSim outperforms existing methods in\ngenerating effective safety-critical scenarios. Notably, AuthSim achieves a\n5.25% improvement in average cut-in distance and a 27.12% enhancement in\naverage collision interval time, while maintaining higher efficiency in\ngenerating effective safety-critical scenarios compared to existing methods.\nThis underscores its significant advantage in producing authentic scenarios\nover current methodologies.",
      "pdf_url": "http://arxiv.org/pdf/2502.21100v1",
      "published": "2025-02-28T14:38:35+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.21100v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "Re-evaluating Theory of Mind evaluation in large language models",
      "authors": [
        "Jennifer Hu",
        "Felix Sosa",
        "Tomer Ullman"
      ],
      "abstract": "The question of whether large language models (LLMs) possess Theory of Mind\n(ToM) -- often defined as the ability to reason about others' mental states --\nhas sparked significant scientific and public interest. However, the evidence\nas to whether LLMs possess ToM is mixed, and the recent growth in evaluations\nhas not resulted in a convergence. Here, we take inspiration from cognitive\nscience to re-evaluate the state of ToM evaluation in LLMs. We argue that a\nmajor reason for the disagreement on whether LLMs have ToM is a lack of clarity\non whether models should be expected to match human behaviors, or the\ncomputations underlying those behaviors. We also highlight ways in which\ncurrent evaluations may be deviating from \"pure\" measurements of ToM abilities,\nwhich also contributes to the confusion. We conclude by discussing several\ndirections for future research, including the relationship between ToM and\npragmatic communication, which could advance our understanding of artificial\nsystems as well as human cognition.",
      "pdf_url": "http://arxiv.org/pdf/2502.21098v1",
      "published": "2025-02-28T14:36:57+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.21098v1",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "An LLM-based Delphi Study to Predict GenAI Evolution",
      "authors": [
        "Francesco Bertolotti",
        "Luca Mari"
      ],
      "abstract": "Predicting the future trajectory of complex and rapidly evolving systems\nremains a significant challenge, particularly in domains where data is scarce\nor unreliable. This study introduces a novel approach to qualitative\nforecasting by leveraging Large Language Models to conduct Delphi studies. The\nmethodology was applied to explore the future evolution of Generative\nArtificial Intelligence, revealing insights into key factors such as\ngeopolitical tensions, economic disparities, regulatory frameworks, and ethical\nconsiderations. The results highlight how LLM-based Delphi studies can\nfacilitate structured scenario analysis, capturing diverse perspectives while\nmitigating issues such as respondent fatigue. However, limitations emerge in\nterms of knowledge cutoffs, inherent biases, and sensitivity to initial\nconditions. While the approach provides an innovative means for structured\nforesight, this method could be also considered as a novel form of reasoning.\nfurther research is needed to refine its ability to manage heterogeneity,\nimprove reliability, and integrate external data sources.",
      "pdf_url": "http://arxiv.org/pdf/2502.21092v1",
      "published": "2025-02-28T14:31:25+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.21092v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "PASemiQA: Plan-Assisted Agent for Question Answering on Semi-Structured Data with Text and Relational Information",
      "authors": [
        "Hansi Yang",
        "Qi Zhang",
        "Wei Jiang",
        "Jianguo Li"
      ],
      "abstract": "Large language models (LLMs) have shown impressive abilities in answering\nquestions across various domains, but they often encounter hallucination issues\non questions that require professional and up-to-date knowledge. To address\nthis limitation, retrieval-augmented generation (RAG) techniques have been\nproposed, which retrieve relevant information from external sources to inform\ntheir responses. However, existing RAG methods typically focus on a single type\nof external data, such as vectorized text database or knowledge graphs, and\ncannot well handle real-world questions on semi-structured data containing both\ntext and relational information. To bridge this gap, we introduce PASemiQA, a\nnovel approach that jointly leverages text and relational information in\nsemi-structured data to answer questions. PASemiQA first generates a plan to\nidentify relevant text and relational information to answer the question in\nsemi-structured data, and then uses an LLM agent to traverse the\nsemi-structured data and extract necessary information. Our empirical results\ndemonstrate the effectiveness of PASemiQA across different semi-structured\ndatasets from various domains, showcasing its potential to improve the accuracy\nand reliability of question answering systems on semi-structured data.",
      "pdf_url": "http://arxiv.org/pdf/2502.21087v1",
      "published": "2025-02-28T14:26:47+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.21087v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Are foundation models useful feature extractors for electroencephalography analysis?",
      "authors": [
        "Özgün Turgut",
        "Felix S. Bott",
        "Markus Ploner",
        "Daniel Rueckert"
      ],
      "abstract": "The success of foundation models in natural language processing and computer\nvision has motivated similar approaches for general time series analysis. While\nthese models are effective for a variety of tasks, their applicability in\nmedical domains with limited data remains largely unexplored. To address this,\nwe investigate the effectiveness of foundation models in medical time series\nanalysis involving electroencephalography (EEG). Through extensive experiments\non tasks such as age prediction, seizure detection, and the classification of\nclinically relevant EEG events, we compare their diagnostic accuracy with that\nof specialised EEG models. Our analysis shows that foundation models extract\nmeaningful EEG features, outperform specialised models even without domain\nadaptation, and localise task-specific biomarkers. Moreover, we demonstrate\nthat diagnostic accuracy is substantially influenced by architectural choices\nsuch as context length. Overall, our study reveals that foundation models with\ngeneral time series understanding eliminate the dependency on large\ndomain-specific datasets, making them valuable tools for clinical practice.",
      "pdf_url": "http://arxiv.org/pdf/2502.21086v1",
      "published": "2025-02-28T14:21:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.21086v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Enhancing deep neural networks through complex-valued representations and Kuramoto synchronization dynamics",
      "authors": [
        "Sabine Muzellec",
        "Andrea Alamia",
        "Thomas Serre",
        "Rufin VanRullen"
      ],
      "abstract": "Neural synchrony is hypothesized to play a crucial role in how the brain\norganizes visual scenes into structured representations, enabling the robust\nencoding of multiple objects within a scene. However, current deep learning\nmodels often struggle with object binding, limiting their ability to represent\nmultiple objects effectively. Inspired by neuroscience, we investigate whether\nsynchrony-based mechanisms can enhance object encoding in artificial models\ntrained for visual categorization. Specifically, we combine complex-valued\nrepresentations with Kuramoto dynamics to promote phase alignment, facilitating\nthe grouping of features belonging to the same object. We evaluate two\narchitectures employing synchrony: a feedforward model and a recurrent model\nwith feedback connections to refine phase synchronization using top-down\ninformation. Both models outperform their real-valued counterparts and\ncomplex-valued models without Kuramoto synchronization on tasks involving\nmulti-object images, such as overlapping handwritten digits, noisy inputs, and\nout-of-distribution transformations. Our findings highlight the potential of\nsynchrony-driven mechanisms to enhance deep learning models, improving their\nperformance, robustness, and generalization in complex visual categorization\ntasks.",
      "pdf_url": "http://arxiv.org/pdf/2502.21077v1",
      "published": "2025-02-28T14:10:42+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.21077v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "nlin.AO",
        "q-bio.NC"
      ]
    },
    {
      "title": "FC-Attack: Jailbreaking Large Vision-Language Models via Auto-Generated Flowcharts",
      "authors": [
        "Ziyi Zhang",
        "Zhen Sun",
        "Zongmin Zhang",
        "Jihui Guo",
        "Xinlei He"
      ],
      "abstract": "Large Vision-Language Models (LVLMs) have become powerful and widely adopted\nin some practical applications. However, recent research has revealed their\nvulnerability to multimodal jailbreak attacks, whereby the model can be induced\nto generate harmful content, leading to safety risks. Although most LVLMs have\nundergone safety alignment, recent research shows that the visual modality is\nstill vulnerable to jailbreak attacks. In our work, we discover that by using\nflowcharts with partially harmful information, LVLMs can be induced to provide\nadditional harmful details. Based on this, we propose a jailbreak attack method\nbased on auto-generated flowcharts, FC-Attack. Specifically, FC-Attack first\nfine-tunes a pre-trained LLM to create a step-description generator based on\nbenign datasets. The generator is then used to produce step descriptions\ncorresponding to a harmful query, which are transformed into flowcharts in 3\ndifferent shapes (vertical, horizontal, and S-shaped) as visual prompts. These\nflowcharts are then combined with a benign textual prompt to execute a\njailbreak attack on LVLMs. Our evaluations using the Advbench dataset show that\nFC-Attack achieves over 90% attack success rates on Gemini-1.5, Llaval-Next,\nQwen2-VL, and InternVL-2.5 models, outperforming existing LVLM jailbreak\nmethods. Additionally, we investigate factors affecting the attack performance,\nincluding the number of steps and the font styles in the flowcharts. Our\nevaluation shows that FC-Attack can improve the jailbreak performance from 4%\nto 28% in Claude-3.5 by changing the font style. To mitigate the attack, we\nexplore several defenses and find that AdaShield can largely reduce the\njailbreak performance but with the cost of utility drop.",
      "pdf_url": "http://arxiv.org/pdf/2502.21059v1",
      "published": "2025-02-28T13:59:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.21059v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ]
    },
    {
      "title": "Robust Deterministic Policy Gradient for Disturbance Attenuation and Its Application to Quadrotor Control",
      "authors": [
        "Taeho Lee",
        "Donghwan Lee"
      ],
      "abstract": "Practical control systems pose significant challenges in identifying optimal\ncontrol policies due to uncertainties in the system model and external\ndisturbances. While $H_\\infty$ control techniques are commonly used to design\nrobust controllers that mitigate the effects of disturbances, these methods\noften require complex and computationally intensive calculations. To address\nthis issue, this paper proposes a reinforcement learning algorithm called\nRobust Deterministic Policy Gradient (RDPG), which formulates the $H_\\infty$\ncontrol problem as a two-player zero-sum dynamic game. In this formulation, one\nplayer (the user) aims to minimize the cost, while the other player (the\nadversary) seeks to maximize it. We then employ deterministic policy gradient\n(DPG) and its deep reinforcement learning counterpart to train a robust control\npolicy with effective disturbance attenuation. In particular, for practical\nimplementation, we introduce an algorithm called robust deep deterministic\npolicy gradient (RDDPG), which employs a deep neural network architecture and\nintegrates techniques from the twin-delayed deep deterministic policy gradient\n(TD3) to enhance stability and learning efficiency. To evaluate the proposed\nalgorithm, we implement it on an unmanned aerial vehicle (UAV) tasked with\nfollowing a predefined path in a disturbance-prone environment. The\nexperimental results demonstrate that the proposed method outperforms other\ncontrol approaches in terms of robustness against disturbances, enabling\nprecise real-time tracking of moving targets even under severe disturbance\nconditions.",
      "pdf_url": "http://arxiv.org/pdf/2502.21057v1",
      "published": "2025-02-28T13:58:22+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.21057v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "Synthesizing Individualized Aging Brains in Health and Disease with Generative Models and Parallel Transport",
      "authors": [
        "Jingru Fu",
        "Yuqi Zheng",
        "Neel Dey",
        "Daniel Ferreira",
        "Rodrigo Moreno"
      ],
      "abstract": "Simulating prospective magnetic resonance imaging (MRI) scans from a given\nindividual brain image is challenging, as it requires accounting for canonical\nchanges in aging and/or disease progression while also considering the\nindividual brain's current status and unique characteristics. While current\ndeep generative models can produce high-resolution anatomically accurate\ntemplates for population-wide studies, their ability to predict future aging\ntrajectories for individuals remains limited, particularly in capturing\nsubject-specific neuroanatomical variations over time. In this study, we\nintroduce Individualized Brain Synthesis (InBrainSyn), a framework for\nsynthesizing high-resolution subject-specific longitudinal MRI scans that\nsimulate neurodegeneration in both Alzheimer's disease (AD) and normal aging.\nInBrainSyn uses a parallel transport algorithm to adapt the population-level\naging trajectories learned by a generative deep template network, enabling\nindividualized aging synthesis. As InBrainSyn uses diffeomorphic\ntransformations to simulate aging, the synthesized images are topologically\nconsistent with the original anatomy by design. We evaluated InBrainSyn both\nquantitatively and qualitatively on AD and healthy control cohorts from the\nOpen Access Series of Imaging Studies - version 3 dataset. Experimentally,\nInBrainSyn can also model neuroanatomical transitions between normal aging and\nAD. An evaluation of an external set supports its generalizability. Overall,\nwith only a single baseline scan, InBrainSyn synthesizes realistic 3D\nspatiotemporal T1w MRI scans, producing personalized longitudinal aging\ntrajectories. The code for InBrainSyn is available at:\nhttps://github.com/Fjr9516/InBrainSyn.",
      "pdf_url": "http://arxiv.org/pdf/2502.21049v1",
      "published": "2025-02-28T13:45:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.21049v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ]
    },
    {
      "title": "Fast Adversarial Training against Sparse Attacks Requires Loss Smoothing",
      "authors": [
        "Xuyang Zhong",
        "Yixiao Huang",
        "Chen Liu"
      ],
      "abstract": "This paper studies fast adversarial training against sparse adversarial\nperturbations bounded by $l_0$ norm. We demonstrate the challenges of employing\n$1$-step attacks on $l_0$ bounded perturbations for fast adversarial training,\nincluding degraded performance and the occurrence of catastrophic overfitting\n(CO). We highlight that CO in $l_0$ adversarial training is caused by\nsub-optimal perturbation locations of $1$-step attack. Theoretical and\nempirical analyses reveal that the loss landscape of $l_0$ adversarial training\nis more craggy compared to its $l_\\infty$, $l_2$ and $l_1$ counterparts.\nMoreover, we corroborate that the craggy loss landscape can aggravate CO. To\naddress these issues, we propose Fast-LS-$l_0$ that incorporates soft labels\nand the trade-off loss function to smooth the adversarial loss landscape.\nExtensive experiments demonstrate our method can overcome the challenge of\ncatastrophic overfitting, achieve state-of-the-art performance, and narrow down\nthe performance gap between $1$-step and multi-step adversarial training\nagainst sparse attacks.",
      "pdf_url": "http://arxiv.org/pdf/2502.21041v1",
      "published": "2025-02-28T13:32:47+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.21041v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Reward Learning from Multiple Feedback Types",
      "authors": [
        "Yannick Metz",
        "András Geiszl",
        "Raphaël Baur",
        "Mennatallah El-Assady"
      ],
      "abstract": "Learning rewards from preference feedback has become an important tool in the\nalignment of agentic models. Preference-based feedback, often implemented as a\nbinary comparison between multiple completions, is an established method to\nacquire large-scale human feedback. However, human feedback in other contexts\nis often much more diverse. Such diverse feedback can better support the goals\nof a human annotator, and the simultaneous use of multiple sources might be\nmutually informative for the learning process or carry type-dependent biases\nfor the reward learning process. Despite these potential benefits, learning\nfrom different feedback types has yet to be explored extensively. In this\npaper, we bridge this gap by enabling experimentation and evaluating multi-type\nfeedback in a broad set of environments. We present a process to generate\nhigh-quality simulated feedback of six different types. Then, we implement\nreward models and downstream RL training for all six feedback types. Based on\nthe simulated feedback, we investigate the use of types of feedback across ten\nRL environments and compare them to pure preference-based baselines. We show\nempirically that diverse types of feedback can be utilized and lead to strong\nreward modeling performance. This work is the first strong indicator of the\npotential of multi-type feedback for RLHF.",
      "pdf_url": "http://arxiv.org/pdf/2502.21038v1",
      "published": "2025-02-28T13:29:54+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.21038v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Synthesizing Tabular Data Using Selectivity Enhanced Generative Adversarial Networks",
      "authors": [
        "Youran Zhou",
        "Jianzhong Qi"
      ],
      "abstract": "As E-commerce platforms face surging transactions during major shopping\nevents like Black Friday, stress testing with synthesized data is crucial for\nresource planning. Most recent studies use Generative Adversarial Networks\n(GANs) to generate tabular data while ensuring privacy and machine learning\nutility. However, these methods overlook the computational demands of\nprocessing GAN-generated data, making them unsuitable for E-commerce stress\ntesting.\n  This thesis introduces a novel GAN-based approach incorporating query\nselectivity constraints, a key factor in database transaction processing. We\nintegrate a pre-trained deep neural network to maintain selectivity consistency\nbetween real and synthetic data. Our method, tested on five real-world\ndatasets, outperforms three state-of-the-art GANs and a VAE model, improving\nselectivity estimation accuracy by up to 20pct and machine learning utility by\nup to 6 pct.",
      "pdf_url": "http://arxiv.org/pdf/2502.21034v1",
      "published": "2025-02-28T13:26:41+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.21034v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Beyond Words: A Latent Memory Approach to Internal Reasoning in LLMs",
      "authors": [
        "José I. Orlicki"
      ],
      "abstract": "Recent advances in large language models (LLMs) have popularized the\nchain-of-thought (CoT) paradigm, in which models produce explicit reasoning\nsteps in natural language. Although this approach improves interpretability and\nfacilitates external auditing, it may not represent the most computationally\nefficient method for internal reasoning. In contrast, human cognition relies on\nimplicit mental representations that recall past sensory and episodic\ninformation without requiring complete verbalization. In this paper, we propose\na framework that integrates implicit mental representations into the internal\nreasoning processes of LLMs. Preliminary experiments indicate that\nincorporating an Implicit Memory Module (IMM) into a simple GPT model yields a\nreduction of between 35% and 57% in final training loss compared to a regular\nGPT baseline. The addition of an explicit interpretability channel (e.g., a\nchain-of-thought decoder) is straightforward to implement within this approach.\nWe outline theoretical foundations, propose technical mechanisms to scale the\nmemory module, and discuss how these ideas may lead to more efficient and\nrobust reasoning, with optional future extensions for explicit auditability.",
      "pdf_url": "http://arxiv.org/pdf/2502.21030v1",
      "published": "2025-02-28T13:22:29+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.21030v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Measuring and identifying factors of individuals' trust in Large Language Models",
      "authors": [
        "Edoardo Sebastiano De Duro",
        "Giuseppe Alessandro Veltri",
        "Hudson Golino",
        "Massimo Stella"
      ],
      "abstract": "Large Language Models (LLMs) can engage in human-looking conversational\nexchanges. Although conversations can elicit trust between users and LLMs,\nscarce empirical research has examined trust formation in human-LLM contexts,\nbeyond LLMs' trustworthiness or human trust in AI in general. Here, we\nintroduce the Trust-In-LLMs Index (TILLMI) as a new framework to measure\nindividuals' trust in LLMs, extending McAllister's cognitive and affective\ntrust dimensions to LLM-human interactions. We developed TILLMI as a\npsychometric scale, prototyped with a novel protocol we called LLM-simulated\nvalidity. The LLM-based scale was then validated in a sample of 1,000 US\nrespondents. Exploratory Factor Analysis identified a two-factor structure. Two\nitems were then removed due to redundancy, yielding a final 6-item scale with a\n2-factor structure. Confirmatory Factor Analysis on a separate subsample showed\nstrong model fit ($CFI = .995$, $TLI = .991$, $RMSEA = .046$, $p_{X^2} > .05$).\nConvergent validity analysis revealed that trust in LLMs correlated positively\nwith openness to experience, extraversion, and cognitive flexibility, but\nnegatively with neuroticism. Based on these findings, we interpreted TILLMI's\nfactors as \"closeness with LLMs\" (affective dimension) and \"reliance on LLMs\"\n(cognitive dimension). Younger males exhibited higher closeness with- and\nreliance on LLMs compared to older women. Individuals with no direct experience\nwith LLMs exhibited lower levels of trust compared to LLMs' users. These\nfindings offer a novel empirical foundation for measuring trust in AI-driven\nverbal communication, informing responsible design, and fostering balanced\nhuman-AI collaboration.",
      "pdf_url": "http://arxiv.org/pdf/2502.21028v1",
      "published": "2025-02-28T13:16:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.21028v1",
      "categories": [
        "cs.HC",
        "cs.AI"
      ]
    },
    {
      "title": "Merging Clinical Knowledge into Large Language Models for Medical Research and Applications: A Survey",
      "authors": [
        "Qiyuan Li",
        "Haijiang Liu",
        "Caicai Guo",
        "Deyu Chen",
        "Meng Wang",
        "Feng Gao",
        "Jinguang Gu"
      ],
      "abstract": "Clinical knowledge is the collection of information learned from studies on\nthe causes, prognosis, diagnosis, and treatment of diseases. This type of\nknowledge can improve curing performances, and promote physical health. With\nthe emergence of large language models (LLMs), medical artificial intelligence\n(medical AI), which aims to apply academic medical AI systems to real-world\nmedical scenarios, has entered a new age of development, resulting in excellent\nworks such as DoctorGPT and Pangu-Drug from academic and industrial researches.\nHowever, the field lacks a comprehensive compendium and comparison of building\nmedical AI systems from academia and industry. Therefore, this survey focuses\non the building paradigms of medical AI systems including the use of clinical\ndatabases, datasets, training pipelines, integrating medical knowledge graphs,\nsystem applications, and evaluation systems. We hope that this survey can help\nrelevant practical researchers understand the current performance of academic\nmodels in various fields of healthcare, as well as the potential problems and\nfuture directions for implementing these scientific achievements.",
      "pdf_url": "http://arxiv.org/pdf/2502.20988v1",
      "published": "2025-02-28T12:00:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.20988v1",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "LesionLocator: Zero-Shot Universal Tumor Segmentation and Tracking in 3D Whole-Body Imaging",
      "authors": [
        "Maximilian Rokuss",
        "Yannick Kirchhoff",
        "Seval Akbal",
        "Balint Kovacs",
        "Saikat Roy",
        "Constantin Ulrich",
        "Tassilo Wald",
        "Lukas T. Rotkopf",
        "Heinz-Peter Schlemmer",
        "Klaus Maier-Hein"
      ],
      "abstract": "In this work, we present LesionLocator, a framework for zero-shot\nlongitudinal lesion tracking and segmentation in 3D medical imaging,\nestablishing the first end-to-end model capable of 4D tracking with dense\nspatial prompts. Our model leverages an extensive dataset of 23,262 annotated\nmedical scans, as well as synthesized longitudinal data across diverse lesion\ntypes. The diversity and scale of our dataset significantly enhances model\ngeneralizability to real-world medical imaging challenges and addresses key\nlimitations in longitudinal data availability. LesionLocator outperforms all\nexisting promptable models in lesion segmentation by nearly 10 dice points,\nreaching human-level performance, and achieves state-of-the-art results in\nlesion tracking, with superior lesion retrieval and segmentation accuracy.\nLesionLocator not only sets a new benchmark in universal promptable lesion\nsegmentation and automated longitudinal lesion tracking but also provides the\nfirst open-access solution of its kind, releasing our synthetic 4D dataset and\nmodel to the community, empowering future advancements in medical imaging. Code\nis available at: www.github.com/MIC-DKFZ/LesionLocator",
      "pdf_url": "http://arxiv.org/pdf/2502.20985v1",
      "published": "2025-02-28T11:58:33+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.20985v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "UoR-NCL at SemEval-2025 Task 1: Using Generative LLMs and CLIP Models for Multilingual Multimodal Idiomaticity Representation",
      "authors": [
        "Thanet Markchom",
        "Tong Wu",
        "Liting Huang",
        "Huizhi Liang"
      ],
      "abstract": "SemEval-2025 Task 1 focuses on ranking images based on their alignment with a\ngiven nominal compound that may carry idiomatic meaning in both English and\nBrazilian Portuguese. To address this challenge, this work uses generative\nlarge language models (LLMs) and multilingual CLIP models to enhance idiomatic\ncompound representations. LLMs generate idiomatic meanings for potentially\nidiomatic compounds, enriching their semantic interpretation. These meanings\nare then encoded using multilingual CLIP models, serving as representations for\nimage ranking. Contrastive learning and data augmentation techniques are\napplied to fine-tune these embeddings for improved performance. Experimental\nresults show that multimodal representations extracted through this method\noutperformed those based solely on the original nominal compounds. The\nfine-tuning approach shows promising outcomes but is less effective than using\nembeddings without fine-tuning. The source code used in this paper is available\nat https://github.com/tongwu17/SemEval-2025-Task1-UoR-NCL.",
      "pdf_url": "http://arxiv.org/pdf/2502.20984v1",
      "published": "2025-02-28T11:52:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.20984v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Improving Open-world Continual Learning under the Constraints of Scarce Labeled Data",
      "authors": [
        "Yujie Li",
        "Xiangkun Wang",
        "Xin Yang",
        "Marcello Bonsangue",
        "Junbo Zhang",
        "Tianrui Li"
      ],
      "abstract": "Open-world continual learning (OWCL) adapts to sequential tasks with open\nsamples, learning knowledge incrementally while preventing forgetting. However,\nexisting OWCL still requires a large amount of labeled data for training, which\nis often impractical in real-world applications. Given that new\ncategories/entities typically come with limited annotations and are in small\nquantities, a more realistic situation is OWCL with scarce labeled data, i.e.,\nfew-shot training samples. Hence, this paper investigates the problem of\nopen-world few-shot continual learning (OFCL), challenging in (i) learning\nunbounded tasks without forgetting previous knowledge and avoiding overfitting,\n(ii) constructing compact decision boundaries for open detection with limited\nlabeled data, and (iii) transferring knowledge about knowns and unknowns and\neven update the unknowns to knowns once the labels of open samples are learned.\nIn response, we propose a novel OFCL framework that integrates three key\ncomponents: (1) an instance-wise token augmentation (ITA) that represents and\nenriches sample representations with additional knowledge, (2) a margin-based\nopen boundary (MOB) that supports open detection with new tasks emerge over\ntime, and (3) an adaptive knowledge space (AKS) that endows unknowns with\nknowledge for the updating from unknowns to knowns. Finally, extensive\nexperiments show the proposed OFCL framework outperforms all baselines\nremarkably with practical importance and reproducibility. The source code is\nreleased at https://github.com/liyj1201/OFCL.",
      "pdf_url": "http://arxiv.org/pdf/2502.20974v1",
      "published": "2025-02-28T11:39:18+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.20974v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Fine-Grained Retrieval-Augmented Generation for Visual Question Answering",
      "authors": [
        "Zhengxuan Zhang",
        "Yin Wu",
        "Yuyu Luo",
        "Nan Tang"
      ],
      "abstract": "Visual Question Answering (VQA) focuses on providing answers to natural\nlanguage questions by utilizing information from images. Although cutting-edge\nmultimodal large language models (MLLMs) such as GPT-4o achieve strong\nperformance on VQA tasks, they frequently fall short in accessing\ndomain-specific or the latest knowledge. To mitigate this issue,\nretrieval-augmented generation (RAG) leveraging external knowledge bases (KBs),\nreferred to as KB-VQA, emerges as a promising approach. Nevertheless,\nconventional unimodal retrieval techniques, which translate images into textual\ndescriptions, often result in the loss of critical visual details. This study\npresents fine-grained knowledge units, which merge textual snippets with entity\nimages stored in vector databases. Furthermore, we introduce a knowledge unit\nretrieval-augmented generation framework (KU-RAG) that integrates fine-grained\nretrieval with MLLMs. The proposed KU-RAG framework ensures precise retrieval\nof relevant knowledge and enhances reasoning capabilities through a knowledge\ncorrection chain. Experimental findings demonstrate that our approach\nsignificantly boosts the performance of leading KB-VQA methods, achieving\nimprovements of up to 10%.",
      "pdf_url": "http://arxiv.org/pdf/2502.20964v1",
      "published": "2025-02-28T11:25:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.20964v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Retrieval Augmented Generation for Topic Modeling in Organizational Research: An Introduction with Empirical Demonstration",
      "authors": [
        "Gerion Spielberger",
        "Florian Artinger",
        "Jochen Reb",
        "Rudolf Kerschreiter"
      ],
      "abstract": "Analyzing textual data is the cornerstone of qualitative research. While\ntraditional methods such as grounded theory and content analysis are widely\nused, they are labor-intensive and time-consuming. Topic modeling offers an\nautomated complement. Yet, existing approaches, including LLM-based topic\nmodeling, still struggle with issues such as high data preprocessing\nrequirements, interpretability, and reliability. This paper introduces Agentic\nRetrieval-Augmented Generation (Agentic RAG) as a method for topic modeling\nwith LLMs. It integrates three key components: (1) retrieval, enabling\nautomatized access to external data beyond an LLM's pre-trained knowledge; (2)\ngeneration, leveraging LLM capabilities for text synthesis; and (3)\nagent-driven learning, iteratively refining retrieval and query formulation\nprocesses. To empirically validate Agentic RAG for topic modeling, we reanalyze\na Twitter/X dataset, previously examined by Mu et al. (2024a). Our findings\ndemonstrate that the approach is more efficient, interpretable and at the same\ntime achieves higher reliability and validity in comparison to the standard\nmachine learning approach but also in comparison to LLM prompting for topic\nmodeling. These results highlight Agentic RAG's ability to generate\nsemantically relevant and reproducible topics, positioning it as a robust,\nscalable, and transparent alternative for AI-driven qualitative research in\nleadership, managerial, and organizational research.",
      "pdf_url": "http://arxiv.org/pdf/2502.20963v1",
      "published": "2025-02-28T11:25:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.20963v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "econ.GN",
        "q-fin.EC"
      ]
    },
    {
      "title": "Concealed Adversarial attacks on neural networks for sequential data",
      "authors": [
        "Petr Sokerin",
        "Dmitry Anikin",
        "Sofia Krehova",
        "Alexey Zaytsev"
      ],
      "abstract": "The emergence of deep learning led to the broad usage of neural networks in\nthe time series domain for various applications, including finance and\nmedicine. While powerful, these models are prone to adversarial attacks: a\nbenign targeted perturbation of input data leads to significant changes in a\nclassifier's output. However, formally small attacks in the time series domain\nbecome easily detected by the human eye or a simple detector model.\n  We develop a concealed adversarial attack for different time-series models:\nit provides more realistic perturbations, being hard to detect by a human or\nmodel discriminator. To achieve this goal, the proposed adversarial attack\nmaximizes an aggregation of a classifier and a trained discriminator loss. To\nmake the attack stronger, we also propose a training procedure for a\ndiscriminator that provides broader coverage of possible attacks. Extensive\nbenchmarking on six UCR time series datasets across four diverse architectures\n- including recurrent, convolutional, state-space, and transformer-based models\n- demonstrates the superiority of our attack for a concealability-efficiency\ntrade-off. Our findings highlight the growing challenge of designing robust\ntime series models, emphasizing the need for improved defenses against\nrealistic and effective attacks.",
      "pdf_url": "http://arxiv.org/pdf/2502.20948v1",
      "published": "2025-02-28T11:03:32+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.20948v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    }
  ]
}