{
  "last_updated": "2025-07-22T00:56:33.415082",
  "papers": [
    {
      "title": "Toward Temporal Causal Representation Learning with Tensor Decomposition",
      "authors": [
        "Jianhong Chen",
        "Meng Zhao",
        "Mostafa Reisi Gahrooei",
        "Xubo Yue"
      ],
      "abstract": "Temporal causal representation learning is a powerful tool for uncovering\ncomplex patterns in observational studies, which are often represented as\nlow-dimensional time series. However, in many real-world applications, data are\nhigh-dimensional with varying input lengths and naturally take the form of\nirregular tensors. To analyze such data, irregular tensor decomposition is\ncritical for extracting meaningful clusters that capture essential information.\nIn this paper, we focus on modeling causal representation learning based on the\ntransformed information. First, we present a novel causal formulation for a set\nof latent clusters. We then propose CaRTeD, a joint learning framework that\nintegrates temporal causal representation learning with irregular tensor\ndecomposition. Notably, our framework provides a blueprint for downstream tasks\nusing the learned tensor factors, such as modeling latent structures and\nextracting causal information, and offers a more flexible regularization design\nto enhance tensor decomposition. Theoretically, we show that our algorithm\nconverges to a stationary point. More importantly, our results fill the gap in\ntheoretical guarantees for the convergence of state-of-the-art irregular tensor\ndecomposition. Experimental results on synthetic and real-world electronic\nhealth record (EHR) datasets (MIMIC-III), with extensive benchmarks from both\nphenotyping and network recovery perspectives, demonstrate that our proposed\nmethod outperforms state-of-the-art techniques and enhances the explainability\nof causal representations.",
      "pdf_url": "http://arxiv.org/pdf/2507.14126v1",
      "published": "2025-07-18T17:55:42+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.14126v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ]
    },
    {
      "title": "Kolmogorov Arnold Networks (KANs) for Imbalanced Data -- An Empirical Perspective",
      "authors": [
        "Pankaj Yadav",
        "Vivek Vijay"
      ],
      "abstract": "Kolmogorov Arnold Networks (KANs) are recent architectural advancement in\nneural computation that offer a mathematically grounded alternative to standard\nneural networks. This study presents an empirical evaluation of KANs in context\nof class imbalanced classification, using ten benchmark datasets. We observe\nthat KANs can inherently perform well on raw imbalanced data more effectively\nthan Multi-Layer Perceptrons (MLPs) without any resampling strategy. However,\nconventional imbalance strategies fundamentally conflict with KANs mathematical\nstructure as resampling and focal loss implementations significantly degrade\nKANs performance, while marginally benefiting MLPs. Crucially, KANs suffer from\nprohibitive computational costs without proportional performance gains.\nStatistical validation confirms that MLPs with imbalance techniques achieve\nequivalence with KANs (|d| < 0.08 across metrics) at minimal resource costs.\nThese findings reveal that KANs represent a specialized solution for raw\nimbalanced data where resources permit. But their severe performance-resource\ntradeoffs and incompatibility with standard resampling techniques currently\nlimits practical deployment. We identify critical research priorities as\ndeveloping KAN specific architectural modifications for imbalance learning,\noptimizing computational efficiency, and theoretical reconciling their conflict\nwith data augmentation. This work establishes foundational insights for next\ngeneration KAN architectures in imbalanced classification scenarios.",
      "pdf_url": "http://arxiv.org/pdf/2507.14121v1",
      "published": "2025-07-18T17:50:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.14121v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "NoHumansRequired: Autonomous High-Quality Image Editing Triplet Mining",
      "authors": [
        "Maksim Kuprashevich",
        "Grigorii Alekseenko",
        "Irina Tolstykh",
        "Georgii Fedorov",
        "Bulat Suleimanov",
        "Vladimir Dokholyan",
        "Aleksandr Gordeev"
      ],
      "abstract": "Recent advances in generative modeling enable image editing assistants that\nfollow natural language instructions without additional user input. Their\nsupervised training requires millions of triplets: original image, instruction,\nedited image. Yet mining pixel-accurate examples is hard. Each edit must affect\nonly prompt-specified regions, preserve stylistic coherence, respect physical\nplausibility, and retain visual appeal. The lack of robust automated\nedit-quality metrics hinders reliable automation at scale. We present an\nautomated, modular pipeline that mines high-fidelity triplets across domains,\nresolutions, instruction complexities, and styles. Built on public generative\nmodels and running without human intervention, our system uses a task-tuned\nGemini validator to score instruction adherence and aesthetics directly,\nremoving any need for segmentation or grounding models. Inversion and\ncompositional bootstrapping enlarge the mined set by approximately 2.2x,\nenabling large-scale high-fidelity training data. By automating the most\nrepetitive annotation steps, the approach allows a new scale of training\nwithout human labeling effort. To democratize research in this\nresource-intensive area, we release NHR-Edit: an open dataset of 358k\nhigh-quality triplets. In the largest cross-dataset evaluation, it surpasses\nall public alternatives. We also release Bagel-NHR-Edit, an open-source\nfine-tuned Bagel model, which achieves state-of-the-art metrics in our\nexperiments.",
      "pdf_url": "http://arxiv.org/pdf/2507.14119v1",
      "published": "2025-07-18T17:50:00+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.14119v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    },
    {
      "title": "CUDA-L1: Improving CUDA Optimization via Contrastive Reinforcement Learning",
      "authors": [
        "Xiaoya Li",
        "Xiaofei Sun",
        "Albert Wang",
        "Jiwei Li",
        "Chris Shum"
      ],
      "abstract": "The exponential growth in demand for GPU computing resources, driven by the\nrapid advancement of Large Language Models, has created an urgent need for\nautomated CUDA optimization strategies. While recent advances in LLMs show\npromise for code generation, current SOTA models (e.g. R1, o1) achieve low\nsuccess rates in improving CUDA speed. In this paper, we introduce CUDA-L1, an\nautomated reinforcement learning framework for CUDA optimization.\n  CUDA-L1 achieves performance improvements on the CUDA optimization task:\ntrained on NVIDIA A100, it delivers an average speedup of x17.7 across all 250\nCUDA kernels of KernelBench, with peak speedups reaching x449. Furthermore, the\nmodel also demonstrates excellent portability across GPU architectures,\nachieving average speedups of x17.8 on H100, x19.0 on RTX 3090, x16.5 on L40,\nx14.7 on H800, and x13.9 on H20 despite being optimized specifically for A100.\nBeyond these benchmark results, CUDA-L1 demonstrates several remarkable\nproperties: 1) Discovers a variety of CUDA optimization techniques and learns\nto combine them strategically to achieve optimal performance; 2) Uncovers\nfundamental principles of CUDA optimization; 3) Identifies non-obvious\nperformance bottlenecks and rejects seemingly beneficial optimizations that\nharm performance.\n  The capabilities of CUDA-L1 demonstrate that reinforcement learning can\ntransform an initially poor-performing LLM into an effective CUDA optimizer\nthrough speedup-based reward signals alone, without human expertise or domain\nknowledge. More importantly, the trained RL model extend the acquired reasoning\nabilities to new kernels. This paradigm opens possibilities for automated\noptimization of CUDA operations, and holds promise to substantially promote GPU\nefficiency and alleviate the rising pressure on GPU computing resources.",
      "pdf_url": "http://arxiv.org/pdf/2507.14111v1",
      "published": "2025-07-18T17:43:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.14111v1",
      "categories": [
        "cs.AI",
        "cs.DC",
        "cs.LG"
      ]
    },
    {
      "title": "Automated Interpretation of Non-Destructive Evaluation Contour Maps Using Large Language Models for Bridge Condition Assessment",
      "authors": [
        "Viraj Nishesh Darji",
        "Callie C. Liao",
        "Duoduo Liao"
      ],
      "abstract": "Bridge maintenance and safety are essential for transportation authorities,\nand Non-Destructive Evaluation (NDE) techniques are critical to assessing\nstructural integrity. However, interpreting NDE data can be time-consuming and\nrequires expertise, potentially delaying decision-making. Recent advancements\nin Large Language Models (LLMs) offer new ways to automate and improve this\nanalysis. This pilot study introduces a holistic assessment of LLM capabilities\nfor interpreting NDE contour maps and demonstrates the effectiveness of LLMs in\nproviding detailed bridge condition analyses. It establishes a framework for\nintegrating LLMs into bridge inspection workflows, indicating that LLM-assisted\nanalysis can enhance efficiency without compromising accuracy. In this study,\nseveral LLMs are explored with prompts specifically designed to enhance the\nquality of image descriptions, which are applied to interpret five different\nNDE contour maps obtained through technologies for assessing bridge conditions.\nEach LLM model is evaluated based on its ability to produce detailed\ndescriptions, identify defects, provide actionable recommendations, and\ndemonstrate overall accuracy. The research indicates that four of the nine\nmodels provide better image descriptions, effectively covering a wide range of\ntopics related to the bridge's condition. The outputs from these four models\nare summarized using five different LLMs to form a comprehensive overview of\nthe bridge. Notably, LLMs ChatGPT-4 and Claude 3.5 Sonnet generate more\neffective summaries. The findings suggest that LLMs have the potential to\nsignificantly improve efficiency and accuracy. This pilot study presents an\ninnovative approach that leverages LLMs for image captioning in parallel and\nsummarization, enabling faster decision-making in bridge maintenance and\nenhancing infrastructure management and safety assessments.",
      "pdf_url": "http://arxiv.org/pdf/2507.14107v1",
      "published": "2025-07-18T17:39:03+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.14107v1",
      "categories": [
        "cs.AI",
        "cs.IR"
      ]
    },
    {
      "title": "Generative AI-Driven High-Fidelity Human Motion Simulation",
      "authors": [
        "Hari Iyer",
        "Neel Macwan",
        "Atharva Jitendra Hude",
        "Heejin Jeong",
        "Shenghan Guo"
      ],
      "abstract": "Human motion simulation (HMS) supports cost-effective evaluation of worker\nbehavior, safety, and productivity in industrial tasks. However, existing\nmethods often suffer from low motion fidelity. This study introduces\nGenerative-AI-Enabled HMS (G-AI-HMS), which integrates text-to-text and\ntext-to-motion models to enhance simulation quality for physical tasks.\nG-AI-HMS tackles two key challenges: (1) translating task descriptions into\nmotion-aware language using Large Language Models aligned with MotionGPT's\ntraining vocabulary, and (2) validating AI-enhanced motions against real human\nmovements using computer vision. Posture estimation algorithms are applied to\nreal-time videos to extract joint landmarks, and motion similarity metrics are\nused to compare them with AI-enhanced sequences. In a case study involving\neight tasks, the AI-enhanced motions showed lower error than human created\ndescriptions in most scenarios, performing better in six tasks based on spatial\naccuracy, four tasks based on alignment after pose normalization, and seven\ntasks based on overall temporal similarity. Statistical analysis showed that\nAI-enhanced prompts significantly (p $<$ 0.0001) reduced joint error and\ntemporal misalignment while retaining comparable posture accuracy.",
      "pdf_url": "http://arxiv.org/pdf/2507.14097v1",
      "published": "2025-07-18T17:24:50+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.14097v1",
      "categories": [
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Lessons from the TREC Plain Language Adaptation of Biomedical Abstracts (PLABA) track",
      "authors": [
        "Brian Ondov",
        "William Xia",
        "Kush Attal",
        "Ishita Unde",
        "Jerry He",
        "Hoa Dang",
        "Ian Soboroff",
        "Dina Demner-Fushman"
      ],
      "abstract": "Objective: Recent advances in language models have shown potential to adapt\nprofessional-facing biomedical literature to plain language, making it\naccessible to patients and caregivers. However, their unpredictability,\ncombined with the high potential for harm in this domain, means rigorous\nevaluation is necessary. Our goals with this track were to stimulate research\nand to provide high-quality evaluation of the most promising systems.\n  Methods: We hosted the Plain Language Adaptation of Biomedical Abstracts\n(PLABA) track at the 2023 and 2024 Text Retrieval Conferences. Tasks included\ncomplete, sentence-level, rewriting of abstracts (Task 1) as well as\nidentifying and replacing difficult terms (Task 2). For automatic evaluation of\nTask 1, we developed a four-fold set of professionally-written references.\nSubmissions for both Tasks 1 and 2 were provided extensive manual evaluation\nfrom biomedical experts.\n  Results: Twelve teams spanning twelve countries participated in the track,\nwith models from multilayer perceptrons to large pretrained transformers. In\nmanual judgments of Task 1, top-performing models rivaled human levels of\nfactual accuracy and completeness, but not simplicity or brevity. Automatic,\nreference-based metrics generally did not correlate well with manual judgments.\nIn Task 2, systems struggled with identifying difficult terms and classifying\nhow to replace them. When generating replacements, however, LLM-based systems\ndid well in manually judged accuracy, completeness, and simplicity, though not\nin brevity.\n  Conclusion: The PLABA track showed promise for using Large Language Models to\nadapt biomedical literature for the general public, while also highlighting\ntheir deficiencies and the need for improved automatic benchmarking tools.",
      "pdf_url": "http://arxiv.org/pdf/2507.14096v1",
      "published": "2025-07-18T17:23:52+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.14096v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ]
    },
    {
      "title": "Multi-Centre Validation of a Deep Learning Model for Scoliosis Assessment",
      "authors": [
        "Šimon Kubov",
        "Simon Klíčník",
        "Jakub Dandár",
        "Zdeněk Straka",
        "Karolína Kvaková",
        "Daniel Kvak"
      ],
      "abstract": "Scoliosis affects roughly 2 to 4 percent of adolescents, and treatment\ndecisions depend on precise Cobb angle measurement. Manual assessment is time\nconsuming and subject to inter observer variation. We conducted a\nretrospective, multi centre evaluation of a fully automated deep learning\nsoftware (Carebot AI Bones, Spine Measurement functionality; Carebot s.r.o.) on\n103 standing anteroposterior whole spine radiographs collected from ten\nhospitals. Two musculoskeletal radiologists independently measured each study\nand served as reference readers. Agreement between the AI and each radiologist\nwas assessed with Bland Altman analysis, mean absolute error (MAE), root mean\nsquared error (RMSE), Pearson correlation coefficient, and Cohen kappa for four\ngrade severity classification. Against Radiologist 1 the AI achieved an MAE of\n3.89 degrees (RMSE 4.77 degrees) with a bias of 0.70 degrees and limits of\nagreement from minus 8.59 to plus 9.99 degrees. Against Radiologist 2 the AI\nachieved an MAE of 3.90 degrees (RMSE 5.68 degrees) with a bias of 2.14 degrees\nand limits from minus 8.23 to plus 12.50 degrees. Pearson correlations were r\nequals 0.906 and r equals 0.880 (inter reader r equals 0.928), while Cohen\nkappa for severity grading reached 0.51 and 0.64 (inter reader kappa 0.59).\nThese results demonstrate that the proposed software reproduces expert level\nCobb angle measurements and categorical grading across multiple centres,\nsuggesting its utility for streamlining scoliosis reporting and triage in\nclinical workflows.",
      "pdf_url": "http://arxiv.org/pdf/2507.14093v1",
      "published": "2025-07-18T17:21:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.14093v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "The Emotion-Memory Link: Do Memorability Annotations Matter for Intelligent Systems?",
      "authors": [
        "Maria Tsfasman",
        "Ramin Ghorbani",
        "Catholijn M. Jonker",
        "Bernd Dudzik"
      ],
      "abstract": "Humans have a selective memory, remembering relevant episodes and forgetting\nthe less relevant information. Possessing awareness of event memorability for a\nuser could help intelligent systems in more accurate user modelling, especially\nfor such applications as meeting support systems, memory augmentation, and\nmeeting summarisation. Emotion recognition has been widely studied, since\nemotions are thought to signal moments of high personal relevance to users. The\nemotional experience of situations and their memorability have traditionally\nbeen considered to be closely tied to one another: moments that are experienced\nas highly emotional are considered to also be highly memorable. This\nrelationship suggests that emotional annotations could serve as proxies for\nmemorability. However, existing emotion recognition systems rely heavily on\nthird-party annotations, which may not accurately represent the first-person\nexperience of emotional relevance and memorability. This is why, in this study,\nwe empirically examine the relationship between perceived group emotions\n(Pleasure-Arousal) and group memorability in the context of conversational\ninteractions. Our investigation involves continuous time-based annotations of\nboth emotions and memorability in dynamic, unstructured group settings,\napproximating conditions of real-world conversational AI applications such as\nonline meeting support systems. Our results show that the observed relationship\nbetween affect and memorability annotations cannot be reliably distinguished\nfrom what might be expected under random chance. We discuss the implications of\nthis surprising finding for the development and applications of Affective\nComputing technology. In addition, we contextualise our findings in broader\ndiscourses in the Affective Computing and point out important targets for\nfuture research efforts.",
      "pdf_url": "http://arxiv.org/pdf/2507.14084v1",
      "published": "2025-07-18T17:06:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.14084v1",
      "categories": [
        "cs.HC",
        "cs.AI"
      ]
    },
    {
      "title": "DENSE: Longitudinal Progress Note Generation with Temporal Modeling of Heterogeneous Clinical Notes Across Hospital Visits",
      "authors": [
        "Garapati Keerthana",
        "Manik Gupta"
      ],
      "abstract": "Progress notes are among the most clinically meaningful artifacts in an\nElectronic Health Record (EHR), offering temporally grounded insights into a\npatient's evolving condition, treatments, and care decisions. Despite their\nimportance, they are severely underrepresented in large-scale EHR datasets. For\ninstance, in the widely used Medical Information Mart for Intensive Care III\n(MIMIC-III) dataset, only about $8.56\\%$ of hospital visits include progress\nnotes, leaving gaps in longitudinal patient narratives. In contrast, the\ndataset contains a diverse array of other note types, each capturing different\naspects of care.\n  We present DENSE (Documenting Evolving Progress Notes from Scattered\nEvidence), a system designed to align with clinical documentation workflows by\nsimulating how physicians reference past encounters while drafting progress\nnotes. The system introduces a fine-grained note categorization and a temporal\nalignment mechanism that organizes heterogeneous notes across visits into\nstructured, chronological inputs. At its core, DENSE leverages a clinically\ninformed retrieval strategy to identify temporally and semantically relevant\ncontent from both current and prior visits. This retrieved evidence is used to\nprompt a large language model (LLM) to generate clinically coherent and\ntemporally aware progress notes.\n  We evaluate DENSE on a curated cohort of patients with multiple visits and\ncomplete progress note documentation. The generated notes demonstrate strong\nlongitudinal fidelity, achieving a temporal alignment ratio of $1.089$,\nsurpassing the continuity observed in original notes. By restoring narrative\ncoherence across fragmented documentation, our system supports improved\ndownstream tasks such as summarization, predictive modeling, and clinical\ndecision support, offering a scalable solution for LLM-driven note synthesis in\nreal-world healthcare settings.",
      "pdf_url": "http://arxiv.org/pdf/2507.14079v1",
      "published": "2025-07-18T17:00:27+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.14079v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ]
    },
    {
      "title": "Glucose-ML: A collection of longitudinal diabetes datasets for development of robust AI solutions",
      "authors": [
        "Temiloluwa Prioleau",
        "Baiying Lu",
        "Yanjun Cui"
      ],
      "abstract": "Artificial intelligence (AI) algorithms are a critical part of\nstate-of-the-art digital health technology for diabetes management. Yet, access\nto large high-quality datasets is creating barriers that impede development of\nrobust AI solutions. To accelerate development of transparent, reproducible,\nand robust AI solutions, we present Glucose-ML, a collection of 10 publicly\navailable diabetes datasets, released within the last 7 years (i.e., 2018 -\n2025). The Glucose-ML collection comprises over 300,000 days of continuous\nglucose monitor (CGM) data with a total of 38 million glucose samples collected\nfrom 2500+ people across 4 countries. Participants include persons living with\ntype 1 diabetes, type 2 diabetes, prediabetes, and no diabetes. To support\nresearchers and innovators with using this rich collection of diabetes\ndatasets, we present a comparative analysis to guide algorithm developers with\ndata selection. Additionally, we conduct a case study for the task of blood\nglucose prediction - one of the most common AI tasks within the field. Through\nthis case study, we provide a benchmark for short-term blood glucose prediction\nacross all 10 publicly available diabetes datasets within the Glucose-ML\ncollection. We show that the same algorithm can have significantly different\nprediction results when developed/evaluated with different datasets. Findings\nfrom this study are then used to inform recommendations for developing robust\nAI solutions within the diabetes or broader health domain. We provide direct\nlinks to each longitudinal diabetes dataset in the Glucose-ML collection and\nopenly provide our code.",
      "pdf_url": "http://arxiv.org/pdf/2507.14077v1",
      "published": "2025-07-18T16:53:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.14077v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Edge Intelligence with Spiking Neural Networks",
      "authors": [
        "Shuiguang Deng",
        "Di Yu",
        "Changze Lv",
        "Xin Du",
        "Linshan Jiang",
        "Xiaofan Zhao",
        "Wentao Tong",
        "Xiaoqing Zheng",
        "Weijia Fang",
        "Peng Zhao",
        "Gang Pan",
        "Schahram Dustdar",
        "Albert Y. Zomaya"
      ],
      "abstract": "The convergence of artificial intelligence and edge computing has spurred\ngrowing interest in enabling intelligent services directly on\nresource-constrained devices. While traditional deep learning models require\nsignificant computational resources and centralized data management, the\nresulting latency, bandwidth consumption, and privacy concerns have exposed\ncritical limitations in cloud-centric paradigms. Brain-inspired computing,\nparticularly Spiking Neural Networks (SNNs), offers a promising alternative by\nemulating biological neuronal dynamics to achieve low-power, event-driven\ncomputation. This survey provides a comprehensive overview of Edge Intelligence\nbased on SNNs (EdgeSNNs), examining their potential to address the challenges\nof on-device learning, inference, and security in edge scenarios. We present a\nsystematic taxonomy of EdgeSNN foundations, encompassing neuron models,\nlearning algorithms, and supporting hardware platforms. Three representative\npractical considerations of EdgeSNN are discussed in depth: on-device inference\nusing lightweight SNN models, resource-aware training and updating under\nnon-stationary data conditions, and secure and privacy-preserving issues.\nFurthermore, we highlight the limitations of evaluating EdgeSNNs on\nconventional hardware and introduce a dual-track benchmarking strategy to\nsupport fair comparisons and hardware-aware optimization. Through this study,\nwe aim to bridge the gap between brain-inspired learning and practical edge\ndeployment, offering insights into current advancements, open challenges, and\nfuture research directions. To the best of our knowledge, this is the first\ndedicated and comprehensive survey on EdgeSNNs, providing an essential\nreference for researchers and practitioners working at the intersection of\nneuromorphic computing and edge intelligence.",
      "pdf_url": "http://arxiv.org/pdf/2507.14069v1",
      "published": "2025-07-18T16:47:52+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.14069v1",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.ET",
        "cs.NE"
      ]
    },
    {
      "title": "VLA-Mark: A cross modal watermark for large vision-language alignment model",
      "authors": [
        "Shuliang Liu",
        "Qi Zheng",
        "Jesse Jiaxi Xu",
        "Yibo Yan",
        "He Geng",
        "Aiwei Liu",
        "Peijie Jiang",
        "Jia Liu",
        "Yik-Cheung Tam",
        "Xuming Hu"
      ],
      "abstract": "Vision-language models demand watermarking solutions that protect\nintellectual property without compromising multimodal coherence. Existing text\nwatermarking methods disrupt visual-textual alignment through biased token\nselection and static strategies, leaving semantic-critical concepts vulnerable.\nWe propose VLA-Mark, a vision-aligned framework that embeds detectable\nwatermarks while preserving semantic fidelity through cross-modal coordination.\nOur approach integrates multiscale visual-textual alignment metrics, combining\nlocalized patch affinity, global semantic coherence, and contextual attention\npatterns, to guide watermark injection without model retraining. An\nentropy-sensitive mechanism dynamically balances watermark strength and\nsemantic preservation, prioritizing visual grounding during low-uncertainty\ngeneration phases. Experiments show 7.4% lower PPL and 26.6% higher BLEU than\nconventional methods, with near-perfect detection (98.8% AUC). The framework\ndemonstrates 96.1\\% attack resilience against attacks such as paraphrasing and\nsynonym substitution, while maintaining text-visual consistency, establishing\nnew standards for quality-preserving multimodal watermarking",
      "pdf_url": "http://arxiv.org/pdf/2507.14067v1",
      "published": "2025-07-18T16:44:41+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.14067v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Noradrenergic-inspired gain modulation attenuates the stability gap in joint training",
      "authors": [
        "Alejandro Rodriguez-Garcia",
        "Anindya Ghosh",
        "Srikanth Ramaswamy"
      ],
      "abstract": "Recent studies in continual learning have identified a transient drop in\nperformance on mastered tasks when assimilating new ones, known as the\nstability gap. Such dynamics contradict the objectives of continual learning,\nrevealing a lack of robustness in mitigating forgetting, and notably,\npersisting even under an ideal joint-loss regime. Examining this gap within\nthis idealized joint training context is critical to isolate it from other\nsources of forgetting. We argue that it reflects an imbalance between rapid\nadaptation and robust retention at task boundaries, underscoring the need to\ninvestigate mechanisms that reconcile plasticity and stability within continual\nlearning frameworks. Biological brains navigate a similar dilemma by operating\nconcurrently on multiple timescales, leveraging neuromodulatory signals to\nmodulate synaptic plasticity. However, artificial networks lack native\nmultitimescale dynamics, and although optimizers like momentum-SGD and Adam\nintroduce implicit timescale regularization, they still exhibit stability gaps.\nInspired by locus coeruleus mediated noradrenergic bursts, which transiently\nenhance neuronal gain under uncertainty to facilitate sensory assimilation, we\npropose uncertainty-modulated gain dynamics - an adaptive mechanism that\napproximates a two-timescale optimizer and dynamically balances integration of\nknowledge with minimal interference on previously consolidated information. We\nevaluate our mechanism on domain-incremental and class-incremental variants of\nthe MNIST and CIFAR benchmarks under joint training, demonstrating that\nuncertainty-modulated gain dynamics effectively attenuate the stability gap.\nFinally, our analysis elucidates how gain modulation replicates noradrenergic\nfunctions in cortical circuits, offering mechanistic insights into reducing\nstability gaps and enhance performance in continual learning tasks.",
      "pdf_url": "http://arxiv.org/pdf/2507.14056v1",
      "published": "2025-07-18T16:34:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.14056v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.NC",
        "68T05"
      ]
    },
    {
      "title": "A multi-strategy improved snake optimizer for three-dimensional UAV path planning and engineering problems",
      "authors": [
        "Genliang Li",
        "Yaxin Cui",
        "Jinyu Su"
      ],
      "abstract": "Metaheuristic algorithms have gained widespread application across various\nfields owing to their ability to generate diverse solutions. One such algorithm\nis the Snake Optimizer (SO), a progressive optimization approach. However, SO\nsuffers from the issues of slow convergence speed and susceptibility to local\noptima. In light of these shortcomings, we propose a novel Multi-strategy\nImproved Snake Optimizer (MISO). Firstly, we propose a new adaptive random\ndisturbance strategy based on sine function to alleviate the risk of getting\ntrapped in a local optimum. Secondly, we introduce adaptive Levy flight\nstrategy based on scale factor and leader and endow the male snake leader with\nflight capability, which makes it easier for the algorithm to leap out of the\nlocal optimum and find the global optimum. More importantly, we put forward a\nposition update strategy combining elite leadership and Brownian motion,\neffectively accelerating the convergence speed while ensuring precision.\nFinally, to demonstrate the performance of MISO, we utilize 30 CEC2017 test\nfunctions and the CEC2022 test suite, comparing it with 11 popular algorithms\nacross different dimensions to validate its effectiveness. Moreover, Unmanned\nAerial Vehicle (UAV) has been widely used in various fields due to its\nadvantages of low cost, high mobility and easy operation. However, the UAV path\nplanning problem is crucial for flight safety and efficiency, and there are\nstill challenges in establishing and optimizing the path model. Therefore, we\napply MISO to the UAV 3D path planning problem as well as 6 engineering design\nproblems to assess its feasibility in practical applications. The experimental\nresults demonstrate that MISO exceeds other competitive algorithms in terms of\nsolution quality and stability, establishing its strong potential for\napplication.",
      "pdf_url": "http://arxiv.org/pdf/2507.14043v1",
      "published": "2025-07-18T16:11:35+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.14043v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CE"
      ]
    },
    {
      "title": "KROMA: Ontology Matching with Knowledge Retrieval and Large Language Models",
      "authors": [
        "Lam Nguyen",
        "Erika Barcelos",
        "Roger French",
        "Yinghui Wu"
      ],
      "abstract": "Ontology Matching (OM) is a cornerstone task of semantic interoperability,\nyet existing systems often rely on handcrafted rules or specialized models with\nlimited adaptability. We present KROMA, a novel OM framework that harnesses\nLarge Language Models (LLMs) within a Retrieval-Augmented Generation (RAG)\npipeline to dynamically enrich the semantic context of OM tasks with\nstructural, lexical, and definitional knowledge. To optimize both performance\nand efficiency, KROMA integrates a bisimilarity-based concept matching and a\nlightweight ontology refinement step, which prune candidate concepts and\nsubstantially reduce the communication overhead from invoking LLMs. Through\nexperiments on multiple benchmark datasets, we show that integrating knowledge\nretrieval with context-augmented LLMs significantly enhances ontology matching,\noutperforming both classic OM systems and cutting-edge LLM-based approaches\nwhile keeping communication overhead comparable. Our study highlights the\nfeasibility and benefit of the proposed optimization techniques (targeted\nknowledge retrieval, prompt enrichment, and ontology refinement) for ontology\nmatching at scale.",
      "pdf_url": "http://arxiv.org/pdf/2507.14032v1",
      "published": "2025-07-18T16:00:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.14032v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Photonic Fabric Platform for AI Accelerators",
      "authors": [
        "Jing Ding",
        "Trung Diep"
      ],
      "abstract": "This paper presents the Photonic FabricTM and the Photonic Fabric ApplianceTM\n(PFA), a photonic-enabled switch and memory subsystem that delivers low\nlatency, high bandwidth, and low per-bit energy. By integrating high-bandwidth\nHBM3E memory, an on-module photonic switch, and external DDR5 in a 2.5D\nelectro-optical system-in-package, the PFA offers up to 32 TB of shared memory\nalongside 115 Tbps of all-to-all digital switching. The Photonic FabricTM\nenables distributed AI training and inference to execute parallelism strategies\nmore efficiently. The Photonic Fabric removes the silicon beachfront constraint\nthat limits the fixed memory-to-compute ratio observed in virtually all current\nXPU accelerator designs. Replacing a local HBM stack on an XPU with a chiplet\nthat connects to the Photonic Fabric increases its memory capacity and\ncorrespondingly its memory bandwidth by offering a flexible path to scaling\nwell beyond the limitations of on-package HBM alone. We introduce CelestiSim, a\nlightweight analytical simulator validated on NVIDIA H100 and H200 systems. It\nis used to evaluate the performance of LLM reference and energy savings on PFA,\nwithout any significant change to the GPU core design. With the PFA, the\nsimulation results show that up to 3.66x throughput and 1.40x latency\nimprovements in LLM inference at 405B parameters, up to 7.04x throughput and\n1.41x latency improvements at 1T parameters, and 60-90% energy savings in data\nmovement for heavy collective operations in all LLM training scenarios. While\nthese results are shown for NVIDIA GPUs, they can be applied similarly to other\nAI accelerator designs (XPUs) that share the same fundamental limitation of\nfixed memory to compute.",
      "pdf_url": "http://arxiv.org/pdf/2507.14000v1",
      "published": "2025-07-18T15:14:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.14000v1",
      "categories": [
        "cs.PF",
        "cs.AI",
        "C.4"
      ]
    },
    {
      "title": "OrthoInsight: Rib Fracture Diagnosis and Report Generation Based on Multi-Modal Large Models",
      "authors": [
        "Ningyong Wu",
        "Jinzhi Wang",
        "Wenhong Zhao",
        "Chenzhan Yu",
        "Zhigang Xiu",
        "Duwei Dai"
      ],
      "abstract": "The growing volume of medical imaging data has increased the need for\nautomated diagnostic tools, especially for musculoskeletal injuries like rib\nfractures, commonly detected via CT scans. Manual interpretation is\ntime-consuming and error-prone. We propose OrthoInsight, a multi-modal deep\nlearning framework for rib fracture diagnosis and report generation. It\nintegrates a YOLOv9 model for fracture detection, a medical knowledge graph for\nretrieving clinical context, and a fine-tuned LLaVA language model for\ngenerating diagnostic reports. OrthoInsight combines visual features from CT\nimages with expert textual data to deliver clinically useful outputs. Evaluated\non 28,675 annotated CT images and expert reports, it achieves high performance\nacross Diagnostic Accuracy, Content Completeness, Logical Coherence, and\nClinical Guidance Value, with an average score of 4.28, outperforming models\nlike GPT-4 and Claude-3. This study demonstrates the potential of multi-modal\nlearning in transforming medical image analysis and providing effective support\nfor radiologists.",
      "pdf_url": "http://arxiv.org/pdf/2507.13993v1",
      "published": "2025-07-18T15:01:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.13993v1",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "CSD-VAR: Content-Style Decomposition in Visual Autoregressive Models",
      "authors": [
        "Quang-Binh Nguyen",
        "Minh Luu",
        "Quang Nguyen",
        "Anh Tran",
        "Khoi Nguyen"
      ],
      "abstract": "Disentangling content and style from a single image, known as content-style\ndecomposition (CSD), enables recontextualization of extracted content and\nstylization of extracted styles, offering greater creative flexibility in\nvisual synthesis. While recent personalization methods have explored the\ndecomposition of explicit content style, they remain tailored for diffusion\nmodels. Meanwhile, Visual Autoregressive Modeling (VAR) has emerged as a\npromising alternative with a next-scale prediction paradigm, achieving\nperformance comparable to that of diffusion models. In this paper, we explore\nVAR as a generative framework for CSD, leveraging its scale-wise generation\nprocess for improved disentanglement. To this end, we propose CSD-VAR, a novel\nmethod that introduces three key innovations: (1) a scale-aware alternating\noptimization strategy that aligns content and style representation with their\nrespective scales to enhance separation, (2) an SVD-based rectification method\nto mitigate content leakage into style representations, and (3) an Augmented\nKey-Value (K-V) memory enhancing content identity preservation. To benchmark\nthis task, we introduce CSD-100, a dataset specifically designed for\ncontent-style decomposition, featuring diverse subjects rendered in various\nartistic styles. Experiments demonstrate that CSD-VAR outperforms prior\napproaches, achieving superior content preservation and stylization fidelity.",
      "pdf_url": "http://arxiv.org/pdf/2507.13984v1",
      "published": "2025-07-18T14:45:48+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.13984v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "A segmented robot grasping perception neural network for edge AI",
      "authors": [
        "Casper Bröcheler",
        "Thomas Vroom",
        "Derrick Timmermans",
        "Alan van den Akker",
        "Guangzhi Tang",
        "Charalampos S. Kouzinopoulos",
        "Rico Möckel"
      ],
      "abstract": "Robotic grasping, the ability of robots to reliably secure and manipulate\nobjects of varying shapes, sizes and orientations, is a complex task that\nrequires precise perception and control. Deep neural networks have shown\nremarkable success in grasp synthesis by learning rich and abstract\nrepresentations of objects. When deployed at the edge, these models can enable\nlow-latency, low-power inference, making real-time grasping feasible in\nresource-constrained environments. This work implements Heatmap-Guided Grasp\nDetection, an end-to-end framework for the detection of 6-Dof grasp poses, on\nthe GAP9 RISC-V System-on-Chip. The model is optimised using hardware-aware\ntechniques, including input dimensionality reduction, model partitioning, and\nquantisation. Experimental evaluation on the GraspNet-1Billion benchmark\nvalidates the feasibility of fully on-chip inference, highlighting the\npotential of low-power MCUs for real-time, autonomous manipulation.",
      "pdf_url": "http://arxiv.org/pdf/2507.13970v1",
      "published": "2025-07-18T14:32:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.13970v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "I.2; I.2.9; I.2.10"
      ]
    },
    {
      "title": "Bottom-up Domain-specific Superintelligence: A Reliable Knowledge Graph is What We Need",
      "authors": [
        "Bhishma Dedhia",
        "Yuval Kansal",
        "Niraj K. Jha"
      ],
      "abstract": "Language models traditionally used for cross-domain generalization have\nrecently demonstrated task-specific reasoning. However, their top-down training\napproach on general corpora is insufficient for acquiring abstractions needed\nfor deep domain expertise. This may require a bottom-up approach that acquires\nexpertise by learning to compose simple domain concepts into more complex ones.\nA knowledge graph (KG) provides this compositional structure, where domain\nprimitives are represented as head-relation-tail edges and their paths encode\nhigher-level concepts. We present a task generation pipeline that synthesizes\ntasks directly from KG primitives, enabling models to acquire and compose them\nfor reasoning. We fine-tune language models on the resultant KG-grounded\ncurriculum to demonstrate domain-specific superintelligence. While broadly\napplicable, we validate our approach in medicine, where reliable KGs exist.\nUsing a medical KG, we curate 24,000 reasoning tasks paired with thinking\ntraces derived from diverse medical primitives. We fine-tune the QwQ-32B model\non this curriculum to obtain QwQ-Med-3 that takes a step towards medical\nsuperintelligence. We also introduce ICD-Bench, an evaluation suite to quantify\nreasoning abilities across 15 medical domains. Our experiments demonstrate that\nQwQ-Med-3 significantly outperforms state-of-the-art reasoning models on\nICD-Bench categories. Further analysis reveals that QwQ-Med-3 utilizes acquired\nprimitives to widen the performance gap on the hardest tasks of ICD-Bench.\nFinally, evaluation on medical question-answer benchmarks shows that QwQ-Med-3\ntransfers acquired expertise to enhance the base model's performance. While the\nindustry's approach to artificial general intelligence (AGI) emphasizes broad\nexpertise, we envision a future in which AGI emerges from the composable\ninteraction of efficient domain-specific superintelligent agents.",
      "pdf_url": "http://arxiv.org/pdf/2507.13966v1",
      "published": "2025-07-18T14:30:08+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.13966v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Towards Constraint Temporal Answer Set Programming",
      "authors": [
        "Pedro Cabalar",
        "Martín Diéguez",
        "François Olivier",
        "Torsten Schaub",
        "Igor Stéphan"
      ],
      "abstract": "Reasoning about dynamic systems with a fine-grained temporal and numeric\nresolution presents significant challenges for logic-based approaches like\nAnswer Set Programming (ASP). To address this, we introduce and elaborate upon\na novel temporal and constraint-based extension of the logic of Here-and-There\nand its nonmonotonic equilibrium extension, representing, to the best of our\nknowledge, the first approach to nonmonotonic temporal reasoning with\nconstraints specifically tailored for ASP. This expressive system is achieved\nby a synergistic combination of two foundational ASP extensions: the\nlinear-time logic of Here-and-There, providing robust nonmonotonic temporal\nreasoning capabilities, and the logic of Here-and-There with constraints,\nenabling the direct integration and manipulation of numeric constraints, among\nothers. This work establishes the foundational logical framework for tackling\ncomplex dynamic systems with high resolution within the ASP paradigm.",
      "pdf_url": "http://arxiv.org/pdf/2507.13958v1",
      "published": "2025-07-18T14:22:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.13958v1",
      "categories": [
        "cs.AI",
        "cs.LO"
      ]
    },
    {
      "title": "DUALRec: A Hybrid Sequential and Language Model Framework for Context-Aware Movie Recommendation",
      "authors": [
        "Yitong Li",
        "Raoul Grasman"
      ],
      "abstract": "The modern recommender systems are facing an increasing challenge of\nmodelling and predicting the dynamic and context-rich user preferences.\nTraditional collaborative filtering and content-based methods often struggle to\ncapture the temporal patternings and evolving user intentions. While Large\nLanguage Models (LLMs) have gained gradual attention in recent years, by their\nstrong semantic understanding and reasoning abilities, they are not inherently\ndesigned to model chronologically evolving user preference and intentions. On\nthe other hand, for sequential models like LSTM (Long-Short-Term-Memory) which\nis good at capturing the temporal dynamics of user behaviour and evolving user\npreference over time, but still lacks a rich semantic understanding for\ncomprehensive recommendation generation. In this study, we propose DUALRec\n(Dynamic User-Aware Language-based Recommender), a novel recommender that\nleverages the complementary strength of both models, which combines the\ntemporal modelling abilities of LSTM networks with semantic reasoning power of\nthe fine-tuned Large Language Models. The LSTM component will capture users\nevolving preference through their viewing history, while the fine-tuned LLM\nvariants will leverage these temporal user insights to generate next movies\nthat users might enjoy. Experimental results on MovieLens-1M dataset shows that\nthe DUALRec model outperforms a wide range of baseline models, with\ncomprehensive evaluation matrices of Hit Rate (HR@k), Normalized Discounted\nCumulative Gain (NDCG@k), and genre similarity metrics. This research proposes\na novel architecture that bridges the gap between temporal sequence modeling\nand semantic reasoning, and offers a promising direction for developing more\nintelligent and context-aware recommenders.",
      "pdf_url": "http://arxiv.org/pdf/2507.13957v1",
      "published": "2025-07-18T14:22:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.13957v1",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG",
        "68T05, 68T50, 62M45",
        "H.3.3; I.2.6; H.3.4; I.2.7"
      ]
    },
    {
      "title": "Cross-modal Causal Intervention for Alzheimer's Disease Prediction",
      "authors": [
        "Yutao Jin",
        "Haowen Xiao",
        "Jielei Chu",
        "Fengmao Lv",
        "Yuxiao Li",
        "Tianrui Li"
      ],
      "abstract": "Mild Cognitive Impairment (MCI) serves as a prodromal stage of Alzheimer's\nDisease (AD), where early identification and intervention can effectively slow\nthe progression to dementia. However, diagnosing AD remains a significant\nchallenge in neurology due to the confounders caused mainly by the selection\nbias of multimodal data and the complex relationships between variables. To\naddress these issues, we propose a novel visual-language causal intervention\nframework named Alzheimer's Disease Prediction with Cross-modal Causal\nIntervention (ADPC) for diagnostic assistance. Our ADPC employs large language\nmodel (LLM) to summarize clinical data under strict templates, maintaining\nstructured text outputs even with incomplete or unevenly distributed datasets.\nThe ADPC model utilizes Magnetic Resonance Imaging (MRI), functional MRI (fMRI)\nimages and textual data generated by LLM to classify participants into\nCognitively Normal (CN), MCI, and AD categories. Because of the presence of\nconfounders, such as neuroimaging artifacts and age-related biomarkers,\nnon-causal models are likely to capture spurious input-output correlations,\ngenerating less reliable results. Our framework implicitly eliminates\nconfounders through causal intervention. Experimental results demonstrate the\noutstanding performance of our method in distinguishing CN/MCI/AD cases,\nachieving state-of-the-art (SOTA) metrics across most evaluation metrics. The\nstudy showcases the potential of integrating causal reasoning with multi-modal\nlearning for neurological disease diagnosis.",
      "pdf_url": "http://arxiv.org/pdf/2507.13956v1",
      "published": "2025-07-18T14:21:24+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.13956v1",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.MM"
      ]
    },
    {
      "title": "Exploiting Primacy Effect To Improve Large Language Models",
      "authors": [
        "Bianca Raimondi",
        "Maurizio Gabbrielli"
      ],
      "abstract": "Large Language Models (LLMs) have become essential in many Natural Language\nProcessing (NLP) tasks, leveraging extensive pre-training and fine-tuning to\nachieve high accuracy. However, like humans, LLMs exhibit biases, particularly\npositional biases such as primacy and recency effects, which can influence the\naccuracy of the answers. The primacy effect-where items presented first are\nmore likely to be remembered or selected-plays a key role in Multiple Choice\nQuestion Answering (MCQA), where the order of answer options can affect\nprediction outcomes. This study focuses on primacy bias in fine-tuned LLMs: We\nfirst show that fine-tuning amplifies this bias, probably due to exposure to\nhuman-like patterns. Hence, we strategically leverage this effect by reordering\nresponse options based on semantic similarity to the query, without requiring\nknowledge of the correct answer. Our experimental results show that this\napproach significantly improves performance in MCQA. More generally, our\nfindings underscore the dual nature of biases as both challenges and\nopportunities, offering insights for bias-aware model design and NLP\napplications.",
      "pdf_url": "http://arxiv.org/pdf/2507.13949v1",
      "published": "2025-07-18T14:18:18+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.13949v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Generalist Forecasting with Frozen Video Models via Latent Diffusion",
      "authors": [
        "Jacob C Walker",
        "Pedro Vélez",
        "Luisa Polania Cabrera",
        "Guangyao Zhou",
        "Rishabh Kabra",
        "Carl Doersch",
        "Maks Ovsjanikov",
        "João Carreira",
        "Shiry Ginosar"
      ],
      "abstract": "Forecasting what will happen next is a critical skill for general-purpose\nsystems that plan or act in the world at different levels of abstraction. In\nthis paper, we identify a strong correlation between a vision model's\nperceptual ability and its generalist forecasting performance over short time\nhorizons. This trend holds across a diverse set of pretrained models-including\nthose trained generatively-and across multiple levels of abstraction, from raw\npixels to depth, point tracks, and object motion. The result is made possible\nby a novel generalist forecasting framework that operates on any frozen vision\nbackbone: we train latent diffusion models to forecast future features in the\nfrozen representation space, which are then decoded via lightweight,\ntask-specific readouts. To enable consistent evaluation across tasks, we\nintroduce distributional metrics that compare distributional properties\ndirectly in the space of downstream tasks and apply this framework to nine\nmodels and four tasks. Our results highlight the value of bridging\nrepresentation learning and generative modeling for temporally grounded video\nunderstanding.",
      "pdf_url": "http://arxiv.org/pdf/2507.13942v1",
      "published": "2025-07-18T14:14:19+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.13942v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Convergent transformations of visual representation in brains and models",
      "authors": [
        "Pablo Marcos-Manchón",
        "Lluís Fuentemilla"
      ],
      "abstract": "A fundamental question in cognitive neuroscience is what shapes visual\nperception: the external world's structure or the brain's internal\narchitecture. Although some perceptual variability can be traced to individual\ndifferences, brain responses to naturalistic stimuli evoke similar activity\npatterns across individuals, suggesting a convergent representational\nprinciple. Here, we test if this stimulus-driven convergence follows a common\ntrajectory across people and deep neural networks (DNNs) during its\ntransformation from sensory to high-level internal representations. We\nintroduce a unified framework that traces representational flow by combining\ninter-subject similarity with alignment to model hierarchies. Applying this\nframework to three independent fMRI datasets of visual scene perception, we\nreveal a cortex-wide network, conserved across individuals, organized into two\npathways: a medial-ventral stream for scene structure and a lateral-dorsal\nstream tuned for social and biological content. This functional organization is\ncaptured by the hierarchies of vision DNNs but not language models, reinforcing\nthe specificity of the visual-to-semantic transformation. These findings show a\nconvergent computational solution for visual encoding in both human and\nartificial vision, driven by the structure of the external world.",
      "pdf_url": "http://arxiv.org/pdf/2507.13941v1",
      "published": "2025-07-18T14:13:54+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.13941v1",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.CV",
        "eess.IV",
        "I.2.10"
      ]
    },
    {
      "title": "Preprint: Did I Just Browse A Website Written by LLMs?",
      "authors": [
        "Sichang \"Steven\" He",
        "Ramesh Govindan",
        "Harsha V. Madhyastha"
      ],
      "abstract": "Increasingly, web content is automatically generated by large language models\n(LLMs) with little human input. We call this \"LLM-dominant\" content. Since LLMs\nplagiarize and hallucinate, LLM-dominant content can be unreliable and\nunethical. Yet, websites rarely disclose such content, and human readers\nstruggle to distinguish it. Thus, we must develop reliable detectors for\nLLM-dominant content. However, state-of-the-art LLM detectors are insufficient,\nbecause they perform well mainly on clean, prose-like text, while web content\nhas complex markup and diverse genres.\n  We propose a highly reliable, scalable pipeline that classifies entire\nwebsites. Instead of naively classifying text extracted from each page, we\nclassify each site based on an LLM text detector's outputs of multiple\nprose-like pages. We train and evaluate our detector by collecting 2 distinct\nground truth datasets totaling 120 sites, and obtain 100% accuracies testing\nacross them. In the wild, we detect a sizable portion of sites as LLM-dominant\namong 10k sites in search engine results and 10k in Common Crawl archives. We\nfind LLM-dominant sites are growing in prevalence and rank highly in search\nresults, raising questions about their impact on end users and the overall Web\necosystem.",
      "pdf_url": "http://arxiv.org/pdf/2507.13933v1",
      "published": "2025-07-18T14:09:04+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.13933v1",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ]
    },
    {
      "title": "The Levers of Political Persuasion with Conversational AI",
      "authors": [
        "Kobi Hackenburg",
        "Ben M. Tappin",
        "Luke Hewitt",
        "Ed Saunders",
        "Sid Black",
        "Hause Lin",
        "Catherine Fist",
        "Helen Margetts",
        "David G. Rand",
        "Christopher Summerfield"
      ],
      "abstract": "There are widespread fears that conversational AI could soon exert\nunprecedented influence over human beliefs. Here, in three large-scale\nexperiments (N=76,977), we deployed 19 LLMs-including some post-trained\nexplicitly for persuasion-to evaluate their persuasiveness on 707 political\nissues. We then checked the factual accuracy of 466,769 resulting LLM claims.\nContrary to popular concerns, we show that the persuasive power of current and\nnear-future AI is likely to stem more from post-training and prompting\nmethods-which boosted persuasiveness by as much as 51% and 27%\nrespectively-than from personalization or increasing model scale. We further\nshow that these methods increased persuasion by exploiting LLMs' unique ability\nto rapidly access and strategically deploy information and that, strikingly,\nwhere they increased AI persuasiveness they also systematically decreased\nfactual accuracy.",
      "pdf_url": "http://arxiv.org/pdf/2507.13919v1",
      "published": "2025-07-18T13:50:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.13919v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.HC"
      ]
    },
    {
      "title": "Political Leaning and Politicalness Classification of Texts",
      "authors": [
        "Matous Volf",
        "Jakub Simko"
      ],
      "abstract": "This paper addresses the challenge of automatically classifying text\naccording to political leaning and politicalness using transformer models. We\ncompose a comprehensive overview of existing datasets and models for these\ntasks, finding that current approaches create siloed solutions that perform\npoorly on out-of-distribution texts. To address this limitation, we compile a\ndiverse dataset by combining 12 datasets for political leaning classification\nand creating a new dataset for politicalness by extending 18 existing datasets\nwith the appropriate label. Through extensive benchmarking with leave-one-in\nand leave-one-out methodologies, we evaluate the performance of existing models\nand train new ones with enhanced generalization capabilities.",
      "pdf_url": "http://arxiv.org/pdf/2507.13913v1",
      "published": "2025-07-18T13:44:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.13913v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Self-supervised learning on gene expression data",
      "authors": [
        "Kevin Dradjat",
        "Massinissa Hamidi",
        "Pierre Bartet",
        "Blaise Hanczar"
      ],
      "abstract": "Predicting phenotypes from gene expression data is a crucial task in\nbiomedical research, enabling insights into disease mechanisms, drug responses,\nand personalized medicine. Traditional machine learning and deep learning rely\non supervised learning, which requires large quantities of labeled data that\nare costly and time-consuming to obtain in the case of gene expression data.\nSelf-supervised learning has recently emerged as a promising approach to\novercome these limitations by extracting information directly from the\nstructure of unlabeled data. In this study, we investigate the application of\nstate-of-the-art self-supervised learning methods to bulk gene expression data\nfor phenotype prediction. We selected three self-supervised methods, based on\ndifferent approaches, to assess their ability to exploit the inherent structure\nof the data and to generate qualitative representations which can be used for\ndownstream predictive tasks. By using several publicly available gene\nexpression datasets, we demonstrate how the selected methods can effectively\ncapture complex information and improve phenotype prediction accuracy. The\nresults obtained show that self-supervised learning methods can outperform\ntraditional supervised models besides offering significant advantage by\nreducing the dependency on annotated data. We provide a comprehensive analysis\nof the performance of each method by highlighting their strengths and\nlimitations. We also provide recommendations for using these methods depending\non the case under study. Finally, we outline future research directions to\nenhance the application of self-supervised learning in the field of gene\nexpression data analysis. This study is the first work that deals with bulk\nRNA-Seq data and self-supervised learning.",
      "pdf_url": "http://arxiv.org/pdf/2507.13912v1",
      "published": "2025-07-18T13:43:04+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.13912v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Using LLMs to identify features of personal and professional skills in an open-response situational judgment test",
      "authors": [
        "Cole Walsh",
        "Rodica Ivan",
        "Muhammad Zafar Iqbal",
        "Colleen Robb"
      ],
      "abstract": "Academic programs are increasingly recognizing the importance of personal and\nprofessional skills and their critical role alongside technical expertise in\npreparing students for future success in diverse career paths. With this\ngrowing demand comes the need for scalable systems to measure, evaluate, and\ndevelop these skills. Situational Judgment Tests (SJTs) offer one potential\navenue for measuring these skills in a standardized and reliable way, but\nopen-response SJTs have traditionally relied on trained human raters for\nevaluation, presenting operational challenges to delivering SJTs at scale. Past\nattempts at developing NLP-based scoring systems for SJTs have fallen short due\nto issues with construct validity of these systems. In this article, we explore\na novel approach to extracting construct-relevant features from SJT responses\nusing large language models (LLMs). We use the Casper SJT to demonstrate the\nefficacy of this approach. This study sets the foundation for future\ndevelopments in automated scoring for personal and professional skills.",
      "pdf_url": "http://arxiv.org/pdf/2507.13881v1",
      "published": "2025-07-18T12:59:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.13881v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ]
    },
    {
      "title": "Real-Time Fusion of Visual and Chart Data for Enhanced Maritime Vision",
      "authors": [
        "Marten Kreis",
        "Benjamin Kiefer"
      ],
      "abstract": "This paper presents a novel approach to enhancing marine vision by fusing\nreal-time visual data with chart information. Our system overlays nautical\nchart data onto live video feeds by accurately matching detected navigational\naids, such as buoys, with their corresponding representations in chart data. To\nachieve robust association, we introduce a transformer-based end-to-end neural\nnetwork that predicts bounding boxes and confidence scores for buoy queries,\nenabling the direct matching of image-domain detections with world-space chart\nmarkers. The proposed method is compared against baseline approaches, including\na ray-casting model that estimates buoy positions via camera projection and a\nYOLOv7-based network extended with a distance estimation module. Experimental\nresults on a dataset of real-world maritime scenes demonstrate that our\napproach significantly improves object localization and association accuracy in\ndynamic and challenging environments.",
      "pdf_url": "http://arxiv.org/pdf/2507.13880v1",
      "published": "2025-07-18T12:58:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.13880v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Large Language Models as Innovators: A Framework to Leverage Latent Space Exploration for Novelty Discovery",
      "authors": [
        "Mateusz Bystroński",
        "Mikołaj Hołysz",
        "Grzegorz Piotrowski",
        "Nitesh V. Chawla",
        "Tomasz Kajdanowicz"
      ],
      "abstract": "Innovative idea generation remains a core challenge in AI, as large language\nmodels (LLMs) often struggle to produce outputs that are both novel and\nrelevant. Despite their fluency, LLMs tend to replicate patterns seen during\ntraining, limiting their ability to diverge creatively without extensive prompt\nengineering. Prior work has addressed this through domain-specific heuristics\nand structured prompting pipelines, but such solutions are brittle and\ndifficult to generalize. In this paper, we propose a model-agnostic\nlatent-space ideation framework that enables controlled, scalable creativity by\nnavigating the continuous embedding space of ideas. Unlike prior methods, our\nframework requires no handcrafted rules and adapts easily to different domains,\ninput formats, and creative tasks. This paper introduces an early-stage\nprototype of our method, outlining the conceptual framework and preliminary\nresults highlighting its potential as a general-purpose co-ideator for human-AI\ncollaboration.",
      "pdf_url": "http://arxiv.org/pdf/2507.13874v1",
      "published": "2025-07-18T12:54:28+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.13874v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "When Seeing Overrides Knowing: Disentangling Knowledge Conflicts in Vision-Language Models",
      "authors": [
        "Francesco Ortu",
        "Zhijing Jin",
        "Diego Doimo",
        "Alberto Cazzaniga"
      ],
      "abstract": "Vision-language models (VLMs) increasingly leverage diverse knowledge sources\nto address complex tasks, often encountering conflicts between their internal\nparametric knowledge and external information. Knowledge conflicts can result\nin hallucinations and unreliable responses, but the mechanisms governing such\ninteractions remain unknown. To address this gap, we analyze the mechanisms\nthat VLMs use to resolve cross-modal conflicts by introducing a dataset of\nmultimodal counterfactual queries that deliberately contradict internal\ncommonsense knowledge. We localize with logit inspection a small set of heads\nthat control the conflict. Moreover, by modifying these heads, we can steer the\nmodel towards its internal knowledge or the visual inputs. Finally, we show\nthat attention from such heads pinpoints localized image regions driving visual\noverrides, outperforming gradient-based attribution in precision.",
      "pdf_url": "http://arxiv.org/pdf/2507.13868v1",
      "published": "2025-07-18T12:42:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.13868v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "SPARQL Query Generation with LLMs: Measuring the Impact of Training Data Memorization and Knowledge Injection",
      "authors": [
        "Aleksandr Gashkov",
        "Aleksandr Perevalov",
        "Maria Eltsova",
        "Andreas Both"
      ],
      "abstract": "Nowadays, the importance of software with natural-language user interfaces\ncannot be underestimated. In particular, in Question Answering (QA) systems,\ngenerating a SPARQL query for a given natural-language question (often named\nQuery Building) from the information retrieved from the same question is the\ncentral task of QA systems working over Knowledge Graphs (KGQA). Due to the\nrise of Large Language Models (LLMs), they are considered a well-suited method\nto increase the quality of the question-answering functionality, as there is\nstill a lot of room for improvement, aiming for enhanced quality and\ntrustworthiness. However, LLMs are trained on web data, where researchers have\nno control over whether the benchmark or the knowledge graph was already\nincluded in the training data. In this paper, we introduce a novel method that\nevaluates the quality of LLMs by generating a SPARQL query from a\nnatural-language question under various conditions: (1) zero-shot SPARQL\ngeneration, (2) with knowledge injection, and (3) with \"anonymized\" knowledge\ninjection. This enables us, for the first time, to estimate the influence of\nthe training data on the QA quality improved by LLMs. Ultimately, this will\nhelp to identify how portable a method is or whether good results might mostly\nbe achieved because a benchmark was already included in the training data (cf.\nLLM memorization). The developed method is portable, robust, and supports any\nknowledge graph; therefore, it could be easily applied to any KGQA or LLM,\ns.t., generating consistent insights into the actual LLM capabilities is\npossible.",
      "pdf_url": "http://arxiv.org/pdf/2507.13859v1",
      "published": "2025-07-18T12:28:08+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.13859v1",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Causal Knowledge Transfer for Multi-Agent Reinforcement Learning in Dynamic Environments",
      "authors": [
        "Kathrin Korte",
        "Christian Medeiros Adriano",
        "Sona Ghahremani",
        "Holger Giese"
      ],
      "abstract": "[Context] Multi-agent reinforcement learning (MARL) has achieved notable\nsuccess in environments where agents must learn coordinated behaviors. However,\ntransferring knowledge across agents remains challenging in non-stationary\nenvironments with changing goals. [Problem] Traditional knowledge transfer\nmethods in MARL struggle to generalize, and agents often require costly\nretraining to adapt. [Approach] This paper introduces a causal knowledge\ntransfer framework that enables RL agents to learn and share compact causal\nrepresentations of paths within a non-stationary environment. As the\nenvironment changes (new obstacles), agents' collisions require adaptive\nrecovery strategies. We model each collision as a causal intervention\ninstantiated as a sequence of recovery actions (a macro) whose effect\ncorresponds to a causal knowledge of how to circumvent the obstacle while\nincreasing the chances of achieving the agent's goal (maximizing cumulative\nreward). This recovery action macro is transferred online from a second agent\nand is applied in a zero-shot fashion, i.e., without retraining, just by\nquerying a lookup model with local context information (collisions). [Results]\nOur findings reveal two key insights: (1) agents with heterogeneous goals were\nable to bridge about half of the gap between random exploration and a fully\nretrained policy when adapting to new environments, and (2) the impact of\ncausal knowledge transfer depends on the interplay between environment\ncomplexity and agents' heterogeneous goals.",
      "pdf_url": "http://arxiv.org/pdf/2507.13846v1",
      "published": "2025-07-18T11:59:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.13846v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Scalable Submodular Policy Optimization via Pruned Submodularity Graph",
      "authors": [
        "Aditi Anand",
        "Suman Banerjee",
        "Dildar Ali"
      ],
      "abstract": "In Reinforcement Learning (abbreviated as RL), an agent interacts with the\nenvironment via a set of possible actions, and a reward is generated from some\nunknown distribution. The task here is to find an optimal set of actions such\nthat the reward after a certain time step gets maximized. In a traditional\nsetup, the reward function in an RL Problem is considered additive. However, in\nreality, there exist many problems, including path planning, coverage control,\netc., the reward function follows the diminishing return, which can be modeled\nas a submodular function. In this paper, we study a variant of the RL Problem\nwhere the reward function is submodular, and our objective is to find an\noptimal policy such that this reward function gets maximized. We have proposed\na pruned submodularity graph-based approach that provides a provably\napproximate solution in a feasible computation time. The proposed approach has\nbeen analyzed to understand its time and space requirements as well as a\nperformance guarantee. We have experimented with a benchmark agent-environment\nsetup, which has been used for similar previous studies, and the results are\nreported. From the results, we observe that the policy obtained by our proposed\napproach leads to more reward than the baseline methods.",
      "pdf_url": "http://arxiv.org/pdf/2507.13834v1",
      "published": "2025-07-18T11:42:07+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.13834v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ]
    },
    {
      "title": "When Speed meets Accuracy: an Efficient and Effective Graph Model for Temporal Link Prediction",
      "authors": [
        "Haoyang Li",
        "Yuming Xu",
        "Yiming Li",
        "Hanmo Liu",
        "Darian Li",
        "Chen Jason Zhang",
        "Lei Chen",
        "Qing Li"
      ],
      "abstract": "Temporal link prediction in dynamic graphs is a critical task with\napplications in diverse domains such as social networks, recommendation\nsystems, and e-commerce platforms. While existing Temporal Graph Neural\nNetworks (T-GNNs) have achieved notable success by leveraging complex\narchitectures to model temporal and structural dependencies, they often suffer\nfrom scalability and efficiency challenges due to high computational overhead.\nIn this paper, we propose EAGLE, a lightweight framework that integrates\nshort-term temporal recency and long-term global structural patterns. EAGLE\nconsists of a time-aware module that aggregates information from a node's most\nrecent neighbors to reflect its immediate preferences, and a structure-aware\nmodule that leverages temporal personalized PageRank to capture the influence\nof globally important nodes. To balance these attributes, EAGLE employs an\nadaptive weighting mechanism to dynamically adjust their contributions based on\ndata characteristics. Also, EAGLE eliminates the need for complex multi-hop\nmessage passing or memory-intensive mechanisms, enabling significant\nimprovements in efficiency. Extensive experiments on seven real-world temporal\ngraphs demonstrate that EAGLE consistently achieves superior performance\nagainst state-of-the-art T-GNNs in both effectiveness and efficiency,\ndelivering more than a 50x speedup over effective transformer-based T-GNNs.",
      "pdf_url": "http://arxiv.org/pdf/2507.13825v1",
      "published": "2025-07-18T11:29:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.13825v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "RAG-based Architectures for Drug Side Effect Retrieval in LLMs",
      "authors": [
        "Shad Nygren",
        "Pinar Avci",
        "Andre Daniels",
        "Reza Rassol",
        "Afshin Beheshti",
        "Diego Galeano"
      ],
      "abstract": "Drug side effects are a major global health concern, necessitating advanced\nmethods for their accurate detection and analysis. While Large Language Models\n(LLMs) offer promising conversational interfaces, their inherent limitations,\nincluding reliance on black-box training data, susceptibility to\nhallucinations, and lack of domain-specific knowledge, hinder their reliability\nin specialized fields like pharmacovigilance. To address this gap, we propose\ntwo architectures: Retrieval-Augmented Generation (RAG) and GraphRAG, which\nintegrate comprehensive drug side effect knowledge into a Llama 3 8B language\nmodel. Through extensive evaluations on 19,520 drug side effect associations\n(covering 976 drugs and 3,851 side effect terms), our results demonstrate that\nGraphRAG achieves near-perfect accuracy in drug side effect retrieval. This\nframework offers a highly accurate and scalable solution, signifying a\nsignificant advancement in leveraging LLMs for critical pharmacovigilance\napplications.",
      "pdf_url": "http://arxiv.org/pdf/2507.13822v1",
      "published": "2025-07-18T11:20:52+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.13822v1",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Team of One: Cracking Complex Video QA with Model Synergy",
      "authors": [
        "Jun Xie",
        "Zhaoran Zhao",
        "Xiongjun Guan",
        "Yingjian Zhu",
        "Hongzhu Yi",
        "Xinming Wang",
        "Feng Chen",
        "Zhepeng Wang"
      ],
      "abstract": "We propose a novel framework for open-ended video question answering that\nenhances reasoning depth and robustness in complex real-world scenarios, as\nbenchmarked on the CVRR-ES dataset. Existing Video-Large Multimodal Models\n(Video-LMMs) often exhibit limited contextual understanding, weak temporal\nmodeling, and poor generalization to ambiguous or compositional queries. To\naddress these challenges, we introduce a prompting-and-response integration\nmechanism that coordinates multiple heterogeneous Video-Language Models (VLMs)\nvia structured chains of thought, each tailored to distinct reasoning pathways.\nAn external Large Language Model (LLM) serves as an evaluator and integrator,\nselecting and fusing the most reliable responses. Extensive experiments\ndemonstrate that our method significantly outperforms existing baselines across\nall evaluation metrics, showcasing superior generalization and robustness. Our\napproach offers a lightweight, extensible strategy for advancing multimodal\nreasoning without requiring model retraining, setting a strong foundation for\nfuture Video-LMM development.",
      "pdf_url": "http://arxiv.org/pdf/2507.13820v1",
      "published": "2025-07-18T11:12:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.13820v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Food safety trends across Europe: insights from the 392-million-entry CompreHensive European Food Safety (CHEFS) database",
      "authors": [
        "Nehir Kizililsoley",
        "Floor van Meer",
        "Osman Mutlu",
        "Wouter F Hoenderdaal",
        "Rosan G. Hobé",
        "Wenjuan Mu",
        "Arjen Gerssen",
        "H. J. van der Fels-Klerx",
        "Ákos Jóźwiak",
        "Ioannis Manikas",
        "Ali Hürriyetoǧlu",
        "Bas H. M. van der Velden"
      ],
      "abstract": "In the European Union, official food safety monitoring data collected by\nmember states are submitted to the European Food Safety Authority (EFSA) and\npublished on Zenodo. This data includes 392 million analytical results derived\nfrom over 15.2 million samples covering more than 4,000 different types of food\nproducts, offering great opportunities for artificial intelligence to analyze\ntrends, predict hazards, and support early warning systems. However, the\ncurrent format with data distributed across approximately 1000 files totaling\nseveral hundred gigabytes hinders accessibility and analysis. To address this,\nwe introduce the CompreHensive European Food Safety (CHEFS) database, which\nconsolidates EFSA monitoring data on pesticide residues, veterinary medicinal\nproduct residues, and chemical contaminants into a unified and structured\ndataset. We describe the creation and structure of the CHEFS database and\ndemonstrate its potential by analyzing trends in European food safety\nmonitoring data from 2000 to 2024. Our analyses explore changes in monitoring\nactivities, the most frequently tested products, which products were most often\nnon-compliant and which contaminants were most often found, and differences\nacross countries. These findings highlight the CHEFS database as both a\ncentralized data source and a strategic tool for guiding food safety policy,\nresearch, and regulation.",
      "pdf_url": "http://arxiv.org/pdf/2507.13802v1",
      "published": "2025-07-18T10:29:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.13802v1",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "One Step Closer: Creating the Future to Boost Monocular Semantic Scene Completion",
      "authors": [
        "Haoang Lu",
        "Yuanqi Su",
        "Xiaoning Zhang",
        "Hao Hu"
      ],
      "abstract": "In recent years, visual 3D Semantic Scene Completion (SSC) has emerged as a\ncritical perception task for autonomous driving due to its ability to infer\ncomplete 3D scene layouts and semantics from single 2D images. However, in\nreal-world traffic scenarios, a significant portion of the scene remains\noccluded or outside the camera's field of view -- a fundamental challenge that\nexisting monocular SSC methods fail to address adequately. To overcome these\nlimitations, we propose Creating the Future SSC (CF-SSC), a novel temporal SSC\nframework that leverages pseudo-future frame prediction to expand the model's\neffective perceptual range. Our approach combines poses and depths to establish\naccurate 3D correspondences, enabling geometrically-consistent fusion of past,\npresent, and predicted future frames in 3D space. Unlike conventional methods\nthat rely on simple feature stacking, our 3D-aware architecture achieves more\nrobust scene completion by explicitly modeling spatial-temporal relationships.\nComprehensive experiments on SemanticKITTI and SSCBench-KITTI-360 benchmarks\ndemonstrate state-of-the-art performance, validating the effectiveness of our\napproach, highlighting our method's ability to improve occlusion reasoning and\n3D scene completion accuracy.",
      "pdf_url": "http://arxiv.org/pdf/2507.13801v1",
      "published": "2025-07-18T10:24:58+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.13801v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Localized FNO for Spatiotemporal Hemodynamic Upsampling in Aneurysm MRI",
      "authors": [
        "Kyriakos Flouris",
        "Moritz Halter",
        "Yolanne Y. R. Lee",
        "Samuel Castonguay",
        "Luuk Jacobs",
        "Pietro Dirix",
        "Jonathan Nestmann",
        "Sebastian Kozerke",
        "Ender Konukoglu"
      ],
      "abstract": "Hemodynamic analysis is essential for predicting aneurysm rupture and guiding\ntreatment. While magnetic resonance flow imaging enables time-resolved\nvolumetric blood velocity measurements, its low spatiotemporal resolution and\nsignal-to-noise ratio limit its diagnostic utility. To address this, we propose\nthe Localized Fourier Neural Operator (LoFNO), a novel 3D architecture that\nenhances both spatial and temporal resolution with the ability to predict wall\nshear stress (WSS) directly from clinical imaging data. LoFNO integrates\nLaplacian eigenvectors as geometric priors for improved structural awareness on\nirregular, unseen geometries and employs an Enhanced Deep Super-Resolution\nNetwork (EDSR) layer for robust upsampling. By combining geometric priors with\nneural operator frameworks, LoFNO de-noises and spatiotemporally upsamples flow\ndata, achieving superior velocity and WSS predictions compared to interpolation\nand alternative deep learning methods, enabling more precise cerebrovascular\ndiagnostics.",
      "pdf_url": "http://arxiv.org/pdf/2507.13789v1",
      "published": "2025-07-18T10:00:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.13789v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "physics.comp-ph"
      ]
    },
    {
      "title": "Learning Spectral Diffusion Prior for Hyperspectral Image Reconstruction",
      "authors": [
        "Mingyang Yu",
        "Zhijian Wu",
        "Dingjiang Huang"
      ],
      "abstract": "Hyperspectral image (HSI) reconstruction aims to recover 3D HSI from its\ndegraded 2D measurements. Recently great progress has been made in deep\nlearning-based methods, however, these methods often struggle to accurately\ncapture high-frequency details of the HSI. To address this issue, this paper\nproposes a Spectral Diffusion Prior (SDP) that is implicitly learned from\nhyperspectral images using a diffusion model. Leveraging the powerful ability\nof the diffusion model to reconstruct details, this learned prior can\nsignificantly improve the performance when injected into the HSI model. To\nfurther improve the effectiveness of the learned prior, we also propose the\nSpectral Prior Injector Module (SPIM) to dynamically guide the model to recover\nthe HSI details. We evaluate our method on two representative HSI methods: MST\nand BISRNet. Experimental results show that our method outperforms existing\nnetworks by about 0.5 dB, effectively improving the performance of HSI\nreconstruction.",
      "pdf_url": "http://arxiv.org/pdf/2507.13769v1",
      "published": "2025-07-18T09:27:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.13769v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "From Extraction to Synthesis: Entangled Heuristics for Agent-Augmented Strategic Reasoning",
      "authors": [
        "Renato Ghisellini",
        "Remo Pareschi",
        "Marco Pedroni",
        "Giovanni Battista Raggi"
      ],
      "abstract": "We present a hybrid architecture for agent-augmented strategic reasoning,\ncombining heuristic extraction, semantic activation, and compositional\nsynthesis. Drawing on sources ranging from classical military theory to\ncontemporary corporate strategy, our model activates and composes multiple\nheuristics through a process of semantic interdependence inspired by research\nin quantum cognition. Unlike traditional decision engines that select the best\nrule, our system fuses conflicting heuristics into coherent and\ncontext-sensitive narratives, guided by semantic interaction modeling and\nrhetorical framing. We demonstrate the framework via a Meta vs. FTC case study,\nwith preliminary validation through semantic metrics. Limitations and\nextensions (e.g., dynamic interference tuning) are discussed.",
      "pdf_url": "http://arxiv.org/pdf/2507.13768v1",
      "published": "2025-07-18T09:26:37+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.13768v1",
      "categories": [
        "cs.AI",
        "I.2.7"
      ]
    },
    {
      "title": "OntView: What you See is What you Meant",
      "authors": [
        "Carlos Bobed",
        "Carlota Quintana",
        "Eduardo Mena",
        "Jorge Bobed",
        "Fernando Bobillo"
      ],
      "abstract": "In the field of knowledge management and computer science, ontologies provide\na structured framework for modeling domain-specific knowledge by defining\nconcepts and their relationships. However, the lack of tools that provide\neffective visualization is still a significant challenge. While numerous\nontology editors and viewers exist, most of them fail to graphically represent\nontology structures in a meaningful and non-overwhelming way, limiting users'\nability to comprehend dependencies and properties within large ontological\nframeworks.\n  In this paper, we present OntView, an ontology viewer that is designed to\nprovide users with an intuitive visual representation of ontology concepts and\ntheir formal definitions through a user-friendly interface. Building on the use\nof a DL reasoner, OntView follows a \"What you see is what you meant\" paradigm,\nshowing the actual inferred knowledge. One key aspect for this is its ability\nto visualize General Concept Inclusions (GCI), a feature absent in existing\nvisualization tools. Moreover, to avoid a possible information overload,\nOntView also offers different ways to show a simplified view of the ontology\nby: 1) creating ontology summaries by assessing the importance of the concepts\n(according to different available algorithms), 2) focusing the visualization on\nthe existing TBox elements between two given classes and 3) allowing to\nhide/show different branches in a dynamic way without losing the semantics.\nOntView has been released with an open-source license for the whole community.",
      "pdf_url": "http://arxiv.org/pdf/2507.13759v1",
      "published": "2025-07-18T09:06:49+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.13759v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Search-Optimized Quantization in Biomedical Ontology Alignment",
      "authors": [
        "Oussama Bouaggad",
        "Natalia Grabar"
      ],
      "abstract": "In the fast-moving world of AI, as organizations and researchers develop more\nadvanced models, they face challenges due to their sheer size and computational\ndemands. Deploying such models on edge devices or in resource-constrained\nenvironments adds further challenges related to energy consumption, memory\nusage and latency. To address these challenges, emerging trends are shaping the\nfuture of efficient model optimization techniques. From this premise, by\nemploying supervised state-of-the-art transformer-based models, this research\nintroduces a systematic method for ontology alignment, grounded in cosine-based\nsemantic similarity between a biomedical layman vocabulary and the Unified\nMedical Language System (UMLS) Metathesaurus. It leverages Microsoft Olive to\nsearch for target optimizations among different Execution Providers (EPs) using\nthe ONNX Runtime backend, followed by an assembled process of dynamic\nquantization employing Intel Neural Compressor and IPEX (Intel Extension for\nPyTorch). Through our optimization process, we conduct extensive assessments on\nthe two tasks from the DEFT 2020 Evaluation Campaign, achieving a new\nstate-of-the-art in both. We retain performance metrics intact, while attaining\nan average inference speed-up of 20x and reducing memory usage by approximately\n70%.",
      "pdf_url": "http://arxiv.org/pdf/2507.13742v1",
      "published": "2025-07-18T08:42:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.13742v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ]
    },
    {
      "title": "SamGoG: A Sampling-Based Graph-of-Graphs Framework for Imbalanced Graph Classification",
      "authors": [
        "Shangyou Wang",
        "Zezhong Ding",
        "Xike Xie"
      ],
      "abstract": "Graph Neural Networks (GNNs) have shown remarkable success in graph\nclassification tasks by capturing both structural and feature-based\nrepresentations. However, real-world graphs often exhibit two critical forms of\nimbalance: class imbalance and graph size imbalance. These imbalances can bias\nthe learning process and degrade model performance. Existing methods typically\naddress only one type of imbalance or incur high computational costs. In this\nwork, we propose SamGoG, a sampling-based Graph-of-Graphs (GoG) learning\nframework that effectively mitigates both class and graph size imbalance.\nSamGoG constructs multiple GoGs through an efficient importance-based sampling\nmechanism and trains on them sequentially. This sampling mechanism incorporates\nthe learnable pairwise similarity and adaptive GoG node degree to enhance edge\nhomophily, thus improving downstream model quality. SamGoG can seamlessly\nintegrate with various downstream GNNs, enabling their efficient adaptation for\ngraph classification tasks. Extensive experiments on benchmark datasets\ndemonstrate that SamGoG achieves state-of-the-art performance with up to a\n15.66% accuracy improvement with 6.7$\\times$ training acceleration.",
      "pdf_url": "http://arxiv.org/pdf/2507.13741v1",
      "published": "2025-07-18T08:41:58+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.13741v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Can Synthetic Images Conquer Forgetting? Beyond Unexplored Doubts in Few-Shot Class-Incremental Learning",
      "authors": [
        "Junsu Kim",
        "Yunhoe Ku",
        "Seungryul Baek"
      ],
      "abstract": "Few-shot class-incremental learning (FSCIL) is challenging due to extremely\nlimited training data; while aiming to reduce catastrophic forgetting and learn\nnew information. We propose Diffusion-FSCIL, a novel approach that employs a\ntext-to-image diffusion model as a frozen backbone. Our conjecture is that\nFSCIL can be tackled using a large generative model's capabilities benefiting\nfrom 1) generation ability via large-scale pre-training; 2) multi-scale\nrepresentation; 3) representational flexibility through the text encoder. To\nmaximize the representation capability, we propose to extract multiple\ncomplementary diffusion features to play roles as latent replay with slight\nsupport from feature distillation for preventing generative biases. Our\nframework realizes efficiency through 1) using a frozen backbone; 2) minimal\ntrainable components; 3) batch processing of multiple feature extractions.\nExtensive experiments on CUB-200, \\emph{mini}ImageNet, and CIFAR-100 show that\nDiffusion-FSCIL surpasses state-of-the-art methods, preserving performance on\npreviously learned classes and adapting effectively to new ones.",
      "pdf_url": "http://arxiv.org/pdf/2507.13739v1",
      "published": "2025-07-18T08:38:07+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.13739v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    }
  ]
}