{
  "last_updated": "2025-06-24T00:54:03.460204",
  "papers": [
    {
      "title": "No Free Lunch: Rethinking Internal Feedback for LLM Reasoning",
      "authors": [
        "Yanzhi Zhang",
        "Zhaoxi Zhang",
        "Haoxiang Guan",
        "Yilin Cheng",
        "Yitong Duan",
        "Chen Wang",
        "Yue Wang",
        "Shuxin Zheng",
        "Jiyan He"
      ],
      "abstract": "Reinforcement learning has emerged as a powerful paradigm for post-training\nlarge language models (LLMs) to improve reasoning. Approaches like\nReinforcement Learning from Human Feedback (RLHF) and Reinforcement Learning\nwith Verifiable Rewards (RLVR) have shown strong results, but they require\nextensive external supervision. We investigate an alternative class of methods,\nReinforcement Learning from Internal Feedback (RLIF), which relies solely on\nintrinsic model-derived signals instead of external rewards. In particular, we\nleverage unsupervised reward proxies such as token-level entropy,\ntrajectory-level entropy, and self-certainty. Our theoretical analysis shows\nthese internal objectives are partially equivalent, and we empirically evaluate\nvarious RLIF strategies on challenging math reasoning benchmarks. Experimental\nresults demonstrate that RLIF can boost the reasoning performance of base LLMs\nat the beginning phase of the training, matching or surpassing RLVR techniques\non these tasks. However, when training progresses, performance degrades even\nbelow the model before training. Moreover, we find that RLIF yields little\nimprovement for instruction-tuned models, indicating diminishing returns of\nintrinsic feedback once an LLM is already instruction-tuned. We further analyze\nthis limitation by mixing model weights and explain the reason of RLIF's\ntraining behaviors, providing practical guidelines for integrating internal\nfeedback signals into LLM training. We hope our analysis of internal feedback\nwill inform more principled and effective strategies for LLM post-training.",
      "pdf_url": "http://arxiv.org/pdf/2506.17219v1",
      "published": "2025-06-20T17:59:52+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.17219v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Machine Mental Imagery: Empower Multimodal Reasoning with Latent Visual Tokens",
      "authors": [
        "Zeyuan Yang",
        "Xueyang Yu",
        "Delin Chen",
        "Maohao Shen",
        "Chuang Gan"
      ],
      "abstract": "Vision-language models (VLMs) excel at multimodal understanding, yet their\ntext-only decoding forces them to verbalize visual reasoning, limiting\nperformance on tasks that demand visual imagination. Recent attempts train VLMs\nto render explicit images, but the heavy image-generation pre-training often\nhinders the reasoning ability. Inspired by the way humans reason with mental\nimagery-the internal construction and manipulation of visual cues-we\ninvestigate whether VLMs can reason through interleaved multimodal trajectories\nwithout producing explicit images. To this end, we present a Machine Mental\nImagery framework, dubbed as Mirage, which augments VLM decoding with latent\nvisual tokens alongside ordinary text. Concretely, whenever the model chooses\nto ``think visually'', it recasts its hidden states as next tokens, thereby\ncontinuing a multimodal trajectory without generating pixel-level images. Begin\nby supervising the latent tokens through distillation from ground-truth image\nembeddings, we then switch to text-only supervision to make the latent\ntrajectory align tightly with the task objective. A subsequent reinforcement\nlearning stage further enhances the multimodal reasoning capability.\nExperiments on diverse benchmarks demonstrate that Mirage unlocks stronger\nmultimodal reasoning without explicit image generation.",
      "pdf_url": "http://arxiv.org/pdf/2506.17218v1",
      "published": "2025-06-20T17:59:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.17218v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Long-term Traffic Simulation with Interleaved Autoregressive Motion and Scenario Generation",
      "authors": [
        "Xiuyu Yang",
        "Shuhan Tan",
        "Philipp Krähenbühl"
      ],
      "abstract": "An ideal traffic simulator replicates the realistic long-term point-to-point\ntrip that a self-driving system experiences during deployment. Prior models and\nbenchmarks focus on closed-loop motion simulation for initial agents in a\nscene. This is problematic for long-term simulation. Agents enter and exit the\nscene as the ego vehicle enters new regions. We propose InfGen, a unified\nnext-token prediction model that performs interleaved closed-loop motion\nsimulation and scene generation. InfGen automatically switches between\nclosed-loop motion simulation and scene generation mode. It enables stable\nlong-term rollout simulation. InfGen performs at the state-of-the-art in\nshort-term (9s) traffic simulation, and significantly outperforms all other\nmethods in long-term (30s) simulation. The code and model of InfGen will be\nreleased at https://orangesodahub.github.io/InfGen",
      "pdf_url": "http://arxiv.org/pdf/2506.17213v1",
      "published": "2025-06-20T17:59:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.17213v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ]
    },
    {
      "title": "Part$^{2}$GS: Part-aware Modeling of Articulated Objects using 3D Gaussian Splatting",
      "authors": [
        "Tianjiao Yu",
        "Vedant Shah",
        "Muntasir Wahed",
        "Ying Shen",
        "Kiet A. Nguyen",
        "Ismini Lourentzou"
      ],
      "abstract": "Articulated objects are common in the real world, yet modeling their\nstructure and motion remains a challenging task for 3D reconstruction methods.\nIn this work, we introduce Part$^{2}$GS, a novel framework for modeling\narticulated digital twins of multi-part objects with high-fidelity geometry and\nphysically consistent articulation. Part$^{2}$GS leverages a part-aware 3D\nGaussian representation that encodes articulated components with learnable\nattributes, enabling structured, disentangled transformations that preserve\nhigh-fidelity geometry. To ensure physically consistent motion, we propose a\nmotion-aware canonical representation guided by physics-based constraints,\nincluding contact enforcement, velocity consistency, and vector-field\nalignment. Furthermore, we introduce a field of repel points to prevent part\ncollisions and maintain stable articulation paths, significantly improving\nmotion coherence over baselines. Extensive evaluations on both synthetic and\nreal-world datasets show that Part$^{2}$GS consistently outperforms\nstate-of-the-art methods by up to 10$\\times$ in Chamfer Distance for movable\nparts.",
      "pdf_url": "http://arxiv.org/pdf/2506.17212v1",
      "published": "2025-06-20T17:59:12+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.17212v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ]
    },
    {
      "title": "Dissecting the SWE-Bench Leaderboards: Profiling Submitters and Architectures of LLM- and Agent-Based Repair Systems",
      "authors": [
        "Matias Martinez",
        "Xavier Franch"
      ],
      "abstract": "The rapid progress in Automated Program Repair (APR) has been driven by\nadvances in AI, particularly large language models (LLMs) and agent-based\nsystems. SWE-Bench is a recent benchmark designed to evaluate LLM-based repair\nsystems using real issues and pull requests mined from 12 popular open-source\nPython repositories. Its public leaderboards, SWE-Bench Lite and SWE-Bench\nVerified, have become central platforms for tracking progress and comparing\nsolutions. However, because the submission process does not require detailed\ndocumentation, the architectural design and origin of many solutions remain\nunclear. In this paper, we present the first comprehensive study of all\nsubmissions to the SWE-Bench Lite (68 entries) and Verified (79 entries)\nleaderboards, analyzing 67 unique approaches across dimensions such as\nsubmitter type, product availability, LLM usage, and system architecture. Our\nfindings reveal the dominance of proprietary LLMs (especially Claude 3.5/3.7),\nthe presence of both agentic and non-agentic designs, and a contributor base\nspanning from individual developers to large tech companies.",
      "pdf_url": "http://arxiv.org/pdf/2506.17208v1",
      "published": "2025-06-20T17:57:08+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.17208v1",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Network Sparsity Unlocks the Scaling Potential of Deep Reinforcement Learning",
      "authors": [
        "Guozheng Ma",
        "Lu Li",
        "Zilin Wang",
        "Li Shen",
        "Pierre-Luc Bacon",
        "Dacheng Tao"
      ],
      "abstract": "Effectively scaling up deep reinforcement learning models has proven\nnotoriously difficult due to network pathologies during training, motivating\nvarious targeted interventions such as periodic reset and architectural\nadvances such as layer normalization. Instead of pursuing more complex\nmodifications, we show that introducing static network sparsity alone can\nunlock further scaling potential beyond their dense counterparts with\nstate-of-the-art architectures. This is achieved through simple one-shot random\npruning, where a predetermined percentage of network weights are randomly\nremoved once before training. Our analysis reveals that, in contrast to naively\nscaling up dense DRL networks, such sparse networks achieve both higher\nparameter efficiency for network expressivity and stronger resistance to\noptimization challenges like plasticity loss and gradient interference. We\nfurther extend our evaluation to visual and streaming RL scenarios,\ndemonstrating the consistent benefits of network sparsity.",
      "pdf_url": "http://arxiv.org/pdf/2506.17204v1",
      "published": "2025-06-20T17:54:24+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.17204v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Facial Landmark Visualization and Emotion Recognition Through Neural Networks",
      "authors": [
        "Israel Juárez-Jiménez",
        "Tiffany Guadalupe Martínez Paredes",
        "Jesús García-Ramírez",
        "Eric Ramos Aguilar"
      ],
      "abstract": "Emotion recognition from facial images is a crucial task in human-computer\ninteraction, enabling machines to learn human emotions through facial\nexpressions. Previous studies have shown that facial images can be used to\ntrain deep learning models; however, most of these studies do not include a\nthrough dataset analysis. Visualizing facial landmarks can be challenging when\nextracting meaningful dataset insights; to address this issue, we propose\nfacial landmark box plots, a visualization technique designed to identify\noutliers in facial datasets. Additionally, we compare two sets of facial\nlandmark features: (i) the landmarks' absolute positions and (ii) their\ndisplacements from a neutral expression to the peak of an emotional expression.\nOur results indicate that a neural network achieves better performance than a\nrandom forest classifier.",
      "pdf_url": "http://arxiv.org/pdf/2506.17191v1",
      "published": "2025-06-20T17:45:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.17191v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Towards AI Search Paradigm",
      "authors": [
        "Yuchen Li",
        "Hengyi Cai",
        "Rui Kong",
        "Xinran Chen",
        "Jiamin Chen",
        "Jun Yang",
        "Haojie Zhang",
        "Jiayi Li",
        "Jiayi Wu",
        "Yiqun Chen",
        "Changle Qu",
        "Keyi Kong",
        "Wenwen Ye",
        "Lixin Su",
        "Xinyu Ma",
        "Long Xia",
        "Daiting Shi",
        "Jiashu Zhao",
        "Haoyi Xiong",
        "Shuaiqiang Wang",
        "Dawei Yin"
      ],
      "abstract": "In this paper, we introduce the AI Search Paradigm, a comprehensive blueprint\nfor next-generation search systems capable of emulating human information\nprocessing and decision-making. The paradigm employs a modular architecture of\nfour LLM-powered agents (Master, Planner, Executor and Writer) that dynamically\nadapt to the full spectrum of information needs, from simple factual queries to\ncomplex multi-stage reasoning tasks. These agents collaborate dynamically\nthrough coordinated workflows to evaluate query complexity, decompose problems\ninto executable plans, and orchestrate tool usage, task execution, and content\nsynthesis. We systematically present key methodologies for realizing this\nparadigm, including task planning and tool integration, execution strategies,\naligned and robust retrieval-augmented generation, and efficient LLM inference,\nspanning both algorithmic techniques and infrastructure-level optimizations. By\nproviding an in-depth guide to these foundational components, this work aims to\ninform the development of trustworthy, adaptive, and scalable AI search\nsystems.",
      "pdf_url": "http://arxiv.org/pdf/2506.17188v1",
      "published": "2025-06-20T17:42:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.17188v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ]
    },
    {
      "title": "Continual Learning with Columnar Spiking Neural Networks",
      "authors": [
        "Denis Larionov",
        "Nikolay Bazenkov",
        "Mikhail Kiselev"
      ],
      "abstract": "This study investigates columnar-organized spiking neural networks (SNNs) for\ncontinual learning and catastrophic forgetting. Using CoLaNET (Columnar Layered\nNetwork), we show that microcolumns adapt most efficiently to new tasks when\nthey lack shared structure with prior learning. We demonstrate how CoLaNET\nhyperparameters govern the trade-off between retaining old knowledge\n(stability) and acquiring new information (plasticity). Our optimal\nconfiguration learns ten sequential MNIST tasks effectively, maintaining 92%\naccuracy on each. It shows low forgetting, with only 4% performance degradation\non the first task after training on nine subsequent tasks.",
      "pdf_url": "http://arxiv.org/pdf/2506.17169v1",
      "published": "2025-06-20T17:13:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.17169v1",
      "categories": [
        "cs.NE",
        "cs.AI"
      ]
    },
    {
      "title": "Proportional Sensitivity in Generative Adversarial Network (GAN)-Augmented Brain Tumor Classification Using Convolutional Neural Network",
      "authors": [
        "Mahin Montasir Afif",
        "Abdullah Al Noman",
        "K. M. Tahsin Kabir",
        "Md. Mortuza Ahmmed",
        "Md. Mostafizur Rahman",
        "Mufti Mahmud",
        "Md. Ashraful Babu"
      ],
      "abstract": "Generative Adversarial Networks (GAN) have shown potential in expanding\nlimited medical imaging datasets. This study explores how different ratios of\nGAN-generated and real brain tumor MRI images impact the performance of a CNN\nin classifying healthy vs. tumorous scans. A DCGAN was used to create synthetic\nimages which were mixed with real ones at various ratios to train a custom CNN.\nThe CNN was then evaluated on a separate real-world test set. Our results\nindicate that the model maintains high sensitivity and precision in tumor\nclassification, even when trained predominantly on synthetic data. When only a\nsmall portion of GAN data was added, such as 900 real images and 100 GAN\nimages, the model achieved excellent performance, with test accuracy reaching\n95.2%, and precision, recall, and F1-score all exceeding 95%. However, as the\nproportion of GAN images increased further, performance gradually declined.\nThis study suggests that while GANs are useful for augmenting limited datasets\nespecially when real data is scarce, too much synthetic data can introduce\nartifacts that affect the model's ability to generalize to real world cases.",
      "pdf_url": "http://arxiv.org/pdf/2506.17165v1",
      "published": "2025-06-20T17:12:03+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.17165v1",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "The MedPerturb Dataset: What Non-Content Perturbations Reveal About Human and Clinical LLM Decision Making",
      "authors": [
        "Abinitha Gourabathina",
        "Yuexing Hao",
        "Walter Gerych",
        "Marzyeh Ghassemi"
      ],
      "abstract": "Clinical robustness is critical to the safe deployment of medical Large\nLanguage Models (LLMs), but key questions remain about how LLMs and humans may\ndiffer in response to the real-world variability typified by clinical settings.\nTo address this, we introduce MedPerturb, a dataset designed to systematically\nevaluate medical LLMs under controlled perturbations of clinical input.\nMedPerturb consists of clinical vignettes spanning a range of pathologies, each\ntransformed along three axes: (1) gender modifications (e.g., gender-swapping\nor gender-removal); (2) style variation (e.g., uncertain phrasing or colloquial\ntone); and (3) format changes (e.g., LLM-generated multi-turn conversations or\nsummaries). With MedPerturb, we release a dataset of 800 clinical contexts\ngrounded in realistic input variability, outputs from four LLMs, and three\nhuman expert reads per clinical context. We use MedPerturb in two case studies\nto reveal how shifts in gender identity cues, language style, or format reflect\ndiverging treatment selections between humans and LLMs. We find that LLMs are\nmore sensitive to gender and style perturbations while human annotators are\nmore sensitive to LLM-generated format perturbations such as clinical\nsummaries. Our results highlight the need for evaluation frameworks that go\nbeyond static benchmarks to assess the similarity between human clinician and\nLLM decisions under the variability characteristic of clinical settings.",
      "pdf_url": "http://arxiv.org/pdf/2506.17163v1",
      "published": "2025-06-20T17:09:27+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.17163v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Sparse-Reg: Improving Sample Complexity in Offline Reinforcement Learning using Sparsity",
      "authors": [
        "Samin Yeasar Arnob",
        "Scott Fujimoto",
        "Doina Precup"
      ],
      "abstract": "In this paper, we investigate the use of small datasets in the context of\noffline reinforcement learning (RL). While many common offline RL benchmarks\nemploy datasets with over a million data points, many offline RL applications\nrely on considerably smaller datasets. We show that offline RL algorithms can\noverfit on small datasets, resulting in poor performance. To address this\nchallenge, we introduce \"Sparse-Reg\": a regularization technique based on\nsparsity to mitigate overfitting in offline reinforcement learning, enabling\neffective learning in limited data settings and outperforming state-of-the-art\nbaselines in continuous control.",
      "pdf_url": "http://arxiv.org/pdf/2506.17155v1",
      "published": "2025-06-20T16:57:59+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.17155v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Do We Need Large VLMs for Spotting Soccer Actions?",
      "authors": [
        "Ritabrata Chakraborty",
        "Rajatsubhra Chakraborty",
        "Avijit Dasgupta",
        "Sandeep Chaurasia"
      ],
      "abstract": "Traditional video-based tasks like soccer action spotting rely heavily on\nvisual inputs, often requiring complex and computationally expensive models to\nprocess dense video data. In this work, we propose a shift from this\nvideo-centric approach to a text-based task, making it lightweight and scalable\nby utilizing Large Language Models (LLMs) instead of Vision-Language Models\n(VLMs). We posit that expert commentary, which provides rich, fine-grained\ndescriptions and contextual cues such as excitement and tactical insights,\ncontains enough information to reliably spot key actions in a match. To\ndemonstrate this, we use the SoccerNet Echoes dataset, which provides\ntimestamped commentary, and employ a system of three LLMs acting as judges\nspecializing in outcome, excitement, and tactics. Each LLM evaluates sliding\nwindows of commentary to identify actions like goals, cards, and substitutions,\ngenerating accurate timestamps for these events. Our experiments show that this\nlanguage-centric approach performs effectively in detecting critical match\nevents, providing a lightweight and training-free alternative to traditional\nvideo-based methods for action spotting.",
      "pdf_url": "http://arxiv.org/pdf/2506.17144v1",
      "published": "2025-06-20T16:45:54+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.17144v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "MeDi: Metadata-Guided Diffusion Models for Mitigating Biases in Tumor Classification",
      "authors": [
        "David Jacob Drexlin",
        "Jonas Dippel",
        "Julius Hense",
        "Niklas Prenißl",
        "Grégoire Montavon",
        "Frederick Klauschen",
        "Klaus-Robert Müller"
      ],
      "abstract": "Deep learning models have made significant advances in histological\nprediction tasks in recent years. However, for adaptation in clinical practice,\ntheir lack of robustness to varying conditions such as staining, scanner,\nhospital, and demographics is still a limiting factor: if trained on\noverrepresented subpopulations, models regularly struggle with less frequent\npatterns, leading to shortcut learning and biased predictions. Large-scale\nfoundation models have not fully eliminated this issue. Therefore, we propose a\nnovel approach explicitly modeling such metadata into a Metadata-guided\ngenerative Diffusion model framework (MeDi). MeDi allows for a targeted\naugmentation of underrepresented subpopulations with synthetic data, which\nbalances limited training data and mitigates biases in downstream models. We\nexperimentally show that MeDi generates high-quality histopathology images for\nunseen subpopulations in TCGA, boosts the overall fidelity of the generated\nimages, and enables improvements in performance for downstream classifiers on\ndatasets with subpopulation shifts. Our work is a proof-of-concept towards\nbetter mitigating data biases with generative models.",
      "pdf_url": "http://arxiv.org/pdf/2506.17140v1",
      "published": "2025-06-20T16:41:25+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.17140v1",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Consistent Sampling and Simulation: Molecular Dynamics with Energy-Based Diffusion Models",
      "authors": [
        "Michael Plainer",
        "Hao Wu",
        "Leon Klein",
        "Stephan Günnemann",
        "Frank Noé"
      ],
      "abstract": "Diffusion models have recently gained significant attention due to their\neffectiveness in various scientific domains, including biochemistry. When\ntrained on equilibrium molecular distributions, diffusion models provide both:\na generative procedure to sample equilibrium conformations and associated\nforces derived from the model's scores. However, using the forces for\ncoarse-grained molecular dynamics simulations uncovers inconsistencies in the\nsamples generated via classical diffusion inference and simulation, despite\nboth originating from the same model. Particularly at the small diffusion\ntimesteps required for simulations, diffusion models fail to satisfy the\nFokker-Planck equation, which governs how the score should evolve over time. We\ninterpret this deviation as an indication of the observed inconsistencies and\npropose an energy-based diffusion model with a Fokker-Planck-derived\nregularization term enforcing consistency. We demonstrate the effectiveness of\nour approach on toy systems, alanine dipeptide, and introduce a\nstate-of-the-art transferable Boltzmann emulator for dipeptides that supports\nsimulation and demonstrates enhanced consistency and efficient sampling.",
      "pdf_url": "http://arxiv.org/pdf/2506.17139v1",
      "published": "2025-06-20T16:38:29+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.17139v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.chem-ph",
        "physics.comp-ph",
        "stat.ML"
      ]
    },
    {
      "title": "Robust Training with Data Augmentation for Medical Imaging Classification",
      "authors": [
        "Josué Martínez-Martínez",
        "Olivia Brown",
        "Mostafa Karami",
        "Sheida Nabavi"
      ],
      "abstract": "Deep neural networks are increasingly being used to detect and diagnose\nmedical conditions using medical imaging. Despite their utility, these models\nare highly vulnerable to adversarial attacks and distribution shifts, which can\naffect diagnostic reliability and undermine trust among healthcare\nprofessionals. In this study, we propose a robust training algorithm with data\naugmentation (RTDA) to mitigate these vulnerabilities in medical image\nclassification. We benchmark classifier robustness against adversarial\nperturbations and natural variations of RTDA and six competing baseline\ntechniques, including adversarial training and data augmentation approaches in\nisolation and combination, using experimental data sets with three different\nimaging technologies (mammograms, X-rays, and ultrasound). We demonstrate that\nRTDA achieves superior robustness against adversarial attacks and improved\ngeneralization performance in the presence of distribution shift in each image\nclassification task while maintaining high clean accuracy.",
      "pdf_url": "http://arxiv.org/pdf/2506.17133v1",
      "published": "2025-06-20T16:36:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.17133v1",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ]
    },
    {
      "title": "Chain-of-Trust: A Progressive Trust Evaluation Framework Enabled by Generative AI",
      "authors": [
        "Botao Zhu",
        "Xianbin Wang",
        "Lei Zhang",
        "Xuemin",
        "Shen"
      ],
      "abstract": "In collaborative systems with complex tasks relying on distributed resources,\ntrust evaluation of potential collaborators has emerged as an effective\nmechanism for task completion. However, due to the network dynamics and varying\ninformation gathering latencies, it is extremely challenging to observe and\ncollect all trust attributes of a collaborating device concurrently for a\ncomprehensive trust assessment. In this paper, a novel progressive trust\nevaluation framework, namely chain-of-trust, is proposed to make better use of\nmisaligned device attribute data. This framework, designed for effective task\ncompletion, divides the trust evaluation process into multiple chained stages\nbased on task decomposition. At each stage, based on the task completion\nprocess, the framework only gathers the latest device attribute data relevant\nto that stage, leading to reduced trust evaluation complexity and overhead. By\nleveraging advanced in-context learning, few-shot learning, and reasoning\ncapabilities, generative AI is then employed to analyze and interpret the\ncollected data to produce correct evaluation results quickly. Only devices\ndeemed trustworthy at this stage proceed to the next round of trust evaluation.\nThe framework ultimately determines devices that remain trustworthy across all\nstages. Experimental results demonstrate that the proposed framework achieves\nhigh accuracy in trust evaluation.",
      "pdf_url": "http://arxiv.org/pdf/2506.17130v1",
      "published": "2025-06-20T16:33:03+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.17130v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Rapid and Continuous Trust Evaluation for Effective Task Collaboration Through Siamese Model",
      "authors": [
        "Botao Zhu",
        "Xianbin Wang"
      ],
      "abstract": "Trust is emerging as an effective tool to ensure the successful completion of\ncollaborative tasks within collaborative systems. However, rapidly and\ncontinuously evaluating the trustworthiness of collaborators during task\nexecution is a significant challenge due to distributed devices, complex\noperational environments, and dynamically changing resources. To tackle this\nchallenge, this paper proposes a Siamese-enabled rapid and continuous trust\nevaluation framework (SRCTE) to facilitate effective task collaboration. First,\nthe communication and computing resource attributes of the collaborator in a\ntrusted state, along with historical collaboration data, are collected and\nrepresented using an attributed control flow graph (ACFG) that captures\ntrust-related semantic information and serves as a reference for comparison\nwith data collected during task execution. At each time slot of task execution,\nthe collaborator's communication and computing resource attributes, as well as\ntask completion effectiveness, are collected in real time and represented with\nan ACFG to convey their trust-related semantic information. A Siamese model,\nconsisting of two shared-parameter Structure2vec networks, is then employed to\nlearn the deep semantics of each pair of ACFGs and generate their embeddings.\nFinally, the similarity between the embeddings of each pair of ACFGs is\ncalculated to determine the collaborator's trust value at each time slot. A\nreal system is built using two Dell EMC 5200 servers and a Google Pixel 8 to\ntest the effectiveness of the proposed SRCTE framework. Experimental results\ndemonstrate that SRCTE converges rapidly with only a small amount of data and\nachieves a high anomaly trust detection rate compared to the baseline\nalgorithm.",
      "pdf_url": "http://arxiv.org/pdf/2506.17128v1",
      "published": "2025-06-20T16:30:59+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.17128v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "When Can Model-Free Reinforcement Learning be Enough for Thinking?",
      "authors": [
        "Josiah P. Hanna",
        "Nicholas E. Corrado"
      ],
      "abstract": "Recent work on large language models has demonstrated the use of model-free\nreinforcement learning (RL) to train reasoning-like capabilities. The emergence\nof \"thinking\" through model-free RL is interesting as thinking actions neither\nproduce reward nor change the external world state to one where the agent is\nmore likely to get reward. This paper seeks to build a domain-independent\nunderstanding of when model-free RL will lead to \"thinking\" as a strategy for\nreward maximization. To build this understanding, we first introduce a\ntheoretical model which we call a \\textit{thought Markov decision process}\n(MDP). Thought MDPs minimally extend the classical MDP model to include an\nabstract notion of thought state and thought action. Using the thought MDP\nmodel, we prove the importance of policy initialization in determining whether\nor not thinking emerges and show formally that thought actions are equivalent\nto the agent choosing to perform a step of policy improvement before continuing\nto act. We then show that open-source LLMs satisfy the conditions that our\ntheory predicts are necessary for model-free RL to produce thinking-like\nbehavior. Finally, we hypothesize sufficient conditions that would enable\nthinking to be learned outside of language generation and introduce a toy\ndomain where a combination of multi-task pre-training and designated thought\nactions enable more data-efficient RL compared to non-thinking agents.",
      "pdf_url": "http://arxiv.org/pdf/2506.17124v1",
      "published": "2025-06-20T16:23:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.17124v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Mathematical Proof as a Litmus Test: Revealing Failure Modes of Advanced Large Reasoning Models",
      "authors": [
        "Dadi Guo",
        "Jiayu Liu",
        "Zhiyuan Fan",
        "Zhitao He",
        "Haoran Li",
        "Yumeng Wang",
        "Yi R.",
        "Fung"
      ],
      "abstract": "Large reasoning models (e.g., R1, o3) have demonstrated remarkable\nmathematical problem-solving abilities. However, the high reported accuracy of\nthese advanced models on popular datasets, reliance on purely numerical\nevaluation and potential benchmark leakage, often masks their true reasoning\nshortcomings. To address this, we propose leveraging the inherent rigor and\nmethodological complexity of mathematical proofs as a diagnostic tool to expose\nthese hidden failures. Specifically, we introduce the RFMDataset (Reveal\nFailure Modes), a collection of 200 diverse mathematical proof problems, and\nthoroughly evaluate advanced models' performance on it. Our in-depth analysis\nof their failures uncovers 10 fine-grained error types, which shows fundamental\nlimitations in current large reasoning models: 1) large reasoning models\ngrapple profoundly with mathematical proofs, with some generating entirely\ncorrect proofs for less than 20% of problems and failing even on basic ones; 2)\nmodels exhibit a diverse spectrum of reasoning failures, prominently\ndemonstrating the lack of guarantees for the correctness and rigor of\nsingle-step reasoning; and 3) models show hallucination and incompleteness\nduring the reasoning process. Our findings reveal that models' self-reflection\nis insufficient to resolve the current logical dilemmas, necessitating\nformalized and fine-grained logical training.",
      "pdf_url": "http://arxiv.org/pdf/2506.17114v1",
      "published": "2025-06-20T16:14:18+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.17114v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "MEXA: Towards General Multimodal Reasoning with Dynamic Multi-Expert Aggregation",
      "authors": [
        "Shoubin Yu",
        "Yue Zhang",
        "Ziyang Wang",
        "Jaehong Yoon",
        "Mohit Bansal"
      ],
      "abstract": "Combining pre-trained expert models offers substantial potential for scalable\nmultimodal reasoning, but building a unified framework remains challenging due\nto the increasing diversity of input modalities and task complexity. For\ninstance, medical diagnosis requires precise reasoning over structured clinical\ntables, while financial forecasting depends on interpreting plot-based data to\nmake informed predictions. To tackle this challenge, we introduce MEXA, a\ntraining-free framework that performs modality- and task-aware aggregation of\nmultiple expert models to enable effective multimodal reasoning across diverse\nand distinct domains. MEXA dynamically selects expert models based on the input\nmodality and the task-specific reasoning demands (i.e., skills). Each expert\nmodel, specialized in a modality task pair, generates interpretable textual\nreasoning outputs. MEXA then aggregates and reasons over these outputs using a\nLarge Reasoning Model (LRM) to produce the final answer. This modular design\nallows flexible and transparent multimodal reasoning across diverse domains\nwithout additional training overhead. We extensively evaluate our approach on\ndiverse multimodal benchmarks, including Video Reasoning, Audio Reasoning, 3D\nUnderstanding, and Medical QA. MEXA consistently delivers performance\nimprovements over strong multimodal baselines, highlighting the effectiveness\nand broad applicability of our expert-driven selection and aggregation in\ndiverse multimodal reasoning tasks.",
      "pdf_url": "http://arxiv.org/pdf/2506.17113v1",
      "published": "2025-06-20T16:14:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.17113v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Are Bias Evaluation Methods Biased ?",
      "authors": [
        "Lina Berrayana",
        "Sean Rooney",
        "Luis Garcés-Erice",
        "Ioana Giurgiu"
      ],
      "abstract": "The creation of benchmarks to evaluate the safety of Large Language Models is\none of the key activities within the trusted AI community. These benchmarks\nallow models to be compared for different aspects of safety such as toxicity,\nbias, harmful behavior etc. Independent benchmarks adopt different approaches\nwith distinct data sets and evaluation methods. We investigate how robust such\nbenchmarks are by using different approaches to rank a set of representative\nmodels for bias and compare how similar are the overall rankings. We show that\ndifferent but widely used bias evaluations methods result in disparate model\nrankings. We conclude with recommendations for the community in the usage of\nsuch benchmarks.",
      "pdf_url": "http://arxiv.org/pdf/2506.17111v1",
      "published": "2025-06-20T16:11:25+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.17111v1",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Towards Advanced Mathematical Reasoning for LLMs via First-Order Logic Theorem Proving",
      "authors": [
        "Chuxue Cao",
        "Mengze Li",
        "Juntao Dai",
        "Jinluan Yang",
        "Zijian Zhao",
        "Shengyu Zhang",
        "Weijie Shi",
        "Chengzhong Liu",
        "Sirui Han",
        "Yike Guo"
      ],
      "abstract": "Large language models (LLMs) have shown promising first-order logic (FOL)\nreasoning capabilities with applications in various areas. However, their\neffectiveness in complex mathematical reasoning involving multi-step FOL\ndeductions is still under-researched. While LLMs perform competitively on\nestablished mathematical reasoning benchmarks, they struggle with multi-step\nFOL tasks, as demonstrated by Deepseek-Prover-V2-7B's low accuracy (4.2%) on\nour proposed theorem proving dataset. This issue arises from the limited\nexploration of diverse proof strategies and the potential for early reasoning\nmistakes to undermine entire proofs. To address these issues, we propose DREAM,\na self-adaptive solution that enhances the Diversity and REAsonability of LLMs'\ngeneration strategies. DREAM incorporates an Axiom-Driven Strategy\nDiversification mechanism to promote varied strategic outcomes and a\nSub-Proposition Error Feedback to help LLMs reflect on and correct their\nproofs. Our contributions include pioneering advancements in LLMs' mathematical\nreasoning through FOL theorem proving, introducing a novel inference stage\nsolution that improves performance by 0.6% to 6.4%, and providing a curated\ndataset of 447 mathematical theorems in Lean 4 format for evaluation.",
      "pdf_url": "http://arxiv.org/pdf/2506.17104v1",
      "published": "2025-06-20T16:09:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.17104v1",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LO"
      ]
    },
    {
      "title": "TransDreamerV3: Implanting Transformer In DreamerV3",
      "authors": [
        "Shruti Sadanand Dongare",
        "Amun Kharel",
        "Jonathan Samuel",
        "Xiaona Zhou"
      ],
      "abstract": "This paper introduces TransDreamerV3, a reinforcement learning model that\nenhances the DreamerV3 architecture by integrating a transformer encoder. The\nmodel is designed to improve memory and decision-making capabilities in complex\nenvironments. We conducted experiments on Atari-Boxing, Atari-Freeway,\nAtari-Pong, and Crafter tasks, where TransDreamerV3 demonstrated improved\nperformance over DreamerV3, particularly in the Atari-Freeway and Crafter\ntasks. While issues in the Minecraft task and limited training across all tasks\nwere noted, TransDreamerV3 displays advancement in world model-based\nreinforcement learning, leveraging transformer architectures.",
      "pdf_url": "http://arxiv.org/pdf/2506.17103v1",
      "published": "2025-06-20T16:09:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.17103v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Identifiability of Deep Polynomial Neural Networks",
      "authors": [
        "Konstantin Usevich",
        "Clara Dérand",
        "Ricardo Borsoi",
        "Marianne Clausel"
      ],
      "abstract": "Polynomial Neural Networks (PNNs) possess a rich algebraic and geometric\nstructure. However, their identifiability -- a key property for ensuring\ninterpretability -- remains poorly understood. In this work, we present a\ncomprehensive analysis of the identifiability of deep PNNs, including\narchitectures with and without bias terms. Our results reveal an intricate\ninterplay between activation degrees and layer widths in achieving\nidentifiability. As special cases, we show that architectures with\nnon-increasing layer widths are generically identifiable under mild conditions,\nwhile encoder-decoder networks are identifiable when the decoder widths do not\ngrow too rapidly. Our proofs are constructive and center on a connection\nbetween deep PNNs and low-rank tensor decompositions, and Kruskal-type\nuniqueness theorems. This yields both generic conditions determined by the\narchitecture, and effective conditions that depend on the network's parameters.\nWe also settle an open conjecture on the expected dimension of PNN's\nneurovarieties, and provide new bounds on the activation degrees required for\nit to reach its maximum.",
      "pdf_url": "http://arxiv.org/pdf/2506.17093v1",
      "published": "2025-06-20T15:58:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.17093v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.AG",
        "stat.ML",
        "68T07, 62R01, 15A69, 14M99"
      ]
    },
    {
      "title": "Dispositions and Roles of Generically Dependent Entities",
      "authors": [
        "Fabian Neuhaus"
      ],
      "abstract": "BFO 2020 does not support functions, dispositions, and roles of generically\ndependent continuants (like software or datasets). In this paper, we argue that\nthis is a severe limitation, which prevents, for example, the adequate\nrepresentation of the functions of computer models or the various roles of\ndatasets during the execution of these models. We discuss the aspects of BFO\n2020 that prevent the representation of realizable entities of generically\ndependent continuants. Two approaches to address the issue are presented: (a)\nthe use of defined classes and (b) a proposal of changes that allow BFO to\nsupport functions, dispositions, and roles of generically dependent\ncontinuants.",
      "pdf_url": "http://arxiv.org/pdf/2506.17085v1",
      "published": "2025-06-20T15:40:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.17085v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Tower+: Bridging Generality and Translation Specialization in Multilingual LLMs",
      "authors": [
        "Ricardo Rei",
        "Nuno M. Guerreiro",
        "José Pombal",
        "João Alves",
        "Pedro Teixeirinha",
        "Amin Farajian",
        "André F. T. Martins"
      ],
      "abstract": "Fine-tuning pretrained LLMs has been shown to be an effective strategy for\nreaching state-of-the-art performance on specific tasks like machine\ntranslation. However, this process of adaptation often implies sacrificing\ngeneral-purpose capabilities, such as conversational reasoning and\ninstruction-following, hampering the utility of the system in real-world\napplications that require a mixture of skills. In this paper, we introduce\nTower+, a suite of models designed to deliver strong performance across both\ntranslation and multilingual general-purpose text capabilities. We achieve a\nPareto frontier between translation specialization and multilingual\ngeneral-purpose capabilities by introducing a novel training recipe that builds\non Tower (Alves et al., 2024), comprising continued pretraining, supervised\nfine-tuning, preference optimization, and reinforcement learning with\nverifiable rewards. At each stage of training, we carefully generate and curate\ndata to strengthen performance on translation as well as general-purpose tasks\ninvolving code generation, mathematics problem solving, and general\ninstruction-following. We develop models at multiple scales: 2B, 9B, and 72B.\nOur smaller models often outperform larger general-purpose open-weight and\nproprietary LLMs (e.g., Llama 3.3 70B, GPT-4o). Our largest model delivers\nbest-in-class translation performance for high-resource languages and top\nresults in multilingual Arena Hard evaluations and in IF-MT, a benchmark we\nintroduce for evaluating both translation and instruction-following. Our\nfindings highlight that it is possible to rival frontier models in general\ncapabilities, while optimizing for specific business domains, such as\ntranslation and localization.",
      "pdf_url": "http://arxiv.org/pdf/2506.17080v1",
      "published": "2025-06-20T15:30:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.17080v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "LLM-Based Bot Broadens the Range of Arguments in Online Discussions, Even When Transparently Disclosed as AI",
      "authors": [
        "Valeria Vuk",
        "Cristina Sarasua",
        "Fabrizio Gilardi"
      ],
      "abstract": "A wide range of participation is essential for democracy, as it helps prevent\nthe dominance of extreme views, erosion of legitimacy, and political\npolarization. However, engagement in online political discussions often\nfeatures a limited spectrum of views due to high levels of self-selection and\nthe tendency of online platforms to facilitate exchanges primarily among\nlike-minded individuals. This study examines whether an LLM-based bot can widen\nthe scope of perspectives expressed by participants in online discussions\nthrough two pre-registered randomized experiments conducted in a chatroom. We\nevaluate the impact of a bot that actively monitors discussions, identifies\nmissing arguments, and introduces them into the conversation. The results\nindicate that our bot significantly expands the range of arguments, as measured\nby both objective and subjective metrics. Furthermore, disclosure of the bot as\nAI does not significantly alter these effects. These findings suggest that\nLLM-based moderation tools can positively influence online political discourse.",
      "pdf_url": "http://arxiv.org/pdf/2506.17073v1",
      "published": "2025-06-20T15:24:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.17073v1",
      "categories": [
        "cs.CY",
        "cs.AI"
      ]
    },
    {
      "title": "Flow-Based Non-stationary Temporal Regime Causal Structure Learning",
      "authors": [
        "Abdellah Rahmani",
        "Pascal Frossard"
      ],
      "abstract": "Understanding causal relationships in multivariate time series is crucial in\nmany scenarios, such as those dealing with financial or neurological data. Many\nsuch time series exhibit multiple regimes, i.e., consecutive temporal segments\nwith a priori unknown boundaries, with each regime having its own causal\nstructure. Inferring causal dependencies and regime shifts is critical for\nanalyzing the underlying processes. However, causal structure learning in this\nsetting is challenging due to (1) non stationarity, i.e., each regime can have\nits own causal graph and mixing function, and (2) complex noise distributions,\nwhich may be non Gaussian or heteroscedastic. Existing causal discovery\napproaches cannot address these challenges, since generally assume stationarity\nor Gaussian noise with constant variance. Hence, we introduce FANTOM, a unified\nframework for causal discovery that handles non stationary processes along with\nnon Gaussian and heteroscedastic noises. FANTOM simultaneously infers the\nnumber of regimes and their corresponding indices and learns each regime's\nDirected Acyclic Graph. It uses a Bayesian Expectation Maximization algorithm\nthat maximizes the evidence lower bound of the data log likelihood. On the\ntheoretical side, we prove, under mild assumptions, that temporal\nheteroscedastic causal models, introduced in FANTOM's formulation, are\nidentifiable in both stationary and non stationary settings. In addition,\nextensive experiments on synthetic and real data show that FANTOM outperforms\nexisting methods.",
      "pdf_url": "http://arxiv.org/pdf/2506.17065v1",
      "published": "2025-06-20T15:12:43+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.17065v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "From Concepts to Components: Concept-Agnostic Attention Module Discovery in Transformers",
      "authors": [
        "Jingtong Su",
        "Julia Kempe",
        "Karen Ullrich"
      ],
      "abstract": "Transformers have achieved state-of-the-art performance across language and\nvision tasks. This success drives the imperative to interpret their internal\nmechanisms with the dual goals of enhancing performance and improving\nbehavioral control. Attribution methods help advance interpretability by\nassigning model outputs associated with a target concept to specific model\ncomponents. Current attribution research primarily studies multi-layer\nperceptron neurons and addresses relatively simple concepts such as factual\nassociations (e.g., Paris is located in France). This focus tends to overlook\nthe impact of the attention mechanism and lacks a unified approach for\nanalyzing more complex concepts. To fill these gaps, we introduce Scalable\nAttention Module Discovery (SAMD), a concept-agnostic method for mapping\narbitrary, complex concepts to specific attention heads of general transformer\nmodels. We accomplish this by representing each concept as a vector,\ncalculating its cosine similarity with each attention head, and selecting the\nTopK-scoring heads to construct the concept-associated attention module. We\nthen propose Scalar Attention Module Intervention (SAMI), a simple strategy to\ndiminish or amplify the effects of a concept by adjusting the attention module\nusing only a single scalar parameter. Empirically, we demonstrate SAMD on\nconcepts of varying complexity, and visualize the locations of their\ncorresponding modules. Our results demonstrate that module locations remain\nstable before and after LLM post-training, and confirm prior work on the\nmechanics of LLM multilingualism. Through SAMI, we facilitate jailbreaking on\nHarmBench (+72.7%) by diminishing \"safety\" and improve performance on the GSM8K\nbenchmark (+1.6%) by amplifying \"reasoning\". Lastly, we highlight the\ndomain-agnostic nature of our approach by suppressing the image classification\naccuracy of vision transformers on ImageNet.",
      "pdf_url": "http://arxiv.org/pdf/2506.17052v1",
      "published": "2025-06-20T15:04:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.17052v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "MAWIFlow Benchmark: Realistic Flow-Based Evaluation for Network Intrusion Detection",
      "authors": [
        "Joshua Schraven",
        "Alexander Windmann",
        "Oliver Niggemann"
      ],
      "abstract": "Benchmark datasets for network intrusion detection commonly rely on\nsynthetically generated traffic, which fails to reflect the statistical\nvariability and temporal drift encountered in operational environments. This\npaper introduces MAWIFlow, a flow-based benchmark derived from the MAWILAB v1.1\ndataset, designed to enable realistic and reproducible evaluation of anomaly\ndetection methods. A reproducible preprocessing pipeline is presented that\ntransforms raw packet captures into flow representations conforming to the\nCICFlowMeter format, while preserving MAWILab's original anomaly labels. The\nresulting datasets comprise temporally distinct samples from January 2011,\n2016, and 2021, drawn from trans-Pacific backbone traffic.\n  To establish reference baselines, traditional machine learning methods,\nincluding Decision Trees, Random Forests, XGBoost, and Logistic Regression, are\ncompared to a deep learning model based on a CNN-BiLSTM architecture. Empirical\nresults demonstrate that tree-based classifiers perform well on temporally\nstatic data but experience significant performance degradation over time. In\ncontrast, the CNN-BiLSTM model maintains better performance, thus showing\nimproved generalization. These findings underscore the limitations of synthetic\nbenchmarks and static models, and motivate the adoption of realistic datasets\nwith explicit temporal structure. All datasets, pipeline code, and model\nimplementations are made publicly available to foster transparency and\nreproducibility.",
      "pdf_url": "http://arxiv.org/pdf/2506.17041v1",
      "published": "2025-06-20T14:51:35+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.17041v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "LSCD: Lomb-Scargle Conditioned Diffusion for Time series Imputation",
      "authors": [
        "Elizabeth Fons",
        "Alejandro Sztrajman",
        "Yousef El-Laham",
        "Luciana Ferrer",
        "Svitlana Vyetrenko",
        "Manuela Veloso"
      ],
      "abstract": "Time series with missing or irregularly sampled data are a persistent\nchallenge in machine learning. Many methods operate on the frequency-domain,\nrelying on the Fast Fourier Transform (FFT) which assumes uniform sampling,\ntherefore requiring prior interpolation that can distort the spectra. To\naddress this limitation, we introduce a differentiable Lomb--Scargle layer that\nenables a reliable computation of the power spectrum of irregularly sampled\ndata. We integrate this layer into a novel score-based diffusion model (LSCD)\nfor time series imputation conditioned on the entire signal spectrum.\nExperiments on synthetic and real-world benchmarks demonstrate that our method\nrecovers missing data more accurately than purely time-domain baselines, while\nsimultaneously producing consistent frequency estimates. Crucially, our method\ncan be easily integrated into learning frameworks, enabling broader adoption of\nspectral guidance in machine learning approaches involving incomplete or\nirregular data.",
      "pdf_url": "http://arxiv.org/pdf/2506.17039v1",
      "published": "2025-06-20T14:48:42+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.17039v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Instituto de Telecomunicações at IWSLT 2025: Aligning Small-Scale Speech and Language Models for Speech-to-Text Learning",
      "authors": [
        "Giuseppe Attanasio",
        "Sonal Sannigrahi",
        "Ben Peters",
        "André F. T. Martins"
      ],
      "abstract": "This paper presents the IT-IST submission to the IWSLT 2025 Shared Task on\nInstruction Following Speech Processing. We submit results for the Short Track,\ni.e., speech recognition, translation, and spoken question answering. Our model\nis a unified speech-to-text model that integrates a pre-trained continuous\nspeech encoder and text decoder through a first phase of modality alignment and\na second phase of instruction fine-tuning. Crucially, we focus on using\nsmall-scale language model backbones (< 2B) and restrict to high-quality, CC-BY\ndata along with synthetic data generation to supplement existing resources.",
      "pdf_url": "http://arxiv.org/pdf/2506.17019v1",
      "published": "2025-06-20T14:17:42+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.17019v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "A Quantile Regression Approach for Remaining Useful Life Estimation with State Space Models",
      "authors": [
        "Davide Frizzo",
        "Francesco Borsatti",
        "Gian Antonio Susto"
      ],
      "abstract": "Predictive Maintenance (PdM) is pivotal in Industry 4.0 and 5.0, proactively\nenhancing efficiency through accurate equipment Remaining Useful Life (RUL)\nprediction, thus optimizing maintenance scheduling and reducing unexpected\nfailures and premature interventions. This paper introduces a novel RUL\nestimation approach leveraging State Space Models (SSM) for efficient long-term\nsequence modeling. To handle model uncertainty, Simoultaneous Quantile\nRegression (SQR) is integrated into the SSM, enabling multiple quantile\nestimations. The proposed method is benchmarked against traditional sequence\nmodelling techniques (LSTM, Transformer, Informer) using the C-MAPSS dataset.\nResults demonstrate superior accuracy and computational efficiency of SSM\nmodels, underscoring their potential for high-stakes industrial applications.",
      "pdf_url": "http://arxiv.org/pdf/2506.17018v1",
      "published": "2025-06-20T14:15:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.17018v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Elevating Styled Mahjong Agents with Learning from Demonstration",
      "authors": [
        "Lingfeng Li",
        "Yunlong Lu",
        "Yongyi Wang",
        "Wenxin Li"
      ],
      "abstract": "A wide variety of bots in games enriches the gameplay experience and enhances\nreplayability. Recent advancements in game artificial intelligence have\npredominantly focused on improving the proficiency of bots. Nevertheless,\ndeveloping highly competent bots with a wide range of distinct play styles\nremains a relatively under-explored area. We select the Mahjong game\nenvironment as a case study. The high degree of randomness inherent in the\nMahjong game and the prevalence of out-of-distribution states lead to\nsuboptimal performance of existing offline learning and\nLearning-from-Demonstration (LfD) algorithms. In this paper, we leverage the\ngameplay histories of existing Mahjong agents and put forward a novel LfD\nalgorithm that necessitates only minimal modifications to the Proximal Policy\nOptimization algorithm. The comprehensive empirical results illustrate that our\nproposed method not only significantly enhances the proficiency of the agents\nbut also effectively preserves their unique play styles.",
      "pdf_url": "http://arxiv.org/pdf/2506.16995v1",
      "published": "2025-06-20T13:46:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.16995v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "TeXpert: A Multi-Level Benchmark for Evaluating LaTeX Code Generation by LLMs",
      "authors": [
        "Sahil Kale",
        "Vijaykant Nadadur"
      ],
      "abstract": "LaTeX's precision and flexibility in typesetting have made it the gold\nstandard for the preparation of scientific documentation. Large Language Models\n(LLMs) present a promising opportunity for researchers to produce\npublication-ready material using LaTeX with natural language instructions, yet\ncurrent benchmarks completely lack evaluation of this ability. By introducing\nTeXpert, our benchmark dataset with natural language prompts for generating\nLaTeX code focused on components of scientific documents across multiple\ndifficulty levels, we conduct an in-depth analysis of LLM performance in this\nregard and identify frequent error types. Our evaluation across open and\nclosed-source LLMs highlights multiple key findings: LLMs excelling on standard\nbenchmarks perform poorly in LaTeX generation with a significant accuracy\ndrop-off as the complexity of tasks increases; open-source models like DeepSeek\nv3 and DeepSeek Coder strongly rival closed-source counterparts in LaTeX tasks;\nand formatting and package errors are unexpectedly prevalent, suggesting a lack\nof diverse LaTeX examples in the training datasets of most LLMs. Our dataset,\ncode, and model evaluations are available at\nhttps://github.com/knowledge-verse-ai/TeXpert.",
      "pdf_url": "http://arxiv.org/pdf/2506.16990v1",
      "published": "2025-06-20T13:39:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.16990v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Language Bottleneck Models: A Framework for Interpretable Knowledge Tracing and Beyond",
      "authors": [
        "Antonin Berthon",
        "Mihaela van der Schaar"
      ],
      "abstract": "Accurately assessing student knowledge is critical for effective education,\nyet traditional Knowledge Tracing (KT) methods rely on opaque latent\nembeddings, limiting interpretability. Even LLM-based approaches generate\ndirect predictions or summaries that may hallucinate without any accuracy\nguarantees. We recast KT as an inverse problem: learning the minimum\nnatural-language summary that makes past answers explainable and future answers\npredictable. Our Language Bottleneck Model (LBM) consists of an encoder LLM\nthat writes an interpretable knowledge summary and a frozen decoder LLM that\nmust reconstruct and predict student responses using only that summary text. By\nconstraining all predictive information to pass through a short\nnatural-language bottleneck, LBMs ensure that the summary contains accurate\ninformation while remaining human-interpretable. Experiments on synthetic\narithmetic benchmarks and the large-scale Eedi dataset show that LBMs rival the\naccuracy of state-of-the-art KT and direct LLM methods while requiring\norders-of-magnitude fewer student trajectories. We demonstrate that training\nthe encoder with group-relative policy optimization, using downstream decoding\naccuracy as a reward signal, effectively improves summary quality.",
      "pdf_url": "http://arxiv.org/pdf/2506.16982v1",
      "published": "2025-06-20T13:21:14+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.16982v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Latent Concept Disentanglement in Transformer-based Language Models",
      "authors": [
        "Guan Zhe Hong",
        "Bhavya Vasudeva",
        "Vatsal Sharan",
        "Cyrus Rashtchian",
        "Prabhakar Raghavan",
        "Rina Panigrahy"
      ],
      "abstract": "When large language models (LLMs) use in-context learning (ICL) to solve a\nnew task, they seem to grasp not only the goal of the task but also core,\nlatent concepts in the demonstration examples. This begs the question of\nwhether transformers represent latent structures as part of their computation\nor whether they take shortcuts to solve the problem. Prior mechanistic work on\nICL does not address this question because it does not sufficiently examine the\nrelationship between the learned representation and the latent concept, and the\nconsidered problem settings often involve only single-step reasoning. In this\nwork, we examine how transformers disentangle and use latent concepts. We show\nthat in 2-hop reasoning tasks with a latent, discrete concept, the model\nsuccessfully identifies the latent concept and does step-by-step concept\ncomposition. In tasks parameterized by a continuous latent concept, we find\nlow-dimensional subspaces in the representation space where the geometry mimics\nthe underlying parameterization. Together, these results refine our\nunderstanding of ICL and the representation of transformers, and they provide\nevidence for highly localized structures in the model that disentangle latent\nconcepts in ICL tasks.",
      "pdf_url": "http://arxiv.org/pdf/2506.16975v1",
      "published": "2025-06-20T13:08:12+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.16975v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Formal Control for Uncertain Systems via Contract-Based Probabilistic Surrogates (Extended Version)",
      "authors": [
        "Oliver Schön",
        "Sofie Haesaert",
        "Sadegh Soudjani"
      ],
      "abstract": "The requirement for identifying accurate system representations has not only\nbeen a challenge to fulfill, but it has compromised the scalability of formal\nmethods, as the resulting models are often too complex for effective decision\nmaking with formal correctness and performance guarantees. Focusing on\nprobabilistic simulation relations and surrogate models of stochastic systems,\nwe propose an approach that significantly enhances the scalability and\npractical applicability of such simulation relations by eliminating the need to\ncompute error bounds directly. As a result, we provide an abstraction-based\ntechnique that scales effectively to higher dimensions while addressing complex\nnonlinear agent-environment interactions with infinite-horizon temporal logic\nguarantees amidst uncertainty. Our approach trades scalability for conservatism\nfavorably, as demonstrated on a complex high-dimensional vehicle intersection\ncase study.",
      "pdf_url": "http://arxiv.org/pdf/2506.16971v1",
      "published": "2025-06-20T13:00:50+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.16971v1",
      "categories": [
        "cs.SY",
        "cs.AI",
        "cs.MA",
        "eess.SY"
      ]
    },
    {
      "title": "Enhancing Step-by-Step and Verifiable Medical Reasoning in MLLMs",
      "authors": [
        "Haoran Sun",
        "Yankai Jiang",
        "Wenjie Lou",
        "Yujie Zhang",
        "Wenjie Li",
        "Lilong Wang",
        "Mianxin Liu",
        "Lei Liu",
        "Xiaosong Wang"
      ],
      "abstract": "Multimodal large language models (MLLMs) have begun to demonstrate robust\nreasoning capabilities on general tasks, yet their application in the medical\ndomain remains in its early stages. Constructing chain-of-thought (CoT)\ntraining data is essential for bolstering the reasoning abilities of medical\nMLLMs. However, existing approaches exhibit a deficiency in offering a\ncomprehensive framework for searching and evaluating effective reasoning paths\ntowards critical diagnosis. To address this challenge, we propose Mentor-Intern\nCollaborative Search (MICS), a novel reasoning-path searching scheme to\ngenerate rigorous and effective medical CoT data. MICS first leverages mentor\nmodels to initialize the reasoning, one step at a time, then prompts each\nintern model to continue the thinking along those initiated paths, and finally\nselects the optimal reasoning path according to the overall reasoning\nperformance of multiple intern models. The reasoning performance is determined\nby an MICS-Score, which assesses the quality of generated reasoning paths.\nEventually, we construct MMRP, a multi-task medical reasoning dataset with\nranked difficulty, and Chiron-o1, a new medical MLLM devised via a curriculum\nlearning strategy, with robust visual question-answering and generalizable\nreasoning capabilities. Extensive experiments demonstrate that Chiron-o1,\ntrained on our CoT dataset constructed using MICS, achieves state-of-the-art\nperformance across a list of medical visual question answering and reasoning\nbenchmarks. Codes are available at GitHub - manglu097/Chiron-o1: Enhancing\nStep-by-Step and Verifiable Medical Reasoning in MLLMs",
      "pdf_url": "http://arxiv.org/pdf/2506.16962v1",
      "published": "2025-06-20T12:51:19+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.16962v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Multimodal Fused Learning for Solving the Generalized Traveling Salesman Problem in Robotic Task Planning",
      "authors": [
        "Jiaqi Chen",
        "Mingfeng Fan",
        "Xuefeng Zhang",
        "Jingsong Liang",
        "Yuhong Cao",
        "Guohua Wu",
        "Guillaume Adrien Sartoretti"
      ],
      "abstract": "Effective and efficient task planning is essential for mobile robots,\nespecially in applications like warehouse retrieval and environmental\nmonitoring. These tasks often involve selecting one location from each of\nseveral target clusters, forming a Generalized Traveling Salesman Problem\n(GTSP) that remains challenging to solve both accurately and efficiently. To\naddress this, we propose a Multimodal Fused Learning (MMFL) framework that\nleverages both graph and image-based representations to capture complementary\naspects of the problem, and learns a policy capable of generating high-quality\ntask planning schemes in real time. Specifically, we first introduce a\ncoordinate-based image builder that transforms GTSP instances into spatially\ninformative representations. We then design an adaptive resolution scaling\nstrategy to enhance adaptability across different problem scales, and develop a\nmultimodal fusion module with dedicated bottlenecks that enables effective\nintegration of geometric and spatial features. Extensive experiments show that\nour MMFL approach significantly outperforms state-of-the-art methods across\nvarious GTSP instances while maintaining the computational efficiency required\nfor real-time robotic applications. Physical robot tests further validate its\npractical effectiveness in real-world scenarios.",
      "pdf_url": "http://arxiv.org/pdf/2506.16931v1",
      "published": "2025-06-20T11:51:52+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.16931v1",
      "categories": [
        "cs.AI",
        "cs.RO"
      ]
    },
    {
      "title": "A deep learning and machine learning approach to predict neonatal death in the context of São Paulo",
      "authors": [
        "Mohon Raihan",
        "Plabon Kumar Saha",
        "Rajan Das Gupta",
        "A Z M Tahmidul Kabir",
        "Afia Anjum Tamanna",
        "Md. Harun-Ur-Rashid",
        "Adnan Bin Abdus Salam",
        "Md Tanvir Anjum",
        "A Z M Ahteshamul Kabir"
      ],
      "abstract": "Neonatal death is still a concerning reality for underdeveloped and even some\ndeveloped countries. Worldwide data indicate that 26.693 babies out of 1,000\nbirths die, according to Macro Trades. To reduce this number, early prediction\nof endangered babies is crucial. Such prediction enables the opportunity to\ntake ample care of the child and mother so that early child death can be\navoided. In this context, machine learning was used to determine whether a\nnewborn baby is at risk. To train the predictive model, historical data of 1.4\nmillion newborns was used. Machine learning and deep learning techniques such\nas logical regression, K-nearest neighbor, random forest classifier, extreme\ngradient boosting (XGBoost), convolutional neural network, and long short-term\nmemory (LSTM) were implemented using the dataset to identify the most accurate\nmodel for predicting neonatal mortality. Among the machine learning algorithms,\nXGBoost and random forest classifier achieved the best accuracy with 94%, while\namong the deep learning models, LSTM delivered the highest accuracy with 99%.\nTherefore, using LSTM appears to be the most suitable approach to predict\nwhether precautionary measures for a child are necessary.",
      "pdf_url": "http://arxiv.org/pdf/2506.16929v1",
      "published": "2025-06-20T11:44:48+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.16929v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Single-shot thermometry of simulated Bose--Einstein condensates using artificial intelligence",
      "authors": [
        "Jack Griffiths",
        "Steven A. Wrathmall",
        "Simon A. Gardiner"
      ],
      "abstract": "Precise determination of thermodynamic parameters in ultracold Bose gases\nremains challenging due to the destructive nature of conventional measurement\ntechniques and inherent experimental uncertainties. We demonstrate an\nartificial intelligence approach for rapid, non-destructive estimation of the\nchemical potential and temperature from single-shot, in situ imaged density\nprofiles of finite-temperature Bose gases. Our convolutional neural network is\ntrained exclusively on quasi-2D `pancake' condensates in harmonic trap\nconfigurations. It achieves parameter extraction within fractions of a second.\nThe model also demonstrates zero-shot generalisation across both trap geometry\nand thermalisation dynamics, successfully estimating thermodynamic parameters\nfor toroidally trapped condensates with errors of only a few nanokelvin despite\nno prior exposure to such geometries during training, and maintaining\npredictive accuracy during dynamic thermalisation processes after a relatively\nbrief evolution without explicit training on non-equilibrium states. These\nresults suggest that supervised learning can overcome traditional limitations\nin ultracold atom thermometry, with extension to broader geometric\nconfigurations, temperature ranges, and additional parameters potentially\nenabling comprehensive real-time analysis of quantum gas experiments. Such\ncapabilities could significantly streamline experimental workflows whilst\nimproving measurement precision across a range of quantum fluid systems.",
      "pdf_url": "http://arxiv.org/pdf/2506.16925v1",
      "published": "2025-06-20T11:36:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.16925v1",
      "categories": [
        "cond-mat.quant-gas",
        "cs.AI",
        "physics.comp-ph"
      ]
    },
    {
      "title": "Real-Time Black-Box Optimization for Dynamic Discrete Environments Using Embedded Ising Machines",
      "authors": [
        "Tomoya Kashimata",
        "Yohei Hamakawa",
        "Masaya Yamasaki",
        "Kosuke Tatsumura"
      ],
      "abstract": "Many real-time systems require the optimization of discrete variables.\nBlack-box optimization (BBO) algorithms and multi-armed bandit (MAB) algorithms\nperform optimization by repeatedly taking actions and observing the\ncorresponding instant rewards without any prior knowledge. Recently, a BBO\nmethod using an Ising machine has been proposed to find the best action that is\nrepresented by a combination of discrete values and maximizes the instant\nreward in static environments. In contrast, dynamic environments, where\nreal-time systems operate, necessitate MAB algorithms that maximize the average\nreward over multiple trials. However, due to the enormous number of actions\nresulting from the combinatorial nature of discrete optimization, conventional\nMAB algorithms cannot effectively optimize dynamic, discrete environments.\nHere, we show a heuristic MAB method for dynamic, discrete environments by\nextending the BBO method, in which an Ising machine effectively explores the\nactions while considering interactions between variables and changes in dynamic\nenvironments. We demonstrate the dynamic adaptability of the proposed method in\na wireless communication system with moving users.",
      "pdf_url": "http://arxiv.org/pdf/2506.16924v1",
      "published": "2025-06-20T11:31:43+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.16924v1",
      "categories": [
        "cs.AI",
        "cs.ET",
        "I.2.8"
      ]
    },
    {
      "title": "Towards Effective Complementary Security Analysis using Large Language Models",
      "authors": [
        "Jonas Wagner",
        "Simon Müller",
        "Christian Näther",
        "Jan-Philipp Steghöfer",
        "Andreas Both"
      ],
      "abstract": "A key challenge in security analysis is the manual evaluation of potential\nsecurity weaknesses generated by static application security testing (SAST)\ntools. Numerous false positives (FPs) in these reports reduce the effectiveness\nof security analysis. We propose using Large Language Models (LLMs) to improve\nthe assessment of SAST findings. We investigate the ability of LLMs to reduce\nFPs while trying to maintain a perfect true positive rate, using datasets\nextracted from the OWASP Benchmark (v1.2) and a real-world software project.\nOur results indicate that advanced prompting techniques, such as\nChain-of-Thought and Self-Consistency, substantially improve FP detection.\nNotably, some LLMs identified approximately 62.5% of FPs in the OWASP Benchmark\ndataset without missing genuine weaknesses. Combining detections from different\nLLMs would increase this FP detection to approximately 78.9%. Additionally, we\ndemonstrate our approach's generalizability using a real-world dataset covering\nfive SAST tools, three programming languages, and infrastructure files. The\nbest LLM detected 33.85% of all FPs without missing genuine weaknesses, while\ncombining detections from different LLMs would increase this detection to\n38.46%. Our findings highlight the potential of LLMs to complement traditional\nSAST tools, enhancing automation and reducing resources spent addressing false\nalarms.",
      "pdf_url": "http://arxiv.org/pdf/2506.16899v1",
      "published": "2025-06-20T10:46:35+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.16899v1",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "title": "AI's Blind Spots: Geographic Knowledge and Diversity Deficit in Generated Urban Scenario",
      "authors": [
        "Ciro Beneduce",
        "Massimiliano Luca",
        "Bruno Lepri"
      ],
      "abstract": "Image generation models are revolutionizing many domains, and urban analysis\nand design is no exception. While such models are widely adopted, there is a\nlimited literature exploring their geographic knowledge, along with the biases\nthey embed. In this work, we generated 150 synthetic images for each state in\nthe USA and related capitals using FLUX 1 and Stable Diffusion 3.5, two\nstate-of-the-art models for image generation. We embed each image using DINO-v2\nViT-S/14 and the Fr\\'echet Inception Distances to measure the similarity\nbetween the generated images. We found that while these models have implicitly\nlearned aspects of USA geography, if we prompt the models to generate an image\nfor \"United States\" instead of specific cities or states, the models exhibit a\nstrong representative bias toward metropolis-like areas, excluding rural states\nand smaller cities. {\\color{black} In addition, we found that models\nsystematically exhibit some entity-disambiguation issues with European-sounding\nnames like Frankfort or Devon.",
      "pdf_url": "http://arxiv.org/pdf/2506.16898v1",
      "published": "2025-06-20T10:43:22+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.16898v1",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.CY"
      ]
    },
    {
      "title": "With Limited Data for Multimodal Alignment, Let the STRUCTURE Guide You",
      "authors": [
        "Fabian Gröger",
        "Shuo Wen",
        "Huyen Le",
        "Maria Brbić"
      ],
      "abstract": "Multimodal models have demonstrated powerful capabilities in complex tasks\nrequiring multimodal alignment including zero-shot classification and\ncross-modal retrieval. However, existing models typically rely on millions of\npaired multimodal samples, which are prohibitively expensive or infeasible to\nobtain in many domains. In this work, we explore the feasibility of building\nmultimodal models with limited amount of paired data by aligning pretrained\nunimodal foundation models. We show that high-quality alignment is possible\nwith as few as tens of thousands of paired samples$\\unicode{x2013}$less than\n$1\\%$ of the data typically used in the field. To achieve this, we introduce\nSTRUCTURE, an effective regularization technique that preserves the\nneighborhood geometry of the latent space of unimodal encoders. Additionally,\nwe show that aligning last layers is often suboptimal and demonstrate the\nbenefits of aligning the layers with the highest representational similarity\nacross modalities. These two components can be readily incorporated into\nexisting alignment methods, yielding substantial gains across 24 zero-shot\nimage classification and retrieval benchmarks, with average relative\nimprovement of $51.6\\%$ in classification and $91.8\\%$ in retrieval tasks. Our\nresults highlight the effectiveness and broad applicability of our framework\nfor limited-sample multimodal learning and offer a promising path forward for\nresource-constrained domains.",
      "pdf_url": "http://arxiv.org/pdf/2506.16895v1",
      "published": "2025-06-20T10:32:54+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.16895v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "The Importance of Being Lazy: Scaling Limits of Continual Learning",
      "authors": [
        "Jacopo Graldi",
        "Alessandro Breccia",
        "Giulia Lanzillotta",
        "Thomas Hofmann",
        "Lorenzo Noci"
      ],
      "abstract": "Despite recent efforts, neural networks still struggle to learn in\nnon-stationary environments, and our understanding of catastrophic forgetting\n(CF) is far from complete. In this work, we perform a systematic study on the\nimpact of model scale and the degree of feature learning in continual learning.\nWe reconcile existing contradictory observations on scale in the literature, by\ndifferentiating between lazy and rich training regimes through a variable\nparameterization of the architecture. We show that increasing model width is\nonly beneficial when it reduces the amount of feature learning, yielding more\nlaziness. Using the framework of dynamical mean field theory, we then study the\ninfinite width dynamics of the model in the feature learning regime and\ncharacterize CF, extending prior theoretical results limited to the lazy\nregime. We study the intricate relationship between feature learning, task\nnon-stationarity, and forgetting, finding that high feature learning is only\nbeneficial with highly similar tasks. We identify a transition modulated by\ntask similarity where the model exits an effectively lazy regime with low\nforgetting to enter a rich regime with significant forgetting. Finally, our\nfindings reveal that neural networks achieve optimal performance at a critical\nlevel of feature learning, which depends on task non-stationarity and transfers\nacross model scales. This work provides a unified perspective on the role of\nscale and feature learning in continual learning.",
      "pdf_url": "http://arxiv.org/pdf/2506.16884v1",
      "published": "2025-06-20T10:12:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.16884v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ]
    },
    {
      "title": "ParkFormer: A Transformer-Based Parking Policy with Goal Embedding and Pedestrian-Aware Control",
      "authors": [
        "Jun Fu",
        "Bin Tian",
        "Haonan Chen",
        "Shi Meng",
        "Tingting Yao"
      ],
      "abstract": "Autonomous parking plays a vital role in intelligent vehicle systems,\nparticularly in constrained urban environments where high-precision control is\nrequired. While traditional rule-based parking systems struggle with\nenvironmental uncertainties and lack adaptability in crowded or dynamic scenes,\nhuman drivers demonstrate the ability to park intuitively without explicit\nmodeling. Inspired by this observation, we propose a Transformer-based\nend-to-end framework for autonomous parking that learns from expert\ndemonstrations. The network takes as input surround-view camera images,\ngoal-point representations, ego vehicle motion, and pedestrian trajectories. It\noutputs discrete control sequences including throttle, braking, steering, and\ngear selection. A novel cross-attention module integrates BEV features with\ntarget points, and a GRU-based pedestrian predictor enhances safety by modeling\ndynamic obstacles. We validate our method on the CARLA 0.9.14 simulator in both\nvertical and parallel parking scenarios. Experiments show our model achieves a\nhigh success rate of 96.57\\%, with average positional and orientation errors of\n0.21 meters and 0.41 degrees, respectively. The ablation studies further\ndemonstrate the effectiveness of key modules such as pedestrian prediction and\ngoal-point attention fusion. The code and dataset will be released at:\nhttps://github.com/little-snail-f/ParkFormer.",
      "pdf_url": "http://arxiv.org/pdf/2506.16856v1",
      "published": "2025-06-20T09:14:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.16856v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Bandwidth Selectors on Semiparametric Bayesian Networks",
      "authors": [
        "Victor Alejandre",
        "Concha Bielza",
        "Pedro Larrañaga"
      ],
      "abstract": "Semiparametric Bayesian networks (SPBNs) integrate parametric and\nnon-parametric probabilistic models, offering flexibility in learning complex\ndata distributions from samples. In particular, kernel density estimators\n(KDEs) are employed for the non-parametric component. Under the assumption of\ndata normality, the normal rule is used to learn the bandwidth matrix for the\nKDEs in SPBNs. This matrix is the key hyperparameter that controls the\ntrade-off between bias and variance. However, real-world data often deviates\nfrom normality, potentially leading to suboptimal density estimation and\nreduced predictive performance. This paper first establishes the theoretical\nframework for the application of state-of-the-art bandwidth selectors and\nsubsequently evaluates their impact on SPBN performance. We explore the\napproaches of cross-validation and plug-in selectors, assessing their\neffectiveness in enhancing the learning capability and applicability of SPBNs.\nTo support this investigation, we have extended the open-source package\nPyBNesian for SPBNs with the additional bandwidth selection techniques and\nconducted extensive experimental analyses. Our results demonstrate that the\nproposed bandwidth selectors leverage increasing information more effectively\nthan the normal rule, which, despite its robustness, stagnates with more data.\nIn particular, unbiased cross-validation generally outperforms the normal rule,\nhighlighting its advantage in high sample size scenarios.",
      "pdf_url": "http://arxiv.org/pdf/2506.16844v1",
      "published": "2025-06-20T08:48:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.16844v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML",
        "I.2.6; I.5.1; G.3"
      ]
    }
  ]
}