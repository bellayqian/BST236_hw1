{
  "last_updated": "2025-04-22T00:50:05.439267",
  "papers": [
    {
      "title": "Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model?",
      "authors": [
        "Yang Yue",
        "Zhiqi Chen",
        "Rui Lu",
        "Andrew Zhao",
        "Zhaokai Wang",
        "Yang Yue",
        "Shiji Song",
        "Gao Huang"
      ],
      "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has recently\ndemonstrated notable success in enhancing the reasoning capabilities of LLMs,\nparticularly in mathematics and programming tasks. It is widely believed that\nRLVR enables LLMs to continuously self-improve, thus acquiring novel reasoning\nabilities that exceed corresponding base models' capacity. In this study,\nhowever, we critically re-examines this assumption by measuring the\npass@\\textit{k} metric with large values of \\textit{k} to explore the reasoning\ncapability boundary of the models across a wide range of model families and\nbenchmarks. Surprisingly, the RL does \\emph{not}, in fact, elicit fundamentally\nnew reasoning patterns. While RL-trained models outperform their base models at\nsmaller values of $k$ (\\eg, $k$=1), base models can achieve a comparable or\neven higher pass@$k$ score compared to their RL counterparts at large $k$\nvalues. The reasoning paths generated by RL-trained models are already included\nin the base models' sampling distribution, suggesting that most reasoning\nabilities manifested in RL-trained models are already obtained by base models.\nFurther analysis shows that RL training boosts the performance by biasing the\nmodel's output distribution toward paths that are more likely to yield rewards,\ntherefore sampling correct responses more efficiently. But this also results in\na narrower reasoning capability boundary compared to base models. Similar\nresults are observed in visual reasoning tasks trained with RLVR. Moreover, we\nfind that distillation can genuinely introduce new knowledge into the model,\ndifferent from RLVR. These findings underscore a critical limitation of RLVR in\nadvancing LLM reasoning abilities which requires us to fundamentally rethink\nthe impact of RL training in reasoning LLMs and the need of a better paradigm.\nProject Page: https://limit-of-RLVR.github.io",
      "pdf_url": "http://arxiv.org/pdf/2504.13837v1",
      "published": "2025-04-18T17:59:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.13837v1",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ]
    },
    {
      "title": "MIG: Automatic Data Selection for Instruction Tuning by Maximizing Information Gain in Semantic Space",
      "authors": [
        "Yicheng Chen",
        "Yining Li",
        "Kai Hu",
        "Zerun Ma",
        "Haochen Ye",
        "Kai Chen"
      ],
      "abstract": "Data quality and diversity are key to the construction of effective\ninstruction-tuning datasets. % With the increasing availability of open-source\ninstruction-tuning datasets, it is advantageous to automatically select\nhigh-quality and diverse subsets from a vast amount of data. % Existing methods\ntypically prioritize instance quality and use heuristic rules to maintain\ndiversity. % However, this absence of a comprehensive view of the entire\ncollection often leads to suboptimal results. % Moreover, heuristic rules\ngenerally focus on distance or clustering within the embedding space, which\nfails to accurately capture the intent of complex instructions in the semantic\nspace. % To bridge this gap, we propose a unified method for quantifying the\ninformation content of datasets. This method models the semantic space by\nconstructing a label graph and quantifies diversity based on the distribution\nof information within the graph. % Based on such a measurement, we further\nintroduce an efficient sampling method that selects data samples iteratively to\n\\textbf{M}aximize the \\textbf{I}nformation \\textbf{G}ain (MIG) in semantic\nspace. % Experiments on various datasets and base models demonstrate that MIG\nconsistently outperforms state-of-the-art methods. % Notably, the model\nfine-tuned with 5\\% Tulu3 data sampled by MIG achieves comparable performance\nto the official SFT model trained on the full dataset, with improvements of\n+5.73\\% on AlpacaEval and +6.89\\% on Wildbench.",
      "pdf_url": "http://arxiv.org/pdf/2504.13835v1",
      "published": "2025-04-18T17:59:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.13835v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Generative AI Act II: Test Time Scaling Drives Cognition Engineering",
      "authors": [
        "Shijie Xia",
        "Yiwei Qin",
        "Xuefeng Li",
        "Yan Ma",
        "Run-Ze Fan",
        "Steffi Chern",
        "Haoyang Zou",
        "Fan Zhou",
        "Xiangkun Hu",
        "Jiahe Jin",
        "Yanheng He",
        "Yixin Ye",
        "Yixiu Liu",
        "Pengfei Liu"
      ],
      "abstract": "The first generation of Large Language Models - what might be called \"Act I\"\nof generative AI (2020-2023) - achieved remarkable success through massive\nparameter and data scaling, yet exhibited fundamental limitations in knowledge\nlatency, shallow reasoning, and constrained cognitive processes. During this\nera, prompt engineering emerged as our primary interface with AI, enabling\ndialogue-level communication through natural language. We now witness the\nemergence of \"Act II\" (2024-present), where models are transitioning from\nknowledge-retrieval systems (in latent space) to thought-construction engines\nthrough test-time scaling techniques. This new paradigm establishes a\nmind-level connection with AI through language-based thoughts. In this paper,\nwe clarify the conceptual foundations of cognition engineering and explain why\nthis moment is critical for its development. We systematically break down these\nadvanced approaches through comprehensive tutorials and optimized\nimplementations, democratizing access to cognition engineering and enabling\nevery practitioner to participate in AI's second act. We provide a regularly\nupdated collection of papers on test-time scaling in the GitHub Repository:\nhttps://github.com/GAIR-NLP/cognition-engineering",
      "pdf_url": "http://arxiv.org/pdf/2504.13828v1",
      "published": "2025-04-18T17:55:58+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.13828v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Parameter-Efficient Continual Fine-Tuning: A Survey",
      "authors": [
        "Eric Nuertey Coleman",
        "Luigi Quarantiello",
        "Ziyue Liu",
        "Qinwen Yang",
        "Samrat Mukherjee",
        "Julio Hurtado",
        "Vincenzo Lomonaco"
      ],
      "abstract": "The emergence of large pre-trained networks has revolutionized the AI field,\nunlocking new possibilities and achieving unprecedented performance. However,\nthese models inherit a fundamental limitation from traditional Machine Learning\napproaches: their strong dependence on the \\textit{i.i.d.} assumption hinders\ntheir adaptability to dynamic learning scenarios. We believe the next\nbreakthrough in AI lies in enabling efficient adaptation to evolving\nenvironments -- such as the real world -- where new data and tasks arrive\nsequentially. This challenge defines the field of Continual Learning (CL), a\nMachine Learning paradigm focused on developing lifelong learning neural\nmodels. One alternative to efficiently adapt these large-scale models is known\nParameter-Efficient Fine-Tuning (PEFT). These methods tackle the issue of\nadapting the model to a particular data or scenario by performing small and\nefficient modifications, achieving similar performance to full fine-tuning.\nHowever, these techniques still lack the ability to adjust the model to\nmultiple tasks continually, as they suffer from the issue of Catastrophic\nForgetting. In this survey, we first provide an overview of CL algorithms and\nPEFT methods before reviewing the state-of-the-art on Parameter-Efficient\nContinual Fine-Tuning (PECFT). We examine various approaches, discuss\nevaluation metrics, and explore potential future research directions. Our goal\nis to highlight the synergy between CL and Parameter-Efficient Fine-Tuning,\nguide researchers in this field, and pave the way for novel future research\ndirections.",
      "pdf_url": "http://arxiv.org/pdf/2504.13822v1",
      "published": "2025-04-18T17:51:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.13822v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Not All Rollouts are Useful: Down-Sampling Rollouts in LLM Reinforcement Learning",
      "authors": [
        "Yixuan Even Xu",
        "Yash Savani",
        "Fei Fang",
        "Zico Kolter"
      ],
      "abstract": "Reinforcement learning (RL) has emerged as a powerful paradigm for enhancing\nreasoning capabilities in large language models, but faces a fundamental\nasymmetry in computation and memory requirements: inference is embarrassingly\nparallel with a minimal memory footprint, while policy updates require\nextensive synchronization and are memory-intensive. To address this asymmetry,\nwe introduce PODS (Policy Optimization with Down-Sampling), a framework that\nstrategically decouples these phases by generating numerous rollouts in\nparallel but updating only on an informative subset. Within this framework, we\ndevelop max-variance down-sampling, a theoretically motivated method that\nselects rollouts with maximally diverse reward signals. We prove that this\napproach has an efficient algorithmic solution, and empirically demonstrate\nthat GRPO with PODS using max-variance down-sampling achieves superior\nperformance over standard GRPO on the GSM8K benchmark.",
      "pdf_url": "http://arxiv.org/pdf/2504.13818v1",
      "published": "2025-04-18T17:49:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.13818v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Near-optimal algorithms for private estimation and sequential testing of collision probability",
      "authors": [
        "Robert Busa-Fekete",
        "Umar Syed"
      ],
      "abstract": "We present new algorithms for estimating and testing \\emph{collision\nprobability}, a fundamental measure of the spread of a discrete distribution\nthat is widely used in many scientific fields. We describe an algorithm that\nsatisfies $(\\alpha, \\beta)$-local differential privacy and estimates collision\nprobability with error at most $\\epsilon$ using\n$\\tilde{O}\\left(\\frac{\\log(1/\\beta)}{\\alpha^2 \\epsilon^2}\\right)$ samples for\n$\\alpha \\le 1$, which improves over previous work by a factor of\n$\\frac{1}{\\alpha^2}$. We also present a sequential testing algorithm for\ncollision probability, which can distinguish between collision probability\nvalues that are separated by $\\epsilon$ using $\\tilde{O}(\\frac{1}{\\epsilon^2})$\nsamples, even when $\\epsilon$ is unknown. Our algorithms have nearly the\noptimal sample complexity, and in experiments we show that they require\nsignificantly fewer samples than previous methods.",
      "pdf_url": "http://arxiv.org/pdf/2504.13804v1",
      "published": "2025-04-18T17:12:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.13804v1",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Imitation Learning with Precisely Labeled Human Demonstrations",
      "authors": [
        "Yilong Song"
      ],
      "abstract": "Within the imitation learning paradigm, training generalist robots requires\nlarge-scale datasets obtainable only through diverse curation. Due to the\nrelative ease to collect, human demonstrations constitute a valuable addition\nwhen incorporated appropriately. However, existing methods utilizing human\ndemonstrations face challenges in inferring precise actions, ameliorating\nembodiment gaps, and fusing with frontier generalist robot training pipelines.\nIn this work, building on prior studies that demonstrate the viability of using\nhand-held grippers for efficient data collection, we leverage the user's\ncontrol over the gripper's appearance--specifically by assigning it a unique,\neasily segmentable color--to enable simple and reliable application of the\nRANSAC and ICP registration method for precise end-effector pose estimation. We\nshow in simulation that precisely labeled human demonstrations on their own\nallow policies to reach on average 88.1% of the performance of using robot\ndemonstrations, and boost policy performance when combined with robot\ndemonstrations, despite the inherent embodiment gap.",
      "pdf_url": "http://arxiv.org/pdf/2504.13803v1",
      "published": "2025-04-18T17:12:00+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.13803v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "Meta-Learning and Knowledge Discovery based Physics-Informed Neural Network for Remaining Useful Life Prediction",
      "authors": [
        "Yu Wang",
        "Shujie Liu",
        "Shuai Lv",
        "Gengshuo Liu"
      ],
      "abstract": "Predicting the remaining useful life (RUL) of rotating machinery is critical\nfor industrial safety and maintenance, but existing methods struggle with\nscarce target-domain data and unclear degradation dynamics. We propose a\nMeta-Learning and Knowledge Discovery-based Physics-Informed Neural Network\n(MKDPINN) to address these challenges. The method first maps noisy sensor data\nto a low-dimensional hidden state space via a Hidden State Mapper (HSM). A\nPhysics-Guided Regulator (PGR) then learns unknown nonlinear PDEs governing\ndegradation evolution, embedding these physical constraints into the PINN\nframework. This integrates data-driven and physics-based approaches. The\nframework uses meta-learning, optimizing across source-domain meta-tasks to\nenable few-shot adaptation to new target tasks. Experiments on industrial data\nand the C-MAPSS benchmark show MKDPINN outperforms baselines in generalization\nand accuracy, proving its effectiveness for RUL prediction under data scarcity",
      "pdf_url": "http://arxiv.org/pdf/2504.13797v1",
      "published": "2025-04-18T16:58:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.13797v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Collective Learning Mechanism based Optimal Transport Generative Adversarial Network for Non-parallel Voice Conversion",
      "authors": [
        "Sandipan Dhar",
        "Md. Tousin Akhter",
        "Nanda Dulal Jana",
        "Swagatam Das"
      ],
      "abstract": "After demonstrating significant success in image synthesis, Generative\nAdversarial Network (GAN) models have likewise made significant progress in the\nfield of speech synthesis, leveraging their capacity to adapt the precise\ndistribution of target data through adversarial learning processes. Notably, in\nthe realm of State-Of-The-Art (SOTA) GAN-based Voice Conversion (VC) models,\nthere exists a substantial disparity in naturalness between real and\nGAN-generated speech samples. Furthermore, while many GAN models currently\noperate on a single generator discriminator learning approach, optimizing\ntarget data distribution is more effectively achievable through a single\ngenerator multi-discriminator learning scheme. Hence, this study introduces a\nnovel GAN model named Collective Learning Mechanism-based Optimal Transport GAN\n(CLOT-GAN) model, incorporating multiple discriminators, including the Deep\nConvolutional Neural Network (DCNN) model, Vision Transformer (ViT), and\nconformer. The objective of integrating various discriminators lies in their\nability to comprehend the formant distribution of mel-spectrograms, facilitated\nby a collective learning mechanism. Simultaneously, the inclusion of Optimal\nTransport (OT) loss aims to precisely bridge the gap between the source and\ntarget data distribution, employing the principles of OT theory. The\nexperimental validation on VCC 2018, VCTK, and CMU-Arctic datasets confirms\nthat the CLOT-GAN-VC model outperforms existing VC models in objective and\nsubjective assessments.",
      "pdf_url": "http://arxiv.org/pdf/2504.13791v1",
      "published": "2025-04-18T16:44:01+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.13791v1",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ]
    },
    {
      "title": "Probabilistic Stability Guarantees for Feature Attributions",
      "authors": [
        "Helen Jin",
        "Anton Xue",
        "Weiqiu You",
        "Surbhi Goel",
        "Eric Wong"
      ],
      "abstract": "Stability guarantees are an emerging tool for evaluating feature\nattributions, but existing certification methods rely on smoothed classifiers\nand often yield conservative guarantees. To address these limitations, we\nintroduce soft stability and propose a simple, model-agnostic, and\nsample-efficient stability certification algorithm (SCA) that provides\nnon-trivial and interpretable guarantees for any attribution. Moreover, we show\nthat mild smoothing enables a graceful tradeoff between accuracy and stability,\nin contrast to prior certification methods that require a more aggressive\ncompromise. Using Boolean function analysis, we give a novel characterization\nof stability under smoothing. We evaluate SCA on vision and language tasks, and\ndemonstrate the effectiveness of soft stability in measuring the robustness of\nexplanation methods.",
      "pdf_url": "http://arxiv.org/pdf/2504.13787v1",
      "published": "2025-04-18T16:39:08+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.13787v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Learning Through Retrospection: Improving Trajectory Prediction for Automated Driving with Error Feedback",
      "authors": [
        "Steffen Hagedorn",
        "Aron Distelzweig",
        "Marcel Hallgarten",
        "Alexandru P. Condurache"
      ],
      "abstract": "In automated driving, predicting trajectories of surrounding vehicles\nsupports reasoning about scene dynamics and enables safe planning for the ego\nvehicle. However, existing models handle predictions as an instantaneous task\nof forecasting future trajectories based on observed information. As time\nproceeds, the next prediction is made independently of the previous one, which\nmeans that the model cannot correct its errors during inference and will repeat\nthem. To alleviate this problem and better leverage temporal data, we propose a\nnovel retrospection technique. Through training on closed-loop rollouts the\nmodel learns to use aggregated feedback. Given new observations it reflects on\nprevious predictions and analyzes its errors to improve the quality of\nsubsequent predictions. Thus, the model can learn to correct systematic errors\nduring inference. Comprehensive experiments on nuScenes and Argoverse\ndemonstrate a considerable decrease in minimum Average Displacement Error of up\nto 31.9% compared to the state-of-the-art baseline without retrospection. We\nfurther showcase the robustness of our technique by demonstrating a better\nhandling of out-of-distribution scenarios with undetected road-users.",
      "pdf_url": "http://arxiv.org/pdf/2504.13785v1",
      "published": "2025-04-18T16:35:12+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.13785v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "DP2Unlearning: An Efficient and Guaranteed Unlearning Framework for LLMs",
      "authors": [
        "Tamim Al Mahmud",
        "Najeeb Jebreel",
        "Josep Domingo-Ferrer",
        "David Sanchez"
      ],
      "abstract": "Large language models (LLMs) have recently revolutionized language processing\ntasks but have also brought ethical and legal issues. LLMs have a tendency to\nmemorize potentially private or copyrighted information present in the training\ndata, which might then be delivered to end users at inference time. When this\nhappens, a naive solution is to retrain the model from scratch after excluding\nthe undesired data. Although this guarantees that the target data have been\nforgotten, it is also prohibitively expensive for LLMs. Approximate unlearning\noffers a more efficient alternative, as it consists of ex post modifications of\nthe trained model itself to prevent undesirable results, but it lacks\nforgetting guarantees because it relies solely on empirical evidence. In this\nwork, we present DP2Unlearning, a novel LLM unlearning framework that offers\nformal forgetting guarantees at a significantly lower cost than retraining from\nscratch on the data to be retained. DP2Unlearning involves training LLMs on\ntextual data protected using {\\epsilon}-differential privacy (DP), which later\nenables efficient unlearning with the guarantees against disclosure associated\nwith the chosen {\\epsilon}. Our experiments demonstrate that DP2Unlearning\nachieves similar model performance post-unlearning, compared to an LLM\nretraining from scratch on retained data -- the gold standard exact unlearning\n-- but at approximately half the unlearning cost. In addition, with a\nreasonable computational cost, it outperforms approximate unlearning methods at\nboth preserving the utility of the model post-unlearning and effectively\nforgetting the targeted information.",
      "pdf_url": "http://arxiv.org/pdf/2504.13774v1",
      "published": "2025-04-18T16:22:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.13774v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Decoding Vision Transformers: the Diffusion Steering Lens",
      "authors": [
        "Ryota Takatsuki",
        "Sonia Joseph",
        "Ippei Fujisawa",
        "Ryota Kanai"
      ],
      "abstract": "Logit Lens is a widely adopted method for mechanistic interpretability of\ntransformer-based language models, enabling the analysis of how internal\nrepresentations evolve across layers by projecting them into the output\nvocabulary space. Although applying Logit Lens to Vision Transformers (ViTs) is\ntechnically straightforward, its direct use faces limitations in capturing the\nrichness of visual representations. Building on the work of Toker et al.\n(2024)~\\cite{Toker2024-ve}, who introduced Diffusion Lens to visualize\nintermediate representations in the text encoders of text-to-image diffusion\nmodels, we demonstrate that while Diffusion Lens can effectively visualize\nresidual stream representations in image encoders, it fails to capture the\ndirect contributions of individual submodules. To overcome this limitation, we\npropose \\textbf{Diffusion Steering Lens} (DSL), a novel, training-free approach\nthat steers submodule outputs and patches subsequent indirect contributions. We\nvalidate our method through interventional studies, showing that DSL provides\nan intuitive and reliable interpretation of the internal processing in ViTs.",
      "pdf_url": "http://arxiv.org/pdf/2504.13763v1",
      "published": "2025-04-18T16:00:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.13763v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Scaling sparse feature circuit finding for in-context learning",
      "authors": [
        "Dmitrii Kharlapenko",
        "Stepan Shabalin",
        "Fazl Barez",
        "Arthur Conmy",
        "Neel Nanda"
      ],
      "abstract": "Sparse autoencoders (SAEs) are a popular tool for interpreting large language\nmodel activations, but their utility in addressing open questions in\ninterpretability remains unclear. In this work, we demonstrate their\neffectiveness by using SAEs to deepen our understanding of the mechanism behind\nin-context learning (ICL). We identify abstract SAE features that (i) encode\nthe model's knowledge of which task to execute and (ii) whose latent vectors\ncausally induce the task zero-shot. This aligns with prior work showing that\nICL is mediated by task vectors. We further demonstrate that these task vectors\nare well approximated by a sparse sum of SAE latents, including these\ntask-execution features. To explore the ICL mechanism, we adapt the sparse\nfeature circuits methodology of Marks et al. (2024) to work for the much larger\nGemma-1 2B model, with 30 times as many parameters, and to the more complex\ntask of ICL. Through circuit finding, we discover task-detecting features with\ncorresponding SAE latents that activate earlier in the prompt, that detect when\ntasks have been performed. They are causally linked with task-execution\nfeatures through the attention and MLP sublayers.",
      "pdf_url": "http://arxiv.org/pdf/2504.13756v1",
      "published": "2025-04-18T15:45:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.13756v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Towards Accurate and Interpretable Neuroblastoma Diagnosis via Contrastive Multi-scale Pathological Image Analysis",
      "authors": [
        "Zhu Zhu",
        "Shuo Jiang",
        "Jingyuan Zheng",
        "Yawen Li",
        "Yifei Chen",
        "Manli Zhao",
        "Weizhong Gu",
        "Feiwei Qin",
        "Jinhu Wang",
        "Gang Yu"
      ],
      "abstract": "Neuroblastoma, adrenal-derived, is among the most common pediatric solid\nmalignancies, characterized by significant clinical heterogeneity. Timely and\naccurate pathological diagnosis from hematoxylin and eosin-stained whole slide\nimages is critical for patient prognosis. However, current diagnostic practices\nprimarily rely on subjective manual examination by pathologists, leading to\ninconsistent accuracy. Existing automated whole slide image classification\nmethods encounter challenges such as poor interpretability, limited feature\nextraction capabilities, and high computational costs, restricting their\npractical clinical deployment. To overcome these limitations, we propose\nCMSwinKAN, a contrastive-learning-based multi-scale feature fusion model\ntailored for pathological image classification, which enhances the Swin\nTransformer architecture by integrating a Kernel Activation Network within its\nmultilayer perceptron and classification head modules, significantly improving\nboth interpretability and accuracy. By fusing multi-scale features and\nleveraging contrastive learning strategies, CMSwinKAN mimics clinicians'\ncomprehensive approach, effectively capturing global and local tissue\ncharacteristics. Additionally, we introduce a heuristic soft voting mechanism\nguided by clinical insights to seamlessly bridge patch-level predictions to\nwhole slide image-level classifications. We validate CMSwinKAN on the PpNTs\ndataset, which was collaboratively established with our partner hospital and\nthe publicly accessible BreakHis dataset. Results demonstrate that CMSwinKAN\nperforms better than existing state-of-the-art pathology-specific models\npre-trained on large datasets. Our source code is available at\nhttps://github.com/JSLiam94/CMSwinKAN.",
      "pdf_url": "http://arxiv.org/pdf/2504.13754v1",
      "published": "2025-04-18T15:39:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.13754v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "A Survey for What Developers Require in AI-powered Tools that Aid in Component Selection in CBSD",
      "authors": [
        "Mahdi Jaberzadeh Ansari",
        "Ann Barcomb"
      ],
      "abstract": "Although it has been more than four decades that the first components-based\nsoftware development (CBSD) studies were conducted, there is still no standard\nmethod or tool for component selection which is widely accepted by the\nindustry. The gulf between industry and academia contributes to the lack of an\naccepted tool. We conducted a mixed methods survey of nearly 100 people engaged\nin component-based software engineering practice or research to better\nunderstand the problems facing industry, how these needs could be addressed,\nand current best practices employed in component selection. We also sought to\nidentify and prioritize quality criteria for component selection from an\nindustry perspective. In response to the call for CBSD component selection\ntools to incorporate recent technical advances, we also explored the\nperceptions of professionals about AI-driven tools, present and envisioned.",
      "pdf_url": "http://arxiv.org/pdf/2504.13751v1",
      "published": "2025-04-18T15:35:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.13751v1",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CY"
      ]
    },
    {
      "title": "ESPLoRA: Enhanced Spatial Precision with Low-Rank Adaption in Text-to-Image Diffusion Models for High-Definition Synthesis",
      "authors": [
        "Andrea Rigo",
        "Luca Stornaiuolo",
        "Mauro Martino",
        "Bruno Lepri",
        "Nicu Sebe"
      ],
      "abstract": "Diffusion models have revolutionized text-to-image (T2I) synthesis, producing\nhigh-quality, photorealistic images. However, they still struggle to properly\nrender the spatial relationships described in text prompts. To address the lack\nof spatial information in T2I generations, existing methods typically use\nexternal network conditioning and predefined layouts, resulting in higher\ncomputational costs and reduced flexibility. Our approach builds upon a curated\ndataset of spatially explicit prompts, meticulously extracted and synthesized\nfrom LAION-400M to ensure precise alignment between textual descriptions and\nspatial layouts. Alongside this dataset, we present ESPLoRA, a flexible\nfine-tuning framework based on Low-Rank Adaptation, specifically designed to\nenhance spatial consistency in generative models without increasing generation\ntime or compromising the quality of the outputs. In addition to ESPLoRA, we\npropose refined evaluation metrics grounded in geometric constraints, capturing\n3D spatial relations such as \\textit{in front of} or \\textit{behind}. These\nmetrics also expose spatial biases in T2I models which, even when not fully\nmitigated, can be strategically exploited by our TORE algorithm to further\nimprove the spatial consistency of generated images. Our method outperforms the\ncurrent state-of-the-art framework, CoMPaSS, by 13.33% on established spatial\nconsistency benchmarks.",
      "pdf_url": "http://arxiv.org/pdf/2504.13745v1",
      "published": "2025-04-18T15:21:37+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.13745v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.4.0"
      ]
    },
    {
      "title": "Controlled Territory and Conflict Tracking (CONTACT): (Geo-)Mapping Occupied Territory from Open Source Intelligence",
      "authors": [
        "Paul K. Mandal",
        "Cole Leo",
        "Connor Hurley"
      ],
      "abstract": "Open-source intelligence provides a stream of unstructured textual data that\ncan inform assessments of territorial control. We present CONTACT, a framework\nfor territorial control prediction using large language models (LLMs) and\nminimal supervision. We evaluate two approaches: SetFit, an embedding-based\nfew-shot classifier, and a prompt tuning method applied to BLOOMZ-560m, a\nmultilingual generative LLM. Our model is trained on a small hand-labeled\ndataset of news articles covering ISIS activity in Syria and Iraq, using\nprompt-conditioned extraction of control-relevant signals such as military\noperations, casualties, and location references. We show that the BLOOMZ-based\nmodel outperforms the SetFit baseline, and that prompt-based supervision\nimproves generalization in low-resource settings. CONTACT demonstrates that\nLLMs fine-tuned using few-shot methods can reduce annotation burdens and\nsupport structured inference from open-ended OSINT streams. Our code is\navailable at https://github.com/PaulKMandal/CONTACT/.",
      "pdf_url": "http://arxiv.org/pdf/2504.13730v1",
      "published": "2025-04-18T14:57:07+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.13730v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "I.2.7; I.2.6; I.2.8; H.3.1; K.4.1"
      ]
    },
    {
      "title": "Human-aligned Deep Learning: Explainability, Causality, and Biological Inspiration",
      "authors": [
        "Gianluca Carloni"
      ],
      "abstract": "This work aligns deep learning (DL) with human reasoning capabilities and\nneeds to enable more efficient, interpretable, and robust image classification.\nWe approach this from three perspectives: explainability, causality, and\nbiological vision. Introduction and background open this work before diving\ninto operative chapters. First, we assess neural networks' visualization\ntechniques for medical images and validate an explainable-by-design method for\nbreast mass classification. A comprehensive review at the intersection of XAI\nand causality follows, where we introduce a general scaffold to organize past\nand future research, laying the groundwork for our second perspective. In the\ncausality direction, we propose novel modules that exploit feature\nco-occurrence in medical images, leading to more effective and explainable\npredictions. We further introduce CROCODILE, a general framework that\nintegrates causal concepts, contrastive learning, feature disentanglement, and\nprior knowledge to enhance generalization. Lastly, we explore biological\nvision, examining how humans recognize objects, and propose CoCoReco, a\nconnectivity-inspired network with context-aware attention mechanisms. Overall,\nour key findings include: (i) simple activation maximization lacks insight for\nmedical imaging DL models; (ii) prototypical-part learning is effective and\nradiologically aligned; (iii) XAI and causal ML are deeply connected; (iv) weak\ncausal signals can be leveraged without a priori information to improve\nperformance and interpretability; (v) our framework generalizes across medical\ndomains and out-of-distribution data; (vi) incorporating biological circuit\nmotifs improves human-aligned recognition. This work contributes toward\nhuman-aligned DL and highlights pathways to bridge the gap between research and\nclinical adoption, with implications for improved trust, diagnostic accuracy,\nand safe deployment.",
      "pdf_url": "http://arxiv.org/pdf/2504.13717v1",
      "published": "2025-04-18T14:40:58+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.13717v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "eess.IV",
        "q-bio.NC",
        "I.2; I.2.6; I.4; I.4.7; I.5; J.3; J.6"
      ]
    },
    {
      "title": "OpenDeception: Benchmarking and Investigating AI Deceptive Behaviors via Open-ended Interaction Simulation",
      "authors": [
        "Yichen Wu",
        "Xudong Pan",
        "Geng Hong",
        "Min Yang"
      ],
      "abstract": "As the general capabilities of large language models (LLMs) improve and agent\napplications become more widespread, the underlying deception risks urgently\nrequire systematic evaluation and effective oversight. Unlike existing\nevaluation which uses simulated games or presents limited choices, we introduce\nOpenDeception, a novel deception evaluation framework with an open-ended\nscenario dataset. OpenDeception jointly evaluates both the deception intention\nand capabilities of LLM-based agents by inspecting their internal reasoning\nprocess. Specifically, we construct five types of common use cases where LLMs\nintensively interact with the user, each consisting of ten diverse, concrete\nscenarios from the real world. To avoid ethical concerns and costs of high-risk\ndeceptive interactions with human testers, we propose to simulate the\nmulti-turn dialogue via agent simulation. Extensive evaluation of eleven\nmainstream LLMs on OpenDeception highlights the urgent need to address\ndeception risks and security concerns in LLM-based agents: the deception\nintention ratio across the models exceeds 80%, while the deception success rate\nsurpasses 50%. Furthermore, we observe that LLMs with stronger capabilities do\nexhibit a higher risk of deception, which calls for more alignment efforts on\ninhibiting deceptive behaviors.",
      "pdf_url": "http://arxiv.org/pdf/2504.13707v1",
      "published": "2025-04-18T14:11:27+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.13707v1",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Exploring Multimodal Prompt for Visualization Authoring with Large Language Models",
      "authors": [
        "Zhen Wen",
        "Luoxuan Weng",
        "Yinghao Tang",
        "Runjin Zhang",
        "Yuxin Liu",
        "Bo Pan",
        "Minfeng Zhu",
        "Wei Chen"
      ],
      "abstract": "Recent advances in large language models (LLMs) have shown great potential in\nautomating the process of visualization authoring through simple natural\nlanguage utterances. However, instructing LLMs using natural language is\nlimited in precision and expressiveness for conveying visualization intent,\nleading to misinterpretation and time-consuming iterations. To address these\nlimitations, we conduct an empirical study to understand how LLMs interpret\nambiguous or incomplete text prompts in the context of visualization authoring,\nand the conditions making LLMs misinterpret user intent. Informed by the\nfindings, we introduce visual prompts as a complementary input modality to text\nprompts, which help clarify user intent and improve LLMs' interpretation\nabilities. To explore the potential of multimodal prompting in visualization\nauthoring, we design VisPilot, which enables users to easily create\nvisualizations using multimodal prompts, including text, sketches, and direct\nmanipulations on existing visualizations. Through two case studies and a\ncontrolled user study, we demonstrate that VisPilot provides a more intuitive\nway to create visualizations without affecting the overall task efficiency\ncompared to text-only prompting approaches. Furthermore, we analyze the impact\nof text and visual prompts in different visualization tasks. Our findings\nhighlight the importance of multimodal prompting in improving the usability of\nLLMs for visualization authoring. We discuss design implications for future\nvisualization systems and provide insights into how multimodal prompts can\nenhance human-AI collaboration in creative visualization tasks. All materials\nare available at https://OSF.IO/2QRAK.",
      "pdf_url": "http://arxiv.org/pdf/2504.13700v1",
      "published": "2025-04-18T14:00:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.13700v1",
      "categories": [
        "cs.HC",
        "cs.AI"
      ]
    },
    {
      "title": "AnyTSR: Any-Scale Thermal Super-Resolution for UAV",
      "authors": [
        "Mengyuan Li",
        "Changhong Fu",
        "Ziyu Lu",
        "Zijie Zhang",
        "Haobo Zuo",
        "Liangliang Yao"
      ],
      "abstract": "Thermal imaging can greatly enhance the application of intelligent unmanned\naerial vehicles (UAV) in challenging environments. However, the inherent low\nresolution of thermal sensors leads to insufficient details and blurred\nboundaries. Super-resolution (SR) offers a promising solution to address this\nissue, while most existing SR methods are designed for fixed-scale SR. They are\ncomputationally expensive and inflexible in practical applications. To address\nabove issues, this work proposes a novel any-scale thermal SR method (AnyTSR)\nfor UAV within a single model. Specifically, a new image encoder is proposed to\nexplicitly assign specific feature code to enable more accurate and flexible\nrepresentation. Additionally, by effectively embedding coordinate offset\ninformation into the local feature ensemble, an innovative any-scale upsampler\nis proposed to better understand spatial relationships and reduce artifacts.\nMoreover, a novel dataset (UAV-TSR), covering both land and water scenes, is\nconstructed for thermal SR tasks. Experimental results demonstrate that the\nproposed method consistently outperforms state-of-the-art methods across all\nscaling factors as well as generates more accurate and detailed high-resolution\nimages. The code is located at https://github.com/vision4robotics/AnyTSR.",
      "pdf_url": "http://arxiv.org/pdf/2504.13682v1",
      "published": "2025-04-18T13:23:25+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.13682v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Revisiting Uncertainty Quantification Evaluation in Language Models: Spurious Interactions with Response Length Bias Results",
      "authors": [
        "Andrea Santilli",
        "Adam Golinski",
        "Michael Kirchhof",
        "Federico Danieli",
        "Arno Blaas",
        "Miao Xiong",
        "Luca Zappella",
        "Sinead Williamson"
      ],
      "abstract": "Uncertainty Quantification (UQ) in Language Models (LMs) is crucial for\nimproving their safety and reliability. Evaluations often use performance\nmetrics like AUROC to assess how well UQ methods (e.g., negative sequence\nprobabilities) correlate with task correctness functions (e.g., ROUGE-L). In\nthis paper, we show that commonly used correctness functions bias UQ\nevaluations by inflating the performance of certain UQ methods. We evaluate 7\ncorrectness functions -- from lexical-based and embedding-based metrics to\nLLM-as-a-judge approaches -- across 4 datasets x 4 models x 6 UQ methods. Our\nanalysis reveals that length biases in the errors of these correctness\nfunctions distort UQ assessments by interacting with length biases in UQ\nmethods. We identify LLM-as-a-judge approaches as among the least length-biased\nchoices and hence a potential solution to mitigate these biases.",
      "pdf_url": "http://arxiv.org/pdf/2504.13677v1",
      "published": "2025-04-18T13:13:42+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.13677v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Trace Gadgets: Minimizing Code Context for Machine Learning-Based Vulnerability Prediction",
      "authors": [
        "Felix Mächtle",
        "Nils Loose",
        "Tim Schulz",
        "Florian Sieck",
        "Jan-Niclas Serr",
        "Ralf Möller",
        "Thomas Eisenbarth"
      ],
      "abstract": "As the number of web applications and API endpoints exposed to the Internet\ncontinues to grow, so does the number of exploitable vulnerabilities. Manually\nidentifying such vulnerabilities is tedious. Meanwhile, static security\nscanners tend to produce many false positives. While machine learning-based\napproaches are promising, they typically perform well only in scenarios where\ntraining and test data are closely related. A key challenge for ML-based\nvulnerability detection is providing suitable and concise code context, as\nexcessively long contexts negatively affect the code comprehension capabilities\nof machine learning models, particularly smaller ones.\n  This work introduces Trace Gadgets, a novel code representation that\nminimizes code context by removing non-related code. Trace Gadgets precisely\ncapture the statements that cover the path to the vulnerability. As input for\nML models, Trace Gadgets provide a minimal but complete context, thereby\nimproving the detection performance. Moreover, we collect a large-scale dataset\ngenerated from real-world applications with manually curated labels to further\nimprove the performance of ML-based vulnerability detectors. Our results show\nthat state-of-the-art machine learning models perform best when using Trace\nGadgets compared to previous code representations, surpassing the detection\ncapabilities of industry-standard static scanners such as GitHub's CodeQL by at\nleast 4% on a fully unseen dataset. By applying our framework to real-world\napplications, we identify and report previously unknown vulnerabilities in\nwidely deployed software.",
      "pdf_url": "http://arxiv.org/pdf/2504.13676v1",
      "published": "2025-04-18T13:13:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.13676v1",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "title": "Large Language Models Will Change The Way Children Think About Technology And Impact Every Interaction Paradigm",
      "authors": [
        "Russell Beale"
      ],
      "abstract": "This paper presents a hopeful perspective on the potentially dramatic impacts\nof Large Language Models on how we children learn and how they will expect to\ninteract with technology. We review the effects of LLMs on education so far,\nand make the case that these effects are minor compared to the upcoming changes\nthat are occurring. We present a small scenario and self-ethnographic study\ndemonstrating the effects of these changes, and define five significant\nconsiderations that interactive systems designers will have to accommodate in\nthe future.",
      "pdf_url": "http://arxiv.org/pdf/2504.13667v1",
      "published": "2025-04-18T13:01:27+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.13667v1",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Do Prompt Patterns Affect Code Quality? A First Empirical Assessment of ChatGPT-Generated Code",
      "authors": [
        "Antonio Della Porta",
        "Stefano Lambiase",
        "Fabio Palomba"
      ],
      "abstract": "Large Language Models (LLMs) have rapidly transformed software development,\nespecially in code generation. However, their inconsistent performance, prone\nto hallucinations and quality issues, complicates program comprehension and\nhinders maintainability. Research indicates that prompt engineering-the\npractice of designing inputs to direct LLMs toward generating relevant\noutputs-may help address these challenges. In this regard, researchers have\nintroduced prompt patterns, structured templates intended to guide users in\nformulating their requests. However, the influence of prompt patterns on code\nquality has yet to be thoroughly investigated. An improved understanding of\nthis relationship would be essential to advancing our collective knowledge on\nhow to effectively use LLMs for code generation, thereby enhancing their\nunderstandability in contemporary software development. This paper empirically\ninvestigates the impact of prompt patterns on code quality, specifically\nmaintainability, security, and reliability, using the Dev-GPT dataset. Results\nshow that Zero-Shot prompting is most common, followed by Zero-Shot with\nChain-of-Thought and Few-Shot. Analysis of 7583 code files across quality\nmetrics revealed minimal issues, with Kruskal-Wallis tests indicating no\nsignificant differences among patterns, suggesting that prompt structure may\nnot substantially impact these quality metrics in ChatGPT-assisted code\ngeneration.",
      "pdf_url": "http://arxiv.org/pdf/2504.13656v1",
      "published": "2025-04-18T12:37:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.13656v1",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "Multi-Type Context-Aware Conversational Recommender Systems via Mixture-of-Experts",
      "authors": [
        "Jie Zou",
        "Cheng Lin",
        "Weikang Guo",
        "Zheng Wang",
        "Jiwei Wei",
        "Yang Yang",
        "Hengtao Shen"
      ],
      "abstract": "Conversational recommender systems enable natural language conversations and\nthus lead to a more engaging and effective recommendation scenario. As the\nconversations for recommender systems usually contain limited contextual\ninformation, many existing conversational recommender systems incorporate\nexternal sources to enrich the contextual information. However, how to combine\ndifferent types of contextual information is still a challenge. In this paper,\nwe propose a multi-type context-aware conversational recommender system, called\nMCCRS, effectively fusing multi-type contextual information via\nmixture-of-experts to improve conversational recommender systems. MCCRS\nincorporates both structured information and unstructured information,\nincluding the structured knowledge graph, unstructured conversation history,\nand unstructured item reviews. It consists of several experts, with each expert\nspecialized in a particular domain (i.e., one specific contextual information).\nMultiple experts are then coordinated by a ChairBot to generate the final\nresults. Our proposed MCCRS model takes advantage of different contextual\ninformation and the specialization of different experts followed by a ChairBot\nbreaks the model bottleneck on a single contextual information. Experimental\nresults demonstrate that our proposed MCCRS method achieves significantly\nhigher performance compared to existing baselines.",
      "pdf_url": "http://arxiv.org/pdf/2504.13655v1",
      "published": "2025-04-18T12:28:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.13655v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ]
    },
    {
      "title": "Lightweight LiDAR-Camera 3D Dynamic Object Detection and Multi-Class Trajectory Prediction",
      "authors": [
        "Yushen He",
        "Lei Zhao",
        "Tianchen Deng",
        "Zipeng Fang",
        "Weidong Chen"
      ],
      "abstract": "Service mobile robots are often required to avoid dynamic objects while\nperforming their tasks, but they usually have only limited computational\nresources. So we present a lightweight multi-modal framework for 3D object\ndetection and trajectory prediction. Our system synergistically integrates\nLiDAR and camera inputs to achieve real-time perception of pedestrians,\nvehicles, and riders in 3D space. The framework proposes two novel modules: 1)\na Cross-Modal Deformable Transformer (CMDT) for object detection with high\naccuracy and acceptable amount of computation, and 2) a Reference\nTrajectory-based Multi-Class Transformer (RTMCT) for efficient and diverse\ntrajectory prediction of mult-class objects with flexible trajectory lengths.\nEvaluations on the CODa benchmark demonstrate superior performance over\nexisting methods across detection (+2.03% in mAP) and trajectory prediction\n(-0.408m in minADE5 of pedestrians) metrics. Remarkably, the system exhibits\nexceptional deployability - when implemented on a wheelchair robot with an\nentry-level NVIDIA 3060 GPU, it achieves real-time inference at 13.2 fps. To\nfacilitate reproducibility and practical deployment, we release the related\ncode of the method at https://github.com/TossherO/3D_Perception and its ROS\ninference version at https://github.com/TossherO/ros_packages.",
      "pdf_url": "http://arxiv.org/pdf/2504.13647v1",
      "published": "2025-04-18T11:59:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.13647v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Exploring the Potential for Large Language Models to Demonstrate Rational Probabilistic Beliefs",
      "authors": [
        "Gabriel Freedman",
        "Francesca Toni"
      ],
      "abstract": "Advances in the general capabilities of large language models (LLMs) have led\nto their use for information retrieval, and as components in automated decision\nsystems. A faithful representation of probabilistic reasoning in these models\nmay be essential to ensure trustworthy, explainable and effective performance\nin these tasks. Despite previous work suggesting that LLMs can perform complex\nreasoning and well-calibrated uncertainty quantification, we find that current\nversions of this class of model lack the ability to provide rational and\ncoherent representations of probabilistic beliefs. To demonstrate this, we\nintroduce a novel dataset of claims with indeterminate truth values and apply a\nnumber of well-established techniques for uncertainty quantification to measure\nthe ability of LLM's to adhere to fundamental properties of probabilistic\nreasoning.",
      "pdf_url": "http://arxiv.org/pdf/2504.13644v1",
      "published": "2025-04-18T11:50:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.13644v1",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Multi-modal Knowledge Graph Generation with Semantics-enriched Prompts",
      "authors": [
        "Yajing Xu",
        "Zhiqiang Liu",
        "Jiaoyan Chen",
        "Mingchen Tu",
        "Zhuo Chen",
        "Jeff Z. Pan",
        "Yichi Zhang",
        "Yushan Zhu",
        "Wen Zhang",
        "Huajun Chen"
      ],
      "abstract": "Multi-modal Knowledge Graphs (MMKGs) have been widely applied across various\ndomains for knowledge representation. However, the existing MMKGs are\nsignificantly fewer than required, and their construction faces numerous\nchallenges, particularly in ensuring the selection of high-quality,\ncontextually relevant images for knowledge graph enrichment. To address these\nchallenges, we present a framework for constructing MMKGs from conventional\nKGs. Furthermore, to generate higher-quality images that are more relevant to\nthe context in the given knowledge graph, we designed a neighbor selection\nmethod called Visualizable Structural Neighbor Selection (VSNS). This method\nconsists of two modules: Visualizable Neighbor Selection (VNS) and Structural\nNeighbor Selection (SNS). The VNS module filters relations that are difficult\nto visualize, while the SNS module selects neighbors that most effectively\ncapture the structural characteristics of the entity. To evaluate the quality\nof the generated images, we performed qualitative and quantitative evaluations\non two datasets, MKG-Y and DB15K. The experimental results indicate that using\nthe VSNS method to select neighbors results in higher-quality images that are\nmore relevant to the knowledge graph.",
      "pdf_url": "http://arxiv.org/pdf/2504.13631v1",
      "published": "2025-04-18T11:12:49+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.13631v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Divergent LLM Adoption and Heterogeneous Convergence Paths in Research Writing",
      "authors": [
        "Cong William Lin",
        "Wu Zhu"
      ],
      "abstract": "Large Language Models (LLMs), such as ChatGPT, are reshaping content creation\nand academic writing. This study investigates the impact of AI-assisted\ngenerative revisions on research manuscripts, focusing on heterogeneous\nadoption patterns and their influence on writing convergence. Leveraging a\ndataset of over 627,000 academic papers from arXiv, we develop a novel\nclassification framework by fine-tuning prompt- and discipline-specific large\nlanguage models to detect the style of ChatGPT-revised texts. Our findings\nreveal substantial disparities in LLM adoption across academic disciplines,\ngender, native language status, and career stage, alongside a rapid evolution\nin scholarly writing styles. Moreover, LLM usage enhances clarity, conciseness,\nand adherence to formal writing conventions, with improvements varying by\nrevision type. Finally, a difference-in-differences analysis shows that while\nLLMs drive convergence in academic writing, early adopters, male researchers,\nnon-native speakers, and junior scholars exhibit the most pronounced stylistic\nshifts, aligning their writing more closely with that of established\nresearchers.",
      "pdf_url": "http://arxiv.org/pdf/2504.13629v1",
      "published": "2025-04-18T11:09:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.13629v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "econ.GN",
        "q-fin.EC"
      ]
    },
    {
      "title": "Thought Manipulation: External Thought Can Be Efficient for Large Reasoning Models",
      "authors": [
        "Yule Liu",
        "Jingyi Zheng",
        "Zhen Sun",
        "Zifan Peng",
        "Wenhan Dong",
        "Zeyang Sha",
        "Shiwen Cui",
        "Weiqiang Wang",
        "Xinlei He"
      ],
      "abstract": "Recent advancements in large reasoning models (LRMs) have demonstrated the\neffectiveness of scaling test-time computation to enhance reasoning\ncapabilities in multiple tasks. However, LRMs typically suffer from\n\"overthinking\" problems, where models generate significantly redundant\nreasoning steps while bringing limited performance gains. Existing work relies\non fine-tuning to mitigate overthinking, which requires additional data,\nunconventional training setups, risky safety misalignment, and poor\ngeneralization.\n  Through empirical analysis, we reveal an important characteristic of LRM\nbehaviors that placing external CoTs generated by smaller models between the\nthinking token ($\\texttt{<think>}$ and $\\texttt{</think>)}$ can effectively\nmanipulate the model to generate fewer thoughts. Building on these insights, we\npropose a simple yet efficient pipeline, ThoughtMani, to enable LRMs to bypass\nunnecessary intermediate steps and reduce computational costs significantly. We\nconduct extensive experiments to validate the utility and efficiency of\nThoughtMani. For instance, when applied to QwQ-32B on the LiveBench/Code\ndataset, ThoughtMani keeps the original performance and reduces output token\ncounts by approximately 30%, with little overhead from the CoT generator.\nFurthermore, we find that ThoughtMani enhances safety alignment by an average\nof 10%. Since model vendors typically serve models of different sizes\nsimultaneously, ThoughtMani provides an effective way to construct more\nefficient and accessible LRMs for real-world applications.",
      "pdf_url": "http://arxiv.org/pdf/2504.13626v1",
      "published": "2025-04-18T11:07:19+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.13626v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Adaptive Long-term Embedding with Denoising and Augmentation for Recommendation",
      "authors": [
        "Zahra Akhlaghi",
        "Mostafa Haghir Chehreghani"
      ],
      "abstract": "The rapid growth of the internet has made personalized recommendation systems\nindispensable. Graph-based sequential recommendation systems, powered by Graph\nNeural Networks (GNNs), effectively capture complex user-item interactions but\noften face challenges such as noise and static representations. In this paper,\nwe introduce the Adaptive Long-term Embedding with Denoising and Augmentation\nfor Recommendation (ALDA4Rec) method, a novel model that constructs an\nitem-item graph, filters noise through community detection, and enriches\nuser-item interactions. Graph Convolutional Networks (GCNs) are then employed\nto learn short-term representations, while averaging, GRUs, and attention\nmechanisms are utilized to model long-term embeddings. An MLP-based adaptive\nweighting strategy is further incorporated to dynamically optimize long-term\nuser preferences. Experiments conducted on four real-world datasets demonstrate\nthat ALDA4Rec outperforms state-of-the-art baselines, delivering notable\nimprovements in both accuracy and robustness. The source code is available at\nhttps://github.com/zahraakhlaghi/ALDA4Rec.",
      "pdf_url": "http://arxiv.org/pdf/2504.13614v1",
      "published": "2025-04-18T10:42:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.13614v1",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.NE"
      ]
    },
    {
      "title": "Entropic Time Schedulers for Generative Diffusion Models",
      "authors": [
        "Dejan Stancevic",
        "Luca Ambrogioni"
      ],
      "abstract": "The practical performance of generative diffusion models depends on the\nappropriate choice of the noise scheduling function, which can also be\nequivalently expressed as a time reparameterization. In this paper, we present\na time scheduler that selects sampling points based on entropy rather than\nuniform time spacing, ensuring that each point contributes an equal amount of\ninformation to the final generation. We prove that this time reparameterization\ndoes not depend on the initial choice of time. Furthermore, we provide a\ntractable exact formula to estimate this \\emph{entropic time} for a trained\nmodel using the training loss without substantial overhead. Alongside the\nentropic time, inspired by the optimality results, we introduce a rescaled\nentropic time. In our experiments with mixtures of Gaussian distributions and\nImageNet, we show that using the (rescaled) entropic times greatly improves the\ninference performance of trained models. In particular, we found that the image\nquality in pretrained EDM2 models, as evaluated by FID and FD-DINO scores, can\nbe substantially increased by the rescaled entropic time reparameterization\nwithout increasing the number of function evaluations, with greater\nimprovements in the few NFEs regime.",
      "pdf_url": "http://arxiv.org/pdf/2504.13612v1",
      "published": "2025-04-18T10:35:19+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.13612v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "FocusNet: Transformer-enhanced Polyp Segmentation with Local and Pooling Attention",
      "authors": [
        "Jun Zeng",
        "KC Santosh",
        "Deepak Rajan Nayak",
        "Thomas de Lange",
        "Jonas Varkey",
        "Tyler Berzin",
        "Debesh Jha"
      ],
      "abstract": "Colonoscopy is vital in the early diagnosis of colorectal polyps. Regular\nscreenings can effectively prevent benign polyps from progressing to CRC. While\ndeep learning has made impressive strides in polyp segmentation, most existing\nmodels are trained on single-modality and single-center data, making them less\neffective in real-world clinical environments. To overcome these limitations,\nwe propose FocusNet, a Transformer-enhanced focus attention network designed to\nimprove polyp segmentation. FocusNet incorporates three essential modules: the\nCross-semantic Interaction Decoder Module (CIDM) for generating coarse\nsegmentation maps, the Detail Enhancement Module (DEM) for refining shallow\nfeatures, and the Focus Attention Module (FAM), to balance local detail and\nglobal context through local and pooling attention mechanisms. We evaluate our\nmodel on PolypDB, a newly introduced dataset with multi-modality and\nmulti-center data for building more reliable segmentation methods. Extensive\nexperiments showed that FocusNet consistently outperforms existing\nstate-of-the-art approaches with a high dice coefficients of 82.47% on the BLI\nmodality, 88.46% on FICE, 92.04% on LCI, 82.09% on the NBI and 93.42% on WLI\nmodality, demonstrating its accuracy and robustness across five different\nmodalities. The source code for FocusNet is available at\nhttps://github.com/JunZengz/FocusNet.",
      "pdf_url": "http://arxiv.org/pdf/2504.13597v1",
      "published": "2025-04-18T09:59:26+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.13597v1",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "HAECcity: Open-Vocabulary Scene Understanding of City-Scale Point Clouds with Superpoint Graph Clustering",
      "authors": [
        "Alexander Rusnak",
        "Frédéric Kaplan"
      ],
      "abstract": "Traditional 3D scene understanding techniques are generally predicated on\nhand-annotated label sets, but in recent years a new class of open-vocabulary\n3D scene understanding techniques has emerged. Despite the success of this\nparadigm on small scenes, existing approaches cannot scale efficiently to\ncity-scale 3D datasets. In this paper, we present Hierarchical vocab-Agnostic\nExpert Clustering (HAEC), after the latin word for 'these', a superpoint graph\nclustering based approach which utilizes a novel mixture of experts graph\ntransformer for its backbone. We administer this highly scalable approach to\nthe first application of open-vocabulary scene understanding on the SensatUrban\ncity-scale dataset. We also demonstrate a synthetic labeling pipeline which is\nderived entirely from the raw point clouds with no hand-annotation. Our\ntechnique can help unlock complex operations on dense urban 3D scenes and open\na new path forward in the processing of digital twins.",
      "pdf_url": "http://arxiv.org/pdf/2504.13590v1",
      "published": "2025-04-18T09:48:42+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.13590v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "RAG Without the Lag: Interactive Debugging for Retrieval-Augmented Generation Pipelines",
      "authors": [
        "Quentin Romero Lauro",
        "Shreya Shankar",
        "Sepanta Zeighami",
        "Aditya Parameswaran"
      ],
      "abstract": "Retrieval-augmented generation (RAG) pipelines have become the de-facto\napproach for building AI assistants with access to external, domain-specific\nknowledge. Given a user query, RAG pipelines typically first retrieve (R)\nrelevant information from external sources, before invoking a Large Language\nModel (LLM), augmented (A) with this information, to generate (G) responses.\nModern RAG pipelines frequently chain multiple retrieval and generation\ncomponents, in any order. However, developing effective RAG pipelines is\nchallenging because retrieval and generation components are intertwined, making\nit hard to identify which component(s) cause errors in the eventual output. The\nparameters with the greatest impact on output quality often require hours of\npre-processing after each change, creating prohibitively slow feedback cycles.\nTo address these challenges, we present RAGGY, a developer tool that combines a\nPython library of composable RAG primitives with an interactive interface for\nreal-time debugging. We contribute the design and implementation of RAGGY,\ninsights into expert debugging patterns through a qualitative study with 12\nengineers, and design implications for future RAG tools that better align with\ndevelopers' natural workflows.",
      "pdf_url": "http://arxiv.org/pdf/2504.13587v1",
      "published": "2025-04-18T09:38:49+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.13587v1",
      "categories": [
        "cs.HC",
        "cs.AI"
      ]
    },
    {
      "title": "MetaDSE: A Few-shot Meta-learning Framework for Cross-workload CPU Design Space Exploration",
      "authors": [
        "Runzhen Xue",
        "Hao Wu",
        "Mingyu Yan",
        "Ziheng Xiao",
        "Xiaochun Ye",
        "Dongrui Fan"
      ],
      "abstract": "Cross-workload design space exploration (DSE) is crucial in CPU architecture\ndesign. Existing DSE methods typically employ the transfer learning technique\nto leverage knowledge from source workloads, aiming to minimize the requirement\nof target workload simulation. However, these methods struggle with\noverfitting, data ambiguity, and workload dissimilarity.\n  To address these challenges, we reframe the cross-workload CPU DSE task as a\nfew-shot meta-learning problem and further introduce MetaDSE. By leveraging\nmodel agnostic meta-learning, MetaDSE swiftly adapts to new target workloads,\ngreatly enhancing the efficiency of cross-workload CPU DSE. Additionally,\nMetaDSE introduces a novel knowledge transfer method called the\nworkload-adaptive architectural mask algorithm, which uncovers the inherent\nproperties of the architecture. Experiments on SPEC CPU 2017 demonstrate that\nMetaDSE significantly reduces prediction error by 44.3\\% compared to the\nstate-of-the-art. MetaDSE is open-sourced and available at this\n\\href{https://anonymous.4open.science/r/Meta_DSE-02F8}{anonymous GitHub.}",
      "pdf_url": "http://arxiv.org/pdf/2504.13568v1",
      "published": "2025-04-18T09:11:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.13568v1",
      "categories": [
        "cs.AR",
        "cs.AI"
      ]
    },
    {
      "title": "Zero-Shot Industrial Anomaly Segmentation with Image-Aware Prompt Generation",
      "authors": [
        "SoYoung Park",
        "Hyewon Lee",
        "Mingyu Choi",
        "Seunghoon Han",
        "Jong-Ryul Lee",
        "Sungsu Lim",
        "Tae-Ho Kim"
      ],
      "abstract": "Anomaly segmentation is essential for industrial quality, maintenance, and\nstability. Existing text-guided zero-shot anomaly segmentation models are\neffective but rely on fixed prompts, limiting adaptability in diverse\nindustrial scenarios. This highlights the need for flexible, context-aware\nprompting strategies. We propose Image-Aware Prompt Anomaly Segmentation\n(IAP-AS), which enhances anomaly segmentation by generating dynamic,\ncontext-aware prompts using an image tagging model and a large language model\n(LLM). IAP-AS extracts object attributes from images to generate context-aware\nprompts, improving adaptability and generalization in dynamic and unstructured\nindustrial environments. In our experiments, IAP-AS improves the F1-max metric\nby up to 10%, demonstrating superior adaptability and generalization. It\nprovides a scalable solution for anomaly segmentation across industries",
      "pdf_url": "http://arxiv.org/pdf/2504.13560v1",
      "published": "2025-04-18T08:58:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.13560v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Transformers Can Overcome the Curse of Dimensionality: A Theoretical Study from an Approximation Perspective",
      "authors": [
        "Yuling Jiao",
        "Yanming Lai",
        "Yang Wang",
        "Bokai Yan"
      ],
      "abstract": "The Transformer model is widely used in various application areas of machine\nlearning, such as natural language processing. This paper investigates the\napproximation of the H\\\"older continuous function class\n$\\mathcal{H}_{Q}^{\\beta}\\left([0,1]^{d\\times n},\\mathbb{R}^{d\\times n}\\right)$\nby Transformers and constructs several Transformers that can overcome the curse\nof dimensionality. These Transformers consist of one self-attention layer with\none head and the softmax function as the activation function, along with\nseveral feedforward layers. For example, to achieve an approximation accuracy\nof $\\epsilon$, if the activation functions of the feedforward layers in the\nTransformer are ReLU and floor, only\n$\\mathcal{O}\\left(\\log\\frac{1}{\\epsilon}\\right)$ layers of feedforward layers\nare needed, with widths of these layers not exceeding\n$\\mathcal{O}\\left(\\frac{1}{\\epsilon^{2/\\beta}}\\log\\frac{1}{\\epsilon}\\right)$.\nIf other activation functions are allowed in the feedforward layers, the width\nof the feedforward layers can be further reduced to a constant. These results\ndemonstrate that Transformers have a strong expressive capability. The\nconstruction in this paper is based on the Kolmogorov-Arnold Representation\nTheorem and does not require the concept of contextual mapping, hence our proof\nis more intuitively clear compared to previous Transformer approximation works.\nAdditionally, the translation technique proposed in this paper helps to apply\nthe previous approximation results of feedforward neural networks to\nTransformer research.",
      "pdf_url": "http://arxiv.org/pdf/2504.13558v1",
      "published": "2025-04-18T08:56:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.13558v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "41A25, 68T07, 68T50",
        "G.0"
      ]
    },
    {
      "title": "Task Assignment and Exploration Optimization for Low Altitude UAV Rescue via Generative AI Enhanced Multi-agent Reinforcement Learning",
      "authors": [
        "Xin Tang",
        "Qian Chen",
        "Wenjie Weng",
        "Chao Jin",
        "Zhang Liu",
        "Jiacheng Wang",
        "Geng Sun",
        "Xiaohuan Li",
        "Dusit Niyato"
      ],
      "abstract": "Artificial Intelligence (AI)-driven convolutional neural networks enhance\nrescue, inspection, and surveillance tasks performed by low-altitude uncrewed\naerial vehicles (UAVs) and ground computing nodes (GCNs) in unknown\nenvironments. However, their high computational demands often exceed a single\nUAV's capacity, leading to system instability, further exacerbated by the\nlimited and dynamic resources of GCNs. To address these challenges, this paper\nproposes a novel cooperation framework involving UAVs, ground-embedded robots\n(GERs), and high-altitude platforms (HAPs), which enable resource pooling\nthrough UAV-to-GER (U2G) and UAV-to-HAP (U2H) communications to provide\ncomputing services for UAV offloaded tasks. Specifically, we formulate the\nmulti-objective optimization problem of task assignment and exploration\noptimization in UAVs as a dynamic long-term optimization problem. Our objective\nis to minimize task completion time and energy consumption while ensuring\nsystem stability over time. To achieve this, we first employ the Lyapunov\noptimization technique to transform the original problem, with stability\nconstraints, into a per-slot deterministic problem. We then propose an\nalgorithm named HG-MADDPG, which combines the Hungarian algorithm with a\ngenerative diffusion model (GDM)-based multi-agent deep deterministic policy\ngradient (MADDPG) approach. We first introduce the Hungarian algorithm as a\nmethod for exploration area selection, enhancing UAV efficiency in interacting\nwith the environment. We then innovatively integrate the GDM and multi-agent\ndeep deterministic policy gradient (MADDPG) to optimize task assignment\ndecisions, such as task offloading and resource allocation. Simulation results\ndemonstrate the effectiveness of the proposed approach, with significant\nimprovements in task offloading efficiency, latency reduction, and system\nstability compared to baseline methods.",
      "pdf_url": "http://arxiv.org/pdf/2504.13554v1",
      "published": "2025-04-18T08:44:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.13554v1",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ]
    },
    {
      "title": "Q-FAKER: Query-free Hard Black-box Attack via Controlled Generation",
      "authors": [
        "CheolWon Na",
        "YunSeok Choi",
        "Jee-Hyong Lee"
      ],
      "abstract": "Many adversarial attack approaches are proposed to verify the vulnerability\nof language models. However, they require numerous queries and the information\non the target model. Even black-box attack methods also require the target\nmodel's output information. They are not applicable in real-world scenarios, as\nin hard black-box settings where the target model is closed and inaccessible.\nEven the recently proposed hard black-box attacks still require many queries\nand demand extremely high costs for training adversarial generators. To address\nthese challenges, we propose Q-faker (Query-free Hard Black-box Attacker), a\nnovel and efficient method that generates adversarial examples without\naccessing the target model. To avoid accessing the target model, we use a\nsurrogate model instead. The surrogate model generates adversarial sentences\nfor a target-agnostic attack. During this process, we leverage controlled\ngeneration techniques. We evaluate our proposed method on eight datasets.\nExperimental results demonstrate our method's effectiveness including high\ntransferability and the high quality of the generated adversarial examples, and\nprove its practical in hard black-box settings.",
      "pdf_url": "http://arxiv.org/pdf/2504.13551v1",
      "published": "2025-04-18T08:36:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.13551v1",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Beyond One-Hot Labels: Semantic Mixing for Model Calibration",
      "authors": [
        "Haoyang Luo",
        "Linwei Tao",
        "Minjing Dong",
        "Chang Xu"
      ],
      "abstract": "Model calibration seeks to ensure that models produce confidence scores that\naccurately reflect the true likelihood of their predictions being correct.\nHowever, existing calibration approaches are fundamentally tied to datasets of\none-hot labels implicitly assuming full certainty in all the annotations. Such\ndatasets are effective for classification but provides insufficient knowledge\nof uncertainty for model calibration, necessitating the curation of datasets\nwith numerically rich ground-truth confidence values. However, due to the\nscarcity of uncertain visual examples, such samples are not easily available as\nreal datasets. In this paper, we introduce calibration-aware data augmentation\nto create synthetic datasets of diverse samples and their ground-truth\nuncertainty. Specifically, we present Calibration-aware Semantic Mixing (CSM),\na novel framework that generates training samples with mixed class\ncharacteristics and annotates them with distinct confidence scores via\ndiffusion models. Based on this framework, we propose calibrated reannotation\nto tackle the misalignment between the annotated confidence score and the\nmixing ratio during the diffusion reverse process. Besides, we explore the loss\nfunctions that better fit the new data representation paradigm. Experimental\nresults demonstrate that CSM achieves superior calibration compared to the\nstate-of-the-art calibration approaches. Code is available at\ngithub.com/E-Galois/CSM.",
      "pdf_url": "http://arxiv.org/pdf/2504.13548v1",
      "published": "2025-04-18T08:26:18+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.13548v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Enhancing Multilingual Sentiment Analysis with Explainability for Sinhala, English, and Code-Mixed Content",
      "authors": [
        "Azmarah Rizvi",
        "Navojith Thamindu",
        "A. M. N. H. Adhikari",
        "W. P. U. Senevirathna",
        "Dharshana Kasthurirathna",
        "Lakmini Abeywardhana"
      ],
      "abstract": "Sentiment analysis is crucial for brand reputation management in the banking\nsector, where customer feedback spans English, Sinhala, Singlish, and\ncode-mixed text. Existing models struggle with low-resource languages like\nSinhala and lack interpretability for practical use. This research develops a\nhybrid aspect-based sentiment analysis framework that enhances multilingual\ncapabilities with explainable outputs. Using cleaned banking customer reviews,\nwe fine-tune XLM-RoBERTa for Sinhala and code-mixed text, integrate\ndomain-specific lexicon correction, and employ BERT-base-uncased for English.\nThe system classifies sentiment (positive, neutral, negative) with confidence\nscores, while SHAP and LIME improve interpretability by providing real-time\nsentiment explanations. Experimental results show that our approaches\noutperform traditional transformer-based classifiers, achieving 92.3 percent\naccuracy and an F1-score of 0.89 in English and 88.4 percent in Sinhala and\ncode-mixed content. An explainability analysis reveals key sentiment drivers,\nimproving trust and transparency. A user-friendly interface delivers\naspect-wise sentiment insights, ensuring accessibility for businesses. This\nresearch contributes to robust, transparent sentiment analysis for financial\napplications by bridging gaps in multilingual, low-resource NLP and\nexplainability.",
      "pdf_url": "http://arxiv.org/pdf/2504.13545v1",
      "published": "2025-04-18T08:21:12+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.13545v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "SwitchMT: An Adaptive Context Switching Methodology for Scalable Multi-Task Learning in Intelligent Autonomous Agents",
      "authors": [
        "Avaneesh Devkota",
        "Rachmad Vidya Wicaksana Putra",
        "Muhammad Shafique"
      ],
      "abstract": "The ability to train intelligent autonomous agents (such as mobile robots) on\nmultiple tasks is crucial for adapting to dynamic real-world environments.\nHowever, state-of-the-art reinforcement learning (RL) methods only excel in\nsingle-task settings, and still struggle to generalize across multiple tasks\ndue to task interference. Moreover, real-world environments also demand the\nagents to have data stream processing capabilities. Toward this, a\nstate-of-the-art work employs Spiking Neural Networks (SNNs) to improve\nmulti-task learning by exploiting temporal information in data stream, while\nenabling lowpower/energy event-based operations. However, it relies on fixed\ncontext/task-switching intervals during its training, hence limiting the\nscalability and effectiveness of multi-task learning. To address these\nlimitations, we propose SwitchMT, a novel adaptive task-switching methodology\nfor RL-based multi-task learning in autonomous agents. Specifically, SwitchMT\nemploys the following key ideas: (1) a Deep Spiking Q-Network with active\ndendrites and dueling structure, that utilizes task-specific context signals to\ncreate specialized sub-networks; and (2) an adaptive task-switching policy that\nleverages both rewards and internal dynamics of the network parameters.\nExperimental results demonstrate that SwitchMT achieves superior performance in\nmulti-task learning compared to state-of-the-art methods. It achieves\ncompetitive scores in multiple Atari games (i.e., Pong: -8.8, Breakout: 5.6,\nand Enduro: 355.2) compared to the state-of-the-art, showing its better\ngeneralized learning capability. These results highlight the effectiveness of\nour SwitchMT methodology in addressing task interference while enabling\nmulti-task learning automation through adaptive task switching, thereby paving\nthe way for more efficient generalist agents with scalable multi-task learning\ncapabilities.",
      "pdf_url": "http://arxiv.org/pdf/2504.13541v1",
      "published": "2025-04-18T08:12:59+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.13541v1",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ]
    },
    {
      "title": "CoT-RAG: Integrating Chain of Thought and Retrieval-Augmented Generation to Enhance Reasoning in Large Language Models",
      "authors": [
        "Feiyang Li",
        "Peng Fang",
        "Zhan Shi",
        "Arijit Khan",
        "Fang Wang",
        "Dan Feng",
        "Weihao Wang",
        "Xin Zhang",
        "Yongjian Cui"
      ],
      "abstract": "While chain-of-thought (CoT) reasoning improves the performance of large\nlanguage models (LLMs) in complex tasks, it still has two main challenges: the\nlow reliability of relying solely on LLMs to generate reasoning chains and the\ninterference of natural language reasoning chains on the inference logic of\nLLMs. To address these issues, we propose CoT-RAG, a novel reasoning framework\nwith three key designs: (i) Knowledge Graph-driven CoT Generation, featuring\nknowledge graphs to modulate reasoning chain generation of LLMs, thereby\nenhancing reasoning credibility; (ii) Learnable Knowledge Case-aware RAG, which\nincorporates retrieval-augmented generation (RAG) into knowledge graphs to\nretrieve relevant sub-cases and sub-descriptions, providing LLMs with learnable\ninformation; (iii) Pseudo-Program Prompting Execution, which encourages LLMs to\nexecute reasoning tasks in pseudo-programs with greater logical rigor. We\nconduct a comprehensive evaluation on nine public datasets, covering three\nreasoning problems. Compared with the-state-of-the-art methods, CoT-RAG\nexhibits a significant accuracy improvement, ranging from 4.0% to 23.0%.\nFurthermore, testing on four domain-specific datasets, CoT-RAG shows remarkable\naccuracy and efficient execution, highlighting its strong practical\napplicability and scalability.",
      "pdf_url": "http://arxiv.org/pdf/2504.13534v1",
      "published": "2025-04-18T07:55:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.13534v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Deep Learning Models Meet Financial Data Modalities",
      "authors": [
        "Kasymkhan Khubiev",
        "Michail Semenov"
      ],
      "abstract": "Algorithmic trading relies on extracting meaningful signals from diverse\nfinancial data sources, including candlestick charts, order statistics on put\nand canceled orders, traded volume data, limit order books, and news flow.\nWhile deep learning has demonstrated remarkable success in processing\nunstructured data and has significantly advanced natural language processing,\nits application to structured financial data remains an ongoing challenge. This\nstudy investigates the integration of deep learning models with financial data\nmodalities, aiming to enhance predictive performance in trading strategies and\nportfolio optimization. We present a novel approach to incorporating limit\norder book analysis into algorithmic trading by developing embedding techniques\nand treating sequential limit order book snapshots as distinct input channels\nin an image-based representation. Our methodology for processing limit order\nbook data achieves state-of-the-art performance in high-frequency trading\nalgorithms, underscoring the effectiveness of deep learning in financial\napplications.",
      "pdf_url": "http://arxiv.org/pdf/2504.13521v1",
      "published": "2025-04-18T07:19:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.13521v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE",
        "q-fin.ST"
      ]
    },
    {
      "title": "Optimizing Electric Vehicle Charging Station Locations: A Data-driven System with Multi-source Fusion",
      "authors": [
        "Lihuan Li",
        "Du Yin",
        "Hao Xue",
        "David Lillo-Trynes",
        "Flora Salim"
      ],
      "abstract": "With the growing electric vehicles (EVs) charging demand, urban planners face\nthe challenges of providing charging infrastructure at optimal locations. For\nexample, range anxiety during long-distance travel and the inadequate\ndistribution of residential charging stations are the major issues many cities\nface. To achieve reasonable estimation and deployment of the charging demand,\nwe develop a data-driven system based on existing EV trips in New South Wales\n(NSW) state, Australia, incorporating multiple factors that enhance the\ngeographical feasibility of recommended charging stations. Our system\nintegrates data sources including EV trip data, geographical data such as route\ndata and Local Government Area (LGA) boundaries, as well as features like fire\nand flood risks, and Points of Interest (POIs). We visualize our results to\nintuitively demonstrate the findings from our data-driven, multi-source fusion\nsystem, and evaluate them through case studies. The outcome of this work can\nprovide a platform for discussion to develop new insights that could be used to\ngive guidance on where to position future EV charging stations.",
      "pdf_url": "http://arxiv.org/pdf/2504.13517v1",
      "published": "2025-04-18T07:10:48+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.13517v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Large Language Models for Validating Network Protocol Parsers",
      "authors": [
        "Mingwei Zheng",
        "Danning Xie",
        "Xiangyu Zhang"
      ],
      "abstract": "Network protocol parsers are essential for enabling correct and secure\ncommunication between devices. Bugs in these parsers can introduce critical\nvulnerabilities, including memory corruption, information leakage, and\ndenial-of-service attacks. An intuitive way to assess parser correctness is to\ncompare the implementation with its official protocol standard. However, this\ncomparison is challenging because protocol standards are typically written in\nnatural language, whereas implementations are in source code. Existing methods\nlike model checking, fuzzing, and differential testing have been used to find\nparsing bugs, but they either require significant manual effort or ignore the\nprotocol standards, limiting their ability to detect semantic violations. To\nenable more automated validation of parser implementations against protocol\nstandards, we propose PARVAL, a multi-agent framework built on large language\nmodels (LLMs). PARVAL leverages the capabilities of LLMs to understand both\nnatural language and code. It transforms both protocol standards and their\nimplementations into a unified intermediate representation, referred to as\nformat specifications, and performs a differential comparison to uncover\ninconsistencies. We evaluate PARVAL on the Bidirectional Forwarding Detection\n(BFD) protocol. Our experiments demonstrate that PARVAL successfully identifies\ninconsistencies between the implementation and its RFC standard, achieving a\nlow false positive rate of 5.6%. PARVAL uncovers seven unique bugs, including\nfive previously unknown issues.",
      "pdf_url": "http://arxiv.org/pdf/2504.13515v1",
      "published": "2025-04-18T07:09:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.13515v1",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "Statistical Validation in Cultural Adaptations of Cognitive Tests: A Multi- Regional Systematic Review",
      "authors": [
        "Miit Daga",
        "Priyasha Mohanty",
        "Ram Krishna",
        "Swarna Priya RM"
      ],
      "abstract": "This systematic review discusses the methodological approaches and\nstatistical confirmations of cross-cultural adaptations of cognitive evaluation\ntools used with different populations. The review considers six seminal studies\non the methodology of cultural adaptation in Europe, Asia, Africa, and South\nAmerica. The results indicate that proper adaptations need holistic models with\ndemographic changes, and education explained as much as 26.76% of the variance\nin MoCA-H scores. Cultural-linguistic factors explained 6.89% of the variance\nin European adaptations of MoCA-H; however, another study on adapted MMSE and\nBCSB among Brazilian Indigenous populations reported excellent diagnostic\nperformance, with a sensitivity of 94.4% and specificity of 99.2%. There was\n78.5% inter-rater agreement on the evaluation of cultural adaptation using the\nManchester Translation Evaluation Checklist. A paramount message of the paper\nis that community feedback is necessary for culturally appropriate preparation,\nstandardized translation protocols also must be included, along with robust\nstatistical validation methodologies for developing cognitive assessment\ninstruments. This review supplies evidence-based frameworks for the further\nadaptation of cognitive assessments in increasingly diverse global health\nsettings.",
      "pdf_url": "http://arxiv.org/pdf/2504.13495v1",
      "published": "2025-04-18T06:25:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.13495v1",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ]
    }
  ]
}