{
  "last_updated": "2025-11-18T00:52:03.806277",
  "papers": [
    {
      "title": "Private Frequency Estimation Via Residue Number Systems",
      "authors": [
        "Héber H. Arcolezi"
      ],
      "abstract": "We present \\textsf{ModularSubsetSelection} (MSS), a new algorithm for locally differentially private (LDP) frequency estimation. Given a universe of size $k$ and $n$ users, our $\\varepsilon$-LDP mechanism encodes each input via a Residue Number System (RNS) over $\\ell$ pairwise-coprime moduli $m_0, \\ldots, m_{\\ell-1}$, and reports a randomly chosen index $j \\in [\\ell]$ along with the perturbed residue using the statistically optimal \\textsf{SubsetSelection}~(SS) (Wang et al. 2016). This design reduces the user communication cost from $Θ\\bigl(ω\\log_2(k/ω)\\bigr)$ bits required by standard SS (with $ω\\approx k/(e^\\varepsilon+1)$) down to $\\lceil \\log_2 \\ell \\rceil + \\lceil \\log_2 m_j \\rceil$ bits, where $m_j < k$. Server-side decoding runs in $Θ(n + r k \\ell)$ time, where $r$ is the number of LSMR (Fong and Saunders 2011) iterations. In practice, with well-conditioned moduli (\\textit{i.e.}, constant $r$ and $\\ell = Θ(\\log k)$), this becomes $Θ(n + k \\log k)$. We prove that MSS achieves worst-case MSE within a constant factor of state-of-the-art protocols such as SS and \\textsf{ProjectiveGeometryResponse} (PGR) (Feldman et al. 2022), while avoiding the algebraic prerequisites and dynamic-programming decoder required by PGR. Empirically, MSS matches the estimation accuracy of SS, PGR, and \\textsf{RAPPOR} (Erlingsson, Pihur, and Korolova 2014) across realistic $(k, \\varepsilon)$ settings, while offering faster decoding than PGR and shorter user messages than SS. Lastly, by sampling from multiple moduli and reporting only a single perturbed residue, MSS achieves the lowest reconstruction-attack success rate among all evaluated LDP protocols.",
      "pdf_url": "https://arxiv.org/pdf/2511.11569v1",
      "published": "2025-11-14T18:58:41+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.11569v1",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "title": "A Unified Convergence Analysis for Semi-Decentralized Learning: Sampled-to-Sampled vs. Sampled-to-All Communication",
      "authors": [
        "Angelo Rodio",
        "Giovanni Neglia",
        "Zheng Chen",
        "Erik G. Larsson"
      ],
      "abstract": "In semi-decentralized federated learning, devices primarily rely on device-to-device communication but occasionally interact with a central server. Periodically, a sampled subset of devices uploads their local models to the server, which computes an aggregate model. The server can then either (i) share this aggregate model only with the sampled clients (sampled-to-sampled, S2S) or (ii) broadcast it to all clients (sampled-to-all, S2A). Despite their practical significance, a rigorous theoretical and empirical comparison of these two strategies remains absent. We address this gap by analyzing S2S and S2A within a unified convergence framework that accounts for key system parameters: sampling rate, server aggregation frequency, and network connectivity. Our results, both analytical and experimental, reveal distinct regimes where one strategy outperforms the other, depending primarily on the degree of data heterogeneity across devices. These insights lead to concrete design guidelines for practical semi-decentralized FL deployments.",
      "pdf_url": "https://arxiv.org/pdf/2511.11560v1",
      "published": "2025-11-14T18:53:37+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.11560v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ]
    },
    {
      "title": "Human-AI collaborative autonomous synthesis with pulsed laser deposition for remote epitaxy",
      "authors": [
        "Asraful Haque",
        "Daniel T. Yimam",
        "Jawad Chowdhury",
        "Ralph Bulanadi",
        "Ivan Vlassiouk",
        "John Lasseter",
        "Sujoy Ghosh",
        "Christopher M. Rouleau",
        "Kai Xiao",
        "Yongtao Liu",
        "Eva Zarkadoula",
        "Rama K. Vasudevan",
        "Sumner B. Harris"
      ],
      "abstract": "Autonomous laboratories typically rely on data-driven decision-making, occasionally with human-in-the-loop oversight to inject domain expertise. Fully leveraging AI agents, however, requires tightly coupled, collaborative workflows spanning hypothesis generation, experimental planning, execution, and interpretation. To address this, we develop and deploy a human-AI collaborative (HAIC) workflow that integrates large language models for hypothesis generation and analysis, with collaborative policy updates driving autonomous pulsed laser deposition (PLD) experiments for remote epitaxy of BaTiO$_3$/graphene. HAIC accelerated the hypothesis formation and experimental design and efficiently mapped the growth space to graphene-damage. In situ Raman spectroscopy reveals that chemistry drives degradation while the highest energy plume components seed defects, identifying a low-O$_2$ pressure low-temperature synthesis window that preserves graphene but is incompatible with optimal BaTiO$_3$ growth. Thus, we show a two-step Ar/O$_2$ deposition is required to exfoliate ferroelectric BaTiO$_3$ while maintaining a monolayer graphene interlayer. HAIC stages human insight with AI reasoning between autonomous batches to drive rapid scientific progress, providing an evolution to many existing human-in-the-loop autonomous workflows.",
      "pdf_url": "https://arxiv.org/pdf/2511.11558v1",
      "published": "2025-11-14T18:48:52+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.11558v1",
      "categories": [
        "cond-mat.mtrl-sci",
        "cs.AI"
      ]
    },
    {
      "title": "Aligning Machiavellian Agents: Behavior Steering via Test-Time Policy Shaping",
      "authors": [
        "Dena Mujtaba",
        "Brian Hu",
        "Anthony Hoogs",
        "Arslan Basharat"
      ],
      "abstract": "The deployment of decision-making AI agents presents a critical challenge in maintaining alignment with human values or guidelines while operating in complex, dynamic environments. Agents trained solely to achieve their objectives may adopt harmful behavior, exposing a key trade-off between maximizing the reward function and maintaining the alignment. For the pre-trained agents, ensuring alignment is particularly challenging, as retraining can be a costly and slow process. This is further complicated by the diverse and potentially conflicting attributes representing the ethical values for alignment. To address these challenges, we propose a test-time alignment technique based on model-guided policy shaping. Our method allows precise control over individual behavioral attributes, generalizes across diverse reinforcement learning (RL) environments, and facilitates a principled trade-off between ethical alignment and reward maximization without requiring agent retraining. We evaluate our approach using the MACHIAVELLI benchmark, which comprises 134 text-based game environments and thousands of annotated scenarios involving ethical decisions. The RL agents are first trained to maximize the reward in their respective games. At test time, we apply policy shaping via scenario-action attribute classifiers to ensure decision alignment with ethical attributes. We compare our approach against prior training-time methods and general-purpose agents, as well as study several types of ethical violations and power-seeking behavior. Our results demonstrate that test-time policy shaping provides an effective and scalable solution for mitigating unethical behavior across diverse environments and alignment attributes.",
      "pdf_url": "https://arxiv.org/pdf/2511.11551v1",
      "published": "2025-11-14T18:42:18+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.11551v1",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Volumetric Ergodic Control",
      "authors": [
        "Jueun Kwon",
        "Max M. Sun",
        "Todd Murphey"
      ],
      "abstract": "Ergodic control synthesizes optimal coverage behaviors over spatial distributions for nonlinear systems. However, existing formulations model the robot as a non-volumetric point, but in practice a robot interacts with the environment through its body and sensors with physical volume. In this work, we introduce a new ergodic control formulation that optimizes spatial coverage using a volumetric state representation. Our method preserves the asymptotic coverage guarantees of ergodic control, adds minimal computational overhead for real-time control, and supports arbitrary sample-based volumetric models. We evaluate our method across search and manipulation tasks -- with multiple robot dynamics and end-effector geometries or sensor models -- and show that it improves coverage efficiency by more than a factor of two while maintaining a 100% task completion rate across all experiments, outperforming the standard ergodic control method. Finally, we demonstrate the effectiveness of our method on a robot arm performing mechanical erasing tasks.",
      "pdf_url": "https://arxiv.org/pdf/2511.11533v1",
      "published": "2025-11-14T18:10:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.11533v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "Experience-Guided Adaptation of Inference-Time Reasoning Strategies",
      "authors": [
        "Adam Stein",
        "Matthew Trager",
        "Benjamin Bowman",
        "Michael Kleinman",
        "Aditya Chattopadhyay",
        "Wei Xia",
        "Stefano Soatto"
      ],
      "abstract": "Enabling agentic AI systems to adapt their problem-solving approaches based on post-training interactions remains a fundamental challenge. While systems that update and maintain a memory at inference time have been proposed, existing designs only steer the system by modifying textual input to a language model or agent, which means that they cannot change sampling parameters, remove tools, modify system prompts, or switch between agentic and workflow paradigms. On the other hand, systems that adapt more flexibly require offline optimization and remain static once deployed. We present Experience-Guided Reasoner (EGuR), which generates tailored strategies -- complete computational procedures involving LLM calls, tools, sampling parameters, and control logic -- dynamically at inference time based on accumulated experience. We achieve this using an LLM-based meta-strategy -- a strategy that outputs strategies -- enabling adaptation of all strategy components (prompts, sampling parameters, tool configurations, and control logic). EGuR operates through two components: a Guide generates multiple candidate strategies conditioned on the current problem and structured memory of past experiences, while a Consolidator integrates execution feedback to improve future strategy generation. This produces complete, ready-to-run strategies optimized for each problem, which can be cached, retrieved, and executed as needed without wasting resources. Across five challenging benchmarks (AIME 2025, 3-SAT, and three Big Bench Extra Hard tasks), EGuR achieves up to 14% accuracy improvements over the strongest baselines while reducing computational costs by up to 111x, with both metrics improving as the system gains experience.",
      "pdf_url": "https://arxiv.org/pdf/2511.11519v1",
      "published": "2025-11-14T17:45:28+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.11519v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "PAS : Prelim Attention Score for Detecting Object Hallucinations in Large Vision--Language Models",
      "authors": [
        "Nhat Hoang-Xuan",
        "Minh Vu",
        "My T. Thai",
        "Manish Bhattarai"
      ],
      "abstract": "Large vision-language models (LVLMs) are powerful, yet they remain unreliable due to object hallucinations. In this work, we show that in many hallucinatory predictions the LVLM effectively ignores the image and instead relies on previously generated output (prelim) tokens to infer new objects. We quantify this behavior via the mutual information between the image and the predicted object conditioned on the prelim, demonstrating that weak image dependence strongly correlates with hallucination. Building on this finding, we introduce the Prelim Attention Score (PAS), a lightweight, training-free signal computed from attention weights over prelim tokens. PAS requires no additional forward passes and can be computed on the fly during inference. Exploiting this previously overlooked signal, PAS achieves state-of-the-art object-hallucination detection across multiple models and datasets, enabling real-time filtering and intervention.",
      "pdf_url": "https://arxiv.org/pdf/2511.11502v1",
      "published": "2025-11-14T17:23:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.11502v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Intrinsic Dimension Estimation for Radio Galaxy Zoo using Diffusion Models",
      "authors": [
        "Joan Font-Quer Roset",
        "Devina Mohan",
        "Anna Scaife"
      ],
      "abstract": "In this work, we estimate the intrinsic dimension (iD) of the Radio Galaxy Zoo (RGZ) dataset using a score-based diffusion model. We examine how the iD estimates vary as a function of Bayesian neural network (BNN) energy scores, which measure how similar the radio sources are to the MiraBest subset of the RGZ dataset. We find that out-of-distribution sources exhibit higher iD values, and that the overall iD for RGZ exceeds those typically reported for natural image datasets. Furthermore, we analyse how iD varies across Fanaroff-Riley (FR) morphological classes and as a function of the signal-to-noise ratio (SNR). While no relationship is found between FR I and FR II classes, a weak trend toward higher SNR at lower iD. Future work using the RGZ dataset could make use of the relationship between iD and energy scores to quantitatively study and improve the representations learned by various self-supervised learning algorithms.",
      "pdf_url": "https://arxiv.org/pdf/2511.11490v1",
      "published": "2025-11-14T17:09:01+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.11490v1",
      "categories": [
        "cs.LG",
        "astro-ph.IM",
        "cs.AI"
      ]
    },
    {
      "title": "ImAgent: A Unified Multimodal Agent Framework for Test-Time Scalable Image Generation",
      "authors": [
        "Kaishen Wang",
        "Ruibo Chen",
        "Tong Zheng",
        "Heng Huang"
      ],
      "abstract": "Recent text-to-image (T2I) models have made remarkable progress in generating visually realistic and semantically coherent images. However, they still suffer from randomness and inconsistency with the given prompts, particularly when textual descriptions are vague or underspecified. Existing approaches, such as prompt rewriting, best-of-N sampling, and self-refinement, can mitigate these issues but usually require additional modules and operate independently, hindering test-time scaling efficiency and increasing computational overhead. In this paper, we introduce ImAgent, a training-free unified multimodal agent that integrates reasoning, generation, and self-evaluation within a single framework for efficient test-time scaling. Guided by a policy controller, multiple generation actions dynamically interact and self-organize to enhance image fidelity and semantic alignment without relying on external models. Extensive experiments on image generation and editing tasks demonstrate that ImAgent consistently improves over the backbone and even surpasses other strong baselines where the backbone model fails, highlighting the potential of unified multimodal agents for adaptive and efficient image generation under test-time scaling.",
      "pdf_url": "https://arxiv.org/pdf/2511.11483v1",
      "published": "2025-11-14T17:00:29+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.11483v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Inferring response times of perceptual decisions with Poisson variational autoencoders",
      "authors": [
        "Hayden R. Johnson",
        "Anastasia N. Krouglova",
        "Hadi Vafaii",
        "Jacob L. Yates",
        "Pedro J. Gonçalves"
      ],
      "abstract": "Many properties of perceptual decision making are well-modeled by deep neural networks. However, such architectures typically treat decisions as instantaneous readouts, overlooking the temporal dynamics of the decision process. We present an image-computable model of perceptual decision making in which choices and response times arise from efficient sensory encoding and Bayesian decoding of neural spiking activity. We use a Poisson variational autoencoder to learn unsupervised representations of visual stimuli in a population of rate-coded neurons, modeled as independent homogeneous Poisson processes. A task-optimized decoder then continually infers an approximate posterior over actions conditioned on incoming spiking activity. Combining these components with an entropy-based stopping rule yields a principled and image-computable model of perceptual decisions capable of generating trial-by-trial patterns of choices and response times. Applied to MNIST digit classification, the model reproduces key empirical signatures of perceptual decision making, including stochastic variability, right-skewed response time distributions, logarithmic scaling of response times with the number of alternatives (Hick's law), and speed-accuracy trade-offs.",
      "pdf_url": "https://arxiv.org/pdf/2511.11480v1",
      "published": "2025-11-14T16:58:04+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.11480v1",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Context-aware Adaptive Visualizations for Critical Decision Making",
      "authors": [
        "Angela Lopez-Cardona",
        "Mireia Masias Bruns",
        "Nuwan T. Attygalle",
        "Sebastian Idesis",
        "Matteo Salvatori",
        "Konstantinos Raftopoulos",
        "Konstantinos Oikonomou",
        "Saravanakumar Duraisamy",
        "Parvin Emami",
        "Nacera Latreche",
        "Alaa Eddine Anis Sahraoui",
        "Michalis Vakallelis",
        "Jean Vanderdonckt",
        "Ioannis Arapakis",
        "Luis A. Leiva"
      ],
      "abstract": "Effective decision-making often relies on timely insights from complex visual data. While Information Visualization (InfoVis) dashboards can support this process, they rarely adapt to users' cognitive state, and less so in real time. We present Symbiotik, an intelligent, context-aware adaptive visualization system that leverages neurophysiological signals to estimate mental workload (MWL) and dynamically adapt visual dashboards using reinforcement learning (RL). Through a user study with 120 participants and three visualization types, we demonstrate that our approach improves task performance and engagement. Symbiotik offers a scalable, real-time adaptation architecture, and a validated methodology for neuroadaptive user interfaces.",
      "pdf_url": "https://arxiv.org/pdf/2511.11476v1",
      "published": "2025-11-14T16:53:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.11476v1",
      "categories": [
        "cs.HC",
        "cs.AI"
      ]
    },
    {
      "title": "Benchmarking Visual LLMs Resilience to Unanswerable Questions on Visually Rich Documents",
      "authors": [
        "Davide Napolitano",
        "Luca Cagliero",
        "Fabrizio Battiloro"
      ],
      "abstract": "The evolution of Visual Large Language Models (VLLMs) has revolutionized the automatic understanding of Visually Rich Documents (VRDs), which contain both textual and visual elements. Although VLLMs excel in Visual Question Answering (VQA) on multi-page VRDs, their ability to detect unanswerable questions is still an open research question. Our research delves into the robustness of the VLLMs to plausible yet unanswerable questions, i.e., questions that appear valid but cannot be answered due to subtle corruptions caused by swaps between related concepts or plausible question formulations. Corruptions are generated by replacing the original natural language entities with other ones of the same type, belonging to different document elements, and in different layout positions or pages of the related document. To this end, we present VRD-UQA (VISUALLY RICH DOCUMENT UNANSWERABLE QUESTION ANSWERING), a benchmark for evaluating VLLMs' resilience to plausible yet unanswerable questions across multiple dimensions. It automatically alters the questions of existing VQA datasets consisting of multi-page VRDs, verifies their unanswerability using a VLLM-as-a-judge approach, and then thoroughly evaluates VLLMs' performance. Experiments, run on 12 models, analyze: (1) The VLLMs' accuracy in detecting unanswerable questions at both page and document levels; (2) The effect of different types of corruption (NLP entity, document element, layout); (3) The effectiveness of different knowledge injection strategies based on in-context learning (OCR, multi-page selection, or the possibility of unanswerability). Our findings reveal VLLMs' limitations and demonstrate that VRD-UQA can serve as an evaluation framework for developing resilient document VQA systems.",
      "pdf_url": "https://arxiv.org/pdf/2511.11468v1",
      "published": "2025-11-14T16:41:10+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.11468v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Epistemic Error Decomposition for Multi-step Time Series Forecasting: Rethinking Bias-Variance in Recursive and Direct Strategies",
      "authors": [
        "Riku Green",
        "Huw Day",
        "Zahraa S. Abdallah",
        "Telmo M. Silva Filho"
      ],
      "abstract": "Multi-step forecasting is often described through a simple rule of thumb: recursive strategies are said to have high bias and low variance, while direct strategies are said to have low bias and high variance. We revisit this belief by decomposing the expected multi-step forecast error into three parts: irreducible noise, a structural approximation gap, and an estimation-variance term. For linear predictors we show that the structural gap is identically zero for any dataset. For nonlinear predictors, however, the repeated composition used in recursion can increase model expressivity, making the structural gap depend on both the model and the data. We further show that the estimation variance of the recursive strategy at any horizon can be written as the one-step variance multiplied by a Jacobian-based amplification factor that measures how sensitive the composed predictor is to parameter error. This perspective explains when recursive forecasting may simultaneously have lower bias and higher variance than direct forecasting. Experiments with multilayer perceptrons on the ETTm1 dataset confirm these findings. The results offer practical guidance for choosing between recursive and direct strategies based on model nonlinearity and noise characteristics, rather than relying on traditional bias-variance intuition.",
      "pdf_url": "https://arxiv.org/pdf/2511.11461v1",
      "published": "2025-11-14T16:32:42+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.11461v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Retrofit: Continual Learning with Bounded Forgetting for Security Applications",
      "authors": [
        "Yiling He",
        "Junchi Lei",
        "Hongyu She",
        "Shuo Shao",
        "Xinran Zheng",
        "Yiping Liu",
        "Zhan Qin",
        "Lorenzo Cavallaro"
      ],
      "abstract": "Modern security analytics are increasingly powered by deep learning models, but their performance often degrades as threat landscapes evolve and data representations shift. While continual learning (CL) offers a promising paradigm to maintain model effectiveness, many approaches rely on full retraining or data replay, which are infeasible in data-sensitive environments. Moreover, existing methods remain inadequate for security-critical scenarios, facing two coupled challenges in knowledge transfer: preserving prior knowledge without old data and integrating new knowledge with minimal interference.\n  We propose RETROFIT, a data retrospective-free continual learning method that achieves bounded forgetting for effective knowledge transfer. Our key idea is to consolidate previously trained and newly fine-tuned models, serving as teachers of old and new knowledge, through parameter-level merging that eliminates the need for historical data. To mitigate interference, we apply low-rank and sparse updates that confine parameter changes to independent subspaces, while a knowledge arbitration dynamically balances the teacher contributions guided by model confidence. Our evaluation on two representative applications demonstrates that RETROFIT consistently mitigates forgetting while maintaining adaptability. In malware detection under temporal drift, it substantially improves the retention score, from 20.2% to 38.6% over CL baselines, and exceeds the oracle upper bound on new data. In binary summarization across decompilation levels, where analyzing stripped binaries is especially challenging, RETROFIT achieves around twice the BLEU score of transfer learning used in prior work and surpasses all baselines in cross-representation generalization.",
      "pdf_url": "https://arxiv.org/pdf/2511.11439v1",
      "published": "2025-11-14T16:07:03+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.11439v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "The Persistence of Cultural Memory: Investigating Multimodal Iconicity in Diffusion Models",
      "authors": [
        "Maria-Teresa De Rosa Palmini",
        "Eva Cetinic"
      ],
      "abstract": "Our work addresses the ambiguity between generalization and memorization in text-to-image diffusion models, focusing on a specific case we term multimodal iconicity. This refers to instances where images and texts evoke culturally shared associations, such as when a title recalls a familiar artwork or film scene. While prior research on memorization and unlearning emphasizes forgetting, we examine what is remembered and how, focusing on the balance between recognizing cultural references and reproducing them. We introduce an evaluation framework that separates recognition, whether a model identifies a reference, from realization, how it depicts it through replication or reinterpretation, quantified through measures capturing both dimensions. By evaluating five diffusion models across 767 Wikidata-derived cultural references spanning static and dynamic imagery, we show that our framework distinguishes replication from transformation more effectively than existing similarity-based methods. To assess linguistic sensitivity, we conduct prompt perturbation experiments using synonym substitutions and literal image descriptions, finding that models often reproduce iconic visual structures even when textual cues are altered. Finally, our analysis shows that cultural alignment correlates not only with training data frequency, but also textual uniqueness, reference popularity, and creation date. Our work reveals that the value of diffusion models lies not only in what they reproduce but in how they transform and recontextualize cultural knowledge, advancing evaluation beyond simple text-image matching toward richer contextual understanding.",
      "pdf_url": "https://arxiv.org/pdf/2511.11435v1",
      "published": "2025-11-14T16:03:10+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.11435v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "CURENet: Combining Unified Representations for Efficient Chronic Disease Prediction",
      "authors": [
        "Cong-Tinh Dao",
        "Nguyen Minh Thao Phan",
        "Jun-En Ding",
        "Chenwei Wu",
        "David Restrepo",
        "Dongsheng Luo",
        "Fanyi Zhao",
        "Chun-Chieh Liao",
        "Wen-Chih Peng",
        "Chi-Te Wang",
        "Pei-Fu Chen",
        "Ling Chen",
        "Xinglong Ju",
        "Feng Liu",
        "Fang-Ming Hung"
      ],
      "abstract": "Electronic health records (EHRs) are designed to synthesize diverse data types, including unstructured clinical notes, structured lab tests, and time-series visit data. Physicians draw on these multimodal and temporal sources of EHR data to form a comprehensive view of a patient's health, which is crucial for informed therapeutic decision-making. Yet, most predictive models fail to fully capture the interactions, redundancies, and temporal patterns across multiple data modalities, often focusing on a single data type or overlooking these complexities. In this paper, we present CURENet, a multimodal model (Combining Unified Representations for Efficient chronic disease prediction) that integrates unstructured clinical notes, lab tests, and patients' time-series data by utilizing large language models (LLMs) for clinical text processing and textual lab tests, as well as transformer encoders for longitudinal sequential visits. CURENet has been capable of capturing the intricate interaction between different forms of clinical data and creating a more reliable predictive model for chronic illnesses. We evaluated CURENet using the public MIMIC-III and private FEMH datasets, where it achieved over 94\\% accuracy in predicting the top 10 chronic conditions in a multi-label framework. Our findings highlight the potential of multimodal EHR integration to enhance clinical decision-making and improve patient outcomes.",
      "pdf_url": "https://arxiv.org/pdf/2511.11423v1",
      "published": "2025-11-14T15:52:22+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.11423v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Variational Quantum Algorithms for Particle Track Reconstruction",
      "authors": [
        "Vincenzo Lipardi",
        "Xenofon Chiotopoulos",
        "Jacco A. de Vries",
        "Domenica Dibenedetto",
        "Kurt Driessens",
        "Marcel Merk",
        "Mark H. M. Winands"
      ],
      "abstract": "Quantum Computing is a rapidly developing field with the potential to tackle the increasing computational challenges faced in high-energy physics. In this work, we explore the potential and limitations of variational quantum algorithms in solving the particle track reconstruction problem. We present an analysis of two distinct formulations for identifying straight-line tracks in a multilayer detection system, inspired by the LHCb vertex detector. The first approach is formulated as a ground-state energy problem, while the second approach is formulated as a system of linear equations. This work addresses one of the main challenges when dealing with variational quantum algorithms on general problems, namely designing an expressive and efficient quantum ansatz working on tracking events with fixed detector geometry. For this purpose, we employed a quantum architecture search method based on Monte Carlo Tree Search to design the quantum circuits for different problem sizes. We provide experimental results to test our approach on both formulations for different problem sizes in terms of performance and computational cost.",
      "pdf_url": "https://arxiv.org/pdf/2511.11397v1",
      "published": "2025-11-14T15:24:59+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.11397v1",
      "categories": [
        "quant-ph",
        "cs.AI"
      ]
    },
    {
      "title": "Robust and Efficient Communication in Multi-Agent Reinforcement Learning",
      "authors": [
        "Zejiao Liu",
        "Yi Li",
        "Jiali Wang",
        "Junqi Tu",
        "Yitian Hong",
        "Fangfei Li",
        "Yang Liu",
        "Toshiharu Sugawara",
        "Yang Tang"
      ],
      "abstract": "Multi-agent reinforcement learning (MARL) has made significant strides in enabling coordinated behaviors among autonomous agents. However, most existing approaches assume that communication is instantaneous, reliable, and has unlimited bandwidth; these conditions are rarely met in real-world deployments. This survey systematically reviews recent advances in robust and efficient communication strategies for MARL under realistic constraints, including message perturbations, transmission delays, and limited bandwidth. Furthermore, because the challenges of low-latency reliability, bandwidth-intensive data sharing, and communication-privacy trade-offs are central to practical MARL systems, we focus on three applications involving cooperative autonomous driving, distributed simultaneous localization and mapping, and federated learning. Finally, we identify key open challenges and future research directions, advocating a unified approach that co-designs communication, learning, and robustness to bridge the gap between theoretical MARL models and practical implementations.",
      "pdf_url": "https://arxiv.org/pdf/2511.11393v1",
      "published": "2025-11-14T15:23:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.11393v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "MarsRL: Advancing Multi-Agent Reasoning System via Reinforcement Learning with Agentic Pipeline Parallelism",
      "authors": [
        "Shulin Liu",
        "Dong Du",
        "Tao Yang",
        "Yang Li",
        "Boyu Qiu"
      ],
      "abstract": "Recent progress in large language models (LLMs) has been propelled by reinforcement learning with verifiable rewards (RLVR) and test-time scaling. However, the limited output length of LLMs constrains the depth of reasoning attainable in a single inference process. Multi-agent reasoning systems offer a promising alternative by employing multiple agents including Solver, Verifier, and Corrector, to iteratively refine solutions. While effective in closed-source models like Gemini 2.5 Pro, they struggle to generalize to open-source models due to insufficient critic and correction capabilities. To address this, we propose MarsRL, a novel reinforcement learning framework with agentic pipeline parallelism, designed to jointly optimize all agents in the system. MarsRL introduces agent-specific reward mechanisms to mitigate reward noise and employs pipeline-inspired training to enhance efficiency in handling long trajectories. Applied to Qwen3-30B-A3B-Thinking-2507, MarsRL improves AIME2025 accuracy from 86.5% to 93.3% and BeyondAIME from 64.9% to 73.8%, even surpassing Qwen3-235B-A22B-Thinking-2507. These findings highlight the potential of MarsRL to advance multi-agent reasoning systems and broaden their applicability across diverse reasoning tasks.",
      "pdf_url": "https://arxiv.org/pdf/2511.11373v1",
      "published": "2025-11-14T14:52:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.11373v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "KarmaTS: A Universal Simulation Platform for Multivariate Time Series with Functional Causal Dynamics",
      "authors": [
        "Haixin Li",
        "Yanke Li",
        "Diego Paez-Granados"
      ],
      "abstract": "We introduce KarmaTS, an interactive framework for constructing lag-indexed, executable spatiotemporal causal graphical models for multivariate time series (MTS) simulation. Motivated by the challenge of access-restricted physiological data, KarmaTS generates synthetic MTS with known causal dynamics and augments real-world datasets with expert knowledge. The system constructs a discrete-time structural causal process (DSCP) by combining expert knowledge and algorithmic proposals in a mixed-initiative, human-in-the-loop workflow. The resulting DSCP supports simulation and causal interventions, including those under user-specified distribution shifts. KarmaTS handles mixed variable types, contemporaneous and lagged edges, and modular edge functionals ranging from parameterizable templates to neural network models. Together, these features enable flexible validation and benchmarking of causal discovery algorithms through expert-informed simulation.",
      "pdf_url": "https://arxiv.org/pdf/2511.11357v1",
      "published": "2025-11-14T14:44:14+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.11357v1",
      "categories": [
        "cs.AI",
        "cs.HC"
      ]
    },
    {
      "title": "Privacy Challenges and Solutions in Retrieval-Augmented Generation-Enhanced LLMs for Healthcare Chatbots: A Review of Applications, Risks, and Future Directions",
      "authors": [
        "Shaowei Guan",
        "Hin Chi Kwok",
        "Ngai Fong Law",
        "Gregor Stiglic",
        "Vivian Hui"
      ],
      "abstract": "Retrieval-augmented generation (RAG) has rapidly emerged as a transformative approach for integrating large language models into clinical and biomedical workflows. However, privacy risks, such as protected health information (PHI) exposure, remain inconsistently mitigated. This review provides a thorough analysis of the current landscape of RAG applications in healthcare, including (i) sensitive data type across clinical scenarios, (ii) the associated privacy risks, (iii) current and emerging data-privacy protection mechanisms and (iv) future direction for patient data privacy protection. We synthesize 23 articles on RAG applications in healthcare and systematically analyze privacy challenges through a pipeline-structured framework encompassing data storage, transmission, retrieval and generation stages, delineating potential failure modes, their underlying causes in threat models and system mechanisms, and their practical implications. Building on this analysis, we critically review 17 articles on privacy-preserving strategies for RAG systems. Our evaluation reveals critical gaps, including insufficient clinical validation, absence of standardized evaluation frameworks, and lack of automated assessment tools. We propose actionable directions based on these limitations and conclude with a call to action. This review provides researchers and practitioners with a structured framework for understanding privacy vulnerabilities in healthcare RAG and offers a roadmap toward developing systems that achieve both clinical effectiveness and robust privacy preservation.",
      "pdf_url": "https://arxiv.org/pdf/2511.11347v1",
      "published": "2025-11-14T14:33:58+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.11347v1",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "title": "M-DAIGT: A Shared Task on Multi-Domain Detection of AI-Generated Text",
      "authors": [
        "Salima Lamsiyah",
        "Saad Ezzini",
        "Abdelkader El Mahdaouy",
        "Hamza Alami",
        "Abdessamad Benlahbib",
        "Samir El Amrany",
        "Salmane Chafik",
        "Hicham Hammouchi"
      ],
      "abstract": "The generation of highly fluent text by Large Language Models (LLMs) poses a significant challenge to information integrity and academic research. In this paper, we introduce the Multi-Domain Detection of AI-Generated Text (M-DAIGT) shared task, which focuses on detecting AI-generated text across multiple domains, particularly in news articles and academic writing. M-DAIGT comprises two binary classification subtasks: News Article Detection (NAD) (Subtask 1) and Academic Writing Detection (AWD) (Subtask 2). To support this task, we developed and released a new large-scale benchmark dataset of 30,000 samples, balanced between human-written and AI-generated texts. The AI-generated content was produced using a variety of modern LLMs (e.g., GPT-4, Claude) and diverse prompting strategies. A total of 46 unique teams registered for the shared task, of which four teams submitted final results. All four teams participated in both Subtask 1 and Subtask 2. We describe the methods employed by these participating teams and briefly discuss future directions for M-DAIGT.",
      "pdf_url": "https://arxiv.org/pdf/2511.11340v1",
      "published": "2025-11-14T14:26:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.11340v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "NOVA: An Agentic Framework for Automated Histopathology Analysis and Discovery",
      "authors": [
        "Anurag J. Vaidya",
        "Felix Meissen",
        "Daniel C. Castro",
        "Shruthi Bannur",
        "Tristan Lazard",
        "Drew F. K. Williamson",
        "Faisal Mahmood",
        "Javier Alvarez-Valle",
        "Stephanie L. Hyland",
        "Kenza Bouzid"
      ],
      "abstract": "Digitized histopathology analysis involves complex, time-intensive workflows and specialized expertise, limiting its accessibility. We introduce NOVA, an agentic framework that translates scientific queries into executable analysis pipelines by iteratively generating and running Python code. NOVA integrates 49 domain-specific tools (e.g., nuclei segmentation, whole-slide encoding) built on open-source software, and can also create new tools ad hoc. To evaluate such systems, we present SlideQuest, a 90-question benchmark -- verified by pathologists and biomedical scientists -- spanning data processing, quantitative analysis, and hypothesis testing. Unlike prior biomedical benchmarks focused on knowledge recall or diagnostic QA, SlideQuest demands multi-step reasoning, iterative coding, and computational problem solving. Quantitative evaluation shows NOVA outperforms coding-agent baselines, and a pathologist-verified case study links morphology to prognostically relevant PAM50 subtypes, demonstrating its scalable discovery potential.",
      "pdf_url": "https://arxiv.org/pdf/2511.11324v1",
      "published": "2025-11-14T14:01:18+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.11324v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "RLSLM: A Hybrid Reinforcement Learning Framework Aligning Rule-Based Social Locomotion Model with Human Social Norms",
      "authors": [
        "Yitian Kou",
        "Yihe Gu",
        "Chen Zhou",
        "DanDan Zhu",
        "Shuguang Kuai"
      ],
      "abstract": "Navigating human-populated environments without causing discomfort is a critical capability for socially-aware agents. While rule-based approaches offer interpretability through predefined psychological principles, they often lack generalizability and flexibility. Conversely, data-driven methods can learn complex behaviors from large-scale datasets, but are typically inefficient, opaque, and difficult to align with human intuitions. To bridge this gap, we propose RLSLM, a hybrid Reinforcement Learning framework that integrates a rule-based Social Locomotion Model, grounded in empirical behavioral experiments, into the reward function of a reinforcement learning framework. The social locomotion model generates an orientation-sensitive social comfort field that quantifies human comfort across space, enabling socially aligned navigation policies with minimal training. RLSLM then jointly optimizes mechanical energy and social comfort, allowing agents to avoid intrusions into personal or group space. A human-agent interaction experiment using an immersive VR-based setup demonstrates that RLSLM outperforms state-of-the-art rule-based models in user experience. Ablation and sensitivity analyses further show the model's significantly improved interpretability over conventional data-driven methods. This work presents a scalable, human-centered methodology that effectively integrates cognitive science and machine learning for real-world social navigation.",
      "pdf_url": "https://arxiv.org/pdf/2511.11323v1",
      "published": "2025-11-14T13:59:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.11323v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "LAET: A Layer-wise Adaptive Ensemble Tuning Framework for Pretrained Language Models",
      "authors": [
        "Jawad Ibn Ahad",
        "Muhammad Rafsan Kabir",
        "Robin Krambroeckers",
        "Sifat Momen",
        "Nabeel Mohammed",
        "Shafin Rahman"
      ],
      "abstract": "Natural Language Processing (NLP) has transformed the financial industry, enabling advancements in areas such as textual analysis, risk management, and forecasting. Large language models (LLMs) like BloombergGPT and FinMA have set new benchmarks across various financial NLP tasks, including sentiment analysis, stock movement prediction, and credit risk assessment. Furthermore, FinMA-ES, a bilingual financial LLM, has also demonstrated strong performance using the FLARE and FLARE-ES benchmarks. However, the high computational demands of these models limit the accessibility of many organizations. To address this, we propose Layer-wise Adaptive Ensemble Tuning (LAET), a novel strategy that selectively fine-tunes the most effective layers of pre-trained LLMs by analyzing hidden state representations while freezing less critical layers. LAET significantly reduces computational overhead while enhancing task-specific performance. Our approach shows strong results in financial NLP tasks, outperforming existing benchmarks and state-of-the-art LLMs such as GPT-4, even with smaller LLMs ($\\sim$3B parameters). This work bridges cutting-edge financial NLP research and real-world deployment with efficient and scalable models for financial applications.",
      "pdf_url": "https://arxiv.org/pdf/2511.11315v1",
      "published": "2025-11-14T13:57:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.11315v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CE"
      ]
    },
    {
      "title": "Large-scale modality-invariant foundation models for brain MRI analysis: Application to lesion segmentation",
      "authors": [
        "Petros Koutsouvelis",
        "Matej Gazda",
        "Leroy Volmer",
        "Sina Amirrajab",
        "Kamil Barbierik",
        "Branislav Setlak",
        "Jakub Gazda",
        "Peter Drotar"
      ],
      "abstract": "The field of computer vision is undergoing a paradigm shift toward large-scale foundation model pre-training via self-supervised learning (SSL). Leveraging large volumes of unlabeled brain MRI data, such models can learn anatomical priors that improve few-shot performance in diverse neuroimaging tasks. However, most SSL frameworks are tailored to natural images, and their adaptation to capture multi-modal MRI information remains underexplored. This work proposes a modality-invariant representation learning setup and evaluates its effectiveness in stroke and epilepsy lesion segmentation, following large-scale pre-training. Experimental results suggest that despite successful cross-modality alignment, lesion segmentation primarily benefits from preserving fine-grained modality-specific features. Model checkpoints and code are made publicly available.",
      "pdf_url": "https://arxiv.org/pdf/2511.11311v1",
      "published": "2025-11-14T13:56:07+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.11311v1",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ]
    },
    {
      "title": "iMAD: Intelligent Multi-Agent Debate for Efficient and Accurate LLM Inference",
      "authors": [
        "Wei Fan",
        "JinYi Yoon",
        "Bo Ji"
      ],
      "abstract": "Large Language Model (LLM) agent systems have advanced rapidly, driven by their strong generalization in zero-shot settings. To further enhance reasoning and accuracy on complex tasks, Multi-Agent Debate (MAD) has emerged as a promising framework that engages multiple LLM agents in structured debates to encourage diverse reasoning. However, triggering MAD for every query is inefficient, as it incurs substantial computational (token) cost and may even degrade accuracy by overturning correct single-agent answers. To address these limitations, we propose intelligent Multi-Agent Debate (iMAD), a token-efficient framework that selectively triggers MAD only when it is likely to be beneficial (i.e., correcting an initially wrong answer). To achieve this goal, iMAD learns generalizable model behaviors to make accurate debate decisions. Specifically, iMAD first prompts a single agent to produce a structured self-critique response, from which we extract 41 interpretable linguistic and semantic features capturing hesitation cues. Then, iMAD uses a lightweight debate-decision classifier, trained using our proposed FocusCal loss, to determine whether to trigger MAD, enabling robust debate decisions without test dataset-specific tuning. Through extensive experiments using six (visual) question answering datasets against five competitive baselines, we have shown that iMAD significantly reduces token usage (by up to 92%) while also improving final answer accuracy (by up to 13.5%).",
      "pdf_url": "https://arxiv.org/pdf/2511.11306v1",
      "published": "2025-11-14T13:50:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.11306v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.MA"
      ]
    },
    {
      "title": "MOON Embedding: Multimodal Representation Learning for E-commerce Search Advertising",
      "authors": [
        "Chenghan Fu",
        "Daoze Zhang",
        "Yukang Lin",
        "Zhanheng Nie",
        "Xiang Zhang",
        "Jianyu Liu",
        "Yueran Liu",
        "Wanxian Guan",
        "Pengjie Wang",
        "Jian Xu",
        "Bo Zheng"
      ],
      "abstract": "We introduce MOON, our comprehensive set of sustainable iterative practices for multimodal representation learning for e-commerce applications. MOON has already been fully deployed across all stages of Taobao search advertising system, including retrieval, relevance, ranking, and so on. The performance gains are particularly significant on click-through rate (CTR) prediction task, which achieves an overall +20.00% online CTR improvement. Over the past three years, this project has delivered the largest improvement on CTR prediction task and undergone five full-scale iterations. Throughout the exploration and iteration of our MOON, we have accumulated valuable insights and practical experience that we believe will benefit the research community. MOON contains a three-stage training paradigm of \"Pretraining, Post-training, and Application\", allowing effective integration of multimodal representations with downstream tasks. Notably, to bridge the misalignment between the objectives of multimodal representation learning and downstream training, we define the exchange rate to quantify how effectively improvements in an intermediate metric can translate into downstream gains. Through this analysis, we identify the image-based search recall as a critical intermediate metric guiding the optimization of multimodal models. Over three years and five iterations, MOON has evolved along four critical dimensions: data processing, training strategy, model architecture, and downstream application. The lessons and insights gained through the iterative improvements will also be shared. As part of our exploration into scaling effects in the e-commerce field, we further conduct a systematic study of the scaling laws governing multimodal representation learning, examining multiple factors such as the number of training tokens, negative samples, and the length of user behavior sequences.",
      "pdf_url": "https://arxiv.org/pdf/2511.11305v1",
      "published": "2025-11-14T13:49:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.11305v1",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ]
    },
    {
      "title": "EcoAlign: An Economically Rational Framework for Efficient LVLM Alignment",
      "authors": [
        "Ruoxi Cheng",
        "Haoxuan Ma",
        "Teng Ma",
        "Hongyi Zhang"
      ],
      "abstract": "Large Vision-Language Models (LVLMs) exhibit powerful reasoning capabilities but suffer sophisticated jailbreak vulnerabilities. Fundamentally, aligning LVLMs is not just a safety challenge but a problem of economic efficiency. Current alignment methods struggle with the trade-off between safety, utility, and operational costs. Critically, a focus solely on final outputs (process-blindness) wastes significant computational budget on unsafe deliberation. This flaw allows harmful reasoning to be disguised with benign justifications, thereby circumventing simple additive safety scores. To address this, we propose EcoAlign, an inference-time framework that reframes alignment as an economically rational search by treating the LVLM as a boundedly rational agent. EcoAlign incrementally expands a thought graph and scores actions using a forward-looking function (analogous to net present value) that dynamically weighs expected safety, utility, and cost against the remaining budget. To prevent deception, path safety is enforced via the weakest-link principle. Extensive experiments across 3 closed-source and 2 open-source models on 6 datasets show that EcoAlign matches or surpasses state-of-the-art safety and utility at a lower computational cost, thereby offering a principled, economical pathway to robust LVLM alignment.",
      "pdf_url": "https://arxiv.org/pdf/2511.11301v1",
      "published": "2025-11-14T13:38:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.11301v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "AUVIC: Adversarial Unlearning of Visual Concepts for Multi-modal Large Language Models",
      "authors": [
        "Haokun Chen",
        "Jianing Li",
        "Yao Zhang",
        "Jinhe Bi",
        "Yan Xia",
        "Jindong Gu",
        "Volker Tresp"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) achieve impressive performance once optimized on massive datasets. Such datasets often contain sensitive or copyrighted content, raising significant data privacy concerns. Regulatory frameworks mandating the 'right to be forgotten' drive the need for machine unlearning. This technique allows for the removal of target data without resource-consuming retraining. However, while well-studied for text, visual concept unlearning in MLLMs remains underexplored. A primary challenge is precisely removing a target visual concept without disrupting model performance on related entities. To address this, we introduce AUVIC, a novel visual concept unlearning framework for MLLMs. AUVIC applies adversarial perturbations to enable precise forgetting. This approach effectively isolates the target concept while avoiding unintended effects on similar entities. To evaluate our method, we construct VCUBench. It is the first benchmark designed to assess visual concept unlearning in group contexts. Experimental results demonstrate that AUVIC achieves state-of-the-art target forgetting rates while incurs minimal performance degradation on non-target concepts.",
      "pdf_url": "https://arxiv.org/pdf/2511.11299v1",
      "published": "2025-11-14T13:35:32+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.11299v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Experiences from Benchmarking Vision-Language-Action Models for Robotic Manipulation",
      "authors": [
        "Yihao Zhang",
        "Yuankai Qi",
        "Xi Zheng"
      ],
      "abstract": "Foundation models applied in robotics, particularly \\textbf{Vision--Language--Action (VLA)} models, hold great promise for achieving general-purpose manipulation. Yet, systematic real-world evaluations and cross-model comparisons remain scarce. This paper reports our \\textbf{empirical experiences} from benchmarking four representative VLAs -- \\textbf{ACT}, \\textbf{OpenVLA--OFT}, \\textbf{RDT-1B}, and \\boldmath{$π_0$} -- across four manipulation tasks conducted in both simulation and on the \\textbf{ALOHA Mobile} platform. We establish a \\textbf{standardized evaluation framework} that measures performance along three key dimensions: (1) \\textit{accuracy and efficiency} (success rate and time-to-success), (2) \\textit{adaptability} across in-distribution, spatial out-of-distribution, and instance-plus-spatial out-of-distribution settings, and (3) \\textit{language instruction-following accuracy}. Through this process, we observe that \\boldmath{$π_0$} demonstrates superior adaptability in out-of-distribution scenarios, while \\textbf{ACT} provides the highest stability in-distribution. Further analysis highlights differences in computational demands, data-scaling behavior, and recurring failure modes such as near-miss grasps, premature releases, and long-horizon state drift. These findings reveal practical trade-offs among VLA model architectures in balancing precision, generalization, and deployment cost, offering actionable insights for selecting and deploying VLAs in real-world robotic manipulation tasks.",
      "pdf_url": "https://arxiv.org/pdf/2511.11298v1",
      "published": "2025-11-14T13:35:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.11298v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "Building the Web for Agents: A Declarative Framework for Agent-Web Interaction",
      "authors": [
        "Sven Schultze",
        "Meike Verena Kietzmann",
        "Nils-Lucas Schönfeld",
        "Ruth Stock-Homburg"
      ],
      "abstract": "The increasing deployment of autonomous AI agents on the web is hampered by a fundamental misalignment: agents must infer affordances from human-oriented user interfaces, leading to brittle, inefficient, and insecure interactions. To address this, we introduce VOIX, a web-native framework that enables websites to expose reliable, auditable, and privacy-preserving capabilities for AI agents through simple, declarative HTML elements. VOIX introduces <tool> and <context> tags, allowing developers to explicitly define available actions and relevant state, thereby creating a clear, machine-readable contract for agent behavior. This approach shifts control to the website developer while preserving user privacy by disconnecting the conversational interactions from the website. We evaluated the framework's practicality, learnability, and expressiveness in a three-day hackathon study with 16 developers. The results demonstrate that participants, regardless of prior experience, were able to rapidly build diverse and functional agent-enabled web applications. Ultimately, this work provides a foundational mechanism for realizing the Agentic Web, enabling a future of seamless and secure human-AI collaboration on the web.",
      "pdf_url": "https://arxiv.org/pdf/2511.11287v1",
      "published": "2025-11-14T13:23:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.11287v1",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.MA"
      ]
    },
    {
      "title": "D-GAP: Improving Out-of-Domain Robustness via Dataset-Agnostic and Gradient-Guided Augmentation in Amplitude and Pixel Spaces",
      "authors": [
        "Ruoqi Wang",
        "Haitao Wang",
        "Shaojie Guo",
        "Qiong Luo"
      ],
      "abstract": "Out-of-domain (OOD) robustness is challenging to achieve in real-world computer vision applications, where shifts in image background, style, and acquisition instruments always degrade model performance. Generic augmentations show inconsistent gains under such shifts, whereas dataset-specific augmentations require expert knowledge and prior analysis. Moreover, prior studies show that neural networks adapt poorly to domain shifts because they exhibit a learning bias to domain-specific frequency components. Perturbing frequency values can mitigate such bias but overlooks pixel-level details, leading to suboptimal performance. To address these problems, we propose D-GAP (Dataset-agnostic and Gradient-guided augmentation in Amplitude and Pixel spaces), improving OOD robustness by introducing targeted augmentation in both the amplitude space (frequency space) and pixel space. Unlike conventional handcrafted augmentations, D-GAP computes sensitivity maps in the frequency space from task gradients, which reflect how strongly the model responds to different frequency components, and uses the maps to adaptively interpolate amplitudes between source and target samples. This way, D-GAP reduces the learning bias in frequency space, while a complementary pixel-space blending procedure restores fine spatial details. Extensive experiments on four real-world datasets and three domain-adaptation benchmarks show that D-GAP consistently outperforms both generic and dataset-specific augmentations, improving average OOD performance by +5.3% on real-world datasets and +1.8% on benchmark datasets.",
      "pdf_url": "https://arxiv.org/pdf/2511.11286v1",
      "published": "2025-11-14T13:22:10+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.11286v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Can You Tell the Difference? Contrastive Explanations for ABox Entailments",
      "authors": [
        "Patrick Koopmann",
        "Yasir Mahmood",
        "Axel-Cyrille Ngonga Ngomo",
        "Balram Tiwari"
      ],
      "abstract": "We introduce the notion of contrastive ABox explanations to answer questions of the type \"Why is a an instance of C, but b is not?\". While there are various approaches for explaining positive entailments (why is C(a) entailed by the knowledge base) as well as missing entailments (why is C(b) not entailed) in isolation, contrastive explanations consider both at the same time, which allows them to focus on the relevant commonalities and differences between a and b. We develop an appropriate notion of contrastive explanations for the special case of ABox reasoning with description logic ontologies, and analyze the computational complexity for different variants under different optimality criteria, considering lightweight as well as more expressive description logics. We implemented a first method for computing one variant of contrastive explanations, and evaluated it on generated problems for realistic knowledge bases.",
      "pdf_url": "https://arxiv.org/pdf/2511.11281v1",
      "published": "2025-11-14T13:16:43+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.11281v1",
      "categories": [
        "cs.AI",
        "cs.LO"
      ]
    },
    {
      "title": "A Workflow for Full Traceability of AI Decisions",
      "authors": [
        "Julius Wenzel",
        "Syeda Umaima Alam",
        "Andreas Schmidt",
        "Hanwei Zhang",
        "Holger Hermanns"
      ],
      "abstract": "An ever increasing number of high-stake decisions are made or assisted by automated systems employing brittle artificial intelligence technology. There is a substantial risk that some of these decision induce harm to people, by infringing their well-being or their fundamental human rights. The state-of-the-art in AI systems makes little effort with respect to appropriate documentation of the decision process. This obstructs the ability to trace what went into a decision, which in turn is a prerequisite to any attempt of reconstructing a responsibility chain. Specifically, such traceability is linked to a documentation that will stand up in court when determining the cause of some AI-based decision that inadvertently or intentionally violates the law.\n  This paper takes a radical, yet practical, approach to this problem, by enforcing the documentation of each and every component that goes into the training or inference of an automated decision. As such, it presents the first running workflow supporting the generation of tamper-proof, verifiable and exhaustive traces of AI decisions. In doing so, we expand the DBOM concept into an effective running workflow leveraging confidential computing technology. We demonstrate the inner workings of the workflow in the development of an app to tell poisonous and edible mushrooms apart, meant as a playful example of high-stake decision support.",
      "pdf_url": "https://arxiv.org/pdf/2511.11275v1",
      "published": "2025-11-14T13:10:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.11275v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "SQuaD: The Software Quality Dataset",
      "authors": [
        "Mikel Robredo",
        "Matteo Esposito",
        "Davide Taibi",
        "Rafael Peñaloza",
        "Valentina Lenarduzzi"
      ],
      "abstract": "Software quality research increasingly relies on large-scale datasets that measure both the product and process aspects of software systems. However, existing resources often focus on limited dimensions, such as code smells, technical debt, or refactoring activity, thereby restricting comprehensive analyses across time and quality dimensions. To address this gap, we present the Software Quality Dataset (SQuaD), a multi-dimensional, time-aware collection of software quality metrics extracted from 450 mature open-source projects across diverse ecosystems, including Apache, Mozilla, FFmpeg, and the Linux kernel. By integrating nine state-of-the-art static analysis tools, i.e., SonarQube, CodeScene, PMD, Understand, CK, JaSoMe, RefactoringMiner, RefactoringMiner++, and PyRef, our dataset unifies over 700 unique metrics at method, class, file, and project levels. Covering a total of 63,586 analyzed project releases, SQuaD also provides version control and issue-tracking histories, software vulnerability data (CVE/CWE), and process metrics proven to enhance Just-In-Time (JIT) defect prediction. The SQuaD enables empirical research on maintainability, technical debt, software evolution, and quality assessment at unprecedented scale. We also outline emerging research directions, including automated dataset updates and cross-project quality modeling to support the continuous evolution of software analytics. The dataset is publicly available on ZENODO (DOI: 10.5281/zenodo.17566690).",
      "pdf_url": "https://arxiv.org/pdf/2511.11265v1",
      "published": "2025-11-14T12:57:22+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.11265v1",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "cs.CR",
        "cs.IR"
      ]
    },
    {
      "title": "KGQuest: Template-Driven QA Generation from Knowledge Graphs with LLM-Based Refinement",
      "authors": [
        "Sania Nayab",
        "Marco Simoni",
        "Giulio Rossolini",
        "Andrea Saracino"
      ],
      "abstract": "The generation of questions and answers (QA) from knowledge graphs (KG) plays a crucial role in the development and testing of educational platforms, dissemination tools, and large language models (LLM). However, existing approaches often struggle with scalability, linguistic quality, and factual consistency. This paper presents a scalable and deterministic pipeline for generating natural language QA from KGs, with an additional refinement step using LLMs to further enhance linguistic quality. The approach first clusters KG triplets based on their relations, creating reusable templates through natural language rules derived from the entity types of objects and relations. A module then leverages LLMs to refine these templates, improving clarity and coherence while preserving factual accuracy. Finally, the instantiation of answer options is achieved through a selection strategy that introduces distractors from the KG. Our experiments demonstrate that this hybrid approach efficiently generates high-quality QA pairs, combining scalability with fluency and linguistic precision.",
      "pdf_url": "https://arxiv.org/pdf/2511.11258v1",
      "published": "2025-11-14T12:54:01+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.11258v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "AIonopedia: an LLM agent orchestrating multimodal learning for ionic liquid discovery",
      "authors": [
        "Yuqi Yin",
        "Yibo Fu",
        "Siyuan Wang",
        "Peng Sun",
        "Hongyu Wang",
        "Xiaohui Wang",
        "Lei Zheng",
        "Zhiyong Li",
        "Zhirong Liu",
        "Jianji Wang",
        "Zhaoxi Sun"
      ],
      "abstract": "The discovery of novel Ionic Liquids (ILs) is hindered by critical challenges in property prediction, including limited data, poor model accuracy, and fragmented workflows. Leveraging the power of Large Language Models (LLMs), we introduce AIonopedia, to the best of our knowledge, the first LLM agent for IL discovery. Powered by an LLM-augmented multimodal domain foundation model for ILs, AIonopedia enables accurate property predictions and incorporates a hierarchical search architecture for molecular screening and design. Trained and evaluated on a newly curated and comprehensive IL dataset, our model delivers superior performance. Complementing these results, evaluations on literature-reported systems indicate that the agent can perform effective IL modification. Moving beyond offline tests, the practical efficacy was further confirmed through real-world wet-lab validation, in which the agent demonstrated exceptional generalization capabilities on challenging out-of-distribution tasks, underscoring its ability to accelerate real-world IL discovery.",
      "pdf_url": "https://arxiv.org/pdf/2511.11257v1",
      "published": "2025-11-14T12:53:57+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.11257v1",
      "categories": [
        "cs.AI",
        "cs.CE",
        "cs.LG"
      ]
    },
    {
      "title": "UAVBench: An Open Benchmark Dataset for Autonomous and Agentic AI UAV Systems via LLM-Generated Flight Scenarios",
      "authors": [
        "Mohamed Amine Ferrag",
        "Abderrahmane Lakas",
        "Merouane Debbah"
      ],
      "abstract": "Autonomous aerial systems increasingly rely on large language models (LLMs) for mission planning, perception, and decision-making, yet the lack of standardized and physically grounded benchmarks limits systematic evaluation of their reasoning capabilities. To address this gap, we introduce UAVBench, an open benchmark dataset comprising 50,000 validated UAV flight scenarios generated through taxonomy-guided LLM prompting and multi-stage safety validation. Each scenario is encoded in a structured JSON schema that includes mission objectives, vehicle configuration, environmental conditions, and quantitative risk labels, providing a unified representation of UAV operations across diverse domains. Building on this foundation, we present UAVBench_MCQ, a reasoning-oriented extension containing 50,000 multiple-choice questions spanning ten cognitive and ethical reasoning styles, ranging from aerodynamics and navigation to multi-agent coordination and integrated reasoning. This framework enables interpretable and machine-checkable assessment of UAV-specific cognition under realistic operational contexts. We evaluate 32 state-of-the-art LLMs, including GPT-5, ChatGPT-4o, Gemini 2.5 Flash, DeepSeek V3, Qwen3 235B, and ERNIE 4.5 300B, and find strong performance in perception and policy reasoning but persistent challenges in ethics-aware and resource-constrained decision-making. UAVBench establishes a reproducible and physically grounded foundation for benchmarking agentic AI in autonomous aerial systems and advancing next-generation UAV reasoning intelligence. To support open science and reproducibility, we release the UAVBench dataset, the UAVBench_MCQ benchmark, evaluation scripts, and all related materials on GitHub at https://github.com/maferrag/UAVBench",
      "pdf_url": "https://arxiv.org/pdf/2511.11252v1",
      "published": "2025-11-14T12:51:48+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.11252v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Toward Gaze Target Detection of Young Autistic Children",
      "authors": [
        "Shijian Deng",
        "Erin E. Kosloski",
        "Siva Sai Nagender Vasireddy",
        "Jia Li",
        "Randi Sierra Sherwood",
        "Feroz Mohamed Hatha",
        "Siddhi Patel",
        "Pamela R Rollins",
        "Yapeng Tian"
      ],
      "abstract": "The automatic detection of gaze targets in autistic children through artificial intelligence can be impactful, especially for those who lack access to a sufficient number of professionals to improve their quality of life. This paper introduces a new, real-world AI application for gaze target detection in autistic children, which predicts a child's point of gaze from an activity image. This task is foundational for building automated systems that can measure joint attention-a core challenge in Autism Spectrum Disorder (ASD). To facilitate the study of this challenging application, we collected the first-ever Autism Gaze Target (AGT) dataset. We further propose a novel Socially Aware Coarse-to-Fine (SACF) gaze detection framework that explicitly leverages the social context of a scene to overcome the class imbalance common in autism datasets-a consequence of autistic children's tendency to show reduced gaze to faces. It utilizes a two-pathway architecture with expert models specialized in social and non-social gaze, guided by a context-awareness gate module. The results of our comprehensive experiments demonstrate that our framework achieves new state-of-the-art performance for gaze target detection in this population, significantly outperforming existing methods, especially on the critical minority class of face-directed gaze.",
      "pdf_url": "https://arxiv.org/pdf/2511.11244v1",
      "published": "2025-11-14T12:44:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.11244v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "HealSplit: Towards Self-Healing through Adversarial Distillation in Split Federated Learning",
      "authors": [
        "Yuhan Xie",
        "Chen Lyu"
      ],
      "abstract": "Split Federated Learning (SFL) is an emerging paradigm for privacy-preserving distributed learning. However, it remains vulnerable to sophisticated data poisoning attacks targeting local features, labels, smashed data, and model weights. Existing defenses, primarily adapted from traditional Federated Learning (FL), are less effective under SFL due to limited access to complete model updates. This paper presents HealSplit, the first unified defense framework tailored for SFL, offering end-to-end detection and recovery against five sophisticated types of poisoning attacks. HealSplit comprises three key components: (1) a topology-aware detection module that constructs graphs over smashed data to identify poisoned samples via topological anomaly scoring (TAS); (2) a generative recovery pipeline that synthesizes semantically consistent substitutes for detected anomalies, validated by a consistency validation student; and (3) an adversarial multi-teacher distillation framework trains the student using semantic supervision from a Vanilla Teacher and anomaly-aware signals from an Anomaly-Influence Debiasing (AD) Teacher, guided by the alignment between topological and gradient-based interaction matrices. Extensive experiments on four benchmark datasets demonstrate that HealSplit consistently outperforms ten state-of-the-art defenses, achieving superior robustness and defense effectiveness across diverse attack scenarios.",
      "pdf_url": "https://arxiv.org/pdf/2511.11240v1",
      "published": "2025-11-14T12:42:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.11240v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Virtual Width Networks",
      "authors": [
        "Seed",
        "Baisheng Li",
        "Banggu Wu",
        "Bole Ma",
        "Bowen Xiao",
        "Chaoyi Zhang",
        "Cheng Li",
        "Chengyi Wang",
        "Chenyin Xu",
        "Chi Zhang",
        "Chong Hu",
        "Daoguang Zan",
        "Defa Zhu",
        "Dongyu Xu",
        "Du Li",
        "Faming Wu",
        "Fan Xia",
        "Ge Zhang",
        "Guang Shi",
        "Haobin Chen",
        "Hongyu Zhu",
        "Hongzhi Huang",
        "Huan Zhou",
        "Huanzhang Dou",
        "Jianhui Duan",
        "Jianqiao Lu",
        "Jianyu Jiang",
        "Jiayi Xu",
        "Jiecao Chen",
        "Jin Chen",
        "Jin Ma",
        "Jing Su",
        "Jingji Chen",
        "Jun Wang",
        "Jun Yuan",
        "Juncai Liu",
        "Jundong Zhou",
        "Kai Hua",
        "Kai Shen",
        "Kai Xiang",
        "Kaiyuan Chen",
        "Kang Liu",
        "Ke Shen",
        "Liang Xiang",
        "Lin Yan",
        "Lishu Luo",
        "Mengyao Zhang",
        "Ming Ding",
        "Mofan Zhang",
        "Nianning Liang",
        "Peng Li",
        "Penghao Huang",
        "Pengpeng Mu",
        "Qi Huang",
        "Qianli Ma",
        "Qiyang Min",
        "Qiying Yu",
        "Renming Pang",
        "Ru Zhang",
        "Shen Yan",
        "Shen Yan",
        "Shixiong Zhao",
        "Shuaishuai Cao",
        "Shuang Wu",
        "Siyan Chen",
        "Siyu Li",
        "Siyuan Qiao",
        "Tao Sun",
        "Tian Xin",
        "Tiantian Fan",
        "Ting Huang",
        "Ting-Han Fan",
        "Wei Jia",
        "Wenqiang Zhang",
        "Wenxuan Liu",
        "Xiangzhong Wu",
        "Xiaochen Zuo",
        "Xiaoying Jia",
        "Ximing Yang",
        "Xin Liu",
        "Xin Yu",
        "Xingyan Bin",
        "Xintong Hao",
        "Xiongcai Luo",
        "Xujing Li",
        "Xun Zhou",
        "Yanghua Peng",
        "Yangrui Chen",
        "Yi Lin",
        "Yichong Leng",
        "Yinghao Li",
        "Yingshuan Song",
        "Yiyuan Ma",
        "Yong Shan",
        "Yongan Xiang",
        "Yonghui Wu",
        "Yongtao Zhang",
        "Yongzhen Yao",
        "Yu Bao",
        "Yuehang Yang",
        "Yufeng Yuan",
        "Yunshui Li",
        "Yuqiao Xian",
        "Yutao Zeng",
        "Yuxuan Wang",
        "Zehua Hong",
        "Zehua Wang",
        "Zengzhi Wang",
        "Zeyu Yang",
        "Zhengqiang Yin",
        "Zhenyi Lu",
        "Zhexi Zhang",
        "Zhi Chen",
        "Zhi Zhang",
        "Zhiqi Lin",
        "Zihao Huang",
        "Zilin Xu",
        "Ziyun Wei",
        "Zuo Wang"
      ],
      "abstract": "We introduce Virtual Width Networks (VWN), a framework that delivers the benefits of wider representations without incurring the quadratic cost of increasing the hidden size. VWN decouples representational width from backbone width, expanding the embedding space while keeping backbone compute nearly constant. In our large-scale experiment, an 8-times expansion accelerates optimization by over 2 times for next-token and 3 times for next-2-token prediction. The advantage amplifies over training as both the loss gap grows and the convergence-speedup ratio increases, showing that VWN is not only token-efficient but also increasingly effective with scale. Moreover, we identify an approximately log-linear scaling relation between virtual width and loss reduction, offering an initial empirical basis and motivation for exploring virtual-width scaling as a new dimension of large-model efficiency.",
      "pdf_url": "https://arxiv.org/pdf/2511.11238v1",
      "published": "2025-11-14T12:41:57+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.11238v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "STaR: Towards Cognitive Table Reasoning via Slow-Thinking Large Language Models",
      "authors": [
        "Huajian Zhang",
        "Mingyue Cheng",
        "Yucong Luo",
        "Xiaoyu Tao"
      ],
      "abstract": "Table reasoning with the large language models (LLMs) is a fundamental path toward building intelligent systems that can understand and analyze over structured data. While recent progress has shown promising results, they still suffer from two key limitations: (i) the reasoning processes lack the depth and iterative refinement characteristic of human cognition; and (ii) the reasoning processes exhibit instability, which compromises their reliability in downstream applications. In this work, we present STaR (slow-thinking for table reasoning), a new framework achieving cognitive table reasoning, in which LLMs are equipped with slow-thinking capabilities by explicitly modeling step-by-step thinking and uncertainty-aware inference. During training, STaR employs two-stage difficulty-aware reinforcement learning (DRL), progressively learning from simple to complex queries under a composite reward. During inference, STaR performs trajectory-level uncertainty quantification by integrating token-level confidence and answer consistency, enabling selection of more credible reasoning paths. Extensive experiments on benchmarks demonstrate that STaR achieves superior performance and enhanced reasoning stability. Moreover, strong generalization over out-of-domain datasets further demonstrates STaR's potential as a reliable and cognitively inspired solution for table reasoning with LLMs.",
      "pdf_url": "https://arxiv.org/pdf/2511.11233v1",
      "published": "2025-11-14T12:34:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.11233v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "3D Gaussian and Diffusion-Based Gaze Redirection",
      "authors": [
        "Abiram Panchalingam",
        "Indu Bodala",
        "Stuart Middleton"
      ],
      "abstract": "High-fidelity gaze redirection is critical for generating augmented data to improve the generalization of gaze estimators. 3D Gaussian Splatting (3DGS) models like GazeGaussian represent the state-of-the-art but can struggle with rendering subtle, continuous gaze shifts. In this paper, we propose DiT-Gaze, a framework that enhances 3D gaze redirection models using a novel combination of Diffusion Transformer (DiT), weak supervision across gaze angles, and an orthogonality constraint loss. DiT allows higher-fidelity image synthesis, while our weak supervision strategy using synthetically generated intermediate gaze angles provides a smooth manifold of gaze directions during training. The orthogonality constraint loss mathematically enforces the disentanglement of internal representations for gaze, head pose, and expression. Comprehensive experiments show that DiT-Gaze sets a new state-of-the-art in both perceptual quality and redirection accuracy, reducing the state-of-the-art gaze error by 4.1% to 6.353 degrees, providing a superior method for creating synthetic training data. Our code and models will be made available for the research community to benchmark against.",
      "pdf_url": "https://arxiv.org/pdf/2511.11231v1",
      "published": "2025-11-14T12:32:22+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.11231v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Multi-agent Undercover Gaming: Hallucination Removal via Counterfactual Test for Multimodal Reasoning",
      "authors": [
        "Dayong Liang",
        "Xiao-Yong Wei",
        "Changmeng Zheng"
      ],
      "abstract": "Hallucination continues to pose a major obstacle in the reasoning capabilities of large language models (LLMs). Although the Multi-Agent Debate (MAD) paradigm offers a promising solution by promoting consensus among multiple agents to enhance reliability, it relies on the unrealistic assumption that all debaters are rational and reflective, which is a condition that may not hold when agents themselves are prone to hallucinations. To address this gap, we introduce the Multi-agent Undercover Gaming (MUG) protocol, inspired by social deduction games like \"Who is Undercover?\". MUG reframes MAD as a process of detecting \"undercover\" agents (those suffering from hallucinations) by employing multimodal counterfactual tests. Specifically, we modify reference images to introduce counterfactual evidence and observe whether agents can accurately identify these changes, providing ground-truth for identifying hallucinating agents and enabling robust, crowd-powered multimodal reasoning. MUG advances MAD protocols along three key dimensions: (1) enabling factual verification beyond statistical consensus through counterfactual testing; (2) introducing cross-evidence reasoning via dynamically modified evidence sources instead of relying on static inputs; and (3) fostering active reasoning, where agents engage in probing discussions rather than passively answering questions. Collectively, these innovations offer a more reliable and effective framework for multimodal reasoning in LLMs. The source code can be accessed at https://github.com/YongLD/MUG.git.",
      "pdf_url": "https://arxiv.org/pdf/2511.11182v1",
      "published": "2025-11-14T11:27:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.11182v1",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.MA",
        "cs.MM"
      ]
    },
    {
      "title": "Enhancing Group Recommendation using Soft Impute Singular Value Decomposition",
      "authors": [
        "Mubaraka Sani Ibrahim",
        "Isah Charles Saidu",
        "Lehel Csato"
      ],
      "abstract": "The growing popularity of group activities increased the need to develop methods for providing recommendations to a group of users based on the collective preferences of the group members. Several group recommender systems have been proposed, but these methods often struggle due to sparsity and high-dimensionality of the available data, common in many real-world applications. In this paper, we propose a group recommender system called Group Soft-Impute SVD, which leverages soft-impute singular value decomposition to enhance group recommendations. This approach addresses the challenge of sparse high-dimensional data using low-rank matrix completion. We compared the performance of Group Soft-Impute SVD with Group MF based approaches and found that our method outperforms the baselines in recall for small user groups while achieving comparable results across all group sizes when tasked on Goodbooks, Movielens, and Synthetic datasets. Furthermore, our method recovers lower matrix ranks than the baselines, demonstrating its effectiveness in handling high-dimensional data.",
      "pdf_url": "https://arxiv.org/pdf/2511.11172v1",
      "published": "2025-11-14T11:13:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.11172v1",
      "categories": [
        "cs.IR",
        "cs.AI"
      ]
    },
    {
      "title": "Refine and Align: Confidence Calibration through Multi-Agent Interaction in VQA",
      "authors": [
        "Ayush Pandey",
        "Jai Bardhan",
        "Ishita Jain",
        "Ramya S Hebbalaguppe",
        "Rohan Raju Dhanakshirur",
        "Lovekesh Vig"
      ],
      "abstract": "In the context of Visual Question Answering (VQA) and Agentic AI, calibration refers to how closely an AI system's confidence in its answers reflects their actual correctness. This aspect becomes especially important when such systems operate autonomously and must make decisions under visual uncertainty. While modern VQA systems, powered by advanced vision-language models (VLMs), are increasingly used in high-stakes domains like medical diagnostics and autonomous navigation due to their improved accuracy, the reliability of their confidence estimates remains under-examined. Particularly, these systems often produce overconfident responses. To address this, we introduce AlignVQA, a debate-based multi-agent framework, in which diverse specialized VLM -- each following distinct prompting strategies -- generate candidate answers and then engage in two-stage interaction: generalist agents critique, refine and aggregate these proposals. This debate process yields confidence estimates that more accurately reflect the model's true predictive performance. We find that more calibrated specialized agents produce better aligned confidences. Furthermore, we introduce a novel differentiable calibration-aware loss function called aligncal designed to fine-tune the specialized agents by minimizing an upper bound on the calibration error. This objective explicitly improves the fidelity of each agent's confidence estimates. Empirical results across multiple benchmark VQA datasets substantiate the efficacy of our approach, demonstrating substantial reductions in calibration discrepancies. Furthermore, we propose a novel differentiable calibration-aware loss to fine-tune the specialized agents and improve the quality of their individual confidence estimates based on minimising upper bound calibration error.",
      "pdf_url": "https://arxiv.org/pdf/2511.11169v1",
      "published": "2025-11-14T11:08:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.11169v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "OT-ALD: Aligning Latent Distributions with Optimal Transport for Accelerated Image-to-Image Translation",
      "authors": [
        "Zhanpeng Wang",
        "Shuting Cao",
        "Yuhang Lu",
        "Yuhan Li",
        "Na Lei",
        "Zhongxuan Luo"
      ],
      "abstract": "The Dual Diffusion Implicit Bridge (DDIB) is an emerging image-to-image (I2I) translation method that preserves cycle consistency while achieving strong flexibility. It links two independently trained diffusion models (DMs) in the source and target domains by first adding noise to a source image to obtain a latent code, then denoising it in the target domain to generate the translated image. However, this method faces two key challenges: (1) low translation efficiency, and (2) translation trajectory deviations caused by mismatched latent distributions. To address these issues, we propose a novel I2I translation framework, OT-ALD, grounded in optimal transport (OT) theory, which retains the strengths of DDIB-based approach. Specifically, we compute an OT map from the latent distribution of the source domain to that of the target domain, and use the mapped distribution as the starting point for the reverse diffusion process in the target domain. Our error analysis confirms that OT-ALD eliminates latent distribution mismatches. Moreover, OT-ALD effectively balances faster image translation with improved image quality. Experiments on four translation tasks across three high-resolution datasets show that OT-ALD improves sampling efficiency by 20.29% and reduces the FID score by 2.6 on average compared to the top-performing baseline models.",
      "pdf_url": "https://arxiv.org/pdf/2511.11162v1",
      "published": "2025-11-14T10:57:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.11162v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Specification, Application, and Operationalization of a Metamodel of Fairness",
      "authors": [
        "Julian Alfredo Mendez",
        "Timotheus Kampik"
      ],
      "abstract": "This paper presents the AR fairness metamodel, aimed at formally representing, analyzing, and comparing fairness scenarios. The metamodel provides an abstract representation of fairness, enabling the formal definition of fairness notions. We instantiate the metamodel through several examples, with a particular focus on comparing the notions of equity and equality.\n  We use the Tiles framework, which offers modular components that can be interconnected to represent various definitions of fairness. Its primary objective is to support the operationalization of AR-based fairness definitions in a range of scenarios, providing a robust method for defining, comparing, and evaluating fairness.\n  Tiles has an open-source implementation for fairness modeling and evaluation.",
      "pdf_url": "https://arxiv.org/pdf/2511.11144v1",
      "published": "2025-11-14T10:21:07+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.11144v1",
      "categories": [
        "cs.CY",
        "cs.AI"
      ]
    },
    {
      "title": "GGBench: A Geometric Generative Reasoning Benchmark for Unified Multimodal Models",
      "authors": [
        "Jingxuan Wei",
        "Caijun Jia",
        "Xi Bai",
        "Xinglong Xu",
        "Siyuan Li",
        "Linzhuang Sun",
        "Bihui Yu",
        "Conghui He",
        "Lijun Wu",
        "Cheng Tan"
      ],
      "abstract": "The advent of Unified Multimodal Models (UMMs) signals a paradigm shift in artificial intelligence, moving from passive perception to active, cross-modal generation. Despite their unprecedented ability to synthesize information, a critical gap persists in evaluation: existing benchmarks primarily assess discriminative understanding or unconstrained image generation separately, failing to measure the integrated cognitive process of generative reasoning. To bridge this gap, we propose that geometric construction provides an ideal testbed as it inherently demands a fusion of language comprehension and precise visual generation. We introduce GGBench, a benchmark designed specifically to evaluate geometric generative reasoning. It provides a comprehensive framework for systematically diagnosing a model's ability to not only understand and reason but to actively construct a solution, thereby setting a more rigorous standard for the next generation of intelligent systems. Project website: https://opendatalab-raiser.github.io/GGBench/.",
      "pdf_url": "https://arxiv.org/pdf/2511.11134v1",
      "published": "2025-11-14T10:07:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.11134v1",
      "categories": [
        "cs.AI"
      ]
    }
  ]
}