{
  "last_updated": "2025-12-11T00:55:47.879741",
  "papers": [
    {
      "title": "Astra: General Interactive World Model with Autoregressive Denoising",
      "authors": [
        "Yixuan Zhu",
        "Jiaqi Feng",
        "Wenzhao Zheng",
        "Yuan Gao",
        "Xin Tao",
        "Pengfei Wan",
        "Jie Zhou",
        "Jiwen Lu"
      ],
      "abstract": "Recent advances in diffusion transformers have empowered video generation models to generate high-quality video clips from texts or images. However, world models with the ability to predict long-horizon futures from past observations and actions remain underexplored, especially for general-purpose scenarios and various forms of actions. To bridge this gap, we introduce Astra, an interactive general world model that generates real-world futures for diverse scenarios (e.g., autonomous driving, robot grasping) with precise action interactions (e.g., camera motion, robot action). We propose an autoregressive denoising architecture and use temporal causal attention to aggregate past observations and support streaming outputs. We use a noise-augmented history memory to avoid over-reliance on past frames to balance responsiveness with temporal coherence. For precise action control, we introduce an action-aware adapter that directly injects action signals into the denoising process. We further develop a mixture of action experts that dynamically route heterogeneous action modalities, enhancing versatility across diverse real-world tasks such as exploration, manipulation, and camera control. Astra achieves interactive, consistent, and general long-term video prediction and supports various forms of interactions. Experiments across multiple datasets demonstrate the improvements of Astra in fidelity, long-range prediction, and action alignment over existing state-of-the-art world models.",
      "pdf_url": "https://arxiv.org/pdf/2512.08931v1",
      "published": "2025-12-09T18:59:57+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.08931v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Same Content, Different Answers: Cross-Modal Inconsistency in MLLMs",
      "authors": [
        "Angela van Sprang",
        "Laurens Samson",
        "Ana Lucic",
        "Erman Acar",
        "Sennay Ghebreab",
        "Yuki M. Asano"
      ],
      "abstract": "We introduce two new benchmarks REST and REST+(Render-Equivalence Stress Tests) to enable systematic evaluation of cross-modal inconsistency in multimodal large language models (MLLMs). MLLMs are trained to represent vision and language in the same embedding space, yet they cannot perform the same tasks in both modalities. Our benchmarks contain samples with the same semantic information in three modalities (image, text, mixed) and we show that state-of-the-art MLLMs cannot consistently reason over these different modalities. We evaluate 15 MLLMs and find that the degree of modality inconsistency varies substantially, even when accounting for problems with text recognition (OCR). Neither rendering text as image nor rendering an image as text solves the inconsistency. Even if OCR is correct, we find that visual characteristics (text colour and resolution, but not font) and the number of vision tokens have an impact on model performance. Finally, we find that our consistency score correlates with the modality gap between text and images, highlighting a mechanistic interpretation of cross-modal inconsistent MLLMs.",
      "pdf_url": "https://arxiv.org/pdf/2512.08923v1",
      "published": "2025-12-09T18:57:07+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.08923v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "SAQ: Stabilizer-Aware Quantum Error Correction Decoder",
      "authors": [
        "David Zenati",
        "Eliya Nachmani"
      ],
      "abstract": "Quantum Error Correction (QEC) decoding faces a fundamental accuracy-efficiency tradeoff. Classical methods like Minimum Weight Perfect Matching (MWPM) exhibit variable performance across noise models and suffer from polynomial complexity, while tensor network decoders achieve high accuracy but at prohibitively high computational cost. Recent neural decoders reduce complexity but lack the accuracy needed to compete with computationally expensive classical methods. We introduce SAQ-Decoder, a unified framework combining transformer-based learning with constraint aware post-processing that achieves both near Maximum Likelihood (ML) accuracy and linear computational scalability with respect to the syndrome size. Our approach combines a dual-stream transformer architecture that processes syndromes and logical information with asymmetric attention patterns, and a novel differentiable logical loss that directly optimizes Logical Error Rates (LER) through smooth approximations over finite fields. SAQ-Decoder achieves near-optimal performance, with error thresholds of 10.99% (independent noise) and 18.6% (depolarizing noise) on toric codes that approach the ML bounds of 11.0% and 18.9% while outperforming existing neural and classical baselines in accuracy, complexity, and parameter efficiency. Our findings establish that learned decoders can simultaneously achieve competitive decoding accuracy and computational efficiency, addressing key requirements for practical fault-tolerant quantum computing systems.",
      "pdf_url": "https://arxiv.org/pdf/2512.08914v1",
      "published": "2025-12-09T18:51:35+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.08914v1",
      "categories": [
        "quant-ph",
        "cs.AI"
      ]
    },
    {
      "title": "Revisiting the Scaling Properties of Downstream Metrics in Large Language Model Training",
      "authors": [
        "Jakub Krajewski",
        "Amitis Shidani",
        "Dan Busbridge",
        "Sam Wiseman",
        "Jason Ramapuram"
      ],
      "abstract": "While scaling laws for Large Language Models (LLMs) traditionally focus on proxy metrics like pretraining loss, predicting downstream task performance has been considered unreliable. This paper challenges that view by proposing a direct framework to model the scaling of benchmark performance from the training budget. We find that for a fixed token-to-parameter ratio, a simple power law can accurately describe the scaling behavior of log accuracy on multiple popular downstream tasks. Our results show that the direct approach extrapolates better than the previously proposed two-stage procedure, which is prone to compounding errors. Furthermore, we introduce functional forms that predict accuracy across token-to-parameter ratios and account for inference compute under repeated sampling. We validate our findings on models with up to 17B parameters trained on up to 350B tokens across two dataset mixtures. To support reproducibility and encourage future research, we release the complete set of pretraining losses and downstream evaluation results.",
      "pdf_url": "https://arxiv.org/pdf/2512.08894v1",
      "published": "2025-12-09T18:33:48+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.08894v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Toward Faithful Retrieval-Augmented Generation with Sparse Autoencoders",
      "authors": [
        "Guangzhi Xiong",
        "Zhenghao He",
        "Bohan Liu",
        "Sanchit Sinha",
        "Aidong Zhang"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) improves the factuality of large language models (LLMs) by grounding outputs in retrieved evidence, but faithfulness failures, where generations contradict or extend beyond the provided sources, remain a critical challenge. Existing hallucination detection methods for RAG often rely either on large-scale detector training, which requires substantial annotated data, or on querying external LLM judges, which leads to high inference costs. Although some approaches attempt to leverage internal representations of LLMs for hallucination detection, their accuracy remains limited. Motivated by recent advances in mechanistic interpretability, we employ sparse autoencoders (SAEs) to disentangle internal activations, successfully identifying features that are specifically triggered during RAG hallucinations. Building on a systematic pipeline of information-based feature selection and additive feature modeling, we introduce RAGLens, a lightweight hallucination detector that accurately flags unfaithful RAG outputs using LLM internal representations. RAGLens not only achieves superior detection performance compared to existing methods, but also provides interpretable rationales for its decisions, enabling effective post-hoc mitigation of unfaithful RAG. Finally, we justify our design choices and reveal new insights into the distribution of hallucination-related signals within LLMs. The code is available at https://github.com/Teddy-XiongGZ/RAGLens.",
      "pdf_url": "https://arxiv.org/pdf/2512.08892v1",
      "published": "2025-12-09T18:33:22+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.08892v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "No Labels, No Problem: Training Visual Reasoners with Multimodal Verifiers",
      "authors": [
        "Damiano Marsili",
        "Georgia Gkioxari"
      ],
      "abstract": "Visual reasoning is challenging, requiring both precise object grounding and understanding complex spatial relationships. Existing methods fall into two camps: language-only chain-of-thought approaches, which demand large-scale (image, query, answer) supervision, and program-synthesis approaches which use pre-trained models and avoid training, but suffer from flawed logic and erroneous grounding. We propose an annotation-free training framework that improves both reasoning and grounding. Our framework uses AI-powered verifiers: an LLM verifier refines LLM reasoning via reinforcement learning, while a VLM verifier strengthens visual grounding through automated hard-negative mining, eliminating the need for ground truth labels. This design combines the strengths of modern AI systems: advanced language-only reasoning models for decomposing spatial queries into simpler subtasks, and strong vision specialist models improved via performant VLM critics. We evaluate our approach across diverse spatial reasoning tasks, and show that our method improves visual reasoning and surpasses open-source and proprietary models, while with our improved visual grounding model we further outperform recent text-only visual reasoning methods. Project webpage: https://glab-caltech.github.io/valor/",
      "pdf_url": "https://arxiv.org/pdf/2512.08889v1",
      "published": "2025-12-09T18:30:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.08889v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "DAO-GP Drift Aware Online Non-Linear Regression Gaussian-Process",
      "authors": [
        "Mohammad Abu-Shaira",
        "Ajita Rattani",
        "Weishi Shi"
      ],
      "abstract": "Real-world datasets often exhibit temporal dynamics characterized by evolving data distributions. Disregarding this phenomenon, commonly referred to as concept drift, can significantly diminish a model's predictive accuracy. Furthermore, the presence of hyperparameters in online models exacerbates this issue. These parameters are typically fixed and cannot be dynamically adjusted by the user in response to the evolving data distribution. Gaussian Process (GP) models offer powerful non-parametric regression capabilities with uncertainty quantification, making them ideal for modeling complex data relationships in an online setting. However, conventional online GP methods face several critical limitations, including a lack of drift-awareness, reliance on fixed hyperparameters, vulnerability to data snooping, absence of a principled decay mechanism, and memory inefficiencies. In response, we propose DAO-GP (Drift-Aware Online Gaussian Process), a novel, fully adaptive, hyperparameter-free, decayed, and sparse non-linear regression model. DAO-GP features a built-in drift detection and adaptation mechanism that dynamically adjusts model behavior based on the severity of drift. Extensive empirical evaluations confirm DAO-GP's robustness across stationary conditions, diverse drift types (abrupt, incremental, gradual), and varied data characteristics. Analyses demonstrate its dynamic adaptation, efficient in-memory and decay-based management, and evolving inducing points. Compared with state-of-the-art parametric and non-parametric models, DAO-GP consistently achieves superior or competitive performance, establishing it as a drift-resilient solution for online non-linear regression.",
      "pdf_url": "https://arxiv.org/pdf/2512.08879v1",
      "published": "2025-12-09T18:12:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.08879v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "When Tables Leak: Attacking String Memorization in LLM-Based Tabular Data Generation",
      "authors": [
        "Joshua Ward",
        "Bochao Gu",
        "Chi-Hua Wang",
        "Guang Cheng"
      ],
      "abstract": "Large Language Models (LLMs) have recently demonstrated remarkable performance in generating high-quality tabular synthetic data. In practice, two primary approaches have emerged for adapting LLMs to tabular data generation: (i) fine-tuning smaller models directly on tabular datasets, and (ii) prompting larger models with examples provided in context. In this work, we show that popular implementations from both regimes exhibit a tendency to compromise privacy by reproducing memorized patterns of numeric digits from their training data. To systematically analyze this risk, we introduce a simple No-box Membership Inference Attack (MIA) called LevAtt that assumes adversarial access to only the generated synthetic data and targets the string sequences of numeric digits in synthetic observations. Using this approach, our attack exposes substantial privacy leakage across a wide range of models and datasets, and in some cases, is even a perfect membership classifier on state-of-the-art models. Our findings highlight a unique privacy vulnerability of LLM-based synthetic data generation and the need for effective defenses. To this end, we propose two methods, including a novel sampling strategy that strategically perturbs digits during generation. Our evaluation demonstrates that this approach can defeat these attacks with minimal loss of fidelity and utility of the synthetic data.",
      "pdf_url": "https://arxiv.org/pdf/2512.08875v1",
      "published": "2025-12-09T18:06:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.08875v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Siamese-Driven Optimization for Low-Resolution Image Latent Embedding in Image Captioning",
      "authors": [
        "Jing Jie Tan",
        "Anissa Mokraoui",
        "Ban-Hoe Kwan",
        "Danny Wee-Kiat Ng",
        "Yan-Chai Hum"
      ],
      "abstract": "Image captioning is essential in many fields including assisting visually impaired individuals, improving content management systems, and enhancing human-computer interaction. However, a recent challenge in this domain is dealing with low-resolution image (LRI). While performance can be improved by using larger models like transformers for encoding, these models are typically heavyweight, demanding significant computational resources and memory, leading to challenges in retraining. To address this, the proposed SOLI (Siamese-Driven Optimization for Low-Resolution Image Latent Embedding in Image Captioning) approach presents a solution specifically designed for lightweight, low-resolution images captioning. It employs a Siamese network architecture to optimize latent embeddings, enhancing the efficiency and accuracy of the image-to-text translation process. By focusing on a dual-pathway neural network structure, SOLI minimizes computational overhead without sacrificing performance, making it an ideal choice for training on resource-constrained scenarios.",
      "pdf_url": "https://arxiv.org/pdf/2512.08873v1",
      "published": "2025-12-09T18:05:59+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.08873v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC"
      ]
    },
    {
      "title": "Fed-SE: Federated Self-Evolution for Privacy-Constrained Multi-Environment LLM Agents",
      "authors": [
        "Xiang Chen",
        "Yuling Shi",
        "Qizhen Lan",
        "Yuchao Qiu",
        "Xiaodong Gu"
      ],
      "abstract": "LLM agents are widely deployed in complex interactive tasks, yet privacy constraints often preclude centralized optimization and co-evolution across dynamic environments. While Federated Learning (FL) has proven effective on static datasets, its extension to the open-ended self-evolution of agents remains underexplored. Directly applying standard FL is challenging: heterogeneous tasks and sparse, trajectory-level rewards introduce severe gradient conflicts, destabilizing the global optimization process. To bridge this gap, we propose Fed-SE, a Federated Self-Evolution framework for LLM agents. Fed-SE establishes a local evolution-global aggregation paradigm. Locally, agents employ parameter-efficient fine-tuning on filtered, high-return trajectories to achieve stable gradient updates. Globally, Fed-SE aggregates updates within a low-rank subspace that disentangles environment-specific dynamics, effectively reducing negative transfer across clients. Experiments across five heterogeneous environments demonstrate that Fed-SE improves average task success rates by approximately 18% over federated baselines, validating its effectiveness in robust cross-environment knowledge transfer in privacy-constrained deployments.",
      "pdf_url": "https://arxiv.org/pdf/2512.08870v1",
      "published": "2025-12-09T18:04:41+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.08870v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Differentially Private Synthetic Data Generation Using Context-Aware GANs",
      "authors": [
        "Anantaa Kotal",
        "Anupam Joshi"
      ],
      "abstract": "The widespread use of big data across sectors has raised major privacy concerns, especially when sensitive information is shared or analyzed. Regulations such as GDPR and HIPAA impose strict controls on data handling, making it difficult to balance the need for insights with privacy requirements. Synthetic data offers a promising solution by creating artificial datasets that reflect real patterns without exposing sensitive information. However, traditional synthetic data methods often fail to capture complex, implicit rules that link different elements of the data and are essential in domains like healthcare. They may reproduce explicit patterns but overlook domain-specific constraints that are not directly stated yet crucial for realism and utility. For example, prescription guidelines that restrict certain medications for specific conditions or prevent harmful drug interactions may not appear explicitly in the original data. Synthetic data generated without these implicit rules can lead to medically inappropriate or unrealistic profiles. To address this gap, we propose ContextGAN, a Context-Aware Differentially Private Generative Adversarial Network that integrates domain-specific rules through a constraint matrix encoding both explicit and implicit knowledge. The constraint-aware discriminator evaluates synthetic data against these rules to ensure adherence to domain constraints, while differential privacy protects sensitive details from the original data. We validate ContextGAN across healthcare, security, and finance, showing that it produces high-quality synthetic data that respects domain rules and preserves privacy. Our results demonstrate that ContextGAN improves realism and utility by enforcing domain constraints, making it suitable for applications that require compliance with both explicit patterns and implicit rules under strict privacy guarantees.",
      "pdf_url": "https://arxiv.org/pdf/2512.08869v1",
      "published": "2025-12-09T18:02:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.08869v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ]
    },
    {
      "title": "EcomBench: Towards Holistic Evaluation of Foundation Agents in E-commerce",
      "authors": [
        "Rui Min",
        "Zile Qiao",
        "Ze Xu",
        "Jiawen Zhai",
        "Wenyu Gao",
        "Xuanzhong Chen",
        "Haozhen Sun",
        "Zhen Zhang",
        "Xinyu Wang",
        "Hong Zhou",
        "Wenbiao Yin",
        "Xuan Zhou",
        "Yong Jiang",
        "Haicheng Liu",
        "Liang Ding",
        "Ling Zou",
        "Yi R.",
        "Fung",
        "Yalong Li",
        "Pengjun Xie"
      ],
      "abstract": "Foundation agents have rapidly advanced in their ability to reason and interact with real environments, making the evaluation of their core capabilities increasingly important. While many benchmarks have been developed to assess agent performance, most concentrate on academic settings or artificially designed scenarios while overlooking the challenges that arise in real applications. To address this issue, we focus on a highly practical real-world setting, the e-commerce domain, which involves a large volume of diverse user interactions, dynamic market conditions, and tasks directly tied to real decision-making processes. To this end, we introduce EcomBench, a holistic E-commerce Benchmark designed to evaluate agent performance in realistic e-commerce environments. EcomBench is built from genuine user demands embedded in leading global e-commerce ecosystems and is carefully curated and annotated through human experts to ensure clarity, accuracy, and domain relevance. It covers multiple task categories within e-commerce scenarios and defines three difficulty levels that evaluate agents on key capabilities such as deep information retrieval, multi-step reasoning, and cross-source knowledge integration. By grounding evaluation in real e-commerce contexts, EcomBench provides a rigorous and dynamic testbed for measuring the practical capabilities of agents in modern e-commerce.",
      "pdf_url": "https://arxiv.org/pdf/2512.08868v1",
      "published": "2025-12-09T18:00:26+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.08868v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Interpolation in Knowledge Representation",
      "authors": [
        "Jean Christoph Jung",
        "Patrick Koopmann",
        "Matthias Knorr"
      ],
      "abstract": "Craig interpolation and uniform interpolation have many applications in knowledge representation, including explainability, forgetting, modularization and reuse, and even learning. At the same time, many relevant knowledge representation formalisms do in general not have Craig or uniform interpolation, and computing interpolants in practice is challenging. We have a closer look at two prominent knowledge representation formalisms, description logics and logic programming, and discuss theoretical results and practical methods for computing interpolants.",
      "pdf_url": "https://arxiv.org/pdf/2512.08833v1",
      "published": "2025-12-09T17:21:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.08833v1",
      "categories": [
        "cs.AI",
        "cs.LO"
      ]
    },
    {
      "title": "InfiniteVL: Synergizing Linear and Sparse Attention for Highly-Efficient, Unlimited-Input Vision-Language Models",
      "authors": [
        "Hongyuan Tao",
        "Bencheng Liao",
        "Shaoyu Chen",
        "Haoran Yin",
        "Qian Zhang",
        "Wenyu Liu",
        "Xinggang Wang"
      ],
      "abstract": "Window attention and linear attention represent two principal strategies for mitigating the quadratic complexity and ever-growing KV cache in Vision-Language Models (VLMs). However, we observe that window-based VLMs suffer performance degradation when sequence length exceeds the window size, while linear attention underperforms on information-intensive tasks such as OCR and document understanding. To overcome these limitations, we propose InfiniteVL, a linear-complexity VLM architecture that synergizes sliding window attention (SWA) with Gated DeltaNet. For achieving competitive multimodal performance under constrained resources, we design a three-stage training strategy comprising distillation pretraining, instruction tuning, and long-sequence SFT. Remarkably, using less than 2\\% of the training data required by leading VLMs, InfiniteVL not only substantially outperforms previous linear-complexity VLMs but also matches the performance of leading Transformer-based VLMs, while demonstrating effective long-term memory retention. Compared to similar-sized Transformer-based VLMs accelerated by FlashAttention-2, InfiniteVL achieves over 3.6\\times inference speedup while maintaining constant latency and memory footprint. In streaming video understanding scenarios, it sustains a stable 24 FPS real-time prefill speed while preserving long-term memory cache. Code and models are available at https://github.com/hustvl/InfiniteVL.",
      "pdf_url": "https://arxiv.org/pdf/2512.08829v1",
      "published": "2025-12-09T17:18:32+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.08829v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "CARLoS: Retrieval via Concise Assessment Representation of LoRAs at Scale",
      "authors": [
        "Shahar Sarfaty",
        "Adi Haviv",
        "Uri Hacohen",
        "Niva Elkin-Koren",
        "Roi Livni",
        "Amit H. Bermano"
      ],
      "abstract": "The rapid proliferation of generative components, such as LoRAs, has created a vast but unstructured ecosystem. Existing discovery methods depend on unreliable user descriptions or biased popularity metrics, hindering usability. We present CARLoS, a large-scale framework for characterizing LoRAs without requiring additional metadata. Analyzing over 650 LoRAs, we employ them in image generation over a variety of prompts and seeds, as a credible way to assess their behavior. Using CLIP embeddings and their difference to a base-model generation, we concisely define a three-part representation: Directions, defining semantic shift; Strength, quantifying the significance of the effect; and Consistency, quantifying how stable the effect is. Using these representations, we develop an efficient retrieval framework that semantically matches textual queries to relevant LoRAs while filtering overly strong or unstable ones, outperforming textual baselines in automated and human evaluations. While retrieval is our primary focus, the same representation also supports analyses linking Strength and Consistency to legal notions of substantiality and volition, key considerations in copyright, positioning CARLoS as a practical system with broader relevance for LoRA analysis.",
      "pdf_url": "https://arxiv.org/pdf/2512.08826v1",
      "published": "2025-12-09T17:15:32+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.08826v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Training-Free Dual Hyperbolic Adapters for Better Cross-Modal Reasoning",
      "authors": [
        "Yi Zhang",
        "Chun-Wun Cheng",
        "Junyi He",
        "Ke Yu",
        "Yushun Tang",
        "Carola-Bibiane Schönlieb",
        "Zhihai He",
        "Angelica I. Aviles-Rivero"
      ],
      "abstract": "Recent research in Vision-Language Models (VLMs) has significantly advanced our capabilities in cross-modal reasoning. However, existing methods suffer from performance degradation with domain changes or require substantial computational resources for fine-tuning in new domains. To address this issue, we develop a new adaptation method for large vision-language models, called \\textit{Training-free Dual Hyperbolic Adapters} (T-DHA). We characterize the vision-language relationship between semantic concepts, which typically has a hierarchical tree structure, in the hyperbolic space instead of the traditional Euclidean space. Hyperbolic spaces exhibit exponential volume growth with radius, unlike the polynomial growth in Euclidean space. We find that this unique property is particularly effective for embedding hierarchical data structures using the Poincaré ball model, achieving significantly improved representation and discrimination power. Coupled with negative learning, it provides more accurate and robust classifications with fewer feature dimensions. Our extensive experimental results on various datasets demonstrate that the T-DHA method significantly outperforms existing state-of-the-art methods in few-shot image recognition and domain generalization tasks.",
      "pdf_url": "https://arxiv.org/pdf/2512.08820v1",
      "published": "2025-12-09T17:12:22+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.08820v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Do Depth-Grown Models Overcome the Curse of Depth? An In-Depth Analysis",
      "authors": [
        "Ferdinand Kapl",
        "Emmanouil Angelis",
        "Tobias Höppe",
        "Kaitlin Maile",
        "Johannes von Oswald",
        "Nino Scherrer",
        "Stefan Bauer"
      ],
      "abstract": "Gradually growing the depth of Transformers during training can not only reduce training cost but also lead to improved reasoning performance, as shown by MIDAS (Saunshi et al., 2024). Thus far, however, a mechanistic understanding of these gains has been missing. In this work, we establish a connection to recent work showing that layers in the second half of non-grown, pre-layernorm Transformers contribute much less to the final output distribution than those in the first half - also known as the Curse of Depth (Sun et al., 2025, Csordás et al., 2025). Using depth-wise analyses, we demonstrate that growth via gradual middle stacking yields more effective utilization of model depth, alters the residual stream structure, and facilitates the formation of permutable computational blocks. In addition, we propose a lightweight modification of MIDAS that yields further improvements in downstream reasoning benchmarks. Overall, this work highlights how the gradual growth of model depth can lead to the formation of distinct computational circuits and overcome the limited depth utilization seen in standard non-grown models.",
      "pdf_url": "https://arxiv.org/pdf/2512.08819v1",
      "published": "2025-12-09T17:12:04+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.08819v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Emovectors: assessing emotional content in jazz improvisations for creativity evaluation",
      "authors": [
        "Anna Jordanous"
      ],
      "abstract": "Music improvisation is fascinating to study, being essentially a live demonstration of a creative process. In jazz, musicians often improvise across predefined chord progressions (leadsheets). How do we assess the creativity of jazz improvisations? And can we capture this in automated metrics for creativity for current LLM-based generative systems? Demonstration of emotional involvement is closely linked with creativity in improvisation. Analysing musical audio, can we detect emotional involvement? This study hypothesises that if an improvisation contains more evidence of emotion-laden content, it is more likely to be recognised as creative. An embeddings-based method is proposed for capturing the emotional content in musical improvisations, using a psychologically-grounded classification of musical characteristics associated with emotions. Resulting 'emovectors' are analysed to test the above hypothesis, comparing across multiple improvisations. Capturing emotional content in this quantifiable way can contribute towards new metrics for creativity evaluation that can be applied at scale.",
      "pdf_url": "https://arxiv.org/pdf/2512.08812v1",
      "published": "2025-12-09T17:05:36+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.08812v1",
      "categories": [
        "cs.SD",
        "cs.AI"
      ]
    },
    {
      "title": "Multicalibration for LLM-based Code Generation",
      "authors": [
        "Viola Campos",
        "Robin Kuschnereit",
        "Adrian Ulges"
      ],
      "abstract": "As AI-based code generation becomes widespread, researchers are investigating the calibration of code LLMs - ensuring their confidence scores faithfully represent the true likelihood of code correctness. To do so, we investigate multicalibration, which can capture additional factors about a coding problem, such as complexity, code length, or programming language used. We study four multicalibration approaches on three function synthesis benchmarks, using latest-generation code LLMs (Qwen3 Coder, GPT-OSS, DeepSeek-R1-Distill). Our results demonstrate that multicalibration can yield distinct improvements over both uncalibrated token likelihoods (+1.03 in skill score) and baseline calibrations (+0.37 in skill score). We study the influence of the aforementioned factors in ablations, and make our dataset (consisting of code generations, likelihoods, and correctness labels) available for future research on code LLM calibration.",
      "pdf_url": "https://arxiv.org/pdf/2512.08810v1",
      "published": "2025-12-09T17:04:01+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.08810v1",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "PrivTune: Efficient and Privacy-Preserving Fine-Tuning of Large Language Models via Device-Cloud Collaboration",
      "authors": [
        "Yi Liu",
        "Weixiang Han",
        "Chengjun Cai",
        "Xingliang Yuan",
        "Cong Wang"
      ],
      "abstract": "With the rise of large language models, service providers offer language models as a service, enabling users to fine-tune customized models via uploaded private datasets. However, this raises concerns about sensitive data leakage. Prior methods, relying on differential privacy within device-cloud collaboration frameworks, struggle to balance privacy and utility, exposing users to inference attacks or degrading fine-tuning performance. To address this, we propose PrivTune, an efficient and privacy-preserving fine-tuning framework via Split Learning (SL). The key idea of PrivTune is to inject crafted noise into token representations from the SL bottom model, making each token resemble the $n$-hop indirect neighbors. PrivTune formulates this as an optimization problem to compute the optimal noise vector, aligning with defense-utility goals. On this basis, it then adjusts the parameters (i.e., mean) of the $d_χ$-Privacy noise distribution to align with the optimization direction and scales the noise according to token importance to minimize distortion. Experiments on five datasets (covering both classification and generation tasks) against three embedding inversion and three attribute inference attacks show that, using RoBERTa on the Stanford Sentiment Treebank dataset, PrivTune reduces the attack success rate to 10% with only a 3.33% drop in utility performance, outperforming state-of-the-art baselines.",
      "pdf_url": "https://arxiv.org/pdf/2512.08809v1",
      "published": "2025-12-09T17:03:59+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.08809v1",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Democratizing ML for Enterprise Security: A Self-Sustained Attack Detection Framework",
      "authors": [
        "Sadegh Momeni",
        "Ge Zhang",
        "Birkett Huber",
        "Hamza Harkous",
        "Sam Lipton",
        "Benoit Seguin",
        "Yanis Pavlidis"
      ],
      "abstract": "Despite advancements in machine learning for security, rule-based detection remains prevalent in Security Operations Centers due to the resource intensiveness and skill gap associated with ML solutions. While traditional rule-based methods offer efficiency, their rigidity leads to high false positives or negatives and requires continuous manual maintenance. This paper proposes a novel, two-stage hybrid framework to democratize ML-based threat detection. The first stage employs intentionally loose YARA rules for coarse-grained filtering, optimized for high recall. The second stage utilizes an ML classifier to filter out false positives from the first stage's output. To overcome data scarcity, the system leverages Simula, a seedless synthetic data generation framework, enabling security analysts to create high-quality training datasets without extensive data science expertise or pre-labeled examples. A continuous feedback loop incorporates real-time investigation results to adaptively tune the ML model, preventing rule degradation.\n  This proposed model with active learning has been rigorously tested for a prolonged time in a production environment spanning tens of thousands of systems. The system handles initial raw log volumes often reaching 250 billion events per day, significantly reducing them through filtering and ML inference to a handful of daily tickets for human investigation. Live experiments over an extended timeline demonstrate a general improvement in the model's precision over time due to the active learning feature. This approach offers a self-sustained, low-overhead, and low-maintenance solution, allowing security professionals to guide model learning as expert ``teachers''.",
      "pdf_url": "https://arxiv.org/pdf/2512.08802v1",
      "published": "2025-12-09T16:58:08+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.08802v1",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "title": "Can TabPFN Compete with GNNs for Node Classification via Graph Tabularization?",
      "authors": [
        "Jeongwhan Choi",
        "Woosung Kang",
        "Minseo Kim",
        "Jongwoo Kim",
        "Noseong Park"
      ],
      "abstract": "Foundation models pretrained on large data have demonstrated remarkable zero-shot generalization capabilities across domains. Building on the success of TabPFN for tabular data and its recent extension to time series, we investigate whether graph node classification can be effectively reformulated as a tabular learning problem. We introduce TabPFN-GN, which transforms graph data into tabular features by extracting node attributes, structural properties, positional encodings, and optionally smoothed neighborhood features. This enables TabPFN to perform direct node classification without any graph-specific training or language model dependencies. Our experiments on 12 benchmark datasets reveal that TabPFN-GN achieves competitive performance with GNNs on homophilous graphs and consistently outperforms them on heterophilous graphs. These results demonstrate that principled feature engineering can bridge the gap between tabular and graph domains, providing a practical alternative to task-specific GNN training and LLM-dependent graph foundation models.",
      "pdf_url": "https://arxiv.org/pdf/2512.08798v1",
      "published": "2025-12-09T16:51:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.08798v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "MatteViT: High-Frequency-Aware Document Shadow Removal with Shadow Matte Guidance",
      "authors": [
        "Chaewon Kim",
        "Seoyeon Lee",
        "Jonghyuk Park"
      ],
      "abstract": "Document shadow removal is essential for enhancing the clarity of digitized documents. Preserving high-frequency details (e.g., text edges and lines) is critical in this process because shadows often obscure or distort fine structures. This paper proposes a matte vision transformer (MatteViT), a novel shadow removal framework that applies spatial and frequency-domain information to eliminate shadows while preserving fine-grained structural details. To effectively retain these details, we employ two preservation strategies. First, our method introduces a lightweight high-frequency amplification module (HFAM) that decomposes and adaptively amplifies high-frequency components. Second, we present a continuous luminance-based shadow matte, generated using a custom-built matte dataset and shadow matte generator, which provides precise spatial guidance from the earliest processing stage. These strategies enable the model to accurately identify fine-grained regions and restore them with high fidelity. Extensive experiments on public benchmarks (RDD and Kligler) demonstrate that MatteViT achieves state-of-the-art performance, providing a robust and practical solution for real-world document shadow removal. Furthermore, the proposed method better preserves text-level details in downstream tasks, such as optical character recognition, improving recognition performance over prior methods.",
      "pdf_url": "https://arxiv.org/pdf/2512.08789v1",
      "published": "2025-12-09T16:40:10+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.08789v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "A Systematic Evaluation of Preference Aggregation in Federated RLHF for Pluralistic Alignment of LLMs",
      "authors": [
        "Mahmoud Srewa",
        "Tianyu Zhao",
        "Salma Elmalaki"
      ],
      "abstract": "This paper addresses the challenge of aligning large language models (LLMs) with diverse human preferences within federated learning (FL) environments, where standard methods often fail to adequately represent diverse viewpoints. We introduce a comprehensive evaluation framework that systematically assesses the trade-off between alignment quality and fairness when using different aggregation strategies for human preferences. In our federated setting, each group locally evaluates rollouts and produces reward signals, and the server aggregates these group-level rewards without accessing any raw data. Specifically, we evaluate standard reward aggregation techniques (min, max, and average) and introduce a novel adaptive scheme that dynamically adjusts preference weights based on a group's historical alignment performance. Our experiments on question-answering (Q/A) tasks using a PPO-based RLHF pipeline demonstrate that our adaptive approach consistently achieves superior fairness while maintaining competitive alignment scores. This work offers a robust methodology for evaluating LLM behavior across diverse populations and provides a practical solution for developing truly pluralistic and fairly aligned models.",
      "pdf_url": "https://arxiv.org/pdf/2512.08786v1",
      "published": "2025-12-09T16:39:32+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.08786v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Fluent Alignment with Disfluent Judges: Post-training for Lower-resource Languages",
      "authors": [
        "David Samuel",
        "Lilja Øvrelid",
        "Erik Velldal",
        "Andrey Kutuzov"
      ],
      "abstract": "We propose a post-training method for lower-resource languages that preserves fluency of language models even when aligned by disfluent reward models. Preference-optimization is now a well-researched topic, but previous work has mostly addressed models for English and Chinese. Lower-resource languages lack both datasets written by native speakers and language models capable of generating fluent synthetic data. Thus, in this work, we focus on developing a fluent preference-aligned language model without any instruction-tuning data in the target language. Our approach uses an on-policy training method, which we compare with two common approaches: supervised finetuning on machine-translated data and multilingual finetuning. We conduct a case study on Norwegian Bokmål and evaluate fluency through native-speaker assessments. The results show that the on-policy aspect is crucial and outperforms the alternatives without relying on any hard-to-obtain data.",
      "pdf_url": "https://arxiv.org/pdf/2512.08777v1",
      "published": "2025-12-09T16:31:48+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.08777v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Refining Visual Artifacts in Diffusion Models via Explainable AI-based Flaw Activation Maps",
      "authors": [
        "Seoyeon Lee",
        "Gwangyeol Yu",
        "Chaewon Kim",
        "Jonghyuk Park"
      ],
      "abstract": "Diffusion models have achieved remarkable success in image synthesis. However, addressing artifacts and unrealistic regions remains a critical challenge. We propose self-refining diffusion, a novel framework that enhances image generation quality by detecting these flaws. The framework employs an explainable artificial intelligence (XAI)-based flaw highlighter to produce flaw activation maps (FAMs) that identify artifacts and unrealistic regions. These FAMs improve reconstruction quality by amplifying noise in flawed regions during the forward process and by focusing on these regions during the reverse process. The proposed approach achieves up to a 27.3% improvement in Fréchet inception distance across various diffusion-based models, demonstrating consistently strong performance on diverse datasets. It also shows robust effectiveness across different tasks, including image generation, text-to-image generation, and inpainting. These results demonstrate that explainable AI techniques can extend beyond interpretability to actively contribute to image refinement. The proposed framework offers a versatile and effective approach applicable to various diffusion models and tasks, significantly advancing the field of image synthesis.",
      "pdf_url": "https://arxiv.org/pdf/2512.08774v1",
      "published": "2025-12-09T16:30:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.08774v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "A Practical Guide for Designing, Developing, and Deploying Production-Grade Agentic AI Workflows",
      "authors": [
        "Eranga Bandara",
        "Ross Gore",
        "Peter Foytik",
        "Sachin Shetty",
        "Ravi Mukkamala",
        "Abdul Rahman",
        "Xueping Liang",
        "Safdar H. Bouk",
        "Amin Hass",
        "Sachini Rajapakse",
        "Ng Wee Keong",
        "Kasun De Zoysa",
        "Aruna Withanage",
        "Nilaan Loganathan"
      ],
      "abstract": "Agentic AI marks a major shift in how autonomous systems reason, plan, and execute multi-step tasks. Unlike traditional single model prompting, agentic workflows integrate multiple specialized agents with different Large Language Models(LLMs), tool-augmented capabilities, orchestration logic, and external system interactions to form dynamic pipelines capable of autonomous decision-making and action. As adoption accelerates across industry and research, organizations face a central challenge: how to design, engineer, and operate production-grade agentic AI workflows that are reliable, observable, maintainable, and aligned with safety and governance requirements. This paper provides a practical, end-to-end guide for designing, developing, and deploying production-quality agentic AI systems. We introduce a structured engineering lifecycle encompassing workflow decomposition, multi-agent design patterns, Model Context Protocol(MCP), and tool integration, deterministic orchestration, Responsible-AI considerations, and environment-aware deployment strategies. We then present nine core best practices for engineering production-grade agentic AI workflows, including tool-first design over MCP, pure-function invocation, single-tool and single-responsibility agents, externalized prompt management, Responsible-AI-aligned model-consortium design, clean separation between workflow logic and MCP servers, containerized deployment for scalable operations, and adherence to the Keep it Simple, Stupid (KISS) principle to maintain simplicity and robustness. To demonstrate these principles in practice, we present a comprehensive case study: a multimodal news-analysis and media-generation workflow. By combining architectural guidance, operational patterns, and practical implementation insights, this paper offers a foundational reference to build robust, extensible, and production-ready agentic AI workflows.",
      "pdf_url": "https://arxiv.org/pdf/2512.08769v1",
      "published": "2025-12-09T16:23:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.08769v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Data-Driven Dynamic Parameter Learning of manipulator robots",
      "authors": [
        "Mohammed Elseiagy",
        "Tsige Tadesse Alemayoh",
        "Ranulfo Bezerra",
        "Shotaro Kojima",
        "Kazunori Ohno"
      ],
      "abstract": "Bridging the sim-to-real gap remains a fundamental challenge in robotics, as accurate dynamic parameter estimation is essential for reliable model-based control, realistic simulation, and safe deployment of manipulators. Traditional analytical approaches often fall short when faced with complex robot structures and interactions. Data-driven methods offer a promising alternative, yet conventional neural networks such as recurrent models struggle to capture long-range dependencies critical for accurate estimation. In this study, we propose a Transformer-based approach for dynamic parameter estimation, supported by an automated pipeline that generates diverse robot models and enriched trajectory data using Jacobian-derived features. The dataset consists of 8,192 robots with varied inertial and frictional properties. Leveraging attention mechanisms, our model effectively captures both temporal and spatial dependencies. Experimental results highlight the influence of sequence length, sampling rate, and architecture, with the best configuration (sequence length 64, 64 Hz, four layers, 32 heads) achieving a validation R2 of 0.8633. Mass and inertia are estimated with near-perfect accuracy, Coulomb friction with moderate-to-high accuracy, while viscous friction and distal link center-of-mass remain more challenging. These results demonstrate that combining Transformers with automated dataset generation and kinematic enrichment enables scalable, accurate dynamic parameter estimation, contributing to improved sim-to-real transfer in robotic systems",
      "pdf_url": "https://arxiv.org/pdf/2512.08767v1",
      "published": "2025-12-09T16:15:58+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.08767v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "Performance Comparison of Aerial RIS and STAR-RIS in 3D Wireless Environments",
      "authors": [
        "Dongdong Yang",
        "Bin Li",
        "Jiguang He"
      ],
      "abstract": "Reconfigurable intelligent surface (RIS) and simultaneously transmitting and reflecting RIS (STAR-RIS) have emerged as key enablers for enhancing wireless coverage and capacity in next-generation networks. When mounted on unmanned aerial vehicles (UAVs), they benefit from flexible deployment and improved line-of-sight conditions. Despite their promising potential, a comprehensive performance comparison between aerial RIS and STAR-RIS architectures has not been thoroughly investigated. This letter presents a detailed performance comparison between aerial RIS and STAR-RIS in three-dimensional wireless environments. Accurate channel models incorporating directional radiation patterns are established, and the influence of deployment altitude and orientation is thoroughly examined. To optimize the system sum-rate, we formulate joint optimization problems for both architectures and propose an efficient solution based on the weighted minimum mean square error and block coordinate descent algorithms. Simulation results reveal that STAR-RIS outperforms RIS in low-altitude scenarios due to its full-space coverage capability, whereas RIS delivers better performance near the base station at higher altitudes. The findings provide practical insights for the deployment of aerial intelligent surfaces in future 6G communication systems.",
      "pdf_url": "https://arxiv.org/pdf/2512.08755v1",
      "published": "2025-12-09T16:06:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.08755v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Towards Foundation Models with Native Multi-Agent Intelligence",
      "authors": [
        "Shuyue Hu",
        "Haoyang Yan",
        "Yiqun Zhang",
        "Yang Chen",
        "Dongzhan Zhou",
        "Lei Bai"
      ],
      "abstract": "Foundation models (FMs) are increasingly assuming the role of the \"brain\" of AI agents. While recent efforts have begun to equip FMs with native single-agent abilities -- such as GUI interaction or integrated tool use -- we argue that the next frontier is endowing FMs with native multi-agent intelligence. We identify four core capabilities of FMs in multi-agent contexts: understanding, planning, efficient communication, and adaptation. Contrary to assumptions about the spontaneous emergence of such abilities, we provide extensive empirical evidence across 41 large language models showing that strong single-agent performance alone does not automatically yield robust multi-agent intelligence. To address this gap, we outline key research directions -- spanning dataset construction, evaluation, training paradigms, and safety considerations -- for building FMs with native multi-agent intelligence.",
      "pdf_url": "https://arxiv.org/pdf/2512.08743v1",
      "published": "2025-12-09T15:51:36+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.08743v1",
      "categories": [
        "cs.AI",
        "cs.MA"
      ]
    },
    {
      "title": "Deconstructing the Dual Black Box:A Plug-and-Play Cognitive Framework for Human-AI Collaborative Enhancement and Its Implications for AI Governance",
      "authors": [
        "Yiming Lu"
      ],
      "abstract": "Currently, there exists a fundamental divide between the \"cognitive black box\" (implicit intuition) of human experts and the \"computational black box\" (untrustworthy decision-making) of artificial intelligence (AI). This paper proposes a new paradigm of \"human-AI collaborative cognitive enhancement,\" aiming to transform the dual black boxes into a composable, auditable, and extensible \"functional white-box\" system through structured \"meta-interaction.\" The core breakthrough lies in the \"plug-and-play cognitive framework\"--a computable knowledge package that can be extracted from expert dialogues and loaded into the Recursive Adversarial Meta-Thinking Network (RAMTN). This enables expert thinking, such as medical diagnostic logic and teaching intuition, to be converted into reusable and scalable public assets, realizing a paradigm shift from \"AI as a tool\" to \"AI as a thinking partner.\" This work not only provides the first engineering proof for \"cognitive equity\" but also opens up a new path for AI governance: constructing a verifiable and intervenable governance paradigm through \"transparency of interaction protocols\" rather than prying into the internal mechanisms of models. The framework is open-sourced to promote technology for good and cognitive inclusion. This paper is an independent exploratory research conducted by the author. All content presented, including the theoretical framework (RAMTN), methodology (meta-interaction), system implementation, and case validation, constitutes the author's individual research achievements.",
      "pdf_url": "https://arxiv.org/pdf/2512.08740v1",
      "published": "2025-12-09T15:50:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.08740v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Mitigating Individual Skin Tone Bias in Skin Lesion Classification through Distribution-Aware Reweighting",
      "authors": [
        "Kuniko Paxton",
        "Zeinab Dehghani",
        "Koorosh Aslansefat",
        "Dhavalkumar Thakker",
        "Yiannis Papadopoulos"
      ],
      "abstract": "Skin color has historically been a focal point of discrimination, yet fairness research in machine learning for medical imaging often relies on coarse subgroup categories, overlooking individual-level variations. Such group-based approaches risk obscuring biases faced by outliers within subgroups. This study introduces a distribution-based framework for evaluating and mitigating individual fairness in skin lesion classification. We treat skin tone as a continuous attribute rather than a categorical label, and employ kernel density estimation (KDE) to model its distribution. We further compare twelve statistical distance metrics to quantify disparities between skin tone distributions and propose a distance-based reweighting (DRW) loss function to correct underrepresentation in minority tones. Experiments across CNN and Transformer models demonstrate: (i) the limitations of categorical reweighting in capturing individual-level disparities, and (ii) the superior performance of distribution-based reweighting, particularly with Fidelity Similarity (FS), Wasserstein Distance (WD), Hellinger Metric (HM), and Harmonic Mean Similarity (HS). These findings establish a robust methodology for advancing fairness at individual level in dermatological AI systems, and highlight broader implications for sensitive continuous attributes in medical image analysis.",
      "pdf_url": "https://arxiv.org/pdf/2512.08733v1",
      "published": "2025-12-09T15:45:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.08733v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Multi-domain performance analysis with scores tailored to user preferences",
      "authors": [
        "Sébastien Piérard",
        "Adrien Deliège",
        "Marc Van Droogenbroeck"
      ],
      "abstract": "The performance of algorithms, methods, and models tends to depend heavily on the distribution of cases on which they are applied, this distribution being specific to the applicative domain. After performing an evaluation in several domains, it is highly informative to compute a (weighted) mean performance and, as shown in this paper, to scrutinize what happens during this averaging. To achieve this goal, we adopt a probabilistic framework and consider a performance as a probability measure (e.g., a normalized confusion matrix for a classification task). It appears that the corresponding weighted mean is known to be the summarization, and that only some remarkable scores assign to the summarized performance a value equal to a weighted arithmetic mean of the values assigned to the domain-specific performances. These scores include the family of ranking scores, a continuum parameterized by user preferences, and that the weights to consider in the arithmetic mean depend on the user preferences. Based on this, we rigorously define four domains, named easiest, most difficult, preponderant, and bottleneck domains, as functions of user preferences. After establishing the theory in a general setting, regardless of the task, we develop new visual tools for two-class classification.",
      "pdf_url": "https://arxiv.org/pdf/2512.08715v1",
      "published": "2025-12-09T15:29:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.08715v1",
      "categories": [
        "cs.PF",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ]
    },
    {
      "title": "Automatic Essay Scoring and Feedback Generation in Basque Language Learning",
      "authors": [
        "Ekhi Azurmendi",
        "Xabier Arregi",
        "Oier Lopez de Lacalle"
      ],
      "abstract": "This paper introduces the first publicly available dataset for Automatic Essay Scoring (AES) and feedback generation in Basque, targeting the CEFR C1 proficiency level. The dataset comprises 3,200 essays from HABE, each annotated by expert evaluators with criterion specific scores covering correctness, richness, coherence, cohesion, and task alignment enriched with detailed feedback and error examples. We fine-tune open-source models, including RoBERTa-EusCrawl and Latxa 8B/70B, for both scoring and explanation generation. Our experiments show that encoder models remain highly reliable for AES, while supervised fine-tuning (SFT) of Latxa significantly enhances performance, surpassing state-of-the-art (SoTA) closed-source systems such as GPT-5 and Claude Sonnet 4.5 in scoring consistency and feedback quality. We also propose a novel evaluation methodology for assessing feedback generation, combining automatic consistency metrics with expert-based validation of extracted learner errors. Results demonstrate that the fine-tuned Latxa model produces criterion-aligned, pedagogically meaningful feedback and identifies a wider range of error types than proprietary models. This resource and benchmark establish a foundation for transparent, reproducible, and educationally grounded NLP research in low-resource languages such as Basque.",
      "pdf_url": "https://arxiv.org/pdf/2512.08713v1",
      "published": "2025-12-09T15:28:35+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.08713v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Multi-Agent Intelligence for Multidisciplinary Decision-Making in Gastrointestinal Oncology",
      "authors": [
        "Rongzhao Zhang",
        "Junqiao Wang",
        "Shuyun Yang",
        "Mouxiao Bian",
        "Chao Ding",
        "Yuwei Bai",
        "Chihao Zhang",
        "Yuguang Shen",
        "Lei Wang",
        "Lei Zheng",
        "Qiujuan Yan",
        "Yun Zhong",
        "Meiling Liu",
        "Jiwei Yu",
        "Zheng Wang",
        "Jie Xu",
        "Meng Luo"
      ],
      "abstract": "Multimodal clinical reasoning in the field of gastrointestinal (GI) oncology necessitates the integrated interpretation of endoscopic imagery, radiological data, and biochemical markers. Despite the evident potential exhibited by Multimodal Large Language Models (MLLMs), they frequently encounter challenges such as context dilution and hallucination when confronted with intricate, heterogeneous medical histories. In order to address these limitations, a hierarchical Multi-Agent Framework is proposed, which emulates the collaborative workflow of a human Multidisciplinary Team (MDT). The system attained a composite expert evaluation score of 4.60/5.00, thereby demonstrating a substantial improvement over the monolithic baseline. It is noteworthy that the agent-based architecture yielded the most substantial enhancements in reasoning logic and medical accuracy. The findings indicate that mimetic, agent-based collaboration provides a scalable, interpretable, and clinically robust paradigm for automated decision support in oncology.",
      "pdf_url": "https://arxiv.org/pdf/2512.08674v1",
      "published": "2025-12-09T14:56:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.08674v1",
      "categories": [
        "cs.AI",
        "cs.MA"
      ]
    },
    {
      "title": "Reusability in MLOps: Leveraging Ports and Adapters to Build a Microservices Architecture for the Maritime Domain",
      "authors": [
        "Renato Cordeiro Ferreira",
        "Aditya Dhinavahi",
        "Rowanne Trapmann",
        "Willem-Jan van den Heuvel"
      ],
      "abstract": "ML-Enabled Systems (MLES) are inherently complex since they require multiple components to achieve their business goal. This experience report showcases the software architecture reusability techniques applied while building Ocean Guard, an MLES for anomaly detection in the maritime domain. In particular, it highlights the challenges and lessons learned to reuse the Ports and Adapters pattern to support building multiple microservices from a single codebase. This experience report hopes to inspire software engineers, machine learning engineers, and data scientists to apply the Hexagonal Architecture pattern to build their MLES.",
      "pdf_url": "https://arxiv.org/pdf/2512.08657v1",
      "published": "2025-12-09T14:43:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.08657v1",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Aerial Vision-Language Navigation with a Unified Framework for Spatial, Temporal and Embodied Reasoning",
      "authors": [
        "Huilin Xu",
        "Zhuoyang Liu",
        "Yixiang Luomei",
        "Feng Xu"
      ],
      "abstract": "Aerial Vision-and-Language Navigation (VLN) aims to enable unmanned aerial vehicles (UAVs) to interpret natural language instructions and navigate complex urban environments using onboard visual observation. This task holds promise for real-world applications such as low-altitude inspection, search-and-rescue, and autonomous aerial delivery. Existing methods often rely on panoramic images, depth inputs, or odometry to support spatial reasoning and action planning. These requirements increase system cost and integration complexity, thus hindering practical deployment for lightweight UAVs. We present a unified aerial VLN framework that operates solely on egocentric monocular RGB observations and natural language instructions. The model formulates navigation as a next-token prediction problem, jointly optimizing spatial perception, trajectory reasoning, and action prediction through prompt-guided multi-task learning. Moreover, we propose a keyframe selection strategy to reduce visual redundancy by retaining semantically informative frames, along with an action merging and label reweighting mechanism that mitigates long-tailed supervision imbalance and facilitates stable multi-task co-training. Extensive experiments on the Aerial VLN benchmark validate the effectiveness of our method. Under the challenging monocular RGB-only setting, our model achieves strong results across both seen and unseen environments. It significantly outperforms existing RGB-only baselines and narrows the performance gap with state-of-the-art panoramic RGB-D counterparts. Comprehensive ablation studies further demonstrate the contribution of our task design and architectural choices.",
      "pdf_url": "https://arxiv.org/pdf/2512.08639v1",
      "published": "2025-12-09T14:25:24+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.08639v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "See-Control: A Multimodal Agent Framework for Smartphone Interaction with a Robotic Arm",
      "authors": [
        "Haoyu Zhao",
        "Weizhong Ding",
        "Yuhao Yang",
        "Zheng Tian",
        "Linyi Yang",
        "Kun Shao",
        "Jun Wang"
      ],
      "abstract": "Recent advances in Multimodal Large Language Models (MLLMs) have enabled their use as intelligent agents for smartphone operation. However, existing methods depend on the Android Debug Bridge (ADB) for data transmission and action execution, limiting their applicability to Android devices. In this work, we introduce the novel Embodied Smartphone Operation (ESO) task and present See-Control, a framework that enables smartphone operation via direct physical interaction with a low-DoF robotic arm, offering a platform-agnostic solution. See-Control comprises three key components: (1) an ESO benchmark with 155 tasks and corresponding evaluation metrics; (2) an MLLM-based embodied agent that generates robotic control commands without requiring ADB or system back-end access; and (3) a richly annotated dataset of operation episodes, offering valuable resources for future research. By bridging the gap between digital agents and the physical world, See-Control provides a concrete step toward enabling home robots to perform smartphone-dependent tasks in realistic environments.",
      "pdf_url": "https://arxiv.org/pdf/2512.08629v1",
      "published": "2025-12-09T14:14:37+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.08629v1",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.HC"
      ]
    },
    {
      "title": "Protein Secondary Structure Prediction Using Transformers",
      "authors": [
        "Manzi Kevin Maxime"
      ],
      "abstract": "Predicting protein secondary structures such as alpha helices, beta sheets, and coils from amino acid sequences is essential for understanding protein function. This work presents a transformer-based model that applies attention mechanisms to protein sequence data to predict structural motifs. A sliding-window data augmentation technique is used on the CB513 dataset to expand the training samples. The transformer shows strong ability to generalize across variable-length sequences while effectively capturing both local and long-range residue interactions.",
      "pdf_url": "https://arxiv.org/pdf/2512.08613v1",
      "published": "2025-12-09T13:58:47+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.08613v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "CogMCTS: A Novel Cognitive-Guided Monte Carlo Tree Search Framework for Iterative Heuristic Evolution with Large Language Models",
      "authors": [
        "Hui Wang",
        "Yang Liu",
        "Xiaoyu Zhang",
        "Chaoxu Mu"
      ],
      "abstract": "Automatic Heuristic Design (AHD) is an effective1 framework for solving complex optimization prob-2 lems. The development of large language mod-3 els (LLMs) enables the automated generation of4 heuristics. Existing LLM-based evolutionary meth-5 ods rely on population strategies and are prone6 to local optima. Integrating LLMs with Monte7 Carlo Tree Search (MCTS) improves the trade-off8 between exploration and exploitation, but multi-9 round cognitive integration remains limited and10 search diversity is constrained. To overcome these11 limitations, this paper proposes a novel cognitive-12 guided MCTS framework (CogMCTS). CogMCTS13 tightly integrates the cognitive guidance mecha-14 nism of LLMs with MCTS to achieve efficient au-15 tomated heuristic optimization. The framework16 employs multi-round cognitive feedback to incor-17 porate historical experience, node information, and18 negative outcomes, dynamically improving heuris-19 tic generation. Dual-track node expansion com-20 bined with elite heuristic management balances the21 exploration of diverse heuristics and the exploita-22 tion of high-quality experience. In addition, strate-23 gic mutation modifies the heuristic forms and pa-24 rameters to further enhance the diversity of the so-25 lution and the overall optimization performance.26 The experimental results indicate that CogMCTS27 outperforms existing LLM-based AHD methods in28 stability, efficiency, and solution quality.",
      "pdf_url": "https://arxiv.org/pdf/2512.08609v1",
      "published": "2025-12-09T13:54:18+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.08609v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Decoupling Template Bias in CLIP: Harnessing Empty Prompts for Enhanced Few-Shot Learning",
      "authors": [
        "Zhenyu Zhang",
        "Guangyao Chen",
        "Yixiong Zou",
        "Zhimeng Huang",
        "Yuhua Li"
      ],
      "abstract": "The Contrastive Language-Image Pre-Training (CLIP) model excels in few-shot learning by aligning visual and textual representations. Our study shows that template-sample similarity (TSS), defined as the resemblance between a text template and an image sample, introduces bias. This bias leads the model to rely on template proximity rather than true sample-to-category alignment, reducing both accuracy and robustness in classification. We present a framework that uses empty prompts, textual inputs that convey the idea of \"emptiness\" without category information. These prompts capture unbiased template features and offset TSS bias. The framework employs two stages. During pre-training, empty prompts reveal and reduce template-induced bias within the CLIP encoder. During few-shot fine-tuning, a bias calibration loss enforces correct alignment between images and their categories, ensuring the model focuses on relevant visual cues. Experiments across multiple benchmarks demonstrate that our template correction method significantly reduces performance fluctuations caused by TSS, yielding higher classification accuracy and stronger robustness. The repository of this project is available at https://github.com/zhenyuZ-HUST/Decoupling-Template-Bias-in-CLIP.",
      "pdf_url": "https://arxiv.org/pdf/2512.08606v1",
      "published": "2025-12-09T13:51:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.08606v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Examining Student Interactions with a Pedagogical AI-Assistant for Essay Writing and their Impact on Students Writing Quality",
      "authors": [
        "Wicaksono Febriantoro",
        "Qi Zhou",
        "Wannapon Suraworachet",
        "Sahan Bulathwela",
        "Andrea Gauthier",
        "Eva Millan",
        "Mutlu Cukurova"
      ],
      "abstract": "The dynamic nature of interactions between students and GenAI, as well as their relationship to writing quality, remains underexplored. While most research has examined how general-purpose GenAI can support writing, fewer studies have investigated how students interact with pedagogically designed systems across different phases of the writing process. To address this gap, we evaluated a GenAI-driven essay-writing assistant (EWA) designed to support higher education students in argumentative writing. Drawing on 1,282 interaction logs from 32 undergraduates during a two-hour writing session, Sequential Pattern Mining and K-Means clustering were used to identify behavioral patterns. Two clusters emerged: Cluster 1 emphasized outline planning and essay structure, while Cluster 2 focused on content development. A Mann-Whitney U test revealed a moderate effect size (r = 0.36) in the essay Organization dimension, with Cluster 1 showing higher scores. Qualitative analysis indicated that students with better performance actively wrote and shared essay sections with EWA for feedback, rather than interacted passively by asking questions. These findings suggest implications for teaching and system design. Teachers can encourage active engagement, while future EWAs may integrate automatic labeling and monitoring to prompt students to move from questioning to writing, enabling fuller benefits from GenAI-supported learning.",
      "pdf_url": "https://arxiv.org/pdf/2512.08596v1",
      "published": "2025-12-09T13:34:33+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.08596v1",
      "categories": [
        "cs.CY",
        "cs.AI"
      ]
    },
    {
      "title": "The SMART+ Framework for AI Systems",
      "authors": [
        "Laxmiraju Kandikatla",
        "Branislav Radeljic"
      ],
      "abstract": "Artificial Intelligence (AI) systems are now an integral part of multiple industries. In clinical research, AI supports automated adverse event detection in clinical trials, patient eligibility screening for protocol enrollment, and data quality validation. Beyond healthcare, AI is transforming finance through real-time fraud detection, automated loan risk assessment, and algorithmic decision-making. Similarly, in manufacturing, AI enables predictive maintenance to reduce equipment downtime, enhances quality control through computer-vision inspection, and optimizes production workflows using real-time operational data. While these technologies enhance operational efficiency, they introduce new challenges regarding safety, accountability, and regulatory compliance. To address these concerns, we introduce the SMART+ Framework - a structured model built on the pillars of Safety, Monitoring, Accountability, Reliability, and Transparency, and further enhanced with Privacy & Security, Data Governance, Fairness & Bias, and Guardrails. SMART+ offers a practical, comprehensive approach to evaluating and governing AI systems across industries. This framework aligns with evolving mechanisms and regulatory guidance to integrate operational safeguards, oversight procedures, and strengthened privacy and governance controls. SMART+ demonstrates risk mitigation, trust-building, and compliance readiness. By enabling responsible AI adoption and ensuring auditability, SMART+ provides a robust foundation for effective AI governance in clinical research.",
      "pdf_url": "https://arxiv.org/pdf/2512.08592v1",
      "published": "2025-12-09T13:33:14+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.08592v1",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.HC",
        "eess.SY"
      ]
    },
    {
      "title": "Mind to Hand: Purposeful Robotic Control via Embodied Reasoning",
      "authors": [
        "Peijun Tang",
        "Shangjin Xie",
        "Binyan Sun",
        "Baifu Huang",
        "Kuncheng Luo",
        "Haotian Yang",
        "Weiqi Jin",
        "Jianan Wang"
      ],
      "abstract": "Humans act with context and intention, with reasoning playing a central role. While internet-scale data has enabled broad reasoning capabilities in AI systems, grounding these abilities in physical action remains a major challenge. We introduce Lumo-1, a generalist vision-language-action (VLA) model that unifies robot reasoning (\"mind\") with robot action (\"hand\"). Our approach builds upon the general multi-modal reasoning capabilities of pre-trained vision-language models (VLMs), progressively extending them to embodied reasoning and action prediction, and ultimately towards structured reasoning and reasoning-action alignment. This results in a three-stage pre-training pipeline: (1) Continued VLM pre-training on curated vision-language data to enhance embodied reasoning skills such as planning, spatial understanding, and trajectory prediction; (2) Co-training on cross-embodiment robot data alongside vision-language data; and (3) Action training with reasoning process on trajectories collected on Astribot S1, a bimanual mobile manipulator with human-like dexterity and agility. Finally, we integrate reinforcement learning to further refine reasoning-action consistency and close the loop between semantic inference and motor control. Extensive experiments demonstrate that Lumo-1 achieves significant performance improvements in embodied vision-language reasoning, a critical component for generalist robotic control. Real-world evaluations further show that Lumo-1 surpasses strong baselines across a wide range of challenging robotic tasks, with strong generalization to novel objects and environments, excelling particularly in long-horizon tasks and responding to human-natural instructions that require reasoning over strategy, concepts and space.",
      "pdf_url": "https://arxiv.org/pdf/2512.08580v1",
      "published": "2025-12-09T13:19:37+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.08580v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "Disturbance-Free Surgical Video Generation from Multi-Camera Shadowless Lamps for Open Surgery",
      "authors": [
        "Yuna Kato",
        "Shohei Mori",
        "Hideo Saito",
        "Yoshifumi Takatsume",
        "Hiroki Kajita",
        "Mariko Isogawa"
      ],
      "abstract": "Video recordings of open surgeries are greatly required for education and research purposes. However, capturing unobstructed videos is challenging since surgeons frequently block the camera field of view. To avoid occlusion, the positions and angles of the camera must be frequently adjusted, which is highly labor-intensive. Prior work has addressed this issue by installing multiple cameras on a shadowless lamp and arranging them to fully surround the surgical area. This setup increases the chances of some cameras capturing an unobstructed view. However, manual image alignment is needed in post-processing since camera configurations change every time surgeons move the lamp for optimal lighting. This paper aims to fully automate this alignment task. The proposed method identifies frames in which the lighting system moves, realigns them, and selects the camera with the least occlusion to generate a video that consistently presents the surgical field from a fixed perspective. A user study involving surgeons demonstrated that videos generated by our method were superior to those produced by conventional methods in terms of the ease of confirming the surgical area and the comfort during video viewing. Additionally, our approach showed improvements in video quality over existing techniques. Furthermore, we implemented several synthesis options for the proposed view-synthesis method and conducted a user study to assess surgeons' preferences for each option.",
      "pdf_url": "https://arxiv.org/pdf/2512.08577v1",
      "published": "2025-12-09T13:15:32+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.08577v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ]
    },
    {
      "title": "A Hybrid Model for Stock Market Forecasting: Integrating News Sentiment and Time Series Data with Graph Neural Networks",
      "authors": [
        "Nader Sadek",
        "Mirette Moawad",
        "Christina Naguib",
        "Mariam Elzahaby"
      ],
      "abstract": "Stock market prediction is a long-standing challenge in finance, as accurate forecasts support informed investment decisions. Traditional models rely mainly on historical prices, but recent work shows that financial news can provide useful external signals. This paper investigates a multimodal approach that integrates companies' news articles with their historical stock data to improve prediction performance. We compare a Graph Neural Network (GNN) model with a baseline LSTM model. Historical data for each company is encoded using an LSTM, while news titles are embedded with a language model. These embeddings form nodes in a heterogeneous graph, and GraphSAGE is used to capture interactions between articles, companies, and industries. We evaluate two targets: a binary direction-of-change label and a significance-based label. Experiments on the US equities and Bloomberg datasets show that the GNN outperforms the LSTM baseline, achieving 53% accuracy on the first target and a 4% precision gain on the second. Results also indicate that companies with more associated news yield higher prediction accuracy. Moreover, headlines contain stronger predictive signals than full articles, suggesting that concise news summaries play an important role in short-term market reactions.",
      "pdf_url": "https://arxiv.org/pdf/2512.08567v1",
      "published": "2025-12-09T13:05:54+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.08567v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Bridging Scale Discrepancies in Robotic Control via Language-Based Action Representations",
      "authors": [
        "Yuchi Zhang",
        "Churui Sun",
        "Shiqi Liang",
        "Diyuan Liu",
        "Chao Ji",
        "Wei-Nan Zhang",
        "Ting Liu"
      ],
      "abstract": "Recent end-to-end robotic manipulation research increasingly adopts architectures inspired by large language models to enable robust manipulation. However, a critical challenge arises from severe distribution shifts between robotic action data, primarily due to substantial numerical variations in action commands across diverse robotic platforms and tasks, hindering the effective transfer of pretrained knowledge. To address this limitation, we propose a semantically grounded linguistic representation to normalize actions for efficient pretraining. Unlike conventional discretized action representations that are sensitive to numerical scales, the motion representation specifically disregards numeric scale effects, emphasizing directionality instead. This abstraction mitigates distribution shifts, yielding a more generalizable pretraining representation. Moreover, using the motion representation narrows the feature distance between action tokens and standard vocabulary tokens, mitigating modality gaps. Multi-task experiments on two benchmarks demonstrate that the proposed method significantly improves generalization performance and transferability in robotic manipulation tasks.",
      "pdf_url": "https://arxiv.org/pdf/2512.08548v1",
      "published": "2025-12-09T12:45:12+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.08548v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "Curriculum Guided Massive Multi Agent System Solving For Robust Long Horizon Tasks",
      "authors": [
        "Indrajit Kar",
        "Kalathur Chenchu Kishore Kumar"
      ],
      "abstract": "Large Language Models and multi-agent systems have shown promise in decomposing complex tasks, yet they struggle with long-horizon reasoning tasks and escalating computation cost. This work introduces a hierarchical multi-agent architecture that distributes reasoning across a 64*64 grid of lightweight agents, supported by a selective oracle. A spatial curriculum progressively expands the operational region of the grid, ensuring that agents master easier central tasks before tackling harder peripheral ones. To improve reliability, the system integrates Negative Log-Likelihood as a measure of confidence, allowing the curriculum to prioritize regions where agents are both accurate and well calibrated. A Thompson Sampling curriculum manager adaptively chooses training zones based on competence and NLL-driven reward signals. We evaluate the approach on a spatially grounded Tower of Hanoi benchmark, which mirrors the long-horizon structure of many robotic manipulation and planning tasks. Results demonstrate improved stability, reduced oracle usage, and stronger long-range reasoning from distributed agent cooperation.",
      "pdf_url": "https://arxiv.org/pdf/2512.08545v1",
      "published": "2025-12-09T12:40:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.08545v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.MA"
      ]
    },
    {
      "title": "A Novel Wasserstein Quaternion Generative Adversarial Network for Color Image Generation",
      "authors": [
        "Zhigang Jia",
        "Duan Wang",
        "Hengkai Wang",
        "Yajun Xie",
        "Meixiang Zhao",
        "Xiaoyu Zhao"
      ],
      "abstract": "Color image generation has a wide range of applications, but the existing generation models ignore the correlation among color channels, which may lead to chromatic aberration problems. In addition, the data distribution problem of color images has not been systematically elaborated and explained, so that there is still the lack of the theory about measuring different color images datasets. In this paper, we define a new quaternion Wasserstein distance and develop its dual theory. To deal with the quaternion linear programming problem, we derive the strong duality form with helps of quaternion convex set separation theorem and quaternion Farkas lemma. With using quaternion Wasserstein distance, we propose a novel Wasserstein quaternion generative adversarial network. Experiments demonstrate that this novel model surpasses both the (quaternion) generative adversarial networks and the Wasserstein generative adversarial network in terms of generation efficiency and image quality.",
      "pdf_url": "https://arxiv.org/pdf/2512.08542v1",
      "published": "2025-12-09T12:39:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.08542v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "math.NA"
      ]
    },
    {
      "title": "Principles2Plan: LLM-Guided System for Operationalising Ethical Principles into Plans",
      "authors": [
        "Tammy Zhong",
        "Yang Song",
        "Maurice Pagnucco"
      ],
      "abstract": "Ethical awareness is critical for robots operating in human environments, yet existing automated planning tools provide little support. Manually specifying ethical rules is labour-intensive and highly context-specific. We present Principles2Plan, an interactive research prototype demonstrating how a human and a Large Language Model (LLM) can collaborate to produce context-sensitive ethical rules and guide automated planning. A domain expert provides the planning domain, problem details, and relevant high-level principles such as beneficence and privacy. The system generates operationalisable ethical rules consistent with these principles, which the user can review, prioritise, and supply to a planner to produce ethically-informed plans. To our knowledge, no prior system supports users in generating principle-grounded rules for classical planning contexts. Principles2Plan showcases the potential of human-LLM collaboration for making ethical automated planning more practical and feasible.",
      "pdf_url": "https://arxiv.org/pdf/2512.08536v1",
      "published": "2025-12-09T12:34:54+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.08536v1",
      "categories": [
        "cs.AI"
      ]
    }
  ]
}