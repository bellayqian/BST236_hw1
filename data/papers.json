{
  "last_updated": "2025-07-15T00:57:18.394695",
  "papers": [
    {
      "title": "Lumos-1: On Autoregressive Video Generation from a Unified Model Perspective",
      "authors": [
        "Hangjie Yuan",
        "Weihua Chen",
        "Jun Cen",
        "Hu Yu",
        "Jingyun Liang",
        "Shuning Chang",
        "Zhihui Lin",
        "Tao Feng",
        "Pengwei Liu",
        "Jiazheng Xing",
        "Hao Luo",
        "Jiasheng Tang",
        "Fan Wang",
        "Yi Yang"
      ],
      "abstract": "Autoregressive large language models (LLMs) have unified a vast range of\nlanguage tasks, inspiring preliminary efforts in autoregressive video\ngeneration. Existing autoregressive video generators either diverge from\nstandard LLM architectures, depend on bulky external text encoders, or incur\nprohibitive latency due to next-token decoding. In this paper, we introduce\nLumos-1, an autoregressive video generator that retains the LLM architecture\nwith minimal architectural modifications. To inject spatiotemporal correlations\nin LLMs, we identify the efficacy of incorporating 3D RoPE and diagnose its\nimbalanced frequency spectrum ranges. Therefore, we propose MM-RoPE, a RoPE\nscheme that preserves the original textual RoPE while providing comprehensive\nfrequency spectra and scaled 3D positions for modeling multimodal\nspatiotemporal data. Moreover, Lumos-1 resorts to a token dependency strategy\nthat obeys intra-frame bidirectionality and inter-frame temporal causality.\nBased on this dependency strategy, we identify the issue of frame-wise loss\nimbalance caused by spatial information redundancy and solve it by proposing\nAutoregressive Discrete Diffusion Forcing (AR-DF). AR-DF introduces temporal\ntube masking during training with a compatible inference-time masking policy to\navoid quality degradation. By using memory-efficient training techniques, we\npre-train Lumos-1 on only 48 GPUs, achieving performance comparable to EMU3 on\nGenEval, COSMOS-Video2World on VBench-I2V, and OpenSoraPlan on VBench-T2V. Code\nand models are available at https://github.com/alibaba-damo-academy/Lumos.",
      "pdf_url": "http://arxiv.org/pdf/2507.08801v1",
      "published": "2025-07-11T17:59:42+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.08801v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ]
    },
    {
      "title": "NeuralOS: Towards Simulating Operating Systems via Neural Generative Models",
      "authors": [
        "Luke Rivard",
        "Sun Sun",
        "Hongyu Guo",
        "Wenhu Chen",
        "Yuntian Deng"
      ],
      "abstract": "We introduce NeuralOS, a neural framework that simulates graphical user\ninterfaces (GUIs) of operating systems by directly predicting screen frames in\nresponse to user inputs such as mouse movements, clicks, and keyboard events.\nNeuralOS combines a recurrent neural network (RNN), which tracks computer\nstate, with a diffusion-based neural renderer that generates screen images. The\nmodel is trained on a large-scale dataset of Ubuntu XFCE recordings, which\ninclude both randomly generated interactions and realistic interactions\nproduced by AI agents. Experiments show that NeuralOS successfully renders\nrealistic GUI sequences, accurately captures mouse interactions, and reliably\npredicts state transitions like application launches. Although modeling\nfine-grained keyboard interactions precisely remains challenging, NeuralOS\noffers a step toward creating fully adaptive, generative neural interfaces for\nfuture human-computer interaction systems.",
      "pdf_url": "http://arxiv.org/pdf/2507.08800v1",
      "published": "2025-07-11T17:59:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.08800v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "cs.LG"
      ]
    },
    {
      "title": "KV Cache Steering for Inducing Reasoning in Small Language Models",
      "authors": [
        "Max Belitsky",
        "Dawid J. Kopiczko",
        "Michael Dorkenwald",
        "M. Jehanzeb Mirza",
        "Cees G. M. Snoek",
        "Yuki M. Asano"
      ],
      "abstract": "We propose cache steering, a lightweight method for implicit steering of\nlanguage models via a one-shot intervention applied directly to the key-value\ncache. To validate its effectiveness, we apply cache steering to induce\nchain-of-thought reasoning in small language models. Our approach leverages\nGPT-4o-generated reasoning traces to construct steering vectors that shift\nmodel behavior toward more explicit, multi-step reasoning without fine-tuning\nor prompt modifications. Experimental evaluations on diverse reasoning\nbenchmarks demonstrate that cache steering improves both the qualitative\nstructure of model reasoning and quantitative task performance. Compared to\nprior activation steering techniques that require continuous interventions, our\none-shot cache steering offers substantial advantages in terms of\nhyperparameter stability, inference-time efficiency, and ease of integration,\nmaking it a more robust and practical solution for controlled generation.",
      "pdf_url": "http://arxiv.org/pdf/2507.08799v1",
      "published": "2025-07-11T17:59:36+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.08799v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Optimistic Exploration for Risk-Averse Constrained Reinforcement Learning",
      "authors": [
        "James McCarthy",
        "Radu Marinescu",
        "Elizabeth Daly",
        "Ivana Dusparic"
      ],
      "abstract": "Risk-averse Constrained Reinforcement Learning (RaCRL) aims to learn policies\nthat minimise the likelihood of rare and catastrophic constraint violations\ncaused by an environment's inherent randomness. In general, risk-aversion leads\nto conservative exploration of the environment which typically results in\nconverging to sub-optimal policies that fail to adequately maximise reward or,\nin some cases, fail to achieve the goal. In this paper, we propose an\nexploration-based approach for RaCRL called Optimistic Risk-averse Actor Critic\n(ORAC), which constructs an exploratory policy by maximising a local upper\nconfidence bound of the state-action reward value function whilst minimising a\nlocal lower confidence bound of the risk-averse state-action cost value\nfunction. Specifically, at each step, the weighting assigned to the cost value\nis increased or decreased if it exceeds or falls below the safety constraint\nvalue. This way the policy is encouraged to explore uncertain regions of the\nenvironment to discover high reward states whilst still satisfying the safety\nconstraints. Our experimental results demonstrate that the ORAC approach\nprevents convergence to sub-optimal policies and improves significantly the\nreward-cost trade-off in various continuous control tasks such as\nSafety-Gymnasium and a complex building energy management environment\nCityLearn.",
      "pdf_url": "http://arxiv.org/pdf/2507.08793v1",
      "published": "2025-07-11T17:54:54+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.08793v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "On Barriers to Archival Audio Processing",
      "authors": [
        "Peter Sullivan",
        "Muhammad Abdul-Mageed"
      ],
      "abstract": "In this study, we leverage a unique UNESCO collection of mid-20th century\nradio recordings to probe the robustness of modern off-the-shelf language\nidentification (LID) and speaker recognition (SR) methods, especially with\nrespect to the impact of multilingual speakers and cross-age recordings. Our\nfindings suggest that LID systems, such as Whisper, are increasingly adept at\nhandling second-language and accented speech. However, speaker embeddings\nremain a fragile component of speech processing pipelines that is prone to\nbiases related to the channel, age, and language. Issues which will need to be\novercome should archives aim to employ SR methods for speaker indexing.",
      "pdf_url": "http://arxiv.org/pdf/2507.08768v1",
      "published": "2025-07-11T17:27:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.08768v1",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "eess.AS"
      ]
    },
    {
      "title": "A Hybrid Multi-Well Hopfield-CNN with Feature Extraction and K-Means for MNIST Classification",
      "authors": [
        "Ahmed Farooq"
      ],
      "abstract": "This study presents a hybrid model for classifying handwritten digits in the\nMNIST dataset, combining convolutional neural networks (CNNs) with a multi-well\nHopfield network. The approach employs a CNN to extract high-dimensional\nfeatures from input images, which are then clustered into class-specific\nprototypes using k-means clustering. These prototypes serve as attractors in a\nmulti-well energy landscape, where a Hopfield network performs classification\nby minimizing an energy function that balances feature similarity and class\nassignment.The model's design enables robust handling of intraclass\nvariability, such as diverse handwriting styles, while providing an\ninterpretable framework through its energy-based decision process. Through\nsystematic optimization of the CNN architecture and the number of wells, the\nmodel achieves a high test accuracy of 99.2% on 10,000 MNIST images,\ndemonstrating its effectiveness for image classification tasks. The findings\nhighlight the critical role of deep feature extraction and sufficient prototype\ncoverage in achieving high performance, with potential for broader applications\nin pattern recognition.",
      "pdf_url": "http://arxiv.org/pdf/2507.08766v1",
      "published": "2025-07-11T17:26:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.08766v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Compress Any Segment Anything Model (SAM)",
      "authors": [
        "Juntong Fan",
        "Zhiwei Hao",
        "Jianqiang Shen",
        "Shang-Ling Jui",
        "Yi Zhang",
        "Jing-Xiao Liao",
        "Feng-Lei Fan"
      ],
      "abstract": "Due to the excellent performance in yielding high-quality, zero-shot\nsegmentation, Segment Anything Model (SAM) and its variants have been widely\napplied in diverse scenarios such as healthcare and intelligent manufacturing.\nTherefore, effectively compressing SAMs has become an increasingly pressing\npractical need. In this study, we propose Birkhoff, a novel data-free\ncompression algorithm for SAM and its variants. Unlike quantization, pruning,\ndistillation, and other compression methods, Birkhoff embodies versatility\nacross model types, agility in deployment, faithfulness to the original model,\nand compactness in model size. Specifically, Birkhoff introduces a novel\ncompression algorithm: Hyper-Compression, whose core principle is to find a\ndense trajectory to turn a high-dimensional parameter vector into a\nlow-dimensional scalar. Furthermore, Birkhoff designs a dedicated linear layer\noperator, HyperLinear, to fuse decompression and matrix multiplication to\nsignificantly accelerate inference of the compressed SAMs. Extensive\nexperiments on 18 SAMs in the COCO, LVIS, and SA-1B datasets show that Birkhoff\nperforms consistently and competitively in compression time, compression ratio,\npost-compression performance, and inference speed. For example, Birkhoff can\nachieve a compression ratio of 5.17x on SAM2-B, with less than 1% performance\ndrop without using any fine-tuning data. Moreover, the compression is finished\nwithin 60 seconds for all models.",
      "pdf_url": "http://arxiv.org/pdf/2507.08765v1",
      "published": "2025-07-11T17:21:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.08765v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Penalizing Infeasible Actions and Reward Scaling in Reinforcement Learning with Offline Data",
      "authors": [
        "Jeonghye Kim",
        "Yongjae Shin",
        "Whiyoung Jung",
        "Sunghoon Hong",
        "Deunsol Yoon",
        "Youngchul Sung",
        "Kanghoon Lee",
        "Woohyung Lim"
      ],
      "abstract": "Reinforcement learning with offline data suffers from Q-value extrapolation\nerrors. To address this issue, we first demonstrate that linear extrapolation\nof the Q-function beyond the data range is particularly problematic. To\nmitigate this, we propose guiding the gradual decrease of Q-values outside the\ndata range, which is achieved through reward scaling with layer normalization\n(RS-LN) and a penalization mechanism for infeasible actions (PA). By combining\nRS-LN and PA, we develop a new algorithm called PARS. We evaluate PARS across a\nrange of tasks, demonstrating superior performance compared to state-of-the-art\nalgorithms in both offline training and online fine-tuning on the D4RL\nbenchmark, with notable success in the challenging AntMaze Ultra task.",
      "pdf_url": "http://arxiv.org/pdf/2507.08761v1",
      "published": "2025-07-11T17:16:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.08761v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Geo-ORBIT: A Federated Digital Twin Framework for Scene-Adaptive Lane Geometry Detection",
      "authors": [
        "Rei Tamaru",
        "Pei Li",
        "Bin Ran"
      ],
      "abstract": "Digital Twins (DT) have the potential to transform traffic management and\noperations by creating dynamic, virtual representations of transportation\nsystems that sense conditions, analyze operations, and support decision-making.\nA key component for DT of the transportation system is dynamic roadway geometry\nsensing. However, existing approaches often rely on static maps or costly\nsensors, limiting scalability and adaptability. Additionally, large-scale DTs\nthat collect and analyze data from multiple sources face challenges in privacy,\ncommunication, and computational efficiency. To address these challenges, we\nintroduce Geo-ORBIT (Geometrical Operational Roadway Blueprint with Integrated\nTwin), a unified framework that combines real-time lane detection, DT\nsynchronization, and federated meta-learning. At the core of Geo-ORBIT is\nGeoLane, a lightweight lane detection model that learns lane geometries from\nvehicle trajectory data using roadside cameras. We extend this model through\nMeta-GeoLane, which learns to personalize detection parameters for local\nentities, and FedMeta-GeoLane, a federated learning strategy that ensures\nscalable and privacy-preserving adaptation across roadside deployments. Our\nsystem is integrated with CARLA and SUMO to create a high-fidelity DT that\nrenders highway scenarios and captures traffic flows in real-time. Extensive\nexperiments across diverse urban scenes show that FedMeta-GeoLane consistently\noutperforms baseline and meta-learning approaches, achieving lower geometric\nerror and stronger generalization to unseen locations while drastically\nreducing communication overhead. This work lays the foundation for flexible,\ncontext-aware infrastructure modeling in DTs. The framework is publicly\navailable at https://github.com/raynbowy23/FedMeta-GeoLane.git.",
      "pdf_url": "http://arxiv.org/pdf/2507.08743v1",
      "published": "2025-07-11T16:45:59+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.08743v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Adaptive Nonlinear Vector Autoregression: Robust Forecasting for Noisy Chaotic Time Series",
      "authors": [
        "Azimov Sherkhon",
        "Susana Lopez-Moreno",
        "Eric Dolores-Cuenca",
        "Sieun Lee",
        "Sangil Kim"
      ],
      "abstract": "Nonlinear vector autoregression (NVAR) and reservoir computing (RC) have\nshown promise in forecasting chaotic dynamical systems, such as the Lorenz-63\nmodel and El Nino-Southern Oscillation. However, their reliance on fixed\nnonlinearities - polynomial expansions in NVAR or random feature maps in RC -\nlimits their adaptability to high noise or real-world data. These methods also\nscale poorly in high-dimensional settings due to costly matrix inversion during\nreadout computation. We propose an adaptive NVAR model that combines\ndelay-embedded linear inputs with features generated by a shallow, learnable\nmulti-layer perceptron (MLP). The MLP and linear readout are jointly trained\nusing gradient-based optimization, enabling the model to learn data-driven\nnonlinearities while preserving a simple readout structure. Unlike standard\nNVAR, our approach avoids the need for an exhaustive and sensitive grid search\nover ridge and delay parameters. Instead, tuning is restricted to neural\nnetwork hyperparameters, improving scalability. Initial experiments on chaotic\nsystems tested under noise-free and synthetically noisy conditions showed that\nthe adaptive model outperformed the standard NVAR in predictive accuracy and\nshowed robust forecasting under noisy conditions with a lower observation\nfrequency.",
      "pdf_url": "http://arxiv.org/pdf/2507.08738v1",
      "published": "2025-07-11T16:40:10+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.08738v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.DS",
        "68T07, 37M10, 00A79, 37M22, 65P20"
      ]
    },
    {
      "title": "Catastrophic Forgetting Mitigation Through Plateau Phase Activity Profiling",
      "authors": [
        "Idan Mashiach",
        "Oren Glickman",
        "Tom Tirer"
      ],
      "abstract": "Catastrophic forgetting in deep neural networks occurs when learning new\ntasks degrades performance on previously learned tasks due to knowledge\noverwriting. Among the approaches to mitigate this issue, regularization\ntechniques aim to identify and constrain \"important\" parameters to preserve\nprevious knowledge. In the highly nonconvex optimization landscape of deep\nlearning, we propose a novel perspective: tracking parameters during the final\ntraining plateau is more effective than monitoring them throughout the entire\ntraining process. We argue that parameters that exhibit higher activity\n(movement and variability) during this plateau reveal directions in the loss\nlandscape that are relatively flat, making them suitable for adaptation to new\ntasks while preserving knowledge from previous ones. Our comprehensive\nexperiments demonstrate that this approach achieves superior performance in\nbalancing catastrophic forgetting mitigation with strong performance on newly\nlearned tasks.",
      "pdf_url": "http://arxiv.org/pdf/2507.08736v1",
      "published": "2025-07-11T16:38:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.08736v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Dually Hierarchical Drift Adaptation for Online Configuration Performance Learning",
      "authors": [
        "Zezhen Xiang",
        "Jingzhi Gong",
        "Tao Chen"
      ],
      "abstract": "Modern configurable software systems need to learn models that correlate\nconfiguration and performance. However, when the system operates in dynamic\nenvironments, the workload variations, hardware changes, and system updates\nwill inevitably introduce concept drifts at different levels - global drifts,\nwhich reshape the performance landscape of the entire configuration space; and\nlocal drifts, which only affect certain sub-regions of that space. As such,\nexisting offline and transfer learning approaches can struggle to adapt to\nthese implicit and unpredictable changes in real-time, rendering configuration\nperformance learning challenging. To address this, we propose DHDA, an online\nconfiguration performance learning framework designed to capture and adapt to\nthese drifts at different levels. The key idea is that DHDA adapts to both the\nlocal and global drifts using dually hierarchical adaptation: at the upper\nlevel, we redivide the data into different divisions, within each of which the\nlocal model is retrained, to handle global drifts only when necessary. At the\nlower level, the local models of the divisions can detect local drifts and\nadapt themselves asynchronously. To balance responsiveness and efficiency, DHDA\ncombines incremental updates with periodic full retraining to minimize\nredundant computation when no drifts are detected. Through evaluating eight\nsoftware systems and against state-of-the-art approaches, we show that DHDA\nachieves considerably better accuracy and can effectively adapt to drifts with\nup to 2x improvements, while incurring reasonable overhead and is able to\nimprove different local models in handling concept drift.",
      "pdf_url": "http://arxiv.org/pdf/2507.08730v1",
      "published": "2025-07-11T16:31:42+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.08730v1",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "Monitoring Risks in Test-Time Adaptation",
      "authors": [
        "Mona Schirmer",
        "Metod Jazbec",
        "Christian A. Naesseth",
        "Eric Nalisnick"
      ],
      "abstract": "Encountering shifted data at test time is a ubiquitous challenge when\ndeploying predictive models. Test-time adaptation (TTA) methods address this\nissue by continuously adapting a deployed model using only unlabeled test data.\nWhile TTA can extend the model's lifespan, it is only a temporary solution.\nEventually the model might degrade to the point that it must be taken offline\nand retrained. To detect such points of ultimate failure, we propose pairing\nTTA with risk monitoring frameworks that track predictive performance and raise\nalerts when predefined performance criteria are violated. Specifically, we\nextend existing monitoring tools based on sequential testing with confidence\nsequences to accommodate scenarios in which the model is updated at test time\nand no test labels are available to estimate the performance metrics of\ninterest. Our extensions unlock the application of rigorous statistical risk\nmonitoring to TTA, and we demonstrate the effectiveness of our proposed TTA\nmonitoring framework across a representative set of datasets, distribution\nshift types, and TTA methods.",
      "pdf_url": "http://arxiv.org/pdf/2507.08721v1",
      "published": "2025-07-11T16:21:33+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.08721v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ]
    },
    {
      "title": "Multilingual Multimodal Software Developer for Code Generation",
      "authors": [
        "Linzheng Chai",
        "Jian Yang",
        "Shukai Liu",
        "Wei Zhang",
        "Liran Wang",
        "Ke Jin",
        "Tao Sun",
        "Congnan Liu",
        "Chenchen Zhang",
        "Hualei Zhu",
        "Jiaheng Liu",
        "Xianjie Wu",
        "Ge Zhang",
        "Tianyu Liu",
        "Zhoujun Li"
      ],
      "abstract": "The rapid advancement of Large Language Models (LLMs) has significantly\nimproved code generation, yet most models remain text-only, neglecting crucial\nvisual aids like diagrams and flowcharts used in real-world software\ndevelopment. To bridge this gap, we introduce MM-Coder, a Multilingual\nMultimodal software developer. MM-Coder integrates visual design inputs-Unified\nModeling Language (UML) diagrams and flowcharts (termed Visual Workflow)-with\ntextual instructions to enhance code generation accuracy and architectural\nalignment. To enable this, we developed MMc-Instruct, a diverse multimodal\ninstruction-tuning dataset including visual-workflow-based code generation,\nallowing MM-Coder to synthesize textual and graphical information like human\ndevelopers, distinct from prior work on narrow tasks. Furthermore, we introduce\nMMEval, a new benchmark for evaluating multimodal code generation, addressing\nexisting text-only limitations. Our evaluations using MMEval highlight\nsignificant remaining challenges for models in precise visual information\ncapture, instruction following, and advanced programming knowledge. Our work\naims to revolutionize industrial programming by enabling LLMs to interpret and\nimplement complex specifications conveyed through both text and visual designs.",
      "pdf_url": "http://arxiv.org/pdf/2507.08719v1",
      "published": "2025-07-11T16:19:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.08719v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SE"
      ]
    },
    {
      "title": "System-of-systems Modeling and Optimization: An Integrated Framework for Intermodal Mobility",
      "authors": [
        "Paul Saves",
        "Jasper Bussemaker",
        "Rémi Lafage",
        "Thierry Lefebvre",
        "Nathalie Bartoli",
        "Youssef Diouane",
        "Joseph Morlier"
      ],
      "abstract": "For developing innovative systems architectures, modeling and optimization\ntechniques have been central to frame the architecting process and define the\noptimization and modeling problems. In this context, for system-of-systems the\nuse of efficient dedicated approaches (often physics-based simulations) is\nhighly recommended to reduce the computational complexity of the targeted\napplications. However, exploring novel architectures using such dedicated\napproaches might pose challenges for optimization algorithms, including\nincreased evaluation costs and potential failures. To address these challenges,\nsurrogate-based optimization algorithms, such as Bayesian optimization\nutilizing Gaussian process models have emerged.",
      "pdf_url": "http://arxiv.org/pdf/2507.08715v1",
      "published": "2025-07-11T16:15:41+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.08715v1",
      "categories": [
        "cs.AI",
        "cs.SY",
        "eess.SY",
        "math.OC"
      ]
    },
    {
      "title": "elsciRL: Integrating Language Solutions into Reinforcement Learning Problem Settings",
      "authors": [
        "Philip Osborne",
        "Danilo S. Carvalho",
        "André Freitas"
      ],
      "abstract": "We present elsciRL, an open-source Python library to facilitate the\napplication of language solutions on reinforcement learning problems. We\ndemonstrate the potential of our software by extending the Language Adapter\nwith Self-Completing Instruction framework defined in (Osborne, 2024) with the\nuse of LLMs. Our approach can be re-applied to new applications with minimal\nsetup requirements. We provide a novel GUI that allows a user to provide text\ninput for an LLM to generate instructions which it can then self-complete.\nEmpirical results indicate that these instructions \\textit{can} improve a\nreinforcement learning agent's performance. Therefore, we present this work to\naccelerate the evaluation of language solutions on reward based environments to\nenable new opportunities for scientific discovery.",
      "pdf_url": "http://arxiv.org/pdf/2507.08705v1",
      "published": "2025-07-11T16:02:24+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.08705v1",
      "categories": [
        "cs.AI",
        "I.2.5; I.2.1; I.2.7; I.2.11"
      ]
    },
    {
      "title": "KG-Attention: Knowledge Graph-Guided Attention at Test-Time via Bidirectional Information Aggregation",
      "authors": [
        "Songlin Zhai",
        "Guilin Qi",
        "Yuan Meng"
      ],
      "abstract": "Knowledge graphs (KGs) play a critical role in enhancing large language\nmodels (LLMs) by introducing structured and grounded knowledge into the\nlearning process. However, most existing KG-enhanced approaches rely on\nparameter-intensive fine-tuning, which risks catastrophic forgetting and\ndegrades the pretrained model's generalization. Moreover, they exhibit limited\nadaptability to real-time knowledge updates due to their static integration\nframeworks. To address these issues, we introduce the first test-time\nKG-augmented framework for LLMs, built around a dedicated knowledge\ngraph-guided attention (KGA) module that enables dynamic knowledge fusion\nwithout any parameter updates. The proposed KGA module augments the standard\nself-attention mechanism with two synergistic pathways: outward and inward\naggregation. Specifically, the outward pathway dynamically integrates external\nknowledge into input representations via input-driven KG fusion. This inward\naggregation complements the outward pathway by refining input representations\nthrough KG-guided filtering, suppressing task-irrelevant signals and amplifying\nknowledge-relevant patterns. Importantly, while the outward pathway handles\nknowledge fusion, the inward path selects the most relevant triples and feeds\nthem back into the fusion process, forming a closed-loop enhancement mechanism.\nBy synergistically combining these two pathways, the proposed method supports\nreal-time knowledge fusion exclusively at test-time, without any parameter\nmodification. Extensive experiments on five benchmarks verify the comparable\nknowledge fusion performance of KGA.",
      "pdf_url": "http://arxiv.org/pdf/2507.08704v1",
      "published": "2025-07-11T15:57:37+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.08704v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "ONION: A Multi-Layered Framework for Participatory ER Design",
      "authors": [
        "Viktoriia Makovska",
        "George Fletcher",
        "Julia Stoyanovich"
      ],
      "abstract": "We present ONION, a multi-layered framework for participatory\nEntity-Relationship (ER) modeling that integrates insights from design justice,\nparticipatory AI, and conceptual modeling. ONION introduces a five-stage\nmethodology: Observe, Nurture, Integrate, Optimize, Normalize. It supports\nprogressive abstraction from unstructured stakeholder input to structured ER\ndiagrams.\n  Our approach aims to reduce designer bias, promote inclusive participation,\nand increase transparency through the modeling process. We evaluate ONION\nthrough real-world workshops focused on sociotechnical systems in Ukraine,\nhighlighting how diverse stakeholder engagement leads to richer data models and\ndeeper mutual understanding. Early results demonstrate ONION's potential to\nhost diversity in early-stage data modeling. We conclude with lessons learned,\nlimitations and challenges involved in scaling and refining the framework for\nbroader adoption.",
      "pdf_url": "http://arxiv.org/pdf/2507.08702v1",
      "published": "2025-07-11T15:53:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.08702v1",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.CY"
      ]
    },
    {
      "title": "A Personalised Formal Verification Framework for Monitoring Activities of Daily Living of Older Adults Living Independently in Their Homes",
      "authors": [
        "Ricardo Contreras",
        "Filip Smola",
        "Nuša Farič",
        "Jiawei Zheng",
        "Jane Hillston",
        "Jacques D. Fleuriot"
      ],
      "abstract": "There is an imperative need to provide quality of life to a growing\npopulation of older adults living independently. Personalised solutions that\nfocus on the person and take into consideration their preferences and context\nare key. In this work, we introduce a framework for representing and reasoning\nabout the Activities of Daily Living of older adults living independently at\nhome. The framework integrates data from sensors and contextual information\nthat aggregates semi-structured interviews, home layouts and sociological\nobservations from the participants. We use these data to create formal models,\npersonalised for each participant according to their preferences and context.\nWe formulate requirements that are specific to each individual as properties\nencoded in Linear Temporal Logic and use a model checker to verify whether each\nproperty is satisfied by the model. When a property is violated, a\ncounterexample is generated giving the cause of the violation. We demonstrate\nthe framework's generalisability by applying it to different participants,\nhighlighting its potential to enhance the safety and well-being of older adults\nageing in place.",
      "pdf_url": "http://arxiv.org/pdf/2507.08701v1",
      "published": "2025-07-11T15:53:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.08701v1",
      "categories": [
        "cs.LO",
        "cs.AI",
        "cs.CY"
      ]
    },
    {
      "title": "MoSAiC: Multi-Modal Multi-Label Supervision-Aware Contrastive Learning for Remote Sensing",
      "authors": [
        "Debashis Gupta",
        "Aditi Golder",
        "Rongkhun Zhu",
        "Kangning Cui",
        "Wei Tang",
        "Fan Yang",
        "Ovidiu Csillik",
        "Sarra Alaqahtani",
        "V. Paul Pauca"
      ],
      "abstract": "Contrastive learning (CL) has emerged as a powerful paradigm for learning\ntransferable representations without the reliance on large labeled datasets.\nIts ability to capture intrinsic similarities and differences among data\nsamples has led to state-of-the-art results in computer vision tasks. These\nstrengths make CL particularly well-suited for Earth System Observation (ESO),\nwhere diverse satellite modalities such as optical and SAR imagery offer\nnaturally aligned views of the same geospatial regions. However, ESO presents\nunique challenges, including high inter-class similarity, scene clutter, and\nambiguous boundaries, which complicate representation learning -- especially in\nlow-label, multi-label settings. Existing CL frameworks often focus on\nintra-modality self-supervision or lack mechanisms for multi-label alignment\nand semantic precision across modalities. In this work, we introduce MoSAiC, a\nunified framework that jointly optimizes intra- and inter-modality contrastive\nlearning with a multi-label supervised contrastive loss. Designed specifically\nfor multi-modal satellite imagery, MoSAiC enables finer semantic\ndisentanglement and more robust representation learning across spectrally\nsimilar and spatially complex classes. Experiments on two benchmark datasets,\nBigEarthNet V2.0 and Sent12MS, show that MoSAiC consistently outperforms both\nfully supervised and self-supervised baselines in terms of accuracy, cluster\ncoherence, and generalization in low-label and high-class-overlap scenarios.",
      "pdf_url": "http://arxiv.org/pdf/2507.08683v1",
      "published": "2025-07-11T15:33:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.08683v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "KELPS: A Framework for Verified Multi-Language Autoformalization via Semantic-Syntactic Alignment",
      "authors": [
        "Jiyao Zhang",
        "Chengli Zhong",
        "Hui Xu",
        "Qige Li",
        "Yi Zhou"
      ],
      "abstract": "Modern large language models (LLMs) show promising progress in formalizing\ninformal mathematics into machine-verifiable theorems. However, these methods\nstill face bottlenecks due to the limited quantity and quality of multilingual\nparallel corpora. In this paper, we propose a novel neuro-symbolic framework\nKELPS (Knowledge-Equation based Logical Processing System) to address these\nproblems. KELPS is an iterative framework for translating, synthesizing, and\nfiltering informal data into multiple formal languages (Lean, Coq, and\nIsabelle). First, we translate natural language into Knowledge Equations (KEs),\na novel language that we designed, theoretically grounded in assertional logic.\nNext, we convert them to target languages through rigorously defined rules that\npreserve both syntactic structure and semantic meaning. This process yielded a\nparallel corpus of over 60,000 problems. Our framework achieves 88.9% syntactic\naccuracy (pass@1) on MiniF2F, outperforming SOTA models such as Deepseek-V3\n(81%) and Herald (81.3%) across multiple datasets. All datasets and codes are\navailable in the supplementary materials.",
      "pdf_url": "http://arxiv.org/pdf/2507.08665v1",
      "published": "2025-07-11T15:05:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.08665v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Introspection of Thought Helps AI Agents",
      "authors": [
        "Haoran Sun",
        "Shaoning Zeng"
      ],
      "abstract": "AI Agents rely on Large Language Models (LLMs) and Multimodal-LLMs (MLLMs) to\nperform interpretation and inference in text and image tasks without\npost-training, where LLMs and MLLMs play the most critical role and determine\nthe initial ability and limitations of AI Agents. Usually, AI Agents utilize\nsophisticated prompt engineering and external reasoning framework to obtain a\npromising interaction with LLMs, e.g., Chain-of-Thought, Iteration of Thought\nand Image-of-Thought. However, they are still constrained by the inherent\nlimitations of LLM in understanding natural language, and the iterative\nreasoning process will generate a large amount of inference cost. To this end,\nwe propose a novel AI Agent Reasoning Framework with Introspection of Thought\n(INoT) by designing a new LLM-Read code in prompt. It enables LLM to execute\nprogrammatic dialogue reasoning processes following the code in prompt.\nTherefore, self-denial and reflection occur within LLM instead of outside LLM,\nwhich can reduce token cost effectively. Through our experiments on six\nbenchmarks for three different tasks, the effectiveness of INoT is verified,\nwith an average improvement of 7.95\\% in performance, exceeding the baselines.\nFurthermore, the token cost of INoT is lower on average than the best\nperforming method at baseline by 58.3\\%. In addition, we demonstrate the\nversatility of INoT in image interpretation and inference through verification\nexperiments.",
      "pdf_url": "http://arxiv.org/pdf/2507.08664v1",
      "published": "2025-07-11T15:03:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.08664v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Safe Deep Reinforcement Learning for Resource Allocation with Peak Age of Information Violation Guarantees",
      "authors": [
        "Berire Gunes Reyhan",
        "Sinem Coleri"
      ],
      "abstract": "In Wireless Networked Control Systems (WNCSs), control and communication\nsystems must be co-designed due to their strong interdependence. This paper\npresents a novel optimization theory-based safe deep reinforcement learning\n(DRL) framework for ultra-reliable WNCSs, ensuring constraint satisfaction\nwhile optimizing performance, for the first time in the literature. The\napproach minimizes power consumption under key constraints, including Peak Age\nof Information (PAoI) violation probability, transmit power, and schedulability\nin the finite blocklength regime. PAoI violation probability is uniquely\nderived by combining stochastic maximum allowable transfer interval (MATI) and\nmaximum allowable packet delay (MAD) constraints in a multi-sensor network. The\nframework consists of two stages: optimization theory and safe DRL. The first\nstage derives optimality conditions to establish mathematical relationships\namong variables, simplifying and decomposing the problem. The second stage\nemploys a safe DRL model where a teacher-student framework guides the DRL agent\n(student). The control mechanism (teacher) evaluates compliance with system\nconstraints and suggests the nearest feasible action when needed. Extensive\nsimulations show that the proposed framework outperforms rule-based and other\noptimization theory based DRL benchmarks, achieving faster convergence, higher\nrewards, and greater stability.",
      "pdf_url": "http://arxiv.org/pdf/2507.08653v1",
      "published": "2025-07-11T14:57:37+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.08653v1",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ]
    },
    {
      "title": "Leanabell-Prover-V2: Verifier-integrated Reasoning for Formal Theorem Proving via Reinforcement Learning",
      "authors": [
        "Xingguang Ji",
        "Yahui Liu",
        "Qi Wang",
        "Jingyuan Zhang",
        "Yang Yue",
        "Rui Shi",
        "Chenxi Sun",
        "Fuzheng Zhang",
        "Guorui Zhou",
        "Kun Gai"
      ],
      "abstract": "We introduce our Leanabell-Prover-V2, a 7B large language models (LLMs) that\ncan produce formal theorem proofs in Lean 4, with verifier-integrated Long\nChain-of-Thoughts (CoT). Following our previous work Leanabell-Prover-V1, we\ncontinual to choose to posttrain existing strong prover models for further\nperformance improvement. In our V2 version, we mainly upgrade the Reinforcement\nLearning (RL) with feedback provided by the Lean 4 verifier. Crucially,\nverifier feedback, such as indicating success or detailing specific errors,\nallows the LLM to become ``self-aware'' of the correctness of its own reasoning\nprocess and learn to reflexively correct errors. Leanabell-Prover-V2 directly\noptimizes LLM reasoning trajectories with multi-turn verifier interactions,\ntogether with feedback token masking for stable RL training and a simple reward\nstrategy. Experiments show that Leanabell-Prover-V2 improves performance by\n3.2% (pass@128) with Kimina-Prover-Preview-Distill-7B and 2.0% (pass@128) with\nDeepSeek-Prover-V2-7B on the MiniF2F test set. The source codes, curated data\nand models are available at:\nhttps://github.com/Leanabell-LM/Leanabell-Prover-V2.",
      "pdf_url": "http://arxiv.org/pdf/2507.08649v1",
      "published": "2025-07-11T14:53:14+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.08649v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "DatasetAgent: A Novel Multi-Agent System for Auto-Constructing Datasets from Real-World Images",
      "authors": [
        "Haoran Sun",
        "Haoyu Bian",
        "Shaoning Zeng",
        "Yunbo Rao",
        "Xu Xu",
        "Lin Mei",
        "Jianping Gou"
      ],
      "abstract": "Common knowledge indicates that the process of constructing image datasets\nusually depends on the time-intensive and inefficient method of manual\ncollection and annotation. Large models offer a solution via data generation.\nNonetheless, real-world data are obviously more valuable comparing to\nartificially intelligence generated data, particularly in constructing image\ndatasets. For this reason, we propose a novel method for auto-constructing\ndatasets from real-world images by a multiagent collaborative system, named as\nDatasetAgent. By coordinating four different agents equipped with Multi-modal\nLarge Language Models (MLLMs), as well as a tool package for image\noptimization, DatasetAgent is able to construct high-quality image datasets\naccording to user-specified requirements. In particular, two types of\nexperiments are conducted, including expanding existing datasets and creating\nnew ones from scratch, on a variety of open-source datasets. In both cases,\nmultiple image datasets constructed by DatasetAgent are used to train various\nvision models for image classification, object detection, and image\nsegmentation.",
      "pdf_url": "http://arxiv.org/pdf/2507.08648v1",
      "published": "2025-07-11T14:51:33+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.08648v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Scaling Attention to Very Long Sequences in Linear Time with Wavelet-Enhanced Random Spectral Attention (WERSA)",
      "authors": [
        "Vincenzo Dentamaro"
      ],
      "abstract": "Transformer models are computationally costly on long sequences since regular\nattention has quadratic $O(n^2)$ time complexity. We introduce Wavelet-Enhanced\nRandom Spectral Attention (WERSA), a novel mechanism of linear $O(n)$ time\ncomplexity that is pivotal to enable successful long-sequence processing\nwithout the performance trade-off. WERSA merges content-adaptive random\nspectral features together with multi-resolution Haar wavelets and learnable\nparameters to selectively attend to informative scales of data while preserving\nlinear efficiency.\n  Large-scale comparisons \\textbf{on single GPU} and across various benchmarks\n(vision, NLP, hierarchical reasoning) and various attention mechanisms (like\nMultiheaded Attention, Flash-Attention-2, FNet, Linformer, Performer,\nWaveformer), reveal uniform advantages of WERSA. It achieves best accuracy in\nall tests. On ArXiv classification, WERSA improves accuracy over vanilla\nattention by 1.2\\% (86.2\\% vs 85.0\\%) while cutting training time by 81\\% (296s\nvs 1554s) and FLOPS by 73.4\\% (26.2G vs 98.4G). Significantly, WERSA excels\nwhere vanilla and FlashAttention-2 fail: on ArXiv-128k's extremely lengthy\nsequences, it achieves best accuracy (79.1\\%) and AUC (0.979) among viable\nmethods, operating on data that gives Out-Of-Memory errors to quadratic methods\nwhile being \\textbf{twice as fast} as Waveformer, its next-best competitor.\n  By significantly reducing computational loads without compromising accuracy,\nWERSA makes possible more practical, more affordable, long-context models, in\nparticular on low-resource hardware, for more sustainable and more scalable AI\ndevelopment.",
      "pdf_url": "http://arxiv.org/pdf/2507.08637v1",
      "published": "2025-07-11T14:40:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.08637v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Normalized vs Diplomatic Annotation: A Case Study of Automatic Information Extraction from Handwritten Uruguayan Birth Certificates",
      "authors": [
        "Natalia Bottaioli",
        "Solène Tarride",
        "Jérémy Anger",
        "Seginus Mowlavi",
        "Marina Gardella",
        "Antoine Tadros",
        "Gabriele Facciolo",
        "Rafael Grompone von Gioi",
        "Christopher Kermorvant",
        "Jean-Michel Morel",
        "Javier Preciozzi"
      ],
      "abstract": "This study evaluates the recently proposed Document Attention Network (DAN)\nfor extracting key-value information from Uruguayan birth certificates,\nhandwritten in Spanish. We investigate two annotation strategies for\nautomatically transcribing handwritten documents, fine-tuning DAN with minimal\ntraining data and annotation effort. Experiments were conducted on two datasets\ncontaining the same images (201 scans of birth certificates written by more\nthan 15 different writers) but with different annotation methods. Our findings\nindicate that normalized annotation is more effective for fields that can be\nstandardized, such as dates and places of birth, whereas diplomatic annotation\nperforms much better for fields containing names and surnames, which can not be\nstandardized.",
      "pdf_url": "http://arxiv.org/pdf/2507.08636v1",
      "published": "2025-07-11T14:40:07+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.08636v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Adaptive Framework for Ambient Intelligence in Rehabilitation Assistance",
      "authors": [
        "Gábor Baranyi",
        "Zsolt Csibi",
        "Kristian Fenech",
        "Áron Fóthi",
        "Zsófia Gaál",
        "Joul Skaf",
        "András Lőrincz"
      ],
      "abstract": "This paper introduces the Ambient Intelligence Rehabilitation Support (AIRS)\nframework, an advanced artificial intelligence-based solution tailored for home\nrehabilitation environments. AIRS integrates cutting-edge technologies,\nincluding Real-Time 3D Reconstruction (RT-3DR), intelligent navigation, and\nlarge Vision-Language Models (VLMs), to create a comprehensive system for\nmachine-guided physical rehabilitation. The general AIRS framework is\ndemonstrated in rehabilitation scenarios following total knee replacement\n(TKR), utilizing a database of 263 video recordings for evaluation. A\nsmartphone is employed within AIRS to perform RT-3DR of living spaces and has a\nbody-matched avatar to provide visual feedback about the excercise. This avatar\nis necessary in (a) optimizing exercise configurations, including camera\nplacement, patient positioning, and initial poses, and (b) addressing privacy\nconcerns and promoting compliance with the AI Act. The system guides users\nthrough the recording process to ensure the collection of properly recorded\nvideos. AIRS employs two feedback mechanisms: (i) visual 3D feedback, enabling\ndirect comparisons between prerecorded clinical exercises and patient home\nrecordings and (ii) VLM-generated feedback, providing detailed explanations and\ncorrections for exercise errors. The framework also supports people with visual\nand hearing impairments. It also features a modular design that can be adapted\nto broader rehabilitation contexts. AIRS software components are available for\nfurther use and customization.",
      "pdf_url": "http://arxiv.org/pdf/2507.08624v1",
      "published": "2025-07-11T14:27:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.08624v1",
      "categories": [
        "cs.HC",
        "cs.AI"
      ]
    },
    {
      "title": "A comprehensive study of LLM-based argument classification: from LLAMA through GPT-4o to Deepseek-R1",
      "authors": [
        "Marcin Pietroń",
        "Rafał Olszowski",
        "Jakub Gomułka",
        "Filip Gampel",
        "Andrzej Tomski"
      ],
      "abstract": "Argument mining (AM) is an interdisciplinary research field that integrates\ninsights from logic, philosophy, linguistics, rhetoric, law, psychology, and\ncomputer science. It involves the automatic identification and extraction of\nargumentative components, such as premises and claims, and the detection of\nrelationships between them, such as support, attack, or neutrality. Recently,\nthe field has advanced significantly, especially with the advent of large\nlanguage models (LLMs), which have enhanced the efficiency of analyzing and\nextracting argument semantics compared to traditional methods and other deep\nlearning models. There are many benchmarks for testing and verifying the\nquality of LLM, but there is still a lack of research and results on the\noperation of these models in publicly available argument classification\ndatabases. This paper presents a study of a selection of LLM's, using diverse\ndatasets such as Args.me and UKP. The models tested include versions of GPT,\nLlama, and DeepSeek, along with reasoning-enhanced variants incorporating the\nChain-of-Thoughts algorithm. The results indicate that ChatGPT-4o outperforms\nthe others in the argument classification benchmarks. In case of models\nincorporated with reasoning capabilities, the Deepseek-R1 shows its\nsuperiority. However, despite their superiority, GPT-4o and Deepseek-R1 still\nmake errors. The most common errors are discussed for all models. To our\nknowledge, the presented work is the first broader analysis of the mentioned\ndatasets using LLM and prompt algorithms. The work also shows some weaknesses\nof known prompt algorithms in argument analysis, while indicating directions\nfor their improvement. The added value of the work is the in-depth analysis of\nthe available argument datasets and the demonstration of their shortcomings.",
      "pdf_url": "http://arxiv.org/pdf/2507.08621v1",
      "published": "2025-07-11T14:23:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.08621v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Agentic Large Language Models for Conceptual Systems Engineering and Design",
      "authors": [
        "Soheyl Massoudi",
        "Mark Fuge"
      ],
      "abstract": "Early-stage engineering design involves complex, iterative reasoning, yet\nexisting large language model (LLM) workflows struggle to maintain task\ncontinuity and generate executable models. We evaluate whether a structured\nmulti-agent system (MAS) can more effectively manage requirements extraction,\nfunctional decomposition, and simulator code generation than a simpler\ntwo-agent system (2AS). The target application is a solar-powered water\nfiltration system as described in a cahier des charges. We introduce the\nDesign-State Graph (DSG), a JSON-serializable representation that bundles\nrequirements, physical embodiments, and Python-based physics models into graph\nnodes. A nine-role MAS iteratively builds and refines the DSG, while the 2AS\ncollapses the process to a Generator-Reflector loop. Both systems run a total\nof 60 experiments (2 LLMs - Llama 3.3 70B vs reasoning-distilled DeepSeek R1\n70B x 2 agent configurations x 3 temperatures x 5 seeds). We report a JSON\nvalidity, requirement coverage, embodiment presence, code compatibility,\nworkflow completion, runtime, and graph size. Across all runs, both MAS and 2AS\nmaintained perfect JSON integrity and embodiment tagging. Requirement coverage\nremained minimal (less than 20\\%). Code compatibility peaked at 100\\% under\nspecific 2AS settings but averaged below 50\\% for MAS. Only the\nreasoning-distilled model reliably flagged workflow completion. Powered by\nDeepSeek R1 70B, the MAS generated more granular DSGs (average 5-6 nodes)\nwhereas 2AS mode-collapsed. Structured multi-agent orchestration enhanced\ndesign detail. Reasoning-distilled LLM improved completion rates, yet low\nrequirements and fidelity gaps in coding persisted.",
      "pdf_url": "http://arxiv.org/pdf/2507.08619v1",
      "published": "2025-07-11T14:19:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.08619v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Towards Collaborative Fairness in Federated Learning Under Imbalanced Covariate Shift",
      "authors": [
        "Tianrun Yu",
        "Jiaqi Wang",
        "Haoyu Wang",
        "Mingquan Lin",
        "Han Liu",
        "Nelson S. Yee",
        "Fenglong Ma"
      ],
      "abstract": "Collaborative fairness is a crucial challenge in federated learning. However,\nexisting approaches often overlook a practical yet complex form of\nheterogeneity: imbalanced covariate shift. We provide a theoretical analysis of\nthis setting, which motivates the design of FedAKD (Federated Asynchronous\nKnowledge Distillation)- simple yet effective approach that balances accurate\nprediction with collaborative fairness. FedAKD consists of client and server\nupdates. In the client update, we introduce a novel asynchronous knowledge\ndistillation strategy based on our preliminary analysis, which reveals that\nwhile correctly predicted samples exhibit similar feature distributions across\nclients, incorrectly predicted samples show significant variability. This\nsuggests that imbalanced covariate shift primarily arises from misclassified\nsamples. Leveraging this insight, our approach first applies traditional\nknowledge distillation to update client models while keeping the global model\nfixed. Next, we select correctly predicted high-confidence samples and update\nthe global model using these samples while keeping client models fixed. The\nserver update simply aggregates all client models. We further provide a\ntheoretical proof of FedAKD's convergence. Experimental results on public\ndatasets (FashionMNIST and CIFAR10) and a real-world Electronic Health Records\n(EHR) dataset demonstrate that FedAKD significantly improves collaborative\nfairness, enhances predictive accuracy, and fosters client participation even\nunder highly heterogeneous data distributions.",
      "pdf_url": "http://arxiv.org/pdf/2507.08617v1",
      "published": "2025-07-11T14:13:41+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.08617v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Unlocking Speech Instruction Data Potential with Query Rewriting",
      "authors": [
        "Yonghua Hei",
        "Yibo Yan",
        "Shuliang Liu",
        "Huiyu Zhou",
        "Linfeng Zhang",
        "Xuming Hu"
      ],
      "abstract": "End-to-end Large Speech Language Models~(\\textbf{LSLMs}) demonstrate strong\npotential in response latency and speech comprehension capabilities, showcasing\ngeneral intelligence across speech understanding tasks. However, the ability to\nfollow speech instructions has not been fully realized due to the lack of\ndatasets and heavily biased training tasks. Leveraging the rich ASR datasets,\nprevious approaches have used Large Language Models~(\\textbf{LLMs}) to continue\nthe linguistic information of speech to construct speech instruction datasets.\nYet, due to the gap between LLM-generated results and real human responses, the\ncontinuation methods further amplify these shortcomings. Given the high costs\nof collecting and annotating speech instruction datasets by humans, using\nspeech synthesis to construct large-scale speech instruction datasets has\nbecome a balanced and robust alternative. Although modern\nText-To-Speech~(\\textbf{TTS}) models have achieved near-human-level synthesis\nquality, it is challenging to appropriately convert out-of-distribution text\ninstruction to speech due to the limitations of the training data distribution\nin TTS models. To address this issue, we propose a query rewriting framework\nwith multi-LLM knowledge fusion, employing multiple agents to annotate and\nvalidate the synthesized speech, making it possible to construct high-quality\nspeech instruction datasets without relying on human annotation. Experiments\nshow that this method can transform text instructions into distributions more\nsuitable for TTS models for speech synthesis through zero-shot rewriting,\nincreasing data usability from 72\\% to 93\\%. It also demonstrates unique\nadvantages in rewriting tasks that require complex knowledge and\ncontext-related abilities.",
      "pdf_url": "http://arxiv.org/pdf/2507.08603v1",
      "published": "2025-07-11T13:55:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.08603v1",
      "categories": [
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ]
    },
    {
      "title": "Generating Proto-Personas through Prompt Engineering: A Case Study on Efficiency, Effectiveness and Empathy",
      "authors": [
        "Fernando Ayach",
        "Vitor Lameirão",
        "Raul Leão",
        "Jerfferson Felizardo",
        "Rafael Sobrinho",
        "Vanessa Borges",
        "Patrícia Matsubara",
        "Awdren Fontão"
      ],
      "abstract": "Proto-personas are commonly used during early-stage Product Discovery, such\nas Lean Inception, to guide product definition and stakeholder alignment.\nHowever, the manual creation of proto-personas is often time-consuming,\ncognitively demanding, and prone to bias. In this paper, we propose and\nempirically investigate a prompt engineering-based approach to generate\nproto-personas with the support of Generative AI (GenAI). Our goal is to\nevaluate the approach in terms of efficiency, effectiveness, user acceptance,\nand the empathy elicited by the generated personas. We conducted a case study\nwith 19 participants embedded in a real Lean Inception, employing a qualitative\nand quantitative methods design. The results reveal the approach's efficiency\nby reducing time and effort and improving the quality and reusability of\npersonas in later discovery phases, such as Minimum Viable Product (MVP)\nscoping and feature refinement. While acceptance was generally high, especially\nregarding perceived usefulness and ease of use, participants noted limitations\nrelated to generalization and domain specificity. Furthermore, although\ncognitive empathy was strongly supported, affective and behavioral empathy\nvaried significantly across participants. These results contribute novel\nempirical evidence on how GenAI can be effectively integrated into software\nProduct Discovery practices, while also identifying key challenges to be\naddressed in future iterations of such hybrid design processes.",
      "pdf_url": "http://arxiv.org/pdf/2507.08594v1",
      "published": "2025-07-11T13:42:12+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.08594v1",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.HC"
      ]
    },
    {
      "title": "To Trade or Not to Trade: An Agentic Approach to Estimating Market Risk Improves Trading Decisions",
      "authors": [
        "Dimitrios Emmanoulopoulos",
        "Ollie Olby",
        "Justin Lyon",
        "Namid R. Stillman"
      ],
      "abstract": "Large language models (LLMs) are increasingly deployed in agentic frameworks,\nin which prompts trigger complex tool-based analysis in pursuit of a goal.\nWhile these frameworks have shown promise across multiple domains including in\nfinance, they typically lack a principled model-building step, relying instead\non sentiment- or trend-based analysis. We address this gap by developing an\nagentic system that uses LLMs to iteratively discover stochastic differential\nequations for financial time series. These models generate risk metrics which\ninform daily trading decisions. We evaluate our system in both traditional\nbacktests and using a market simulator, which introduces synthetic but causally\nplausible price paths and news events. We find that model-informed trading\nstrategies outperform standard LLM-based agents, improving Sharpe ratios across\nmultiple equities. Our results show that combining LLMs with agentic model\ndiscovery enhances market risk estimation and enables more profitable trading\ndecisions.",
      "pdf_url": "http://arxiv.org/pdf/2507.08584v1",
      "published": "2025-07-11T13:29:32+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.08584v1",
      "categories": [
        "q-fin.ST",
        "cs.AI",
        "cs.CE",
        "cs.MA",
        "q-fin.CP",
        "68T42, 65C05, 68T01, 60H10",
        "I.2.11; I.2.0; I.2.1; I.2.3; I.2.4; I.2.8"
      ]
    },
    {
      "title": "Large Multi-modal Model Cartographic Map Comprehension for Textual Locality Georeferencing",
      "authors": [
        "Kalana Wijegunarathna",
        "Kristin Stock",
        "Christopher B. Jones"
      ],
      "abstract": "Millions of biological sample records collected in the last few centuries\narchived in natural history collections are un-georeferenced. Georeferencing\ncomplex locality descriptions associated with these collection samples is a\nhighly labour-intensive task collection agencies struggle with. None of the\nexisting automated methods exploit maps that are an essential tool for\ngeoreferencing complex relations. We present preliminary experiments and\nresults of a novel method that exploits multi-modal capabilities of recent\nLarge Multi-Modal Models (LMM). This method enables the model to visually\ncontextualize spatial relations it reads in the locality description. We use a\ngrid-based approach to adapt these auto-regressive models for this task in a\nzero-shot setting. Our experiments conducted on a small manually annotated\ndataset show impressive results for our approach ($\\sim$1 km Average distance\nerror) compared to uni-modal georeferencing with Large Language Models and\nexisting georeferencing tools. The paper also discusses the findings of the\nexperiments in light of an LMM's ability to comprehend fine-grained maps.\nMotivated by these results, a practical framework is proposed to integrate this\nmethod into a georeferencing workflow.",
      "pdf_url": "http://arxiv.org/pdf/2507.08575v1",
      "published": "2025-07-11T13:23:25+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.08575v1",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ]
    },
    {
      "title": "A Multi-Modal Fusion Framework for Brain Tumor Segmentation Based on 3D Spatial-Language-Vision Integration and Bidirectional Interactive Attention Mechanism",
      "authors": [
        "Mingda Zhang",
        "Kaiwen Pan"
      ],
      "abstract": "This study aims to develop a novel multi-modal fusion framework for brain\ntumor segmentation that integrates spatial-language-vision information through\nbidirectional interactive attention mechanisms to improve segmentation accuracy\nand boundary delineation. Methods: We propose two core components: Multi-modal\nSemantic Fusion Adapter (MSFA) integrating 3D MRI data with clinical text\ndescriptions through hierarchical semantic decoupling, and Bidirectional\nInteractive Visual-semantic Attention (BIVA) enabling iterative information\nexchange between modalities. The framework was evaluated on BraTS 2020 dataset\ncomprising 369 multi-institutional MRI scans. Results: The proposed method\nachieved average Dice coefficient of 0.8505 and 95% Hausdorff distance of\n2.8256mm across enhancing tumor, tumor core, and whole tumor regions,\noutperforming state-of-the-art methods including SCAU-Net, CA-Net, and 3D\nU-Net. Ablation studies confirmed critical contributions of semantic and\nspatial modules to boundary precision. Conclusion: Multi-modal semantic fusion\ncombined with bidirectional interactive attention significantly enhances brain\ntumor segmentation performance, establishing new paradigms for integrating\nclinical knowledge into medical image analysis.",
      "pdf_url": "http://arxiv.org/pdf/2507.08574v1",
      "published": "2025-07-11T13:21:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.08574v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "FreeAudio: Training-Free Timing Planning for Controllable Long-Form Text-to-Audio Generation",
      "authors": [
        "Yuxuan Jiang",
        "Zehua Chen",
        "Zeqian Ju",
        "Chang Li",
        "Weibei Dou",
        "Jun Zhu"
      ],
      "abstract": "Text-to-audio (T2A) generation has achieved promising results with the recent\nadvances in generative models. However, because of the limited quality and\nquantity of temporally-aligned audio-text pairs, existing T2A methods struggle\nto handle the complex text prompts that contain precise timing control, e.g.,\n\"owl hooted at 2.4s-5.2s\". Recent works have explored data augmentation\ntechniques or introduced timing conditions as model inputs to enable\ntiming-conditioned 10-second T2A generation, while their synthesis quality is\nstill limited. In this work, we propose a novel training-free timing-controlled\nT2A framework, FreeAudio, making the first attempt to enable timing-controlled\nlong-form T2A generation, e.g., \"owl hooted at 2.4s-5.2s and crickets chirping\nat 0s-24s\". Specifically, we first employ an LLM to plan non-overlapping time\nwindows and recaption each with a refined natural language description, based\non the input text and timing prompts. Then we introduce: 1) Decoupling and\nAggregating Attention Control for precise timing control; 2) Contextual Latent\nComposition for local smoothness and Reference Guidance for global consistency.\nExtensive experiments show that: 1) FreeAudio achieves state-of-the-art\ntiming-conditioned T2A synthesis quality among training-free methods and is\ncomparable to leading training-based methods; 2) FreeAudio demonstrates\ncomparable long-form generation quality with training-based Stable Audio and\npaves the way for timing-controlled long-form T2A synthesis. Demo samples are\navailable at: https://freeaudio.github.io/FreeAudio/",
      "pdf_url": "http://arxiv.org/pdf/2507.08557v1",
      "published": "2025-07-11T12:57:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.08557v1",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.MM",
        "eess.AS"
      ]
    },
    {
      "title": "RadiomicsRetrieval: A Customizable Framework for Medical Image Retrieval Using Radiomics Features",
      "authors": [
        "Inye Na",
        "Nejung Rue",
        "Jiwon Chung",
        "Hyunjin Park"
      ],
      "abstract": "Medical image retrieval is a valuable field for supporting clinical\ndecision-making, yet current methods primarily support 2D images and require\nfully annotated queries, limiting clinical flexibility. To address this, we\npropose RadiomicsRetrieval, a 3D content-based retrieval framework bridging\nhandcrafted radiomics descriptors with deep learning-based embeddings at the\ntumor level. Unlike existing 2D approaches, RadiomicsRetrieval fully exploits\nvolumetric data to leverage richer spatial context in medical images. We employ\na promptable segmentation model (e.g., SAM) to derive tumor-specific image\nembeddings, which are aligned with radiomics features extracted from the same\ntumor via contrastive learning. These representations are further enriched by\nanatomical positional embedding (APE). As a result, RadiomicsRetrieval enables\nflexible querying based on shape, location, or partial feature sets. Extensive\nexperiments on both lung CT and brain MRI public datasets demonstrate that\nradiomics features significantly enhance retrieval specificity, while APE\nprovides global anatomical context essential for location-based searches.\nNotably, our framework requires only minimal user prompts (e.g., a single\npoint), minimizing segmentation overhead and supporting diverse clinical\nscenarios. The capability to query using either image embeddings or selected\nradiomics attributes highlights its adaptability, potentially benefiting\ndiagnosis, treatment planning, and research on large-scale medical imaging\nrepositories. Our code is available at\nhttps://github.com/nainye/RadiomicsRetrieval.",
      "pdf_url": "http://arxiv.org/pdf/2507.08546v1",
      "published": "2025-07-11T12:48:25+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.08546v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "White-Basilisk: A Hybrid Model for Code Vulnerability Detection",
      "authors": [
        "Ioannis Lamprou",
        "Alexander Shevtsov",
        "Ioannis Arapakis",
        "Sotiris Ioannidis"
      ],
      "abstract": "The proliferation of software vulnerabilities presents a significant\nchallenge to cybersecurity, necessitating more effective detection\nmethodologies. We introduce White-Basilisk, a novel approach to vulnerability\ndetection that demonstrates superior performance while challenging prevailing\nassumptions in AI model scaling. Utilizing an innovative architecture that\nintegrates Mamba layers, linear self-attention, and a Mixture of Experts\nframework, White-Basilisk achieves state-of-the-art results in vulnerability\ndetection tasks with a parameter count of only 200M. The model's capacity to\nprocess sequences of unprecedented length enables comprehensive analysis of\nextensive codebases in a single pass, surpassing the context limitations of\ncurrent Large Language Models (LLMs). White-Basilisk exhibits robust\nperformance on imbalanced, real-world datasets, while maintaining computational\nefficiency that facilitates deployment across diverse organizational scales.\nThis research not only establishes new benchmarks in code security but also\nprovides empirical evidence that compact, efficiently designed models can\noutperform larger counterparts in specialized tasks, potentially redefining\noptimization strategies in AI development for domain-specific applications.",
      "pdf_url": "http://arxiv.org/pdf/2507.08540v1",
      "published": "2025-07-11T12:39:25+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.08540v1",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "title": "MIDI-VALLE: Improving Expressive Piano Performance Synthesis Through Neural Codec Language Modelling",
      "authors": [
        "Jingjing Tang",
        "Xin Wang",
        "Zhe Zhang",
        "Junichi Yamagishi",
        "Geraint Wiggins",
        "George Fazekas"
      ],
      "abstract": "Generating expressive audio performances from music scores requires models to\ncapture both instrument acoustics and human interpretation. Traditional music\nperformance synthesis pipelines follow a two-stage approach, first generating\nexpressive performance MIDI from a score, then synthesising the MIDI into\naudio. However, the synthesis models often struggle to generalise across\ndiverse MIDI sources, musical styles, and recording environments. To address\nthese challenges, we propose MIDI-VALLE, a neural codec language model adapted\nfrom the VALLE framework, which was originally designed for zero-shot\npersonalised text-to-speech (TTS) synthesis. For performance MIDI-to-audio\nsynthesis, we improve the architecture to condition on a reference audio\nperformance and its corresponding MIDI. Unlike previous TTS-based systems that\nrely on piano rolls, MIDI-VALLE encodes both MIDI and audio as discrete tokens,\nfacilitating a more consistent and robust modelling of piano performances.\nFurthermore, the model's generalisation ability is enhanced by training on an\nextensive and diverse piano performance dataset. Evaluation results show that\nMIDI-VALLE significantly outperforms a state-of-the-art baseline, achieving\nover 75% lower Frechet Audio Distance on the ATEPP and Maestro datasets. In the\nlistening test, MIDI-VALLE received 202 votes compared to 58 for the baseline,\ndemonstrating improved synthesis quality and generalisation across diverse\nperformance MIDI inputs.",
      "pdf_url": "http://arxiv.org/pdf/2507.08530v1",
      "published": "2025-07-11T12:28:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.08530v1",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ]
    },
    {
      "title": "A Multi-granularity Concept Sparse Activation and Hierarchical Knowledge Graph Fusion Framework for Rare Disease Diagnosis",
      "authors": [
        "Mingda Zhang",
        "Na Zhao",
        "Jianglong Qin",
        "Guoyu Ye",
        "Ruixiang Tang"
      ],
      "abstract": "Despite advances from medical large language models in healthcare,\nrare-disease diagnosis remains hampered by insufficient\nknowledge-representation depth, limited concept understanding, and constrained\nclinical reasoning. We propose a framework that couples multi-granularity\nsparse activation of medical concepts with a hierarchical knowledge graph. Four\ncomplementary matching algorithms, diversity control, and a five-level fallback\nstrategy enable precise concept activation, while a three-layer knowledge graph\n(taxonomy, clinical features, instances) provides structured, up-to-date\ncontext. Experiments on the BioASQ rare-disease QA set show BLEU gains of 0.09,\nROUGE gains of 0.05, and accuracy gains of 0.12, with peak accuracy of 0.89\napproaching the 0.90 clinical threshold. Expert evaluation confirms\nimprovements in information quality, reasoning, and professional expression,\nsuggesting our approach shortens the \"diagnostic odyssey\" for rare-disease\npatients.",
      "pdf_url": "http://arxiv.org/pdf/2507.08529v1",
      "published": "2025-07-11T12:26:19+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.08529v1",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "From Language to Logic: A Bi-Level Framework for Structured Reasoning",
      "authors": [
        "Keying Yang",
        "Hao Wang",
        "Kai Yang"
      ],
      "abstract": "Structured reasoning over natural language inputs remains a core challenge in\nartificial intelligence, as it requires bridging the gap between unstructured\nlinguistic expressions and formal logical representations. In this paper, we\npropose a novel \\textbf{bi-level framework} that maps language to logic through\na two-stage process: high-level task abstraction and low-level logic\ngeneration. At the upper level, a large language model (LLM) parses natural\nlanguage queries into intermediate structured representations specifying the\nproblem type, objectives, decision variables, and symbolic constraints. At the\nlower level, the LLM uses these representations to generate symbolic workflows\nor executable reasoning programs for accurate and interpretable decision\nmaking. The framework supports modular reasoning, enforces explicit\nconstraints, and generalizes across domains such as mathematical problem\nsolving, question answering, and logical inference. We further optimize the\nframework with an end-to-end {bi-level} optimization approach that jointly\nrefines both the high-level abstraction and low-level logic generation stages.\nExperiments on multiple realistic reasoning benchmarks demonstrate that our\napproach significantly outperforms existing baselines in accuracy, with\naccuracy gains reaching as high as 40\\%. Moreover, the bi-level design enhances\ntransparency and error traceability, offering a promising step toward\ntrustworthy and systematic reasoning with LLMs.",
      "pdf_url": "http://arxiv.org/pdf/2507.08501v1",
      "published": "2025-07-11T11:24:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.08501v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "PromotionGo at SemEval-2025 Task 11: A Feature-Centric Framework for Cross-Lingual Multi-Emotion Detection in Short Texts",
      "authors": [
        "Ziyi Huang",
        "Xia Cui"
      ],
      "abstract": "This paper presents our system for SemEval 2025 Task 11: Bridging the Gap in\nText-Based Emotion Detection (Track A), which focuses on multi-label emotion\ndetection in short texts. We propose a feature-centric framework that\ndynamically adapts document representations and learning algorithms to optimize\nlanguage-specific performance. Our study evaluates three key components:\ndocument representation, dimensionality reduction, and model training in 28\nlanguages, highlighting five for detailed analysis. The results show that\nTF-IDF remains highly effective for low-resource languages, while contextual\nembeddings like FastText and transformer-based document representations, such\nas those produced by Sentence-BERT, exhibit language-specific strengths.\nPrincipal Component Analysis (PCA) reduces training time without compromising\nperformance, particularly benefiting FastText and neural models such as\nMulti-Layer Perceptrons (MLP). Computational efficiency analysis underscores\nthe trade-off between model complexity and processing cost. Our framework\nprovides a scalable solution for multilingual emotion detection, addressing the\nchallenges of linguistic diversity and resource constraints.",
      "pdf_url": "http://arxiv.org/pdf/2507.08499v1",
      "published": "2025-07-11T11:21:18+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.08499v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Enhancing Essay Cohesion Assessment: A Novel Item Response Theory Approach",
      "authors": [
        "Bruno Alexandre Rosa",
        "Hilário Oliveira",
        "Luiz Rodrigues",
        "Eduardo Araujo Oliveira",
        "Rafael Ferreira Mello"
      ],
      "abstract": "Essays are considered a valuable mechanism for evaluating learning outcomes\nin writing. Textual cohesion is an essential characteristic of a text, as it\nfacilitates the establishment of meaning between its parts. Automatically\nscoring cohesion in essays presents a challenge in the field of educational\nartificial intelligence. The machine learning algorithms used to evaluate texts\ngenerally do not consider the individual characteristics of the instances that\ncomprise the analysed corpus. In this meaning, item response theory can be\nadapted to the context of machine learning, characterising the ability,\ndifficulty and discrimination of the models used. This work proposes and\nanalyses the performance of a cohesion score prediction approach based on item\nresponse theory to adjust the scores generated by machine learning models. In\nthis study, the corpus selected for the experiments consisted of the extended\nEssay-BR, which includes 6,563 essays in the style of the National High School\nExam (ENEM), and the Brazilian Portuguese Narrative Essays, comprising 1,235\nessays written by 5th to 9th grade students from public schools. We extracted\n325 linguistic features and treated the problem as a machine learning\nregression task. The experimental results indicate that the proposed approach\noutperforms conventional machine learning models and ensemble methods in\nseveral evaluation metrics. This research explores a potential approach for\nimproving the automatic evaluation of cohesion in educational essays.",
      "pdf_url": "http://arxiv.org/pdf/2507.08487v1",
      "published": "2025-07-11T11:05:27+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.08487v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Pre-Training LLMs on a budget: A comparison of three optimizers",
      "authors": [
        "Joel Schlotthauer",
        "Christian Kroos",
        "Chris Hinze",
        "Viktor Hangya",
        "Luzian Hahn",
        "Fabian Küch"
      ],
      "abstract": "Optimizers play a decisive role in reducing pre-training times for LLMs and\nachieving better-performing models. In this study, we compare three major\nvariants: the de-facto standard AdamW, the simpler Lion, developed through an\nevolutionary search, and the second-order optimizer Sophia. For better\ngeneralization, we train with two different base architectures and use a\nsingle- and a multiple-epoch approach while keeping the number of tokens\nconstant. Using the Maximal Update Parametrization and smaller proxy models, we\ntune relevant hyperparameters separately for each combination of base\narchitecture and optimizer. We found that while the results from all three\noptimizers were in approximately the same range, Sophia exhibited the lowest\ntraining and validation loss, Lion was fastest in terms of training GPU hours\nbut AdamW led to the best downstream evaluation results.",
      "pdf_url": "http://arxiv.org/pdf/2507.08472v1",
      "published": "2025-07-11T10:29:04+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.08472v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "A document is worth a structured record: Principled inductive bias design for document recognition",
      "authors": [
        "Benjamin Meyer",
        "Lukas Tuggener",
        "Sascha Hänzi",
        "Daniel Schmid",
        "Erdal Ayfer",
        "Benjamin F. Grewe",
        "Ahmed Abdulkadir",
        "Thilo Stadelmann"
      ],
      "abstract": "Many document types use intrinsic, convention-driven structures that serve to\nencode precise and structured information, such as the conventions governing\nengineering drawings. However, state-of-the-art approaches treat document\nrecognition as a mere computer vision problem, neglecting these underlying\ndocument-type-specific structural properties, making them dependent on\nsub-optimal heuristic post-processing and rendering many less frequent or more\ncomplicated document types inaccessible to modern document recognition. We\nsuggest a novel perspective that frames document recognition as a transcription\ntask from a document to a record. This implies a natural grouping of documents\nbased on the intrinsic structure inherent in their transcription, where related\ndocument types can be treated (and learned) similarly. We propose a method to\ndesign structure-specific inductive biases for the underlying machine-learned\nend-to-end document recognition systems, and a respective base transformer\narchitecture that we successfully adapt to different structures. We demonstrate\nthe effectiveness of the so-found inductive biases in extensive experiments\nwith progressively complex record structures from monophonic sheet music, shape\ndrawings, and simplified engineering drawings. By integrating an inductive bias\nfor unrestricted graph structures, we train the first-ever successful\nend-to-end model to transcribe engineering drawings to their inherently\ninterlinked information. Our approach is relevant to inform the design of\ndocument recognition systems for document types that are less well understood\nthan standard OCR, OMR, etc., and serves as a guide to unify the design of\nfuture document foundation models.",
      "pdf_url": "http://arxiv.org/pdf/2507.08458v1",
      "published": "2025-07-11T10:02:08+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.08458v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Space filling positionality and the Spiroformer",
      "authors": [
        "M. Maurin",
        "M. Á. Evangelista-Alvarado",
        "P. Suárez-Serrato"
      ],
      "abstract": "Transformers excel when dealing with sequential data. Generalizing\ntransformer models to geometric domains, such as manifolds, we encounter the\nproblem of not having a well-defined global order. We propose a solution with\nattention heads following a space-filling curve. As a first experimental\nexample, we present the Spiroformer, a transformer that follows a polar spiral\non the $2$-sphere.",
      "pdf_url": "http://arxiv.org/pdf/2507.08456v1",
      "published": "2025-07-11T09:56:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.08456v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.DG",
        "math.DS",
        "math.SG"
      ]
    },
    {
      "title": "Why this and not that? A Logic-based Framework for Contrastive Explanations",
      "authors": [
        "Tobias Geibinger",
        "Reijo Jaakkola",
        "Antti Kuusisto",
        "Xinghan Liu",
        "Miikka Vilander"
      ],
      "abstract": "We define several canonical problems related to contrastive explanations,\neach answering a question of the form ''Why P but not Q?''. The problems\ncompute causes for both P and Q, explicitly comparing their differences. We\ninvestigate the basic properties of our definitions in the setting of\npropositional logic. We show, inter alia, that our framework captures a\ncardinality-minimal version of existing contrastive explanations in the\nliterature. Furthermore, we provide an extensive analysis of the computational\ncomplexities of the problems. We also implement the problems for CNF-formulas\nusing answer set programming and present several examples demonstrating how\nthey work in practice.",
      "pdf_url": "http://arxiv.org/pdf/2507.08454v1",
      "published": "2025-07-11T09:55:04+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.08454v1",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.LO",
        "68T27, 03B05",
        "I.2.3; F.4.1"
      ]
    },
    {
      "title": "Review of Feed-forward 3D Reconstruction: From DUSt3R to VGGT",
      "authors": [
        "Wei Zhang",
        "Yihang Wu",
        "Songhua Li",
        "Wenjie Ma",
        "Xin Ma",
        "Qiang Li",
        "Qi Wang"
      ],
      "abstract": "3D reconstruction, which aims to recover the dense three-dimensional\nstructure of a scene, is a cornerstone technology for numerous applications,\nincluding augmented/virtual reality, autonomous driving, and robotics. While\ntraditional pipelines like Structure from Motion (SfM) and Multi-View Stereo\n(MVS) achieve high precision through iterative optimization, they are limited\nby complex workflows, high computational cost, and poor robustness in\nchallenging scenarios like texture-less regions. Recently, deep learning has\ncatalyzed a paradigm shift in 3D reconstruction. A new family of models,\nexemplified by DUSt3R, has pioneered a feed-forward approach. These models\nemploy a unified deep network to jointly infer camera poses and dense geometry\ndirectly from an Unconstrained set of images in a single forward pass. This\nsurvey provides a systematic review of this emerging domain. We begin by\ndissecting the technical framework of these feed-forward models, including\ntheir Transformer-based correspondence modeling, joint pose and geometry\nregression mechanisms, and strategies for scaling from two-view to multi-view\nscenarios. To highlight the disruptive nature of this new paradigm, we contrast\nit with both traditional pipelines and earlier learning-based methods like\nMVSNet. Furthermore, we provide an overview of relevant datasets and evaluation\nmetrics. Finally, we discuss the technology's broad application prospects and\nidentify key future challenges and opportunities, such as model accuracy and\nscalability, and handling dynamic scenes.",
      "pdf_url": "http://arxiv.org/pdf/2507.08448v1",
      "published": "2025-07-11T09:41:54+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.08448v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "CUE-RAG: Towards Accurate and Cost-Efficient Graph-Based RAG via Multi-Partite Graph and Query-Driven Iterative Retrieval",
      "authors": [
        "Yaodong Su",
        "Yixiang Fang",
        "Yingli Zhou",
        "Quanqing Xu",
        "Chuanhui Yang"
      ],
      "abstract": "Despite the remarkable progress of Large Language Models (LLMs), their\nperformance in question answering (QA) remains limited by the lack of\ndomain-specific and up-to-date knowledge. Retrieval-Augmented Generation (RAG)\naddresses this limitation by incorporating external information, often from\ngraph-structured data. However, existing graph-based RAG methods suffer from\npoor graph quality due to incomplete extraction and insufficient utilization of\nquery information during retrieval. To overcome these limitations, we propose\nCUE-RAG, a novel approach that introduces (1) a multi-partite graph index\nincorporates text Chunks, knowledge Units, and Entities to capture semantic\ncontent at multiple levels of granularity, (2) a hybrid extraction strategy\nthat reduces LLM token usage while still producing accurate and disambiguated\nknowledge units, and (3) Q-Iter, a query-driven iterative retrieval strategy\nthat enhances relevance through semantic search and constrained graph\ntraversal. Experiments on three QA benchmarks show that CUE-RAG significantly\noutperforms state-of-the-art baselines, achieving up to 99.33% higher Accuracy\nand 113.51% higher F1 score while reducing indexing costs by 72.58%.\nRemarkably, CUE-RAG matches or outperforms baselines even without using an LLM\nfor indexing. These results demonstrate the effectiveness and cost-efficiency\nof CUE-RAG in advancing graph-based RAG systems.",
      "pdf_url": "http://arxiv.org/pdf/2507.08445v1",
      "published": "2025-07-11T09:36:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.08445v1",
      "categories": [
        "cs.IR",
        "cs.AI"
      ]
    }
  ]
}