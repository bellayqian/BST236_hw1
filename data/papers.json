{
  "last_updated": "2025-11-22T00:49:55.101136",
  "papers": [
    {
      "title": "Dataset Distillation for Pre-Trained Self-Supervised Vision Models",
      "authors": [
        "George Cazenavette",
        "Antonio Torralba",
        "Vincent Sitzmann"
      ],
      "abstract": "The task of dataset distillation aims to find a small set of synthetic images such that training a model on them reproduces the performance of the same model trained on a much larger dataset of real samples. Existing distillation methods focus on synthesizing datasets that enable training randomly initialized models. In contrast, state-of-the-art vision approaches are increasingly building on large, pre-trained self-supervised models rather than training from scratch. In this paper, we investigate the problem of distilling datasets that enable us to optimally train linear probes on top of such large, pre-trained vision models. We introduce a method of dataset distillation for this task called Linear Gradient Matching that optimizes the synthetic images such that, when passed through a pre-trained feature extractor, they induce gradients in the linear classifier similar to those produced by the real data. Our method yields synthetic data that outperform all real-image baselines and, remarkably, generalize across pre-trained vision models, enabling us, for instance, to train a linear CLIP probe that performs competitively using a dataset distilled via a DINO backbone. Further, we show that our distilled datasets are exceptionally effective for fine-grained classification and provide a valuable tool for model interpretability, predicting, among other things, how similar two models' embedding spaces are under the platonic representation hypothesis or whether a model is sensitive to spurious correlations in adversarial datasets.",
      "pdf_url": "https://arxiv.org/pdf/2511.16674v1",
      "published": "2025-11-20T18:59:57+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.16674v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Thinking-while-Generating: Interleaving Textual Reasoning throughout Visual Generation",
      "authors": [
        "Ziyu Guo",
        "Renrui Zhang",
        "Hongyu Li",
        "Manyuan Zhang",
        "Xinyan Chen",
        "Sifan Wang",
        "Yan Feng",
        "Peng Pei",
        "Pheng-Ann Heng"
      ],
      "abstract": "Recent advances in visual generation have increasingly explored the integration of reasoning capabilities. They incorporate textual reasoning, i.e., think, either before (as pre-planning) or after (as post-refinement) the generation process, yet they lack on-the-fly multimodal interaction during the generation itself. In this preliminary study, we introduce Thinking-while-Generating (TwiG), the first interleaved framework that enables co-evolving textual reasoning throughout the visual generation process. As visual content is progressively generating, textual reasoning is interleaved to both guide upcoming local regions and reflect on previously synthesized ones. This dynamic interplay produces more context-aware and semantically rich visual outputs. To unveil the potential of this framework, we investigate three candidate strategies, zero-shot prompting, supervised fine-tuning (SFT) on our curated TwiG-50K dataset, and reinforcement learning (RL) via a customized TwiG-GRPO strategy, each offering unique insights into the dynamics of interleaved reasoning. We hope this work inspires further research into interleaving textual reasoning for enhanced visual generation. Code will be released at: https://github.com/ZiyuGuo99/Thinking-while-Generating.",
      "pdf_url": "https://arxiv.org/pdf/2511.16671v1",
      "published": "2025-11-20T18:59:52+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.16671v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Taming the Long-Tail: Efficient Reasoning RL Training with Adaptive Drafter",
      "authors": [
        "Qinghao Hu",
        "Shang Yang",
        "Junxian Guo",
        "Xiaozhe Yao",
        "Yujun Lin",
        "Yuxian Gu",
        "Han Cai",
        "Chuang Gan",
        "Ana Klimovic",
        "Song Han"
      ],
      "abstract": "The emergence of Large Language Models (LLMs) with strong reasoning capabilities marks a significant milestone, unlocking new frontiers in complex problem-solving. However, training these reasoning models, typically using Reinforcement Learning (RL), encounters critical efficiency bottlenecks: response generation during RL training exhibits a persistent long-tail distribution, where a few very long responses dominate execution time, wasting resources and inflating costs. To address this, we propose TLT, a system that accelerates reasoning RL training losslessly by integrating adaptive speculative decoding. Applying speculative decoding in RL is challenging due to the dynamic workloads, evolving target model, and draft model training overhead. TLT overcomes these obstacles with two synergistic components: (1) Adaptive Drafter, a lightweight draft model trained continuously on idle GPUs during long-tail generation to maintain alignment with the target model at no extra cost; and (2) Adaptive Rollout Engine, which maintains a memory-efficient pool of pre-captured CUDAGraphs and adaptively select suitable SD strategies for each input batch. Evaluations demonstrate that TLT achieves over 1.7x end-to-end RL training speedup over state-of-the-art systems, preserves the model accuracy, and yields a high-quality draft model as a free byproduct suitable for efficient deployment. Code is released at https://github.com/mit-han-lab/fastrl.",
      "pdf_url": "https://arxiv.org/pdf/2511.16665v1",
      "published": "2025-11-20T18:59:25+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.16665v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ]
    },
    {
      "title": "Dexterity from Smart Lenses: Multi-Fingered Robot Manipulation with In-the-Wild Human Demonstrations",
      "authors": [
        "Irmak Guzey",
        "Haozhi Qi",
        "Julen Urain",
        "Changhao Wang",
        "Jessica Yin",
        "Krishna Bodduluri",
        "Mike Lambeta",
        "Lerrel Pinto",
        "Akshara Rai",
        "Jitendra Malik",
        "Tingfan Wu",
        "Akash Sharma",
        "Homanga Bharadhwaj"
      ],
      "abstract": "Learning multi-fingered robot policies from humans performing daily tasks in natural environments has long been a grand goal in the robotics community. Achieving this would mark significant progress toward generalizable robot manipulation in human environments, as it would reduce the reliance on labor-intensive robot data collection. Despite substantial efforts, progress toward this goal has been bottle-necked by the embodiment gap between humans and robots, as well as by difficulties in extracting relevant contextual and motion cues that enable learning of autonomous policies from in-the-wild human videos. We claim that with simple yet sufficiently powerful hardware for obtaining human data and our proposed framework AINA, we are now one significant step closer to achieving this dream. AINA enables learning multi-fingered policies from data collected by anyone, anywhere, and in any environment using Aria Gen 2 glasses. These glasses are lightweight and portable, feature a high-resolution RGB camera, provide accurate on-board 3D head and hand poses, and offer a wide stereo view that can be leveraged for depth estimation of the scene. This setup enables the learning of 3D point-based policies for multi-fingered hands that are robust to background changes and can be deployed directly without requiring any robot data (including online corrections, reinforcement learning, or simulation). We compare our framework against prior human-to-robot policy learning approaches, ablate our design choices, and demonstrate results across nine everyday manipulation tasks. Robot rollouts are best viewed on our website: https://aina-robot.github.io.",
      "pdf_url": "https://arxiv.org/pdf/2511.16661v1",
      "published": "2025-11-20T18:59:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.16661v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Cognitive Foundations for Reasoning and Their Manifestation in LLMs",
      "authors": [
        "Priyanka Kargupta",
        "Shuyue Stella Li",
        "Haocheng Wang",
        "Jinu Lee",
        "Shan Chen",
        "Orevaoghene Ahia",
        "Dean Light",
        "Thomas L. Griffiths",
        "Max Kleiman-Weiner",
        "Jiawei Han",
        "Asli Celikyilmaz",
        "Yulia Tsvetkov"
      ],
      "abstract": "Large language models solve complex problems yet fail on simpler variants, suggesting they achieve correct outputs through mechanisms fundamentally different from human reasoning. We synthesize cognitive science research into a taxonomy of 28 cognitive elements spanning computational constraints, meta-cognitive controls, knowledge representations, and transformation operations, then analyze their behavioral manifestations in reasoning traces. We propose a fine-grained cognitive evaluation framework and conduct the first large-scale analysis of 170K traces from 17 models across text, vision, and audio modalities, alongside 54 human think-aloud traces, which we make publicly available. Our analysis reveals systematic structural differences: humans employ hierarchical nesting and meta-cognitive monitoring while models rely on shallow forward chaining, with divergence most pronounced on ill-structured problems. Meta-analysis of 1,598 LLM reasoning papers reveals the research community concentrates on easily quantifiable behaviors (sequential organization: 55%, decomposition: 60%) while neglecting meta-cognitive controls (self-awareness: 16%, evaluation: 8%) that correlate with success. Models possess behavioral repertoires associated with success but fail to deploy them spontaneously. Leveraging these patterns, we develop test-time reasoning guidance that automatically scaffold successful structures, improving performance by up to 60% on complex problems. By bridging cognitive science and LLM research, we establish a foundation for developing models that reason through principled cognitive mechanisms rather than brittle spurious reasoning shortcuts or memorization, opening new directions for both improving model capabilities and testing theories of human cognition at scale.",
      "pdf_url": "https://arxiv.org/pdf/2511.16660v1",
      "published": "2025-11-20T18:59:00+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.16660v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Enhancing Forex Forecasting Accuracy: The Impact of Hybrid Variable Sets in Cognitive Algorithmic Trading Systems",
      "authors": [
        "Juan C. King",
        "Jose M. Amigo"
      ],
      "abstract": "This paper presents the implementation of an advanced artificial intelligence-based algorithmic trading system specifically designed for the EUR-USD pair within the high-frequency environment of the Forex market. The methodological approach centers on integrating a holistic set of input features: key fundamental macroeconomic variables (for example, Gross Domestic Product and Unemployment Rate) collected from both the Euro Zone and the United States, alongside a comprehensive suite of technical variables (including indicators, oscillators, Fibonacci levels, and price divergences). The performance of the resulting algorithm is evaluated using standard machine learning metrics to quantify predictive accuracy and backtesting simulations across historical data to assess trading profitability and risk. The study concludes with a comparative analysis to determine which class of input features, fundamental or technical, provides greater and more reliable predictive capacity for generating profitable trading signals.",
      "pdf_url": "https://arxiv.org/pdf/2511.16657v1",
      "published": "2025-11-20T18:58:22+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.16657v1",
      "categories": [
        "cs.AI",
        "math.NA"
      ]
    },
    {
      "title": "Evolution Strategies at the Hyperscale",
      "authors": [
        "Bidipta Sarkar",
        "Mattie Fellows",
        "Juan Agustin Duque",
        "Alistair Letcher",
        "Antonio León Villares",
        "Anya Sims",
        "Dylan Cope",
        "Jarek Liesen",
        "Lukas Seier",
        "Theo Wolf",
        "Uljad Berdica",
        "Alexander David Goldie",
        "Aaron Courville",
        "Karin Sevegnani",
        "Shimon Whiteson",
        "Jakob Nicolaus Foerster"
      ],
      "abstract": "We introduce Evolution Guided General Optimization via Low-rank Learning (EGGROLL), an evolution strategies (ES) algorithm designed to scale backprop-free optimization to large population sizes for modern large neural network architectures with billions of parameters. ES is a set of powerful blackbox optimisation methods that can handle non-differentiable or noisy objectives with excellent scaling potential through parallelisation. Na{ï}ve ES becomes prohibitively expensive at scale due to the computational and memory costs associated with generating matrix perturbations $E\\in\\mathbb{R}^{m\\times n}$ and the batched matrix multiplications needed to compute per-member forward passes. EGGROLL overcomes these bottlenecks by generating random matrices $A\\in \\mathbb{R}^{m\\times r},\\ B\\in \\mathbb{R}^{n\\times r}$ with $r\\ll \\min(m,n)$ to form a low-rank matrix perturbation $A B^\\top$ that are used in place of the full-rank perturbation $E$. As the overall update is an average across a population of $N$ workers, this still results in a high-rank update but with significant memory and computation savings, reducing the auxiliary storage from $mn$ to $r(m+n)$ per layer and the cost of a forward pass from $\\mathcal{O}(mn)$ to $\\mathcal{O}(r(m+n))$ when compared to full-rank ES. A theoretical analysis reveals our low-rank update converges to the full-rank update at a fast $\\mathcal{O}\\left(\\frac{1}{r}\\right)$ rate. Our experiments show that (1) EGGROLL does not compromise the performance of ES in tabula-rasa RL settings, despite being faster, (2) it is competitive with GRPO as a technique for improving LLM reasoning, and (3) EGGROLL enables stable pre-training of nonlinear recurrent language models that operate purely in integer datatypes.",
      "pdf_url": "https://arxiv.org/pdf/2511.16652v1",
      "published": "2025-11-20T18:56:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.16652v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Teacher-Guided One-Shot Pruning via Context-Aware Knowledge Distillation",
      "authors": [
        "Md. Samiul Alim",
        "Sharjil Khan",
        "Amrijit Biswas",
        "Fuad Rahman",
        "Shafin Rahman",
        "Nabeel Mohammed"
      ],
      "abstract": "Unstructured pruning remains a powerful strategy for compressing deep neural networks, yet it often demands iterative train-prune-retrain cycles, resulting in significant computational overhead. To address this challenge, we introduce a novel teacher-guided pruning framework that tightly integrates Knowledge Distillation (KD) with importance score estimation. Unlike prior approaches that apply KD as a post-pruning recovery step, our method leverages gradient signals informed by the teacher during importance score calculation to identify and retain parameters most critical for both task performance and knowledge transfer. Our method facilitates a one-shot global pruning strategy that efficiently eliminates redundant weights while preserving essential representations. After pruning, we employ sparsity-aware retraining with and without KD to recover accuracy without reactivating pruned connections. Comprehensive experiments across multiple image classification benchmarks, including CIFAR-10, CIFAR-100, and TinyImageNet, demonstrate that our method consistently achieves high sparsity levels with minimal performance degradation. Notably, our approach outperforms state-of-the-art baselines such as EPG and EPSD at high sparsity levels, while offering a more computationally efficient alternative to iterative pruning schemes like COLT. The proposed framework offers a computation-efficient, performance-preserving solution well suited for deployment in resource-constrained environments.",
      "pdf_url": "https://arxiv.org/pdf/2511.16653v1",
      "published": "2025-11-20T18:56:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.16653v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Faster Certified Symmetry Breaking Using Orders With Auxiliary Variables",
      "authors": [
        "Markus Anders",
        "Bart Bogaerts",
        "Benjamin Bogø",
        "Arthur Gontier",
        "Wietze Koops",
        "Ciaran McCreesh",
        "Magnus O. Myreen",
        "Jakob Nordström",
        "Andy Oertel",
        "Adrian Rebola-Pardo",
        "Yong Kiam Tan"
      ],
      "abstract": "Symmetry breaking is a crucial technique in modern combinatorial solving, but it is difficult to be sure it is implemented correctly. The most successful approach to deal with bugs is to make solvers certifying, so that they output not just a solution, but also a mathematical proof of correctness in a standard format, which can then be checked by a formally verified checker. This requires justifying symmetry reasoning within the proof, but developing efficient methods for this has remained a long-standing open challenge. A fully general approach was recently proposed by Bogaerts et al. (2023), but it relies on encoding lexicographic orders with big integers, which quickly becomes infeasible for large symmetries. In this work, we develop a method for instead encoding orders with auxiliary variables. We show that this leads to orders-of-magnitude speed-ups in both theory and practice by running experiments on proof logging and checking for SAT symmetry breaking using the state-of-the-art satsuma symmetry breaker and the VeriPB proof checking toolchain.",
      "pdf_url": "https://arxiv.org/pdf/2511.16637v1",
      "published": "2025-11-20T18:43:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.16637v1",
      "categories": [
        "cs.LO",
        "cs.AI"
      ]
    },
    {
      "title": "Stabilizing Policy Gradient Methods via Reward Profiling",
      "authors": [
        "Shihab Ahmed",
        "El Houcine Bergou",
        "Aritra Dutta",
        "Yue Wang"
      ],
      "abstract": "Policy gradient methods, which have been extensively studied in the last decade, offer an effective and efficient framework for reinforcement learning problems. However, their performances can often be unsatisfactory, suffering from unreliable reward improvements and slow convergence, due to high variance in gradient estimations. In this paper, we propose a universal reward profiling framework that can be seamlessly integrated with any policy gradient algorithm, where we selectively update the policy based on high-confidence performance estimations. We theoretically justify that our technique will not slow down the convergence of the baseline policy gradient methods, but with high probability, will result in stable and monotonic improvements of their performance. Empirically, on eight continuous-control benchmarks (Box2D and MuJoCo/PyBullet), our profiling yields up to 1.5x faster convergence to near-optimal returns, up to 1.75x reduction in return variance on some setups. Our profiling approach offers a general, theoretically grounded path to more reliable and efficient policy learning in complex environments.",
      "pdf_url": "https://arxiv.org/pdf/2511.16629v1",
      "published": "2025-11-20T18:35:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.16629v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SY"
      ]
    },
    {
      "title": "MedBayes-Lite: Bayesian Uncertainty Quantification for Safe Clinical Decision Support",
      "authors": [
        "Elias Hossain",
        "Md Mehedi Hasan Nipu",
        "Maleeha Sheikh",
        "Rajib Rana",
        "Subash Neupane",
        "Niloofar Yousefi"
      ],
      "abstract": "We propose MedBayes-Lite, a lightweight Bayesian enhancement for transformer-based clinical language models designed to produce reliable, uncertainty-aware predictions. Although transformers show strong potential for clinical decision support, they remain prone to overconfidence, especially in ambiguous medical cases where calibrated uncertainty is critical. MedBayes-Lite embeds uncertainty quantification directly into existing transformer pipelines without any retraining or architectural rewiring, adding no new trainable layers and keeping parameter overhead under 3 percent. The framework integrates three components: (i) Bayesian Embedding Calibration using Monte Carlo dropout for epistemic uncertainty, (ii) Uncertainty-Weighted Attention that marginalizes over token reliability, and (iii) Confidence-Guided Decision Shaping inspired by clinical risk minimization. Across biomedical QA and clinical prediction benchmarks (MedQA, PubMedQA, MIMIC-III), MedBayes-Lite consistently improves calibration and trustworthiness, reducing overconfidence by 32 to 48 percent. In simulated clinical settings, it can prevent up to 41 percent of diagnostic errors by flagging uncertain predictions for human review. These results demonstrate its effectiveness in enabling reliable uncertainty propagation and improving interpretability in medical AI systems.",
      "pdf_url": "https://arxiv.org/pdf/2511.16625v1",
      "published": "2025-11-20T18:33:12+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.16625v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "SAM 3D: 3Dfy Anything in Images",
      "authors": [
        "SAM 3D Team",
        "Xingyu Chen",
        "Fu-Jen Chu",
        "Pierre Gleize",
        "Kevin J Liang",
        "Alexander Sax",
        "Hao Tang",
        "Weiyao Wang",
        "Michelle Guo",
        "Thibaut Hardin",
        "Xiang Li",
        "Aohan Lin",
        "Jiawei Liu",
        "Ziqi Ma",
        "Anushka Sagar",
        "Bowen Song",
        "Xiaodong Wang",
        "Jianing Yang",
        "Bowen Zhang",
        "Piotr Dollár",
        "Georgia Gkioxari",
        "Matt Feiszli",
        "Jitendra Malik"
      ],
      "abstract": "We present SAM 3D, a generative model for visually grounded 3D object reconstruction, predicting geometry, texture, and layout from a single image. SAM 3D excels in natural images, where occlusion and scene clutter are common and visual recognition cues from context play a larger role. We achieve this with a human- and model-in-the-loop pipeline for annotating object shape, texture, and pose, providing visually grounded 3D reconstruction data at unprecedented scale. We learn from this data in a modern, multi-stage training framework that combines synthetic pretraining with real-world alignment, breaking the 3D \"data barrier\". We obtain significant gains over recent work, with at least a 5:1 win rate in human preference tests on real-world objects and scenes. We will release our code and model weights, an online demo, and a new challenging benchmark for in-the-wild 3D object reconstruction.",
      "pdf_url": "https://arxiv.org/pdf/2511.16624v1",
      "published": "2025-11-20T18:31:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.16624v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Bridging VLMs and Embodied Intelligence with Deliberate Practice Policy Optimization",
      "authors": [
        "Yi Zhang",
        "Che Liu",
        "Xiancong Ren",
        "Hanchu Ni",
        "Yingji Zhang",
        "Shuai Zhang",
        "Zeyuan Ding",
        "Jiayu Hu",
        "Haozhe Shan",
        "Junbo Qi",
        "Yan Bai",
        "Dengjie Li",
        "Jiachen Luo",
        "Yidong Wang",
        "Yong Dai",
        "Zenglin Xu",
        "Bin Shen",
        "Qifan Wang",
        "Jian Tang",
        "Xiaozhu Ju"
      ],
      "abstract": "Developing a universal and versatile embodied intelligence system presents two primary challenges: the critical embodied data bottleneck, where real-world data is scarce and expensive, and the algorithmic inefficiency of existing methods, which are resource-prohibitive. To address these limitations, we introduce Deliberate Practice Policy Optimization (DPPO), a metacognitive ``Metaloop'' training framework that dynamically alternates between supervised fine-tuning (competence expansion) and reinforcement learning (skill refinement). This enables automatic weakness identification and targeted resource allocation, specifically designed to maximize learning efficiency from sparse, finite data. Theoretically, DPPO can be formalised as a unified preference-learning framework. Empirically, training a vision-language embodied model with DPPO, referred to as Pelican-VL 1.0, yields a 20.3% performance improvement over the base model and surpasses open-source models at the 100B-parameter scale by 10.6%. We are open-sourcing both the models and code, providing the first systematic framework that alleviates the data and resource bottleneck and enables the community to build versatile embodied agents efficiently.",
      "pdf_url": "https://arxiv.org/pdf/2511.16602v1",
      "published": "2025-11-20T17:58:04+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.16602v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "You Only Forward Once: An Efficient Compositional Judging Paradigm",
      "authors": [
        "Tianlong Zhang",
        "Hongwei Xue",
        "Shilin Yan",
        "Di Wu",
        "Chen Xu",
        "Yunyun Yang"
      ],
      "abstract": "Multimodal large language models (MLLMs) show strong potential as judges. However, existing approaches face a fundamental trade-off: adapting MLLMs to output a single score misaligns with the generative nature of MLLMs and limits fine-grained requirement understanding, whereas autoregressively generating judging analyses is prohibitively slow in high-throughput settings. Observing that judgment reduces to verifying whether inputs satisfy a set of structured requirements, we propose YOFO, a template-conditioned method that judges all requirements in a single forward pass. Built on an autoregressive model, YOFO accepts a structured requirement template and, in one inference step, produces a binary yes/no decision for each requirement by reading the logits of the final token associated with that requirement. This design yields orders-of-magnitude speedups while preserving interpretability. Extensive experiments show that YOFO not only achieves state-of-the-art results on standard recommendation datasets, but also supports dependency-aware analysis-where subsequent judgments are conditioned on previous ones-and further benefits from post-hoc CoT.",
      "pdf_url": "https://arxiv.org/pdf/2511.16600v1",
      "published": "2025-11-20T17:55:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.16600v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "TimeViper: A Hybrid Mamba-Transformer Vision-Language Model for Efficient Long Video Understanding",
      "authors": [
        "Boshen Xu",
        "Zihan Xiao",
        "Jiaze Li",
        "Jianzhong Ju",
        "Zhenbo Luo",
        "Jian Luan",
        "Qin Jin"
      ],
      "abstract": "We introduce TimeViper, a hybrid vision-language model designed to tackle challenges of long video understanding. Processing long videos demands both an efficient model architecture and an effective mechanism for handling extended temporal contexts. To this end, TimeViper adopts a hybrid Mamba-Transformer backbone that combines the efficiency of state-space models with the expressivity of attention mechanisms. Through this hybrid design, we reveal the vision-to-text information aggregation phenomenon, where information progressively flows from vision tokens to text tokens across increasing LLM depth, resulting in severe vision token redundancy. Motivated by this observation, we propose TransV, a token information transfer module that transfers and compresses vision tokens into instruction tokens while maintaining multimodal understanding capabilities. This design enables TimeViper to process hour-long videos exceeding 10,000 frames. Extensive experiments across multiple benchmarks demonstrate that TimeViper competes with state-of-the-art models while extending frame numbers. We further analyze attention behaviors of both Mamba and Transformer layers, offering new insights into hybrid model interpretability. This work represents an initial step towards developing, interpreting, and compressing hybrid Mamba-Transformer architectures.",
      "pdf_url": "https://arxiv.org/pdf/2511.16595v1",
      "published": "2025-11-20T17:48:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.16595v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Green Resilience of Cyber-Physical Systems: Doctoral Dissertation",
      "authors": [
        "Diaeddin Rimawi"
      ],
      "abstract": "Cyber-physical systems (CPS) combine computational and physical components. Online Collaborative AI System (OL-CAIS) is a type of CPS that learn online in collaboration with humans to achieve a common goal, which makes it vulnerable to disruptive events that degrade performance. Decision-makers must therefore restore performance while limiting energy impact, creating a trade-off between resilience and greenness. This research addresses how to balance these two properties in OL-CAIS. It aims to model resilience for automatic state detection, develop agent-based policies that optimize the greenness-resilience trade-off, and understand catastrophic forgetting to maintain performance consistency. We model OL-CAIS behavior through three operational states: steady, disruptive, and final. To support recovery during disruptions, we introduce the GResilience framework, which provides recovery strategies through multi-objective optimization (one-agent), game-theoretic decision-making (two-agent), and reinforcement learning (RL-agent). We also design a measurement framework to quantify resilience and greenness. Empirical evaluation uses real and simulated experiments with a collaborative robot learning object classification from human demonstrations. Results show that the resilience model captures performance transitions during disruptions, and that GResilience policies improve green recovery by shortening recovery time, stabilizing performance, and reducing human dependency. RL-agent policies achieve the strongest results, although with a marginal increase in CO2 emissions. We also observe catastrophic forgetting after repeated disruptions, while our policies help maintain steadiness. A comparison with containerized execution shows that containerization cuts CO2 emissions by half. Overall, this research provides models, metrics, and policies that ensure the green recovery of OL-CAIS.",
      "pdf_url": "https://arxiv.org/pdf/2511.16593v1",
      "published": "2025-11-20T17:46:41+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.16593v1",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CV",
        "cs.RO"
      ]
    },
    {
      "title": "D-GARA: A Dynamic Benchmarking Framework for GUI Agent Robustness in Real-World Anomalies",
      "authors": [
        "Sen Chen",
        "Tong Zhao",
        "Yi Bin",
        "Fei Ma",
        "Wenqi Shao",
        "Zheng Wang"
      ],
      "abstract": "Developing intelligent agents capable of operating a wide range of Graphical User Interfaces (GUIs) with human-level proficiency is a key milestone on the path toward Artificial General Intelligence. While most existing datasets and benchmarks for training and evaluating GUI agents are static and idealized, failing to reflect the complexity and unpredictability of real-world environments, particularly the presence of anomalies. To bridge this research gap, we propose D-GARA, a dynamic benchmarking framework, to evaluate Android GUI agent robustness in real-world anomalies. D-GARA introduces a diverse set of real-world anomalies that GUI agents commonly face in practice, including interruptions such as permission dialogs, battery warnings, and update prompts. Based on D-GARA framework, we construct and annotate a benchmark featuring commonly used Android applications with embedded anomalies to support broader community research. Comprehensive experiments and results demonstrate substantial performance degradation in state-of-the-art GUI agents when exposed to anomaly-rich environments, highlighting the need for robustness-aware learning. D-GARA is modular and extensible, supporting the seamless integration of new tasks, anomaly types, and interaction scenarios to meet specific evaluation goals.",
      "pdf_url": "https://arxiv.org/pdf/2511.16590v1",
      "published": "2025-11-20T17:43:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.16590v1",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Formal Abductive Latent Explanations for Prototype-Based Networks",
      "authors": [
        "Jules Soria",
        "Zakaria Chihani",
        "Julien Girard-Satabin",
        "Alban Grastien",
        "Romain Xu-Darme",
        "Daniela Cancila"
      ],
      "abstract": "Case-based reasoning networks are machine-learning models that make predictions based on similarity between the input and prototypical parts of training samples, called prototypes. Such models are able to explain each decision by pointing to the prototypes that contributed the most to the final outcome. As the explanation is a core part of the prediction, they are often qualified as ``interpretable by design\". While promising, we show that such explanations are sometimes misleading, which hampers their usefulness in safety-critical contexts. In particular, several instances may lead to different predictions and yet have the same explanation. Drawing inspiration from the field of formal eXplainable AI (FXAI), we propose Abductive Latent Explanations (ALEs), a formalism to express sufficient conditions on the intermediate (latent) representation of the instance that imply the prediction. Our approach combines the inherent interpretability of case-based reasoning models and the guarantees provided by formal XAI. We propose a solver-free and scalable algorithm for generating ALEs based on three distinct paradigms, compare them, and present the feasibility of our approach on diverse datasets for both standard and fine-grained image classification. The associated code can be found at https://github.com/julsoria/ale",
      "pdf_url": "https://arxiv.org/pdf/2511.16588v1",
      "published": "2025-11-20T17:42:41+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.16588v1",
      "categories": [
        "cs.AI",
        "cs.LO"
      ]
    },
    {
      "title": "Consciousness in Artificial Intelligence? A Framework for Classifying Objections and Constraints",
      "authors": [
        "Andres Campero",
        "Derek Shiller",
        "Jaan Aru",
        "Jonathan Simon"
      ],
      "abstract": "We develop a taxonomical framework for classifying challenges to the possibility of consciousness in digital artificial intelligence systems. This framework allows us to identify the level of granularity at which a given challenge is intended (the levels we propose correspond to Marr's levels) and to disambiguate its degree of force: is it a challenge to computational functionalism that leaves the possibility of digital consciousness open (degree 1), a practical challenge to digital consciousness that suggests improbability without claiming impossibility (degree 2), or an argument claiming that digital consciousness is strictly impossible (degree 3)? We apply this framework to 14 prominent examples from the scientific and philosophical literature. Our aim is not to take a side in the debate, but to provide structure and a tool for disambiguating between challenges to computational functionalism and challenges to digital consciousness, as well as between different ways of parsing such challenges.",
      "pdf_url": "https://arxiv.org/pdf/2511.16582v1",
      "published": "2025-11-20T17:36:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.16582v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Synthesis of Safety Specifications for Probabilistic Systems",
      "authors": [
        "Gaspard Ohlmann",
        "Edwin Hamel-De le Court",
        "Francesco Belardinelli"
      ],
      "abstract": "Ensuring that agents satisfy safety specifications can be crucial in safety-critical environments. While methods exist for controller synthesis with safe temporal specifications, most existing methods restrict safe temporal specifications to probabilistic-avoidance constraints. Formal methods typically offer more expressive ways to express safety in probabilistic systems, such as Probabilistic Computation Tree Logic (PCTL) formulas. Thus, in this paper, we develop a new approach that supports more general temporal properties expressed in PCTL. Our contribution is twofold. First, we develop a theoretical framework for the Synthesis of safe-PCTL specifications. We show how the reducing global specification satisfaction to local constraints, and define CPCTL, a fragment of safe-PCTL. We demonstrate how the expressiveness of CPCTL makes it a relevant fragment for the Synthesis Problem. Second, we leverage these results and propose a new Value Iteration-based algorithm to solve the synthesis problem for these more general temporal properties, and we prove the soundness and completeness of our method.",
      "pdf_url": "https://arxiv.org/pdf/2511.16579v1",
      "published": "2025-11-20T17:34:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.16579v1",
      "categories": [
        "cs.LO",
        "cs.AI",
        "cs.LG",
        "eess.SY"
      ]
    },
    {
      "title": "Integrating Symbolic Natural Language Understanding and Language Models for Word Sense Disambiguation",
      "authors": [
        "Kexin Zhao",
        "Ken Forbus"
      ],
      "abstract": "Word sense disambiguation is a fundamental challenge in natural language understanding. Current methods are primarily aimed at coarse-grained representations (e.g. WordNet synsets or FrameNet frames) and require hand-annotated training data to construct. This makes it difficult to automatically disambiguate richer representations (e.g. built on OpenCyc) that are needed for sophisticated inference. We propose a method that uses statistical language models as oracles for disambiguation that does not require any hand-annotation of training data. Instead, the multiple candidate meanings generated by a symbolic NLU system are converted into distinguishable natural language alternatives, which are used to query an LLM to select appropriate interpretations given the linguistic context. The selected meanings are propagated back to the symbolic NLU system. We evaluate our method against human-annotated gold answers to demonstrate its effectiveness.",
      "pdf_url": "https://arxiv.org/pdf/2511.16577v1",
      "published": "2025-11-20T17:32:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.16577v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "ECPv2: Fast, Efficient, and Scalable Global Optimization of Lipschitz Functions",
      "authors": [
        "Fares Fourati",
        "Mohamed-Slim Alouini",
        "Vaneet Aggarwal"
      ],
      "abstract": "We propose ECPv2, a scalable and theoretically grounded algorithm for global optimization of Lipschitz-continuous functions with unknown Lipschitz constants. Building on the Every Call is Precious (ECP) framework, which ensures that each accepted function evaluation is potentially informative, ECPv2 addresses key limitations of ECP, including high computational cost and overly conservative early behavior. ECPv2 introduces three innovations: (i) an adaptive lower bound to avoid vacuous acceptance regions, (ii) a Worst-m memory mechanism that restricts comparisons to a fixed-size subset of past evaluations, and (iii) a fixed random projection to accelerate distance computations in high dimensions. We theoretically show that ECPv2 retains ECP's no-regret guarantees with optimal finite-time bounds and expands the acceptance region with high probability. We further empirically validate these findings through extensive experiments and ablation studies. Using principled hyperparameter settings, we evaluate ECPv2 across a wide range of high-dimensional, non-convex optimization problems. Across benchmarks, ECPv2 consistently matches or outperforms state-of-the-art optimizers, while significantly reducing wall-clock time.",
      "pdf_url": "https://arxiv.org/pdf/2511.16575v1",
      "published": "2025-11-20T17:30:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.16575v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC",
        "stat.ML"
      ]
    },
    {
      "title": "NutriScreener: Retrieval-Augmented Multi-Pose Graph Attention Network for Malnourishment Screening",
      "authors": [
        "Misaal Khan",
        "Mayank Vatsa",
        "Kuldeep Singh",
        "Richa Singh"
      ],
      "abstract": "Child malnutrition remains a global crisis, yet existing screening methods are laborious and poorly scalable, hindering early intervention. In this work, we present NutriScreener, a retrieval-augmented, multi-pose graph attention network that combines CLIP-based visual embeddings, class-boosted knowledge retrieval, and context awareness to enable robust malnutrition detection and anthropometric prediction from children's images, simultaneously addressing generalizability and class imbalance. In a clinical study, doctors rated it 4.3/5 for accuracy and 4.6/5 for efficiency, confirming its deployment readiness in low-resource settings. Trained and tested on 2,141 children from AnthroVision and additionally evaluated on diverse cross-continent populations, including ARAN and an in-house collected CampusPose dataset, it achieves 0.79 recall, 0.82 AUC, and significantly lower anthropometric RMSEs, demonstrating reliable measurement in unconstrained pediatric settings. Cross-dataset results show up to 25% recall gain and up to 3.5 cm RMSE reduction using demographically matched knowledge bases. NutriScreener offers a scalable and accurate solution for early malnutrition detection in low-resource environments.",
      "pdf_url": "https://arxiv.org/pdf/2511.16566v1",
      "published": "2025-11-20T17:20:42+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.16566v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Interfacial and bulk switching MoS2 memristors for an all-2D reservoir computing framework",
      "authors": [
        "Asmita S. Thool",
        "Sourodeep Roy",
        "Prahalad Kanti Barman",
        "Kartick Biswas",
        "Pavan Nukala",
        "Abhishek Misra",
        "Saptarshi Das",
        "and Bhaswar Chakrabarti"
      ],
      "abstract": "In this study, we design a reservoir computing (RC) network by exploiting short- and long-term memory dynamics in Au/Ti/MoS$_2$/Au memristive devices. The temporal dynamics is engineered by controlling the thickness of the Chemical Vapor Deposited (CVD) MoS$_2$ films. Devices with a monolayer (1L)-MoS$_2$ film exhibit volatile (short-term memory) switching dynamics. We also report non-volatile resistance switching with excellent uniformity and analog behavior in conductance tuning for the multilayer (ML) MoS$_2$ memristive devices. We correlate this performance with trap-assisted space-charge limited conduction (SCLC) mechanism, leading to a bulk-limited resistance switching behavior. Four-bit reservoir states are generated using volatile memristors. The readout layer is implemented with an array of nonvolatile synapses. This small RC network achieves 89.56\\% precision in a spoken-digit recognition task and is also used to analyze a nonlinear time series equation.",
      "pdf_url": "https://arxiv.org/pdf/2511.16557v1",
      "published": "2025-11-20T17:11:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.16557v1",
      "categories": [
        "cs.ET",
        "cs.AI"
      ]
    },
    {
      "title": "Utilizing Large Language Models for Zero-Shot Medical Ontology Extension from Clinical Notes",
      "authors": [
        "Guanchen Wu",
        "Yuzhang Xie",
        "Huanwei Wu",
        "Zhe He",
        "Hui Shao",
        "Xiao Hu",
        "Carl Yang"
      ],
      "abstract": "Integrating novel medical concepts and relationships into existing ontologies can significantly enhance their coverage and utility for both biomedical research and clinical applications. Clinical notes, as unstructured documents rich with detailed patient observations, offer valuable context-specific insights and represent a promising yet underutilized source for ontology extension. Despite this potential, directly leveraging clinical notes for ontology extension remains largely unexplored. To address this gap, we propose CLOZE, a novel framework that uses large language models (LLMs) to automatically extract medical entities from clinical notes and integrate them into hierarchical medical ontologies. By capitalizing on the strong language understanding and extensive biomedical knowledge of pre-trained LLMs, CLOZE effectively identifies disease-related concepts and captures complex hierarchical relationships. The zero-shot framework requires no additional training or labeled data, making it a cost-efficient solution. Furthermore, CLOZE ensures patient privacy through automated removal of protected health information (PHI). Experimental results demonstrate that CLOZE provides an accurate, scalable, and privacy-preserving ontology extension framework, with strong potential to support a wide range of downstream applications in biomedical research and clinical informatics.",
      "pdf_url": "https://arxiv.org/pdf/2511.16548v1",
      "published": "2025-11-20T17:00:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.16548v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "WER is Unaware: Assessing How ASR Errors Distort Clinical Understanding in Patient Facing Dialogue",
      "authors": [
        "Zachary Ellis",
        "Jared Joselowitz",
        "Yash Deo",
        "Yajie He",
        "Anna Kalygina",
        "Aisling Higham",
        "Mana Rahimzadeh",
        "Yan Jia",
        "Ibrahim Habli",
        "Ernest Lim"
      ],
      "abstract": "As Automatic Speech Recognition (ASR) is increasingly deployed in clinical dialogue, standard evaluations still rely heavily on Word Error Rate (WER). This paper challenges that standard, investigating whether WER or other common metrics correlate with the clinical impact of transcription errors. We establish a gold-standard benchmark by having expert clinicians compare ground-truth utterances to their ASR-generated counterparts, labeling the clinical impact of any discrepancies found in two distinct doctor-patient dialogue datasets. Our analysis reveals that WER and a comprehensive suite of existing metrics correlate poorly with the clinician-assigned risk labels (No, Minimal, or Significant Impact). To bridge this evaluation gap, we introduce an LLM-as-a-Judge, programmatically optimized using GEPA to replicate expert clinical assessment. The optimized judge (Gemini-2.5-Pro) achieves human-comparable performance, obtaining 90% accuracy and a strong Cohen's $κ$ of 0.816. This work provides a validated, automated framework for moving ASR evaluation beyond simple textual fidelity to a necessary, scalable assessment of safety in clinical dialogue.",
      "pdf_url": "https://arxiv.org/pdf/2511.16544v1",
      "published": "2025-11-20T16:59:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.16544v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "The Oracle and The Prism: A Decoupled and Efficient Framework for Generative Recommendation Explanation",
      "authors": [
        "Jiaheng Zhang",
        "Daqiang Zhang"
      ],
      "abstract": "The integration of Large Language Models (LLMs) into explainable recommendation systems often leads to a performance-efficiency trade-off in end-to-end architectures, where joint optimization of ranking and explanation can result in suboptimal compromises. To resolve this, we propose Prism, a novel decoupled framework that rigorously separates the recommendation process into a dedicated ranking stage and an explanation generation stage.\n  Inspired by knowledge distillation, Prism leverages a powerful teacher LLM (e.g., FLAN-T5-XXL) as an Oracle to produce high-fidelity explanatory knowledge. A compact, fine-tuned student model (e.g., BART-Base), the Prism, then specializes in synthesizing this knowledge into personalized explanations. This decomposition ensures that each component is optimized for its specific objective, eliminating inherent conflicts in coupled models.\n  Extensive experiments on benchmark datasets demonstrate that our 140M-parameter Prism model significantly outperforms its 11B-parameter teacher in human evaluations of faithfulness and personalization, while achieving a 24 times speedup and a 10 times reduction in memory consumption during inference. These results validate that decoupling, coupled with targeted distillation, provides an efficient and effective pathway to high-quality explainable recommendation.",
      "pdf_url": "https://arxiv.org/pdf/2511.16543v1",
      "published": "2025-11-20T16:59:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.16543v1",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    },
    {
      "title": "Supervised Contrastive Learning for Few-Shot AI-Generated Image Detection and Attribution",
      "authors": [
        "Jaime Álvarez Urueña",
        "David Camacho",
        "Javier Huertas Tato"
      ],
      "abstract": "The rapid advancement of generative artificial intelligence has enabled the creation of synthetic images that are increasingly indistinguishable from authentic content, posing significant challenges for digital media integrity. This problem is compounded by the accelerated release cycle of novel generative models, which renders traditional detection approaches (reliant on periodic retraining) computationally infeasible and operationally impractical.\n  This work proposes a novel two-stage detection framework designed to address the generalization challenge inherent in synthetic image detection. The first stage employs a vision deep learning model trained via supervised contrastive learning to extract discriminative embeddings from input imagery. Critically, this model was trained on a strategically partitioned subset of available generators, with specific architectures withheld from training to rigorously ablate cross-generator generalization capabilities. The second stage utilizes a k-nearest neighbors (k-NN) classifier operating on the learned embedding space, trained in a few-shot learning paradigm incorporating limited samples from previously unseen test generators.\n  With merely 150 images per class in the few-shot learning regime, which are easily obtainable from current generation models, the proposed framework achieves an average detection accuracy of 91.3\\%, representing a 5.2 percentage point improvement over existing approaches . For the source attribution task, the proposed approach obtains improvements of of 14.70\\% and 4.27\\% in AUC and OSCR respectively on an open set classification context, marking a significant advancement toward robust, scalable forensic attribution systems capable of adapting to the evolving generative AI landscape without requiring exhaustive retraining protocols.",
      "pdf_url": "https://arxiv.org/pdf/2511.16541v1",
      "published": "2025-11-20T16:53:24+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.16541v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "TurkColBERT: A Benchmark of Dense and Late-Interaction Models for Turkish Information Retrieval",
      "authors": [
        "Özay Ezerceli",
        "Mahmoud El Hussieni",
        "Selva Taş",
        "Reyhan Bayraktar",
        "Fatma Betül Terzioğlu",
        "Yusuf Çelebi",
        "Yağız Asker"
      ],
      "abstract": "Neural information retrieval systems excel in high-resource languages but remain underexplored for morphologically rich, lower-resource languages such as Turkish. Dense bi-encoders currently dominate Turkish IR, yet late-interaction models -- which retain token-level representations for fine-grained matching -- have not been systematically evaluated. We introduce TurkColBERT, the first comprehensive benchmark comparing dense encoders and late-interaction models for Turkish retrieval. Our two-stage adaptation pipeline fine-tunes English and multilingual encoders on Turkish NLI/STS tasks, then converts them into ColBERT-style retrievers using PyLate trained on MS MARCO-TR. We evaluate 10 models across five Turkish BEIR datasets covering scientific, financial, and argumentative domains. Results show strong parameter efficiency: the 1.0M-parameter colbert-hash-nano-tr is 600$\\times$ smaller than the 600M turkish-e5-large dense encoder while preserving over 71\\% of its average mAP. Late-interaction models that are 3--5$\\times$ smaller than dense encoders significantly outperform them; ColmmBERT-base-TR yields up to +13.8\\% mAP on domain-specific tasks. For production-readiness, we compare indexing algorithms: MUVERA+Rerank is 3.33$\\times$ faster than PLAID and offers +1.7\\% relative mAP gain. This enables low-latency retrieval, with ColmmBERT-base-TR achieving 0.54 ms query times under MUVERA. We release all checkpoints, configs, and evaluation scripts. Limitations include reliance on moderately sized datasets ($\\leq$50K documents) and translated benchmarks, which may not fully reflect real-world Turkish retrieval conditions; larger-scale MUVERA evaluations remain necessary.",
      "pdf_url": "https://arxiv.org/pdf/2511.16528v1",
      "published": "2025-11-20T16:42:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.16528v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ]
    },
    {
      "title": "ODE-ViT: Plug & Play Attention Layer from the Generalization of the ViT as an Ordinary Differential Equation",
      "authors": [
        "Carlos Boned Riera",
        "David Romero Sanchez",
        "Oriol Ramos Terrades"
      ],
      "abstract": "In recent years, increasingly large models have achieved outstanding performance across CV tasks. However, these models demand substantial computational resources and storage, and their growing complexity limits our understanding of how they make decisions. Most of these architectures rely on the attention mechanism within Transformer-based designs. Building upon the connection between residual neural networks and ordinary differential equations (ODEs), we introduce ODE-ViT, a Vision Transformer reformulated as an ODE system that satisfies the conditions for well-posed and stable dynamics. Experiments on CIFAR-10 and CIFAR-100 demonstrate that ODE-ViT achieves stable, interpretable, and competitive performance with up to one order of magnitude fewer parameters, surpassing prior ODE-based Transformer approaches in classification tasks. We further propose a plug-and-play teacher-student framework in which a discrete ViT guides the continuous trajectory of ODE-ViT by treating the intermediate representations of the teacher as solutions of the ODE. This strategy improves performance by more than 10% compared to training a free ODE-ViT from scratch.",
      "pdf_url": "https://arxiv.org/pdf/2511.16501v1",
      "published": "2025-11-20T16:19:41+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.16501v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Physics-Informed Machine Learning for Efficient Sim-to-Real Data Augmentation in Micro-Object Pose Estimation",
      "authors": [
        "Zongcai Tan",
        "Lan Wei",
        "Dandan Zhang"
      ],
      "abstract": "Precise pose estimation of optical microrobots is essential for enabling high-precision object tracking and autonomous biological studies. However, current methods rely heavily on large, high-quality microscope image datasets, which are difficult and costly to acquire due to the complexity of microrobot fabrication and the labour-intensive labelling. Digital twin systems offer a promising path for sim-to-real data augmentation, yet existing techniques struggle to replicate complex optical microscopy phenomena, such as diffraction artifacts and depth-dependent imaging.This work proposes a novel physics-informed deep generative learning framework that, for the first time, integrates wave optics-based physical rendering and depth alignment into a generative adversarial network (GAN), to synthesise high-fidelity microscope images for microrobot pose estimation efficiently. Our method improves the structural similarity index (SSIM) by 35.6% compared to purely AI-driven methods, while maintaining real-time rendering speeds (0.022 s/frame).The pose estimator (CNN backbone) trained on our synthetic data achieves 93.9%/91.9% (pitch/roll) accuracy, just 5.0%/5.4% (pitch/roll) below that of an estimator trained exclusively on real data. Furthermore, our framework generalises to unseen poses, enabling data augmentation and robust pose estimation for novel microrobot configurations without additional training data.",
      "pdf_url": "https://arxiv.org/pdf/2511.16494v1",
      "published": "2025-11-20T16:10:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.16494v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "LLM4EO: Large Language Model for Evolutionary Optimization in Flexible Job Shop Scheduling",
      "authors": [
        "Rongjie Liao",
        "Junhao Qiu",
        "Xin Chen",
        "Xiaoping Li"
      ],
      "abstract": "Customized static operator design has enabled widespread application of Evolutionary Algorithms (EAs), but their search performance is transient during iterations and prone to degradation. Dynamic operators aim to address this but typically rely on predefined designs and localized parameter control during the search process, lacking adaptive optimization throughout evolution. To overcome these limitations, this work leverages Large Language Models (LLMs) to perceive evolutionary dynamics and enable operator-level meta-evolution. The proposed framework, LLMs for Evolutionary Optimization (LLM4EO), comprises three components: knowledge-transfer-based operator design, evolution perception and analysis, and adaptive operator evolution. Firstly, initialization of operators is performed by transferring the strengths of classical operators via LLMs. Then, search preferences and potential limitations of operators are analyzed by integrating fitness performance and evolutionary features, accompanied by corresponding suggestions for improvement. Upon stagnation of population evolution, gene selection priorities of operators are dynamically optimized via improvement prompting strategies. This approach achieves co-evolution of populations and operators in the search, introducing a novel paradigm for enhancing the efficiency and adaptability of EAs. Finally, a series of validations on multiple benchmark datasets of the flexible job shop scheduling problem demonstrate that LLM4EO accelerates population evolution and outperforms both mainstream evolutionary programming and traditional EAs.",
      "pdf_url": "https://arxiv.org/pdf/2511.16485v1",
      "published": "2025-11-20T15:56:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.16485v1",
      "categories": [
        "cs.NE",
        "cs.AI"
      ]
    },
    {
      "title": "Large Language Model-Based Reward Design for Deep Reinforcement Learning-Driven Autonomous Cyber Defense",
      "authors": [
        "Sayak Mukherjee",
        "Samrat Chatterjee",
        "Emilie Purvine",
        "Ted Fujimoto",
        "Tegan Emerson"
      ],
      "abstract": "Designing rewards for autonomous cyber attack and defense learning agents in a complex, dynamic environment is a challenging task for subject matter experts. We propose a large language model (LLM)-based reward design approach to generate autonomous cyber defense policies in a deep reinforcement learning (DRL)-driven experimental simulation environment. Multiple attack and defense agent personas were crafted, reflecting heterogeneity in agent actions, to generate LLM-guided reward designs where the LLM was first provided with contextual cyber simulation environment information. These reward structures were then utilized within a DRL-driven attack-defense simulation environment to learn an ensemble of cyber defense policies. Our results suggest that LLM-guided reward designs can lead to effective defense strategies against diverse adversarial behaviors.",
      "pdf_url": "https://arxiv.org/pdf/2511.16483v1",
      "published": "2025-11-20T15:54:08+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.16483v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ]
    },
    {
      "title": "Correlation-Aware Feature Attribution Based Explainable AI",
      "authors": [
        "Poushali Sengupta",
        "Yan Zhang",
        "Frank Eliassen",
        "Sabita Maharjan"
      ],
      "abstract": "Explainable AI (XAI) is increasingly essential as modern models become more complex and high-stakes applications demand transparency, trust, and regulatory compliance. Existing global attribution methods often incur high computational costs, lack stability under correlated inputs, and fail to scale efficiently to large or heterogeneous datasets. We address these gaps with \\emph{ExCIR} (Explainability through Correlation Impact Ratio), a correlation-aware attribution score equipped with a lightweight transfer protocol that reproduces full-model rankings using only a fraction of the data. ExCIR quantifies sign-aligned co-movement between features and model outputs after \\emph{robust centering} (subtracting a robust location estimate, e.g., median or mid-mean, from features and outputs). We further introduce \\textsc{BlockCIR}, a \\emph{groupwise} extension of ExCIR that scores \\emph{sets} of correlated features as a single unit. By aggregating the same signed-co-movement numerators and magnitudes over predefined or data-driven groups, \\textsc{BlockCIR} mitigates double-counting in collinear clusters (e.g., synonyms or duplicated sensors) and yields smoother, more stable rankings when strong dependencies are present. Across diverse text, tabular, signal, and image datasets, ExCIR shows trustworthy agreement with established global baselines and the full model, delivers consistent top-$k$ rankings across settings, and reduces runtime via lightweight evaluation on a subset of rows. Overall, ExCIR provides \\emph{computationally efficient}, \\emph{consistent}, and \\emph{scalable} explainability for real-world deployment.",
      "pdf_url": "https://arxiv.org/pdf/2511.16482v1",
      "published": "2025-11-20T15:51:00+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.16482v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ]
    },
    {
      "title": "Anatomy of an Idiom: Tracing Non-Compositionality in Language Models",
      "authors": [
        "Andrew Gomes"
      ],
      "abstract": "We investigate the processing of idiomatic expressions in transformer-based language models using a novel set of techniques for circuit discovery and analysis. First discovering circuits via a modified path patching algorithm, we find that idiom processing exhibits distinct computational patterns. We identify and investigate ``Idiom Heads,'' attention heads that frequently activate across different idioms, as well as enhanced attention between idiom tokens due to earlier processing, which we term ``augmented reception.'' We analyze these phenomena and the general features of the discovered circuits as mechanisms by which transformers balance computational efficiency and robustness. Finally, these findings provide insights into how transformers handle non-compositional language and suggest pathways for understanding the processing of more complex grammatical constructions.",
      "pdf_url": "https://arxiv.org/pdf/2511.16467v1",
      "published": "2025-11-20T15:35:50+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.16467v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "VLA-Pruner: Temporal-Aware Dual-Level Visual Token Pruning for Efficient Vision-Language-Action Inference",
      "authors": [
        "Ziyan Liu",
        "Yeqiu Chen",
        "Hongyi Cai",
        "Tao Lin",
        "Shuo Yang",
        "Zheng Liu",
        "Bo Zhao"
      ],
      "abstract": "Vision-Language-Action (VLA) models have shown great promise for embodied AI, yet the heavy computational cost of processing continuous visual streams severely limits their real-time deployment. Token pruning (keeping salient visual tokens and dropping redundant ones) has emerged as an effective approach for accelerating Vision-Language Models (VLMs), offering a solution for efficient VLA. However, these VLM-specific token pruning methods select tokens based solely on semantic salience metrics (e.g., prefill attention), while overlooking the VLA's intrinsic dual-system nature of high-level semantic understanding and low-level action execution. Consequently, these methods bias token retention toward semantic cues, discard critical information for action generation, and significantly degrade VLA performance. To bridge this gap, we propose VLA-Pruner, a versatile plug-and-play VLA-specific token prune method that aligns with the dual-system nature of VLA models and exploits the temporal continuity in robot manipulation. Specifically, VLA-Pruner adopts a dual-level importance criterion for visual token retention: vision-language prefill attention for semantic-level relevance and action decode attention, estimated via temporal smoothing, for action-level importance. Based on this criterion, VLA-Pruner proposes a novel dual-level token selection strategy that adaptively preserves a compact, informative set of visual tokens for both semantic understanding and action execution under given compute budget. Experiments show that VLA-Pruner achieves state-of-the-art performance across multiple VLA architectures and diverse robotic tasks.",
      "pdf_url": "https://arxiv.org/pdf/2511.16449v1",
      "published": "2025-11-20T15:16:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.16449v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "PersonaDrift: A Benchmark for Temporal Anomaly Detection in Language-Based Dementia Monitoring",
      "authors": [
        "Joy Lai",
        "Alex Mihailidis"
      ],
      "abstract": "People living with dementia (PLwD) often show gradual shifts in how they communicate, becoming less expressive, more repetitive, or drifting off-topic in subtle ways. While caregivers may notice these changes informally, most computational tools are not designed to track such behavioral drift over time. This paper introduces PersonaDrift, a synthetic benchmark designed to evaluate machine learning and statistical methods for detecting progressive changes in daily communication, focusing on user responses to a digital reminder system. PersonaDrift simulates 60-day interaction logs for synthetic users modeled after real PLwD, based on interviews with caregivers. These caregiver-informed personas vary in tone, modality, and communication habits, enabling realistic diversity in behavior. The benchmark focuses on two forms of longitudinal change that caregivers highlighted as particularly salient: flattened sentiment (reduced emotional tone and verbosity) and off-topic replies (semantic drift). These changes are injected progressively at different rates to emulate naturalistic cognitive trajectories, and the framework is designed to be extensible to additional behaviors in future use cases. To explore this novel application space, we evaluate several anomaly detection approaches, unsupervised statistical methods (CUSUM, EWMA, One-Class SVM), sequence models using contextual embeddings (GRU + BERT), and supervised classifiers in both generalized and personalized settings. Preliminary results show that flattened sentiment can often be detected with simple statistical models in users with low baseline variability, while detecting semantic drift requires temporal modeling and personalized baselines. Across both tasks, personalized classifiers consistently outperform generalized ones, highlighting the importance of individual behavioral context.",
      "pdf_url": "https://arxiv.org/pdf/2511.16445v1",
      "published": "2025-11-20T15:15:00+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.16445v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "From generative AI to the brain: five takeaways",
      "authors": [
        "Claudius Gros"
      ],
      "abstract": "The big strides seen in generative AI are not based on somewhat obscure algorithms, but due to clearly defined generative principles. The resulting concrete implementations have proven themselves in large numbers of applications. We suggest that it is imperative to thoroughly investigate which of these generative principles may be operative also in the brain, and hence relevant for cognitive neuroscience. In addition, ML research led to a range of interesting characterizations of neural information processing systems. We discuss five examples, the shortcomings of world modelling, the generation of thought processes, attention, neural scaling laws, and quantization, that illustrate how much neuroscience could potentially learn from ML research.",
      "pdf_url": "https://arxiv.org/pdf/2511.16432v1",
      "published": "2025-11-20T15:00:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.16432v1",
      "categories": [
        "cs.AI",
        "q-bio.NC"
      ]
    },
    {
      "title": "Generative Modeling of Clinical Time Series via Latent Stochastic Differential Equations",
      "authors": [
        "Muhammad Aslanimoghanloo",
        "Ahmed ElGazzar",
        "Marcel van Gerven"
      ],
      "abstract": "Clinical time series data from electronic health records and medical registries offer unprecedented opportunities to understand patient trajectories and inform medical decision-making. However, leveraging such data presents significant challenges due to irregular sampling, complex latent physiology, and inherent uncertainties in both measurements and disease progression. To address these challenges, we propose a generative modeling framework based on latent neural stochastic differential equations (SDEs) that views clinical time series as discrete-time partial observations of an underlying controlled stochastic dynamical system. Our approach models latent dynamics via neural SDEs with modality-dependent emission models, while performing state estimation and parameter learning through variational inference. This formulation naturally handles irregularly sampled observations, learns complex non-linear interactions, and captures the stochasticity of disease progression and measurement noise within a unified scalable probabilistic framework. We validate the framework on two complementary tasks: (i) individual treatment effect estimation using a simulated pharmacokinetic-pharmacodynamic (PKPD) model of lung cancer, and (ii) probabilistic forecasting of physiological signals using real-world intensive care unit (ICU) data from 12,000 patients. Results show that our framework outperforms ordinary differential equation and long short-term memory baseline models in accuracy and uncertainty estimation. These results highlight its potential for enabling precise, uncertainty-aware predictions to support clinical decision-making.",
      "pdf_url": "https://arxiv.org/pdf/2511.16427v1",
      "published": "2025-11-20T14:50:49+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.16427v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "TOFA: Training-Free One-Shot Federated Adaptation for Vision-Language Models",
      "authors": [
        "Li Zhang",
        "Zhongxuan Han",
        "XiaoHua Feng",
        "Jiaming Zhang",
        "Yuyuan Li",
        "Linbo Jiang",
        "Jianan Lin",
        "Chaochao Chen"
      ],
      "abstract": "Efficient and lightweight adaptation of pre-trained Vision-Language Models (VLMs) to downstream tasks through collaborative interactions between local clients and a central server is a rapidly emerging research topic in federated learning. Existing adaptation algorithms are typically trained iteratively, which incur significant communication costs and increase the susceptibility to potential attacks. Motivated by the one-shot federated training techniques that reduce client-server exchanges to a single round, developing a lightweight one-shot federated VLM adaptation method to alleviate these issues is particularly attractive. However, current one-shot approaches face certain challenges in adapting VLMs within federated settings: (1) insufficient exploitation of the rich multimodal information inherent in VLMs; (2) lack of specialized adaptation strategies to systematically handle the severe data heterogeneity; and (3) requiring additional training resource of clients or server. To bridge these gaps, we propose a novel Training-free One-shot Federated Adaptation framework for VLMs, named TOFA. To fully leverage the generalizable multimodal features in pre-trained VLMs, TOFA employs both visual and textual pipelines to extract task-relevant representations. In the visual pipeline, a hierarchical Bayesian model learns personalized, class-specific prototype distributions. For the textual pipeline, TOFA evaluates and globally aligns the generated local text prompts for robustness. An adaptive weight calibration mechanism is also introduced to combine predictions from both modalities, balancing personalization and robustness to handle data heterogeneity. Our method is training-free, not relying on additional training resources on either the client or server side. Extensive experiments across 9 datasets in various federated settings demonstrate the effectiveness of the proposed TOFA method.",
      "pdf_url": "https://arxiv.org/pdf/2511.16423v1",
      "published": "2025-11-20T14:45:59+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.16423v1",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Pharos-ESG: A Framework for Multimodal Parsing, Contextual Narration, and Hierarchical Labeling of ESG Report",
      "authors": [
        "Yan Chen",
        "Yu Zou",
        "Jialei Zeng",
        "Haoran You",
        "Xiaorui Zhou",
        "Aixi Zhong"
      ],
      "abstract": "Environmental, Social, and Governance (ESG) principles are reshaping the foundations of global financial gover- nance, transforming capital allocation architectures, regu- latory frameworks, and systemic risk coordination mecha- nisms. However, as the core medium for assessing corpo- rate ESG performance, the ESG reports present significant challenges for large-scale understanding, due to chaotic read- ing order from slide-like irregular layouts and implicit hier- archies arising from lengthy, weakly structured content. To address these challenges, we propose Pharos-ESG, a uni- fied framework that transforms ESG reports into structured representations through multimodal parsing, contextual nar- ration, and hierarchical labeling. It integrates a reading-order modeling module based on layout flow, hierarchy-aware seg- mentation guided by table-of-contents anchors, and a multi- modal aggregation pipeline that contextually transforms vi- sual elements into coherent natural language. The framework further enriches its outputs with ESG, GRI, and sentiment labels, yielding annotations aligned with the analytical de- mands of financial research. Extensive experiments on anno- tated benchmarks demonstrate that Pharos-ESG consistently outperforms both dedicated document parsing systems and general-purpose multimodal models. In addition, we release Aurora-ESG, the first large-scale public dataset of ESG re- ports, spanning Mainland China, Hong Kong, and U.S. mar- kets, featuring unified structured representations of multi- modal content, enriched with fine-grained layout and seman- tic annotations to better support ESG integration in financial governance and decision-making.",
      "pdf_url": "https://arxiv.org/pdf/2511.16417v1",
      "published": "2025-11-20T14:41:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.16417v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Trustworthy AI in the Agentic Lakehouse: from Concurrency to Governance",
      "authors": [
        "Jacopo Tagliabue",
        "Federico Bianchi",
        "Ciro Greco"
      ],
      "abstract": "Even as AI capabilities improve, most enterprises do not consider agents trustworthy enough to work on production data. In this paper, we argue that the path to trustworthy agentic workflows begins with solving the infrastructure problem first: traditional lakehouses are not suited for agent access patterns, but if we design one around transactions, governance follows. In particular, we draw an operational analogy to MVCC in databases and show why a direct transplant fails in a decoupled, multi-language setting. We then propose an agent-first design, Bauplan, that reimplements data and compute isolation in the lakehouse. We conclude by sharing a reference implementation of a self-healing pipeline in Bauplan, which seamlessly couples agent reasoning with all the desired guarantees for correctness and trust.",
      "pdf_url": "https://arxiv.org/pdf/2511.16402v1",
      "published": "2025-11-20T14:21:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.16402v1",
      "categories": [
        "cs.AI",
        "cs.DB"
      ]
    },
    {
      "title": "Collaborative Management for Chronic Diseases and Depression: A Double Heterogeneity-based Multi-Task Learning Method",
      "authors": [
        "Yidong Chai",
        "Haoxin Liu",
        "Jiaheng Xie",
        "Chaopeng Wang",
        "Xiao Fang"
      ],
      "abstract": "Wearable sensor technologies and deep learning are transforming healthcare management. Yet, most health sensing studies focus narrowly on physical chronic diseases. This overlooks the critical need for joint assessment of comorbid physical chronic diseases and depression, which is essential for collaborative chronic care. We conceptualize multi-disease assessment, including both physical diseases and depression, as a multi-task learning (MTL) problem, where each disease assessment is modeled as a task. This joint formulation leverages inter-disease relationships to improve accuracy, but it also introduces the challenge of double heterogeneity: chronic diseases differ in their manifestation (disease heterogeneity), and patients with the same disease show varied patterns (patient heterogeneity). To address these issues, we first adopt existing techniques and propose a base method. Given the limitations of the base method, we further propose an Advanced Double Heterogeneity-based Multi-Task Learning (ADH-MTL) method that improves the base method through three innovations: (1) group-level modeling to support new patient predictions, (2) a decomposition strategy to reduce model complexity, and (3) a Bayesian network that explicitly captures dependencies while balancing similarities and differences across model components. Empirical evaluations on real-world wearable sensor data demonstrate that ADH-MTL significantly outperforms existing baselines, and each of its innovations is shown to be effective. This study contributes to health information systems by offering a computational solution for integrated physical and mental healthcare and provides design principles for advancing collaborative chronic disease management across the pre-treatment, treatment, and post-treatment phases.",
      "pdf_url": "https://arxiv.org/pdf/2511.16398v1",
      "published": "2025-11-20T14:15:27+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.16398v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "CorrectHDL: Agentic HDL Design with LLMs Leveraging High-Level Synthesis as Reference",
      "authors": [
        "Kangwei Xu",
        "Grace Li Zhang",
        "Ulf Schlichtmann",
        "Bing Li"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable potential in hardware front-end design using hardware description languages (HDLs). However, their inherent tendency toward hallucination often introduces functional errors into the generated HDL designs. To address this issue, we propose the framework CorrectHDL that leverages high-level synthesis (HLS) results as functional references to correct potential errors in LLM-generated HDL designs.The input to the proposed framework is a C/C++ program that specifies the target circuit's functionality. The program is provided to an LLM to directly generate an HDL design, whose syntax errors are repaired using a Retrieval-Augmented Generation (RAG) mechanism. The functional correctness of the LLM-generated circuit is iteratively improved by comparing its simulated behavior with an HLS reference design produced by conventional HLS tools, which ensures the functional correctness of the result but can lead to suboptimal area and power efficiency. Experimental results demonstrate that circuits generated by the proposed framework achieve significantly better area and power efficiency than conventional HLS designs and approach the quality of human-engineered circuits. Meanwhile, the correctness of the resulting HDL implementation is maintained, highlighting the effectiveness and potential of agentic HDL design leveraging the generative capabilities of LLMs and the rigor of traditional correctness-driven IC design flows.",
      "pdf_url": "https://arxiv.org/pdf/2511.16395v1",
      "published": "2025-11-20T14:13:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.16395v1",
      "categories": [
        "cs.AI",
        "cs.PL",
        "cs.SE",
        "eess.SY"
      ]
    },
    {
      "title": "Robot Metacognition: Decision Making with Confidence for Tool Invention",
      "authors": [
        "Ajith Anil Meera",
        "Poppy Collis",
        "Polina Arbuzova",
        "Abián Torres",
        "Paul F Kinghorn",
        "Ricardo Sanz",
        "Pablo Lanillos"
      ],
      "abstract": "Robots today often miss a key ingredient of truly intelligent behavior: the ability to reflect on their own cognitive processes and decisions. In humans, this self-monitoring or metacognition is crucial for learning, decision making and problem solving. For instance, they can evaluate how confident they are in performing a task, thus regulating their own behavior and allocating proper resources. Taking inspiration from neuroscience, we propose a robot metacognition architecture centered on confidence (a second-order judgment on decisions) and we demonstrate it on the use case of autonomous tool invention. We propose the use of confidence as a metacognitive measure within the robot decision making scheme. Confidence-informed robots can evaluate the reliability of their decisions, improving their robustness during real-world physical deployment. This form of robotic metacognition emphasizes embodied action monitoring as a means to achieve better informed decisions. We also highlight potential applications and research directions for robot metacognition.",
      "pdf_url": "https://arxiv.org/pdf/2511.16390v1",
      "published": "2025-11-20T14:10:07+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.16390v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "An Agent-Based Framework for the Automatic Validation of Mathematical Optimization Models",
      "authors": [
        "Alexander Zadorojniy",
        "Segev Wasserkrug",
        "Eitan Farchi"
      ],
      "abstract": "Recently, using Large Language Models (LLMs) to generate optimization models from natural language descriptions has became increasingly popular. However, a major open question is how to validate that the generated models are correct and satisfy the requirements defined in the natural language description. In this work, we propose a novel agent-based method for automatic validation of optimization models that builds upon and extends methods from software testing to address optimization modeling . This method consists of several agents that initially generate a problem-level testing API, then generate tests utilizing this API, and, lastly, generate mutations specific to the optimization model (a well-known software testing technique assessing the fault detection power of the test suite). In this work, we detail this validation framework and show, through experiments, the high quality of validation provided by this agent ensemble in terms of the well-known software testing measure called mutation coverage.",
      "pdf_url": "https://arxiv.org/pdf/2511.16383v1",
      "published": "2025-11-20T14:03:07+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.16383v1",
      "categories": [
        "cs.AI",
        "cs.SE"
      ]
    },
    {
      "title": "Are Foundation Models Useful for Bankruptcy Prediction?",
      "authors": [
        "Marcin Kostrzewa",
        "Oleksii Furman",
        "Roman Furman",
        "Sebastian Tomczak",
        "Maciej Zięba"
      ],
      "abstract": "Foundation models have shown promise across various financial applications, yet their effectiveness for corporate bankruptcy prediction remains systematically unevaluated against established methods. We study bankruptcy forecasting using Llama-3.3-70B-Instruct and TabPFN, evaluated on large, highly imbalanced datasets of over one million company records from the Visegrád Group. We provide the first systematic comparison of foundation models against classical machine learning baselines for this task. Our results show that models such as XGBoost and CatBoost consistently outperform foundation models across all prediction horizons. LLM-based approaches suffer from unreliable probability estimates, undermining their use in risk-sensitive financial settings. TabPFN, while competitive with simpler baselines, requires substantial computational resources with costs not justified by performance gains. These findings suggest that, despite their generality, current foundation models remain less effective than specialized methods for bankruptcy forecasting.",
      "pdf_url": "https://arxiv.org/pdf/2511.16375v1",
      "published": "2025-11-20T13:59:18+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.16375v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Reducing Instability in Synthetic Data Evaluation with a Super-Metric in MalDataGen",
      "authors": [
        "Anna Luiza Gomes da Silva",
        "Diego Kreutz",
        "Angelo Diniz",
        "Rodrigo Mansilha",
        "Celso Nobre da Fonseca"
      ],
      "abstract": "Evaluating the quality of synthetic data remains a persistent challenge in the Android malware domain due to instability and the lack of standardization among existing metrics. This work integrates into MalDataGen a Super-Metric that aggregates eight metrics across four fidelity dimensions, producing a single weighted score. Experiments involving ten generative models and five balanced datasets demonstrate that the Super-Metric is more stable and consistent than traditional metrics, exhibiting stronger correlations with the actual performance of classifiers.",
      "pdf_url": "https://arxiv.org/pdf/2511.16373v1",
      "published": "2025-11-20T13:55:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.16373v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Learning from Sufficient Rationales: Analysing the Relationship Between Explanation Faithfulness and Token-level Regularisation Strategies",
      "authors": [
        "Jonathan Kamp",
        "Lisa Beinborn",
        "Antske Fokkens"
      ],
      "abstract": "Human explanations of natural language, rationales, form a tool to assess whether models learn a label for the right reasons or rely on dataset-specific shortcuts. Sufficiency is a common metric for estimating the informativeness of rationales, but it provides limited insight into the effects of rationale information on model performance. We address this limitation by relating sufficiency to two modelling paradigms: the ability of models to identify which tokens are part of the rationale (through token classification) and the ability of improving model performance by incorporating rationales in the input (through attention regularisation). We find that highly informative rationales are not likely to help classify the instance correctly. Sufficiency conversely captures the classification impact of the non-rationalised context, which interferes with rationale information in the same input. We also find that incorporating rationale information in model inputs can boost cross-domain classification, but results are inconsistent per task and model type. Finally, sufficiency and token classification appear to be unrelated. These results exemplify the complexity of rationales, showing that metrics capable of systematically capturing this type of information merit further investigation.",
      "pdf_url": "https://arxiv.org/pdf/2511.16353v1",
      "published": "2025-11-20T13:39:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.16353v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "OpenMMReasoner: Pushing the Frontiers for Multimodal Reasoning with an Open and General Recipe",
      "authors": [
        "Kaichen Zhang",
        "Keming Wu",
        "Zuhao Yang",
        "Kairui Hu",
        "Bin Wang",
        "Ziwei Liu",
        "Xingxuan Li",
        "Lidong Bing"
      ],
      "abstract": "Recent advancements in large reasoning models have fueled growing interest in extending such capabilities to multimodal domains. However, despite notable progress in visual reasoning, the lack of transparent and reproducible data curation and training strategies remains a major barrier to scalable research. In this work, we introduce OpenMMReasoner, a fully transparent two-stage recipe for multimodal reasoning spanning supervised fine-tuning (SFT) and reinforcement learning (RL). In the SFT stage, we construct an 874K-sample cold-start dataset with rigorous step-by-step validation, providing a strong foundation for reasoning capabilities. The subsequent RL stage leverages a 74K-sample dataset across diverse domains to further sharpen and stabilize these abilities, resulting in a more robust and efficient learning process. Extensive evaluations demonstrate that our training recipe not only surpasses strong baselines but also highlights the critical role of data quality and training design in shaping multimodal reasoning performance. Notably, our method achieves a 11.6% improvement over the Qwen2.5-VL-7B-Instruct baseline across nine multimodal reasoning benchmarks, establishing a solid empirical foundation for future large-scale multimodal reasoning research. We open-sourced all our codes, pipeline, and data at https://github.com/EvolvingLMMs-Lab/OpenMMReasoner.",
      "pdf_url": "https://arxiv.org/pdf/2511.16334v1",
      "published": "2025-11-20T13:11:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2511.16334v1",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    }
  ]
}