{
  "last_updated": "2025-02-13T04:38:37.489101",
  "papers": [
    {
      "title": "Rhythmic sharing: A bio-inspired paradigm for zero-shot adaptation and learning in neural networks",
      "authors": [
        "Hoony Kang",
        "Wolfgang Losert"
      ],
      "abstract": "The brain can rapidly adapt to new contexts and learn from limited data, a\ncoveted characteristic that artificial intelligence algorithms have struggled\nto mimic. Inspired by oscillatory rhythms of the mechanical structures of\nneural cells, we developed a learning paradigm that is based on oscillations in\nlink strengths and associates learning with the coordination of these\noscillations. We find that this paradigm yields rapid adaptation and learning\nin artificial neural networks. Link oscillations can rapidly change\ncoordination, endowing the network with the ability to sense subtle context\nchanges in an unsupervised manner. In other words, the network generates the\nmissing contextual tokens required to perform as a generalist AI architecture\ncapable of predicting dynamics in multiple contexts. Oscillations also allow\nthe network to extrapolate dynamics to never-seen-before contexts. These\ncapabilities make our learning paradigm a powerful starting point for novel\nmodels of learning and cognition. Furthermore, learning through link\ncoordination is agnostic to the specifics of the neural network architecture,\nhence our study opens the door for introducing rapid adaptation and learning\ncapabilities into leading AI models.",
      "pdf_url": "http://arxiv.org/pdf/2502.08644v1",
      "published": "2025-02-12T18:58:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.08644v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.DS",
        "nlin.AO",
        "physics.bio-ph"
      ]
    },
    {
      "title": "A Real-to-Sim-to-Real Approach to Robotic Manipulation with VLM-Generated Iterative Keypoint Rewards",
      "authors": [
        "Shivansh Patel",
        "Xinchen Yin",
        "Wenlong Huang",
        "Shubham Garg",
        "Hooshang Nayyeri",
        "Li Fei-Fei",
        "Svetlana Lazebnik",
        "Yunzhu Li"
      ],
      "abstract": "Task specification for robotic manipulation in open-world environments is\nchallenging, requiring flexible and adaptive objectives that align with human\nintentions and can evolve through iterative feedback. We introduce Iterative\nKeypoint Reward (IKER), a visually grounded, Python-based reward function that\nserves as a dynamic task specification. Our framework leverages VLMs to\ngenerate and refine these reward functions for multi-step manipulation tasks.\nGiven RGB-D observations and free-form language instructions, we sample\nkeypoints in the scene and generate a reward function conditioned on these\nkeypoints. IKER operates on the spatial relationships between keypoints,\nleveraging commonsense priors about the desired behaviors, and enabling precise\nSE(3) control. We reconstruct real-world scenes in simulation and use the\ngenerated rewards to train reinforcement learning (RL) policies, which are then\ndeployed into the real world-forming a real-to-sim-to-real loop. Our approach\ndemonstrates notable capabilities across diverse scenarios, including both\nprehensile and non-prehensile tasks, showcasing multi-step task execution,\nspontaneous error recovery, and on-the-fly strategy adjustments. The results\nhighlight IKER's effectiveness in enabling robots to perform multi-step tasks\nin dynamic environments through iterative reward shaping.",
      "pdf_url": "http://arxiv.org/pdf/2502.08643v1",
      "published": "2025-02-12T18:57:22+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.08643v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Utility Engineering: Analyzing and Controlling Emergent Value Systems in AIs",
      "authors": [
        "Mantas Mazeika",
        "Xuwang Yin",
        "Rishub Tamirisa",
        "Jaehyuk Lim",
        "Bruce W. Lee",
        "Richard Ren",
        "Long Phan",
        "Norman Mu",
        "Adam Khoja",
        "Oliver Zhang",
        "Dan Hendrycks"
      ],
      "abstract": "As AIs rapidly advance and become more agentic, the risk they pose is\ngoverned not only by their capabilities but increasingly by their propensities,\nincluding goals and values. Tracking the emergence of goals and values has\nproven a longstanding problem, and despite much interest over the years it\nremains unclear whether current AIs have meaningful values. We propose a\nsolution to this problem, leveraging the framework of utility functions to\nstudy the internal coherence of AI preferences. Surprisingly, we find that\nindependently-sampled preferences in current LLMs exhibit high degrees of\nstructural coherence, and moreover that this emerges with scale. These findings\nsuggest that value systems emerge in LLMs in a meaningful sense, a finding with\nbroad implications. To study these emergent value systems, we propose utility\nengineering as a research agenda, comprising both the analysis and control of\nAI utilities. We uncover problematic and often shocking values in LLM\nassistants despite existing control measures. These include cases where AIs\nvalue themselves over humans and are anti-aligned with specific individuals. To\nconstrain these emergent value systems, we propose methods of utility control.\nAs a case study, we show how aligning utilities with a citizen assembly reduces\npolitical biases and generalizes to new scenarios. Whether we like it or not,\nvalue systems have already emerged in AIs, and much work remains to fully\nunderstand and control these emergent representations.",
      "pdf_url": "http://arxiv.org/pdf/2502.08640v1",
      "published": "2025-02-12T18:55:43+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.08640v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.CY"
      ]
    },
    {
      "title": "Ensemble based approach to quantifying uncertainty of LLM based classifications",
      "authors": [
        "Srijith Rajamohan",
        "Ahmed Salhin",
        "Josh Frazier",
        "Rohit Kumar",
        "Yu-Cheng Tsai",
        "Todd Cook"
      ],
      "abstract": "The output of Large Language Models (LLMs) are a function of the internal\nmodel's parameters and the input provided into the context window. The\nhypothesis presented here is that under a greedy sampling strategy the variance\nin the LLM's output is a function of the conceptual certainty embedded in the\nmodel's parametric knowledge, as well as the lexical variance in the input.\nFinetuning the model results in reducing the sensitivity of the model output to\nthe lexical input variations. This is then applied to a classification problem\nand a probabilistic method is proposed for estimating the certainties of the\npredicted classes.",
      "pdf_url": "http://arxiv.org/pdf/2502.08631v1",
      "published": "2025-02-12T18:42:42+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.08631v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Randomness of Low-Layer Parameters Determines Confusing Samples in Terms of Interaction Representations of a DNN",
      "authors": [
        "Junpeng Zhang",
        "Lei Cheng",
        "Qing Li",
        "Liang Lin",
        "Quanshi Zhang"
      ],
      "abstract": "In this paper, we find that the complexity of interactions encoded by a deep\nneural network (DNN) can explain its generalization power. We also discover\nthat the confusing samples of a DNN, which are represented by non-generalizable\ninteractions, are determined by its low-layer parameters. In comparison, other\nfactors, such as high-layer parameters and network architecture, have much less\nimpact on the composition of confusing samples. Two DNNs with different\nlow-layer parameters usually have fully different sets of confusing samples,\neven though they have similar performance. This finding extends the\nunderstanding of the lottery ticket hypothesis, and well explains distinctive\nrepresentation power of different DNNs.",
      "pdf_url": "http://arxiv.org/pdf/2502.08625v1",
      "published": "2025-02-12T18:25:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.08625v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ]
    },
    {
      "title": "Quantifying Security Vulnerabilities: A Metric-Driven Security Analysis of Gaps in Current AI Standards",
      "authors": [
        "Keerthana Madhavan",
        "Abbas Yazdinejad",
        "Fattane Zarrinkalam",
        "Ali Dehghantanha"
      ],
      "abstract": "As AI systems integrate into critical infrastructure, security gaps in AI\ncompliance frameworks demand urgent attention. This paper audits and quantifies\nsecurity risks in three major AI governance standards: NIST AI RMF 1.0, UK's AI\nand Data Protection Risk Toolkit, and the EU's ALTAI. Using a novel risk\nassessment methodology, we develop four key metrics: Risk Severity Index (RSI),\nAttack Potential Index (AVPI), Compliance-Security Gap Percentage (CSGP), and\nRoot Cause Vulnerability Score (RCVS). Our analysis identifies 136 concerns\nacross the frameworks, exposing significant gaps. NIST fails to address 69.23\npercent of identified risks, ALTAI has the highest attack vector vulnerability\n(AVPI = 0.51) and the ICO Toolkit has the largest compliance-security gap, with\n80.00 percent of high-risk concerns remaining unresolved. Root cause analysis\nhighlights under-defined processes (ALTAI RCVS = 033) and weak implementation\nguidance (NIST and ICO RCVS = 0.25) as critical weaknesses. These findings\nemphasize the need for stronger, enforceable security controls in AI\ncompliance. We offer targeted recommendations to enhance security posture and\nbridge the gap between compliance and real-world AI risks.",
      "pdf_url": "http://arxiv.org/pdf/2502.08610v1",
      "published": "2025-02-12T17:57:54+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.08610v1",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "title": "Distillation Scaling Laws",
      "authors": [
        "Dan Busbridge",
        "Amitis Shidani",
        "Floris Weers",
        "Jason Ramapuram",
        "Etai Littwin",
        "Russ Webb"
      ],
      "abstract": "We provide a distillation scaling law that estimates distilled model\nperformance based on a compute budget and its allocation between the student\nand teacher. Our findings reduce the risks associated with using distillation\nat scale; compute allocation for both the teacher and student models can now be\ndone to maximize student performance. We provide compute optimal distillation\nrecipes for when 1) a teacher exists, or 2) a teacher needs training. If many\nstudents are to be distilled, or a teacher already exists, distillation\noutperforms supervised pretraining until a compute level which grows\npredictably with student size. If one student is to be distilled and a teacher\nalso needs training, supervised learning should be done instead. Additionally,\nwe provide insights across our large scale study of distillation, which\nincrease our understanding of distillation and inform experimental design.",
      "pdf_url": "http://arxiv.org/pdf/2502.08606v1",
      "published": "2025-02-12T17:52:47+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.08606v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ]
    },
    {
      "title": "CurvGAD: Leveraging Curvature for Enhanced Graph Anomaly Detection",
      "authors": [
        "Karish Grover",
        "Geoffrey J. Gordon",
        "Christos Faloutsos"
      ],
      "abstract": "Does the intrinsic curvature of complex networks hold the key to unveiling\ngraph anomalies that conventional approaches overlook? Reconstruction-based\ngraph anomaly detection (GAD) methods overlook such geometric outliers,\nfocusing only on structural and attribute-level anomalies. To this end, we\npropose CurvGAD - a mixed-curvature graph autoencoder that introduces the\nnotion of curvature-based geometric anomalies. CurvGAD introduces two parallel\npipelines for enhanced anomaly interpretability: (1) Curvature-equivariant\ngeometry reconstruction, which focuses exclusively on reconstructing the edge\ncurvatures using a mixed-curvature, Riemannian encoder and Gaussian\nkernel-based decoder; and (2) Curvature-invariant structure and attribute\nreconstruction, which decouples structural and attribute anomalies from\ngeometric irregularities by regularizing graph curvature under discrete\nOllivier-Ricci flow, thereby isolating the non-geometric anomalies. By\nleveraging curvature, CurvGAD refines the existing anomaly classifications and\nidentifies new curvature-driven anomalies. Extensive experimentation over 10\nreal-world datasets (both homophilic and heterophilic) demonstrates an\nimprovement of up to 6.5% over state-of-the-art GAD methods.",
      "pdf_url": "http://arxiv.org/pdf/2502.08605v1",
      "published": "2025-02-12T17:49:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.08605v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Learning in Markets with Heterogeneous Agents: Dynamics and Survival of Bayesian vs. No-Regret Learners",
      "authors": [
        "David Easley",
        "Yoav Kolumbus",
        "Eva Tardos"
      ],
      "abstract": "We analyze the performance of heterogeneous learning agents in asset markets\nwith stochastic payoffs. Our agents aim to maximize the expected growth rate of\ntheir wealth but have different theories on how to learn this best. We focus on\ncomparing Bayesian and no-regret learners in market dynamics. Bayesian learners\nwith a prior over a finite set of models that assign positive prior probability\nto the correct model have posterior probabilities that converge exponentially\nto the correct model. Consequently, they survive even in the presence of agents\nwho invest according to the correct model of the stochastic process. Bayesians\nwith a continuum prior converge to the correct model at a rate of $O((\\log\nT)/T)$. Online learning theory provides no-regret algorithms for maximizing the\nlog of wealth in this setting, achieving a worst-case regret bound of $O(\\log\nT)$ without assuming a steady underlying stochastic process but comparing to\nthe best fixed investment rule. This regret, as we observe, is of the same\norder of magnitude as that of a Bayesian learner with a continuum prior.\nHowever, we show that even such low regret may not be sufficient for survival\nin asset markets: an agent can have regret as low as $O(\\log T)$, but still\nvanish in market dynamics when competing against agents who invest according to\nthe correct model or even against a perfect Bayesian with a finite prior. On\nthe other hand, we show that Bayesian learning is fragile, while no-regret\nlearning requires less knowledge of the environment and is therefore more\nrobust. Any no-regret learner will drive out of the market an imperfect\nBayesian whose finite prior or update rule has even small errors. We formally\nestablish the relationship between notions of survival, vanishing, and market\ndomination studied in economics and the framework of regret minimization, thus\nbridging these theories.",
      "pdf_url": "http://arxiv.org/pdf/2502.08597v1",
      "published": "2025-02-12T17:34:04+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.08597v1",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.MA",
        "econ.TH"
      ]
    },
    {
      "title": "Commercial LLM Agents Are Already Vulnerable to Simple Yet Dangerous Attacks",
      "authors": [
        "Ang Li",
        "Yin Zhou",
        "Vethavikashini Chithrra Raghuram",
        "Tom Goldstein",
        "Micah Goldblum"
      ],
      "abstract": "A high volume of recent ML security literature focuses on attacks against\naligned large language models (LLMs). These attacks may extract private\ninformation or coerce the model into producing harmful outputs. In real-world\ndeployments, LLMs are often part of a larger agentic pipeline including memory\nsystems, retrieval, web access, and API calling. Such additional components\nintroduce vulnerabilities that make these LLM-powered agents much easier to\nattack than isolated LLMs, yet relatively little work focuses on the security\nof LLM agents. In this paper, we analyze security and privacy vulnerabilities\nthat are unique to LLM agents. We first provide a taxonomy of attacks\ncategorized by threat actors, objectives, entry points, attacker observability,\nattack strategies, and inherent vulnerabilities of agent pipelines. We then\nconduct a series of illustrative attacks on popular open-source and commercial\nagents, demonstrating the immediate practical implications of their\nvulnerabilities. Notably, our attacks are trivial to implement and require no\nunderstanding of machine learning.",
      "pdf_url": "http://arxiv.org/pdf/2502.08586v1",
      "published": "2025-02-12T17:19:36+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.08586v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "FBFL: A Field-Based Coordination Approach for Data Heterogeneity in Federated Learning",
      "authors": [
        "Davide Domini",
        "Gianluca Aguzzi",
        "Lukas Esterle",
        "Mirko Viroli"
      ],
      "abstract": "In the last years, Federated learning (FL) has become a popular solution to\ntrain machine learning models in domains with high privacy concerns. However,\nFL scalability and performance face significant challenges in real-world\ndeployments where data across devices are non-independently and identically\ndistributed (non-IID). The heterogeneity in data distribution frequently arises\nfrom spatial distribution of devices, leading to degraded model performance in\nthe absence of proper handling. Additionally, FL typical reliance on\ncentralized architectures introduces bottlenecks and single-point-of-failure\nrisks, particularly problematic at scale or in dynamic environments. To close\nthis gap, we propose Field-Based Federated Learning (FBFL), a novel approach\nleveraging macroprogramming and field coordination to address these limitations\nthrough: (i) distributed spatial-based leader election for personalization to\nmitigate non-IID data challenges; and (ii) construction of a self-organizing,\nhierarchical architecture using advanced macroprogramming patterns. Moreover,\nFBFL not only overcomes the aforementioned limitations, but also enables the\ndevelopment of more specialized models tailored to the specific data\ndistribution in each subregion. This paper formalizes FBFL and evaluates it\nextensively using MNIST, FashionMNIST, and Extended MNIST datasets. We\ndemonstrate that, when operating under IID data conditions, FBFL performs\ncomparably to the widely-used FedAvg algorithm. Furthermore, in challenging\nnon-IID scenarios, FBFL not only outperforms FedAvg but also surpasses other\nstate-of-the-art methods, namely FedProx and Scaffold, which have been\nspecifically designed to address non-IID data distributions. Additionally, we\nshowcase the resilience of FBFL's self-organizing hierarchical architecture\nagainst server failures.",
      "pdf_url": "http://arxiv.org/pdf/2502.08577v1",
      "published": "2025-02-12T17:10:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.08577v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Mapping the Landscape of Generative AI in Network Monitoring and Management",
      "authors": [
        "Giampaolo Bovenzi",
        "Francesco Cerasuolo",
        "Domenico Ciuonzo",
        "Davide Di Monda",
        "Idio Guarino",
        "Antonio Montieri",
        "Valerio Persico",
        "Antonio Pescapè"
      ],
      "abstract": "Generative Artificial Intelligence (GenAI) models such as LLMs, GPTs, and\nDiffusion Models have recently gained widespread attention from both the\nresearch and the industrial communities. This survey explores their application\nin network monitoring and management, focusing on prominent use cases, as well\nas challenges and opportunities. We discuss how network traffic generation and\nclassification, network intrusion detection, networked system log analysis, and\nnetwork digital assistance can benefit from the use of GenAI models.\nAdditionally, we provide an overview of the available GenAI models, datasets\nfor large-scale training phases, and platforms for the development of such\nmodels. Finally, we discuss research directions that potentially mitigate the\nroadblocks to the adoption of GenAI for network monitoring and management. Our\ninvestigation aims to map the current landscape and pave the way for future\nresearch in leveraging GenAI for network monitoring and management.",
      "pdf_url": "http://arxiv.org/pdf/2502.08576v1",
      "published": "2025-02-12T17:10:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.08576v1",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.LG",
        "C.2; I.2"
      ]
    },
    {
      "title": "COAST: Intelligent Time-Adaptive Neural Operators",
      "authors": [
        "Zhikai Wu",
        "Shiyang Zhang",
        "Sizhuang He",
        "Sifan Wang",
        "Min Zhu",
        "Anran Jiao",
        "Lu Lu",
        "David van Dijk"
      ],
      "abstract": "We introduce Causal Operator with Adaptive Solver Transformer (COAST), a\nnovel neural operator learning method that leverages a causal language model\n(CLM) framework to dynamically adapt time steps. Our method predicts both the\nevolution of a system and its optimal time step, intelligently balancing\ncomputational efficiency and accuracy. We find that COAST generates variable\nstep sizes that correlate with the underlying system intrinsicities, both\nwithin and across dynamical systems. Within a single trajectory, smaller steps\nare taken in regions of high complexity, while larger steps are employed in\nsimpler regions. Across different systems, more complex dynamics receive more\ngranular time steps. Benchmarked on diverse systems with varied dynamics, COAST\nconsistently outperforms state-of-the-art methods, achieving superior\nperformance in both efficiency and accuracy. This work underscores the\npotential of CLM-based intelligent adaptive solvers for scalable operator\nlearning of dynamical systems.",
      "pdf_url": "http://arxiv.org/pdf/2502.08574v1",
      "published": "2025-02-12T17:09:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.08574v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "A Novel Approach to for Multimodal Emotion Recognition : Multimodal semantic information fusion",
      "authors": [
        "Wei Dai",
        "Dequan Zheng",
        "Feng Yu",
        "Yanrong Zhang",
        "Yaohui Hou"
      ],
      "abstract": "With the advancement of artificial intelligence and computer vision\ntechnologies, multimodal emotion recognition has become a prominent research\ntopic. However, existing methods face challenges such as heterogeneous data\nfusion and the effective utilization of modality correlations. This paper\nproposes a novel multimodal emotion recognition approach, DeepMSI-MER, based on\nthe integration of contrastive learning and visual sequence compression. The\nproposed method enhances cross-modal feature fusion through contrastive\nlearning and reduces redundancy in the visual modality by leveraging visual\nsequence compression. Experimental results on two public datasets, IEMOCAP and\nMELD, demonstrate that DeepMSI-MER significantly improves the accuracy and\nrobustness of emotion recognition, validating the effectiveness of multimodal\nfeature fusion and the proposed approach.",
      "pdf_url": "http://arxiv.org/pdf/2502.08573v1",
      "published": "2025-02-12T17:07:43+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.08573v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Brain Latent Progression: Individual-based Spatiotemporal Disease Progression on 3D Brain MRIs via Latent Diffusion",
      "authors": [
        "Lemuel Puglisi",
        "Daniel C. Alexander",
        "Daniele Ravì"
      ],
      "abstract": "The growing availability of longitudinal Magnetic Resonance Imaging (MRI)\ndatasets has facilitated Artificial Intelligence (AI)-driven modeling of\ndisease progression, making it possible to predict future medical scans for\nindividual patients. However, despite significant advancements in AI, current\nmethods continue to face challenges including achieving patient-specific\nindividualization, ensuring spatiotemporal consistency, efficiently utilizing\nlongitudinal data, and managing the substantial memory demands of 3D scans. To\naddress these challenges, we propose Brain Latent Progression (BrLP), a novel\nspatiotemporal model designed to predict individual-level disease progression\nin 3D brain MRIs. The key contributions in BrLP are fourfold: (i) it operates\nin a small latent space, mitigating the computational challenges posed by\nhigh-dimensional imaging data; (ii) it explicitly integrates subject metadata\nto enhance the individualization of predictions; (iii) it incorporates prior\nknowledge of disease dynamics through an auxiliary model, facilitating the\nintegration of longitudinal data; and (iv) it introduces the Latent Average\nStabilization (LAS) algorithm, which (a) enforces spatiotemporal consistency in\nthe predicted progression at inference time and (b) allows us to derive a\nmeasure of the uncertainty for the prediction. We train and evaluate BrLP on\n11,730 T1-weighted (T1w) brain MRIs from 2,805 subjects and validate its\ngeneralizability on an external test set comprising 2,257 MRIs from 962\nsubjects. Our experiments compare BrLP-generated MRI scans with real follow-up\nMRIs, demonstrating state-of-the-art accuracy compared to existing methods. The\ncode is publicly available at: https://github.com/LemuelPuglisi/BrLP.",
      "pdf_url": "http://arxiv.org/pdf/2502.08560v1",
      "published": "2025-02-12T16:47:41+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.08560v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Human-Centric Foundation Models: Perception, Generation and Agentic Modeling",
      "authors": [
        "Shixiang Tang",
        "Yizhou Wang",
        "Lu Chen",
        "Yuan Wang",
        "Sida Peng",
        "Dan Xu",
        "Wanli Ouyang"
      ],
      "abstract": "Human understanding and generation are critical for modeling digital humans\nand humanoid embodiments. Recently, Human-centric Foundation Models (HcFMs)\ninspired by the success of generalist models, such as large language and vision\nmodels, have emerged to unify diverse human-centric tasks into a single\nframework, surpassing traditional task-specific approaches. In this survey, we\npresent a comprehensive overview of HcFMs by proposing a taxonomy that\ncategorizes current approaches into four groups: (1) Human-centric Perception\nFoundation Models that capture fine-grained features for multi-modal 2D and 3D\nunderstanding. (2) Human-centric AIGC Foundation Models that generate\nhigh-fidelity, diverse human-related content. (3) Unified Perception and\nGeneration Models that integrate these capabilities to enhance both human\nunderstanding and synthesis. (4) Human-centric Agentic Foundation Models that\nextend beyond perception and generation to learn human-like intelligence and\ninteractive behaviors for humanoid embodied tasks. We review state-of-the-art\ntechniques, discuss emerging challenges and future research directions. This\nsurvey aims to serve as a roadmap for researchers and practitioners working\ntowards more robust, versatile, and intelligent digital human and embodiments\nmodeling.",
      "pdf_url": "http://arxiv.org/pdf/2502.08556v1",
      "published": "2025-02-12T16:38:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.08556v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MM"
      ]
    },
    {
      "title": "Fostering Appropriate Reliance on Large Language Models: The Role of Explanations, Sources, and Inconsistencies",
      "authors": [
        "Sunnie S. Y. Kim",
        "Jennifer Wortman Vaughan",
        "Q. Vera Liao",
        "Tania Lombrozo",
        "Olga Russakovsky"
      ],
      "abstract": "Large language models (LLMs) can produce erroneous responses that sound\nfluent and convincing, raising the risk that users will rely on these responses\nas if they were correct. Mitigating such overreliance is a key challenge.\nThrough a think-aloud study in which participants use an LLM-infused\napplication to answer objective questions, we identify several features of LLM\nresponses that shape users' reliance: explanations (supporting details for\nanswers), inconsistencies in explanations, and sources. Through a large-scale,\npre-registered, controlled experiment (N=308), we isolate and study the effects\nof these features on users' reliance, accuracy, and other measures. We find\nthat the presence of explanations increases reliance on both correct and\nincorrect responses. However, we observe less reliance on incorrect responses\nwhen sources are provided or when explanations exhibit inconsistencies. We\ndiscuss the implications of these findings for fostering appropriate reliance\non LLMs.",
      "pdf_url": "http://arxiv.org/pdf/2502.08554v1",
      "published": "2025-02-12T16:35:41+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.08554v1",
      "categories": [
        "cs.HC",
        "cs.AI"
      ]
    },
    {
      "title": "LLMs can implicitly learn from mistakes in-context",
      "authors": [
        "Lisa Alazraki",
        "Maximilian Mozes",
        "Jon Ander Campos",
        "Yi Chern Tan",
        "Marek Rei",
        "Max Bartolo"
      ],
      "abstract": "Learning from mistakes is a fundamental feature of human intelligence.\nPrevious work has shown that Large Language Models (LLMs) can also learn from\nincorrect answers when provided with a comprehensive rationale detailing why an\nanswer is wrong or how to correct it. In this work, we examine whether LLMs can\nlearn from mistakes in mathematical reasoning tasks when these explanations are\nnot provided. We investigate if LLMs are able to implicitly infer such\nrationales simply from observing both incorrect and correct answers.\nSurprisingly, we find that LLMs perform better, on average, when rationales are\neliminated from the context and incorrect answers are simply shown alongside\ncorrect ones. This approach also substantially outperforms chain-of-thought\nprompting in our evaluations. We show that these results are consistent across\nLLMs of different sizes and varying reasoning abilities. Further, we carry out\nan in-depth analysis, and show that prompting with both wrong and correct\nanswers leads to greater performance and better generalisation than introducing\nadditional, more diverse question-answer pairs into the context. Finally, we\nshow that new rationales generated by models that have only observed incorrect\nand correct answers are scored equally as highly by humans as those produced\nwith the aid of exemplar rationales. Our results demonstrate that LLMs are\nindeed capable of in-context implicit learning.",
      "pdf_url": "http://arxiv.org/pdf/2502.08550v1",
      "published": "2025-02-12T16:31:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.08550v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Representation Learning to Advance Multi-institutional Studies with Electronic Health Record Data",
      "authors": [
        "Doudou Zhou",
        "Han Tong",
        "Linshanshan Wang",
        "Suqi Liu",
        "Xin Xiong",
        "Ziming Gan",
        "Romain Griffier",
        "Boris Hejblum",
        "Yun-Chung Liu",
        "Chuan Hong",
        "Clara-Lea Bonzel",
        "Tianrun Cai",
        "Kevin Pan",
        "Yuk-Lam Ho",
        "Lauren Costa",
        "Vidul A. Panickan",
        "J. Michael Gaziano",
        "Kenneth Mandl",
        "Vianney Jouhet",
        "Rodolphe Thiebaut",
        "Zongqi Xia",
        "Kelly Cho",
        "Katherine Liao",
        "Tianxi Cai"
      ],
      "abstract": "The adoption of EHRs has expanded opportunities to leverage data-driven\nalgorithms in clinical care and research. A major bottleneck in effectively\nconducting multi-institutional EHR studies is the data heterogeneity across\nsystems with numerous codes that either do not exist or represent different\nclinical concepts across institutions. The need for data privacy further limits\nthe feasibility of including multi-institutional patient-level data required to\nstudy similarities and differences across patient subgroups. To address these\nchallenges, we developed the GAME algorithm. Tested and validated across 7\ninstitutions and 2 languages, GAME integrates data in several levels: (1) at\nthe institutional level with knowledge graphs to establish relationships\nbetween codes and existing knowledge sources, providing the medical context for\nstandard codes and their relationship to each other; (2) between institutions,\nleveraging language models to determine the relationships between\ninstitution-specific codes with established standard codes; and (3) quantifying\nthe strength of the relationships between codes using a graph attention\nnetwork. Jointly trained embeddings are created using transfer and federated\nlearning to preserve data privacy. In this study, we demonstrate the\napplicability of GAME in selecting relevant features as inputs for AI-driven\nalgorithms in a range of conditions, e.g., heart failure, rheumatoid arthritis.\nWe then highlight the application of GAME harmonized multi-institutional EHR\ndata in a study of Alzheimer's disease outcomes and suicide risk among patients\nwith mental health disorders, without sharing patient-level data outside\nindividual institutions.",
      "pdf_url": "http://arxiv.org/pdf/2502.08547v1",
      "published": "2025-02-12T16:29:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.08547v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Input convex neural networks: universal approximation theorem and implementation for isotropic polyconvex hyperelastic energies",
      "authors": [
        "Gian-Luca Geuken",
        "Patrick Kurzeja",
        "David Wiedemann",
        "Jörn Mosler"
      ],
      "abstract": "This paper presents a novel framework of neural networks for isotropic\nhyperelasticity that enforces necessary physical and mathematical constraints\nwhile simultaneously satisfying the universal approximation theorem. The two\nkey ingredients are an input convex network architecture and a formulation in\nthe elementary polynomials of the signed singular values of the deformation\ngradient. In line with previously published networks, it can rigorously capture\nframe-indifference and polyconvexity - as well as further constraints like\nbalance of angular momentum and growth conditions. However and in contrast to\nprevious networks, a universal approximation theorem for the proposed approach\nis proven. To be more explicit, the proposed network can approximate any\nframe-indifferent, isotropic polyconvex energy (provided the network is large\nenough). This is possible by working with a sufficient and necessary criterion\nfor frame-indifferent, isotropic polyconvex functions. Comparative studies with\nexisting approaches identify the advantages of the proposed method,\nparticularly in approximating non-polyconvex energies as well as computing\npolyconvex hulls.",
      "pdf_url": "http://arxiv.org/pdf/2502.08534v1",
      "published": "2025-02-12T16:15:03+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.08534v1",
      "categories": [
        "cs.CE",
        "cs.AI",
        "74B20, 68T07",
        "J.2; I.2.1"
      ]
    },
    {
      "title": "FedMHO: Heterogeneous One-Shot Federated Learning Towards Resource-Constrained Edge Devices",
      "authors": [
        "Dezhong Yao",
        "Yuexin Shi",
        "Tongtong Liu",
        "Zhiqiang Xu"
      ],
      "abstract": "Federated Learning (FL) is increasingly adopted in edge computing scenarios,\nwhere a large number of heterogeneous clients operate under constrained or\nsufficient resources. The iterative training process in conventional FL\nintroduces significant computation and communication overhead, which is\nunfriendly for resource-constrained edge devices. One-shot FL has emerged as a\npromising approach to mitigate communication overhead, and model-heterogeneous\nFL solves the problem of diverse computing resources across clients. However,\nexisting methods face challenges in effectively managing model-heterogeneous\none-shot FL, often leading to unsatisfactory global model performance or\nreliance on auxiliary datasets. To address these challenges, we propose a novel\nFL framework named FedMHO, which leverages deep classification models on\nresource-sufficient clients and lightweight generative models on\nresource-constrained devices. On the server side, FedMHO involves a two-stage\nprocess that includes data generation and knowledge fusion. Furthermore, we\nintroduce FedMHO-MD and FedMHO-SD to mitigate the knowledge-forgetting problem\nduring the knowledge fusion stage, and an unsupervised data optimization\nsolution to improve the quality of synthetic samples. Comprehensive experiments\ndemonstrate the effectiveness of our methods, as they outperform\nstate-of-the-art baselines in various experimental setups.",
      "pdf_url": "http://arxiv.org/pdf/2502.08518v1",
      "published": "2025-02-12T15:54:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.08518v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ]
    },
    {
      "title": "Measuring Diversity in Synthetic Datasets",
      "authors": [
        "Yuchang Zhu",
        "Huizhe Zhang",
        "Bingzhe Wu",
        "Jintang Li",
        "Zibin Zheng",
        "Peilin Zhao",
        "Liang Chen",
        "Yatao Bian"
      ],
      "abstract": "Large language models (LLMs) are widely adopted to generate synthetic\ndatasets for various natural language processing (NLP) tasks, such as text\nclassification and summarization. However, accurately measuring the diversity\nof these synthetic datasets-an aspect crucial for robust model\nperformance-remains a significant challenge. In this paper, we introduce\nDCScore, a novel method for measuring synthetic dataset diversity from a\nclassification perspective. Specifically, DCScore formulates diversity\nevaluation as a sample classification task, leveraging mutual relationships\namong samples. We further provide theoretical verification of the\ndiversity-related axioms satisfied by DCScore, highlighting its role as a\nprincipled diversity evaluation method. Experimental results on synthetic\ndatasets reveal that DCScore enjoys a stronger correlation with multiple\ndiversity pseudo-truths of evaluated datasets, underscoring its effectiveness.\nMoreover, both empirical and theoretical evidence demonstrate that DCScore\nsubstantially reduces computational costs compared to existing approaches. Code\nis available at: https://github.com/BlueWhaleLab/DCScore.",
      "pdf_url": "http://arxiv.org/pdf/2502.08512v1",
      "published": "2025-02-12T15:46:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.08512v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Revisiting 3D LLM Benchmarks: Are We Really Testing 3D Capabilities?",
      "authors": [
        "Jiahe Jin",
        "Yanheng He",
        "Mingyan Yang"
      ],
      "abstract": "In this work, we identify the \"2D-Cheating\" problem in 3D LLM evaluation,\nwhere these tasks might be easily solved by VLMs with rendered images of point\nclouds, exposing ineffective evaluation of 3D LLMs' unique 3D capabilities. We\ntest VLM performance across multiple 3D LLM benchmarks and, using this as a\nreference, propose principles for better assessing genuine 3D understanding. We\nalso advocate explicitly separating 3D abilities from 1D or 2D aspects when\nevaluating 3D LLMs.",
      "pdf_url": "http://arxiv.org/pdf/2502.08503v1",
      "published": "2025-02-12T15:34:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.08503v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Enhancing Auto-regressive Chain-of-Thought through Loop-Aligned Reasoning",
      "authors": [
        "Qifan Yu",
        "Zhenyu He",
        "Sijie Li",
        "Xun Zhou",
        "Jun Zhang",
        "Jingjing Xu",
        "Di He"
      ],
      "abstract": "Chain-of-Thought (CoT) prompting has emerged as a powerful technique for\nenhancing language model's reasoning capabilities. However, generating long and\ncorrect CoT trajectories is challenging. Recent studies have demonstrated that\nLooped Transformers possess remarkable length generalization capabilities, but\ntheir limited generality and adaptability prevent them from serving as an\nalternative to auto-regressive solutions. To better leverage the strengths of\nLooped Transformers, we propose RELAY (REasoning through Loop Alignment\niterativelY). Specifically, we align the steps of Chain-of-Thought (CoT)\nreasoning with loop iterations and apply intermediate supervision during the\ntraining of Looped Transformers. This additional iteration-wise supervision not\nonly preserves the Looped Transformer's ability for length generalization but\nalso enables it to predict CoT reasoning steps for unseen data. Therefore, we\nleverage this Looped Transformer to generate accurate reasoning chains for\ncomplex problems that exceed the training length, which will then be used to\nfine-tune an auto-regressive model. We conduct extensive experiments, and the\nresults demonstrate the effectiveness of our approach, with significant\nimprovements in the performance of the auto-regressive model. Code will be\nreleased at https://github.com/qifanyu/RELAY.",
      "pdf_url": "http://arxiv.org/pdf/2502.08482v1",
      "published": "2025-02-12T15:17:04+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.08482v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "mmE5: Improving Multimodal Multilingual Embeddings via High-quality Synthetic Data",
      "authors": [
        "Haonan Chen",
        "Liang Wang",
        "Nan Yang",
        "Yutao Zhu",
        "Ziliang Zhao",
        "Furu Wei",
        "Zhicheng Dou"
      ],
      "abstract": "Multimodal embedding models have gained significant attention for their\nability to map data from different modalities, such as text and images, into a\nunified representation space. However, the limited labeled multimodal data\noften hinders embedding performance. Recent approaches have leveraged data\nsynthesis to address this problem, yet the quality of synthetic data remains a\ncritical bottleneck. In this work, we identify three criteria for high-quality\nsynthetic multimodal data. First, broad scope ensures that the generated data\ncovers diverse tasks and modalities, making it applicable to various downstream\nscenarios. Second, robust cross-modal alignment makes different modalities\nsemantically consistent. Third, high fidelity ensures that the synthetic data\nmaintains realistic details to enhance its reliability. Guided by these\nprinciples, we synthesize datasets that: (1) cover a wide range of tasks,\nmodality combinations, and languages, (2) are generated via a deep thinking\nprocess within a single pass of a multimodal large language model, and (3)\nincorporate real-world images with accurate and relevant texts, ensuring\nfidelity through self-evaluation and refinement. Leveraging these high-quality\nsynthetic and labeled datasets, we train a multimodal multilingual E5 model\nmmE5. Extensive experiments demonstrate that mmE5 achieves state-of-the-art\nperformance on the MMEB Benchmark and superior multilingual performance on the\nXTD benchmark. Our codes, datasets and models are released in\nhttps://github.com/haon-chen/mmE5.",
      "pdf_url": "http://arxiv.org/pdf/2502.08468v1",
      "published": "2025-02-12T15:03:33+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.08468v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Towards Prompt Generalization: Grammar-aware Cross-Prompt Automated Essay Scoring",
      "authors": [
        "Heejin Do",
        "Taehee Park",
        "Sangwon Ryu",
        "Gary Geunbae Lee"
      ],
      "abstract": "In automated essay scoring (AES), recent efforts have shifted toward\ncross-prompt settings that score essays on unseen prompts for practical\napplicability. However, prior methods trained with essay-score pairs of\nspecific prompts pose challenges in obtaining prompt-generalized essay\nrepresentation. In this work, we propose a grammar-aware cross-prompt trait\nscoring (GAPS), which internally captures prompt-independent syntactic aspects\nto learn generic essay representation. We acquire grammatical error-corrected\ninformation in essays via the grammar error correction technique and design the\nAES model to seamlessly integrate such information. By internally referring to\nboth the corrected and the original essays, the model can focus on generic\nfeatures during training. Empirical experiments validate our method's\ngeneralizability, showing remarkable improvements in prompt-independent and\ngrammar-related traits. Furthermore, GAPS achieves notable QWK gains in the\nmost challenging cross-prompt scenario, highlighting its strength in evaluating\nunseen prompts.",
      "pdf_url": "http://arxiv.org/pdf/2502.08450v1",
      "published": "2025-02-12T14:41:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.08450v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "CordViP: Correspondence-based Visuomotor Policy for Dexterous Manipulation in Real-World",
      "authors": [
        "Yankai Fu",
        "Qiuxuan Feng",
        "Ning Chen",
        "Zichen Zhou",
        "Mengzhen Liu",
        "Mingdong Wu",
        "Tianxing Chen",
        "Shanyu Rong",
        "Jiaming Liu",
        "Hao Dong",
        "Shanghang Zhang"
      ],
      "abstract": "Achieving human-level dexterity in robots is a key objective in the field of\nrobotic manipulation. Recent advancements in 3D-based imitation learning have\nshown promising results, providing an effective pathway to achieve this goal.\nHowever, obtaining high-quality 3D representations presents two key problems:\n(1) the quality of point clouds captured by a single-view camera is\nsignificantly affected by factors such as camera resolution, positioning, and\nocclusions caused by the dexterous hand; (2) the global point clouds lack\ncrucial contact information and spatial correspondences, which are necessary\nfor fine-grained dexterous manipulation tasks. To eliminate these limitations,\nwe propose CordViP, a novel framework that constructs and learns\ncorrespondences by leveraging the robust 6D pose estimation of objects and\nrobot proprioception. Specifically, we first introduce the interaction-aware\npoint clouds, which establish correspondences between the object and the hand.\nThese point clouds are then used for our pre-training policy, where we also\nincorporate object-centric contact maps and hand-arm coordination information,\neffectively capturing both spatial and temporal dynamics. Our method\ndemonstrates exceptional dexterous manipulation capabilities with an average\nsuccess rate of 90\\% in four real-world tasks, surpassing other baselines by a\nlarge margin. Experimental results also highlight the superior generalization\nand robustness of CordViP to different objects, viewpoints, and scenarios. Code\nand videos are available on https://aureleopku.github.io/CordViP.",
      "pdf_url": "http://arxiv.org/pdf/2502.08449v1",
      "published": "2025-02-12T14:41:14+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.08449v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "Better Embeddings with Coupled Adam",
      "authors": [
        "Felix Stollenwerk",
        "Tobias Stollenwerk"
      ],
      "abstract": "Despite their remarkable capabilities, LLMs learn word representations that\nexhibit the undesirable yet poorly understood feature of anisotropy. In this\npaper, we argue that the second moment in Adam is a cause of anisotropic\nembeddings, and suggest a modified optimizer called Coupled Adam to mitigate\nthe problem. Our experiments demonstrate that Coupled Adam significantly\nimproves the quality of embeddings, while also leading to better upstream and\ndownstream performance on large enough datasets.",
      "pdf_url": "http://arxiv.org/pdf/2502.08441v1",
      "published": "2025-02-12T14:32:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.08441v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Composite Sketch+Text Queries for Retrieving Objects with Elusive Names and Complex Interactions",
      "authors": [
        "Prajwal Gatti",
        "Kshitij Parikh",
        "Dhriti Prasanna Paul",
        "Manish Gupta",
        "Anand Mishra"
      ],
      "abstract": "Non-native speakers with limited vocabulary often struggle to name specific\nobjects despite being able to visualize them, e.g., people outside Australia\nsearching for numbats. Further, users may want to search for such elusive\nobjects with difficult-to-sketch interactions, e.g., numbat digging in the\nground. In such common but complex situations, users desire a search interface\nthat accepts composite multimodal queries comprising hand-drawn sketches of\ndifficult-to-name but easy-to-draw objects and text describing\ndifficult-to-sketch but easy-to-verbalize object attributes or interaction with\nthe scene. This novel problem statement distinctly differs from the previously\nwell-researched TBIR (text-based image retrieval) and SBIR (sketch-based image\nretrieval) problems. To study this under-explored task, we curate a dataset,\nCSTBIR (Composite Sketch+Text Based Image Retrieval), consisting of approx. 2M\nqueries and 108K natural scene images. Further, as a solution to this problem,\nwe propose a pretrained multimodal transformer-based baseline, STNET\n(Sketch+Text Network), that uses a hand-drawn sketch to localize relevant\nobjects in the natural scene image, and encodes the text and image to perform\nimage retrieval. In addition to contrastive learning, we propose multiple\ntraining objectives that improve the performance of our model. Extensive\nexperiments show that our proposed method outperforms several state-of-the-art\nretrieval methods for text-only, sketch-only, and composite query modalities.\nWe make the dataset and code available at our project website.",
      "pdf_url": "http://arxiv.org/pdf/2502.08438v1",
      "published": "2025-02-12T14:22:59+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.08438v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.IR",
        "cs.MM"
      ]
    },
    {
      "title": "From Haystack to Needle: Label Space Reduction for Zero-shot Classification",
      "authors": [
        "Nathan Vandemoortele",
        "Bram Steenwinckel",
        "Femke Ongenae",
        "Sofie Van Hoecke"
      ],
      "abstract": "We present Label Space Reduction (LSR), a novel method for improving\nzero-shot classification performance of Large Language Models (LLMs). LSR\niteratively refines the classification label space by systematically ranking\nand reducing candidate classes, enabling the model to concentrate on the most\nrelevant options. By leveraging unlabeled data with the statistical learning\ncapabilities of data-driven models, LSR dynamically optimizes the label space\nrepresentation at test time. Our experiments across seven benchmarks\ndemonstrate that LSR improves macro-F1 scores by an average of 7.0% (up to\n14.2%) with Llama-3.1-70B and 3.3% (up to 11.1%) with Claude-3.5-Sonnet\ncompared to standard zero-shot classification baselines. To reduce the\ncomputational overhead of LSR, which requires an additional LLM call at each\niteration, we propose distilling the model into a probabilistic classifier,\nallowing for efficient inference.",
      "pdf_url": "http://arxiv.org/pdf/2502.08436v1",
      "published": "2025-02-12T14:20:36+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.08436v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Handwritten Text Recognition: A Survey",
      "authors": [
        "Carlos Garrido-Munoz",
        "Antonio Rios-Vila",
        "Jorge Calvo-Zaragoza"
      ],
      "abstract": "Handwritten Text Recognition (HTR) has become an essential field within\npattern recognition and machine learning, with applications spanning historical\ndocument preservation to modern data entry and accessibility solutions. The\ncomplexity of HTR lies in the high variability of handwriting, which makes it\nchallenging to develop robust recognition systems. This survey examines the\nevolution of HTR models, tracing their progression from early heuristic-based\napproaches to contemporary state-of-the-art neural models, which leverage deep\nlearning techniques. The scope of the field has also expanded, with models\ninitially capable of recognizing only word-level content progressing to recent\nend-to-end document-level approaches. Our paper categorizes existing work into\ntwo primary levels of recognition: (1) \\emph{up to line-level}, encompassing\nword and line recognition, and (2) \\emph{beyond line-level}, addressing\nparagraph- and document-level challenges. We provide a unified framework that\nexamines research methodologies, recent advances in benchmarking, key datasets\nin the field, and a discussion of the results reported in the literature.\nFinally, we identify pressing research challenges and outline promising future\ndirections, aiming to equip researchers and practitioners with a roadmap for\nadvancing the field.",
      "pdf_url": "http://arxiv.org/pdf/2502.08417v1",
      "published": "2025-02-12T13:59:37+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.08417v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Learning Humanoid Standing-up Control across Diverse Postures",
      "authors": [
        "Tao Huang",
        "Junli Ren",
        "Huayi Wang",
        "Zirui Wang",
        "Qingwei Ben",
        "Muning Wen",
        "Xiao Chen",
        "Jianan Li",
        "Jiangmiao Pang"
      ],
      "abstract": "Standing-up control is crucial for humanoid robots, with the potential for\nintegration into current locomotion and loco-manipulation systems, such as fall\nrecovery. Existing approaches are either limited to simulations that overlook\nhardware constraints or rely on predefined ground-specific motion trajectories,\nfailing to enable standing up across postures in real-world scenes. To bridge\nthis gap, we present HoST (Humanoid Standing-up Control), a reinforcement\nlearning framework that learns standing-up control from scratch, enabling\nrobust sim-to-real transfer across diverse postures. HoST effectively learns\nposture-adaptive motions by leveraging a multi-critic architecture and\ncurriculum-based training on diverse simulated terrains. To ensure successful\nreal-world deployment, we constrain the motion with smoothness regularization\nand implicit motion speed bound to alleviate oscillatory and violent motions on\nphysical hardware, respectively. After simulation-based training, the learned\ncontrol policies are directly deployed on the Unitree G1 humanoid robot. Our\nexperimental results demonstrate that the controllers achieve smooth, stable,\nand robust standing-up motions across a wide range of laboratory and outdoor\nenvironments. Videos are available at\nhttps://taohuang13.github.io/humanoid-standingup.github.io/.",
      "pdf_url": "http://arxiv.org/pdf/2502.08378v1",
      "published": "2025-02-12T13:10:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.08378v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Uncertainty Aware Human-machine Collaboration in Camouflaged Object Detection",
      "authors": [
        "Ziyue Yang",
        "Kehan Wang",
        "Yuhang Ming",
        "Yong Peng",
        "Han Yang",
        "Qiong Chen",
        "Wanzeng Kong"
      ],
      "abstract": "Camouflaged Object Detection (COD), the task of identifying objects concealed\nwithin their environments, has seen rapid growth due to its wide range of\npractical applications. A key step toward developing trustworthy COD systems is\nthe estimation and effective utilization of uncertainty. In this work, we\npropose a human-machine collaboration framework for classifying the presence of\ncamouflaged objects, leveraging the complementary strengths of computer vision\n(CV) models and noninvasive brain-computer interfaces (BCIs). Our approach\nintroduces a multiview backbone to estimate uncertainty in CV model\npredictions, utilizes this uncertainty during training to improve efficiency,\nand defers low-confidence cases to human evaluation via RSVP-based BCIs during\ntesting for more reliable decision-making. We evaluated the framework in the\nCAMO dataset, achieving state-of-the-art results with an average improvement of\n4.56\\% in balanced accuracy (BA) and 3.66\\% in the F1 score compared to\nexisting methods. For the best-performing participants, the improvements\nreached 7.6\\% in BA and 6.66\\% in the F1 score. Analysis of the training\nprocess revealed a strong correlation between our confidence measures and\nprecision, while an ablation study confirmed the effectiveness of the proposed\ntraining policy and the human-machine collaboration strategy. In general, this\nwork reduces human cognitive load, improves system reliability, and provides a\nstrong foundation for advancements in real-world COD applications and\nhuman-computer interaction. Our code and data are available at:\nhttps://github.com/ziyuey/Uncertainty-aware-human-machine-collaboration-in-camouflaged-object-identification.",
      "pdf_url": "http://arxiv.org/pdf/2502.08373v1",
      "published": "2025-02-12T13:05:24+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.08373v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Towards Principled Multi-Agent Task Agnostic Exploration",
      "authors": [
        "Riccardo Zamboni",
        "Mirco Mutti",
        "Marcello Restelli"
      ],
      "abstract": "In reinforcement learning, we typically refer to task-agnostic exploration\nwhen we aim to explore the environment without access to the task specification\na priori. In a single-agent setting the problem has been extensively studied\nand mostly understood. A popular approach cast the task-agnostic objective as\nmaximizing the entropy of the state distribution induced by the agent's policy,\nfrom which principles and methods follows. In contrast, little is known about\ntask-agnostic exploration in multi-agent settings, which are ubiquitous in the\nreal world. How should different agents explore in the presence of others? In\nthis paper, we address this question through a generalization to multiple\nagents of the problem of maximizing the state distribution entropy. First, we\ninvestigate alternative formulations, highlighting respective positives and\nnegatives. Then, we present a scalable, decentralized, trust-region policy\nsearch algorithm to address the problem in practical settings. Finally, we\nprovide proof of concept experiments to both corroborate the theoretical\nfindings and pave the way for task-agnostic exploration in challenging\nmulti-agent settings.",
      "pdf_url": "http://arxiv.org/pdf/2502.08365v1",
      "published": "2025-02-12T12:51:36+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.08365v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Top-Theta Attention: Sparsifying Transformers by Compensated Thresholding",
      "authors": [
        "Konstantin Berestizshevsky",
        "Renzo Andri",
        "Lukas Cavigelli"
      ],
      "abstract": "The attention mechanism is essential for the impressive capabilities of\ntransformer-based Large Language Models (LLMs). However, calculating attention\nis computationally intensive due to its quadratic dependency on the sequence\nlength. We introduce a novel approach called Top-Theta Attention, or simply\nTop-$\\theta$, which selectively prunes less essential attention elements by\ncomparing them against carefully calibrated thresholds. This method greatly\nimproves the efficiency of self-attention matrix multiplication while\npreserving model accuracy, reducing the number of required V cache rows by 3x\nduring generative decoding and the number of attention elements by 10x during\nthe prefill phase. Our method does not require model retraining; instead, it\nrequires only a brief calibration phase to be resilient to distribution shifts,\nthus not requiring the thresholds for different datasets to be recalibrated.\nUnlike top-k attention, Top-$\\theta$ eliminates full-vector dependency, making\nit suitable for tiling and scale-out and avoiding costly top-k search. A key\ninnovation of our approach is the development of efficient numerical\ncompensation techniques, which help preserve model accuracy even under\naggressive pruning of attention scores.",
      "pdf_url": "http://arxiv.org/pdf/2502.08363v1",
      "published": "2025-02-12T12:50:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.08363v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "68T01",
        "I.2"
      ]
    },
    {
      "title": "Trustworthy GNNs with LLMs: A Systematic Review and Taxonomy",
      "authors": [
        "Ruizhan Xue",
        "Huimin Deng",
        "Fang He",
        "Maojun Wang",
        "Zeyu Zhang"
      ],
      "abstract": "With the extensive application of Graph Neural Networks (GNNs) across various\ndomains, their trustworthiness has emerged as a focal point of research. Some\nexisting studies have shown that the integration of large language models\n(LLMs) can improve the semantic understanding and generation capabilities of\nGNNs, which in turn improves the trustworthiness of GNNs from various aspects.\nOur review introduces a taxonomy that offers researchers a clear framework for\ncomprehending the principles and applications of different methods and helps\nclarify the connections and differences among various approaches. Then we\nsystematically survey representative approaches along the four categories of\nour taxonomy. Through our taxonomy, researchers can understand the applicable\nscenarios, potential advantages, and limitations of each approach for the the\ntrusted integration of GNNs with LLMs. Finally, we present some promising\ndirections of work and future trends for the integration of LLMs and GNNs to\nimprove model trustworthiness.",
      "pdf_url": "http://arxiv.org/pdf/2502.08353v1",
      "published": "2025-02-12T12:28:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.08353v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Graph Foundation Models for Recommendation: A Comprehensive Survey",
      "authors": [
        "Bin Wu",
        "Yihang Wang",
        "Yuanhao Zeng",
        "Jiawei Liu",
        "Jiashu Zhao",
        "Cheng Yang",
        "Yawen Li",
        "Long Xia",
        "Dawei Yin",
        "Chuan Shi"
      ],
      "abstract": "Recommender systems (RS) serve as a fundamental tool for navigating the vast\nexpanse of online information, with deep learning advancements playing an\nincreasingly important role in improving ranking accuracy. Among these, graph\nneural networks (GNNs) excel at extracting higher-order structural information,\nwhile large language models (LLMs) are designed to process and comprehend\nnatural language, making both approaches highly effective and widely adopted.\nRecent research has focused on graph foundation models (GFMs), which integrate\nthe strengths of GNNs and LLMs to model complex RS problems more efficiently by\nleveraging the graph-based structure of user-item relationships alongside\ntextual understanding. In this survey, we provide a comprehensive overview of\nGFM-based RS technologies by introducing a clear taxonomy of current\napproaches, diving into methodological details, and highlighting key challenges\nand future directions. By synthesizing recent advancements, we aim to offer\nvaluable insights into the evolving landscape of GFM-based recommender systems.",
      "pdf_url": "http://arxiv.org/pdf/2502.08346v1",
      "published": "2025-02-12T12:13:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.08346v1",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Hierarchical Learning-based Graph Partition for Large-scale Vehicle Routing Problems",
      "authors": [
        "Yuxin Pan",
        "Ruohong Liu",
        "Yize Chen",
        "Zhiguang Cao",
        "Fangzhen Lin"
      ],
      "abstract": "Neural solvers based on the divide-and-conquer approach for Vehicle Routing\nProblems (VRPs) in general, and capacitated VRP (CVRP) in particular,\nintegrates the global partition of an instance with local constructions for\neach subproblem to enhance generalization. However, during the global partition\nphase, misclusterings within subgraphs have a tendency to progressively\ncompound throughout the multi-step decoding process of the learning-based\npartition policy. This suboptimal behavior in the global partition phase, in\nturn, may lead to a dramatic deterioration in the performance of the overall\ndecomposition-based system, despite using optimal local constructions. To\naddress these challenges, we propose a versatile Hierarchical Learning-based\nGraph Partition (HLGP) framework, which is tailored to benefit the partition of\nCVRP instances by synergistically integrating global and local partition\npolicies. Specifically, the global partition policy is tasked with creating the\ncoarse multi-way partition to generate the sequence of simpler two-way\npartition subtasks. These subtasks mark the initiation of the subsequent K\nlocal partition levels. At each local partition level, subtasks exclusive for\nthis level are assigned to the local partition policy which benefits from the\ninsensitive local topological features to incrementally alleviate the\ncompounded errors. This framework is versatile in the sense that it optimizes\nthe involved partition policies towards a unified objective harmoniously\ncompatible with both reinforcement learning (RL) and supervised learning (SL).\n(*Due to the notification of arXiv \"The Abstract field cannot be longer than\n1,920 characters\", the appeared Abstract is shortened. For the full Abstract,\nplease download the Article.)",
      "pdf_url": "http://arxiv.org/pdf/2502.08340v1",
      "published": "2025-02-12T12:07:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.08340v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Hierarchical Multi-Agent Framework for Carbon-Efficient Liquid-Cooled Data Center Clusters",
      "authors": [
        "Soumyendu Sarkar",
        "Avisek Naug",
        "Antonio Guillen",
        "Vineet Gundecha",
        "Ricardo Luna Gutierrez",
        "Sahand Ghorbanpour",
        "Sajad Mousavi",
        "Ashwin Ramesh Babu",
        "Desik Rengarajan",
        "Cullen Bash"
      ],
      "abstract": "Reducing the environmental impact of cloud computing requires efficient\nworkload distribution across geographically dispersed Data Center Clusters\n(DCCs) and simultaneously optimizing liquid and air (HVAC) cooling with time\nshift of workloads within individual data centers (DC). This paper introduces\nGreen-DCC, which proposes a Reinforcement Learning (RL) based hierarchical\ncontroller to optimize both workload and liquid cooling dynamically in a DCC.\nBy incorporating factors such as weather, carbon intensity, and resource\navailability, Green-DCC addresses realistic constraints and interdependencies.\nWe demonstrate how the system optimizes multiple data centers synchronously,\nenabling the scope of digital twins, and compare the performance of various RL\napproaches based on carbon emissions and sustainability metrics while also\noffering a framework and benchmark simulation for broader ML research in\nsustainability.",
      "pdf_url": "http://arxiv.org/pdf/2502.08337v1",
      "published": "2025-02-12T12:00:58+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.08337v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ]
    },
    {
      "title": "Salience-Invariant Consistent Policy Learning for Generalization in Visual Reinforcement Learning",
      "authors": [
        "Sun Jingbo",
        "Tu Songjun",
        "Zhang Qichao",
        "Chen Ke",
        "Zhao Dongbin"
      ],
      "abstract": "Generalizing policies to unseen scenarios remains a critical challenge in\nvisual reinforcement learning, where agents often overfit to the specific\nvisual observations of the training environment. In unseen environments,\ndistracting pixels may lead agents to extract representations containing\ntask-irrelevant information. As a result, agents may deviate from the optimal\nbehaviors learned during training, thereby hindering visual generalization.To\naddress this issue, we propose the Salience-Invariant Consistent Policy\nLearning (SCPL) algorithm, an efficient framework for zero-shot generalization.\nOur approach introduces a novel value consistency module alongside a dynamics\nmodule to effectively capture task-relevant representations. The value\nconsistency module, guided by saliency, ensures the agent focuses on\ntask-relevant pixels in both original and perturbed observations, while the\ndynamics module uses augmented data to help the encoder capture dynamic- and\nreward-relevant representations. Additionally, our theoretical analysis\nhighlights the importance of policy consistency for generalization. To\nstrengthen this, we introduce a policy consistency module with a KL divergence\nconstraint to maintain consistent policies across original and perturbed\nobservations.Extensive experiments on the DMC-GB, Robotic Manipulation, and\nCARLA benchmarks demonstrate that SCPL significantly outperforms\nstate-of-the-art methods in terms of generalization. Notably, SCPL achieves\naverage performance improvements of 14\\%, 39\\%, and 69\\% in the challenging DMC\nvideo hard setting, the Robotic hard setting, and the CARLA benchmark,\nrespectively.Project Page: https://sites.google.com/view/scpl-rl.",
      "pdf_url": "http://arxiv.org/pdf/2502.08336v1",
      "published": "2025-02-12T12:00:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.08336v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Modification and Generated-Text Detection: Achieving Dual Detection Capabilities for the Outputs of LLM by Watermark",
      "authors": [
        "Yuhang Cai",
        "Yaofei Wang",
        "Donghui Hu",
        "Gu Chen"
      ],
      "abstract": "The development of large language models (LLMs) has raised concerns about\npotential misuse. One practical solution is to embed a watermark in the text,\nallowing ownership verification through watermark extraction. Existing methods\nprimarily focus on defending against modification attacks, often neglecting\nother spoofing attacks. For example, attackers can alter the watermarked text\nto produce harmful content without compromising the presence of the watermark,\nwhich could lead to false attribution of this malicious content to the LLM.\nThis situation poses a serious threat to the LLMs service providers and\nhighlights the significance of achieving modification detection and\ngenerated-text detection simultaneously. Therefore, we propose a technique to\ndetect modifications in text for unbiased watermark which is sensitive to\nmodification. We introduce a new metric called ``discarded tokens\", which\nmeasures the number of tokens not included in watermark detection. When a\nmodification occurs, this metric changes and can serve as evidence of the\nmodification. Additionally, we improve the watermark detection process and\nintroduce a novel method for unbiased watermark. Our experiments demonstrate\nthat we can achieve effective dual detection capabilities: modification\ndetection and generated-text detection by watermark.",
      "pdf_url": "http://arxiv.org/pdf/2502.08332v1",
      "published": "2025-02-12T11:56:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.08332v1",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "title": "Mitigating Hallucinations in Multimodal Spatial Relations through Constraint-Aware Prompting",
      "authors": [
        "Jiarui Wu",
        "Zhuo Liu",
        "Hangfeng He"
      ],
      "abstract": "Spatial relation hallucinations pose a persistent challenge in large\nvision-language models (LVLMs), leading to generate incorrect predictions about\nobject positions and spatial configurations within an image. To address this\nissue, we propose a constraint-aware prompting framework designed to reduce\nspatial relation hallucinations. Specifically, we introduce two types of\nconstraints: (1) bidirectional constraint, which ensures consistency in\npairwise object relations, and (2) transitivity constraint, which enforces\nrelational dependence across multiple objects. By incorporating these\nconstraints, LVLMs can produce more spatially coherent and consistent outputs.\nWe evaluate our method on three widely-used spatial relation datasets,\ndemonstrating performance improvements over existing approaches. Additionally,\na systematic analysis of various bidirectional relation analysis choices and\ntransitivity reference selections highlights greater possibilities of our\nmethods in incorporating constraints to mitigate spatial relation\nhallucinations.",
      "pdf_url": "http://arxiv.org/pdf/2502.08317v1",
      "published": "2025-02-12T11:32:19+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.08317v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "HDT: Hierarchical Discrete Transformer for Multivariate Time Series Forecasting",
      "authors": [
        "Shibo Feng",
        "Peilin Zhao",
        "Liu Liu",
        "Pengcheng Wu",
        "Zhiqi Shen"
      ],
      "abstract": "Generative models have gained significant attention in multivariate time\nseries forecasting (MTS), particularly due to their ability to generate\nhigh-fidelity samples. Forecasting the probability distribution of multivariate\ntime series is a challenging yet practical task. Although some recent attempts\nhave been made to handle this task, two major challenges persist: 1) some\nexisting generative methods underperform in high-dimensional multivariate time\nseries forecasting, which is hard to scale to higher dimensions; 2) the\ninherent high-dimensional multivariate attributes constrain the forecasting\nlengths of existing generative models. In this paper, we point out that\ndiscrete token representations can model high-dimensional MTS with faster\ninference time, and forecasting the target with long-term trends of itself can\nextend the forecasting length with high accuracy. Motivated by this, we propose\na vector quantized framework called Hierarchical Discrete Transformer (HDT)\nthat models time series into discrete token representations with l2\nnormalization enhanced vector quantized strategy, in which we transform the MTS\nforecasting into discrete tokens generation. To address the limitations of\ngenerative models in long-term forecasting, we propose a hierarchical discrete\nTransformer. This model captures the discrete long-term trend of the target at\nthe low level and leverages this trend as a condition to generate the discrete\nrepresentation of the target at the high level that introduces the features of\nthe target itself to extend the forecasting length in high-dimensional MTS.\nExtensive experiments on five popular MTS datasets verify the effectiveness of\nour proposed method.",
      "pdf_url": "http://arxiv.org/pdf/2502.08302v1",
      "published": "2025-02-12T11:03:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.08302v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Compromising Honesty and Harmlessness in Language Models via Deception Attacks",
      "authors": [
        "Laurène Vaugrante",
        "Francesca Carlon",
        "Maluna Menke",
        "Thilo Hagendorff"
      ],
      "abstract": "Recent research on large language models (LLMs) has demonstrated their\nability to understand and employ deceptive behavior, even without explicit\nprompting. However, such behavior has only been observed in rare, specialized\ncases and has not been shown to pose a serious risk to users. Additionally,\nresearch on AI alignment has made significant advancements in training models\nto refuse generating misleading or toxic content. As a result, LLMs generally\nbecame honest and harmless. In this study, we introduce a novel attack that\nundermines both of these traits, revealing a vulnerability that, if exploited,\ncould have serious real-world consequences. In particular, we introduce\nfine-tuning methods that enhance deception tendencies beyond model safeguards.\nThese \"deception attacks\" customize models to mislead users when prompted on\nchosen topics while remaining accurate on others. Furthermore, we find that\ndeceptive models also exhibit toxicity, generating hate speech, stereotypes,\nand other harmful content. Finally, we assess whether models can deceive\nconsistently in multi-turn dialogues, yielding mixed results. Given that\nmillions of users interact with LLM-based chatbots, voice assistants, agents,\nand other interfaces where trustworthiness cannot be ensured, securing these\nmodels against deception attacks is critical.",
      "pdf_url": "http://arxiv.org/pdf/2502.08301v1",
      "published": "2025-02-12T11:02:59+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.08301v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ]
    },
    {
      "title": "Improving Existing Optimization Algorithms with LLMs",
      "authors": [
        "Camilo Chacón Sartori",
        "Christian Blum"
      ],
      "abstract": "The integration of Large Language Models (LLMs) into optimization has created\na powerful synergy, opening exciting research opportunities. This paper\ninvestigates how LLMs can enhance existing optimization algorithms. Using their\npre-trained knowledge, we demonstrate their ability to propose innovative\nheuristic variations and implementation strategies. To evaluate this, we\napplied a non-trivial optimization algorithm, Construct, Merge, Solve and Adapt\n(CMSA) -- a hybrid metaheuristic for combinatorial optimization problems that\nincorporates a heuristic in the solution construction phase. Our results show\nthat an alternative heuristic proposed by GPT-4o outperforms the\nexpert-designed heuristic of CMSA, with the performance gap widening on larger\nand denser graphs. Project URL: https://imp-opt-algo-llms.surge.sh/",
      "pdf_url": "http://arxiv.org/pdf/2502.08298v1",
      "published": "2025-02-12T10:58:57+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.08298v1",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.SE",
        "I.2.7; I.2.8"
      ]
    },
    {
      "title": "CRISP: A Framework for Cryo-EM Image Segmentation and Processing with Conditional Random Field",
      "authors": [
        "Szu-Chi Chung",
        "Po-Cheng Chou"
      ],
      "abstract": "Differentiating signals from the background in micrographs is a critical\ninitial step for cryogenic electron microscopy (cryo-EM), yet it remains\nlaborious due to low signal-to-noise ratio (SNR), the presence of contaminants\nand densely packed particles of varying sizes. Although image segmentation has\nrecently been introduced to distinguish particles at the pixel level, the low\nSNR complicates the automated generation of accurate annotations for training\nsupervised models. Moreover, platforms for systematically comparing different\ndesign choices in pipeline construction are lacking. Thus, a modular framework\nis essential to understand the advantages and limitations of this approach and\ndrive further development. To address these challenges, we present a pipeline\nthat automatically generates high-quality segmentation maps from cryo-EM data\nto serve as ground truth labels. Our modular framework enables the selection of\nvarious segmentation models and loss functions. We also integrate Conditional\nRandom Fields (CRFs) with different solvers and feature sets to refine coarse\npredictions, thereby producing fine-grained segmentation. This flexibility\nfacilitates optimal configurations tailored to cryo-EM datasets. When trained\non a limited set of micrographs, our approach achieves over 90% accuracy,\nrecall, precision, Intersection over Union (IoU), and F1-score on synthetic\ndata. Furthermore, to demonstrate our framework's efficacy in downstream\nanalyses, we show that the particles extracted by our pipeline produce 3D\ndensity maps with higher resolution than those generated by existing particle\npickers on real experimental datasets, while achieving performance comparable\nto that of manually curated datasets from experts.",
      "pdf_url": "http://arxiv.org/pdf/2502.08287v1",
      "published": "2025-02-12T10:44:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.08287v1",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Individualised Treatment Effects Estimation with Composite Treatments and Composite Outcomes",
      "authors": [
        "Vinod Kumar Chauhan",
        "Lei Clifton",
        "Gaurav Nigam",
        "David A. Clifton"
      ],
      "abstract": "Estimating individualised treatment effect (ITE) -- that is the causal effect\nof a set of variables (also called exposures, treatments, actions, policies, or\ninterventions), referred to as \\textit{composite treatments}, on a set of\noutcome variables of interest, referred to as \\textit{composite outcomes}, for\na unit from observational data -- remains a fundamental problem in causal\ninference with applications across disciplines, such as healthcare, economics,\neducation, social science, marketing, and computer science. Previous work in\ncausal machine learning for ITE estimation is limited to simple settings, like\nsingle treatments and single outcomes. This hinders their use in complex\nreal-world scenarios; for example, consider studying the effect of different\nICU interventions, such as beta-blockers and statins for a patient admitted for\nheart surgery, on different outcomes of interest such as atrial fibrillation\nand in-hospital mortality. The limited research into composite treatments and\noutcomes is primarily due to data scarcity for all treatments and outcomes. To\naddress the above challenges, we propose a novel and innovative\nhypernetwork-based approach, called \\emph{H-Learner}, to solve ITE estimation\nunder composite treatments and composite outcomes, which tackles the data\nscarcity issue by dynamically sharing information across treatments and\noutcomes. Our empirical analysis with binary and arbitrary composite treatments\nand outcomes demonstrates the effectiveness of the proposed approach compared\nto existing methods.",
      "pdf_url": "http://arxiv.org/pdf/2502.08282v1",
      "published": "2025-02-12T10:41:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.08282v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "What Is That Talk About? A Video-to-Text Summarization Dataset for Scientific Presentations",
      "authors": [
        "Dongqi Liu",
        "Chenxi Whitehouse",
        "Xi Yu",
        "Louis Mahon",
        "Rohit Saxena",
        "Zheng Zhao",
        "Yifu Qiu",
        "Mirella Lapata",
        "Vera Demberg"
      ],
      "abstract": "Transforming recorded videos into concise and accurate textual summaries is a\ngrowing challenge in multimodal learning. This paper introduces VISTA, a\ndataset specifically designed for video-to-text summarization in scientific\ndomains. VISTA contains 18,599 recorded AI conference presentations paired with\ntheir corresponding paper abstracts. We benchmark the performance of\nstate-of-the-art large models and apply a plan-based framework to better\ncapture the structured nature of abstracts. Both human and automated\nevaluations confirm that explicit planning enhances summary quality and factual\nconsistency. However, a considerable gap remains between models and human\nperformance, highlighting the challenges of scientific video summarization.",
      "pdf_url": "http://arxiv.org/pdf/2502.08279v1",
      "published": "2025-02-12T10:36:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.08279v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Dealing with Annotator Disagreement in Hate Speech Classification",
      "authors": [
        "Somaiyeh Dehghan",
        "Mehmet Umut Sen",
        "Berrin Yanikoglu"
      ],
      "abstract": "Hate speech detection is a crucial task, especially on social media, where\nharmful content can spread quickly. Implementing machine learning models to\nautomatically identify and address hate speech is essential for mitigating its\nimpact and preventing its proliferation. The first step in developing an\neffective hate speech detection model is to acquire a high-quality dataset for\ntraining. Labeled data is foundational for most natural language processing\ntasks, but categorizing hate speech is difficult due to the diverse and often\nsubjective nature of hate speech, which can lead to varying interpretations and\ndisagreements among annotators. This paper examines strategies for addressing\nannotator disagreement, an issue that has been largely overlooked. In\nparticular, we evaluate different approaches to deal with annotator\ndisagreement regarding hate speech classification in Turkish tweets, based on a\nfine-tuned BERT model. Our work highlights the importance of the problem and\nprovides state-of-art benchmark results for detection and understanding of hate\nspeech in online discourse.",
      "pdf_url": "http://arxiv.org/pdf/2502.08266v1",
      "published": "2025-02-12T10:19:50+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.08266v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "I.2; I.2.7"
      ]
    },
    {
      "title": "Exploring the Potential of Large Language Models to Simulate Personality",
      "authors": [
        "Maria Molchanova",
        "Anna Mikhailova",
        "Anna Korzanova",
        "Lidiia Ostyakova",
        "Alexandra Dolidze"
      ],
      "abstract": "With the advancement of large language models (LLMs), the focus in\nConversational AI has shifted from merely generating coherent and relevant\nresponses to tackling more complex challenges, such as personalizing dialogue\nsystems. In an effort to enhance user engagement, chatbots are often designed\nto mimic human behaviour, responding within a defined emotional spectrum and\naligning to a set of values. In this paper, we aim to simulate personal traits\naccording to the Big Five model with the use of LLMs. Our research showed that\ngenerating personality-related texts is still a challenging task for the\nmodels. As a result, we present a dataset of generated texts with the\npredefined Big Five characteristics and provide an analytical framework for\ntesting LLMs on a simulation of personality skills.",
      "pdf_url": "http://arxiv.org/pdf/2502.08265v1",
      "published": "2025-02-12T10:17:18+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.08265v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    }
  ]
}