{
  "last_updated": "2025-07-25T00:56:34.160013",
  "papers": [
    {
      "title": "Large Learning Rates Simultaneously Achieve Robustness to Spurious Correlations and Compressibility",
      "authors": [
        "Melih Barsbey",
        "Lucas Prieto",
        "Stefanos Zafeiriou",
        "Tolga Birdal"
      ],
      "abstract": "Robustness and resource-efficiency are two highly desirable properties for\nmodern machine learning models. However, achieving them jointly remains a\nchallenge. In this paper, we position high learning rates as a facilitator for\nsimultaneously achieving robustness to spurious correlations and network\ncompressibility. We demonstrate that large learning rates also produce\ndesirable representation properties such as invariant feature utilization,\nclass separation, and activation sparsity. Importantly, our findings indicate\nthat large learning rates compare favorably to other hyperparameters and\nregularization methods, in consistently satisfying these properties in tandem.\nIn addition to demonstrating the positive effect of large learning rates across\ndiverse spurious correlation datasets, models, and optimizers, we also present\nstrong evidence that the previously documented success of large learning rates\nin standard classification tasks is likely due to its effect on addressing\nhidden/rare spurious correlations in the training dataset.",
      "pdf_url": "http://arxiv.org/pdf/2507.17748v1",
      "published": "2025-07-23T17:59:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.17748v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "stat.ML"
      ]
    },
    {
      "title": "Pretraining on the Test Set Is No Longer All You Need: A Debate-Driven Approach to QA Benchmarks",
      "authors": [
        "Linbo Cao",
        "Jinman Zhao"
      ],
      "abstract": "As frontier language models increasingly saturate standard QA benchmarks,\nconcerns about data contamination, memorization, and escalating dataset\ncreation costs persist. We propose a debate-driven evaluation paradigm that\ntransforms any existing QA dataset into structured adversarial debates--where\none model is given the official answer to defend, and another constructs and\ndefends an alternative answer--adjudicated by a judge model blind to the\ncorrect solution. By forcing multi-round argumentation, this approach\nsubstantially increases difficulty while penalizing shallow memorization, yet\nreuses QA items to reduce curation overhead. We make two main contributions:\n(1) an evaluation pipeline to systematically convert QA tasks into debate-based\nassessments, and (2) a public benchmark that demonstrates our paradigm's\neffectiveness on a subset of MMLU-Pro questions, complete with standardized\nprotocols and reference models. Empirical results validate the robustness of\nthe method and its effectiveness against data contamination--a Llama 3.1 model\nfine-tuned on test questions showed dramatic accuracy improvements (50% -> 82%)\nbut performed worse in debates. Results also show that even weaker judges can\nreliably differentiate stronger debaters, highlighting how debate-based\nevaluation can scale to future, more capable systems while maintaining a\nfraction of the cost of creating new benchmarks. Overall, our framework\nunderscores that \"pretraining on the test set is no longer all you need,\"\noffering a sustainable path for measuring the genuine reasoning ability of\nadvanced language models.",
      "pdf_url": "http://arxiv.org/pdf/2507.17747v1",
      "published": "2025-07-23T17:58:14+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.17747v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Rubrics as Rewards: Reinforcement Learning Beyond Verifiable Domains",
      "authors": [
        "Anisha Gunjal",
        "Anthony Wang",
        "Elaine Lau",
        "Vaskar Nath",
        "Bing Liu",
        "Sean Hendryx"
      ],
      "abstract": "Extending Reinforcement Learning with Verifiable Rewards (RLVR) to real-world\ntasks often requires balancing objective and subjective evaluation criteria.\nHowever, many such tasks lack a single, unambiguous ground truth-making it\ndifficult to define reliable reward signals for post-training language models.\nWhile traditional preference-based methods offer a workaround, they rely on\nopaque reward functions that are difficult to interpret and prone to spurious\ncorrelations. We introduce $\\textbf{Rubrics as Rewards}$ (RaR), a framework\nthat uses structured, checklist-style rubrics as interpretable reward signals\nfor on-policy training with GRPO. Our best RaR method yields up to a $28\\%$\nrelative improvement on HealthBench-1k compared to simple Likert-based\napproaches, while matching or surpassing the performance of reward signals\nderived from expert-written references. By treating rubrics as structured\nreward signals, we show that RaR enables smaller-scale judge models to better\nalign with human preferences and sustain robust performance across model\nscales.",
      "pdf_url": "http://arxiv.org/pdf/2507.17746v1",
      "published": "2025-07-23T17:57:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.17746v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Ultra3D: Efficient and High-Fidelity 3D Generation with Part Attention",
      "authors": [
        "Yiwen Chen",
        "Zhihao Li",
        "Yikai Wang",
        "Hu Zhang",
        "Qin Li",
        "Chi Zhang",
        "Guosheng Lin"
      ],
      "abstract": "Recent advances in sparse voxel representations have significantly improved\nthe quality of 3D content generation, enabling high-resolution modeling with\nfine-grained geometry. However, existing frameworks suffer from severe\ncomputational inefficiencies due to the quadratic complexity of attention\nmechanisms in their two-stage diffusion pipelines. In this work, we propose\nUltra3D, an efficient 3D generation framework that significantly accelerates\nsparse voxel modeling without compromising quality. Our method leverages the\ncompact VecSet representation to efficiently generate a coarse object layout in\nthe first stage, reducing token count and accelerating voxel coordinate\nprediction. To refine per-voxel latent features in the second stage, we\nintroduce Part Attention, a geometry-aware localized attention mechanism that\nrestricts attention computation within semantically consistent part regions.\nThis design preserves structural continuity while avoiding unnecessary global\nattention, achieving up to 6.7x speed-up in latent generation. To support this\nmechanism, we construct a scalable part annotation pipeline that converts raw\nmeshes into part-labeled sparse voxels. Extensive experiments demonstrate that\nUltra3D supports high-resolution 3D generation at 1024 resolution and achieves\nstate-of-the-art performance in both visual fidelity and user preference.",
      "pdf_url": "http://arxiv.org/pdf/2507.17745v1",
      "published": "2025-07-23T17:57:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.17745v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Yume: An Interactive World Generation Model",
      "authors": [
        "Xiaofeng Mao",
        "Shaoheng Lin",
        "Zhen Li",
        "Chuanhao Li",
        "Wenshuo Peng",
        "Tong He",
        "Jiangmiao Pang",
        "Mingmin Chi",
        "Yu Qiao",
        "Kaipeng Zhang"
      ],
      "abstract": "Yume aims to use images, text, or videos to create an interactive, realistic,\nand dynamic world, which allows exploration and control using peripheral\ndevices or neural signals. In this report, we present a preview version of\n\\method, which creates a dynamic world from an input image and allows\nexploration of the world using keyboard actions. To achieve this high-fidelity\nand interactive video world generation, we introduce a well-designed framework,\nwhich consists of four main components, including camera motion quantization,\nvideo generation architecture, advanced sampler, and model acceleration. First,\nwe quantize camera motions for stable training and user-friendly interaction\nusing keyboard inputs. Then, we introduce the Masked Video Diffusion\nTransformer~(MVDT) with a memory module for infinite video generation in an\nautoregressive manner. After that, training-free Anti-Artifact Mechanism (AAM)\nand Time Travel Sampling based on Stochastic Differential Equations (TTS-SDE)\nare introduced to the sampler for better visual quality and more precise\ncontrol. Moreover, we investigate model acceleration by synergistic\noptimization of adversarial distillation and caching mechanisms. We use the\nhigh-quality world exploration dataset \\sekai to train \\method, and it achieves\nremarkable results in diverse scenes and applications. All data, codebase, and\nmodel weights are available on https://github.com/stdstu12/YUME. Yume will\nupdate monthly to achieve its original goal. Project page:\nhttps://stdstu12.github.io/YUME-Project/.",
      "pdf_url": "http://arxiv.org/pdf/2507.17744v1",
      "published": "2025-07-23T17:57:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.17744v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC"
      ]
    },
    {
      "title": "Flow Matching Meets Biology and Life Science: A Survey",
      "authors": [
        "Zihao Li",
        "Zhichen Zeng",
        "Xiao Lin",
        "Feihao Fang",
        "Yanru Qu",
        "Zhe Xu",
        "Zhining Liu",
        "Xuying Ning",
        "Tianxin Wei",
        "Ge Liu",
        "Hanghang Tong",
        "Jingrui He"
      ],
      "abstract": "Over the past decade, advances in generative modeling, such as generative\nadversarial networks, masked autoencoders, and diffusion models, have\nsignificantly transformed biological research and discovery, enabling\nbreakthroughs in molecule design, protein generation, drug discovery, and\nbeyond. At the same time, biological applications have served as valuable\ntestbeds for evaluating the capabilities of generative models. Recently, flow\nmatching has emerged as a powerful and efficient alternative to diffusion-based\ngenerative modeling, with growing interest in its application to problems in\nbiology and life sciences. This paper presents the first comprehensive survey\nof recent developments in flow matching and its applications in biological\ndomains. We begin by systematically reviewing the foundations and variants of\nflow matching, and then categorize its applications into three major areas:\nbiological sequence modeling, molecule generation and design, and peptide and\nprotein generation. For each, we provide an in-depth review of recent progress.\nWe also summarize commonly used datasets and software tools, and conclude with\na discussion of potential future directions. The corresponding curated\nresources are available at\nhttps://github.com/Violet24K/Awesome-Flow-Matching-Meets-Biology.",
      "pdf_url": "http://arxiv.org/pdf/2507.17731v1",
      "published": "2025-07-23T17:44:29+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.17731v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Online Submission and Evaluation System Design for Competition Operations",
      "authors": [
        "Zhe Chen",
        "Daniel Harabor",
        "Ryan Hechnenberger",
        "Nathan R. Sturtevant"
      ],
      "abstract": "Research communities have developed benchmark datasets across domains to\ncompare the performance of algorithms and techniques However, tracking the\nprogress in these research areas is not easy, as publications appear in\ndifferent venues at the same time, and many of them claim to represent the\nstate-of-the-art. To address this, research communities often organise periodic\ncompetitions to evaluate the performance of various algorithms and techniques,\nthereby tracking advancements in the field. However, these competitions pose a\nsignificant operational burden. The organisers must manage and evaluate a large\nvolume of submissions. Furthermore, participants typically develop their\nsolutions in diverse environments, leading to compatibility issues during the\nevaluation of their submissions. This paper presents an online competition\nsystem that automates the submission and evaluation process for a competition.\nThe competition system allows organisers to manage large numbers of submissions\nefficiently, utilising isolated environments to evaluate submissions. This\nsystem has already been used successfully for several competitions, including\nthe Grid-Based Pathfinding Competition and the League of Robot Runners\ncompetition.",
      "pdf_url": "http://arxiv.org/pdf/2507.17730v1",
      "published": "2025-07-23T17:44:10+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.17730v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "On the Interaction of Compressibility and Adversarial Robustness",
      "authors": [
        "Melih Barsbey",
        "Antônio H. Ribeiro",
        "Umut Şimşekli",
        "Tolga Birdal"
      ],
      "abstract": "Modern neural networks are expected to simultaneously satisfy a host of\ndesirable properties: accurate fitting to training data, generalization to\nunseen inputs, parameter and computational efficiency, and robustness to\nadversarial perturbations. While compressibility and robustness have each been\nstudied extensively, a unified understanding of their interaction still remains\nelusive. In this work, we develop a principled framework to analyze how\ndifferent forms of compressibility - such as neuron-level sparsity and spectral\ncompressibility - affect adversarial robustness. We show that these forms of\ncompression can induce a small number of highly sensitive directions in the\nrepresentation space, which adversaries can exploit to construct effective\nperturbations. Our analysis yields a simple yet instructive robustness bound,\nrevealing how neuron and spectral compressibility impact $L_\\infty$ and $L_2$\nrobustness via their effects on the learned representations. Crucially, the\nvulnerabilities we identify arise irrespective of how compression is achieved -\nwhether via regularization, architectural bias, or implicit learning dynamics.\nThrough empirical evaluations across synthetic and realistic tasks, we confirm\nour theoretical predictions, and further demonstrate that these vulnerabilities\npersist under adversarial training and transfer learning, and contribute to the\nemergence of universal adversarial perturbations. Our findings show a\nfundamental tension between structured compressibility and robustness, and\nsuggest new pathways for designing models that are both efficient and secure.",
      "pdf_url": "http://arxiv.org/pdf/2507.17725v1",
      "published": "2025-07-23T17:35:48+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.17725v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "stat.ML"
      ]
    },
    {
      "title": "AI Telephone Surveying: Automating Quantitative Data Collection with an AI Interviewer",
      "authors": [
        "Danny D. Leybzon",
        "Shreyas Tirumala",
        "Nishant Jain",
        "Summer Gillen",
        "Michael Jackson",
        "Cameron McPhee",
        "Jennifer Schmidt"
      ],
      "abstract": "With the rise of voice-enabled artificial intelligence (AI) systems,\nquantitative survey researchers have access to a new data-collection mode: AI\ntelephone surveying. By using AI to conduct phone interviews, researchers can\nscale quantitative studies while balancing the dual goals of human-like\ninteractivity and methodological rigor. Unlike earlier efforts that used\ninteractive voice response (IVR) technology to automate these surveys, voice AI\nenables a more natural and adaptive respondent experience as it is more robust\nto interruptions, corrections, and other idiosyncrasies of human speech.\n  We built and tested an AI system to conduct quantitative surveys based on\nlarge language models (LLM), automatic speech recognition (ASR), and speech\nsynthesis technologies. The system was specifically designed for quantitative\nresearch, and strictly adhered to research best practices like question order\nrandomization, answer order randomization, and exact wording.\n  To validate the system's effectiveness, we deployed it to conduct two pilot\nsurveys with the SSRS Opinion Panel and followed-up with a separate\nhuman-administered survey to assess respondent experiences. We measured three\nkey metrics: the survey completion rates, break-off rates, and respondent\nsatisfaction scores. Our results suggest that shorter instruments and more\nresponsive AI interviewers may contribute to improvements across all three\nmetrics studied.",
      "pdf_url": "http://arxiv.org/pdf/2507.17718v1",
      "published": "2025-07-23T17:30:14+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.17718v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ]
    },
    {
      "title": "From Feedback to Checklists: Grounded Evaluation of AI-Generated Clinical Notes",
      "authors": [
        "Karen Zhou",
        "John Giorgi",
        "Pranav Mani",
        "Peng Xu",
        "Davis Liang",
        "Chenhao Tan"
      ],
      "abstract": "AI-generated clinical notes are increasingly used in healthcare, but\nevaluating their quality remains a challenge due to high subjectivity and\nlimited scalability of expert review. Existing automated metrics often fail to\nalign with real-world physician preferences. To address this, we propose a\npipeline that systematically distills real user feedback into structured\nchecklists for note evaluation. These checklists are designed to be\ninterpretable, grounded in human feedback, and enforceable by LLM-based\nevaluators. Using deidentified data from over 21,000 clinical encounters,\nprepared in accordance with the HIPAA safe harbor standard, from a deployed AI\nmedical scribe system, we show that our feedback-derived checklist outperforms\nbaseline approaches in our offline evaluations in coverage, diversity, and\npredictive power for human ratings. Extensive experiments confirm the\nchecklist's robustness to quality-degrading perturbations, significant\nalignment with clinician preferences, and practical value as an evaluation\nmethodology. In offline research settings, the checklist can help identify\nnotes likely to fall below our chosen quality thresholds.",
      "pdf_url": "http://arxiv.org/pdf/2507.17717v1",
      "published": "2025-07-23T17:28:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.17717v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Thinking Isn't an Illusion: Overcoming the Limitations of Reasoning Models via Tool Augmentations",
      "authors": [
        "Zhao Song",
        "Song Yue",
        "Jiahao Zhang"
      ],
      "abstract": "Large Reasoning Models (LRMs) have become a central focus in today's large\nlanguage model (LLM) research, where models are designed to output a\nstep-by-step thinking process before arriving at a final answer to handle\ncomplex reasoning tasks. Despite their promise, recent empirical studies (e.g.,\n[Shojaee et al., 2025] from Apple) suggest that this thinking process may not\nactually enhance reasoning ability, where LLMs without explicit reasoning\nactually outperform LRMs on tasks with low or high complexity. In this work, we\nrevisit these findings and investigate whether the limitations of LRMs persist\nwhen tool augmentations are introduced. We incorporate two types of tools,\nPython interpreters and scratchpads, and evaluate three representative LLMs and\ntheir LRM counterparts on Apple's benchmark reasoning puzzles. Our results show\nthat, with proper tool use, LRMs consistently outperform their non-reasoning\ncounterparts across all levels of task complexity. These findings challenge the\nrecent narrative that reasoning is an illusion and highlight the potential of\ntool-augmented LRMs for solving complex problems.",
      "pdf_url": "http://arxiv.org/pdf/2507.17699v1",
      "published": "2025-07-23T17:04:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.17699v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Symbiotic Agents: A Novel Paradigm for Trustworthy AGI-driven Networks",
      "authors": [
        "Ilias Chatzistefanidis",
        "Navid Nikaein"
      ],
      "abstract": "Large Language Model (LLM)-based autonomous agents are expected to play a\nvital role in the evolution of 6G networks, by empowering real-time\ndecision-making related to management and service provisioning to end-users.\nThis shift facilitates the transition from a specialized intelligence approach,\nwhere artificial intelligence (AI) algorithms handle isolated tasks, to\nartificial general intelligence (AGI)-driven networks, where agents possess\nbroader reasoning capabilities and can manage diverse network functions. In\nthis paper, we introduce a novel agentic paradigm that combines LLMs with\nreal-time optimization algorithms towards Trustworthy AI, defined as symbiotic\nagents. Optimizers at the LLM's input-level provide bounded uncertainty\nsteering for numerically precise tasks, whereas output-level optimizers\nsupervised by the LLM enable adaptive real-time control. We design and\nimplement two novel agent types including: (i) Radio Access Network optimizers,\nand (ii) multi-agent negotiators for Service-Level Agreements (SLAs). We\nfurther propose an end-to-end architecture for AGI networks and evaluate it on\na 5G testbed capturing channel fluctuations from moving vehicles. Results show\nthat symbiotic agents reduce decision errors fivefold compared to standalone\nLLM-based agents, while smaller language models (SLM) achieve similar accuracy\nwith a 99.9% reduction in GPU resource overhead and in near-real-time loops of\n82 ms. A multi-agent demonstration for collaborative RAN on the real-world\ntestbed highlights significant flexibility in service-level agreement and\nresource allocation, reducing RAN over-utilization by approximately 44%.\nDrawing on our findings and open-source implementations, we introduce the\nsymbiotic paradigm as the foundation for next-generation, AGI-driven\nnetworks-systems designed to remain adaptable, efficient, and trustworthy even\nas LLMs advance.",
      "pdf_url": "http://arxiv.org/pdf/2507.17695v1",
      "published": "2025-07-23T17:01:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.17695v1",
      "categories": [
        "cs.AI",
        "cs.NI"
      ]
    },
    {
      "title": "CASCADE: LLM-Powered JavaScript Deobfuscator at Google",
      "authors": [
        "Shan Jiang",
        "Pranoy Kovuri",
        "David Tao",
        "Zhixun Tan"
      ],
      "abstract": "Software obfuscation, particularly prevalent in JavaScript, hinders code\ncomprehension and analysis, posing significant challenges to software testing,\nstatic analysis, and malware detection. This paper introduces CASCADE, a novel\nhybrid approach that integrates the advanced coding capabilities of Gemini with\nthe deterministic transformation capabilities of a compiler Intermediate\nRepresentation (IR), specifically JavaScript IR (JSIR). By employing Gemini to\nidentify critical prelude functions, the foundational components underlying the\nmost prevalent obfuscation techniques, and leveraging JSIR for subsequent code\ntransformations, CASCADE effectively recovers semantic elements like original\nstrings and API names, and reveals original program behaviors. This method\novercomes limitations of existing static and dynamic deobfuscation techniques,\neliminating hundreds to thousands of hardcoded rules while achieving\nreliability and flexibility. CASCADE is already deployed in Google's production\nenvironment, demonstrating substantial improvements in JavaScript deobfuscation\nefficiency and reducing reverse engineering efforts.",
      "pdf_url": "http://arxiv.org/pdf/2507.17691v1",
      "published": "2025-07-23T16:57:32+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.17691v1",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CR",
        "cs.LG",
        "cs.PL"
      ]
    },
    {
      "title": "Simulating multiple human perspectives in socio-ecological systems using large language models",
      "authors": [
        "Yongchao Zeng",
        "Calum Brown",
        "Ioannis Kyriakou",
        "Ronja Hotz",
        "Mark Rounsevell"
      ],
      "abstract": "Understanding socio-ecological systems requires insights from diverse\nstakeholder perspectives, which are often hard to access. To enable\nalternative, simulation-based exploration of different stakeholder\nperspectives, we develop the HoPeS (Human-Oriented Perspective Shifting)\nmodelling framework. HoPeS employs agents powered by large language models\n(LLMs) to represent various stakeholders; users can step into the agent roles\nto experience perspectival differences. A simulation protocol serves as a\n\"scaffold\" to streamline multiple perspective-taking simulations, supporting\nusers in reflecting on, transitioning between, and integrating across\nperspectives. A prototype system is developed to demonstrate HoPeS in the\ncontext of institutional dynamics and land use change, enabling both\nnarrative-driven and numerical experiments. In an illustrative experiment, a\nuser successively adopts the perspectives of a system observer and a researcher\n- a role that analyses data from the embedded land use model to inform\nevidence-based decision-making for other LLM agents representing various\ninstitutions. Despite the user's effort to recommend technically sound\npolicies, discrepancies persist between the policy recommendation and\nimplementation due to stakeholders' competing advocacies, mirroring real-world\nmisalignment between researcher and policymaker perspectives. The user's\nreflection highlights the subjective feelings of frustration and disappointment\nas a researcher, especially due to the challenge of maintaining political\nneutrality while attempting to gain political influence. Despite this, the user\nexhibits high motivation to experiment with alternative narrative framing\nstrategies, suggesting the system's potential in exploring different\nperspectives. Further system and protocol refinement are likely to enable new\nforms of interdisciplinary collaboration in socio-ecological simulations.",
      "pdf_url": "http://arxiv.org/pdf/2507.17680v1",
      "published": "2025-07-23T16:42:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.17680v1",
      "categories": [
        "cs.AI",
        "cs.CY"
      ]
    },
    {
      "title": "How Should We Meta-Learn Reinforcement Learning Algorithms?",
      "authors": [
        "Alexander David Goldie",
        "Zilin Wang",
        "Jakob Nicolaus Foerster",
        "Shimon Whiteson"
      ],
      "abstract": "The process of meta-learning algorithms from data, instead of relying on\nmanual design, is growing in popularity as a paradigm for improving the\nperformance of machine learning systems. Meta-learning shows particular promise\nfor reinforcement learning (RL), where algorithms are often adapted from\nsupervised or unsupervised learning despite their suboptimality for RL.\nHowever, until now there has been a severe lack of comparison between different\nmeta-learning algorithms, such as using evolution to optimise over black-box\nfunctions or LLMs to propose code. In this paper, we carry out this empirical\ncomparison of the different approaches when applied to a range of meta-learned\nalgorithms which target different parts of the RL pipeline. In addition to\nmeta-train and meta-test performance, we also investigate factors including the\ninterpretability, sample cost and train time for each meta-learning algorithm.\nBased on these findings, we propose several guidelines for meta-learning new RL\nalgorithms which will help ensure that future learned algorithms are as\nperformant as possible.",
      "pdf_url": "http://arxiv.org/pdf/2507.17668v1",
      "published": "2025-07-23T16:31:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.17668v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Vision Transformer attention alignment with human visual perception in aesthetic object evaluation",
      "authors": [
        "Miguel Carrasco",
        "César González-Martín",
        "José Aranda",
        "Luis Oliveros"
      ],
      "abstract": "Visual attention mechanisms play a crucial role in human perception and\naesthetic evaluation. Recent advances in Vision Transformers (ViTs) have\ndemonstrated remarkable capabilities in computer vision tasks, yet their\nalignment with human visual attention patterns remains underexplored,\nparticularly in aesthetic contexts. This study investigates the correlation\nbetween human visual attention and ViT attention mechanisms when evaluating\nhandcrafted objects. We conducted an eye-tracking experiment with 30\nparticipants (9 female, 21 male, mean age 24.6 years) who viewed 20 artisanal\nobjects comprising basketry bags and ginger jars. Using a Pupil Labs\neye-tracker, we recorded gaze patterns and generated heat maps representing\nhuman visual attention. Simultaneously, we analyzed the same objects using a\npre-trained ViT model with DINO (Self-DIstillation with NO Labels), extracting\nattention maps from each of the 12 attention heads. We compared human and ViT\nattention distributions using Kullback-Leibler divergence across varying\nGaussian parameters (sigma=0.1 to 3.0). Statistical analysis revealed optimal\ncorrelation at sigma=2.4 +-0.03, with attention head #12 showing the strongest\nalignment with human visual patterns. Significant differences were found\nbetween attention heads, with heads #7 and #9 demonstrating the greatest\ndivergence from human attention (p< 0.05, Tukey HSD test). Results indicate\nthat while ViTs exhibit more global attention patterns compared to human focal\nattention, certain attention heads can approximate human visual behavior,\nparticularly for specific object features like buckles in basketry items. These\nfindings suggest potential applications of ViT attention mechanisms in product\ndesign and aesthetic evaluation, while highlighting fundamental differences in\nattention strategies between human perception and current AI models.",
      "pdf_url": "http://arxiv.org/pdf/2507.17616v1",
      "published": "2025-07-23T15:47:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.17616v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "PRIX: Learning to Plan from Raw Pixels for End-to-End Autonomous Driving",
      "authors": [
        "Maciej K. Wozniak",
        "Lianhang Liu",
        "Yixi Cai",
        "Patric Jensfelt"
      ],
      "abstract": "While end-to-end autonomous driving models show promising results, their\npractical deployment is often hindered by large model sizes, a reliance on\nexpensive LiDAR sensors and computationally intensive BEV feature\nrepresentations. This limits their scalability, especially for mass-market\nvehicles equipped only with cameras. To address these challenges, we propose\nPRIX (Plan from Raw Pixels). Our novel and efficient end-to-end driving\narchitecture operates using only camera data, without explicit BEV\nrepresentation and forgoing the need for LiDAR. PRIX leverages a visual feature\nextractor coupled with a generative planning head to predict safe trajectories\nfrom raw pixel inputs directly. A core component of our architecture is the\nContext-aware Recalibration Transformer (CaRT), a novel module designed to\neffectively enhance multi-level visual features for more robust planning. We\ndemonstrate through comprehensive experiments that PRIX achieves\nstate-of-the-art performance on the NavSim and nuScenes benchmarks, matching\nthe capabilities of larger, multimodal diffusion planners while being\nsignificantly more efficient in terms of inference speed and model size, making\nit a practical solution for real-world deployment. Our work is open-source and\nthe code will be at https://maxiuw.github.io/prix.",
      "pdf_url": "http://arxiv.org/pdf/2507.17596v2",
      "published": "2025-07-23T15:28:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.17596v2",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ]
    },
    {
      "title": "Enhancing Quantum Federated Learning with Fisher Information-Based Optimization",
      "authors": [
        "Amandeep Singh Bhatia",
        "Sabre Kais"
      ],
      "abstract": "Federated Learning (FL) has become increasingly popular across different\nsectors, offering a way for clients to work together to train a global model\nwithout sharing sensitive data. It involves multiple rounds of communication\nbetween the global model and participating clients, which introduces several\nchallenges like high communication costs, heterogeneous client data, prolonged\nprocessing times, and increased vulnerability to privacy threats. In recent\nyears, the convergence of federated learning and parameterized quantum circuits\nhas sparked significant research interest, with promising implications for\nfields such as healthcare and finance. By enabling decentralized training of\nquantum models, it allows clients or institutions to collaboratively enhance\nmodel performance and outcomes while preserving data privacy. Recognizing that\nFisher information can quantify the amount of information that a quantum state\ncarries under parameter changes, thereby providing insight into its geometric\nand statistical properties. We intend to leverage this property to address the\naforementioned challenges. In this work, we propose a Quantum Federated\nLearning (QFL) algorithm that makes use of the Fisher information computed on\nlocal client models, with data distributed across heterogeneous partitions.\nThis approach identifies the critical parameters that significantly influence\nthe quantum model's performance, ensuring they are preserved during the\naggregation process. Our research assessed the effectiveness and feasibility of\nQFL by comparing its performance against other variants, and exploring the\nbenefits of incorporating Fisher information in QFL settings. Experimental\nresults on ADNI and MNIST datasets demonstrate the effectiveness of our\napproach in achieving better performance and robustness against the quantum\nfederated averaging method.",
      "pdf_url": "http://arxiv.org/pdf/2507.17580v1",
      "published": "2025-07-23T15:14:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.17580v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "cs.ET",
        "quant-ph"
      ]
    },
    {
      "title": "Constructing Ophthalmic MLLM for Positioning-diagnosis Collaboration Through Clinical Cognitive Chain Reasoning",
      "authors": [
        "Xinyao Liu",
        "Diping Song"
      ],
      "abstract": "Multimodal large language models (MLLMs) demonstrate significant potential in\nthe field of medical diagnosis. However, they face critical challenges in\nspecialized domains such as ophthalmology, particularly the fragmentation of\nannotation granularity and inconsistencies in clinical reasoning logic, which\nhinder precise cross-modal understanding. This paper introduces FundusExpert,\nan ophthalmology-specific MLLM with integrated positioning-diagnosis reasoning\ncapabilities, along with FundusGen, a dataset constructed through the\nintelligent Fundus-Engine system. Fundus-Engine automates localization and\nleverages MLLM-based semantic expansion to integrate global disease\nclassification, local object detection, and fine-grained feature analysis\nwithin a single fundus image. Additionally, by constructing a clinically\naligned cognitive chain, it guides the model to generate interpretable\nreasoning paths. FundusExpert, fine-tuned with instruction data from FundusGen,\nachieves the best performance in ophthalmic question-answering tasks,\nsurpassing the average accuracy of the 40B MedRegA by 26.6%. It also excels in\nzero-shot report generation tasks, achieving a clinical consistency of 77.0%,\nsignificantly outperforming GPT-4o's 47.6%. Furthermore, we reveal a scaling\nlaw between data quality and model capability ($L \\propto N^{0.068}$),\ndemonstrating that the cognitive alignment annotations in FundusGen enhance\ndata utilization efficiency. By integrating region-level localization with\ndiagnostic reasoning chains, our work develops a scalable, clinically-aligned\nMLLM and explores a pathway toward bridging the visual-language gap in specific\nMLLMs. Our project can be found at https://github.com/MeteorElf/FundusExpert.",
      "pdf_url": "http://arxiv.org/pdf/2507.17539v1",
      "published": "2025-07-23T14:19:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.17539v1",
      "categories": [
        "cs.AI",
        "cs.CV",
        "eess.IV"
      ]
    },
    {
      "title": "Federated Majorize-Minimization: Beyond Parameter Aggregation",
      "authors": [
        "Aymeric Dieuleveut",
        "Gersende Fort",
        "Mahmoud Hegazy",
        "Hoi-To Wai"
      ],
      "abstract": "This paper proposes a unified approach for designing stochastic optimization\nalgorithms that robustly scale to the federated learning setting. Our work\nstudies a class of Majorize-Minimization (MM) problems, which possesses a\nlinearly parameterized family of majorizing surrogate functions. This framework\nencompasses (proximal) gradient-based algorithms for (regularized) smooth\nobjectives, the Expectation Maximization algorithm, and many problems seen as\nvariational surrogate MM. We show that our framework motivates a unifying\nalgorithm called Stochastic Approximation Stochastic Surrogate MM (\\SSMM),\nwhich includes previous stochastic MM procedures as special instances. We then\nextend \\SSMM\\ to the federated setting, while taking into consideration common\nbottlenecks such as data heterogeneity, partial participation, and\ncommunication constraints; this yields \\QSMM. The originality of \\QSMM\\ is to\nlearn locally and then aggregate information characterizing the\n\\textit{surrogate majorizing function}, contrary to classical algorithms which\nlearn and aggregate the \\textit{original parameter}. Finally, to showcase the\nflexibility of this methodology beyond our theoretical setting, we use it to\ndesign an algorithm for computing optimal transport maps in the federated\nsetting.",
      "pdf_url": "http://arxiv.org/pdf/2507.17534v1",
      "published": "2025-07-23T14:13:19+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.17534v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC",
        "stat.ML"
      ]
    },
    {
      "title": "Integrating Physics-Based and Data-Driven Approaches for Probabilistic Building Energy Modeling",
      "authors": [
        "Leandro Von Krannichfeldt",
        "Kristina Orehounig",
        "Olga Fink"
      ],
      "abstract": "Building energy modeling is a key tool for optimizing the performance of\nbuilding energy systems. Historically, a wide spectrum of methods has been\nexplored -- ranging from conventional physics-based models to purely\ndata-driven techniques. Recently, hybrid approaches that combine the strengths\nof both paradigms have gained attention. These include strategies such as\nlearning surrogates for physics-based models, modeling residuals between\nsimulated and observed data, fine-tuning surrogates with real-world\nmeasurements, using physics-based outputs as additional inputs for data-driven\nmodels, and integrating the physics-based output into the loss function the\ndata-driven model. Despite this progress, two significant research gaps remain.\nFirst, most hybrid methods focus on deterministic modeling, often neglecting\nthe inherent uncertainties caused by factors like weather fluctuations and\noccupant behavior. Second, there has been little systematic comparison within a\nprobabilistic modeling framework. This study addresses these gaps by evaluating\nfive representative hybrid approaches for probabilistic building energy\nmodeling, focusing on quantile predictions of building thermodynamics in a\nreal-world case study. Our results highlight two main findings. First, the\nperformance of hybrid approaches varies across different building room types,\nbut residual learning with a Feedforward Neural Network performs best on\naverage. Notably, the residual approach is the only model that produces\nphysically intuitive predictions when applied to out-of-distribution test data.\nSecond, Quantile Conformal Prediction is an effective procedure for calibrating\nquantile predictions in case of indoor temperature modeling.",
      "pdf_url": "http://arxiv.org/pdf/2507.17526v1",
      "published": "2025-07-23T14:07:33+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.17526v1",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.LG",
        "cs.SY"
      ]
    },
    {
      "title": "Enabling Cyber Security Education through Digital Twins and Generative AI",
      "authors": [
        "Vita Santa Barletta",
        "Vito Bavaro",
        "Miriana Calvano",
        "Antonio Curci",
        "Antonio Piccinno",
        "Davide Pio Posa"
      ],
      "abstract": "Digital Twins (DTs) are gaining prominence in cybersecurity for their ability\nto replicate complex IT (Information Technology), OT (Operational Technology),\nand IoT (Internet of Things) infrastructures, allowing for real time\nmonitoring, threat analysis, and system simulation. This study investigates how\nintegrating DTs with penetration testing tools and Large Language Models (LLMs)\ncan enhance cybersecurity education and operational readiness. By simulating\nrealistic cyber environments, this approach offers a practical, interactive\nframework for exploring vulnerabilities and defensive strategies. At the core\nof this research is the Red Team Knife (RTK), a custom penetration testing\ntoolkit aligned with the Cyber Kill Chain model. RTK is designed to guide\nlearners through key phases of cyberattacks, including reconnaissance,\nexploitation, and response within a DT powered ecosystem. The incorporation of\nLarge Language Models (LLMs) further enriches the experience by providing\nintelligent, real-time feedback, natural language threat explanations, and\nadaptive learning support during training exercises. This combined DT LLM\nframework is currently being piloted in academic settings to develop hands on\nskills in vulnerability assessment, threat detection, and security operations.\nInitial findings suggest that the integration significantly improves the\neffectiveness and relevance of cybersecurity training, bridging the gap between\ntheoretical knowledge and real-world application. Ultimately, the research\ndemonstrates how DTs and LLMs together can transform cybersecurity education to\nmeet evolving industry demands.",
      "pdf_url": "http://arxiv.org/pdf/2507.17518v1",
      "published": "2025-07-23T13:55:35+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.17518v1",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CY",
        "cs.HC",
        "cs.SE"
      ]
    },
    {
      "title": "TAI Scan Tool: A RAG-Based Tool With Minimalistic Input for Trustworthy AI Self-Assessment",
      "authors": [
        "Athanasios Davvetas",
        "Xenia Ziouvelou",
        "Ypatia Dami",
        "Alexis Kaponis",
        "Konstantina Giouvanopoulou",
        "Michael Papademas"
      ],
      "abstract": "This paper introduces the TAI Scan Tool, a RAG-based TAI self-assessment tool\nwith minimalistic input. The current version of the tool supports the legal TAI\nassessment, with a particular emphasis on facilitating compliance with the AI\nAct. It involves a two-step approach with a pre-screening and an assessment\nphase. The assessment output of the system includes insight regarding the\nrisk-level of the AI system according to the AI Act, while at the same time\nretrieving relevant articles to aid with compliance and notify on their\nobligations. Our qualitative evaluation using use-case scenarios yields\npromising results, correctly predicting risk levels while retrieving relevant\narticles across three distinct semantic groups. Furthermore, interpretation of\nresults shows that the tool's reasoning relies on comparison with the setting\nof high-risk systems, a behaviour attributed to their deployment requiring\ncareful consideration, and therefore frequently presented within the AI Act.",
      "pdf_url": "http://arxiv.org/pdf/2507.17514v1",
      "published": "2025-07-23T13:51:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.17514v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "HOTA: Hamiltonian framework for Optimal Transport Advection",
      "authors": [
        "Nazar Buzun",
        "Daniil Shlenskii",
        "Maxim Bobrin",
        "Dmitry V. Dylov"
      ],
      "abstract": "Optimal transport (OT) has become a natural framework for guiding the\nprobability flows. Yet, the majority of recent generative models assume trivial\ngeometry (e.g., Euclidean) and rely on strong density-estimation assumptions,\nyielding trajectories that do not respect the true principles of optimality in\nthe underlying manifold. We present Hamiltonian Optimal Transport Advection\n(HOTA), a Hamilton-Jacobi-Bellman based method that tackles the dual dynamical\nOT problem explicitly through Kantorovich potentials, enabling efficient and\nscalable trajectory optimization. Our approach effectively evades the need for\nexplicit density modeling, performing even when the cost functionals are\nnon-smooth. Empirically, HOTA outperforms all baselines in standard benchmarks,\nas well as in custom datasets with non-differentiable costs, both in terms of\nfeasibility and optimality.",
      "pdf_url": "http://arxiv.org/pdf/2507.17513v1",
      "published": "2025-07-23T13:51:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.17513v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Can One Domain Help Others? A Data-Centric Study on Multi-Domain Reasoning via Reinforcement Learning",
      "authors": [
        "Yu Li",
        "Zhuoshi Pan",
        "Honglin Lin",
        "Mengyuan Sun",
        "Conghui He",
        "Lijun Wu"
      ],
      "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a\npowerful paradigm for enhancing the reasoning capabilities of LLMs. Existing\nresearch has predominantly concentrated on isolated reasoning domains such as\nmathematical problem-solving, coding tasks, or logical reasoning. However, real\nworld reasoning scenarios inherently demand an integrated application of\nmultiple cognitive skills. Despite this, the interplay among these reasoning\nskills under reinforcement learning remains poorly understood. To bridge this\ngap, we present a systematic investigation of multi-domain reasoning within the\nRLVR framework, explicitly focusing on three primary domains: mathematical\nreasoning, code generation, and logical puzzle solving. We conduct a\ncomprehensive study comprising four key components: (1) Leveraging the GRPO\nalgorithm and the Qwen-2.5-7B model family, our study thoroughly evaluates the\nmodels' in-domain improvements and cross-domain generalization capabilities\nwhen trained on single-domain datasets. (2) Additionally, we examine the\nintricate interactions including mutual enhancements and conflicts that emerge\nduring combined cross-domain training. (3) To further understand the influence\nof SFT on RL, we also analyze and compare performance differences between base\nand instruct models under identical RL configurations. (4) Furthermore, we\ndelve into critical RL training details, systematically exploring the impacts\nof curriculum learning strategies, variations in reward design, and\nlanguage-specific factors. Through extensive experiments, our results offer\nsignificant insights into the dynamics governing domain interactions, revealing\nkey factors influencing both specialized and generalizable reasoning\nperformance. These findings provide valuable guidance for optimizing RL\nmethodologies to foster comprehensive, multi-domain reasoning capabilities in\nLLMs.",
      "pdf_url": "http://arxiv.org/pdf/2507.17512v1",
      "published": "2025-07-23T13:51:04+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.17512v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "To Trust or Not to Trust: On Calibration in ML-based Resource Allocation for Wireless Networks",
      "authors": [
        "Rashika Raina",
        "Nidhi Simmons",
        "David E. Simmons",
        "Michel Daoud Yacoub",
        "Trung Q. Duong"
      ],
      "abstract": "In next-generation communications and networks, machine learning (ML) models\nare expected to deliver not only accurate predictions but also well-calibrated\nconfidence scores that reflect the true likelihood of correct decisions. This\npaper studies the calibration performance of an ML-based outage predictor\nwithin a single-user, multi-resource allocation framework. We first establish\nkey theoretical properties of this system's outage probability (OP) under\nperfect calibration. Importantly, we show that as the number of resources\ngrows, the OP of a perfectly calibrated predictor approaches the expected\noutput conditioned on it being below the classification threshold. In contrast,\nwhen only one resource is available, the system's OP equals the model's overall\nexpected output. We then derive the OP conditions for a perfectly calibrated\npredictor. These findings guide the choice of the classification threshold to\nachieve a desired OP, helping system designers meet specific reliability\nrequirements. We also demonstrate that post-processing calibration cannot\nimprove the system's minimum achievable OP, as it does not introduce new\ninformation about future channel states. Additionally, we show that\nwell-calibrated models are part of a broader class of predictors that\nnecessarily improve OP. In particular, we establish a monotonicity condition\nthat the accuracy-confidence function must satisfy for such improvement to\noccur. To demonstrate these theoretical properties, we conduct a rigorous\nsimulation-based analysis using post-processing calibration techniques: Platt\nscaling and isotonic regression. As part of this framework, the predictor is\ntrained using an outage loss function specifically designed for this system.\nFurthermore, this analysis is performed on Rayleigh fading channels with\ntemporal correlation captured by Clarke's 2D model, which accounts for receiver\nmobility.",
      "pdf_url": "http://arxiv.org/pdf/2507.17494v1",
      "published": "2025-07-23T13:23:43+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.17494v1",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "eess.SP"
      ]
    },
    {
      "title": "Automated Hybrid Grounding Using Structural and Data-Driven Heuristics",
      "authors": [
        "Alexander Beiser",
        "Markus Hecher",
        "Stefan Woltran"
      ],
      "abstract": "The grounding bottleneck poses one of the key challenges that hinders the\nwidespread adoption of Answer Set Programming in industry. Hybrid Grounding is\na step in alleviating the bottleneck by combining the strength of standard\nbottom-up grounding with recently proposed techniques where rule bodies are\ndecoupled during grounding. However, it has remained unclear when hybrid\ngrounding shall use body-decoupled grounding and when to use standard bottom-up\ngrounding. In this paper, we address this issue by developing automated hybrid\ngrounding: we introduce a splitting algorithm based on data-structural\nheuristics that detects when to use body-decoupled grounding and when standard\ngrounding is beneficial. We base our heuristics on the structure of rules and\nan estimation procedure that incorporates the data of the instance. The\nexperiments conducted on our prototypical implementation demonstrate promising\nresults, which show an improvement on hard-to-ground scenarios, whereas on\nhard-to-solve instances we approach state-of-the-art performance.",
      "pdf_url": "http://arxiv.org/pdf/2507.17493v1",
      "published": "2025-07-23T13:19:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.17493v1",
      "categories": [
        "cs.AI",
        "cs.LO"
      ]
    },
    {
      "title": "CQE under Epistemic Dependencies: Algorithms and Experiments (extended version)",
      "authors": [
        "Lorenzo Marconi",
        "Flavia Ricci",
        "Riccardo Rosati"
      ],
      "abstract": "We investigate Controlled Query Evaluation (CQE) over ontologies, where\ninformation disclosure is regulated by epistemic dependencies (EDs), a family\nof logical rules recently proposed for the CQE framework. In particular, we\ncombine EDs with the notion of optimal GA censors, i.e. maximal sets of ground\natoms that are entailed by the ontology and can be safely revealed. We focus on\nanswering Boolean unions of conjunctive queries (BUCQs) with respect to the\nintersection of all optimal GA censors - an approach that has been shown in\nother contexts to ensure strong security guarantees with favorable\ncomputational behavior. First, we characterize the security of this\nintersection-based approach and identify a class of EDs (namely, full EDs) for\nwhich it remains safe. Then, for a subclass of EDs and for DL-Lite_R\nontologies, we show that answering BUCQs in the above CQE semantics is in AC^0\nin data complexity by presenting a suitable, detailed first-order rewriting\nalgorithm. Finally, we report on experiments conducted in two different\nevaluation scenarios, showing the practical feasibility of our rewriting\nfunction.",
      "pdf_url": "http://arxiv.org/pdf/2507.17487v1",
      "published": "2025-07-23T13:10:33+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.17487v1",
      "categories": [
        "cs.AI",
        "cs.DB"
      ]
    },
    {
      "title": "Unsupervised anomaly detection using Bayesian flow networks: application to brain FDG PET in the context of Alzheimer's disease",
      "authors": [
        "Hugues Roy",
        "Reuben Dorent",
        "Ninon Burgos"
      ],
      "abstract": "Unsupervised anomaly detection (UAD) plays a crucial role in neuroimaging for\nidentifying deviations from healthy subject data and thus facilitating the\ndiagnosis of neurological disorders. In this work, we focus on Bayesian flow\nnetworks (BFNs), a novel class of generative models, which have not yet been\napplied to medical imaging or anomaly detection. BFNs combine the strength of\ndiffusion frameworks and Bayesian inference. We introduce AnoBFN, an extension\nof BFNs for UAD, designed to: i) perform conditional image generation under\nhigh levels of spatially correlated noise, and ii) preserve subject specificity\nby incorporating a recursive feedback from the input image throughout the\ngenerative process. We evaluate AnoBFN on the challenging task of Alzheimer's\ndisease-related anomaly detection in FDG PET images. Our approach outperforms\nother state-of-the-art methods based on VAEs (beta-VAE), GANs (f-AnoGAN), and\ndiffusion models (AnoDDPM), demonstrating its effectiveness at detecting\nanomalies while reducing false positive rates.",
      "pdf_url": "http://arxiv.org/pdf/2507.17486v1",
      "published": "2025-07-23T13:09:57+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.17486v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "LTLZinc: a Benchmarking Framework for Continual Learning and Neuro-Symbolic Temporal Reasoning",
      "authors": [
        "Luca Salvatore Lorello",
        "Nikolaos Manginas",
        "Marco Lippi",
        "Stefano Melacci"
      ],
      "abstract": "Neuro-symbolic artificial intelligence aims to combine neural architectures\nwith symbolic approaches that can represent knowledge in a human-interpretable\nformalism. Continual learning concerns with agents that expand their knowledge\nover time, improving their skills while avoiding to forget previously learned\nconcepts. Most of the existing approaches for neuro-symbolic artificial\nintelligence are applied to static scenarios only, and the challenging setting\nwhere reasoning along the temporal dimension is necessary has been seldom\nexplored. In this work we introduce LTLZinc, a benchmarking framework that can\nbe used to generate datasets covering a variety of different problems, against\nwhich neuro-symbolic and continual learning methods can be evaluated along the\ntemporal and constraint-driven dimensions. Our framework generates expressive\ntemporal reasoning and continual learning tasks from a linear temporal logic\nspecification over MiniZinc constraints, and arbitrary image classification\ndatasets. Fine-grained annotations allow multiple neural and neuro-symbolic\ntraining settings on the same generated datasets. Experiments on six\nneuro-symbolic sequence classification and four class-continual learning tasks\ngenerated by LTLZinc, demonstrate the challenging nature of temporal learning\nand reasoning, and highlight limitations of current state-of-the-art methods.\nWe release the LTLZinc generator and ten ready-to-use tasks to the\nneuro-symbolic and continual learning communities, in the hope of fostering\nresearch towards unified temporal learning and reasoning frameworks.",
      "pdf_url": "http://arxiv.org/pdf/2507.17482v1",
      "published": "2025-07-23T13:04:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.17482v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "An Uncertainty-Driven Adaptive Self-Alignment Framework for Large Language Models",
      "authors": [
        "Haoran Sun",
        "Zekun Zhang",
        "Shaoning Zeng"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable progress in\ninstruction following and general-purpose reasoning. However, achieving\nhigh-quality alignment with human intent and safety norms without human\nannotations remains a fundamental challenge. In this work, we propose an\nUncertainty-Driven Adaptive Self-Alignment (UDASA) framework designed to\nimprove LLM alignment in a fully automated manner. UDASA first generates\nmultiple responses for each input and quantifies output uncertainty across\nthree dimensions: semantics, factuality, and value alignment. Based on these\nuncertainty scores, the framework constructs preference pairs and categorizes\ntraining samples into three stages, conservative, moderate, and exploratory,\naccording to their uncertainty difference. The model is then optimized\nprogressively across these stages. In addition, we conduct a series of\npreliminary studies to validate the core design assumptions and provide strong\nempirical motivation for the proposed framework. Experimental results show that\nUDASA outperforms existing alignment methods across multiple tasks, including\nharmlessness, helpfulness, truthfulness, and controlled sentiment generation,\nsignificantly improving model performance.",
      "pdf_url": "http://arxiv.org/pdf/2507.17477v1",
      "published": "2025-07-23T13:00:00+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.17477v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "MultiNRC: A Challenging and Native Multilingual Reasoning Evaluation Benchmark for LLMs",
      "authors": [
        "Alexander R. Fabbri",
        "Diego Mares",
        "Jorge Flores",
        "Meher Mankikar",
        "Ernesto Hernandez",
        "Dean Lee",
        "Bing Liu",
        "Chen Xing"
      ],
      "abstract": "Although recent Large Language Models (LLMs) have shown rapid improvement on\nreasoning benchmarks in English, the evaluation of such LLMs' multilingual\nreasoning capability across diverse languages and cultural contexts remains\nlimited. Existing multilingual reasoning benchmarks are typically constructed\nby translating existing English reasoning benchmarks, biasing these benchmarks\ntowards reasoning problems with context in English language/cultures. In this\nwork, we introduce the Multilingual Native Reasoning Challenge (MultiNRC), a\nbenchmark designed to assess LLMs on more than 1,000 native, linguistic and\nculturally grounded reasoning questions written by native speakers in French,\nSpanish, and Chinese. MultiNRC covers four core reasoning categories:\nlanguage-specific linguistic reasoning, wordplay & riddles, cultural/tradition\nreasoning, and math reasoning with cultural relevance. For cultural/tradition\nreasoning and math reasoning with cultural relevance, we also provide English\nequivalent translations of the multilingual questions by manual translation\nfrom native speakers fluent in English. This set of English equivalents can\nprovide a direct comparison of LLM reasoning capacity in other languages vs.\nEnglish on the same reasoning questions. We systematically evaluate current 14\nleading LLMs covering most LLM families on MultiNRC and its English equivalent\nset. The results show that (1) current LLMs are still not good at native\nmultilingual reasoning, with none scoring above 50% on MultiNRC; (2) LLMs\nexhibit distinct strengths and weaknesses in handling linguistic, cultural, and\nlogical reasoning tasks; (3) Most models perform substantially better in math\nreasoning in English compared to in original languages (+10%), indicating\npersistent challenges with culturally grounded knowledge.",
      "pdf_url": "http://arxiv.org/pdf/2507.17476v1",
      "published": "2025-07-23T12:56:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.17476v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "BGM-HAN: A Hierarchical Attention Network for Accurate and Fair Decision Assessment on Semi-Structured Profiles",
      "authors": [
        "Junhua Liu",
        "Roy Ka-Wei Lee",
        "Kwan Hui Lim"
      ],
      "abstract": "Human decision-making in high-stakes domains often relies on expertise and\nheuristics, but is vulnerable to hard-to-detect cognitive biases that threaten\nfairness and long-term outcomes. This work presents a novel approach to\nenhancing complex decision-making workflows through the integration of\nhierarchical learning alongside various enhancements. Focusing on university\nadmissions as a representative high-stakes domain, we propose BGM-HAN, an\nenhanced Byte-Pair Encoded, Gated Multi-head Hierarchical Attention Network,\ndesigned to effectively model semi-structured applicant data. BGM-HAN captures\nmulti-level representations that are crucial for nuanced assessment, improving\nboth interpretability and predictive performance. Experimental results on real\nadmissions data demonstrate that our proposed model significantly outperforms\nboth state-of-the-art baselines from traditional machine learning to large\nlanguage models, offering a promising framework for augmenting decision-making\nin domains where structure, context, and fairness matter. Source code is\navailable at: https://github.com/junhua/bgm-han.",
      "pdf_url": "http://arxiv.org/pdf/2507.17472v1",
      "published": "2025-07-23T12:52:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.17472v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR"
      ]
    },
    {
      "title": "Demonstration of Efficient Predictive Surrogates for Large-scale Quantum Processors",
      "authors": [
        "Wei-You Liao",
        "Yuxuan Du",
        "Xinbiao Wang",
        "Tian-Ci Tian",
        "Yong Luo",
        "Bo Du",
        "Dacheng Tao",
        "He-Liang Huang"
      ],
      "abstract": "The ongoing development of quantum processors is driving breakthroughs in\nscientific discovery. Despite this progress, the formidable cost of fabricating\nlarge-scale quantum processors means they will remain rare for the foreseeable\nfuture, limiting their widespread application. To address this bottleneck, we\nintroduce the concept of predictive surrogates, which are classical learning\nmodels designed to emulate the mean-value behavior of a given quantum processor\nwith provably computational efficiency. In particular, we propose two\npredictive surrogates that can substantially reduce the need for quantum\nprocessor access in diverse practical scenarios. To demonstrate their potential\nin advancing digital quantum simulation, we use these surrogates to emulate a\nquantum processor with up to 20 programmable superconducting qubits, enabling\nefficient pre-training of variational quantum eigensolvers for families of\ntransverse-field Ising models and identification of non-equilibrium Floquet\nsymmetry-protected topological phases. Experimental results reveal that the\npredictive surrogates not only reduce measurement overhead by orders of\nmagnitude, but can also surpass the performance of conventional,\nquantum-resource-intensive approaches. Collectively, these findings establish\npredictive surrogates as a practical pathway to broadening the impact of\nadvanced quantum processors.",
      "pdf_url": "http://arxiv.org/pdf/2507.17470v1",
      "published": "2025-07-23T12:51:03+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.17470v1",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Probing Vision-Language Understanding through the Visual Entailment Task: promises and pitfalls",
      "authors": [
        "Elena Pitta",
        "Tom Kouwenhoven",
        "Tessa Verhoef"
      ],
      "abstract": "This study investigates the extent to which the Visual Entailment (VE) task\nserves as a reliable probe of vision-language understanding in multimodal\nlanguage models, using the LLaMA 3.2 11B Vision model as a test case. Beyond\nreporting performance metrics, we aim to interpret what these results reveal\nabout the underlying possibilities and limitations of the VE task. We conduct a\nseries of experiments across zero-shot, few-shot, and fine-tuning settings,\nexploring how factors such as prompt design, the number and order of in-context\nexamples and access to visual information might affect VE performance. To\nfurther probe the reasoning processes of the model, we used explanation-based\nevaluations. Results indicate that three-shot inference outperforms the\nzero-shot baselines. However, additional examples introduce more noise than\nthey provide benefits. Additionally, the order of the labels in the prompt is a\ncritical factor that influences the predictions. In the absence of visual\ninformation, the model has a strong tendency to hallucinate and imagine\ncontent, raising questions about the model's over-reliance on linguistic\npriors. Fine-tuning yields strong results, achieving an accuracy of 83.3% on\nthe e-SNLI-VE dataset and outperforming the state-of-the-art OFA-X model.\nAdditionally, the explanation evaluation demonstrates that the fine-tuned model\nprovides semantically meaningful explanations similar to those of humans, with\na BERTScore F1-score of 89.2%. We do, however, find comparable BERTScore\nresults in experiments with limited vision, questioning the visual grounding of\nthis task. Overall, our results highlight both the utility and limitations of\nVE as a diagnostic task for vision-language understanding and point to\ndirections for refining multimodal evaluation methods.",
      "pdf_url": "http://arxiv.org/pdf/2507.17467v1",
      "published": "2025-07-23T12:46:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.17467v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Reasoning-Driven Retrosynthesis Prediction with Large Language Models via Reinforcement Learning",
      "authors": [
        "Situo Zhang",
        "Hanqi Li",
        "Lu Chen",
        "Zihan Zhao",
        "Xuanze Lin",
        "Zichen Zhu",
        "Bo Chen",
        "Xin Chen",
        "Kai Yu"
      ],
      "abstract": "Retrosynthesis planning, essential in organic synthesis and drug discovery,\nhas greatly benefited from recent AI-driven advancements. Nevertheless,\nexisting methods frequently face limitations in both applicability and\nexplainability. Traditional graph-based and sequence-to-sequence models often\nlack generalized chemical knowledge, leading to predictions that are neither\nconsistently accurate nor easily explainable. To address these challenges, we\nintroduce RetroDFM-R, a reasoning-based large language model (LLM) designed\nspecifically for chemical retrosynthesis. Leveraging large-scale reinforcement\nlearning guided by chemically verifiable rewards, RetroDFM-R significantly\nenhances prediction accuracy and explainability. Comprehensive evaluations\ndemonstrate that RetroDFM-R significantly outperforms state-of-the-art methods,\nachieving a top-1 accuracy of 65.0% on the USPTO-50K benchmark. Double-blind\nhuman assessments further validate the chemical plausibility and practical\nutility of RetroDFM-R's predictions. RetroDFM-R also accurately predicts\nmultistep retrosynthetic routes reported in the literature for both real-world\ndrug molecules and perovskite materials. Crucially, the model's explicit\nreasoning process provides human-interpretable insights, thereby enhancing\ntrust and practical value in real-world retrosynthesis applications.",
      "pdf_url": "http://arxiv.org/pdf/2507.17448v1",
      "published": "2025-07-23T12:13:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.17448v1",
      "categories": [
        "cs.CE",
        "cs.AI",
        "physics.chem-ph"
      ]
    },
    {
      "title": "IndoorBEV: Joint Detection and Footprint Completion of Objects via Mask-based Prediction in Indoor Scenarios for Bird's-Eye View Perception",
      "authors": [
        "Haichuan Li",
        "Changda Tian",
        "Panos Trahanias",
        "Tomi Westerlund"
      ],
      "abstract": "Detecting diverse objects within complex indoor 3D point clouds presents\nsignificant challenges for robotic perception, particularly with varied object\nshapes, clutter, and the co-existence of static and dynamic elements where\ntraditional bounding box methods falter. To address these limitations, we\npropose IndoorBEV, a novel mask-based Bird's-Eye View (BEV) method for indoor\nmobile robots.\n  In a BEV method, a 3D scene is projected into a 2D BEV grid which handles\nnaturally occlusions and provides a consistent top-down view aiding to\ndistinguish static obstacles from dynamic agents. The obtained 2D BEV results\nis directly usable to downstream robotic tasks like navigation, motion\nprediction, and planning. Our architecture utilizes an axis compact encoder and\na window-based backbone to extract rich spatial features from this BEV map. A\nquery-based decoder head then employs learned object queries to concurrently\npredict object classes and instance masks in the BEV space. This mask-centric\nformulation effectively captures the footprint of both static and dynamic\nobjects regardless of their shape, offering a robust alternative to bounding\nbox regression. We demonstrate the effectiveness of IndoorBEV on a custom\nindoor dataset featuring diverse object classes including static objects\n  and dynamic elements like robots and miscellaneous items, showcasing its\npotential for robust indoor scene understanding.",
      "pdf_url": "http://arxiv.org/pdf/2507.17445v1",
      "published": "2025-07-23T12:07:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.17445v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "Each to Their Own: Exploring the Optimal Embedding in RAG",
      "authors": [
        "Shiting Chen",
        "Zijian Zhao",
        "Jinsong Chen"
      ],
      "abstract": "Recently, as Large Language Models (LLMs) have fundamentally impacted various\nfields, the methods for incorporating up-to-date information into LLMs or\nadding external knowledge to construct domain-specific models have garnered\nwide attention. Retrieval-Augmented Generation (RAG), serving as an\ninference-time scaling method, is notable for its low cost and minimal effort\nfor parameter tuning. However, due to heterogeneous training data and model\narchitecture, the variant embedding models used in RAG exhibit different\nbenefits across various areas, often leading to different similarity\ncalculation results and, consequently, varying response quality from LLMs. To\naddress this problem, we propose and examine two approaches to enhance RAG by\ncombining the benefits of multiple embedding models, named Mixture-Embedding\nRAG and Confident RAG. Mixture-Embedding RAG simply sorts and selects\nretrievals from multiple embedding models based on standardized similarity;\nhowever, it does not outperform vanilla RAG. In contrast, Confident RAG\ngenerates responses multiple times using different embedding models and then\nselects the responses with the highest confidence level, demonstrating average\nimprovements of approximately 10% and 5% over vanilla LLMs and RAG,\nrespectively. The consistent results across different LLMs and embedding models\nindicate that Confident RAG is an efficient plug-and-play approach for various\ndomains. We will release our code upon publication.",
      "pdf_url": "http://arxiv.org/pdf/2507.17442v1",
      "published": "2025-07-23T12:03:54+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.17442v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Fair Compromises in Participatory Budgeting: a Multi-Agent Deep Reinforcement Learning Approach",
      "authors": [
        "Hugh Adams",
        "Srijoni Majumdar",
        "Evangelos Pournaras"
      ],
      "abstract": "Participatory budgeting is a method of collectively understanding and\naddressing spending priorities where citizens vote on how a budget is spent, it\nis regularly run to improve the fairness of the distribution of public funds.\nParticipatory budgeting requires voters to make decisions on projects which can\nlead to ``choice overload\". A multi-agent reinforcement learning approach to\ndecision support can make decision making easier for voters by identifying\nvoting strategies that increase the winning proportion of their vote. This\nnovel approach can also support policymakers by highlighting aspects of\nelection design that enable fair compromise on projects. This paper presents a\nnovel, ethically aligned approach to decision support using multi-agent deep\nreinforcement learning modelling. This paper introduces a novel use of a\nbranching neural network architecture to overcome scalability challenges of\nmulti-agent reinforcement learning in a decentralized way. Fair compromises are\nfound through optimising voter actions towards greater representation of voter\npreferences in the winning set. Experimental evaluation with real-world\nparticipatory budgeting data reveals a pattern in fair compromise: that it is\nachievable through projects with smaller cost.",
      "pdf_url": "http://arxiv.org/pdf/2507.17433v1",
      "published": "2025-07-23T11:46:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.17433v1",
      "categories": [
        "cs.MA",
        "cs.AI"
      ]
    },
    {
      "title": "Ctx2TrajGen: Traffic Context-Aware Microscale Vehicle Trajectories using Generative Adversarial Imitation Learning",
      "authors": [
        "Joobin Jin",
        "Seokjun Hong",
        "Gyeongseon Baek",
        "Yeeun Kim",
        "Byeongjoon Noh"
      ],
      "abstract": "Precise modeling of microscopic vehicle trajectories is critical for traffic\nbehavior analysis and autonomous driving systems. We propose Ctx2TrajGen, a\ncontext-aware trajectory generation framework that synthesizes realistic urban\ndriving behaviors using GAIL. Leveraging PPO and WGAN-GP, our model addresses\nnonlinear interdependencies and training instability inherent in microscopic\nsettings. By explicitly conditioning on surrounding vehicles and road geometry,\nCtx2TrajGen generates interaction-aware trajectories aligned with real-world\ncontext. Experiments on the drone-captured DRIFT dataset demonstrate superior\nperformance over existing methods in terms of realism, behavioral diversity,\nand contextual fidelity, offering a robust solution to data scarcity and domain\nshift without simulation.",
      "pdf_url": "http://arxiv.org/pdf/2507.17418v1",
      "published": "2025-07-23T11:21:27+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.17418v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Content-based 3D Image Retrieval and a ColBERT-inspired Re-ranking for Tumor Flagging and Staging",
      "authors": [
        "Farnaz Khun Jush",
        "Steffen Vogler",
        "Matthias Lenga"
      ],
      "abstract": "The increasing volume of medical images poses challenges for radiologists in\nretrieving relevant cases. Content-based image retrieval (CBIR) systems offer\npotential for efficient access to similar cases, yet lack standardized\nevaluation and comprehensive studies. Building on prior studies for tumor\ncharacterization via CBIR, this study advances CBIR research for volumetric\nmedical images through three key contributions: (1) a framework eliminating\nreliance on pre-segmented data and organ-specific datasets, aligning with large\nand unstructured image archiving systems, i.e. PACS in clinical practice; (2)\nintroduction of C-MIR, a novel volumetric re-ranking method adapting ColBERT's\ncontextualized late interaction mechanism for 3D medical imaging; (3)\ncomprehensive evaluation across four tumor sites using three feature extractors\nand three database configurations. Our evaluations highlight the significant\nadvantages of C-MIR. We demonstrate the successful adaptation of the late\ninteraction principle to volumetric medical images, enabling effective\ncontext-aware re-ranking. A key finding is C-MIR's ability to effectively\nlocalize the region of interest, eliminating the need for pre-segmentation of\ndatasets and offering a computationally efficient alternative to systems\nrelying on expensive data enrichment steps. C-MIR demonstrates promising\nimprovements in tumor flagging, achieving improved performance, particularly\nfor colon and lung tumors (p<0.05). C-MIR also shows potential for improving\ntumor staging, warranting further exploration of its capabilities. Ultimately,\nour work seeks to bridge the gap between advanced retrieval techniques and\ntheir practical applications in healthcare, paving the way for improved\ndiagnostic processes.",
      "pdf_url": "http://arxiv.org/pdf/2507.17412v1",
      "published": "2025-07-23T11:12:52+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.17412v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.IR"
      ]
    },
    {
      "title": "Millions of $\\text{GeAR}$-s: Extending GraphRAG to Millions of Documents",
      "authors": [
        "Zhili Shen",
        "Chenxin Diao",
        "Pascual Merita",
        "Pavlos Vougiouklis",
        "Jeff Z. Pan"
      ],
      "abstract": "Recent studies have explored graph-based approaches to retrieval-augmented\ngeneration, leveraging structured or semi-structured information -- such as\nentities and their relations extracted from documents -- to enhance retrieval.\nHowever, these methods are typically designed to address specific tasks, such\nas multi-hop question answering and query-focused summarisation, and therefore,\nthere is limited evidence of their general applicability across broader\ndatasets. In this paper, we aim to adapt a state-of-the-art graph-based RAG\nsolution: $\\text{GeAR}$ and explore its performance and limitations on the\nSIGIR 2025 LiveRAG Challenge.",
      "pdf_url": "http://arxiv.org/pdf/2507.17399v1",
      "published": "2025-07-23T10:54:24+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.17399v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ]
    },
    {
      "title": "HiProbe-VAD: Video Anomaly Detection via Hidden States Probing in Tuning-Free Multimodal LLMs",
      "authors": [
        "Zhaolin Cai",
        "Fan Li",
        "Ziwei Zheng",
        "Yanjun Qin"
      ],
      "abstract": "Video Anomaly Detection (VAD) aims to identify and locate deviations from\nnormal patterns in video sequences. Traditional methods often struggle with\nsubstantial computational demands and a reliance on extensive labeled datasets,\nthereby restricting their practical applicability. To address these\nconstraints, we propose HiProbe-VAD, a novel framework that leverages\npre-trained Multimodal Large Language Models (MLLMs) for VAD without requiring\nfine-tuning. In this paper, we discover that the intermediate hidden states of\nMLLMs contain information-rich representations, exhibiting higher sensitivity\nand linear separability for anomalies compared to the output layer. To\ncapitalize on this, we propose a Dynamic Layer Saliency Probing (DLSP)\nmechanism that intelligently identifies and extracts the most informative\nhidden states from the optimal intermediate layer during the MLLMs reasoning.\nThen a lightweight anomaly scorer and temporal localization module efficiently\ndetects anomalies using these extracted hidden states and finally generate\nexplanations. Experiments on the UCF-Crime and XD-Violence datasets demonstrate\nthat HiProbe-VAD outperforms existing training-free and most traditional\napproaches. Furthermore, our framework exhibits remarkable cross-model\ngeneralization capabilities in different MLLMs without any tuning, unlocking\nthe potential of pre-trained MLLMs for video anomaly detection and paving the\nway for more practical and scalable solutions.",
      "pdf_url": "http://arxiv.org/pdf/2507.17394v1",
      "published": "2025-07-23T10:41:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.17394v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Investigating Training Data Detection in AI Coders",
      "authors": [
        "Tianlin Li",
        "Yunxiang Wei",
        "Zhiming Li",
        "Aishan Liu",
        "Qing Guo",
        "Xianglong Liu",
        "Dongning Sun",
        "Yang Liu"
      ],
      "abstract": "Recent advances in code large language models (CodeLLMs) have made them\nindispensable tools in modern software engineering. However, these models\noccasionally produce outputs that contain proprietary or sensitive code\nsnippets, raising concerns about potential non-compliant use of training data,\nand posing risks to privacy and intellectual property. To ensure responsible\nand compliant deployment of CodeLLMs, training data detection (TDD) has become\na critical task. While recent TDD methods have shown promise in natural\nlanguage settings, their effectiveness on code data remains largely\nunderexplored. This gap is particularly important given code's structured\nsyntax and distinct similarity criteria compared to natural language. To\naddress this, we conduct a comprehensive empirical study of seven\nstate-of-the-art TDD methods on source code data, evaluating their performance\nacross eight CodeLLMs. To support this evaluation, we introduce CodeSnitch, a\nfunction-level benchmark dataset comprising 9,000 code samples in three\nprogramming languages, each explicitly labeled as either included or excluded\nfrom CodeLLM training. Beyond evaluation on the original CodeSnitch, we design\ntargeted mutation strategies to test the robustness of TDD methods under three\ndistinct settings. These mutation strategies are grounded in the\nwell-established Type-1 to Type-4 code clone detection taxonomy. Our study\nprovides a systematic assessment of current TDD techniques for code and offers\ninsights to guide the development of more effective and robust detection\nmethods in the future.",
      "pdf_url": "http://arxiv.org/pdf/2507.17389v1",
      "published": "2025-07-23T10:34:22+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.17389v1",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "SFUOD: Source-Free Unknown Object Detection",
      "authors": [
        "Keon-Hee Park",
        "Seun-An Choe",
        "Gyeong-Moon Park"
      ],
      "abstract": "Source-free object detection adapts a detector pre-trained on a source domain\nto an unlabeled target domain without requiring access to labeled source data.\nWhile this setting is practical as it eliminates the need for the source\ndataset during domain adaptation, it operates under the restrictive assumption\nthat only pre-defined objects from the source domain exist in the target\ndomain. This closed-set setting prevents the detector from detecting undefined\nobjects. To ease this assumption, we propose Source-Free Unknown Object\nDetection (SFUOD), a novel scenario which enables the detector to not only\nrecognize known objects but also detect undefined objects as unknown objects.\nTo this end, we propose CollaPAUL (Collaborative tuning and Principal\nAxis-based Unknown Labeling), a novel framework for SFUOD. Collaborative tuning\nenhances knowledge adaptation by integrating target-dependent knowledge from\nthe auxiliary encoder with source-dependent knowledge from the pre-trained\ndetector through a cross-domain attention mechanism. Additionally, principal\naxes-based unknown labeling assigns pseudo-labels to unknown objects by\nestimating objectness via principal axes projection and confidence scores from\nmodel predictions. The proposed CollaPAUL achieves state-of-the-art\nperformances on SFUOD benchmarks, and extensive experiments validate its\neffectiveness.",
      "pdf_url": "http://arxiv.org/pdf/2507.17373v1",
      "published": "2025-07-23T10:16:25+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.17373v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "DynaSearcher: Dynamic Knowledge Graph Augmented Search Agent via Multi-Reward Reinforcement Learning",
      "authors": [
        "Chuzhan Hao",
        "Wenfeng Feng",
        "Yuewei Zhang",
        "Hao Wang"
      ],
      "abstract": "Multi-step agentic retrieval systems based on large language models (LLMs)\nhave demonstrated remarkable performance in complex information search tasks.\nHowever, these systems still face significant challenges in practical\napplications, particularly in generating factually inconsistent intermediate\nqueries and inefficient search trajectories, which can lead to reasoning\ndeviations or redundant computations. To address these issues, we propose\nDynaSearcher, an innovative search agent enhanced by dynamic knowledge graphs\nand multi-reward reinforcement learning (RL). Specifically, our system\nleverages knowledge graphs as external structured knowledge to guide the search\nprocess by explicitly modeling entity relationships, thereby ensuring factual\nconsistency in intermediate queries and mitigating biases from irrelevant\ninformation. Furthermore, we employ a multi-reward RL framework for\nfine-grained control over training objectives such as retrieval accuracy,\nefficiency, and response quality. This framework promotes the generation of\nhigh-quality intermediate queries and comprehensive final answers, while\ndiscouraging unnecessary exploration and minimizing information omissions or\nredundancy. Experimental results demonstrate that our approach achieves\nstate-of-the-art answer accuracy on six multi-hop question answering datasets,\nmatching frontier LLMs while using only small-scale models and limited\ncomputational resources. Furthermore, our approach demonstrates strong\ngeneralization and robustness across diverse retrieval environments and\nlarger-scale models, highlighting its broad applicability.",
      "pdf_url": "http://arxiv.org/pdf/2507.17365v1",
      "published": "2025-07-23T09:58:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.17365v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Swin-TUNA : A Novel PEFT Approach for Accurate Food Image Segmentation",
      "authors": [
        "Haotian Chen",
        "Zhiyong Xiao"
      ],
      "abstract": "In the field of food image processing, efficient semantic segmentation\ntechniques are crucial for industrial applications. However, existing\nlarge-scale Transformer-based models (such as FoodSAM) face challenges in\nmeeting practical deploymentrequirements due to their massive parameter counts\nand high computational resource demands. This paper introduces TUNable Adapter\nmodule (Swin-TUNA), a Parameter Efficient Fine-Tuning (PEFT) method that\nintegrates multiscale trainable adapters into the Swin Transformer\narchitecture, achieving high-performance food image segmentation by updating\nonly 4% of the parameters. The core innovation of Swin-TUNA lies in its\nhierarchical feature adaptation mechanism: it designs separable convolutions in\ndepth and dimensional mappings of varying scales to address the differences in\nfeatures between shallow and deep networks, combined with a dynamic balancing\nstrategy for tasks-agnostic and task-specific features. Experiments demonstrate\nthat this method achieves mIoU of 50.56% and 74.94% on the FoodSeg103 and\nUECFoodPix Complete datasets, respectively, surpassing the fully parameterized\nFoodSAM model while reducing the parameter count by 98.7% (to only 8.13M).\nFurthermore, Swin-TUNA exhibits faster convergence and stronger generalization\ncapabilities in low-data scenarios, providing an efficient solution for\nassembling lightweight food image.",
      "pdf_url": "http://arxiv.org/pdf/2507.17347v2",
      "published": "2025-07-23T09:28:25+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.17347v2",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Temporal Point-Supervised Signal Reconstruction: A Human-Annotation-Free Framework for Weak Moving Target Detection",
      "authors": [
        "Weihua Gao",
        "Chunxu Ren",
        "Wenlong Niu",
        "Xiaodong Peng"
      ],
      "abstract": "In low-altitude surveillance and early warning systems, detecting weak moving\ntargets remains a significant challenge due to low signal energy, small spatial\nextent, and complex background clutter. Existing methods struggle with\nextracting robust features and suffer from the lack of reliable annotations. To\naddress these limitations, we propose a novel Temporal Point-Supervised (TPS)\nframework that enables high-performance detection of weak targets without any\nmanual annotations.Instead of conventional frame-based detection, our framework\nreformulates the task as a pixel-wise temporal signal modeling problem, where\nweak targets manifest as short-duration pulse-like responses. A Temporal Signal\nReconstruction Network (TSRNet) is developed under the TPS paradigm to\nreconstruct these transient signals.TSRNet adopts an encoder-decoder\narchitecture and integrates a Dynamic Multi-Scale Attention (DMSAttention)\nmodule to enhance its sensitivity to diverse temporal patterns. Additionally, a\ngraph-based trajectory mining strategy is employed to suppress false alarms and\nensure temporal consistency.Extensive experiments on a purpose-built low-SNR\ndataset demonstrate that our framework outperforms state-of-the-art methods\nwhile requiring no human annotations. It achieves strong detection performance\nand operates at over 1000 FPS, underscoring its potential for real-time\ndeployment in practical scenarios.",
      "pdf_url": "http://arxiv.org/pdf/2507.17334v1",
      "published": "2025-07-23T09:02:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.17334v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "EarthLink: A Self-Evolving AI Agent for Climate Science",
      "authors": [
        "Zijie Guo",
        "Jiong Wang",
        "Xiaoyu Yue",
        "Wangxu Wei",
        "Zhe Jiang",
        "Wanghan Xu",
        "Ben Fei",
        "Wenlong Zhang",
        "Xinyu Gu",
        "Lijing Cheng",
        "Jing-Jia Luo",
        "Chao Li",
        "Yaqiang Wang",
        "Tao Chen",
        "Wanli Ouyang",
        "Fenghua Ling",
        "Lei Bai"
      ],
      "abstract": "Modern Earth science is at an inflection point. The vast, fragmented, and\ncomplex nature of Earth system data, coupled with increasingly sophisticated\nanalytical demands, creates a significant bottleneck for rapid scientific\ndiscovery. Here we introduce EarthLink, the first AI agent designed as an\ninteractive copilot for Earth scientists. It automates the end-to-end research\nworkflow, from planning and code generation to multi-scenario analysis. Unlike\nstatic diagnostic tools, EarthLink can learn from user interaction,\ncontinuously refining its capabilities through a dynamic feedback loop. We\nvalidated its performance on a number of core scientific tasks of climate\nchange, ranging from model-observation comparisons to the diagnosis of complex\nphenomena. In a multi-expert evaluation, EarthLink produced scientifically\nsound analyses and demonstrated an analytical competency that was rated as\ncomparable to specific aspects of a human junior researcher's workflow.\nAdditionally, its transparent, auditable workflows and natural language\ninterface empower scientists to shift from laborious manual execution to\nstrategic oversight and hypothesis generation. EarthLink marks a pivotal step\ntowards an efficient, trustworthy, and collaborative paradigm for Earth system\nresearch in an era of accelerating global change. The system is accessible at\nour website https://earthlink.intern-ai.org.cn.",
      "pdf_url": "http://arxiv.org/pdf/2507.17311v2",
      "published": "2025-07-23T08:29:25+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.17311v2",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.ao-ph"
      ]
    },
    {
      "title": "Confounded Causal Imitation Learning with Instrumental Variables",
      "authors": [
        "Yan Zeng",
        "Shenglan Nie",
        "Feng Xie",
        "Libo Huang",
        "Peng Wu",
        "Zhi Geng"
      ],
      "abstract": "Imitation learning from demonstrations usually suffers from the confounding\neffects of unmeasured variables (i.e., unmeasured confounders) on the states\nand actions. If ignoring them, a biased estimation of the policy would be\nentailed. To break up this confounding gap, in this paper, we take the best of\nthe strong power of instrumental variables (IV) and propose a Confounded Causal\nImitation Learning (C2L) model. This model accommodates confounders that\ninfluence actions across multiple timesteps, rather than being restricted to\nimmediate temporal dependencies. We develop a two-stage imitation learning\nframework for valid IV identification and policy optimization. In particular,\nin the first stage, we construct a testing criterion based on the defined\npseudo-variable, with which we achieve identifying a valid IV for the C2L\nmodels. Such a criterion entails the sufficient and necessary identifiability\nconditions for IV validity. In the second stage, with the identified IV, we\npropose two candidate policy learning approaches: one is based on a simulator,\nwhile the other is offline. Extensive experiments verified the effectiveness of\nidentifying the valid IV as well as learning the policy.",
      "pdf_url": "http://arxiv.org/pdf/2507.17309v1",
      "published": "2025-07-23T08:23:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.17309v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    }
  ]
}