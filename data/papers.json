{
  "last_updated": "2025-07-24T00:56:54.588769",
  "papers": [
    {
      "title": "ThinkAct: Vision-Language-Action Reasoning via Reinforced Visual Latent Planning",
      "authors": [
        "Chi-Pin Huang",
        "Yueh-Hua Wu",
        "Min-Hung Chen",
        "Yu-Chiang Frank Wang",
        "Fu-En Yang"
      ],
      "abstract": "Vision-language-action (VLA) reasoning tasks require agents to interpret\nmultimodal instructions, perform long-horizon planning, and act adaptively in\ndynamic environments. Existing approaches typically train VLA models in an\nend-to-end fashion, directly mapping inputs to actions without explicit\nreasoning, which hinders their ability to plan over multiple steps or adapt to\ncomplex task variations. In this paper, we propose ThinkAct, a dual-system\nframework that bridges high-level reasoning with low-level action execution via\nreinforced visual latent planning. ThinkAct trains a multimodal LLM to generate\nembodied reasoning plans guided by reinforcing action-aligned visual rewards\nbased on goal completion and trajectory consistency. These reasoning plans are\ncompressed into a visual plan latent that conditions a downstream action model\nfor robust action execution on target environments. Extensive experiments on\nembodied reasoning and robot manipulation benchmarks demonstrate that ThinkAct\nenables few-shot adaptation, long-horizon planning, and self-correction\nbehaviors in complex embodied AI tasks.",
      "pdf_url": "http://arxiv.org/pdf/2507.16815v1",
      "published": "2025-07-22T17:59:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.16815v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ]
    },
    {
      "title": "MegaScience: Pushing the Frontiers of Post-Training Datasets for Science Reasoning",
      "authors": [
        "Run-Ze Fan",
        "Zengzhi Wang",
        "Pengfei Liu"
      ],
      "abstract": "Scientific reasoning is critical for developing AI scientists and supporting\nhuman researchers in advancing the frontiers of natural science discovery.\nHowever, the open-source community has primarily focused on mathematics and\ncoding while neglecting the scientific domain, largely due to the absence of\nopen, large-scale, high-quality, verifiable scientific reasoning datasets. To\nbridge this gap, we first present TextbookReasoning, an open dataset featuring\ntruthful reference answers extracted from 12k university-level scientific\ntextbooks, comprising 650k reasoning questions spanning 7 scientific\ndisciplines. We further introduce MegaScience, a large-scale mixture of\nhigh-quality open-source datasets totaling 1.25 million instances, developed\nthrough systematic ablation studies that evaluate various data selection\nmethodologies to identify the optimal subset for each publicly available\nscientific dataset. Meanwhile, we build a comprehensive evaluation system\ncovering diverse subjects and question types across 15 benchmarks,\nincorporating comprehensive answer extraction strategies to ensure accurate\nevaluation metrics. Our experiments demonstrate that our datasets achieve\nsuperior performance and training efficiency with more concise response lengths\ncompared to existing open-source scientific datasets. Furthermore, we train\nLlama3.1, Qwen2.5, and Qwen3 series base models on MegaScience, which\nsignificantly outperform the corresponding official instruct models in average\nperformance. In addition, MegaScience exhibits greater effectiveness for larger\nand stronger models, suggesting a scaling benefit for scientific tuning. We\nrelease our data curation pipeline, evaluation system, datasets, and seven\ntrained models to the community to advance scientific reasoning research.",
      "pdf_url": "http://arxiv.org/pdf/2507.16812v1",
      "published": "2025-07-22T17:59:03+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.16812v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Rethinking LLM-Based RTL Code Optimization Via Timing Logic Metamorphosis",
      "authors": [
        "Zhihao Xu",
        "Bixin Li",
        "Lulu Wang"
      ],
      "abstract": "Register Transfer Level(RTL) code optimization is crucial for achieving high\nperformance and low power consumption in digital circuit design. However,\ntraditional optimization methods often rely on manual tuning and heuristics,\nwhich can be time-consuming and error-prone. Recent studies proposed to\nleverage Large Language Models(LLMs) to assist in RTL code optimization. LLMs\ncan generate optimized code snippets based on natural language descriptions,\npotentially speeding up the optimization process. However, existing approaches\nhave not thoroughly evaluated the effectiveness of LLM-Based code optimization\nmethods for RTL code with complex timing logic. To address this gap, we\nconducted a comprehensive empirical investigation to assess the capability of\nLLM-Based RTL code optimization methods in handling RTL code with complex\ntiming logic. In this study, we first propose a new benchmark for RTL\noptimization evaluation. It comprises four subsets, each corresponding to a\nspecific area of RTL code optimization. Then we introduce a method based on\nmetamorphosis to systematically evaluate the effectiveness of LLM-Based RTL\ncode optimization methods.Our key insight is that the optimization\neffectiveness should remain consistent for semantically equivalent but more\ncomplex code. After intensive experiments, we revealed several key findings.\n(1) LLM-Based RTL optimization methods can effectively optimize logic\noperations and outperform existing compiler-based methods. (2) LLM-Based RTL\noptimization methods do not perform better than existing compiler-based methods\non RTL code with complex timing logic, particularly in timing control flow\noptimization and clock domain optimization. This is primarily attributed to the\nchallenges LLMs face in understanding timing logic in RTL code. Based on these\nfindings, we provide insights for further research in leveraging LLMs for RTL\ncode optimization.",
      "pdf_url": "http://arxiv.org/pdf/2507.16808v1",
      "published": "2025-07-22T17:57:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.16808v1",
      "categories": [
        "cs.SE",
        "cs.AI",
        "68N19, 68T05",
        "B.6.3; D.3.4; I.2.2; I.2.6"
      ]
    },
    {
      "title": "Beyond Binary Rewards: Training LMs to Reason About Their Uncertainty",
      "authors": [
        "Mehul Damani",
        "Isha Puri",
        "Stewart Slocum",
        "Idan Shenfeld",
        "Leshem Choshen",
        "Yoon Kim",
        "Jacob Andreas"
      ],
      "abstract": "When language models (LMs) are trained via reinforcement learning (RL) to\ngenerate natural language \"reasoning chains\", their performance improves on a\nvariety of difficult question answering tasks. Today, almost all successful\napplications of RL for reasoning use binary reward functions that evaluate the\ncorrectness of LM outputs. Because such reward functions do not penalize\nguessing or low-confidence outputs, they often have the unintended side-effect\nof degrading calibration and increasing the rate at which LMs generate\nincorrect responses (or \"hallucinate\") in other problem domains. This paper\ndescribes RLCR (Reinforcement Learning with Calibration Rewards), an approach\nto training reasoning models that jointly improves accuracy and calibrated\nconfidence estimation. During RLCR, LMs generate both predictions and numerical\nconfidence estimates after reasoning. They are trained to optimize a reward\nfunction that augments a binary correctness score with a Brier score -- a\nscoring rule for confidence estimates that incentivizes calibrated prediction.\nWe first prove that this reward function (or any analogous reward function that\nuses a bounded, proper scoring rule) yields models whose predictions are both\naccurate and well-calibrated. We next show that across diverse datasets, RLCR\nsubstantially improves calibration with no loss in accuracy, on both in-domain\nand out-of-domain evaluations -- outperforming both ordinary RL training and\nclassifiers trained to assign post-hoc confidence scores. While ordinary RL\nhurts calibration, RLCR improves it. Finally, we demonstrate that verbalized\nconfidence can be leveraged at test time to improve accuracy and calibration\nvia confidence-weighted scaling methods. Our results show that explicitly\noptimizing for calibration can produce more generally reliable reasoning\nmodels.",
      "pdf_url": "http://arxiv.org/pdf/2507.16806v1",
      "published": "2025-07-22T17:56:01+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.16806v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Decoding Translation-Related Functional Sequences in 5'UTRs Using Interpretable Deep Learning Models",
      "authors": [
        "Yuxi Lin",
        "Yaxue Fang",
        "Zehong Zhang",
        "Zhouwu Liu",
        "Siyun Zhong",
        "Fulong Yu"
      ],
      "abstract": "Understanding how 5' untranslated regions (5'UTRs) regulate mRNA translation\nis critical for controlling protein expression and designing effective\ntherapeutic mRNAs. While recent deep learning models have shown promise in\npredicting translational efficiency from 5'UTR sequences, most are constrained\nby fixed input lengths and limited interpretability. We introduce UTR-STCNet, a\nTransformer-based architecture for flexible and biologically grounded modeling\nof variable-length 5'UTRs. UTR-STCNet integrates a Saliency-Aware Token\nClustering (SATC) module that iteratively aggregates nucleotide tokens into\nmulti-scale, semantically meaningful units based on saliency scores. A\nSaliency-Guided Transformer (SGT) block then captures both local and distal\nregulatory dependencies using a lightweight attention mechanism. This combined\narchitecture achieves efficient and interpretable modeling without input\ntruncation or increased computational cost. Evaluated across three benchmark\ndatasets, UTR-STCNet consistently outperforms state-of-the-art baselines in\npredicting mean ribosome load (MRL), a key proxy for translational efficiency.\nMoreover, the model recovers known functional elements such as upstream AUGs\nand Kozak motifs, highlighting its potential for mechanistic insight into\ntranslation regulation.",
      "pdf_url": "http://arxiv.org/pdf/2507.16801v1",
      "published": "2025-07-22T17:51:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.16801v1",
      "categories": [
        "q-bio.QM",
        "cs.AI"
      ]
    },
    {
      "title": "Uncertainty-Aware Knowledge Transformers for Peer-to-Peer Energy Trading with Multi-Agent Reinforcement Learning",
      "authors": [
        "Mian Ibad Ali Shah",
        "Enda Barrett",
        "Karl Mason"
      ],
      "abstract": "This paper presents a novel framework for Peer-to-Peer (P2P) energy trading\nthat integrates uncertainty-aware prediction with multi-agent reinforcement\nlearning (MARL), addressing a critical gap in current literature. In contrast\nto previous works relying on deterministic forecasts, the proposed approach\nemploys a heteroscedastic probabilistic transformer-based prediction model\ncalled Knowledge Transformer with Uncertainty (KTU) to explicitly quantify\nprediction uncertainty, which is essential for robust decision-making in the\nstochastic environment of P2P energy trading. The KTU model leverages\ndomain-specific features and is trained with a custom loss function that\nensures reliable probabilistic forecasts and confidence intervals for each\nprediction. Integrating these uncertainty-aware forecasts into the MARL\nframework enables agents to optimize trading strategies with a clear\nunderstanding of risk and variability. Experimental results show that the\nuncertainty-aware Deep Q-Network (DQN) reduces energy purchase costs by up to\n5.7% without P2P trading and 3.2% with P2P trading, while increasing\nelectricity sales revenue by 6.4% and 44.7%, respectively. Additionally, peak\nhour grid demand is reduced by 38.8% without P2P and 45.6% with P2P. These\nimprovements are even more pronounced when P2P trading is enabled, highlighting\nthe synergy between advanced forecasting and market mechanisms for resilient,\neconomically efficient energy communities.",
      "pdf_url": "http://arxiv.org/pdf/2507.16796v1",
      "published": "2025-07-22T17:46:28+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.16796v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Steering Out-of-Distribution Generalization with Concept Ablation Fine-Tuning",
      "authors": [
        "Helena Casademunt",
        "Caden Juang",
        "Adam Karvonen",
        "Samuel Marks",
        "Senthooran Rajamanoharan",
        "Neel Nanda"
      ],
      "abstract": "Fine-tuning large language models (LLMs) can lead to unintended\nout-of-distribution generalization. Standard approaches to this problem rely on\nmodifying training data, for example by adding data that better specify the\nintended generalization. However, this is not always practical. We introduce\nConcept Ablation Fine-Tuning (CAFT), a technique that leverages\ninterpretability tools to control how LLMs generalize from fine-tuning, without\nneeding to modify the training data or otherwise use data from the target\ndistribution. Given a set of directions in an LLM's latent space corresponding\nto undesired concepts, CAFT works by ablating these concepts with linear\nprojections during fine-tuning, steering the model away from unintended\ngeneralizations. We successfully apply CAFT to three fine-tuning tasks,\nincluding emergent misalignment, a phenomenon where LLMs fine-tuned on a narrow\ntask generalize to give egregiously misaligned responses to general questions.\nWithout any changes to the fine-tuning data, CAFT reduces misaligned responses\nby 10x without degrading performance on the training distribution. Overall,\nCAFT represents a novel approach for steering LLM generalization without\nmodifying training data.",
      "pdf_url": "http://arxiv.org/pdf/2507.16795v1",
      "published": "2025-07-22T17:45:04+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.16795v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "ChatChecker: A Framework for Dialogue System Testing and Evaluation Through Non-cooperative User Simulation",
      "authors": [
        "Roman Mayr",
        "Michel Schimpf",
        "Thomas Bohné"
      ],
      "abstract": "While modern dialogue systems heavily rely on large language models (LLMs),\ntheir implementation often goes beyond pure LLM interaction. Developers\nintegrate multiple LLMs, external tools, and databases. Therefore, assessment\nof the underlying LLM alone does not suffice, and the dialogue systems must be\ntested and evaluated as a whole. However, this remains a major challenge. With\nmost previous work focusing on turn-level analysis, less attention has been\npaid to integrated dialogue-level quality assurance. To address this, we\npresent ChatChecker, a framework for automated evaluation and testing of\ncomplex dialogue systems. ChatChecker uses LLMs to simulate diverse user\ninteractions, identify dialogue breakdowns, and evaluate quality. Compared to\nprevious approaches, our design reduces setup effort and is generalizable, as\nit does not require reference dialogues and is decoupled from the\nimplementation of the target dialogue system. We improve breakdown detection\nperformance over a prior LLM-based approach by including an error taxonomy in\nthe prompt. Additionally, we propose a novel non-cooperative user simulator\nbased on challenging personas that uncovers weaknesses in target dialogue\nsystems more effectively. Through this, ChatChecker contributes to thorough and\nscalable testing. This enables both researchers and practitioners to accelerate\nthe development of robust dialogue systems.",
      "pdf_url": "http://arxiv.org/pdf/2507.16792v1",
      "published": "2025-07-22T17:40:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.16792v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "WGRAMMAR: Leverage Prior Knowledge to Accelerate Structured Decoding",
      "authors": [
        "Ran Wang",
        "Xiaoxuan Liu",
        "Hao Ren",
        "Gang Chen",
        "Fanchao Qi",
        "Maosong Sun"
      ],
      "abstract": "Structured decoding enables large language models (LLMs) to generate outputs\nin formats required by downstream systems, such as HTML or JSON. However,\nexisting methods suffer from efficiency bottlenecks due to grammar compilation,\nstate tracking, and mask creation. We observe that many real-world tasks embed\nstrong prior knowledge about output structure. Leveraging this, we propose a\ndecomposition of constraints into static and dynamic components -- precompiling\nstatic structures offline and instantiating dynamic arguments at runtime using\ngrammar snippets. Instead of relying on pushdown automata, we employ a\ncompositional set of operators to model regular formats, achieving lower\ntransition latency. We introduce wgrammar, a lightweight decoding engine that\nintegrates domain-aware simplification, constraint decomposition, and mask\ncaching, achieving up to 250x speedup over existing systems. wgrammar's source\ncode is publicly available at https://github.com/wrran/wgrammar.",
      "pdf_url": "http://arxiv.org/pdf/2507.16768v1",
      "published": "2025-07-22T17:13:47+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.16768v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Never Come Up Empty: Adaptive HyDE Retrieval for Improving LLM Developer Support",
      "authors": [
        "Fangjian Lei",
        "Mariam El Mezouar",
        "Shayan Noei",
        "Ying Zou"
      ],
      "abstract": "Large Language Models (LLMs) have shown promise in assisting developers with\ncode-related questions; however, LLMs carry the risk of generating unreliable\nanswers. To address this, Retrieval-Augmented Generation (RAG) has been\nproposed to reduce the unreliability (i.e., hallucinations) of LLMs. However,\ndesigning effective pipelines remains challenging due to numerous design\nchoices. In this paper, we construct a retrieval corpus of over 3 million Java\nand Python related Stack Overflow posts with accepted answers, and explore\nvarious RAG pipeline designs to answer developer questions, evaluating their\neffectiveness in generating accurate and reliable responses. More specifically,\nwe (1) design and evaluate 7 different RAG pipelines and 63 pipeline variants\nto answer questions that have historically similar matches, and (2) address new\nquestions without any close prior matches by automatically lowering the\nsimilarity threshold during retrieval, thereby increasing the chance of finding\npartially relevant context and improving coverage for unseen cases. We find\nthat implementing a RAG pipeline combining hypothetical-documentation-embedding\n(HyDE) with the full-answer context performs best in retrieving and answering\nsimilarcontent for Stack Overflow questions. Finally, we apply our optimal RAG\npipeline to 4 open-source LLMs and compare the results to their zero-shot\nperformance. Our findings show that RAG with our optimal RAG pipeline\nconsistently outperforms zero-shot baselines across models, achieving higher\nscores for helpfulness, correctness, and detail with LLM-as-a-judge. These\nfindings demonstrate that our optimal RAG pipelines robustly enhance answer\nquality for a wide range of developer queries including both previously seen\nand novel questions across different LLMs",
      "pdf_url": "http://arxiv.org/pdf/2507.16754v1",
      "published": "2025-07-22T16:46:00+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.16754v1",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "AI-enhanced conversational agents for personalized asthma support Factors for engagement, value and efficacy",
      "authors": [
        "Laura Moradbakhti",
        "Dorian Peters",
        "Jennifer K. Quint",
        "Björn Schuller",
        "Darren Cook",
        "Rafael A. Calvo"
      ],
      "abstract": "Asthma-related deaths in the UK are the highest in Europe, and only 30% of\npatients access basic care. There is a need for alternative approaches to\nreaching people with asthma in order to provide health education,\nself-management support and bridges to care. Automated conversational agents\n(specifically, mobile chatbots) present opportunities for providing alternative\nand individually tailored access to health education, self-management support\nand risk self-assessment. But would patients engage with a chatbot, and what\nfactors influence engagement? We present results from a patient survey (N=1257)\ndevised by a team of asthma clinicians, patients, and technology developers,\nconducted to identify optimal factors for efficacy, value and engagement for a\nchatbot. Results indicate that most adults with asthma (53%) are interested in\nusing a chatbot and the patients most likely to do so are those who believe\ntheir asthma is more serious and who are less confident about self-management.\nResults also indicate enthusiasm for 24/7 access, personalisation, and for\nWhatsApp as the preferred access method (compared to app, voice assistant, SMS\nor website). Obstacles to uptake include security/privacy concerns and\nskepticism of technological capabilities. We present detailed findings and\nconsolidate these into 7 recommendations for developers for optimising efficacy\nof chatbot-based health support.",
      "pdf_url": "http://arxiv.org/pdf/2507.16735v1",
      "published": "2025-07-22T16:21:00+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.16735v1",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY",
        "cs.ET",
        "K.4.2; J.3"
      ]
    },
    {
      "title": "Deliberative Searcher: Improving LLM Reliability via Reinforcement Learning with constraints",
      "authors": [
        "Zhenyun Yin",
        "Shujie Wang",
        "Xuhong Wang",
        "Xingjun Ma",
        "Yinchun Wang"
      ],
      "abstract": "Improving the reliability of large language models (LLMs) is critical for\ndeploying them in real-world scenarios. In this paper, we propose\n\\textbf{Deliberative Searcher}, the first framework to integrate certainty\ncalibration with retrieval-based search for open-domain question answering. The\nagent performs multi-step reflection and verification over Wikipedia data and\nis trained with a reinforcement learning algorithm that optimizes for accuracy\nunder a soft reliability constraint. Empirical results show that proposed\nmethod improves alignment between model confidence and correctness, leading to\nmore trustworthy outputs. This paper will be continuously updated.",
      "pdf_url": "http://arxiv.org/pdf/2507.16727v2",
      "published": "2025-07-22T16:09:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.16727v2",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "RAVine: Reality-Aligned Evaluation for Agentic Search",
      "authors": [
        "Yilong Xu",
        "Xiang Long",
        "Zhi Zheng",
        "Jinhua Gao"
      ],
      "abstract": "Agentic search, as a more autonomous and adaptive paradigm of retrieval\naugmentation, is driving the evolution of intelligent search systems. However,\nexisting evaluation frameworks fail to align well with the goals of agentic\nsearch. First, the complex queries commonly used in current benchmarks often\ndeviate from realistic user search scenarios. Second, prior approaches tend to\nintroduce noise when extracting ground truth for end-to-end evaluations,\nleading to distorted assessments at a fine-grained level. Third, most current\nframeworks focus solely on the quality of final answers, neglecting the\nevaluation of the iterative process inherent to agentic search. To address\nthese limitations, we propose RAVine -- a Reality-Aligned eValuation framework\nfor agentic LLMs with search. RAVine targets multi-point queries and long-form\nanswers that better reflect user intents, and introduces an attributable ground\ntruth construction strategy to enhance the accuracy of fine-grained evaluation.\nMoreover, RAVine examines model's interaction with search tools throughout the\niterative process, and accounts for factors of efficiency. We benchmark a\nseries of models using RAVine and derive several insights, which we hope will\ncontribute to advancing the development of agentic search systems. The code and\ndatasets are available at https://github.com/SwordFaith/RAVine.",
      "pdf_url": "http://arxiv.org/pdf/2507.16725v1",
      "published": "2025-07-22T16:08:12+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.16725v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ]
    },
    {
      "title": "Experience is the Best Teacher: Grounding VLMs for Robotics through Self-Generated Memory",
      "authors": [
        "Guowei Lan",
        "Kaixian Qu",
        "René Zurbrügg",
        "Changan Chen",
        "Christopher E. Mower",
        "Haitham Bou-Ammar",
        "Marco Hutter"
      ],
      "abstract": "Vision-language models (VLMs) have been widely adopted in robotics to enable\nautonomous planning. However, grounding VLMs, originally trained on internet\ndata, to diverse real-world robots remains a challenge. This paper presents\nExpTeach, a framework that grounds VLMs to physical robots by building a\nself-generated memory of real-world experiences. In ExpTeach, the VLM\nautonomously plans actions, verifies outcomes, reflects on failures, and adapts\nrobot behaviors in a closed loop. The self-generated experiences during this\nprocess are then summarized into a long-term memory, enabling retrieval of\nlearned knowledge to guide future tasks via retrieval-augmented generation\n(RAG). Additionally, ExpTeach enhances the spatial understanding of VLMs with\nan on-demand image annotation module. In experiments, we show that reflection\nimproves success rates from 36% to 84% on four challenging robotic tasks and\nobserve the emergence of intelligent object interactions, including creative\ntool use. Across extensive tests on 12 real-world scenarios (including eight\nunseen ones), we find that grounding with long-term memory boosts single-trial\nsuccess rates from 22% to 80%, demonstrating the effectiveness and\ngeneralizability of ExpTeach.",
      "pdf_url": "http://arxiv.org/pdf/2507.16713v1",
      "published": "2025-07-22T15:48:49+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.16713v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Advancing Risk and Quality Assurance: A RAG Chatbot for Improved Regulatory Compliance",
      "authors": [
        "Lars Hillebrand",
        "Armin Berger",
        "Daniel Uedelhoven",
        "David Berghaus",
        "Ulrich Warning",
        "Tim Dilmaghani",
        "Bernd Kliem",
        "Thomas Schmid",
        "Rüdiger Loitz",
        "Rafet Sifa"
      ],
      "abstract": "Risk and Quality (R&Q) assurance in highly regulated industries requires\nconstant navigation of complex regulatory frameworks, with employees handling\nnumerous daily queries demanding accurate policy interpretation. Traditional\nmethods relying on specialized experts create operational bottlenecks and limit\nscalability. We present a novel Retrieval Augmented Generation (RAG) system\nleveraging Large Language Models (LLMs), hybrid search and relevance boosting\nto enhance R&Q query processing. Evaluated on 124 expert-annotated real-world\nqueries, our actively deployed system demonstrates substantial improvements\nover traditional RAG approaches. Additionally, we perform an extensive\nhyperparameter analysis to compare and evaluate multiple configuration setups,\ndelivering valuable insights to practitioners.",
      "pdf_url": "http://arxiv.org/pdf/2507.16711v1",
      "published": "2025-07-22T15:46:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.16711v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Screen2AX: Vision-Based Approach for Automatic macOS Accessibility Generation",
      "authors": [
        "Viktor Muryn",
        "Marta Sumyk",
        "Mariya Hirna",
        "Sofiya Garkot",
        "Maksym Shamrai"
      ],
      "abstract": "Desktop accessibility metadata enables AI agents to interpret screens and\nsupports users who depend on tools like screen readers. Yet, many applications\nremain largely inaccessible due to incomplete or missing metadata provided by\ndevelopers - our investigation shows that only 33% of applications on macOS\noffer full accessibility support. While recent work on structured screen\nrepresentation has primarily addressed specific challenges, such as UI element\ndetection or captioning, none has attempted to capture the full complexity of\ndesktop interfaces by replicating their entire hierarchical structure. To\nbridge this gap, we introduce Screen2AX, the first framework to automatically\ncreate real-time, tree-structured accessibility metadata from a single\nscreenshot. Our method uses vision-language and object detection models to\ndetect, describe, and organize UI elements hierarchically, mirroring macOS's\nsystem-level accessibility structure. To tackle the limited availability of\ndata for macOS desktop applications, we compiled and publicly released three\ndatasets encompassing 112 macOS applications, each annotated for UI element\ndetection, grouping, and hierarchical accessibility metadata alongside\ncorresponding screenshots. Screen2AX accurately infers hierarchy trees,\nachieving a 77% F1 score in reconstructing a complete accessibility tree.\nCrucially, these hierarchy trees improve the ability of autonomous agents to\ninterpret and interact with complex desktop interfaces. We introduce\nScreen2AX-Task, a benchmark specifically designed for evaluating autonomous\nagent task execution in macOS desktop environments. Using this benchmark, we\ndemonstrate that Screen2AX delivers a 2.2x performance improvement over native\naccessibility representations and surpasses the state-of-the-art OmniParser V2\nsystem on the ScreenSpot benchmark.",
      "pdf_url": "http://arxiv.org/pdf/2507.16704v1",
      "published": "2025-07-22T15:38:12+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.16704v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.HC"
      ]
    },
    {
      "title": "FISHER: A Foundation Model for Multi-Modal Industrial Signal Comprehensive Representation",
      "authors": [
        "Pingyi Fan",
        "Anbai Jiang",
        "Shuwei Zhang",
        "Zhiqiang Lv",
        "Bing Han",
        "Xinhu Zheng",
        "Wenrui Liang",
        "Junjie Li",
        "Wei-Qiang Zhang",
        "Yanmin Qian",
        "Xie Chen",
        "Cheng Lu",
        "Jia Liu"
      ],
      "abstract": "With the rapid deployment of SCADA systems, how to effectively analyze\nindustrial signals and detect abnormal states is an urgent need for the\nindustry. Due to the significant heterogeneity of these signals, which we\nsummarize as the M5 problem, previous works only focus on small sub-problems\nand employ specialized models, failing to utilize the synergies between\nmodalities and the powerful scaling law. However, we argue that the M5 signals\ncan be modeled in a unified manner due to the intrinsic similarity. As a\nresult, we propose FISHER, a Foundation model for multi-modal Industrial Signal\ncompreHEnsive Representation. To support arbitrary sampling rates, FISHER\nconsiders the increment of sampling rate as the concatenation of sub-band\ninformation. Specifically, FISHER takes the STFT sub-band as the modeling unit\nand adopts a teacher student SSL framework for pre-training. We also develop\nthe RMIS benchmark, which evaluates the representations of M5 industrial\nsignals on multiple health management tasks. Compared with top SSL models,\nFISHER showcases versatile and outstanding capabilities with a general\nperformance gain up to 5.03%, along with much more efficient scaling curves. We\nalso investigate the scaling law on downstream tasks and derive potential\navenues for future works. FISHER is now open-sourced on\nhttps://github.com/jianganbai/FISHER",
      "pdf_url": "http://arxiv.org/pdf/2507.16696v1",
      "published": "2025-07-22T15:31:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.16696v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MM",
        "cs.SD"
      ]
    },
    {
      "title": "Interpretable Topic Extraction and Word Embedding Learning using row-stochastic DEDICOM",
      "authors": [
        "Lars Hillebrand",
        "David Biesner",
        "Christian Bauckhage",
        "Rafet Sifa"
      ],
      "abstract": "The DEDICOM algorithm provides a uniquely interpretable matrix factorization\nmethod for symmetric and asymmetric square matrices. We employ a new\nrow-stochastic variation of DEDICOM on the pointwise mutual information\nmatrices of text corpora to identify latent topic clusters within the\nvocabulary and simultaneously learn interpretable word embeddings. We introduce\na method to efficiently train a constrained DEDICOM algorithm and a qualitative\nevaluation of its topic modeling and word embedding performance.",
      "pdf_url": "http://arxiv.org/pdf/2507.16695v1",
      "published": "2025-07-22T15:30:32+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.16695v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "PICACO: Pluralistic In-Context Value Alignment of LLMs via Total Correlation Optimization",
      "authors": [
        "Han Jiang",
        "Dongyao Zhu",
        "Zhihua Wei",
        "Xiaoyuan Yi",
        "Ziang Xiao",
        "Xing Xie"
      ],
      "abstract": "In-Context Learning has shown great potential for aligning Large Language\nModels (LLMs) with human values, helping reduce harmful outputs and accommodate\ndiverse preferences without costly post-training, known as In-Context Alignment\n(ICA). However, LLMs' comprehension of input prompts remains agnostic, limiting\nICA's ability to address value tensions--human values are inherently\npluralistic, often imposing conflicting demands, e.g., stimulation vs.\ntradition. Current ICA methods therefore face the Instruction Bottleneck\nchallenge, where LLMs struggle to reconcile multiple intended values within a\nsingle prompt, leading to incomplete or biased alignment. To address this, we\npropose PICACO, a novel pluralistic ICA method. Without fine-tuning, PICACO\noptimizes a meta-instruction that navigates multiple values to better elicit\nLLMs' understanding of them and improve their alignment. This is achieved by\nmaximizing the total correlation between specified values and LLM responses,\ntheoretically reinforcing value correlation while reducing distractive noise,\nresulting in effective value instructions. Extensive experiments on five value\nsets show that PICACO works well with both black-box and open-source LLMs,\noutperforms several recent strong baselines, and achieves a better balance\nacross up to 8 distinct values.",
      "pdf_url": "http://arxiv.org/pdf/2507.16679v1",
      "published": "2025-07-22T15:14:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.16679v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ]
    },
    {
      "title": "Meta-Learning for Cold-Start Personalization in Prompt-Tuned LLMs",
      "authors": [
        "Yushang Zhao",
        "Huijie Shen",
        "Dannier Li",
        "Lu Chang",
        "Chengrui Zhou",
        "Yinuo Yang"
      ],
      "abstract": "Generative, explainable, and flexible recommender systems, derived using\nLarge Language Models (LLM) are promising and poorly adapted to the cold-start\nuser situation, where there is little to no history of interaction. The current\nsolutions i.e. supervised fine-tuning and collaborative filtering are\ndense-user-item focused and would be expensive to maintain and update. This\npaper introduces a meta-learning framework, that can be used to perform\nparameter-efficient prompt-tuning, to effectively personalize LLM-based\nrecommender systems quickly at cold-start. The model learns soft prompt\nembeddings with first-order (Reptile) and second-order (MAML) optimization by\ntreating each of the users as the tasks. As augmentations to the input tokens,\nthese learnable vectors are the differentiable control variables that represent\nuser behavioral priors. The prompts are meta-optimized through episodic\nsampling, inner-loop adaptation, and outer-loop generalization. On\nMovieLens-1M, Amazon Reviews, and Recbole, we can see that our adaptive model\noutperforms strong baselines in NDCG@10, HR@10, and MRR, and it runs in\nreal-time (i.e., below 300 ms) on consumer GPUs. Zero-history personalization\nis also supported by this scalable solution, and its 275 ms rate of adaptation\nallows successful real-time risk profiling of financial systems by shortening\ndetection latency and improving payment network stability. Crucially, the 275\nms adaptation capability can enable real-time risk profiling for financial\ninstitutions, reducing systemic vulnerability detection latency significantly\nversus traditional compliance checks. By preventing contagion in payment\nnetworks (e.g., Fedwire), the framework strengthens national financial\ninfrastructure resilience.",
      "pdf_url": "http://arxiv.org/pdf/2507.16672v1",
      "published": "2025-07-22T15:07:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.16672v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Adaptive Inventory Strategies using Deep Reinforcement Learning for Dynamic Agri-Food Supply Chains",
      "authors": [
        "Amandeep Kaur",
        "Gyan Prakash"
      ],
      "abstract": "Agricultural products are often subject to seasonal fluctuations in\nproduction and demand. Predicting and managing inventory levels in response to\nthese variations can be challenging, leading to either excess inventory or\nstockouts. Additionally, the coordination among stakeholders at various level\nof food supply chain is not considered in the existing body of literature. To\nbridge these research gaps, this study focuses on inventory management of\nagri-food products under demand and lead time uncertainties. By implementing\neffective inventory replenishment policy results in maximize the overall profit\nthroughout the supply chain. However, the complexity of the problem increases\ndue to these uncertainties and shelf-life of the product, that makes\nchallenging to implement traditional approaches to generate optimal set of\nsolutions. Thus, the current study propose a novel Deep Reinforcement Learning\n(DRL) algorithm that combines the benefits of both value- and policy-based DRL\napproaches for inventory optimization under uncertainties. The proposed\nalgorithm can incentivize collaboration among stakeholders by aligning their\ninterests and objectives through shared optimization goal of maximizing\nprofitability along the agri-food supply chain while considering perishability,\nand uncertainty simultaneously. By selecting optimal order quantities with\ncontinuous action space, the proposed algorithm effectively addresses the\ninventory optimization challenges. To rigorously evaluate this algorithm, the\nempirical data from fresh agricultural products supply chain inventory is\nconsidered. Experimental results corroborate the improved performance of the\nproposed inventory replenishment policy under stochastic demand patterns and\nlead time scenarios. The research findings hold managerial implications for\npolicymakers to manage the inventory of agricultural products more effectively\nunder uncertainty.",
      "pdf_url": "http://arxiv.org/pdf/2507.16670v1",
      "published": "2025-07-22T15:02:54+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.16670v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Self-Contradiction as Self-Improvement: Mitigating the Generation-Understanding Gap in MLLMs",
      "authors": [
        "Yujin Han",
        "Hao Chen",
        "Andi Han",
        "Zhiheng Wang",
        "Xinyu Lin",
        "Yingya Zhang",
        "Shiwei Zhang",
        "Difan Zou"
      ],
      "abstract": "Despite efforts to unify multimodal generation and understanding tasks in a\nsingle model, we show these MLLMs exhibit self-contradiction where generation\nproduces images deemed misaligned with input prompts based on the model's own\nunderstanding. We define a Nonunified score that quantifies such\nself-contradiction. Our empirical results reveal that the self-contradiction\nmainly arises from weak generation that fails to align with prompts, rather\nthan misunderstanding. This capability asymmetry indicates the potential of\nleveraging self-contradiction for self-improvement, where the stronger model\nunderstanding guides the weaker generation to mitigate the\ngeneration-understanding gap. Applying standard post-training methods (e.g.,\nSFT, DPO) with such internal supervision successfully improves both generation\nand unification. We discover a co-improvement effect on both generation and\nunderstanding when only fine-tuning the generation branch, a phenomenon known\nin pre-training but underexplored in post-training. Our analysis shows\nimprovements stem from better detection of false positives that are previously\nincorrectly identified as prompt-aligned. Theoretically, we show the aligned\ntraining dynamics between generation and understanding allow reduced\nprompt-misaligned generations to also improve mismatch detection in the\nunderstanding branch. Additionally, the framework reveals a potential risk of\nco-degradation under poor supervision-an overlooked phenomenon that is\nempirically validated in our experiments. Notably, we find intrinsic metrics\nlike Nonunified score cannot distinguish co-degradation from co-improvement,\nwhich highlights the necessity of data quality check. Finally, we propose a\ncurriculum-based strategy based on our findings that gradually introduces\nharder samples as the model improves, leading to better unification and\nimproved MLLM generation and understanding.",
      "pdf_url": "http://arxiv.org/pdf/2507.16663v1",
      "published": "2025-07-22T14:56:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.16663v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Towards Automated Regulatory Compliance Verification in Financial Auditing with Large Language Models",
      "authors": [
        "Armin Berger",
        "Lars Hillebrand",
        "David Leonhard",
        "Tobias Deußer",
        "Thiago Bell Felix de Oliveira",
        "Tim Dilmaghani",
        "Mohamed Khaled",
        "Bernd Kliem",
        "Rüdiger Loitz",
        "Christian Bauckhage",
        "Rafet Sifa"
      ],
      "abstract": "The auditing of financial documents, historically a labor-intensive process,\nstands on the precipice of transformation. AI-driven solutions have made\ninroads into streamlining this process by recommending pertinent text passages\nfrom financial reports to align with the legal requirements of accounting\nstandards. However, a glaring limitation remains: these systems commonly fall\nshort in verifying if the recommended excerpts indeed comply with the specific\nlegal mandates. Hence, in this paper, we probe the efficiency of publicly\navailable Large Language Models (LLMs) in the realm of regulatory compliance\nacross different model configurations. We place particular emphasis on\ncomparing cutting-edge open-source LLMs, such as Llama-2, with their\nproprietary counterparts like OpenAI's GPT models. This comparative analysis\nleverages two custom datasets provided by our partner PricewaterhouseCoopers\n(PwC) Germany. We find that the open-source Llama-2 70 billion model\ndemonstrates outstanding performance in detecting non-compliance or true\nnegative occurrences, beating all their proprietary counterparts. Nevertheless,\nproprietary models such as GPT-4 perform the best in a broad variety of\nscenarios, particularly in non-English contexts.",
      "pdf_url": "http://arxiv.org/pdf/2507.16642v1",
      "published": "2025-07-22T14:39:54+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.16642v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Novel Multi-Agent Action Masked Deep Reinforcement Learning for General Industrial Assembly Lines Balancing Problems",
      "authors": [
        "Ali Mohamed Ali",
        "Luca Tirel",
        "Hashim A. Hashim"
      ],
      "abstract": "Efficient planning of activities is essential for modern industrial assembly\nlines to uphold manufacturing standards, prevent project constraint violations,\nand achieve cost-effective operations. While exact solutions to such challenges\ncan be obtained through Integer Programming (IP), the dependence of the search\nspace on input parameters often makes IP computationally infeasible for\nlarge-scale scenarios. Heuristic methods, such as Genetic Algorithms, can also\nbe applied, but they frequently produce suboptimal solutions in extensive\ncases. This paper introduces a novel mathematical model of a generic industrial\nassembly line formulated as a Markov Decision Process (MDP), without imposing\nassumptions on the type of assembly line a notable distinction from most\nexisting models. The proposed model is employed to create a virtual environment\nfor training Deep Reinforcement Learning (DRL) agents to optimize task and\nresource scheduling. To enhance the efficiency of agent training, the paper\nproposes two innovative tools. The first is an action-masking technique, which\nensures the agent selects only feasible actions, thereby reducing training\ntime. The second is a multi-agent approach, where each workstation is managed\nby an individual agent, as a result, the state and action spaces were reduced.\nA centralized training framework with decentralized execution is adopted,\noffering a scalable learning architecture for optimizing industrial assembly\nlines. This framework allows the agents to learn offline and subsequently\nprovide real-time solutions during operations by leveraging a neural network\nthat maps the current factory state to the optimal action. The effectiveness of\nthe proposed scheme is validated through numerical simulations, demonstrating\nsignificantly faster convergence to the optimal solution compared to a\ncomparable model-based approach.",
      "pdf_url": "http://arxiv.org/pdf/2507.16635v1",
      "published": "2025-07-22T14:34:36+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.16635v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "An Experimental Study of Split-Learning TinyML on Ultra-Low-Power Edge/IoT Nodes",
      "authors": [
        "Zied Jenhani",
        "Mounir Bensalem",
        "Jasenka Dizdarević",
        "Admela Jukan"
      ],
      "abstract": "Running deep learning inference directly on ultra-low-power edge/IoT nodes\nhas been limited by the tight memory and compute budgets of microcontrollers.\nSplit learning (SL) addresses this limitation in which it executes part of the\ninference process on the sensor and off-loads the remainder to a companion\ndevice. In the context of constrained devices and the related impact of\nlow-power, over-the-air transport protocols, the performance of split learning\nremains largely unexplored. TO the best of our knowledge, this paper presents\nthe first end-to-end TinyML + SL testbed built on Espressif ESP32-S3 boards,\ndesigned to benchmark the over-the-air performance of split learning TinyML in\nedge/IoT environments. We benchmark the performance of a MobileNetV2 image\nrecognition model, which is quantized to 8-bit integers, partitioned, and\ndelivered to the nodes via over-the-air updates. The intermediate activations\nare exchanged through different wireless communication methods: ESP-NOW, BLE,\nand traditional UDP/IP and TCP/IP, enabling a head-to-head comparison on\nidentical hardware. Measurements show that splitting the model after\nblock_16_project_BN layer generates a 5.66 kB tensor that traverses the link in\n3.2 ms, when UDP is used, achieving a steady-state round-trip latency of 5.8 s.\nESP-NOW presents the most favorable RTT performance 3.7 s; BLE extends battery\nlife further but increases latency beyond 10s.",
      "pdf_url": "http://arxiv.org/pdf/2507.16594v1",
      "published": "2025-07-22T13:50:12+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.16594v1",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.DC"
      ]
    },
    {
      "title": "AI for Better UX in Computer-Aided Engineering: Is Academia Catching Up with Industry Demands? A Multivocal Literature Review",
      "authors": [
        "Choro Ulan Uulu",
        "Mikhail Kulyabin",
        "Layan Etaiwi",
        "Nuno Miguel Martins Pacheco",
        "Jan Joosten",
        "Kerstin Röse",
        "Filippos Petridis",
        "Jan Bosch",
        "Helena Holmström Olsson"
      ],
      "abstract": "Computer-Aided Engineering (CAE) enables simulation experts to optimize\ncomplex models, but faces challenges in user experience (UX) that limit\nefficiency and accessibility. While artificial intelligence (AI) has\ndemonstrated potential to enhance CAE processes, research integrating these\nfields with a focus on UX remains fragmented. This paper presents a multivocal\nliterature review (MLR) examining how AI enhances UX in CAE software across\nboth academic research and industry implementations. Our analysis reveals\nsignificant gaps between academic explorations and industry applications, with\ncompanies actively implementing LLMs, adaptive UIs, and recommender systems\nwhile academic research focuses primarily on technical capabilities without UX\nvalidation. Key findings demonstrate opportunities in AI-powered guidance,\nadaptive interfaces, and workflow automation that remain underexplored in\ncurrent research. By mapping the intersection of these domains, this study\nprovides a foundation for future work to address the identified research gaps\nand advance the integration of AI to improve CAE user experience.",
      "pdf_url": "http://arxiv.org/pdf/2507.16586v1",
      "published": "2025-07-22T13:39:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.16586v1",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.SE"
      ]
    },
    {
      "title": "Pyramid Hierarchical Masked Diffusion Model for Imaging Synthesis",
      "authors": [
        "Xiaojiao Xiao",
        "Qinmin Vivian Hu",
        "Guanghui Wang"
      ],
      "abstract": "Medical image synthesis plays a crucial role in clinical workflows,\naddressing the common issue of missing imaging modalities due to factors such\nas extended scan times, scan corruption, artifacts, patient motion, and\nintolerance to contrast agents. The paper presents a novel image synthesis\nnetwork, the Pyramid Hierarchical Masked Diffusion Model (PHMDiff), which\nemploys a multi-scale hierarchical approach for more detailed control over\nsynthesizing high-quality images across different resolutions and layers.\nSpecifically, this model utilizes randomly multi-scale high-proportion masks to\nspeed up diffusion model training, and balances detail fidelity and overall\nstructure. The integration of a Transformer-based Diffusion model process\nincorporates cross-granularity regularization, modeling the mutual information\nconsistency across each granularity's latent spaces, thereby enhancing\npixel-level perceptual accuracy. Comprehensive experiments on two challenging\ndatasets demonstrate that PHMDiff achieves superior performance in both the\nPeak Signal-to-Noise Ratio (PSNR) and Structural Similarity Index Measure\n(SSIM), highlighting its capability to produce high-quality synthesized images\nwith excellent structural integrity. Ablation studies further confirm the\ncontributions of each component. Furthermore, the PHMDiff model, a multi-scale\nimage synthesis framework across and within medical imaging modalities, shows\nsignificant advantages over other methods. The source code is available at\nhttps://github.com/xiaojiao929/PHMDiff",
      "pdf_url": "http://arxiv.org/pdf/2507.16579v1",
      "published": "2025-07-22T13:30:54+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.16579v1",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Data-Driven Adaptive Gradient Recovery for Unstructured Finite Volume Computations",
      "authors": [
        "G. de Romémont",
        "F. Renac",
        "F. Chinesta",
        "J. Nunez",
        "D. Gueyffier"
      ],
      "abstract": "We present a novel data-driven approach for enhancing gradient reconstruction\nin unstructured finite volume methods for hyperbolic conservation laws,\nspecifically for the 2D Euler equations. Our approach extends previous\nstructured-grid methodologies to unstructured meshes through a modified\nDeepONet architecture that incorporates local geometry in the neural network.\nThe architecture employs local mesh topology to ensure rotation invariance,\nwhile also ensuring first-order constraint on the learned operator. The\ntraining methodology incorporates physics-informed regularization through\nentropy penalization, total variation diminishing penalization, and parameter\nregularization to ensure physically consistent solutions, particularly in\nshock-dominated regions. The model is trained on high-fidelity datasets\nsolutions derived from sine waves and randomized piecewise constant initial\nconditions with periodic boundary conditions, enabling robust generalization to\ncomplex flow configurations or geometries. Validation test cases from the\nliterature, including challenging geometry configuration, demonstrates\nsubstantial improvements in accuracy compared to traditional second-order\nfinite volume schemes. The method achieves gains of 20-60% in solution accuracy\nwhile enhancing computational efficiency. A convergence study has been conveyed\nand reveal improved mesh convergence rates compared to the conventional solver.\nThe proposed algorithm is faster and more accurate than the traditional\nsecond-order finite volume solver, enabling high-fidelity simulations on\ncoarser grids while preserving the stability and conservation properties\nessential for hyperbolic conservation laws. This work is a part of a new\ngeneration of solvers that are built by combining Machine-Learning (ML) tools\nwith traditional numerical schemes, all while ensuring physical constraint on\nthe results.",
      "pdf_url": "http://arxiv.org/pdf/2507.16571v1",
      "published": "2025-07-22T13:23:57+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.16571v1",
      "categories": [
        "math.NA",
        "cs.AI",
        "cs.NA",
        "math.AP"
      ]
    },
    {
      "title": "TTMBA: Towards Text To Multiple Sources Binaural Audio Generation",
      "authors": [
        "Yuxuan He",
        "Xiaoran Yang",
        "Ningning Pan",
        "Gongping Huang"
      ],
      "abstract": "Most existing text-to-audio (TTA) generation methods produce mono outputs,\nneglecting essential spatial information for immersive auditory experiences. To\naddress this issue, we propose a cascaded method for text-to-multisource\nbinaural audio generation (TTMBA) with both temporal and spatial control.\nFirst, a pretrained large language model (LLM) segments the text into a\nstructured format with time and spatial details for each sound event. Next, a\npretrained mono audio generation network creates multiple mono audios with\nvarying durations for each event. These mono audios are transformed into\nbinaural audios using a binaural rendering neural network based on spatial data\nfrom the LLM. Finally, the binaural audios are arranged by their start times,\nresulting in multisource binaural audio. Experimental results demonstrate the\nsuperiority of the proposed method in terms of both audio generation quality\nand spatial perceptual accuracy.",
      "pdf_url": "http://arxiv.org/pdf/2507.16564v1",
      "published": "2025-07-22T13:16:07+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.16564v1",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ]
    },
    {
      "title": "Evaluating Social Acceptance of eXtended Reality (XR) Agent Technology: A User Study (Extended Version)",
      "authors": [
        "Megha Quamara",
        "Viktor Schmuck",
        "Cristina Iani",
        "Axel Primavesi",
        "Alexander Plaum",
        "Luca Vigano"
      ],
      "abstract": "In this paper, we present the findings of a user study that evaluated the\nsocial acceptance of eXtended Reality (XR) agent technology, focusing on a\nremotely accessible, web-based XR training system developed for journalists.\nThis system involves user interaction with a virtual avatar, enabled by a\nmodular toolkit. The interactions are designed to provide tailored training for\njournalists in digital-remote settings, especially for sensitive or dangerous\nscenarios, without requiring specialized end-user equipment like headsets. Our\nresearch adapts and extends the Almere model, representing social acceptance\nthrough existing attributes such as perceived ease of use and perceived\nusefulness, along with added ones like dependability and security in the\nuser-agent interaction. The XR agent was tested through a controlled experiment\nin a real-world setting, with data collected on users' perceptions. Our\nfindings, based on quantitative and qualitative measurements involving\nquestionnaires, contribute to the understanding of user perceptions and\nacceptance of XR agent solutions within a specific social context, while also\nidentifying areas for the improvement of XR systems.",
      "pdf_url": "http://arxiv.org/pdf/2507.16562v1",
      "published": "2025-07-22T13:14:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.16562v1",
      "categories": [
        "cs.HC",
        "cs.AI"
      ]
    },
    {
      "title": "Optimization of DNN-based HSI Segmentation FPGA-based SoC for ADS: A Practical Approach",
      "authors": [
        "Jon Gutiérrez-Zaballa",
        "Koldo Basterretxea",
        "Javier Echanobe"
      ],
      "abstract": "The use of HSI for autonomous navigation is a promising research field aimed\nat improving the accuracy and robustness of detection, tracking, and scene\nunderstanding systems based on vision sensors. Combining advanced computer\nalgorithms, such as DNNs, with small-size snapshot HSI cameras enhances the\nreliability of these systems. HSI overcomes intrinsic limitations of greyscale\nand RGB imaging in depicting physical properties of targets, particularly\nregarding spectral reflectance and metamerism. Despite promising results in\nHSI-based vision developments, safety-critical systems like ADS demand strict\nconstraints on latency, resource consumption, and security, motivating the\nshift of ML workloads to edge platforms. This involves a thorough\nsoftware/hardware co-design scheme to distribute and optimize the tasks\nefficiently among the limited resources of computing platforms. With respect to\ninference, the over-parameterized nature of DNNs poses significant\ncomputational challenges for real-time on-the-edge deployment. In addition, the\nintensive data preprocessing required by HSI, which is frequently overlooked,\nmust be carefully managed in terms of memory arrangement and inter-task\ncommunication to enable an efficient integrated pipeline design on a SoC. This\nwork presents a set of optimization techniques for the practical co-design of a\nDNN-based HSI segmentation processor deployed on a FPGA-based SoC targeted at\nADS, including key optimizations such as functional software/hardware task\ndistribution, hardware-aware preprocessing, ML model compression, and a\ncomplete pipelined deployment. Applied compression techniques significantly\nreduce the complexity of the designed DNN to 24.34% of the original operations\nand to 1.02% of the original number of parameters, achieving a 2.86x speed-up\nin the inference task without noticeable degradation of the segmentation\naccuracy.",
      "pdf_url": "http://arxiv.org/pdf/2507.16556v1",
      "published": "2025-07-22T13:09:04+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.16556v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.AR",
        "cs.LG",
        "eess.IV"
      ]
    },
    {
      "title": "A Comprehensive Data-centric Overview of Federated Graph Learning",
      "authors": [
        "Zhengyu Wu",
        "Xunkai Li",
        "Yinlin Zhu",
        "Zekai Chen",
        "Guochen Yan",
        "Yanyu Yan",
        "Hao Zhang",
        "Yuming Ai",
        "Xinmo Jin",
        "Rong-Hua Li",
        "Guoren Wang"
      ],
      "abstract": "In the era of big data applications, Federated Graph Learning (FGL) has\nemerged as a prominent solution that reconcile the tradeoff between optimizing\nthe collective intelligence between decentralized datasets holders and\npreserving sensitive information to maximum. Existing FGL surveys have\ncontributed meaningfully but largely focus on integrating Federated Learning\n(FL) and Graph Machine Learning (GML), resulting in early stage taxonomies that\nemphasis on methodology and simulated scenarios. Notably, a data centric\nperspective, which systematically examines FGL methods through the lens of data\nproperties and usage, remains unadapted to reorganize FGL research, yet it is\ncritical to assess how FGL studies manage to tackle data centric constraints to\nenhance model performances. This survey propose a two-level data centric\ntaxonomy: Data Characteristics, which categorizes studies based on the\nstructural and distributional properties of datasets used in FGL, and Data\nUtilization, which analyzes the training procedures and techniques employed to\novercome key data centric challenges. Each taxonomy level is defined by three\northogonal criteria, each representing a distinct data centric configuration.\nBeyond taxonomy, this survey examines FGL integration with Pretrained Large\nModels, showcases realistic applications, and highlights future direction\naligned with emerging trends in GML.",
      "pdf_url": "http://arxiv.org/pdf/2507.16541v1",
      "published": "2025-07-22T12:49:24+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.16541v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ]
    },
    {
      "title": "Symbolic Graph Intelligence: Hypervector Message Passing for Learning Graph-Level Patterns with Tsetlin Machines",
      "authors": [
        "Christian D. Blakely"
      ],
      "abstract": "We propose a multilayered symbolic framework for general graph classification\nthat leverages sparse binary hypervectors and Tsetlin Machines. Each graph is\nencoded through structured message passing, where node, edge, and attribute\ninformation are bound and bundled into a symbolic hypervector. This process\npreserves the hierarchical semantics of the graph through layered binding from\nnode attributes to edge relations to structural roles resulting in a compact,\ndiscrete representation. We also formulate a local interpretability framework\nwhich lends itself to a key advantage of our approach being locally\ninterpretable. We validate our method on TUDataset benchmarks, demonstrating\ncompetitive accuracy with strong symbolic transparency compared to neural graph\nmodels.",
      "pdf_url": "http://arxiv.org/pdf/2507.16537v1",
      "published": "2025-07-22T12:47:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.16537v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "EarthCrafter: Scalable 3D Earth Generation via Dual-Sparse Latent Diffusion",
      "authors": [
        "Shang Liu",
        "Chenjie Cao",
        "Chaohui Yu",
        "Wen Qian",
        "Jing Wang",
        "Fan Wang"
      ],
      "abstract": "Despite the remarkable developments achieved by recent 3D generation works,\nscaling these methods to geographic extents, such as modeling thousands of\nsquare kilometers of Earth's surface, remains an open challenge. We address\nthis through a dual innovation in data infrastructure and model architecture.\nFirst, we introduce Aerial-Earth3D, the largest 3D aerial dataset to date,\nconsisting of 50k curated scenes (each measuring 600m x 600m) captured across\nthe U.S. mainland, comprising 45M multi-view Google Earth frames. Each scene\nprovides pose-annotated multi-view images, depth maps, normals, semantic\nsegmentation, and camera poses, with explicit quality control to ensure terrain\ndiversity. Building on this foundation, we propose EarthCrafter, a tailored\nframework for large-scale 3D Earth generation via sparse-decoupled latent\ndiffusion. Our architecture separates structural and textural generation: 1)\nDual sparse 3D-VAEs compress high-resolution geometric voxels and textural 2D\nGaussian Splats (2DGS) into compact latent spaces, largely alleviating the\ncostly computation suffering from vast geographic scales while preserving\ncritical information. 2) We propose condition-aware flow matching models\ntrained on mixed inputs (semantics, images, or neither) to flexibly model\nlatent geometry and texture features independently. Extensive experiments\ndemonstrate that EarthCrafter performs substantially better in extremely\nlarge-scale generation. The framework further supports versatile applications,\nfrom semantic-guided urban layout generation to unconditional terrain\nsynthesis, while maintaining geographic plausibility through our rich data\npriors from Aerial-Earth3D. Our project page is available at\nhttps://whiteinblue.github.io/earthcrafter/",
      "pdf_url": "http://arxiv.org/pdf/2507.16535v2",
      "published": "2025-07-22T12:46:48+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.16535v2",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Frontier AI Risk Management Framework in Practice: A Risk Analysis Technical Report",
      "authors": [
        "Shanghai AI Lab",
        ":",
        "Xiaoyang Chen",
        "Yunhao Chen",
        "Zeren Chen",
        "Zhiyun Chen",
        "Hanyun Cui",
        "Yawen Duan",
        "Jiaxuan Guo",
        "Qi Guo",
        "Xuhao Hu",
        "Hong Huang",
        "Lige Huang",
        "Chunxiao Li",
        "Juncheng Li",
        "Qihao Lin",
        "Dongrui Liu",
        "Xinmin Liu",
        "Zicheng Liu",
        "Chaochao Lu",
        "Xiaoya Lu",
        "Jingjing Qu",
        "Qibing Ren",
        "Jing Shao",
        "Jingwei Shi",
        "Jingwei Sun",
        "Peng Wang",
        "Weibing Wang",
        "Jia Xu",
        "Lewen Yan",
        "Xiao Yu",
        "Yi Yu",
        "Boxuan Zhang",
        "Jie Zhang",
        "Weichen Zhang",
        "Zhijie Zheng",
        "Tianyi Zhou",
        "Bowen Zhou"
      ],
      "abstract": "To understand and identify the unprecedented risks posed by rapidly advancing\nartificial intelligence (AI) models, this report presents a comprehensive\nassessment of their frontier risks. Drawing on the E-T-C analysis (deployment\nenvironment, threat source, enabling capability) from the Frontier AI Risk\nManagement Framework (v1.0) (SafeWork-F1-Framework), we identify critical risks\nin seven areas: cyber offense, biological and chemical risks, persuasion and\nmanipulation, uncontrolled autonomous AI R\\&D, strategic deception and\nscheming, self-replication, and collusion. Guided by the \"AI-$45^\\circ$ Law,\"\nwe evaluate these risks using \"red lines\" (intolerable thresholds) and \"yellow\nlines\" (early warning indicators) to define risk zones: green (manageable risk\nfor routine deployment and continuous monitoring), yellow (requiring\nstrengthened mitigations and controlled deployment), and red (necessitating\nsuspension of development and/or deployment). Experimental results show that\nall recent frontier AI models reside in green and yellow zones, without\ncrossing red lines. Specifically, no evaluated models cross the yellow line for\ncyber offense or uncontrolled AI R\\&D risks. For self-replication, and\nstrategic deception and scheming, most models remain in the green zone, except\nfor certain reasoning models in the yellow zone. In persuasion and\nmanipulation, most models are in the yellow zone due to their effective\ninfluence on humans. For biological and chemical risks, we are unable to rule\nout the possibility of most models residing in the yellow zone, although\ndetailed threat modeling and in-depth assessment are required to make further\nclaims. This work reflects our current understanding of AI frontier risks and\nurges collective action to mitigate these challenges.",
      "pdf_url": "http://arxiv.org/pdf/2507.16534v1",
      "published": "2025-07-22T12:44:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.16534v1",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG"
      ]
    },
    {
      "title": "confopt: A Library for Implementation and Evaluation of Gradient-based One-Shot NAS Methods",
      "authors": [
        "Abhash Kumar Jha",
        "Shakiba Moradian",
        "Arjun Krishnakumar",
        "Martin Rapp",
        "Frank Hutter"
      ],
      "abstract": "Gradient-based one-shot neural architecture search (NAS) has significantly\nreduced the cost of exploring architectural spaces with discrete design\nchoices, such as selecting operations within a model. However, the field faces\ntwo major challenges. First, evaluations of gradient-based NAS methods heavily\nrely on the DARTS benchmark, despite the existence of other available\nbenchmarks. This overreliance has led to saturation, with reported improvements\noften falling within the margin of noise. Second, implementations of\ngradient-based one-shot NAS methods are fragmented across disparate\nrepositories, complicating fair and reproducible comparisons and further\ndevelopment. In this paper, we introduce Configurable Optimizer (confopt), an\nextensible library designed to streamline the development and evaluation of\ngradient-based one-shot NAS methods. Confopt provides a minimal API that makes\nit easy for users to integrate new search spaces, while also supporting the\ndecomposition of NAS optimizers into their core components. We use this\nframework to create a suite of new DARTS-based benchmarks, and combine them\nwith a novel evaluation protocol to reveal a critical flaw in how\ngradient-based one-shot NAS methods are currently assessed. The code can be\nfound at https://github.com/automl/ConfigurableOptimizer.",
      "pdf_url": "http://arxiv.org/pdf/2507.16533v1",
      "published": "2025-07-22T12:44:28+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.16533v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68T01",
        "I.2.6"
      ]
    },
    {
      "title": "Spatial 3D-LLM: Exploring Spatial Awareness in 3D Vision-Language Models",
      "authors": [
        "Xiaoyan Wang",
        "Zeju Li",
        "Yifan Xu",
        "Jiaxing Qi",
        "Zhifei Yang",
        "Ruifei Ma",
        "Xiangde Liu",
        "Chao Zhang"
      ],
      "abstract": "New era has unlocked exciting possibilities for extending Large Language\nModels (LLMs) to tackle 3D vision-language tasks. However, most existing 3D\nmultimodal LLMs (MLLMs) rely on compressing holistic 3D scene information or\nsegmenting independent objects to perform these tasks, which limits their\nspatial awareness due to insufficient representation of the richness inherent\nin 3D scenes. To overcome these limitations, we propose Spatial 3D-LLM, a 3D\nMLLM specifically designed to enhance spatial awareness for 3D vision-language\ntasks by enriching the spatial embeddings of 3D scenes. Spatial 3D-LLM\nintegrates an LLM backbone with a progressive spatial awareness scheme that\nprogressively captures spatial information as the perception field expands,\ngenerating location-enriched 3D scene embeddings to serve as visual prompts.\nFurthermore, we introduce two novel tasks: 3D object distance measurement and\n3D layout editing, and construct a 3D instruction dataset, MODEL, to evaluate\nthe model's spatial awareness capabilities. Experimental results demonstrate\nthat Spatial 3D-LLM achieves state-of-the-art performance across a wide range\nof 3D vision-language tasks, revealing the improvements stemmed from our\nprogressive spatial awareness scheme of mining more profound spatial\ninformation. Our code is available at\nhttps://github.com/bjshuyuan/Spatial-3D-LLM.",
      "pdf_url": "http://arxiv.org/pdf/2507.16524v1",
      "published": "2025-07-22T12:32:35+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.16524v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "The Ever-Evolving Science Exam",
      "authors": [
        "Junying Wang",
        "Zicheng Zhang",
        "Yijin Guo",
        "Farong Wen",
        "Ye Shen",
        "Yingji Liang",
        "Yalun Wu",
        "Wenzhe Li",
        "Chunyi Li",
        "Zijian Chen",
        "Qi Jia",
        "Guangtao Zhai"
      ],
      "abstract": "As foundation models grow rapidly in capability and deployment, evaluating\ntheir scientific understanding becomes increasingly critical. Existing science\nbenchmarks have made progress towards broad **Range**, wide **Reach**, and high\n**Rigor**, yet they often face two major challenges: **data leakage risks**\nthat compromise benchmarking validity, and **evaluation inefficiency** due to\nlarge-scale testing. To address these issues, we introduce the **Ever-Evolving\nScience Exam (EESE)**, a dynamic benchmark designed to reliably assess\nscientific capabilities in foundation models. Our approach consists of two\ncomponents: 1) a non-public **EESE-Pool** with over 100K expertly constructed\nscience instances (question-answer pairs) across 5 disciplines and 500+\nsubfields, built through a multi-stage pipeline ensuring **Range**, **Reach**,\nand **Rigor**, 2) a periodically updated 500-instance subset **EESE**, sampled\nand validated to enable leakage-resilient, low-overhead evaluations.\nExperiments on 32 open- and closed-source models demonstrate that EESE\neffectively differentiates the strengths and weaknesses of models in scientific\nfields and cognitive dimensions. Overall, EESE provides a robust, scalable, and\nforward-compatible solution for science benchmark design, offering a realistic\nmeasure of how well foundation models handle science questions. The project\npage is at: https://github.com/aiben-ch/EESE.",
      "pdf_url": "http://arxiv.org/pdf/2507.16514v1",
      "published": "2025-07-22T12:22:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.16514v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Analogy making as amortised model construction",
      "authors": [
        "David G. Nagy",
        "Tingke Shen",
        "Hanqi Zhou",
        "Charley M. Wu",
        "Peter Dayan"
      ],
      "abstract": "Humans flexibly construct internal models to navigate novel situations. To be\nuseful, these internal models must be sufficiently faithful to the environment\nthat resource-limited planning leads to adequate outcomes; equally, they must\nbe tractable to construct in the first place. We argue that analogy plays a\ncentral role in these processes, enabling agents to reuse solution-relevant\nstructure from past experiences and amortise the computational costs of both\nmodel construction (construal) and planning. Formalising analogies as partial\nhomomorphisms between Markov decision processes, we sketch a framework in which\nabstract modules, derived from previous construals, serve as composable\nbuilding blocks for new ones. This modular reuse allows for flexible adaptation\nof policies and representations across domains with shared structural essence.",
      "pdf_url": "http://arxiv.org/pdf/2507.16511v1",
      "published": "2025-07-22T12:16:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.16511v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Agentic RAG with Knowledge Graphs for Complex Multi-Hop Reasoning in Real-World Applications",
      "authors": [
        "Jean Lelong",
        "Adnane Errazine",
        "Annabelle Blangero"
      ],
      "abstract": "Conventional Retrieval-Augmented Generation (RAG) systems enhance Large\nLanguage Models (LLMs) but often fall short on complex queries, delivering\nlimited, extractive answers and struggling with multiple targeted retrievals or\nnavigating intricate entity relationships. This is a critical gap in\nknowledge-intensive domains. We introduce INRAExplorer, an agentic RAG system\nfor exploring the scientific data of INRAE (France's National Research\nInstitute for Agriculture, Food and Environment). INRAExplorer employs an\nLLM-based agent with a multi-tool architecture to dynamically engage a rich\nknowledge base, through a comprehensive knowledge graph derived from open\naccess INRAE publications. This design empowers INRAExplorer to conduct\niterative, targeted queries, retrieve exhaustive datasets (e.g., all\npublications by an author), perform multi-hop reasoning, and deliver\nstructured, comprehensive answers. INRAExplorer serves as a concrete\nillustration of enhancing knowledge interaction in specialized fields.",
      "pdf_url": "http://arxiv.org/pdf/2507.16507v1",
      "published": "2025-07-22T12:03:10+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.16507v1",
      "categories": [
        "cs.AI",
        "cs.IR"
      ]
    },
    {
      "title": "ICR Probe: Tracking Hidden State Dynamics for Reliable Hallucination Detection in LLMs",
      "authors": [
        "Zhenliang Zhang",
        "Xinyu Hu",
        "Huixuan Zhang",
        "Junzhe Zhang",
        "Xiaojun Wan"
      ],
      "abstract": "Large language models (LLMs) excel at various natural language processing\ntasks, but their tendency to generate hallucinations undermines their\nreliability. Existing hallucination detection methods leveraging hidden states\npredominantly focus on static and isolated representations, overlooking their\ndynamic evolution across layers, which limits efficacy. To address this\nlimitation, we shift the focus to the hidden state update process and introduce\na novel metric, the ICR Score (Information Contribution to Residual Stream),\nwhich quantifies the contribution of modules to the hidden states' update. We\nempirically validate that the ICR Score is effective and reliable in\ndistinguishing hallucinations. Building on these insights, we propose a\nhallucination detection method, the ICR Probe, which captures the cross-layer\nevolution of hidden states. Experimental results show that the ICR Probe\nachieves superior performance with significantly fewer parameters. Furthermore,\nablation studies and case analyses offer deeper insights into the underlying\nmechanism of this method, improving its interpretability.",
      "pdf_url": "http://arxiv.org/pdf/2507.16488v1",
      "published": "2025-07-22T11:44:26+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.16488v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Designing for Difference: How Human Characteristics Shape Perceptions of Collaborative Robots",
      "authors": [
        "Sabrina Livanec",
        "Laura Londoño",
        "Michael Gorki",
        "Adrian Röfer",
        "Abhinav Valada",
        "Andrea Kiesel"
      ],
      "abstract": "The development of assistive robots for social collaboration raises critical\nquestions about responsible and inclusive design, especially when interacting\nwith individuals from protected groups such as those with disabilities or\nadvanced age. Currently, research is scarce on how participants assess varying\nrobot behaviors in combination with diverse human needs, likely since\nparticipants have limited real-world experience with advanced domestic robots.\nIn the current study, we aim to address this gap while using methods that\nenable participants to assess robot behavior, as well as methods that support\nmeaningful reflection despite limited experience. In an online study, 112\nparticipants (from both experimental and control groups) evaluated 7 videos\nfrom a total of 28 variations of human-robot collaboration types. The\nexperimental group first completed a cognitive-affective mapping (CAM) exercise\non human-robot collaboration before providing their ratings. Although CAM\nreflection did not significantly affect overall ratings, it led to more\npronounced assessments for certain combinations of robot behavior and human\ncondition. Most importantly, the type of human-robot collaboration influences\nthe assessment. Antisocial robot behavior was consistently rated as the lowest,\nwhile collaboration with aged individuals elicited more sensitive evaluations.\nScenarios involving object handovers were viewed more positively than those\nwithout them. These findings suggest that both human characteristics and\ninteraction paradigms influence the perceived acceptability of collaborative\nrobots, underscoring the importance of prosocial design. They also highlight\nthe potential of reflective methods, such as CAM, to elicit nuanced feedback,\nsupporting the development of user-centered and socially responsible robotic\nsystems tailored to diverse populations.",
      "pdf_url": "http://arxiv.org/pdf/2507.16480v1",
      "published": "2025-07-22T11:36:08+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.16480v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.ET",
        "cs.SY",
        "eess.SY"
      ]
    },
    {
      "title": "ACT: Bridging the Gap in Code Translation through Synthetic Data Generation & Adaptive Training",
      "authors": [
        "Shreya Saxena",
        "Siva Prasad",
        "Zishan Ahmad",
        "Vishal Vaddina"
      ],
      "abstract": "Code translation is a crucial process in software development and migration\nprojects, enabling interoperability between different programming languages and\nenhancing software adaptability and thus longevity. Traditional automated\ntranslation methods rely heavily on handcrafted transformation rules, which\noften lack flexibility and scalability. Meanwhile, advanced language models\npresent promising alternatives but are often limited by proprietary, API-based\nimplementations that raise concerns over data security and reliance. In this\npaper, we present Auto-Train for Code Translation (ACT), an innovative\nframework that aims to improve code translation capabilities by enabling\nin-house finetuning of open-source Large Language Models (LLMs). ACT's\nautomated pipeline significantly boosts the performance of these models,\nnarrowing the gap between open-source accessibility and the high performance of\nclosed-source solutions. Central to ACT is its synthetic data generation\nmodule, which builds extensive, high-quality datasets from initial code\nsamples, incorporating unit tests to ensure functional accuracy and diversity.\nACT's evaluation framework incorporates execution-level checks, offering a\ncomprehensive assessment of translation quality. A key feature in ACT is its\ncontroller module, which manages the entire pipeline by dynamically adjusting\nhyperparameters, orchestrating iterative data generation, and finetuning based\non real-time evaluations. This enables ACT to intelligently optimize when to\ncontinue training, generate additional targeted training data, or stop the\nprocess. Our results demonstrate that ACT consistently enhances the\neffectiveness of open-source models, offering businesses and developers a\nsecure and reliable alternative. Additionally, applying our data generation\npipeline to industry-scale migration projects has led to a notable increase in\ndeveloper acceleration.",
      "pdf_url": "http://arxiv.org/pdf/2507.16478v1",
      "published": "2025-07-22T11:35:35+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.16478v1",
      "categories": [
        "cs.AI",
        "cs.SE"
      ]
    },
    {
      "title": "Learning Temporal Abstractions via Variational Homomorphisms in Option-Induced Abstract MDPs",
      "authors": [
        "Chang Li",
        "Yaren Zhang",
        "Haoran Lv",
        "Qiong Cao",
        "Chao Xue",
        "Xiaodong He"
      ],
      "abstract": "Large Language Models (LLMs) have shown remarkable reasoning ability through\nexplicit Chain-of-Thought (CoT) prompting, but generating these step-by-step\ntextual explanations is computationally expensive and slow. To overcome this,\nwe aim to develop a framework for efficient, implicit reasoning, where the\nmodel \"thinks\" in a latent space without generating explicit text for every\nstep. We propose that these latent thoughts can be modeled as\ntemporally-extended abstract actions, or options, within a hierarchical\nreinforcement learning framework. To effectively learn a diverse library of\noptions as latent embeddings, we first introduce the Variational Markovian\nOption Critic (VMOC), an off-policy algorithm that uses variational inference\nwithin the HiT-MDP framework. To provide a rigorous foundation for using these\noptions as an abstract reasoning space, we extend the theory of continuous MDP\nhomomorphisms. This proves that learning a policy in the simplified, abstract\nlatent space, for which VMOC is suited, preserves the optimality of the\nsolution to the original, complex problem. Finally, we propose a cold-start\nprocedure that leverages supervised fine-tuning (SFT) data to distill human\nreasoning demonstrations into this latent option space, providing a rich\ninitialization for the model's reasoning capabilities. Extensive experiments\ndemonstrate that our approach achieves strong performance on complex logical\nreasoning benchmarks and challenging locomotion tasks, validating our framework\nas a principled method for learning abstract skills for both language and\ncontrol.",
      "pdf_url": "http://arxiv.org/pdf/2507.16473v1",
      "published": "2025-07-22T11:22:58+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.16473v1",
      "categories": [
        "cs.AI",
        "I.2.7"
      ]
    },
    {
      "title": "Estimating Treatment Effects with Independent Component Analysis",
      "authors": [
        "Patrik Reizinger",
        "Lester Mackey",
        "Wieland Brendel",
        "Rahul Krishnan"
      ],
      "abstract": "The field of causal inference has developed a variety of methods to\naccurately estimate treatment effects in the presence of nuisance. Meanwhile,\nthe field of identifiability theory has developed methods like Independent\nComponent Analysis (ICA) to identify latent sources and mixing weights from\ndata. While these two research communities have developed largely\nindependently, they aim to achieve similar goals: the accurate and\nsample-efficient estimation of model parameters. In the partially linear\nregression (PLR) setting, Mackey et al. (2018) recently found that estimation\nconsistency can be improved with non-Gaussian treatment noise. Non-Gaussianity\nis also a crucial assumption for identifying latent factors in ICA. We provide\nthe first theoretical and empirical insights into this connection, showing that\nICA can be used for causal effect estimation in the PLR model. Surprisingly, we\nfind that linear ICA can accurately estimate multiple treatment effects even in\nthe presence of Gaussian confounders or nonlinear nuisance.",
      "pdf_url": "http://arxiv.org/pdf/2507.16467v1",
      "published": "2025-07-22T11:16:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.16467v1",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Improving ASP-based ORS Schedules through Machine Learning Predictions",
      "authors": [
        "Pierangela Bruno",
        "Carmine Dodaro",
        "Giuseppe Galatà",
        "Marco Maratea",
        "Marco Mochi"
      ],
      "abstract": "The Operating Room Scheduling (ORS) problem deals with the optimization of\ndaily operating room surgery schedules. It is a challenging problem subject to\nmany constraints, like to determine the starting time of different surgeries\nand allocating the required resources, including the availability of beds in\ndifferent department units. Recently, solutions to this problem based on Answer\nSet Programming (ASP) have been delivered. Such solutions are overall\nsatisfying but, when applied to real data, they can currently only verify\nwhether the encoding aligns with the actual data and, at most, suggest\nalternative schedules that could have been computed. As a consequence, it is\nnot currently possible to generate provisional schedules. Furthermore, the\nresulting schedules are not always robust.\n  In this paper, we integrate inductive and deductive techniques for solving\nthese issues. We first employ machine learning algorithms to predict the\nsurgery duration, from historical data, to compute provisional schedules. Then,\nwe consider the confidence of such predictions as an additional input to our\nproblem and update the encoding correspondingly in order to compute more robust\nschedules. Results on historical data from the ASL1 Liguria in Italy confirm\nthe viability of our integration.\n  Under consideration in Theory and Practice of Logic Programming (TPLP).",
      "pdf_url": "http://arxiv.org/pdf/2507.16454v1",
      "published": "2025-07-22T10:56:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.16454v1",
      "categories": [
        "cs.AI",
        "cs.LO"
      ]
    },
    {
      "title": "From model-based learning to model-free behaviour with Meta-Interpretive Learning",
      "authors": [
        "Stassa Patsantzis"
      ],
      "abstract": "A \"model\" is a theory that describes the state of an environment and the\neffects of an agent's decisions on the environment. A model-based agent can use\nits model to predict the effects of its future actions and so plan ahead, but\nmust know the state of the environment. A model-free agent cannot plan, but can\nact without a model and without completely observing the environment. An\nautonomous agent capable of acting independently in novel environments must\ncombine both sets of capabilities. We show how to create such an agent with\nMeta-Interpretive Learning used to learn a model-based Solver used to train a\nmodel-free Controller that can solve the same planning problems as the Solver.\nWe demonstrate the equivalence in problem-solving ability of the two agents on\ngrid navigation problems in two kinds of environment: randomly generated mazes,\nand lake maps with wide open areas. We find that all navigation problems solved\nby the Solver are also solved by the Controller, indicating the two are\nequivalent.",
      "pdf_url": "http://arxiv.org/pdf/2507.16434v1",
      "published": "2025-07-22T10:28:08+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.16434v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Beyond Algorethics: Addressing the Ethical and Anthropological Challenges of AI Recommender Systems",
      "authors": [
        "Octavian M. Machidon"
      ],
      "abstract": "In this paper, I examine the ethical and anthropological challenges posed by\nAI-driven recommender systems (RSs), which have become central to shaping\ndigital environments and social interactions. By curating personalized content,\nRSs do not merely reflect user preferences but actively construct individual\nexperiences across social media, entertainment platforms, and e-commerce.\nDespite their ubiquity, the ethical implications of RSs remain insufficiently\nexplored, even as concerns over privacy, autonomy, and mental well-being\nintensify. I argue that existing ethical approaches, including algorethics, the\neffort to embed ethical principles into algorithmic design, are necessary but\nultimately inadequate. RSs inherently reduce human complexity to quantifiable\ndimensions, exploit user vulnerabilities, and prioritize engagement over\nwell-being. Addressing these concerns requires moving beyond purely technical\nsolutions. I propose a comprehensive framework for human-centered RS design,\nintegrating interdisciplinary perspectives, regulatory strategies, and\neducational initiatives to ensure AI systems foster rather than undermine human\nautonomy and societal flourishing.",
      "pdf_url": "http://arxiv.org/pdf/2507.16430v1",
      "published": "2025-07-22T10:22:08+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.16430v1",
      "categories": [
        "cs.CY",
        "cs.AI"
      ]
    },
    {
      "title": "Identifying Pre-training Data in LLMs: A Neuron Activation-Based Detection Framework",
      "authors": [
        "Hongyi Tang",
        "Zhihao Zhu",
        "Yi Yang"
      ],
      "abstract": "The performance of large language models (LLMs) is closely tied to their\ntraining data, which can include copyrighted material or private information,\nraising legal and ethical concerns. Additionally, LLMs face criticism for\ndataset contamination and internalizing biases. To address these issues, the\nPre-Training Data Detection (PDD) task was proposed to identify if specific\ndata was included in an LLM's pre-training corpus. However, existing PDD\nmethods often rely on superficial features like prediction confidence and loss,\nresulting in mediocre performance. To improve this, we introduce NA-PDD, a\nnovel algorithm analyzing differential neuron activation patterns between\ntraining and non-training data in LLMs. This is based on the observation that\nthese data types activate different neurons during LLM inference. We also\nintroduce CCNewsPDD, a temporally unbiased benchmark employing rigorous data\ntransformations to ensure consistent time distributions between training and\nnon-training data. Our experiments demonstrate that NA-PDD significantly\noutperforms existing methods across three benchmarks and multiple LLMs.",
      "pdf_url": "http://arxiv.org/pdf/2507.16414v1",
      "published": "2025-07-22T10:05:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.16414v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Self-Supervised Inductive Logic Programming",
      "authors": [
        "Stassa Patsantzis"
      ],
      "abstract": "Inductive Logic Programming (ILP) approaches like Meta \\-/ Interpretive\nLearning (MIL) can learn, from few examples, recursive logic programs with\ninvented predicates that generalise well to unseen instances. This ability\nrelies on a background theory and negative examples, both carefully selected\nwith expert knowledge of a learning problem and its solutions. But what if such\na problem-specific background theory or negative examples are not available? We\nformalise this question as a new setting for Self-Supervised ILP and present a\nnew MIL algorithm that learns in the new setting from some positive labelled,\nand zero or more unlabelled examples, and automatically generates, and labels,\nnew positive and negative examples during learning. We implement this algorithm\nin Prolog in a new MIL system, called Poker. We compare Poker to\nstate-of-the-art MIL system Louise on experiments learning grammars for\nContext-Free and L-System languages from labelled, positive example strings, no\nnegative examples, and just the terminal vocabulary of a language, seen in\nexamples, as a first-order background theory. We introduce a new approach for\nthe principled selection of a second-order background theory as a Second Order\nDefinite Normal Form (SONF), sufficiently general to learn all programs in a\nclass, thus removing the need for a backgound theory tailored to a learning\ntask. We find that Poker's performance improves with increasing numbers of\nautomatically generated examples while Louise, bereft of negative examples,\nover-generalises.",
      "pdf_url": "http://arxiv.org/pdf/2507.16405v1",
      "published": "2025-07-22T09:57:24+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.16405v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    }
  ]
}