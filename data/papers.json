{
  "last_updated": "2025-03-26T00:47:02.853535",
  "papers": [
    {
      "title": "Aether: Geometric-Aware Unified World Modeling",
      "authors": [
        "Aether Team",
        "Haoyi Zhu",
        "Yifan Wang",
        "Jianjun Zhou",
        "Wenzheng Chang",
        "Yang Zhou",
        "Zizun Li",
        "Junyi Chen",
        "Chunhua Shen",
        "Jiangmiao Pang",
        "Tong He"
      ],
      "abstract": "The integration of geometric reconstruction and generative modeling remains a\ncritical challenge in developing AI systems capable of human-like spatial\nreasoning. This paper proposes Aether, a unified framework that enables\ngeometry-aware reasoning in world models by jointly optimizing three core\ncapabilities: (1) 4D dynamic reconstruction, (2) action-conditioned video\nprediction, and (3) goal-conditioned visual planning. Through task-interleaved\nfeature learning, Aether achieves synergistic knowledge sharing across\nreconstruction, prediction, and planning objectives. Building upon video\ngeneration models, our framework demonstrates unprecedented synthetic-to-real\ngeneralization despite never observing real-world data during training.\nFurthermore, our approach achieves zero-shot generalization in both action\nfollowing and reconstruction tasks, thanks to its intrinsic geometric modeling.\nRemarkably, even without real-world data, its reconstruction performance far\nexceeds that of domain-specific models. Additionally, Aether leverages a\ngeometry-informed action space to seamlessly translate predictions into\nactions, enabling effective autonomous trajectory planning. We hope our work\ninspires the community to explore new frontiers in physically-reasonable world\nmodeling and its applications.",
      "pdf_url": "http://arxiv.org/pdf/2503.18945v1",
      "published": "2025-03-24T17:59:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.18945v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ]
    },
    {
      "title": "Video-T1: Test-Time Scaling for Video Generation",
      "authors": [
        "Fangfu Liu",
        "Hanyang Wang",
        "Yimo Cai",
        "Kaiyan Zhang",
        "Xiaohang Zhan",
        "Yueqi Duan"
      ],
      "abstract": "With the scale capability of increasing training data, model size, and\ncomputational cost, video generation has achieved impressive results in digital\ncreation, enabling users to express creativity across various domains.\nRecently, researchers in Large Language Models (LLMs) have expanded the scaling\nto test-time, which can significantly improve LLM performance by using more\ninference-time computation. Instead of scaling up video foundation models\nthrough expensive training costs, we explore the power of Test-Time Scaling\n(TTS) in video generation, aiming to answer the question: if a video generation\nmodel is allowed to use non-trivial amount of inference-time compute, how much\ncan it improve generation quality given a challenging text prompt. In this\nwork, we reinterpret the test-time scaling of video generation as a searching\nproblem to sample better trajectories from Gaussian noise space to the target\nvideo distribution. Specifically, we build the search space with test-time\nverifiers to provide feedback and heuristic algorithms to guide searching\nprocess. Given a text prompt, we first explore an intuitive linear search\nstrategy by increasing noise candidates at inference time. As full-step\ndenoising all frames simultaneously requires heavy test-time computation costs,\nwe further design a more efficient TTS method for video generation called\nTree-of-Frames (ToF) that adaptively expands and prunes video branches in an\nautoregressive manner. Extensive experiments on text-conditioned video\ngeneration benchmarks demonstrate that increasing test-time compute\nconsistently leads to significant improvements in the quality of videos.\nProject page: https://liuff19.github.io/Video-T1",
      "pdf_url": "http://arxiv.org/pdf/2503.18942v1",
      "published": "2025-03-24T17:59:04+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.18942v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "AdaWorld: Learning Adaptable World Models with Latent Actions",
      "authors": [
        "Shenyuan Gao",
        "Siyuan Zhou",
        "Yilun Du",
        "Jun Zhang",
        "Chuang Gan"
      ],
      "abstract": "World models aim to learn action-controlled prediction models and have proven\nessential for the development of intelligent agents. However, most existing\nworld models rely heavily on substantial action-labeled data and costly\ntraining, making it challenging to adapt to novel environments with\nheterogeneous actions through limited interactions. This limitation can hinder\ntheir applicability across broader domains. To overcome this challenge, we\npropose AdaWorld, an innovative world model learning approach that enables\nefficient adaptation. The key idea is to incorporate action information during\nthe pretraining of world models. This is achieved by extracting latent actions\nfrom videos in a self-supervised manner, capturing the most critical\ntransitions between frames. We then develop an autoregressive world model that\nconditions on these latent actions. This learning paradigm enables highly\nadaptable world models, facilitating efficient transfer and learning of new\nactions even with limited interactions and finetuning. Our comprehensive\nexperiments across multiple environments demonstrate that AdaWorld achieves\nsuperior performance in both simulation quality and visual planning.",
      "pdf_url": "http://arxiv.org/pdf/2503.18938v1",
      "published": "2025-03-24T17:58:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.18938v1",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.RO"
      ]
    },
    {
      "title": "Statistical Proof of Execution (SPEX)",
      "authors": [
        "Michele Dallachiesa",
        "Antonio Pitasi",
        "David Pinger",
        "Josh Goodbody",
        "Luis Vaello"
      ],
      "abstract": "Many real-world applications are increasingly incorporating automated\ndecision-making, driven by the widespread adoption of ML/AI inference for\nplanning and guidance. This study examines the growing need for verifiable\ncomputing in autonomous decision-making. We formalize the problem of verifiable\ncomputing and introduce a sampling-based protocol that is significantly faster,\nmore cost-effective, and simpler than existing methods. Furthermore, we tackle\nthe challenges posed by non-determinism, proposing a set of strategies to\neffectively manage common scenarios.",
      "pdf_url": "http://arxiv.org/pdf/2503.18899v1",
      "published": "2025-03-24T17:13:25+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.18899v1",
      "categories": [
        "cs.AI",
        "cs.CR"
      ]
    },
    {
      "title": "SimpleRL-Zoo: Investigating and Taming Zero Reinforcement Learning for Open Base Models in the Wild",
      "authors": [
        "Weihao Zeng",
        "Yuzhen Huang",
        "Qian Liu",
        "Wei Liu",
        "Keqing He",
        "Zejun Ma",
        "Junxian He"
      ],
      "abstract": "DeepSeek-R1 has shown that long chain-of-thought (CoT) reasoning can\nnaturally emerge through a simple reinforcement learning (RL) framework with\nrule-based rewards, where the training may directly start from the base\nmodels-a paradigm referred to as zero RL training. Most recent efforts to\nreproduce zero RL training have primarily focused on the Qwen2.5 model series,\nwhich may not be representative as we find the base models already exhibit\nstrong instruction-following and self-reflection abilities. In this work, we\ninvestigate zero RL training across 10 diverse base models, spanning different\nfamilies and sizes including LLama3-8B, Mistral-7B/24B, DeepSeek-Math-7B,\nQwen2.5-math-7B, and all Qwen2.5 models from 0.5B to 32B. Leveraging several\nkey design strategies-such as adjusting format reward and controlling query\ndifficulty-we achieve substantial improvements in both reasoning accuracy and\nresponse length across most settings. However, by carefully monitoring the\ntraining dynamics, we observe that different base models exhibit distinct\npatterns during training. For instance, the increased response length does not\nalways correlate with the emergence of certain cognitive behaviors such as\nverification (i.e., the \"aha moment\"). Notably, we observe the \"aha moment\" for\nthe first time in small models not from the Qwen family. We share the key\ndesigns that enable successful zero RL training, along with our findings and\npractices. To facilitate further research, we open-source the code, models, and\nanalysis tools.",
      "pdf_url": "http://arxiv.org/pdf/2503.18892v1",
      "published": "2025-03-24T17:06:10+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.18892v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "AgentDropout: Dynamic Agent Elimination for Token-Efficient and High-Performance LLM-Based Multi-Agent Collaboration",
      "authors": [
        "Zhexuan Wang",
        "Yutong Wang",
        "Xuebo Liu",
        "Liang Ding",
        "Miao Zhang",
        "Jie Liu",
        "Min Zhang"
      ],
      "abstract": "Multi-agent systems (MAS) based on large language models (LLMs) have\ndemonstrated significant potential in collaborative problem-solving. However,\nthey still face substantial challenges of low communication efficiency and\nsuboptimal task performance, making the careful design of the agents'\ncommunication topologies particularly important. Inspired by the management\ntheory that roles in an efficient team are often dynamically adjusted, we\npropose AgentDropout, which identifies redundant agents and communication\nacross different communication rounds by optimizing the adjacency matrices of\nthe communication graphs and eliminates them to enhance both token efficiency\nand task performance. Compared to state-of-the-art methods, AgentDropout\nachieves an average reduction of 21.6% in prompt token consumption and 18.4% in\ncompletion token consumption, along with a performance improvement of 1.14 on\nthe tasks. Furthermore, the extended experiments demonstrate that AgentDropout\nachieves notable domain transferability and structure robustness, revealing its\nreliability and effectiveness. We release our code at\nhttps://github.com/wangzx1219/AgentDropout.",
      "pdf_url": "http://arxiv.org/pdf/2503.18891v1",
      "published": "2025-03-24T17:04:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.18891v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Bootstrapped Model Predictive Control",
      "authors": [
        "Yuhang Wang",
        "Hanwei Guo",
        "Sizhe Wang",
        "Long Qian",
        "Xuguang Lan"
      ],
      "abstract": "Model Predictive Control (MPC) has been demonstrated to be effective in\ncontinuous control tasks. When a world model and a value function are\navailable, planning a sequence of actions ahead of time leads to a better\npolicy. Existing methods typically obtain the value function and the\ncorresponding policy in a model-free manner. However, we find that such an\napproach struggles with complex tasks, resulting in poor policy learning and\ninaccurate value estimation. To address this problem, we leverage the strengths\nof MPC itself. In this work, we introduce Bootstrapped Model Predictive Control\n(BMPC), a novel algorithm that performs policy learning in a bootstrapped\nmanner. BMPC learns a network policy by imitating an MPC expert, and in turn,\nuses this policy to guide the MPC process. Combined with model-based\nTD-learning, our policy learning yields better value estimation and further\nboosts the efficiency of MPC. We also introduce a lazy reanalyze mechanism,\nwhich enables computationally efficient imitation learning. Our method achieves\nsuperior performance over prior works on diverse continuous control tasks. In\nparticular, on challenging high-dimensional locomotion tasks, BMPC\nsignificantly improves data efficiency while also enhancing asymptotic\nperformance and training stability, with comparable training time and smaller\nnetwork sizes. Code is available at https://github.com/wertyuilife2/bmpc.",
      "pdf_url": "http://arxiv.org/pdf/2503.18871v1",
      "published": "2025-03-24T16:46:36+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.18871v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ]
    },
    {
      "title": "Reasoning to Learn from Latent Thoughts",
      "authors": [
        "Yangjun Ruan",
        "Neil Band",
        "Chris J. Maddison",
        "Tatsunori Hashimoto"
      ],
      "abstract": "Compute scaling for language model (LM) pretraining has outpaced the growth\nof human-written texts, leading to concerns that data will become the\nbottleneck to LM scaling. To continue scaling pretraining in this\ndata-constrained regime, we propose that explicitly modeling and inferring the\nlatent thoughts that underlie the text generation process can significantly\nimprove pretraining data efficiency. Intuitively, our approach views web text\nas the compressed final outcome of a verbose human thought process and that the\nlatent thoughts contain important contextual knowledge and reasoning steps that\nare critical to data-efficient learning. We empirically demonstrate the\neffectiveness of our approach through data-constrained continued pretraining\nfor math. We first show that synthetic data approaches to inferring latent\nthoughts significantly improve data efficiency, outperforming training on the\nsame amount of raw data (5.7\\% $\\rightarrow$ 25.4\\% on MATH). Furthermore, we\ndemonstrate latent thought inference without a strong teacher, where an LM\nbootstraps its own performance by using an EM algorithm to iteratively improve\nthe capability of the trained LM and the quality of thought-augmented\npretraining data. We show that a 1B LM can bootstrap its performance across at\nleast three iterations and significantly outperform baselines trained on raw\ndata, with increasing gains from additional inference compute when performing\nthe E-step. The gains from inference scaling and EM iterations suggest new\nopportunities for scaling data-constrained pretraining.",
      "pdf_url": "http://arxiv.org/pdf/2503.18866v1",
      "published": "2025-03-24T16:41:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.18866v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Structuring Scientific Innovation: A Framework for Modeling and Discovering Impactful Knowledge Combinations",
      "authors": [
        "Junlan Chen",
        "Kexin Zhang",
        "Daifeng Li",
        "Yangyang Feng",
        "Yuxuan Zhang",
        "Bowen Deng"
      ],
      "abstract": "The emergence of large language models offers new possibilities for\nstructured exploration of scientific knowledge. Rather than viewing scientific\ndiscovery as isolated ideas or content, we propose a structured approach that\nemphasizes the role of method combinations in shaping disruptive insights.\nSpecifically, we investigate how knowledge unit--especially those tied to\nmethodological design--can be modeled and recombined to yield research\nbreakthroughs.Our proposed framework addresses two key challenges. First, we\nintroduce a contrastive learning-based mechanism to identify distinguishing\nfeatures of historically disruptive method combinations within problem-driven\ncontexts.Second, we propose a reasoning-guided Monte Carlo search algorithm\nthat leverages the chain-of-thought capability of LLMs to identify promising\nknowledge recombinations for new problem statements.Empirical studies across\nmultiple domains show that the framework is capable of modeling the structural\ndynamics of innovation and successfully highlights combinations with high\ndisruptive potential.This research provides a new path for computationally\nguided scientific ideation grounded in structured reasoning and historical data\nmodeling.",
      "pdf_url": "http://arxiv.org/pdf/2503.18865v1",
      "published": "2025-03-24T16:41:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.18865v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Exploring the Integration of Key-Value Attention Into Pure and Hybrid Transformers for Semantic Segmentation",
      "authors": [
        "DeShin Hwa",
        "Tobias Holmes",
        "Klaus Drechsler"
      ],
      "abstract": "While CNNs were long considered state of the art for image processing, the\nintroduction of Transformer architectures has challenged this position. While\nachieving excellent results in image classification and segmentation,\nTransformers remain inherently reliant on large training datasets and remain\ncomputationally expensive. A newly introduced Transformer derivative named KV\nTransformer shows promising results in synthetic, NLP, and image classification\ntasks, while reducing complexity and memory usage. This is especially conducive\nto use cases where local inference is required, such as medical screening\napplications. We endeavoured to further evaluate the merit of KV Transformers\non semantic segmentation tasks, specifically in the domain of medical imaging.\nBy directly comparing traditional and KV variants of the same base\narchitectures, we provide further insight into the practical tradeoffs of\nreduced model complexity. We observe a notable reduction in parameter count and\nmultiply accumulate operations, while achieving similar performance from most\nof the KV variant models when directly compared to their QKV implementation.",
      "pdf_url": "http://arxiv.org/pdf/2503.18862v1",
      "published": "2025-03-24T16:38:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.18862v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "MC-LLaVA: Multi-Concept Personalized Vision-Language Model",
      "authors": [
        "Ruichuan An",
        "Sihan Yang",
        "Ming Lu",
        "Renrui Zhang",
        "Kai Zeng",
        "Yulin Luo",
        "Jiajun Cao",
        "Hao Liang",
        "Ying Chen",
        "Qi She",
        "Shanghang Zhang",
        "Wentao Zhang"
      ],
      "abstract": "Current vision-language models (VLMs) show exceptional abilities across\ndiverse tasks, such as visual question answering. To enhance user experience,\nrecent studies investigate VLM personalization to understand user-provided\nconcepts. However, they mainly focus on single-concept personalization,\nneglecting the existence and interplay of multiple concepts, which limits\nreal-world applicability. This paper proposes the first multi-concept\npersonalization paradigm, MC-LLaVA. Specifically, MC-LLaVA employs a\nmulti-concept instruction tuning strategy, effectively integrating multiple\nconcepts in a single training step. To reduce the costs related to joint\ntraining, we propose a personalized textual prompt that uses visual token\ninformation to initialize concept tokens. Additionally, we introduce a\npersonalized visual prompt during inference, aggregating location confidence\nmaps for enhanced recognition and grounding capabilities. To advance\nmulti-concept personalization research, we further contribute a high-quality\ninstruction tuning dataset. We carefully collect images with multiple\ncharacters and objects from movies and manually generate question-answer\nsamples for multi-concept scenarios, featuring superior diversity.\nComprehensive qualitative and quantitative experiments demonstrate that\nMC-LLaVA can achieve impressive multi-concept personalized responses, paving\nthe way for VLMs to become better user-specific assistants. The code and\ndataset will be publicly available at\n$\\href{https://github.com/arctanxarc/MC-LLaVA}{https://github.com/arctanxarc/MC-LLaVA}$.",
      "pdf_url": "http://arxiv.org/pdf/2503.18854v1",
      "published": "2025-03-24T16:32:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.18854v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Self-Organizing Graph Reasoning Evolves into a Critical State for Continuous Discovery Through Structural-Semantic Dynamics",
      "authors": [
        "Markus J. Buehler"
      ],
      "abstract": "We report fundamental insights into how agentic graph reasoning systems\nspontaneously evolve toward a critical state that sustains continuous semantic\ndiscovery. By rigorously analyzing structural (Von Neumann graph entropy) and\nsemantic (embedding) entropy, we identify a subtle yet robust regime in which\nsemantic entropy persistently dominates over structural entropy. This interplay\nis quantified by a dimensionless Critical Discovery Parameter that stabilizes\nat a small negative value, indicating a consistent excess of semantic entropy.\nEmpirically, we observe a stable fraction (12%) of \"surprising\" edges, links\nbetween semantically distant concepts, providing evidence of long-range or\ncross-domain connections that drive continuous innovation. Concomitantly, the\nsystem exhibits scale-free and small-world topological features, alongside a\nnegative cross-correlation between structural and semantic measures,\nreinforcing the analogy to self-organized criticality. These results establish\nclear parallels with critical phenomena in physical, biological, and cognitive\ncomplex systems, revealing an entropy-based principle governing adaptability\nand continuous innovation. Crucially, semantic richness emerges as the\nunderlying driver of sustained exploration, despite not being explicitly used\nby the reasoning process. Our findings provide interdisciplinary insights and\npractical strategies for engineering intelligent systems with intrinsic\ncapacities for long-term discovery and adaptation, and offer insights into how\nmodel training strategies can be developed that reinforce critical discovery.",
      "pdf_url": "http://arxiv.org/pdf/2503.18852v1",
      "published": "2025-03-24T16:30:37+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.18852v1",
      "categories": [
        "cs.AI",
        "cond-mat.mes-hall",
        "cs.LG",
        "nlin.AO",
        "physics.app-ph"
      ]
    },
    {
      "title": "Three Kinds of AI Ethics",
      "authors": [
        "Emanuele Ratti"
      ],
      "abstract": "There is an overwhelmingly abundance of works in AI Ethics. This growth is\nchaotic because of how sudden it is, its volume, and its multidisciplinary\nnature. This makes difficult to keep track of debates, and to systematically\ncharacterize goals, research questions, methods, and expertise required by AI\nethicists. In this article, I show that the relation between AI and ethics can\nbe characterized in at least three ways, which correspond to three\nwell-represented kinds of AI ethics: ethics and AI; ethics in AI; ethics of AI.\nI elucidate the features of these three kinds of AI Ethics, characterize their\nresearch questions, and identify the kind of expertise that each kind needs. I\nalso show how certain criticisms to AI ethics are misplaced, as being done from\nthe point of view of one kind of AI ethics, to another kind with different\ngoals. All in all, this work sheds light on the nature of AI ethics, and set\nthe grounds for more informed discussions about scope, methods, and trainings\nof AI ethicists.",
      "pdf_url": "http://arxiv.org/pdf/2503.18842v1",
      "published": "2025-03-24T16:15:03+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.18842v1",
      "categories": [
        "cs.CY",
        "cs.AI"
      ]
    },
    {
      "title": "Dual-domain Multi-path Self-supervised Diffusion Model for Accelerated MRI Reconstruction",
      "authors": [
        "Yuxuan Zhang",
        "Jinkui Hao",
        "Bo Zhou"
      ],
      "abstract": "Magnetic resonance imaging (MRI) is a vital diagnostic tool, but its\ninherently long acquisition times reduce clinical efficiency and patient\ncomfort. Recent advancements in deep learning, particularly diffusion models,\nhave improved accelerated MRI reconstruction. However, existing diffusion\nmodels' training often relies on fully sampled data, models incur high\ncomputational costs, and often lack uncertainty estimation, limiting their\nclinical applicability. To overcome these challenges, we propose a novel\nframework, called Dual-domain Multi-path Self-supervised Diffusion Model\n(DMSM), that integrates a self-supervised dual-domain diffusion model training\nscheme, a lightweight hybrid attention network for the reconstruction diffusion\nmodel, and a multi-path inference strategy, to enhance reconstruction accuracy,\nefficiency, and explainability. Unlike traditional diffusion-based models, DMSM\neliminates the dependency on training from fully sampled data, making it more\npractical for real-world clinical settings. We evaluated DMSM on two human MRI\ndatasets, demonstrating that it achieves favorable performance over several\nsupervised and self-supervised baselines, particularly in preserving fine\nanatomical structures and suppressing artifacts under high acceleration\nfactors. Additionally, our model generates uncertainty maps that correlate\nreasonably well with reconstruction errors, offering valuable clinically\ninterpretable guidance and potentially enhancing diagnostic confidence.",
      "pdf_url": "http://arxiv.org/pdf/2503.18836v1",
      "published": "2025-03-24T16:10:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.18836v1",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Interpretable and Fair Mechanisms for Abstaining Classifiers",
      "authors": [
        "Daphne Lenders",
        "Andrea Pugnana",
        "Roberto Pellungrini",
        "Toon Calders",
        "Dino Pedreschi",
        "Fosca Giannotti"
      ],
      "abstract": "Abstaining classifiers have the option to refrain from providing a prediction\nfor instances that are difficult to classify. The abstention mechanism is\ndesigned to trade off the classifier's performance on the accepted data while\nensuring a minimum number of predictions. In this setting, often fairness\nconcerns arise when the abstention mechanism solely reduces errors for the\nmajority groups of the data, resulting in increased performance differences\nacross demographic groups. While there exist a bunch of methods that aim to\nreduce discrimination when abstaining, there is no mechanism that can do so in\nan explainable way. In this paper, we fill this gap by introducing\nInterpretable and Fair Abstaining Classifier IFAC, an algorithm that can reject\npredictions both based on their uncertainty and their unfairness. By rejecting\npossibly unfair predictions, our method reduces error and positive decision\nrate differences across demographic groups of the non-rejected data. Since the\nunfairness-based rejections are based on an interpretable-by-design method,\ni.e., rule-based fairness checks and situation testing, we create a transparent\nprocess that can empower human decision-makers to review the unfair predictions\nand make more just decisions for them. This explainable aspect is especially\nimportant in light of recent AI regulations, mandating that any high-risk\ndecision task should be overseen by human experts to reduce discrimination\nrisks.",
      "pdf_url": "http://arxiv.org/pdf/2503.18826v1",
      "published": "2025-03-24T16:06:43+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.18826v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "EconEvals: Benchmarks and Litmus Tests for LLM Agents in Unknown Environments",
      "authors": [
        "Sara Fish",
        "Julia Shephard",
        "Minkai Li",
        "Ran I. Shorrer",
        "Yannai A. Gonczarowski"
      ],
      "abstract": "We develop benchmarks for LLM agents that act in, learn from, and strategize\nin unknown environments, the specifications of which the LLM agent must learn\nover time from deliberate exploration. Our benchmarks consist of\ndecision-making tasks derived from key problems in economics. To forestall\nsaturation, the benchmark tasks are synthetically generated with scalable\ndifficulty levels. Additionally, we propose litmus tests, a new kind of\nquantitative measure for LLMs and LLM agents. Unlike benchmarks, litmus tests\nquantify differences in character, values, and tendencies of LLMs and LLM\nagents, by considering their behavior when faced with tradeoffs (e.g.,\nefficiency versus equality) where there is no objectively right or wrong\nbehavior. Overall, our benchmarks and litmus tests assess the abilities and\ntendencies of LLM agents in tackling complex economic problems in diverse\nsettings spanning procurement, scheduling, task allocation, and pricing --\napplications that should grow in importance as such agents are further\nintegrated into the economy.",
      "pdf_url": "http://arxiv.org/pdf/2503.18825v1",
      "published": "2025-03-24T16:06:04+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.18825v1",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.GT"
      ]
    },
    {
      "title": "Enhanced OoD Detection through Cross-Modal Alignment of Multi-Modal Representations",
      "authors": [
        "Jeonghyeon Kim",
        "Sangheum Hwang"
      ],
      "abstract": "Prior research on out-of-distribution detection (OoDD) has primarily focused\non single-modality models. Recently, with the advent of large-scale pretrained\nvision-language models such as CLIP, OoDD methods utilizing such multi-modal\nrepresentations through zero-shot and prompt learning strategies have emerged.\nHowever, these methods typically involve either freezing the pretrained weights\nor only partially tuning them, which can be suboptimal for downstream datasets.\nIn this paper, we highlight that multi-modal fine-tuning (MMFT) can achieve\nnotable OoDD performance. Despite some recent works demonstrating the impact of\nfine-tuning methods for OoDD, there remains significant potential for\nperformance improvement. We investigate the limitation of na\\\"ive fine-tuning\nmethods, examining why they fail to fully leverage the pretrained knowledge.\nOur empirical analysis suggests that this issue could stem from the modality\ngap within in-distribution (ID) embeddings. To address this, we propose a\ntraining objective that enhances cross-modal alignment by regularizing the\ndistances between image and text embeddings of ID data. This adjustment helps\nin better utilizing pretrained textual information by aligning similar\nsemantics from different modalities (i.e., text and image) more closely in the\nhyperspherical representation space. We theoretically demonstrate that the\nproposed regularization corresponds to the maximum likelihood estimation of an\nenergy-based model on a hypersphere. Utilizing ImageNet-1k OoD benchmark\ndatasets, we show that our method, combined with post-hoc OoDD approaches\nleveraging pretrained knowledge (e.g., NegLabel), significantly outperforms\nexisting methods, achieving state-of-the-art OoDD performance and leading ID\naccuracy.",
      "pdf_url": "http://arxiv.org/pdf/2503.18817v1",
      "published": "2025-03-24T16:00:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.18817v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Learning Multi-Robot Coordination through Locality-Based Factorized Multi-Agent Actor-Critic Algorithm",
      "authors": [
        "Chak Lam Shek",
        "Amrit Singh Bedi",
        "Anjon Basak",
        "Ellen Novoseller",
        "Nick Waytowich",
        "Priya Narayanan",
        "Dinesh Manocha",
        "Pratap Tokekar"
      ],
      "abstract": "In this work, we present a novel cooperative multi-agent reinforcement\nlearning method called \\textbf{Loc}ality based \\textbf{Fac}torized\n\\textbf{M}ulti-Agent \\textbf{A}ctor-\\textbf{C}ritic (Loc-FACMAC). Existing\nstate-of-the-art algorithms, such as FACMAC, rely on global reward information,\nwhich may not accurately reflect the quality of individual robots' actions in\ndecentralized systems. We integrate the concept of locality into critic\nlearning, where strongly related robots form partitions during training. Robots\nwithin the same partition have a greater impact on each other, leading to more\nprecise policy evaluation. Additionally, we construct a dependency graph to\ncapture the relationships between robots, facilitating the partitioning\nprocess. This approach mitigates the curse of dimensionality and prevents\nrobots from using irrelevant information. Our method improves existing\nalgorithms by focusing on local rewards and leveraging partition-based learning\nto enhance training efficiency and performance. We evaluate the performance of\nLoc-FACMAC in three environments: Hallway, Multi-cartpole, and\nBounded-Cooperative-Navigation. We explore the impact of partition sizes on the\nperformance and compare the result with baseline MARL algorithms such as LOMAQ,\nFACMAC, and QMIX. The experiments reveal that, if the locality structure is\ndefined properly, Loc-FACMAC outperforms these baseline algorithms up to 108\\%,\nindicating that exploiting the locality structure in the actor-critic framework\nimproves the MARL performance.",
      "pdf_url": "http://arxiv.org/pdf/2503.18816v1",
      "published": "2025-03-24T16:00:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.18816v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "Towards Responsible AI Music: an Investigation of Trustworthy Features for Creative Systems",
      "authors": [
        "Jacopo de Berardinis",
        "Lorenzo Porcaro",
        "Albert Meroño-Peñuela",
        "Angelo Cangelosi",
        "Tess Buckley"
      ],
      "abstract": "Generative AI is radically changing the creative arts, by fundamentally\ntransforming the way we create and interact with cultural artefacts. While\noffering unprecedented opportunities for artistic expression and\ncommercialisation, this technology also raises ethical, societal, and legal\nconcerns. Key among these are the potential displacement of human creativity,\ncopyright infringement stemming from vast training datasets, and the lack of\ntransparency, explainability, and fairness mechanisms. As generative systems\nbecome pervasive in this domain, responsible design is crucial. Whilst previous\nwork has tackled isolated aspects of generative systems (e.g., transparency,\nevaluation, data), we take a comprehensive approach, grounding these efforts\nwithin the Ethics Guidelines for Trustworthy Artificial Intelligence produced\nby the High-Level Expert Group on AI appointed by the European Commission - a\nframework for designing responsible AI systems across seven macro requirements.\nFocusing on generative music AI, we illustrate how these requirements can be\ncontextualised for the field, addressing trustworthiness across multiple\ndimensions and integrating insights from the existing literature. We further\npropose a roadmap for operationalising these contextualised requirements,\nemphasising interdisciplinary collaboration and stakeholder engagement. Our\nwork provides a foundation for designing and evaluating responsible music\ngeneration systems, calling for collaboration among AI experts, ethicists,\nlegal scholars, and artists. This manuscript is accompanied by a website:\nhttps://amresearchlab.github.io/raim-framework/.",
      "pdf_url": "http://arxiv.org/pdf/2503.18814v1",
      "published": "2025-03-24T15:54:47+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.18814v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Defeating Prompt Injections by Design",
      "authors": [
        "Edoardo Debenedetti",
        "Ilia Shumailov",
        "Tianqi Fan",
        "Jamie Hayes",
        "Nicholas Carlini",
        "Daniel Fabian",
        "Christoph Kern",
        "Chongyang Shi",
        "Andreas Terzis",
        "Florian Tramèr"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly deployed in agentic systems\nthat interact with an external environment. However, LLM agents are vulnerable\nto prompt injection attacks when handling untrusted data. In this paper we\npropose CaMeL, a robust defense that creates a protective system layer around\nthe LLM, securing it even when underlying models may be susceptible to attacks.\nTo operate, CaMeL explicitly extracts the control and data flows from the\n(trusted) query; therefore, the untrusted data retrieved by the LLM can never\nimpact the program flow. To further improve security, CaMeL relies on a notion\nof a capability to prevent the exfiltration of private data over unauthorized\ndata flows. We demonstrate effectiveness of CaMeL by solving $67\\%$ of tasks\nwith provable security in AgentDojo [NeurIPS 2024], a recent agentic security\nbenchmark.",
      "pdf_url": "http://arxiv.org/pdf/2503.18813v1",
      "published": "2025-03-24T15:54:10+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.18813v1",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "title": "Classical Planning with LLM-Generated Heuristics: Challenging the State of the Art with Python Code",
      "authors": [
        "Augusto B. Corrêa",
        "André G. Pereira",
        "Jendrik Seipp"
      ],
      "abstract": "In recent years, large language models (LLMs) have shown remarkable\ncapabilities in various artificial intelligence problems. However, they fail to\nplan reliably, even when prompted with a detailed definition of the planning\ntask. Attempts to improve their planning capabilities, such as chain-of-thought\nprompting, fine-tuning, and explicit \"reasoning\" still yield incorrect plans\nand usually fail to generalize to larger tasks. In this paper, we show how to\nuse LLMs to generate correct plans, even for out-of-distribution tasks of\nincreasing size. For a given planning domain, we ask an LLM to generate several\ndomain-dependent heuristic functions in the form of Python code, evaluate them\non a set of training tasks within a greedy best-first search, and choose the\nstrongest one. The resulting LLM-generated heuristics solve many more unseen\ntest tasks than state-of-the-art domain-independent heuristics for classical\nplanning. They are even competitive with the strongest learning algorithm for\ndomain-dependent planning. These findings are especially remarkable given that\nour proof-of-concept implementation is based on an unoptimized Python planner\nand the baselines all build upon highly optimized C++ code. In some domains,\nthe LLM-generated heuristics expand fewer states than the baselines, revealing\nthat they are not only efficiently computable, but sometimes even more\ninformative than the state-of-the-art heuristics. Overall, our results show\nthat sampling a set of planning heuristic function programs can significantly\nimprove the planning capabilities of LLMs.",
      "pdf_url": "http://arxiv.org/pdf/2503.18809v1",
      "published": "2025-03-24T15:50:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.18809v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "REALM: A Dataset of Real-World LLM Use Cases",
      "authors": [
        "Jingwen Cheng",
        "Kshitish Ghate",
        "Wenyue Hua",
        "William Yang Wang",
        "Hong Shen",
        "Fei Fang"
      ],
      "abstract": "Large Language Models, such as the GPT series, have driven significant\nindustrial applications, leading to economic and societal transformations.\nHowever, a comprehensive understanding of their real-world applications remains\nlimited. To address this, we introduce REALM, a dataset of over 94,000 LLM use\ncases collected from Reddit and news articles. REALM captures two key\ndimensions: the diverse applications of LLMs and the demographics of their\nusers. It categorizes LLM applications and explores how users' occupations\nrelate to the types of applications they use. By integrating real-world data,\nREALM offers insights into LLM adoption across different domains, providing a\nfoundation for future research on their evolving societal roles. A dedicated\ndashboard https://realm-e7682.web.app/ presents the data.",
      "pdf_url": "http://arxiv.org/pdf/2503.18792v1",
      "published": "2025-03-24T15:39:25+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.18792v1",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ]
    },
    {
      "title": "Frequency Dynamic Convolution for Dense Image Prediction",
      "authors": [
        "Linwei Chen",
        "Lin Gu",
        "Liang Li",
        "Chenggang Yan",
        "Ying Fu"
      ],
      "abstract": "While Dynamic Convolution (DY-Conv) has shown promising performance by\nenabling adaptive weight selection through multiple parallel weights combined\nwith an attention mechanism, the frequency response of these weights tends to\nexhibit high similarity, resulting in high parameter costs but limited\nadaptability. In this work, we introduce Frequency Dynamic Convolution\n(FDConv), a novel approach that mitigates these limitations by learning a fixed\nparameter budget in the Fourier domain. FDConv divides this budget into\nfrequency-based groups with disjoint Fourier indices, enabling the construction\nof frequency-diverse weights without increasing the parameter cost. To further\nenhance adaptability, we propose Kernel Spatial Modulation (KSM) and Frequency\nBand Modulation (FBM). KSM dynamically adjusts the frequency response of each\nfilter at the spatial level, while FBM decomposes weights into distinct\nfrequency bands in the frequency domain and modulates them dynamically based on\nlocal content. Extensive experiments on object detection, segmentation, and\nclassification validate the effectiveness of FDConv. We demonstrate that when\napplied to ResNet-50, FDConv achieves superior performance with a modest\nincrease of +3.6M parameters, outperforming previous methods that require\nsubstantial increases in parameter budgets (e.g., CondConv +90M, KW +76.5M).\nMoreover, FDConv seamlessly integrates into a variety of architectures,\nincluding ConvNeXt, Swin-Transformer, offering a flexible and efficient\nsolution for modern vision tasks. The code is made publicly available at\nhttps://github.com/Linwei-Chen/FDConv.",
      "pdf_url": "http://arxiv.org/pdf/2503.18783v2",
      "published": "2025-03-24T15:32:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.18783v2",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "The case for delegated AI autonomy for Human AI teaming in healthcare",
      "authors": [
        "Yan Jia",
        "Harriet Evans",
        "Zoe Porter",
        "Simon Graham",
        "John McDermid",
        "Tom Lawton",
        "David Snead",
        "Ibrahim Habli"
      ],
      "abstract": "In this paper we propose an advanced approach to integrating artificial\nintelligence (AI) into healthcare: autonomous decision support. This approach\nallows the AI algorithm to act autonomously for a subset of patient cases\nwhilst serving a supportive role in other subsets of patient cases based on\ndefined delegation criteria. By leveraging the complementary strengths of both\nhumans and AI, it aims to deliver greater overall performance than existing\nhuman-AI teaming models. It ensures safe handling of patient cases and\npotentially reduces clinician review time, whilst being mindful of AI tool\nlimitations. After setting the approach within the context of current human-AI\nteaming models, we outline the delegation criteria and apply them to a specific\nAI-based tool used in histopathology. The potential impact of the approach and\nthe regulatory requirements for its successful implementation are then\ndiscussed.",
      "pdf_url": "http://arxiv.org/pdf/2503.18778v1",
      "published": "2025-03-24T15:26:54+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.18778v1",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ]
    },
    {
      "title": "BitDecoding: Unlocking Tensor Cores for Long-Context LLMs Decoding with Low-Bit KV Cache",
      "authors": [
        "Dayou Du",
        "Shijie Cao",
        "Jianyi Cheng",
        "Ting Cao",
        "Mao Yang"
      ],
      "abstract": "The growing adoption of long-context Large Language Models (LLMs) has\nintroduced significant memory and computational challenges in autoregressive\ndecoding due to the expanding Key-Value (KV) cache. KV cache quantization has\nemerged as a promising solution, with prior work showing that 4-bit or even\n2-bit quantization can maintain model accuracy while reducing memory costs.\nHowever, despite these benefits, preliminary implementations for the low-bit KV\ncache struggle to deliver the expected speedup due to quantization and\ndequantization overheads and the lack of Tensor Cores utilization. In this\nwork, we propose BitDecoding, a GPU-optimized framework that unlocks Tensor\nCores for efficient decoding with low-bit KV cache. Efficiently leveraging\nTensor Cores for low-bit KV cache is challenging due to the dynamic nature of\nKV cache generation at each decoding step. BitDecoding addresses these\nchallenges with a Tensor Cores-Centric BitFusion Scheme that ensures data\nlayout compatibility to enable high utilization of Tensor Cores. Additionally,\nBitDecoding incorporates a warp-efficient parallel decoding kernel and a\nfine-grained asynchronous pipeline, minimizing dequantization overhead and\nimproving computational efficiency. Experiments show that BitDecoding achieves\nup to 7.5x speedup on RTX 4090, 4.8x on A100, and 8.9x on H100, compared to\nFP16 FlashDecoding-v2. It also outperforms the state-of-the-art low-bit KV\ncache implementation (QServe) by up to 4.3x. On LLaMA-3.1-8B with a 128K\nsequence length, BitDecoding reduces single-batch decoding latency by 3x,\ndemonstrating its effectiveness in long-context generation scenarios. The code\nis available at https://github.com/DD-DuDa/BitDecoding.",
      "pdf_url": "http://arxiv.org/pdf/2503.18773v1",
      "published": "2025-03-24T15:22:41+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.18773v1",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.CL",
        "cs.PF"
      ]
    },
    {
      "title": "Mechanistic Interpretability of Fine-Tuned Vision Transformers on Distorted Images: Decoding Attention Head Behavior for Transparent and Trustworthy AI",
      "authors": [
        "Nooshin Bahador"
      ],
      "abstract": "Mechanistic interpretability improves the safety, reliability, and robustness\nof large AI models. This study examined individual attention heads in vision\ntransformers (ViTs) fine tuned on distorted 2D spectrogram images containing\nnon relevant content (axis labels, titles, color bars). By introducing\nextraneous features, the study analyzed how transformer components processed\nunrelated information, using mechanistic interpretability to debug issues and\nreveal insights into transformer architectures. Attention maps assessed head\ncontributions across layers. Heads in early layers (1 to 3) showed minimal task\nimpact with ablation increased MSE loss slightly ({\\mu}=0.11%, {\\sigma}=0.09%),\nindicating focus on less critical low level features. In contrast, deeper heads\n(e.g., layer 6) caused a threefold higher loss increase ({\\mu}=0.34%,\n{\\sigma}=0.02%), demonstrating greater task importance. Intermediate layers (6\nto 11) exhibited monosemantic behavior, attending exclusively to chirp regions.\nSome early heads (1 to 4) were monosemantic but non task relevant (e.g. text\ndetectors, edge or corner detectors). Attention maps distinguished monosemantic\nheads (precise chirp localization) from polysemantic heads (multiple irrelevant\nregions). These findings revealed functional specialization in ViTs, showing\nhow heads processed relevant vs. extraneous information. By decomposing\ntransformers into interpretable components, this work enhanced model\nunderstanding, identified vulnerabilities, and advanced safer, more transparent\nAI.",
      "pdf_url": "http://arxiv.org/pdf/2503.18762v1",
      "published": "2025-03-24T15:11:24+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.18762v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "EgoSurgery-HTS: A Dataset for Egocentric Hand-Tool Segmentation in Open Surgery Videos",
      "authors": [
        "Nathan Darjana",
        "Ryo Fujii",
        "Hideo Saito",
        "Hiroki Kajita"
      ],
      "abstract": "Egocentric open-surgery videos capture rich, fine-grained details essential\nfor accurately modeling surgical procedures and human behavior in the operating\nroom. A detailed, pixel-level understanding of hands and surgical tools is\ncrucial for interpreting a surgeon's actions and intentions. We introduce\nEgoSurgery-HTS, a new dataset with pixel-wise annotations and a benchmark suite\nfor segmenting surgical tools, hands, and interacting tools in egocentric\nopen-surgery videos. Specifically, we provide a labeled dataset for (1) tool\ninstance segmentation of 14 distinct surgical tools, (2) hand instance\nsegmentation, and (3) hand-tool segmentation to label hands and the tools they\nmanipulate. Using EgoSurgery-HTS, we conduct extensive evaluations of\nstate-of-the-art segmentation methods and demonstrate significant improvements\nin the accuracy of hand and hand-tool segmentation in egocentric open-surgery\nvideos compared to existing datasets. The dataset will be released at\nhttps://github.com/Fujiry0/EgoSurgery.",
      "pdf_url": "http://arxiv.org/pdf/2503.18755v1",
      "published": "2025-03-24T15:04:32+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.18755v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Construction Identification and Disambiguation Using BERT: A Case Study of NPN",
      "authors": [
        "Wesley Scivetti",
        "Nathan Schneider"
      ],
      "abstract": "Construction Grammar hypothesizes that knowledge of a language consists\nchiefly of knowledge of form-meaning pairs (''constructions'') that include\nvocabulary, general grammar rules, and even idiosyncratic patterns. Recent work\nhas shown that transformer language models represent at least some\nconstructional patterns, including ones where the construction is rare overall.\nIn this work, we probe BERT's representation of the form and meaning of a minor\nconstruction of English, the NPN (noun-preposition-noun) construction --\nexhibited in such expressions as face to face and day to day -- which is known\nto be polysemous. We construct a benchmark dataset of semantically annotated\ncorpus instances (including distractors that superficially resemble the\nconstruction). With this dataset, we train and evaluate probing classifiers.\nThey achieve decent discrimination of the construction from distractors, as\nwell as sense disambiguation among true instances of the construction,\nrevealing that BERT embeddings carry indications of the construction's\nsemantics. Moreover, artificially permuting the word order of true construction\ninstances causes them to be rejected, indicating sensitivity to matters of\nform. We conclude that BERT does latently encode at least some knowledge of the\nNPN construction going beyond a surface syntactic pattern and lexical cues.",
      "pdf_url": "http://arxiv.org/pdf/2503.18751v1",
      "published": "2025-03-24T14:59:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.18751v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Energy-Efficient Dynamic Training and Inference for GNN-Based Network Modeling",
      "authors": [
        "Chetna Singhal",
        "Yassine Hadjadj-Aoul"
      ],
      "abstract": "Efficient network modeling is essential for resource optimization and network\nplanning in next-generation large-scale complex networks. Traditional\napproaches, such as queuing theory-based modeling and packet-based simulators,\ncan be inefficient due to the assumption made and the computational expense,\nrespectively. To address these challenges, we propose an innovative\nenergy-efficient dynamic orchestration of Graph Neural Networks (GNN) based\nmodel training and inference framework for context-aware network modeling and\npredictions. We have developed a low-complexity solution framework, QAG, that\nis a Quantum approximation optimization (QAO) algorithm for Adaptive\norchestration of GNN-based network modeling. We leverage the tripartite graph\nmodel to represent a multi-application system with many compute nodes.\nThereafter, we apply the constrained graph-cutting using QAO to find the\nfeasible energy-efficient configurations of the GNN-based model and deploying\nthem on the available compute nodes to meet the network modeling application\nrequirements. The proposed QAG scheme closely matches the optimum and offers\natleast a 50% energy saving while meeting the application requirements with 60%\nlower churn-rate.",
      "pdf_url": "http://arxiv.org/pdf/2503.18706v1",
      "published": "2025-03-24T14:17:57+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.18706v1",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.ET",
        "cs.LG"
      ]
    },
    {
      "title": "Efficient Continual Adaptation of Pretrained Robotic Policy with Online Meta-Learned Adapters",
      "authors": [
        "Ruiqi Zhu",
        "Endong Sun",
        "Guanhe Huang",
        "Oya Celiktutan"
      ],
      "abstract": "Continual adaptation is essential for general autonomous agents. For example,\na household robot pretrained with a repertoire of skills must still adapt to\nunseen tasks specific to each household. Motivated by this, building upon\nparameter-efficient fine-tuning in language models, prior works have explored\nlightweight adapters to adapt pretrained policies, which can preserve learned\nfeatures from the pretraining phase and demonstrate good adaptation\nperformances. However, these approaches treat task learning separately,\nlimiting knowledge transfer between tasks. In this paper, we propose Online\nMeta-Learned adapters (OMLA). Instead of applying adapters directly, OMLA can\nfacilitate knowledge transfer from previously learned tasks to current learning\ntasks through a novel meta-learning objective. Extensive experiments in both\nsimulated and real-world environments demonstrate that OMLA can lead to better\nadaptation performances compared to the baseline methods. The project link:\nhttps://ricky-zhu.github.io/OMLA/.",
      "pdf_url": "http://arxiv.org/pdf/2503.18684v1",
      "published": "2025-03-24T13:55:47+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.18684v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "Commander-GPT: Fully Unleashing the Sarcasm Detection Capability of Multi-Modal Large Language Models",
      "authors": [
        "Yazhou Zhang",
        "Chunwang Zou",
        "Bo Wang",
        "Jing Qin"
      ],
      "abstract": "Sarcasm detection, as a crucial research direction in the field of Natural\nLanguage Processing (NLP), has attracted widespread attention. Traditional\nsarcasm detection tasks have typically focused on single-modal approaches\n(e.g., text), but due to the implicit and subtle nature of sarcasm, such\nmethods often fail to yield satisfactory results. In recent years, researchers\nhave shifted the focus of sarcasm detection to multi-modal approaches. However,\neffectively leveraging multi-modal information to accurately identify sarcastic\ncontent remains a challenge that warrants further exploration. Leveraging the\npowerful integrated processing capabilities of Multi-Modal Large Language\nModels (MLLMs) for various information sources, we propose an innovative\nmulti-modal Commander-GPT framework. Inspired by military strategy, we first\ndecompose the sarcasm detection task into six distinct sub-tasks. A central\ncommander (decision-maker) then assigns the best-suited large language model to\naddress each specific sub-task. Ultimately, the detection results from each\nmodel are aggregated to identify sarcasm. We conducted extensive experiments on\nMMSD and MMSD 2.0, utilizing four multi-modal large language models and six\nprompting strategies. Our experiments demonstrate that our approach achieves\nstate-of-the-art performance, with a 19.3% improvement in F1 score, without\nnecessitating fine-tuning or ground-truth rationales.",
      "pdf_url": "http://arxiv.org/pdf/2503.18681v2",
      "published": "2025-03-24T13:53:00+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.18681v2",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Any6D: Model-free 6D Pose Estimation of Novel Objects",
      "authors": [
        "Taeyeop Lee",
        "Bowen Wen",
        "Minjun Kang",
        "Gyuree Kang",
        "In So Kweon",
        "Kuk-Jin Yoon"
      ],
      "abstract": "We introduce Any6D, a model-free framework for 6D object pose estimation that\nrequires only a single RGB-D anchor image to estimate both the 6D pose and size\nof unknown objects in novel scenes. Unlike existing methods that rely on\ntextured 3D models or multiple viewpoints, Any6D leverages a joint object\nalignment process to enhance 2D-3D alignment and metric scale estimation for\nimproved pose accuracy. Our approach integrates a render-and-compare strategy\nto generate and refine pose hypotheses, enabling robust performance in\nscenarios with occlusions, non-overlapping views, diverse lighting conditions,\nand large cross-environment variations. We evaluate our method on five\nchallenging datasets: REAL275, Toyota-Light, HO3D, YCBINEOAT, and LM-O,\ndemonstrating its effectiveness in significantly outperforming state-of-the-art\nmethods for novel object pose estimation. Project page:\nhttps://taeyeop.com/any6d",
      "pdf_url": "http://arxiv.org/pdf/2503.18673v2",
      "published": "2025-03-24T13:46:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.18673v2",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ]
    },
    {
      "title": "AgentSpec: Customizable Runtime Enforcement for Safe and Reliable LLM Agents",
      "authors": [
        "Haoyu Wang",
        "Christopher M. Poskitt",
        "Jun Sun"
      ],
      "abstract": "Agents built on LLMs are increasingly deployed across diverse domains,\nautomating complex decision-making and task execution. However, their autonomy\nintroduces safety risks, including security vulnerabilities, legal violations,\nand unintended harmful actions. Existing mitigation methods, such as\nmodel-based safeguards and early enforcement strategies, fall short in\nrobustness, interpretability, and adaptability. To address these challenges, we\npropose AgentSpec, a lightweight domain-specific language for specifying and\nenforcing runtime constraints on LLM agents. With AgentSpec, users define\nstructured rules that incorporate triggers, predicates, and enforcement\nmechanisms, ensuring agents operate within predefined safety boundaries. We\nimplement AgentSpec across multiple domains, including code execution, embodied\nagents, and autonomous driving, demonstrating its adaptability and\neffectiveness. Our evaluation shows that AgentSpec successfully prevents unsafe\nexecutions in over 90% of code agent cases, eliminates all hazardous actions in\nembodied agent tasks, and enforces 100% compliance by autonomous vehicles\n(AVs). Despite its strong safety guarantees, AgentSpec remains computationally\nlightweight, with overheads in milliseconds. By combining interpretability,\nmodularity, and efficiency, AgentSpec provides a practical and scalable\nsolution for enforcing LLM agent safety across diverse applications. We also\nautomate the generation of rules using LLMs and assess their effectiveness. Our\nevaluation shows that the rules generated by OpenAI o1 achieve a precision of\n95.56% and recall of 70.96% for embodied agents, successfully identifying\n87.26% of the risky code, and prevent AVs from breaking laws in 5 out of 8\nscenarios.",
      "pdf_url": "http://arxiv.org/pdf/2503.18666v1",
      "published": "2025-03-24T13:31:48+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.18666v1",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "From Fragment to One Piece: A Survey on AI-Driven Graphic Design",
      "authors": [
        "Xingxing Zou",
        "Wen Zhang",
        "Nanxuan Zhao"
      ],
      "abstract": "This survey provides a comprehensive overview of the advancements in\nArtificial Intelligence in Graphic Design (AIGD), focusing on integrating AI\ntechniques to support design interpretation and enhance the creative process.\nWe categorize the field into two primary directions: perception tasks, which\ninvolve understanding and analyzing design elements, and generation tasks,\nwhich focus on creating new design elements and layouts. The survey covers\nvarious subtasks, including visual element perception and generation, aesthetic\nand semantic understanding, layout analysis, and generation. We highlight the\nrole of large language models and multimodal approaches in bridging the gap\nbetween localized visual features and global design intent. Despite significant\nprogress, challenges remain to understanding human intent, ensuring\ninterpretability, and maintaining control over multilayered compositions. This\nsurvey serves as a guide for researchers, providing information on the current\nstate of AIGD and potential future\ndirections\\footnote{https://github.com/zhangtianer521/excellent\\_Intelligent\\_graphic\\_design}.",
      "pdf_url": "http://arxiv.org/pdf/2503.18641v1",
      "published": "2025-03-24T13:05:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.18641v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Towards Human-Understandable Multi-Dimensional Concept Discovery",
      "authors": [
        "Arne Grobrügge",
        "Niklas Kühl",
        "Gerhard Satzger",
        "Philipp Spitzer"
      ],
      "abstract": "Concept-based eXplainable AI (C-XAI) aims to overcome the limitations of\ntraditional saliency maps by converting pixels into human-understandable\nconcepts that are consistent across an entire dataset. A crucial aspect of\nC-XAI is completeness, which measures how well a set of concepts explains a\nmodel's decisions. Among C-XAI methods, Multi-Dimensional Concept Discovery\n(MCD) effectively improves completeness by breaking down the CNN latent space\ninto distinct and interpretable concept subspaces. However, MCD's explanations\ncan be difficult for humans to understand, raising concerns about their\npractical utility. To address this, we propose Human-Understandable\nMulti-dimensional Concept Discovery (HU-MCD). HU-MCD uses the Segment Anything\nModel for concept identification and implements a CNN-specific input masking\ntechnique to reduce noise introduced by traditional masking methods. These\nchanges to MCD, paired with the completeness relation, enable HU-MCD to enhance\nconcept understandability while maintaining explanation faithfulness. Our\nexperiments, including human subject studies, show that HU-MCD provides more\nprecise and reliable explanations than existing C-XAI methods. The code is\navailable at https://github.com/grobruegge/hu-mcd.",
      "pdf_url": "http://arxiv.org/pdf/2503.18629v1",
      "published": "2025-03-24T12:45:52+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.18629v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Dig2DIG: Dig into Diffusion Information Gains for Image Fusion",
      "authors": [
        "Bing Cao",
        "Baoshuo Cai",
        "Changqing Zhang",
        "Qinghua Hu"
      ],
      "abstract": "Image fusion integrates complementary information from multi-source images to\ngenerate more informative results. Recently, the diffusion model, which\ndemonstrates unprecedented generative potential, has been explored in image\nfusion. However, these approaches typically incorporate predefined multimodal\nguidance into diffusion, failing to capture the dynamically changing\nsignificance of each modality, while lacking theoretical guarantees. To address\nthis issue, we reveal a significant spatio-temporal imbalance in image\ndenoising; specifically, the diffusion model produces dynamic information gains\nin different image regions with denoising steps. Based on this observation, we\nDig into the Diffusion Information Gains (Dig2DIG) and theoretically derive a\ndiffusion-based dynamic image fusion framework that provably reduces the upper\nbound of the generalization error. Accordingly, we introduce diffusion\ninformation gains (DIG) to quantify the information contribution of each\nmodality at different denoising steps, thereby providing dynamic guidance\nduring the fusion process. Extensive experiments on multiple fusion scenarios\nconfirm that our method outperforms existing diffusion-based approaches in\nterms of both fusion quality and inference efficiency.",
      "pdf_url": "http://arxiv.org/pdf/2503.18627v1",
      "published": "2025-03-24T12:43:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.18627v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Adventurer: Exploration with BiGAN for Deep Reinforcement Learning",
      "authors": [
        "Yongshuai Liu",
        "Xin Liu"
      ],
      "abstract": "Recent developments in deep reinforcement learning have been very successful\nin learning complex, previously intractable problems. Sample efficiency and\nlocal optimality, however, remain significant challenges. To address these\nchallenges, novelty-driven exploration strategies have emerged and shown\npromising potential. Unfortunately, no single algorithm outperforms all others\nin all tasks and most of them struggle with tasks with high-dimensional and\ncomplex observations. In this work, we propose Adventurer, a novelty-driven\nexploration algorithm that is based on Bidirectional Generative Adversarial\nNetworks (BiGAN), where BiGAN is trained to estimate state novelty.\nIntuitively, a generator that has been trained on the distribution of visited\nstates should only be able to generate a state coming from the distribution of\nvisited states. As a result, novel states using the generator to reconstruct\ninput states from certain latent representations would lead to larger\nreconstruction errors. We show that BiGAN performs well in estimating state\nnovelty for complex observations. This novelty estimation method can be\ncombined with intrinsic-reward-based exploration. Our empirical results show\nthat Adventurer produces competitive results on a range of popular benchmark\ntasks, including continuous robotic manipulation tasks (e.g. Mujoco robotics)\nand high-dimensional image-based tasks (e.g. Atari games).",
      "pdf_url": "http://arxiv.org/pdf/2503.18612v1",
      "published": "2025-03-24T12:13:24+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.18612v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Reinforcement Learning in Switching Non-Stationary Markov Decision Processes: Algorithms and Convergence Analysis",
      "authors": [
        "Mohsen Amiri",
        "Sindri Magnússon"
      ],
      "abstract": "Reinforcement learning in non-stationary environments is challenging due to\nabrupt and unpredictable changes in dynamics, often causing traditional\nalgorithms to fail to converge. However, in many real-world cases,\nnon-stationarity has some structure that can be exploited to develop algorithms\nand facilitate theoretical analysis. We introduce one such structure, Switching\nNon-Stationary Markov Decision Processes (SNS-MDP), where environments switch\nover time based on an underlying Markov chain. Under a fixed policy, the value\nfunction of an SNS-MDP admits a closed-form solution determined by the Markov\nchain's statistical properties, and despite the inherent non-stationarity,\nTemporal Difference (TD) learning methods still converge to the correct value\nfunction. Furthermore, policy improvement can be performed, and it is shown\nthat policy iteration converges to the optimal policy. Moreover, since\nQ-learning converges to the optimal Q-function, it likewise yields the\ncorresponding optimal policy. To illustrate the practical advantages of\nSNS-MDPs, we present an example in communication networks where channel noise\nfollows a Markovian pattern, demonstrating how this framework can effectively\nguide decision-making in complex, time-varying contexts.",
      "pdf_url": "http://arxiv.org/pdf/2503.18607v1",
      "published": "2025-03-24T12:05:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.18607v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Adaptive Unimodal Regulation for Balanced Multimodal Information Acquisition",
      "authors": [
        "Chengxiang Huang",
        "Yake Wei",
        "Zequn Yang",
        "Di Hu"
      ],
      "abstract": "Sensory training during the early ages is vital for human development.\nInspired by this cognitive phenomenon, we observe that the early training stage\nis also important for the multimodal learning process, where dataset\ninformation is rapidly acquired. We refer to this stage as the prime learning\nwindow. However, based on our observation, this prime learning window in\nmultimodal learning is often dominated by information-sufficient modalities,\nwhich in turn suppresses the information acquisition of\ninformation-insufficient modalities. To address this issue, we propose\nInformation Acquisition Regulation (InfoReg), a method designed to balance\ninformation acquisition among modalities. Specifically, InfoReg slows down the\ninformation acquisition process of information-sufficient modalities during the\nprime learning window, which could promote information acquisition of\ninformation-insufficient modalities. This regulation enables a more balanced\nlearning process and improves the overall performance of the multimodal\nnetwork. Experiments show that InfoReg outperforms related multimodal\nimbalanced methods across various datasets, achieving superior model\nperformance. The code is available at\nhttps://github.com/GeWu-Lab/InfoReg_CVPR2025.",
      "pdf_url": "http://arxiv.org/pdf/2503.18595v1",
      "published": "2025-03-24T11:52:57+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.18595v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "ClinText-SP and RigoBERTa Clinical: a new set of open resources for Spanish Clinical NLP",
      "authors": [
        "Guillem García Subies",
        "Álvaro Barbero Jiménez",
        "Paloma Martínez Fernández"
      ],
      "abstract": "We present a novel contribution to Spanish clinical natural language\nprocessing by introducing the largest publicly available clinical corpus,\nClinText-SP, along with a state-of-the-art clinical encoder language model,\nRigoBERTa Clinical. Our corpus was meticulously curated from diverse open\nsources, including clinical cases from medical journals and annotated corpora\nfrom shared tasks, providing a rich and diverse dataset that was previously\ndifficult to access. RigoBERTa Clinical, developed through domain-adaptive\npretraining on this comprehensive dataset, significantly outperforms existing\nmodels on multiple clinical NLP benchmarks. By publicly releasing both the\ndataset and the model, we aim to empower the research community with robust\nresources that can drive further advancements in clinical NLP and ultimately\ncontribute to improved healthcare applications.",
      "pdf_url": "http://arxiv.org/pdf/2503.18594v1",
      "published": "2025-03-24T11:52:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.18594v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "The Role of Artificial Intelligence in Enhancing Insulin Recommendations and Therapy Outcomes",
      "authors": [
        "Maria Panagiotou",
        "Knut Stroemmen",
        "Lorenzo Brigato",
        "Bastiaan E. de Galan",
        "Stavroula Mougiakakou"
      ],
      "abstract": "The growing worldwide incidence of diabetes requires more effective\napproaches for managing blood glucose levels. Insulin delivery systems have\nadvanced significantly, with artificial intelligence (AI) playing a key role in\nimproving their precision and adaptability. AI algorithms, particularly those\nbased on reinforcement learning, allow for personalised insulin dosing by\ncontinuously adapting to an individual's responses. Despite these advancements,\nchallenges such as data privacy, algorithm transparency, and accessibility\nstill need to be addressed. Continued progress and validation in AI-driven\ninsulin delivery systems promise to improve therapy outcomes further, offering\npeople more effective and individualised management of their diabetes. This\npaper presents an overview of current strategies, key challenges, and future\ndirections.",
      "pdf_url": "http://arxiv.org/pdf/2503.18592v1",
      "published": "2025-03-24T11:50:14+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.18592v1",
      "categories": [
        "cs.AI",
        "cs.LG",
        "physics.med-ph"
      ]
    },
    {
      "title": "Galaxy Walker: Geometry-aware VLMs For Galaxy-scale Understanding",
      "authors": [
        "Tianyu Chen",
        "Xingcheng Fu",
        "Yisen Gao",
        "Haodong Qian",
        "Yuecen Wei",
        "Kun Yan",
        "Haoyi Zhou",
        "Jianxin Li"
      ],
      "abstract": "Modern vision-language models (VLMs) develop patch embedding and convolution\nbackbone within vector space, especially Euclidean ones, at the very founding.\nWhen expanding VLMs to a galaxy scale for understanding astronomical phenomena,\nthe integration of spherical space for planetary orbits and hyperbolic spaces\nfor black holes raises two formidable challenges. a) The current pre-training\nmodel is confined to Euclidean space rather than a comprehensive geometric\nembedding. b) The predominant architecture lacks suitable backbones for\nanisotropic physical geometries. In this paper, we introduced Galaxy-Walker, a\ngeometry-aware VLM, for the universe-level vision understanding tasks. We\nproposed the geometry prompt that generates geometry tokens by random walks\nacross diverse spaces on a multi-scale physical graph, along with a geometry\nadapter that compresses and reshapes the space anisotropy in a\nmixture-of-experts manner. Extensive experiments demonstrate the effectiveness\nof our approach, with Galaxy-Walker achieving state-of-the-art performance in\nboth galaxy property estimation ($R^2$ scores up to $0.91$) and morphology\nclassification tasks (up to $+0.17$ F1 improvement in challenging features),\nsignificantly outperforming both domain-specific models and general-purpose\nVLMs.",
      "pdf_url": "http://arxiv.org/pdf/2503.18578v1",
      "published": "2025-03-24T11:35:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.18578v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Identifying and Characterising Higher Order Interactions in Mobility Networks Using Hypergraphs",
      "authors": [
        "Prathyush Sambaturu",
        "Bernardo Gutierrez",
        "Moritz U. G. Kraemer"
      ],
      "abstract": "Understanding human mobility is essential for applications ranging from urban\nplanning to public health. Traditional mobility models such as flow networks\nand colocation matrices capture only pairwise interactions between discrete\nlocations, overlooking higher-order relationships among locations (i.e.,\nmobility flow among two or more locations). To address this, we propose\nco-visitation hypergraphs, a model that leverages temporal observation windows\nto extract group interactions between locations from individual mobility\ntrajectory data. Using frequent pattern mining, our approach constructs\nhypergraphs that capture dynamic mobility behaviors across different spatial\nand temporal scales. We validate our method on a publicly available mobility\ndataset and demonstrate its effectiveness in analyzing city-scale mobility\npatterns, detecting shifts during external disruptions such as extreme weather\nevents, and examining how a location's connectivity (degree) relates to the\nnumber of points of interest (POIs) within it. Our results demonstrate that our\nhypergraph-based mobility analysis framework is a valuable tool with potential\napplications in diverse fields such as public health, disaster resilience, and\nurban planning.",
      "pdf_url": "http://arxiv.org/pdf/2503.18572v1",
      "published": "2025-03-24T11:29:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.18572v1",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.DB",
        "cs.DM",
        "math.CO"
      ]
    },
    {
      "title": "Anchor-based oversampling for imbalanced tabular data via contrastive and adversarial learning",
      "authors": [
        "Hadi Mohammadi",
        "Ehsan Nazerfard",
        "Mostafa Haghir Chehreghani"
      ],
      "abstract": "Imbalanced data represent a distribution with more frequencies of one class\n(majority) than the other (minority). This phenomenon occurs across various\ndomains, such as security, medical care and human activity. In imbalanced\nlearning, classification algorithms are typically inclined to classify the\nmajority class accurately, resulting in artificially high accuracy rates. As a\nresult, many minority samples are mistakenly labelled as majority-class\ninstances, resulting in a bias that benefits the majority class. This study\npresents a framework based on boundary anchor samples to tackle the imbalance\nlearning challenge. First, we select and use anchor samples to train a\nmultilayer perceptron (MLP) classifier, which acts as a prior knowledge model\nand aids the adversarial and contrastive learning procedures. Then, we designed\na novel deep generative model called Anchor Stabilized Conditional Generative\nAdversarial Network or Anch-SCGAN in short. Anch-SCGAN is supported with two\ngenerators for the minority and majority classes and a discriminator\nincorporating additional class-specific information from the pre-trained\nfeature extractor MLP. In addition, we facilitate the generator's training\nprocedure in two ways. First, we define a new generator loss function based on\nreprocessed anchor samples and contrastive learning. Second, we apply a scoring\nstrategy to stabilize the adversarial training part in generators. We train\nAnch-SCGAN and further finetune it with anchor samples to improve the precision\nof the generated samples. Our experiments on 16 real-world imbalanced datasets\nillustrate that Anch-SCGAN outperforms the renowned methods in imbalanced\nlearning.",
      "pdf_url": "http://arxiv.org/pdf/2503.18569v1",
      "published": "2025-03-24T11:25:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.18569v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Distil-xLSTM: Learning Attention Mechanisms through Recurrent Structures",
      "authors": [
        "Abdoul Majid O. Thiombiano",
        "Brahim Hnich",
        "Ali Ben Mrad",
        "Mohamed Wiem Mkaouer"
      ],
      "abstract": "The current era of Natural Language Processing (NLP) is dominated by\nTransformer models. However, novel architectures relying on recurrent\nmechanisms, such as xLSTM and Mamba, have been proposed as alternatives to\nattention-based models. Although computation is done differently than with the\nattention mechanism mechanism, these recurrent models yield good results and\nsometimes even outperform state-of-the-art attention-based models. In this\nwork, we propose Distil-xLSTM, an xLSTM-based Small Language Model (SLM)\ntrained by distilling knowledge from a Large Language Model (LLM) that shows\npromising results while being compute and scale efficient. Our Distil-xLSTM\nfocuses on approximating a transformer-based model attention parametrization\nusing its recurrent sequence mixing components and shows good results with\nminimal training.",
      "pdf_url": "http://arxiv.org/pdf/2503.18565v1",
      "published": "2025-03-24T11:18:25+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.18565v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Self-Reported Confidence of Large Language Models in Gastroenterology: Analysis of Commercial, Open-Source, and Quantized Models",
      "authors": [
        "Nariman Naderi",
        "Seyed Amir Ahmad Safavi-Naini",
        "Thomas Savage",
        "Zahra Atf",
        "Peter Lewis",
        "Girish Nadkarni",
        "Ali Soroush"
      ],
      "abstract": "This study evaluated self-reported response certainty across several large\nlanguage models (GPT, Claude, Llama, Phi, Mistral, Gemini, Gemma, and Qwen)\nusing 300 gastroenterology board-style questions. The highest-performing models\n(GPT-o1 preview, GPT-4o, and Claude-3.5-Sonnet) achieved Brier scores of\n0.15-0.2 and AUROC of 0.6. Although newer models demonstrated improved\nperformance, all exhibited a consistent tendency towards overconfidence.\nUncertainty estimation presents a significant challenge to the safe use of LLMs\nin healthcare. Keywords: Large Language Models; Confidence Elicitation;\nArtificial Intelligence; Gastroenterology; Uncertainty Quantification",
      "pdf_url": "http://arxiv.org/pdf/2503.18562v1",
      "published": "2025-03-24T11:16:41+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.18562v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ]
    },
    {
      "title": "EvAnimate: Event-conditioned Image-to-Video Generation for Human Animation",
      "authors": [
        "Qiang Qu",
        "Ming Li",
        "Xiaoming Chen",
        "Tongliang Liu"
      ],
      "abstract": "Conditional human animation transforms a static reference image into a\ndynamic sequence by applying motion cues such as poses. These motion cues are\ntypically derived from video data but are susceptible to limitations including\nlow temporal resolution, motion blur, overexposure, and inaccuracies under\nlow-light conditions. In contrast, event cameras provide data streams with\nexceptionally high temporal resolution, a wide dynamic range, and inherent\nresistance to motion blur and exposure issues. In this work, we propose\nEvAnimate, a framework that leverages event streams as motion cues to animate\nstatic human images. Our approach employs a specialized event representation\nthat transforms asynchronous event streams into 3-channel slices with\ncontrollable slicing rates and appropriate slice density, ensuring\ncompatibility with diffusion models. Subsequently, a dual-branch architecture\ngenerates high-quality videos by harnessing the inherent motion dynamics of the\nevent streams, thereby enhancing both video quality and temporal consistency.\nSpecialized data augmentation strategies further enhance cross-person\ngeneralization. Finally, we establish a new benchmarking, including simulated\nevent data for training and validation, and a real-world event dataset\ncapturing human actions under normal and extreme scenarios. The experiment\nresults demonstrate that EvAnimate achieves high temporal fidelity and robust\nperformance in scenarios where traditional video-derived cues fall short.",
      "pdf_url": "http://arxiv.org/pdf/2503.18552v1",
      "published": "2025-03-24T11:05:41+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.18552v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ]
    },
    {
      "title": "Discriminative protein sequence modelling with Latent Space Diffusion",
      "authors": [
        "Eoin Quinn",
        "Ghassene Jebali",
        "Maxime Seince",
        "Oliver Bent"
      ],
      "abstract": "We explore a framework for protein sequence representation learning that\ndecomposes the task between manifold learning and distributional modelling.\nSpecifically we present a Latent Space Diffusion architecture which combines a\nprotein sequence autoencoder with a denoising diffusion model operating on its\nlatent space. We obtain a one-parameter family of learned representations from\nthe diffusion model, along with the autoencoder's latent representation. We\npropose and evaluate two autoencoder architectures: a homogeneous model forcing\namino acids of the same type to be identically distributed in the latent space,\nand an inhomogeneous model employing a noise-based variant of masking. As a\nbaseline we take a latent space learned by masked language modelling, and\nevaluate discriminative capability on a range of protein property prediction\ntasks. Our finding is twofold: the diffusion models trained on both our\nproposed variants display higher discriminative power than the one trained on\nthe masked language model baseline, none of the diffusion representations\nachieve the performance of the masked language model embeddings themselves.",
      "pdf_url": "http://arxiv.org/pdf/2503.18551v1",
      "published": "2025-03-24T11:03:57+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.18551v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "RLCAD: Reinforcement Learning Training Gym for Revolution Involved CAD Command Sequence Generation",
      "authors": [
        "Xiaolong Yin",
        "Xingyu Lu",
        "Jiahang Shen",
        "Jingzhe Ni",
        "Hailong Li",
        "Ruofeng Tong",
        "Min Tang",
        "Peng Du"
      ],
      "abstract": "A CAD command sequence is a typical parametric design paradigm in 3D CAD\nsystems where a model is constructed by overlaying 2D sketches with operations\nsuch as extrusion, revolution, and Boolean operations. Although there is\ngrowing academic interest in the automatic generation of command sequences,\nexisting methods and datasets only support operations such as 2D sketching,\nextrusion,and Boolean operations. This limitation makes it challenging to\nrepresent more complex geometries. In this paper, we present a reinforcement\nlearning (RL) training environment (gym) built on a CAD geometric engine. Given\nan input boundary representation (B-Rep) geometry, the policy network in the RL\nalgorithm generates an action. This action, along with previously generated\nactions, is processed within the gym to produce the corresponding CAD geometry,\nwhich is then fed back into the policy network. The rewards, determined by the\ndifference between the generated and target geometries within the gym, are used\nto update the RL network. Our method supports operations beyond sketches,\nBoolean, and extrusion, including revolution operations. With this training\ngym, we achieve state-of-the-art (SOTA) quality in generating command sequences\nfrom B-Rep geometries. In addition, our method can significantly improve the\nefficiency of command sequence generation by a factor of 39X compared with the\nprevious training gym.",
      "pdf_url": "http://arxiv.org/pdf/2503.18549v1",
      "published": "2025-03-24T11:01:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.18549v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "An Identity and Interaction Based Network Forensic Analysis",
      "authors": [
        "Nathan Clarke",
        "Gaseb Alotibi",
        "Dany Joy",
        "Fudong Li",
        "Steven Furnell",
        "Ali Alshumrani",
        "Hussan Mohammed"
      ],
      "abstract": "In todays landscape of increasing electronic crime, network forensics plays a\npivotal role in digital investigations. It aids in understanding which systems\nto analyse and as a supplement to support evidence found through more\ntraditional computer based investigations. However, the nature and\nfunctionality of the existing Network Forensic Analysis Tools (NFATs) fall\nshort compared to File System Forensic Analysis Tools (FS FATs) in providing\nusable data. The analysis tends to focus upon IP addresses, which are not\nsynonymous with user identities, a point of significant interest to\ninvestigators. This paper presents several experiments designed to create a\nnovel NFAT approach that can identify users and understand how they are using\nnetwork based applications whilst the traffic remains encrypted. The\nexperiments build upon the prior art and investigate how effective this\napproach is in classifying users and their actions. Utilising an in-house\ndataset composed of 50 million packers, the experiments are formed of three\nincremental developments that assist in improving performance. Building upon\nthe successful experiments, a proposed NFAT interface is presented to\nillustrate the ease at which investigators would be able to ask relevant\nquestions of user interactions. The experiments profiled across 27 users, has\nyielded an average 93.3% True Positive Identification Rate (TPIR), with 41% of\nusers experiencing 100% TPIR. Skype, Wikipedia and Hotmail services achieved a\nnotably high level of recognition performance. The study has developed and\nevaluated an approach to analyse encrypted network traffic more effectively\nthrough the modelling of network traffic and to subsequently visualise these\ninteractions through a novel network forensic analysis tool.",
      "pdf_url": "http://arxiv.org/pdf/2503.18542v1",
      "published": "2025-03-24T10:52:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.18542v1",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    }
  ]
}