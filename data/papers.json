{
  "last_updated": "2025-04-23T00:49:52.658350",
  "papers": [
    {
      "title": "Stop Summation: Min-Form Credit Assignment Is All Process Reward Model Needs for Reasoning",
      "authors": [
        "Jie Cheng",
        "Ruixi Qiao",
        "Lijun Li",
        "Chao Guo",
        "Junle Wang",
        "Gang Xiong",
        "Yisheng Lv",
        "Fei-Yue Wang"
      ],
      "abstract": "Process reward models (PRMs) have proven effective for test-time scaling of\nLarge Language Models (LLMs) on challenging reasoning tasks. However, reward\nhacking issues with PRMs limit their successful application in reinforcement\nfine-tuning. In this paper, we identify the main cause of PRM-induced reward\nhacking: the canonical summation-form credit assignment in reinforcement\nlearning (RL), which defines the value as cumulative gamma-decayed future\nrewards, easily induces LLMs to hack steps with high rewards. To address this,\nwe propose PURE: Process sUpervised Reinforcement lEarning. The key innovation\nof PURE is a min-form credit assignment that formulates the value function as\nthe minimum of future rewards. This method significantly alleviates reward\nhacking by limiting the value function range and distributing advantages more\nreasonably. Through extensive experiments on 3 base models, we show that\nPRM-based approaches enabling min-form credit assignment achieve comparable\nreasoning performance to verifiable reward-based methods within only 30% steps.\nIn contrast, the canonical sum-form credit assignment collapses training even\nat the beginning! Additionally, when we supplement PRM-based fine-tuning with\njust 10% verifiable rewards, we further alleviate reward hacking and produce\nthe best fine-tuned model based on Qwen2.5-Math-7B in our experiments,\nachieving 82.5% accuracy on AMC23 and 53.3% average accuracy across 5\nbenchmarks. Moreover, we summarize the observed reward hacking cases and\nanalyze the causes of training collapse. Code and models are available at\nhttps://github.com/CJReinforce/PURE.",
      "pdf_url": "http://arxiv.org/pdf/2504.15275v1",
      "published": "2025-04-21T17:59:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.15275v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Roll the dice & look before you leap: Going beyond the creative limits of next-token prediction",
      "authors": [
        "Vaishnavh Nagarajan",
        "Chen Henry Wu",
        "Charles Ding",
        "Aditi Raghunathan"
      ],
      "abstract": "We design a suite of minimal algorithmic tasks that are a loose abstraction\nof open-ended real-world tasks. This allows us to cleanly and controllably\nquantify the creative limits of the present-day language model. Much like\nreal-world tasks that require a creative, far-sighted leap of thought, our\ntasks require an implicit, open-ended stochastic planning step that either (a)\ndiscovers new connections in an abstract knowledge graph (like in wordplay,\ndrawing analogies, or research) or (b) constructs new patterns (like in\ndesigning math problems or new proteins). In these tasks, we empirically and\nconceptually argue how next-token learning is myopic and memorizes excessively;\ncomparatively, multi-token approaches, namely teacherless training and\ndiffusion models, excel in producing diverse and original output. Secondly, in\nour tasks, we find that to elicit randomness from the Transformer without\nhurting coherence, it is better to inject noise right at the input layer (via a\nmethod we dub hash-conditioning) rather than defer to temperature sampling from\nthe output layer. Thus, our work offers a principled, minimal test-bed for\nanalyzing open-ended creative skills, and offers new arguments for going beyond\nnext-token learning and softmax-based sampling. We make part of the code\navailable under https://github.com/chenwu98/algorithmic-creativity",
      "pdf_url": "http://arxiv.org/pdf/2504.15266v1",
      "published": "2025-04-21T17:47:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.15266v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Leveraging Language Models for Automated Patient Record Linkage",
      "authors": [
        "Mohammad Beheshti",
        "Lovedeep Gondara",
        "Iris Zachary"
      ],
      "abstract": "Objective: Healthcare data fragmentation presents a major challenge for\nlinking patient data, necessitating robust record linkage to integrate patient\nrecords from diverse sources. This study investigates the feasibility of\nleveraging language models for automated patient record linkage, focusing on\ntwo key tasks: blocking and matching. Materials and Methods: We utilized\nreal-world healthcare data from the Missouri Cancer Registry and Research\nCenter, linking patient records from two independent sources using\nprobabilistic linkage as a baseline. A transformer-based model, RoBERTa, was\nfine-tuned for blocking using sentence embeddings. For matching, several\nlanguage models were experimented under fine-tuned and zero-shot settings,\nassessing their performance against ground truth labels. Results: The\nfine-tuned blocking model achieved a 92% reduction in the number of candidate\npairs while maintaining near-perfect recall. In the matching task, fine-tuned\nMistral-7B achieved the best performance with only 6 incorrect predictions.\nAmong zero-shot models, Mistral-Small-24B performed best, with a total of 55\nincorrect predictions. Discussion: Fine-tuned language models achieved strong\nperformance in patient record blocking and matching with minimal errors.\nHowever, they remain less accurate and efficient than a hybrid rule-based and\nprobabilistic approach for blocking. Additionally, reasoning models like\nDeepSeek-R1 are impractical for large-scale record linkage due to high\ncomputational costs. Conclusion: This study highlights the potential of\nlanguage models for automating patient record linkage, offering improved\nefficiency by eliminating the manual efforts required to perform patient record\nlinkage. Overall, language models offer a scalable solution that can enhance\ndata integration, reduce manual effort, and support disease surveillance and\nresearch.",
      "pdf_url": "http://arxiv.org/pdf/2504.15261v1",
      "published": "2025-04-21T17:41:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.15261v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Bringing Diversity from Diffusion Models to Semantic-Guided Face Asset Generation",
      "authors": [
        "Yunxuan Cai",
        "Sitao Xiang",
        "Zongjian Li",
        "Haiwei Chen",
        "Yajie Zhao"
      ],
      "abstract": "Digital modeling and reconstruction of human faces serve various\napplications. However, its availability is often hindered by the requirements\nof data capturing devices, manual labor, and suitable actors. This situation\nrestricts the diversity, expressiveness, and control over the resulting models.\nThis work aims to demonstrate that a semantically controllable generative\nnetwork can provide enhanced control over the digital face modeling process. To\nenhance diversity beyond the limited human faces scanned in a controlled\nsetting, we introduce a novel data generation pipeline that creates a\nhigh-quality 3D face database using a pre-trained diffusion model. Our proposed\nnormalization module converts synthesized data from the diffusion model into\nhigh-quality scanned data. Using the 44,000 face models we obtained, we further\ndeveloped an efficient GAN-based generator. This generator accepts semantic\nattributes as input, and generates geometry and albedo. It also allows\ncontinuous post-editing of attributes in the latent space. Our asset refinement\ncomponent subsequently creates physically-based facial assets. We introduce a\ncomprehensive system designed for creating and editing high-quality face\nassets. Our proposed model has undergone extensive experiment, comparison and\nevaluation. We also integrate everything into a web-based interactive tool. We\naim to make this tool publicly available with the release of the paper.",
      "pdf_url": "http://arxiv.org/pdf/2504.15259v1",
      "published": "2025-04-21T17:38:50+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.15259v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "FlowReasoner: Reinforcing Query-Level Meta-Agents",
      "authors": [
        "Hongcheng Gao",
        "Yue Liu",
        "Yufei He",
        "Longxu Dou",
        "Chao Du",
        "Zhijie Deng",
        "Bryan Hooi",
        "Min Lin",
        "Tianyu Pang"
      ],
      "abstract": "This paper proposes a query-level meta-agent named FlowReasoner to automate\nthe design of query-level multi-agent systems, i.e., one system per user query.\nOur core idea is to incentivize a reasoning-based meta-agent via external\nexecution feedback. Concretely, by distilling DeepSeek R1, we first endow the\nbasic reasoning ability regarding the generation of multi-agent systems to\nFlowReasoner. Then, we further enhance it via reinforcement learning (RL) with\nexternal execution feedback. A multi-purpose reward is designed to guide the RL\ntraining from aspects of performance, complexity, and efficiency. In this\nmanner, FlowReasoner is enabled to generate a personalized multi-agent system\nfor each user query via deliberative reasoning. Experiments on both engineering\nand competition code benchmarks demonstrate the superiority of FlowReasoner.\nRemarkably, it surpasses o1-mini by 10.52% accuracy across three benchmarks.\nThe code is available at https://github.com/sail-sg/FlowReasoner.",
      "pdf_url": "http://arxiv.org/pdf/2504.15257v1",
      "published": "2025-04-21T17:35:42+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.15257v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "SuoiAI: Building a Dataset for Aquatic Invertebrates in Vietnam",
      "authors": [
        "Tue Vo",
        "Lakshay Sharma",
        "Tuan Dinh",
        "Khuong Dinh",
        "Trang Nguyen",
        "Trung Phan",
        "Minh Do",
        "Duong Vu"
      ],
      "abstract": "Understanding and monitoring aquatic biodiversity is critical for ecological\nhealth and conservation efforts. This paper proposes SuoiAI, an end-to-end\npipeline for building a dataset of aquatic invertebrates in Vietnam and\nemploying machine learning (ML) techniques for species classification. We\noutline the methods for data collection, annotation, and model training,\nfocusing on reducing annotation effort through semi-supervised learning and\nleveraging state-of-the-art object detection and classification models. Our\napproach aims to overcome challenges such as data scarcity, fine-grained\nclassification, and deployment in diverse environmental conditions.",
      "pdf_url": "http://arxiv.org/pdf/2504.15252v1",
      "published": "2025-04-21T17:33:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.15252v1",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ]
    },
    {
      "title": "Values in the Wild: Discovering and Analyzing Values in Real-World Language Model Interactions",
      "authors": [
        "Saffron Huang",
        "Esin Durmus",
        "Miles McCain",
        "Kunal Handa",
        "Alex Tamkin",
        "Jerry Hong",
        "Michael Stern",
        "Arushi Somani",
        "Xiuruo Zhang",
        "Deep Ganguli"
      ],
      "abstract": "AI assistants can impart value judgments that shape people's decisions and\nworldviews, yet little is known empirically about what values these systems\nrely on in practice. To address this, we develop a bottom-up,\nprivacy-preserving method to extract the values (normative considerations\nstated or demonstrated in model responses) that Claude 3 and 3.5 models exhibit\nin hundreds of thousands of real-world interactions. We empirically discover\nand taxonomize 3,307 AI values and study how they vary by context. We find that\nClaude expresses many practical and epistemic values, and typically supports\nprosocial human values while resisting values like \"moral nihilism\". While some\nvalues appear consistently across contexts (e.g. \"transparency\"), many are more\nspecialized and context-dependent, reflecting the diversity of human\ninterlocutors and their varied contexts. For example, \"harm prevention\" emerges\nwhen Claude resists users, \"historical accuracy\" when responding to queries\nabout controversial events, \"healthy boundaries\" when asked for relationship\nadvice, and \"human agency\" in technology ethics discussions. By providing the\nfirst large-scale empirical mapping of AI values in deployment, our work\ncreates a foundation for more grounded evaluation and design of values in AI\nsystems.",
      "pdf_url": "http://arxiv.org/pdf/2504.15236v1",
      "published": "2025-04-21T17:13:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.15236v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ]
    },
    {
      "title": "A Self-Improving Coding Agent",
      "authors": [
        "Maxime Robeyns",
        "Martin Szummer",
        "Laurence Aitchison"
      ],
      "abstract": "We demonstrate that an LLM coding agent, equipped with basic coding tools,\ncan autonomously edit itself, and thereby improve its performance on benchmark\ntasks. We find performance gains from 17% to 53% on a random subset of SWE\nBench Verified, with additional performance gains on LiveCodeBench, as well as\nsynthetically generated agent benchmarks. Our work represents an advancement in\nthe automated and open-ended design of agentic systems, and provides a\nreference agent framework for those seeking to post-train LLMs on tool use and\nother agentic tasks.",
      "pdf_url": "http://arxiv.org/pdf/2504.15228v1",
      "published": "2025-04-21T16:58:18+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.15228v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "A Genetic Fuzzy-Enabled Framework on Robotic Manipulation for In-Space Servicing",
      "authors": [
        "Nathan Steffen",
        "Wilhelm Louw",
        "Nicholas Ernest",
        "Timothy Arnett",
        "Kelly Cohen"
      ],
      "abstract": "Automation of robotic systems for servicing in cislunar space is becoming\nextremely important as the number of satellites in orbit increases. Safety is\ncritical in performing satellite maintenance, so the control techniques\nutilized must be trusted in addition to being highly efficient. In this work,\nGenetic Fuzzy Trees are combined with the widely used LQR control scheme via\nThales' TrUE AI Toolkit to create a trusted and efficient controller for a\ntwo-degree-of-freedom planar robotic manipulator that would theoretically be\nused to perform satellite maintenance. It was found that Genetic Fuzzy-LQR is\n18.5% more performant than optimal LQR on average, and that it is incredibly\nrobust to uncertainty.",
      "pdf_url": "http://arxiv.org/pdf/2504.15226v1",
      "published": "2025-04-21T16:57:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.15226v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ]
    },
    {
      "title": "M$^2$AD: Multi-Sensor Multi-System Anomaly Detection through Global Scoring and Calibrated Thresholding",
      "authors": [
        "Sarah Alnegheimish",
        "Zelin He",
        "Matthew Reimherr",
        "Akash Chandrayan",
        "Abhinav Pradhan",
        "Luca D'Angelo"
      ],
      "abstract": "With the widespread availability of sensor data across industrial and\noperational systems, we frequently encounter heterogeneous time series from\nmultiple systems. Anomaly detection is crucial for such systems to facilitate\npredictive maintenance. However, most existing anomaly detection methods are\ndesigned for either univariate or single-system multivariate data, making them\ninsufficient for these complex scenarios. To address this, we introduce\nM$^2$AD, a framework for unsupervised anomaly detection in multivariate time\nseries data from multiple systems. M$^2$AD employs deep models to capture\nexpected behavior under normal conditions, using the residuals as indicators of\npotential anomalies. These residuals are then aggregated into a global anomaly\nscore through a Gaussian Mixture Model and Gamma calibration. We theoretically\ndemonstrate that this framework can effectively address heterogeneity and\ndependencies across sensors and systems. Empirically, M$^2$AD outperforms\nexisting methods in extensive evaluations by 21% on average, and its\neffectiveness is demonstrated on a large-scale real-world case study on 130\nassets in Amazon Fulfillment Centers. Our code and results are available at\nhttps://github.com/sarahmish/M2AD.",
      "pdf_url": "http://arxiv.org/pdf/2504.15225v1",
      "published": "2025-04-21T16:57:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.15225v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Position: Bayesian Statistics Facilitates Stakeholder Participation in Evaluation of Generative AI",
      "authors": [
        "Yanan Long"
      ],
      "abstract": "The evaluation of Generative AI (GenAI) systems plays a critical role in\npublic policy and decision-making, yet existing methods are often limited by\nreliance on benchmark-driven, point-estimate comparisons that fail to capture\nuncertainty and broader societal impacts. This paper argues for the use of\nBayesian statistics as a principled framework to address these challenges.\nBayesian methods enable the integration of domain expertise through prior\nelicitation, allow for continuous learning from new data, and provide robust\nuncertainty quantification via posterior inference. We demonstrate how Bayesian\ninference can be applied to GenAI evaluation, particularly in incorporating\nstakeholder perspectives to enhance fairness, transparency, and reliability.\nFurthermore, we discuss Bayesian workflows as an iterative process for model\nvalidation and refinement, ensuring robust assessments of GenAI systems in\ndynamic, real-world contexts.",
      "pdf_url": "http://arxiv.org/pdf/2504.15211v1",
      "published": "2025-04-21T16:31:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.15211v1",
      "categories": [
        "cs.AI",
        "stat.AP"
      ]
    },
    {
      "title": "Integrating Symbolic Execution into the Fine-Tuning of Code-Generating LLMs",
      "authors": [
        "Marina Sakharova",
        "Abhinav Anand",
        "Mira Mezini"
      ],
      "abstract": "Code-generating Large Language Models (LLMs) have become essential tools in\nmodern software development, enhancing productivity and accelerating\ndevelopment. This paper aims to investigate the fine-tuning of code-generating\nLLMs using Reinforcement Learning and Direct Preference Optimization, further\nimproving their performance. To achieve this, we enhance the training data for\nthe reward model with the help of symbolic execution techniques, ensuring more\ncomprehensive and objective data. With symbolic execution, we create a custom\ndataset that better captures the nuances in code evaluation. Our reward models,\nfine-tuned on this dataset, demonstrate significant improvements over the\nbaseline, CodeRL, in estimating the quality of generated code. Our\ncode-generating LLMs, trained with the help of reward model feedback, achieve\nsimilar results compared to the CodeRL benchmark.",
      "pdf_url": "http://arxiv.org/pdf/2504.15210v1",
      "published": "2025-04-21T16:29:07+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.15210v1",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "A Causal Convolutional Low-rank Representation Model for Imputation of Water Quality Data",
      "authors": [
        "Xin Liao",
        "Bing Yang",
        "Tan Dongli",
        "Cai Yu"
      ],
      "abstract": "The monitoring of water quality is a crucial part of environmental\nprotection, and a large number of monitors are widely deployed to monitor water\nquality. Due to unavoidable factors such as data acquisition breakdowns,\nsensors and communication failures, water quality monitoring data suffers from\nmissing values over time, resulting in High-Dimensional and Sparse (HDS) Water\nQuality Data (WQD). The simple and rough filling of the missing values leads to\ninaccurate results and affects the implementation of relevant measures.\nTherefore, this paper proposes a Causal convolutional Low-rank Representation\n(CLR) model for imputing missing WQD to improve the completeness of the WQD,\nwhich employs a two-fold idea: a) applying causal convolutional operation to\nconsider the temporal dependence of the low-rank representation, thus\nincorporating temporal information to improve the imputation accuracy; and b)\nimplementing a hyperparameters adaptation scheme to automatically adjust the\nbest hyperparameters during model training, thereby reducing the tedious manual\nadjustment of hyper-parameters. Experimental studies on three real-world water\nquality datasets demonstrate that the proposed CLR model is superior to some of\nthe existing state-of-the-art imputation models in terms of imputation accuracy\nand time cost, as well as indicating that the proposed model provides more\nreliable decision support for environmental monitoring.",
      "pdf_url": "http://arxiv.org/pdf/2504.15209v1",
      "published": "2025-04-21T16:27:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.15209v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68T07 (Primary) 62M10, 65C60 (Secondary)",
        "I.2.7"
      ]
    },
    {
      "title": "Compute-Optimal LLMs Provably Generalize Better With Scale",
      "authors": [
        "Marc Finzi",
        "Sanyam Kapoor",
        "Diego Granziol",
        "Anming Gu",
        "Christopher De Sa",
        "J. Zico Kolter",
        "Andrew Gordon Wilson"
      ],
      "abstract": "Why do larger language models generalize better? To investigate this\nquestion, we develop generalization bounds on the pretraining objective of\nlarge language models (LLMs) in the compute-optimal regime, as described by the\nChinchilla scaling laws. We introduce a novel, fully empirical Freedman-type\nmartingale concentration inequality that tightens existing bounds by accounting\nfor the variance of the loss function. This generalization bound can be\ndecomposed into three interpretable components: the number of parameters per\ntoken, the loss variance, and the quantization error at a fixed bitrate. As\ncompute-optimal language models are scaled up, the number of parameters per\ndata point remains constant; however, both the loss variance and the\nquantization error decrease, implying that larger models should have smaller\ngeneralization gaps. We examine why larger models tend to be more quantizable\nfrom an information theoretic perspective, showing that the rate at which they\ncan integrate new information grows more slowly than their capacity on the\ncompute-optimal frontier. From these findings we produce a scaling law for the\ngeneralization gap, with bounds that become predictably stronger with scale.",
      "pdf_url": "http://arxiv.org/pdf/2504.15208v1",
      "published": "2025-04-21T16:26:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.15208v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Support Evaluation for the TREC 2024 RAG Track: Comparing Human versus LLM Judges",
      "authors": [
        "Nandan Thakur",
        "Ronak Pradeep",
        "Shivani Upadhyay",
        "Daniel Campos",
        "Nick Craswell",
        "Jimmy Lin"
      ],
      "abstract": "Retrieval-augmented generation (RAG) enables large language models (LLMs) to\ngenerate answers with citations from source documents containing \"ground\ntruth\", thereby reducing system hallucinations. A crucial factor in RAG\nevaluation is \"support\", whether the information in the cited documents\nsupports the answer. To this end, we conducted a large-scale comparative study\nof 45 participant submissions on 36 topics to the TREC 2024 RAG Track,\ncomparing an automatic LLM judge (GPT-4o) against human judges for support\nassessment. We considered two conditions: (1) fully manual assessments from\nscratch and (2) manual assessments with post-editing of LLM predictions. Our\nresults indicate that for 56% of the manual from-scratch assessments, human and\nGPT-4o predictions match perfectly (on a three-level scale), increasing to 72%\nin the manual with post-editing condition. Furthermore, by carefully analyzing\nthe disagreements in an unbiased study, we found that an independent human\njudge correlates better with GPT-4o than a human judge, suggesting that LLM\njudges can be a reliable alternative for support assessment. To conclude, we\nprovide a qualitative analysis of human and GPT-4o errors to help guide future\niterations of support assessment.",
      "pdf_url": "http://arxiv.org/pdf/2504.15205v1",
      "published": "2025-04-21T16:20:43+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.15205v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ]
    },
    {
      "title": "Zero-Shot, But at What Cost? Unveiling the Hidden Overhead of MILS's LLM-CLIP Framework for Image Captioning",
      "authors": [
        "Yassir Benhammou",
        "Alessandro Tiberio",
        "Gabriel Trautmann",
        "Suman Kalyan"
      ],
      "abstract": "MILS (Multimodal Iterative LLM Solver) is a recently published framework that\nclaims \"LLMs can see and hear without any training\" by leveraging an iterative,\nLLM-CLIP based approach for zero-shot image captioning. While this MILS\napproach demonstrates good performance, our investigation reveals that this\nsuccess comes at a hidden, substantial computational cost due to its expensive\nmulti-step refinement process. In contrast, alternative models such as BLIP-2\nand GPT-4V achieve competitive results through a streamlined, single-pass\napproach. We hypothesize that the significant overhead inherent in MILS's\niterative process may undermine its practical benefits, thereby challenging the\nnarrative that zero-shot performance can be attained without incurring heavy\nresource demands. This work is the first to expose and quantify the trade-offs\nbetween output quality and computational cost in MILS, providing critical\ninsights for the design of more efficient multimodal models.",
      "pdf_url": "http://arxiv.org/pdf/2504.15199v1",
      "published": "2025-04-21T16:16:19+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.15199v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.PF"
      ]
    },
    {
      "title": "Breast density in MRI: an AI-based quantification and relationship to assessment in mammography",
      "authors": [
        "Yaqian Chen",
        "Lin Li",
        "Hanxue Gu",
        "Haoyu Dong",
        "Derek L. Nguyen",
        "Allan D. Kirk",
        "Maciej A. Mazurowski",
        "E. Shelley Hwang"
      ],
      "abstract": "Mammographic breast density is a well-established risk factor for breast\ncancer. Recently there has been interest in breast MRI as an adjunct to\nmammography, as this modality provides an orthogonal and highly quantitative\nassessment of breast tissue. However, its 3D nature poses analytic challenges\nrelated to delineating and aggregating complex structures across slices. Here,\nwe applied an in-house machine-learning algorithm to assess breast density on\nnormal breasts in three MRI datasets. Breast density was consistent across\ndifferent datasets (0.104 - 0.114). Analysis across different age groups also\ndemonstrated strong consistency across datasets and confirmed a trend of\ndecreasing density with age as reported in previous studies. MR breast density\nwas correlated with mammographic breast density, although some notable\ndifferences suggest that certain breast density components are captured only on\nMRI. Future work will determine how to integrate MR breast density with current\ntools to improve future breast cancer risk prediction.",
      "pdf_url": "http://arxiv.org/pdf/2504.15192v1",
      "published": "2025-04-21T16:01:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.15192v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Synergistic Weak-Strong Collaboration by Aligning Preferences",
      "authors": [
        "Yizhu Jiao",
        "Xuchao Zhang",
        "Zhaoyang Wang",
        "Yubo Ma",
        "Zhun Deng",
        "Rujia Wang",
        "Chetan Bansal",
        "Saravan Rajmohan",
        "Jiawei Han",
        "Huaxiu Yao"
      ],
      "abstract": "Current Large Language Models (LLMs) excel in general reasoning yet struggle\nwith specialized tasks requiring proprietary or domain-specific knowledge.\nFine-tuning large models for every niche application is often infeasible due to\nblack-box constraints and high computational overhead. To address this, we\npropose a collaborative framework that pairs a specialized weak model with a\ngeneral strong model. The weak model, tailored to specific domains, produces\ninitial drafts and background information, while the strong model leverages its\nadvanced reasoning to refine these drafts, extending LLMs' capabilities to\ncritical yet specialized tasks. To optimize this collaboration, we introduce a\ncollaborative feedback to fine-tunes the weak model, which quantifies the\ninfluence of the weak model's contributions in the collaboration procedure and\nestablishes preference pairs to guide preference tuning of the weak model. We\nvalidate our framework through experiments on three domains. We find that the\ncollaboration significantly outperforms each model alone by leveraging\ncomplementary strengths. Moreover, aligning the weak model with the\ncollaborative preference further enhances overall performance.",
      "pdf_url": "http://arxiv.org/pdf/2504.15188v2",
      "published": "2025-04-21T15:57:33+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.15188v2",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Existing Industry Practice for the EU AI Act's General-Purpose AI Code of Practice Safety and Security Measures",
      "authors": [
        "Lily Stelling",
        "Mick Yang",
        "Rokas Gipiškis",
        "Leon Staufer",
        "Ze Shen Chin",
        "Siméon Campos",
        "Michael Chen"
      ],
      "abstract": "This report provides a detailed comparison between the measures proposed in\nthe EU AI Act's General-Purpose AI (GPAI) Code of Practice (Third Draft) and\ncurrent practices adopted by leading AI companies. As the EU moves toward\nenforcing binding obligations for GPAI model providers, the Code of Practice\nwill be key to bridging legal requirements with concrete technical commitments.\nOur analysis focuses on the draft's Safety and Security section which is only\nrelevant for the providers of the most advanced models (Commitments II.1-II.16)\nand excerpts from current public-facing documents quotes that are relevant to\neach individual measure.\n  We systematically reviewed different document types - including companies'\nfrontier safety frameworks and model cards - from over a dozen companies,\nincluding OpenAI, Anthropic, Google DeepMind, Microsoft, Meta, Amazon, and\nothers. This report is not meant to be an indication of legal compliance nor\ndoes it take any prescriptive viewpoint about the Code of Practice or\ncompanies' policies. Instead, it aims to inform the ongoing dialogue between\nregulators and GPAI model providers by surfacing evidence of precedent.",
      "pdf_url": "http://arxiv.org/pdf/2504.15181v1",
      "published": "2025-04-21T15:44:01+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.15181v1",
      "categories": [
        "cs.CY",
        "cs.AI"
      ]
    },
    {
      "title": "An Efficient Aerial Image Detection with Variable Receptive Fields",
      "authors": [
        "Liu Wenbin"
      ],
      "abstract": "Aerial object detection using unmanned aerial vehicles (UAVs) faces critical\nchallenges including sub-10px targets, dense occlusions, and stringent\ncomputational constraints. Existing detectors struggle to balance accuracy and\nefficiency due to rigid receptive fields and redundant architectures. To\naddress these limitations, we propose Variable Receptive Field DETR (VRF-DETR),\na transformer-based detector incorporating three key components: 1) Multi-Scale\nContext Fusion (MSCF) module that dynamically recalibrates features through\nadaptive spatial attention and gated multi-scale fusion, 2) Gated Convolution\n(GConv) layer enabling parameter-efficient local-context modeling via depthwise\nseparable operations and dynamic gating, and 3) Gated Multi-scale Fusion (GMCF)\nBottleneck that hierarchically disentangles occluded objects through cascaded\nglobal-local interactions. Experiments on VisDrone2019 demonstrate VRF-DETR\nachieves 51.4\\% mAP\\textsubscript{50} and 31.8\\% mAP\\textsubscript{50:95} with\nonly 13.5M parameters. This work establishes a new efficiency-accuracy Pareto\nfrontier for UAV-based detection tasks.",
      "pdf_url": "http://arxiv.org/pdf/2504.15165v1",
      "published": "2025-04-21T15:16:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.15165v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Landmark-Free Preoperative-to-Intraoperative Registration in Laparoscopic Liver Resection",
      "authors": [
        "Jun Zhou",
        "Bingchen Gao",
        "Kai Wang",
        "Jialun Pei",
        "Pheng-Ann Heng",
        "Jing Qin"
      ],
      "abstract": "Liver registration by overlaying preoperative 3D models onto intraoperative\n2D frames can assist surgeons in perceiving the spatial anatomy of the liver\nclearly for a higher surgical success rate. Existing registration methods rely\nheavily on anatomical landmark-based workflows, which encounter two major\nlimitations: 1) ambiguous landmark definitions fail to provide efficient\nmarkers for registration; 2) insufficient integration of intraoperative liver\nvisual information in shape deformation modeling. To address these challenges,\nin this paper, we propose a landmark-free preoperative-to-intraoperative\nregistration framework utilizing effective self-supervised learning, termed\n\\ourmodel. This framework transforms the conventional 3D-2D workflow into a\n3D-3D registration pipeline, which is then decoupled into rigid and non-rigid\nregistration subtasks. \\ourmodel~first introduces a feature-disentangled\ntransformer to learn robust correspondences for recovering rigid\ntransformations. Further, a structure-regularized deformation network is\ndesigned to adjust the preoperative model to align with the intraoperative\nliver surface. This network captures structural correlations through geometry\nsimilarity modeling in a low-rank transformer network. To facilitate the\nvalidation of the registration performance, we also construct an in-vivo\nregistration dataset containing liver resection videos of 21 patients, called\n\\emph{P2I-LReg}, which contains 346 keyframes that provide a global view of the\nliver together with liver mask annotations and calibrated camera intrinsic\nparameters. Extensive experiments and user studies on both synthetic and\nin-vivo datasets demonstrate the superiority and potential clinical\napplicability of our method.",
      "pdf_url": "http://arxiv.org/pdf/2504.15152v1",
      "published": "2025-04-21T14:55:57+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.15152v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Behavioral Universe Network (BUN): A Behavioral Information-Based Framework for Complex Systems",
      "authors": [
        "Wei Zhou",
        "Ailiya Borjigin",
        "Cong He"
      ],
      "abstract": "Modern digital ecosystems feature complex, dynamic interactions among\nautonomous entities across diverse domains. Traditional models often separate\nagents and objects, lacking a unified foundation to capture their interactive\nbehaviors. This paper introduces the Behavioral Universe Network (BUN), a\ntheoretical framework grounded in the Agent-Interaction-Behavior (AIB)\nformalism. BUN treats subjects (active agents), objects (resources), and\nbehaviors (operations) as first-class entities, all governed by a shared\nBehavioral Information Base (BIB). We detail the AIB core concepts and\ndemonstrate how BUN leverages information-driven triggers, semantic enrichment,\nand adaptive rules to coordinate multi-agent systems. We highlight key\nbenefits: enhanced behavior analysis, strong adaptability, and cross-domain\ninteroperability. We conclude by positioning BUN as a promising foundation for\nnext-generation digital governance and intelligent applications.",
      "pdf_url": "http://arxiv.org/pdf/2504.15146v1",
      "published": "2025-04-21T14:50:28+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.15146v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "C2RUST-BENCH: A Minimized, Representative Dataset for C-to-Rust Transpilation Evaluation",
      "authors": [
        "Melih Sirlanci",
        "Carter Yagemann",
        "Zhiqiang Lin"
      ],
      "abstract": "Despite the effort in vulnerability detection over the last two decades,\nmemory safety vulnerabilities continue to be a critical problem. Recent reports\nsuggest that the key solution is to migrate to memory-safe languages. To this\nend, C-to-Rust transpilation becomes popular to resolve memory-safety issues in\nC programs. Recent works propose C-to-Rust transpilation frameworks; however, a\ncomprehensive evaluation dataset is missing. Although one solution is to put\ntogether a large enough dataset, this increases the analysis time in automated\nframeworks as well as in manual efforts for some cases. In this work, we build\na method to select functions from a large set to construct a minimized yet\nrepresentative dataset to evaluate the C-to-Rust transpilation. We propose\nC2RUST-BENCH that contains 2,905 functions, which are representative of\nC-to-Rust transpilation, selected from 15,503 functions of real-world programs.",
      "pdf_url": "http://arxiv.org/pdf/2504.15144v1",
      "published": "2025-04-21T14:48:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.15144v1",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.PL"
      ]
    },
    {
      "title": "KGMEL: Knowledge Graph-Enhanced Multimodal Entity Linking",
      "authors": [
        "Juyeon Kim",
        "Geon Lee",
        "Taeuk Kim",
        "Kijung Shin"
      ],
      "abstract": "Entity linking (EL) aligns textual mentions with their corresponding entities\nin a knowledge base, facilitating various applications such as semantic search\nand question answering. Recent advances in multimodal entity linking (MEL) have\nshown that combining text and images can reduce ambiguity and improve alignment\naccuracy. However, most existing MEL methods overlook the rich structural\ninformation available in the form of knowledge-graph (KG) triples. In this\npaper, we propose KGMEL, a novel framework that leverages KG triples to enhance\nMEL. Specifically, it operates in three stages: (1) Generation: Produces\nhigh-quality triples for each mention by employing vision-language models based\non its text and images. (2) Retrieval: Learns joint mention-entity\nrepresentations, via contrastive learning, that integrate text, images, and\n(generated or KG) triples to retrieve candidate entities for each mention. (3)\nReranking: Refines the KG triples of the candidate entities and employs large\nlanguage models to identify the best-matching entity for the mention. Extensive\nexperiments on benchmark datasets demonstrate that KGMEL outperforms existing\nmethods. Our code and datasets are available at:\nhttps://github.com/juyeonnn/KGMEL.",
      "pdf_url": "http://arxiv.org/pdf/2504.15135v1",
      "published": "2025-04-21T14:38:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.15135v1",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "EasyEdit2: An Easy-to-use Steering Framework for Editing Large Language Models",
      "authors": [
        "Ziwen Xu",
        "Shuxun Wang",
        "Kewei Xu",
        "Haoming Xu",
        "Mengru Wang",
        "Xinle Deng",
        "Yunzhi Yao",
        "Guozhou Zheng",
        "Huajun Chen",
        "Ningyu Zhang"
      ],
      "abstract": "In this paper, we introduce EasyEdit2, a framework designed to enable\nplug-and-play adjustability for controlling Large Language Model (LLM)\nbehaviors. EasyEdit2 supports a wide range of test-time interventions,\nincluding safety, sentiment, personality, reasoning patterns, factuality, and\nlanguage features. Unlike its predecessor, EasyEdit2 features a new\narchitecture specifically designed for seamless model steering. It comprises\nkey modules such as the steering vector generator and the steering vector\napplier, which enable automatic generation and application of steering vectors\nto influence the model's behavior without modifying its parameters. One of the\nmain advantages of EasyEdit2 is its ease of use-users do not need extensive\ntechnical knowledge. With just a single example, they can effectively guide and\nadjust the model's responses, making precise control both accessible and\nefficient. Empirically, we report model steering performance across different\nLLMs, demonstrating the effectiveness of these techniques. We have released the\nsource code on GitHub at https://github.com/zjunlp/EasyEdit along with a\ndemonstration notebook. In addition, we provide a demo video at\nhttps://zjunlp.github.io/project/EasyEdit2/video for a quick introduction.",
      "pdf_url": "http://arxiv.org/pdf/2504.15133v1",
      "published": "2025-04-21T14:33:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.15133v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.HC",
        "cs.LG"
      ]
    },
    {
      "title": "Neural ATTF: A Scalable Solution to Lifelong Multi-Agent Path Planning",
      "authors": [
        "Kushal Shah",
        "Jihyun Park",
        "Seung-Kyum Choi"
      ],
      "abstract": "Multi-Agent Pickup and Delivery (MAPD) is a fundamental problem in robotics,\nparticularly in applications such as warehouse automation and logistics.\nExisting solutions often face challenges in scalability, adaptability, and\nefficiency, limiting their applicability in dynamic environments with real-time\nplanning requirements. This paper presents Neural ATTF (Adaptive Task Token\nFramework), a new algorithm that combines a Priority Guided Task Matching\n(PGTM) Module with Neural STA* (Space-Time A*), a data-driven path planning\nmethod. Neural STA* enhances path planning by enabling rapid exploration of the\nsearch space through guided learned heuristics and ensures collision avoidance\nunder dynamic constraints. PGTM prioritizes delayed agents and dynamically\nassigns tasks by prioritizing agents nearest to these tasks, optimizing both\ncontinuity and system throughput. Experimental evaluations against\nstate-of-the-art MAPD algorithms, including TPTS, CENTRAL, RMCA, LNS-PBS, and\nLNS-wPBS, demonstrate the superior scalability, solution quality, and\ncomputational efficiency of Neural ATTF. These results highlight the\nframework's potential for addressing the critical demands of complex,\nreal-world multi-agent systems operating in high-demand, unpredictable\nsettings.",
      "pdf_url": "http://arxiv.org/pdf/2504.15130v1",
      "published": "2025-04-21T14:25:32+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.15130v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "A General Infrastructure and Workflow for Quadrotor Deep Reinforcement Learning and Reality Deployment",
      "authors": [
        "Kangyao Huang",
        "Hao Wang",
        "Yu Luo",
        "Jingyu Chen",
        "Jintao Chen",
        "Xiangkui Zhang",
        "Xiangyang Ji",
        "Huaping Liu"
      ],
      "abstract": "Deploying robot learning methods to a quadrotor in unstructured outdoor\nenvironments is an exciting task. Quadrotors operating in real-world\nenvironments by learning-based methods encounter several challenges: a large\namount of simulator generated data required for training, strict demands for\nreal-time processing onboard, and the sim-to-real gap caused by dynamic and\nnoisy conditions. Current works have made a great breakthrough in applying\nlearning-based methods to end-to-end control of quadrotors, but rarely mention\nthe infrastructure system training from scratch and deploying to reality, which\nmakes it difficult to reproduce methods and applications. To bridge this gap,\nwe propose a platform that enables the seamless transfer of end-to-end deep\nreinforcement learning (DRL) policies. We integrate the training environment,\nflight dynamics control, DRL algorithms, the MAVROS middleware stack, and\nhardware into a comprehensive workflow and architecture that enables\nquadrotors' policies to be trained from scratch to real-world deployment in\nseveral minutes. Our platform provides rich types of environments including\nhovering, dynamic obstacle avoidance, trajectory tracking, balloon hitting, and\nplanning in unknown environments, as a physical experiment benchmark. Through\nextensive empirical validation, we demonstrate the efficiency of proposed\nsim-to-real platform, and robust outdoor flight performance under real-world\nperturbations. Details can be found from our website\nhttps://emnavi.tech/AirGym/.",
      "pdf_url": "http://arxiv.org/pdf/2504.15129v1",
      "published": "2025-04-21T14:25:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.15129v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ]
    },
    {
      "title": "Contemplative Wisdom for Superalignment",
      "authors": [
        "Ruben Laukkonen",
        "Fionn Inglis",
        "Shamil Chandaria",
        "Lars Sandved-Smith",
        "Jakob Hohwy",
        "Jonathan Gold",
        "Adam Elwood"
      ],
      "abstract": "As artificial intelligence (AI) improves, traditional alignment strategies\nmay falter in the face of unpredictable self-improvement, hidden subgoals, and\nthe sheer complexity of intelligent systems. Rather than externally\nconstraining behavior, we advocate designing AI with intrinsic morality built\ninto its cognitive architecture and world model. Inspired by contemplative\nwisdom traditions, we show how four axiomatic principles can instil a resilient\nWise World Model in AI systems. First, mindfulness enables self-monitoring and\nrecalibration of emergent subgoals. Second, emptiness forestalls dogmatic goal\nfixation and relaxes rigid priors. Third, non-duality dissolves adversarial\nself-other boundaries. Fourth, boundless care motivates the universal reduction\nof suffering. We find that prompting AI to reflect on these principles improves\nperformance on the AILuminate Benchmark using GPT-4o, particularly when\ncombined. We offer detailed implementation strategies for state-of-the-art\nmodels, including contemplative architectures, constitutions, and reinforcement\nof chain-of-thought. For future systems, the active inference framework may\noffer the self-organizing and dynamic coupling capabilities needed to enact\nthese insights in embodied agents. This interdisciplinary approach offers a\nself-correcting and resilient alternative to prevailing brittle control\nschemes.",
      "pdf_url": "http://arxiv.org/pdf/2504.15125v1",
      "published": "2025-04-21T14:20:49+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.15125v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Kuwain 1.5B: An Arabic SLM via Language Injection",
      "authors": [
        "Khalil Hennara",
        "Sara Chrouf",
        "Mohamed Motaism Hamed",
        "Zeina Aldallal",
        "Omar Hadid",
        "Safwan AlModhayan"
      ],
      "abstract": "Enhancing existing models with new knowledge is a crucial aspect of AI\ndevelopment. This paper introduces a novel method for integrating a new\nlanguage into a large language model (LLM). Our approach successfully\nincorporates a previously unseen target language into an existing LLM without\ncompromising its prior knowledge. We trained a tiny model with 1.5 billion\nparameters named Kuwain by injecting the Arabic language into a small\nopen-source model mainly trained in English. Our method demonstrates\nsignificant improvements in Arabic language performance, with an average 8%\nimprovement across various benchmarks, while retaining the model's existing\nknowledge with a minimum amount of the original model's data. This offers a\ncost-effective alternative to training a comprehensive model in both English\nand Arabic. The results highlight the potential for efficient, targeted\nlanguage model expansion without extensive retraining or resource-intensive\nprocesses.",
      "pdf_url": "http://arxiv.org/pdf/2504.15120v1",
      "published": "2025-04-21T14:17:25+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.15120v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "A triple-branch network for latent fingerprint enhancement guided by orientation fields and minutiae",
      "authors": [
        "Yurun Wang",
        "Zerong Qi",
        "Shujun Fu",
        "Mingzheng Hu"
      ],
      "abstract": "Latent fingerprint enhancement is a critical step in the process of latent\nfingerprint identification. Existing deep learning-based enhancement methods\nstill fall short of practical application requirements, particularly in\nrestoring low-quality fingerprint regions. Recognizing that different regions\nof latent fingerprints require distinct enhancement strategies, we propose a\nTriple Branch Spatial Fusion Network (TBSFNet), which simultaneously enhances\ndifferent regions of the image using tailored strategies. Furthermore, to\nimprove the generalization capability of the network, we integrate orientation\nfield and minutiae-related modules into TBSFNet and introduce a Multi-Level\nFeature Guidance Network (MLFGNet). Experimental results on the MOLF and MUST\ndatasets demonstrate that MLFGNet outperforms existing enhancement algorithms.",
      "pdf_url": "http://arxiv.org/pdf/2504.15105v1",
      "published": "2025-04-21T13:54:33+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.15105v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "NeuGaze: Reshaping the future BCI",
      "authors": [
        "Yiqian Yang"
      ],
      "abstract": "Traditional brain-computer interfaces (BCIs), reliant on costly\nelectroencephalography or invasive implants, struggle with complex\nhuman-computer interactions due to setup complexity and limited precision. We\npresent NeuGaze, a novel webcam-based system that leverages eye gaze, head\nmovements, and facial expressions to enable intuitive, real-time control using\nonly a standard 30 Hz webcam, often pre-installed in laptops. Requiring minimal\ncalibration, NeuGaze achieves performance comparable to conventional inputs,\nsupporting precise cursor navigation, key triggering via an efficient skill\nwheel, and dynamic gaming interactions, such as defeating formidable opponents\nin first-person games. By harnessing preserved neck-up functionalities in\nmotor-impaired individuals, NeuGaze eliminates the need for specialized\nhardware, offering a low-cost, accessible alternative to BCIs. This paradigm\nempowers diverse applications, from assistive technology to entertainment,\nredefining human-computer interaction for motor-impaired users. Project is at\n\\href{https://github.com/NeuSpeech/NeuGaze}{github.com/NeuSpeech/NeuGaze}.",
      "pdf_url": "http://arxiv.org/pdf/2504.15101v1",
      "published": "2025-04-21T13:49:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.15101v1",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.ET"
      ]
    },
    {
      "title": "Fast-Slow Co-advancing Optimizer: Toward Harmonious Adversarial Training of GAN",
      "authors": [
        "Lin Wang",
        "Xiancheng Wang",
        "Rui Wang",
        "Zhibo Zhang",
        "Minghang Zhao"
      ],
      "abstract": "Up to now, the training processes of typical Generative Adversarial Networks\n(GANs) are still particularly sensitive to data properties and hyperparameters,\nwhich may lead to severe oscillations, difficulties in convergence, or even\nfailures to converge, especially when the overall variances of the training\nsets are large. These phenomena are often attributed to the training\ncharacteristics of such networks. Aiming at the problem, this paper develops a\nnew intelligent optimizer, Fast-Slow Co-advancing Optimizer (FSCO), which\nemploys reinforcement learning in the training process of GANs to make training\neasier. Specifically, this paper allows the training step size to be controlled\nby an agent to improve training stability, and makes the training process more\nintelligent with variable learning rates, making GANs less sensitive to step\nsize. Experiments have been conducted on three benchmark datasets to verify the\neffectiveness of the developed FSCO.",
      "pdf_url": "http://arxiv.org/pdf/2504.15099v1",
      "published": "2025-04-21T13:41:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.15099v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Rethinking the Potential of Multimodality in Collaborative Problem Solving Diagnosis with Large Language Models",
      "authors": [
        "K. Wong",
        "B. Wu",
        "S. Bulathwela",
        "M. Cukurova"
      ],
      "abstract": "Detecting collaborative and problem-solving behaviours from digital traces to\ninterpret students' collaborative problem solving (CPS) competency is a\nlong-term goal in the Artificial Intelligence in Education (AIEd) field.\nAlthough multimodal data and advanced models are argued to have the potential\nto detect complex CPS behaviours, empirical evidence on their value remains\nlimited with some contrasting evidence. In this study, we investigated the\npotential of multimodal data to improve model performance in diagnosing 78\nsecondary school students' CPS subskills and indicators in authentic\neducational settings. In particular, text embeddings from verbal data and\nacoustic embeddings from audio data were used in a multimodal classification\nmodel for CPS diagnosis. Both unimodal and multimodal transformer-based models\noutperformed traditional models in detecting CPS classes. Although the\ninclusion of multimodality did not improve the performance of traditional\nunimodal models, its integration into transformer-based models demonstrated\nimproved performance for diagnosing social-cognitive CPS classes compared to\nunimodal transformer-based models. Based on the results, the paper argues that\nmultimodality and the selection of a particular modelling technique should not\nbe taken for granted to achieve the best performance in the automated detection\nof every CPS subskill and indicator. Rather, their value is limited to certain\ntypes of CPS indicators, affected by the complexity of the labels, and\ndependent on the composition of indicators in the dataset. We conclude the\npaper by discussing the required nuance when considering the value of LLMs and\nmultimodality in automated CPS diagnosis, highlighting the need for human-AI\ncomplementarity, and proposing the exploration of relevant model architectures\nand techniques to improve CPS diagnosis in authentic educational contexts.",
      "pdf_url": "http://arxiv.org/pdf/2504.15093v1",
      "published": "2025-04-21T13:25:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.15093v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Federated Latent Factor Model for Bias-Aware Recommendation with Privacy-Preserving",
      "authors": [
        "Junxiang Gao",
        "Yixin Ran",
        "Jia Chen"
      ],
      "abstract": "A recommender system (RS) aims to provide users with personalized item\nrecommendations, enhancing their overall experience. Traditional RSs collect\nand process all user data on a central server. However, this centralized\napproach raises significant privacy concerns, as it increases the risk of data\nbreaches and privacy leakages, which are becoming increasingly unacceptable to\nprivacy-sensitive users. To address these privacy challenges, federated\nlearning has been integrated into RSs, ensuring that user data remains secure.\nIn centralized RSs, the issue of rating bias is effectively addressed by\njointly analyzing all users' raw interaction data. However, this becomes a\nsignificant challenge in federated RSs, as raw data is no longer accessible due\nto privacy-preserving constraints. To overcome this problem, we propose a\nFederated Bias-Aware Latent Factor (FBALF) model. In FBALF, training bias is\nexplicitly incorporated into every local model's loss function, allowing for\nthe effective elimination of rating bias without compromising data privacy.\nExtensive experiments conducted on three real-world datasets demonstrate that\nFBALF achieves significantly higher recommendation accuracy compared to other\nstate-of-the-art federated RSs.",
      "pdf_url": "http://arxiv.org/pdf/2504.15090v1",
      "published": "2025-04-21T13:24:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.15090v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Empowering AI to Generate Better AI Code: Guided Generation of Deep Learning Projects with LLMs",
      "authors": [
        "Chen Xie",
        "Mingsheng Jiao",
        "Xiaodong Gu",
        "Beijun Shen"
      ],
      "abstract": "While large language models (LLMs) have been widely applied to code\ngeneration, they struggle with generating entire deep learning projects, which\nare characterized by complex structures, longer functions, and stronger\nreliance on domain knowledge than general-purpose code. An open-domain LLM\noften lacks coherent contextual guidance and domain expertise for specific\nprojects, making it challenging to produce complete code that fully meets user\nrequirements.\n  In this paper, we propose a novel planning-guided code generation method,\nDLCodeGen, tailored for generating deep learning projects. DLCodeGen predicts a\nstructured solution plan, offering global guidance for LLMs to generate the\nproject. The generated plan is then leveraged to retrieve semantically\nanalogous code samples and subsequently abstract a code template. To\neffectively integrate these multiple retrieval-augmented techniques, a\ncomparative learning mechanism is designed to generate the final code. We\nvalidate the effectiveness of our approach on a dataset we build for deep\nlearning code generation. Experimental results demonstrate that DLCodeGen\noutperforms other baselines, achieving improvements of 9.7% in CodeBLEU and\n3.6% in human evaluation metrics.",
      "pdf_url": "http://arxiv.org/pdf/2504.15080v1",
      "published": "2025-04-21T13:09:25+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.15080v1",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "Mitigating Degree Bias in Graph Representation Learning with Learnable Structural Augmentation and Structural Self-Attention",
      "authors": [
        "Van Thuy Hoang",
        "Hyeon-Ju Jeon",
        "O-Joun Lee"
      ],
      "abstract": "Graph Neural Networks (GNNs) update node representations through message\npassing, which is primarily based on the homophily principle, assuming that\nadjacent nodes share similar features. However, in real-world graphs with\nlong-tailed degree distributions, high-degree nodes dominate message passing,\ncausing a degree bias where low-degree nodes remain under-represented due to\ninadequate messages. The main challenge in addressing degree bias is how to\ndiscover non-adjacent nodes to provide additional messages to low-degree nodes\nwhile reducing excessive messages for high-degree nodes. Nevertheless,\nexploiting non-adjacent nodes to provide valuable messages is challenging, as\nit could generate noisy information and disrupt the original graph structures.\nTo solve it, we propose a novel Degree Fairness Graph Transformer, named\nDegFairGT, to mitigate degree bias by discovering structural similarities\nbetween non-adjacent nodes through learnable structural augmentation and\nstructural self-attention. Our key idea is to exploit non-adjacent nodes with\nsimilar roles in the same community to generate informative edges under our\naugmentation, which could provide informative messages between nodes with\nsimilar roles while ensuring that the homophily principle is maintained within\nthe community. To enable DegFairGT to learn such structural similarities, we\nthen propose a structural self-attention to capture the similarities between\nnode pairs. To preserve global graph structures and prevent graph augmentation\nfrom hindering graph structure, we propose a Self-Supervised Learning task to\npreserve p-step transition probability and regularize graph augmentation.\nExtensive experiments on six datasets showed that DegFairGT outperformed\nstate-of-the-art baselines in degree fairness analysis, node classification,\nand node clustering tasks.",
      "pdf_url": "http://arxiv.org/pdf/2504.15075v1",
      "published": "2025-04-21T13:03:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.15075v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Chinese-LiPS: A Chinese audio-visual speech recognition dataset with Lip-reading and Presentation Slides",
      "authors": [
        "Jinghua Zhao",
        "Yuhang Jia",
        "Shiyao Wang",
        "Jiaming Zhou",
        "Hui Wang",
        "Yong Qin"
      ],
      "abstract": "Incorporating visual modalities to assist Automatic Speech Recognition (ASR)\ntasks has led to significant improvements. However, existing Audio-Visual\nSpeech Recognition (AVSR) datasets and methods typically rely solely on\nlip-reading information or speaking contextual video, neglecting the potential\nof combining these different valuable visual cues within the speaking context.\nIn this paper, we release a multimodal Chinese AVSR dataset, Chinese-LiPS,\ncomprising 100 hours of speech, video, and corresponding manual transcription,\nwith the visual modality encompassing both lip-reading information and the\npresentation slides used by the speaker. Based on Chinese-LiPS, we develop a\nsimple yet effective pipeline, LiPS-AVSR, which leverages both lip-reading and\npresentation slide information as visual modalities for AVSR tasks. Experiments\nshow that lip-reading and presentation slide information improve ASR\nperformance by approximately 8\\% and 25\\%, respectively, with a combined\nperformance improvement of about 35\\%. The dataset is available at\nhttps://kiri0824.github.io/Chinese-LiPS/",
      "pdf_url": "http://arxiv.org/pdf/2504.15066v1",
      "published": "2025-04-21T12:51:54+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.15066v1",
      "categories": [
        "cs.MM",
        "cs.AI"
      ]
    },
    {
      "title": "Mining Characteristics of Vulnerable Smart Contracts Across Lifecycle Stages",
      "authors": [
        "Hongli Peng",
        "Xiaoqi Li",
        "Wenkai Li"
      ],
      "abstract": "Smart contracts are the cornerstone of decentralized applications and\nfinancial protocols, which extend the application of digital currency\ntransactions. The applications and financial protocols introduce significant\nsecurity challenges, resulting in substantial economic losses. Existing\nsolutions predominantly focus on code vulnerabilities within smart contracts,\naccounting for only 50% of security incidents. Therefore, a more comprehensive\nstudy of security issues related to smart contracts is imperative. The existing\nempirical research realizes the static analysis of smart contracts from the\nperspective of the lifecycle and gives the corresponding measures for each\nstage. However, they lack the characteristic analysis of vulnerabilities in\neach stage and the distinction between the vulnerabilities. In this paper, we\npresent the first empirical study on the security of smart contracts throughout\ntheir lifecycle, including deployment and execution, upgrade, and destruction\nstages. It delves into the security issues at each stage and provides at least\nseven feature descriptions. Finally, utilizing these seven features, five\nmachine-learning classification models are used to identify vulnerabilities at\ndifferent stages. The classification results reveal that vulnerable contracts\nexhibit distinct transaction features and ego network properties at various\nstages.",
      "pdf_url": "http://arxiv.org/pdf/2504.15063v1",
      "published": "2025-04-21T12:42:59+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.15063v1",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "title": "OPO: Making Decision-Focused Data Acquisition Decisions",
      "authors": [
        "Egon Peršak",
        "Miguel F. Anjos"
      ],
      "abstract": "We propose a model for making data acquisition decisions for variables in\ncontextual stochastic optimisation problems. Data acquisition decisions are\ntypically treated as separate and fixed. We explore problem settings in which\nthe acquisition of contextual variables is costly and consequently constrained.\nThe data acquisition problem is often solved heuristically for proxy objectives\nsuch as coverage. The more intuitive objective is the downstream decision\nquality as a result of data acquisition decisions. The whole pipeline can be\ncharacterised as an optimise-then-predict-then-optimise (OPO) problem.\nAnalogously, much recent research has focused on how to integrate prediction\nand optimisation (PO) in the form of decision-focused learning. We propose\nleveraging differentiable optimisation to extend the integration to data\nacquisition. We solve the data acquisition problem with well-defined\nconstraints by learning a surrogate linear objective function. We demonstrate\nan application of this model on a shortest path problem for which we first have\nto set a drone reconnaissance strategy to capture image segments serving as\ninputs to a model that predicts travel costs. We ablate the problem with a\nnumber of training modalities and demonstrate that the differentiable\noptimisation approach outperforms random search strategies.",
      "pdf_url": "http://arxiv.org/pdf/2504.15062v1",
      "published": "2025-04-21T12:41:35+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.15062v1",
      "categories": [
        "math.OC",
        "cs.AI"
      ]
    },
    {
      "title": "VeLU: Variance-enhanced Learning Unit for Deep Neural Networks",
      "authors": [
        "Ashkan Shakarami",
        "Yousef Yeganeh",
        "Azade Farshad",
        "Lorenzo Nicolè",
        "Stefano Ghidoni",
        "Nassir Navab"
      ],
      "abstract": "Activation functions are fundamental in deep neural networks and directly\nimpact gradient flow, optimization stability, and generalization. Although ReLU\nremains standard because of its simplicity, it suffers from vanishing gradients\nand lacks adaptability. Alternatives like Swish and GELU introduce smooth\ntransitions, but fail to dynamically adjust to input statistics. We propose\nVeLU, a Variance-enhanced Learning Unit as an activation function that\ndynamically scales based on input variance by integrating ArcTan-Sin\ntransformations and Wasserstein-2 regularization, effectively mitigating\ncovariate shifts and stabilizing optimization. Extensive experiments on\nViT_B16, VGG19, ResNet50, DenseNet121, MobileNetV2, and EfficientNetB3 confirm\nVeLU's superiority over ReLU, ReLU6, Swish, and GELU on six vision benchmarks.\nThe codes of VeLU are publicly available on GitHub.",
      "pdf_url": "http://arxiv.org/pdf/2504.15051v1",
      "published": "2025-04-21T12:20:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.15051v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Text-to-Decision Agent: Learning Generalist Policies from Natural Language Supervision",
      "authors": [
        "Shilin Zhang",
        "Zican Hu",
        "Wenhao Wu",
        "Xinyi Xie",
        "Jianxiang Tang",
        "Chunlin Chen",
        "Daoyi Dong",
        "Yu Cheng",
        "Zhenhong Sun",
        "Zhi Wang"
      ],
      "abstract": "RL systems usually tackle generalization by inferring task beliefs from\nhigh-quality samples or warmup explorations. The restricted form limits their\ngenerality and usability since these supervision signals are expensive and even\ninfeasible to acquire in advance for unseen tasks. Learning directly from the\nraw text about decision tasks is a promising alternative to leverage a much\nbroader source of supervision. In the paper, we propose Text-to-Decision Agent\n(T2DA), a simple and scalable framework that supervises generalist policy\nlearning with natural language. We first introduce a generalized world model to\nencode multi-task decision data into a dynamics-aware embedding space. Then,\ninspired by CLIP, we predict which textual description goes with which decision\nembedding, effectively bridging their semantic gap via contrastive\nlanguage-decision pre-training and aligning the text embeddings to comprehend\nthe environment dynamics. After training the text-conditioned generalist\npolicy, the agent can directly realize zero-shot text-to-decision generation in\nresponse to language instructions. Comprehensive experiments on MuJoCo and\nMeta-World benchmarks show that T2DA facilitates high-capacity zero-shot\ngeneralization and outperforms various types of baselines.",
      "pdf_url": "http://arxiv.org/pdf/2504.15046v2",
      "published": "2025-04-21T12:00:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.15046v2",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Beyond Terabit/s Integrated Neuromorphic Photonic Processor for DSP-Free Optical Interconnects",
      "authors": [
        "Benshan Wang",
        "Qiarong Xiao",
        "Tengji Xu",
        "Li Fan",
        "Shaojie Liu",
        "Jianji Dong",
        "Junwen Zhang",
        "Chaoran Huang"
      ],
      "abstract": "The rapid expansion of generative AI drives unprecedented demands for\nhigh-performance computing. Training large-scale AI models now requires vast\ninterconnected GPU clusters across multiple data centers. Multi-scale AI\ntraining and inference demand uniform, ultra-low latency, and energy-efficient\nlinks to enable massive GPUs to function as a single cohesive unit. However,\ntraditional electrical and optical interconnects, relying on conventional\ndigital signal processors (DSPs) for signal distortion compensation,\nincreasingly fail to meet these stringent requirements. To overcome these\nlimitations, we present an integrated neuromorphic optical signal processor\n(OSP) that leverages deep reservoir computing and achieves DSP-free,\nall-optical, real-time processing. Experimentally, our OSP achieves a 100 Gbaud\nPAM4 per lane, 1.6 Tbit/s data center interconnect over a 5 km optical fiber in\nthe C-band (equivalent to over 80 km in the O-band), far exceeding the reach of\nstate-of-the-art DSP solutions, which are fundamentally constrained by\nchromatic dispersion in IMDD systems. Simultaneously, it reduces processing\nlatency by four orders of magnitude and energy consumption by three orders of\nmagnitude. Unlike DSPs, which introduce increased latency at high data rates,\nour OSP maintains consistent, ultra-low latency regardless of data rate\nscaling, making it ideal for future optical interconnects. Moreover, the OSP\nretains full optical field information for better impairment compensation and\nadapts to various modulation formats, data rates, and wavelengths. Fabricated\nusing a mature silicon photonic process, the OSP can be monolithically\nintegrated with silicon photonic transceivers, enhancing the compactness and\nreliability of all-optical interconnects. This research provides a highly\nscalable, energy-efficient, and high-speed solution, paving the way for\nnext-generation AI infrastructure.",
      "pdf_url": "http://arxiv.org/pdf/2504.15044v1",
      "published": "2025-04-21T11:56:36+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.15044v1",
      "categories": [
        "physics.optics",
        "cs.AI",
        "cs.ET"
      ]
    },
    {
      "title": "Distribution-aware Forgetting Compensation for Exemplar-Free Lifelong Person Re-identification",
      "authors": [
        "Shiben Liu",
        "Huijie Fan",
        "Qiang Wang",
        "Baojie Fan",
        "Yandong Tang",
        "Liangqiong Qu"
      ],
      "abstract": "Lifelong Person Re-identification (LReID) suffers from a key challenge in\npreserving old knowledge while adapting to new information. The existing\nsolutions include rehearsal-based and rehearsal-free methods to address this\nchallenge. Rehearsal-based approaches rely on knowledge distillation,\ncontinuously accumulating forgetting during the distillation process.\nRehearsal-free methods insufficiently learn the distribution of each domain,\nleading to forgetfulness over time. To solve these issues, we propose a novel\nDistribution-aware Forgetting Compensation (DAFC) model that explores\ncross-domain shared representation learning and domain-specific distribution\nintegration without using old exemplars or knowledge distillation. We propose a\nText-driven Prompt Aggregation (TPA) that utilizes text features to enrich\nprompt elements and guide the prompt model to learn fine-grained\nrepresentations for each instance. This can enhance the differentiation of\nidentity information and establish the foundation for domain distribution\nawareness. Then, Distribution-based Awareness and Integration (DAI) is designed\nto capture each domain-specific distribution by a dedicated expert network and\nadaptively consolidate them into a shared region in high-dimensional space. In\nthis manner, DAI can consolidate and enhance cross-domain shared representation\nlearning while alleviating catastrophic forgetting. Furthermore, we develop a\nKnowledge Consolidation Mechanism (KCM) that comprises instance-level\ndiscrimination and cross-domain consistency alignment strategies to facilitate\nmodel adaptive learning of new knowledge from the current domain and promote\nknowledge consolidation learning between acquired domain-specific\ndistributions, respectively. Experimental results show that our DAFC\noutperforms state-of-the-art methods. Our code is available at\nhttps://github.com/LiuShiBen/DAFC.",
      "pdf_url": "http://arxiv.org/pdf/2504.15041v2",
      "published": "2025-04-21T11:53:43+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.15041v2",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "SOLIDO: A Robust Watermarking Method for Speech Synthesis via Low-Rank Adaptation",
      "authors": [
        "Yue Li",
        "Weizhi Liu",
        "Dongdong Lin"
      ],
      "abstract": "The accelerated advancement of speech generative models has given rise to\nsecurity issues, including model infringement and unauthorized abuse of\ncontent. Although existing generative watermarking techniques have proposed\ncorresponding solutions, most methods require substantial computational\noverhead and training costs. In addition, some methods have limitations in\nrobustness when handling variable-length inputs. To tackle these challenges, we\npropose \\textsc{SOLIDO}, a novel generative watermarking method that integrates\nparameter-efficient fine-tuning with speech watermarking through low-rank\nadaptation (LoRA) for speech diffusion models. Concretely, the watermark\nencoder converts the watermark to align with the input of diffusion models. To\nachieve precise watermark extraction from variable-length inputs, the watermark\ndecoder based on depthwise separable convolution is designed for watermark\nrecovery. To further enhance speech generation performance and watermark\nextraction capability, we propose a speech-driven lightweight fine-tuning\nstrategy, which reduces computational overhead through LoRA. Comprehensive\nexperiments demonstrate that the proposed method ensures high-fidelity\nwatermarked speech even at a large capacity of 2000 bps. Furthermore, against\ncommon individual and compound speech attacks, our SOLIDO achieves a maximum\naverage extraction accuracy of 99.20\\% and 98.43\\%, respectively. It surpasses\nother state-of-the-art methods by nearly 23\\% in resisting time-stretching\nattacks.",
      "pdf_url": "http://arxiv.org/pdf/2504.15035v1",
      "published": "2025-04-21T11:43:36+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.15035v1",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.SD"
      ]
    },
    {
      "title": "Trainable Quantum Neural Network for Multiclass Image Classification with the Power of Pre-trained Tree Tensor Networks",
      "authors": [
        "Keisuke Murota",
        "Takumi Kobori"
      ],
      "abstract": "Tree tensor networks (TTNs) offer powerful models for image classification.\nWhile these TTN image classifiers already show excellent performance on\nclassical hardware, embedding them into quantum neural networks (QNNs) may\nfurther improve the performance by leveraging quantum resources. However,\nembedding TTN classifiers into QNNs for multiclass classification remains\nchallenging. Key obstacles are the highorder gate operations required for large\nbond dimensions and the mid-circuit postselection with exponentially low\nsuccess rates necessary for the exact embedding. In this work, to address these\nchallenges, we propose forest tensor network (FTN)-classifiers, which aggregate\nmultiple small-bond-dimension TTNs. This allows us to handle multiclass\nclassification without requiring large gates in the embedded circuits. We then\nremove the overhead of mid-circuit postselection by extending the adiabatic\nencoding framework to our setting and smoothly encode the FTN-classifiers into\na quantum forest tensor network (qFTN)- classifiers. Numerical experiments on\nMNIST and CIFAR-10 demonstrate that we can successfully train FTN-classifiers\nand encode them into qFTN-classifiers, while maintaining or even improving the\nperformance of the pre-trained FTN-classifiers. These results suggest that\nsynergy between TTN classification models and QNNs can provide a robust and\nscalable framework for multiclass quantum-enhanced image classification.",
      "pdf_url": "http://arxiv.org/pdf/2504.14995v1",
      "published": "2025-04-21T09:51:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.14995v1",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "aiXamine: LLM Safety and Security Simplified",
      "authors": [
        "Fatih Deniz",
        "Dorde Popovic",
        "Yazan Boshmaf",
        "Euisuh Jeong",
        "Minhaj Ahmad",
        "Sanjay Chawla",
        "Issa Khalil"
      ],
      "abstract": "Evaluating Large Language Models (LLMs) for safety and security remains a\ncomplex task, often requiring users to navigate a fragmented landscape of ad\nhoc benchmarks, datasets, metrics, and reporting formats. To address this\nchallenge, we present aiXamine, a comprehensive black-box evaluation platform\nfor LLM safety and security. aiXamine integrates over 40 tests (i.e.,\nbenchmarks) organized into eight key services targeting specific dimensions of\nsafety and security: adversarial robustness, code security, fairness and bias,\nhallucination, model and data privacy, out-of-distribution (OOD) robustness,\nover-refusal, and safety alignment. The platform aggregates the evaluation\nresults into a single detailed report per model, providing a detailed breakdown\nof model performance, test examples, and rich visualizations. We used aiXamine\nto assess over 50 publicly available and proprietary LLMs, conducting over 2K\nexaminations. Our findings reveal notable vulnerabilities in leading models,\nincluding susceptibility to adversarial attacks in OpenAI's GPT-4o, biased\noutputs in xAI's Grok-3, and privacy weaknesses in Google's Gemini 2.0.\nAdditionally, we observe that open-source models can match or exceed\nproprietary models in specific services such as safety alignment, fairness and\nbias, and OOD robustness. Finally, we identify trade-offs between distillation\nstrategies, model size, training methods, and architectural choices.",
      "pdf_url": "http://arxiv.org/pdf/2504.14985v1",
      "published": "2025-04-21T09:26:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.14985v1",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "title": "Evaluating Code Generation of LLMs in Advanced Computer Science Problems",
      "authors": [
        "Emir Catir",
        "Robin Claesson",
        "Rodothea Myrsini Tsoupidi"
      ],
      "abstract": "Large Language Models (LLMs), such as GitHub Copilot and ChatGPT have become\npopular among programming students. Students use LLMs to assist them in\nprogramming courses, including generating source code. Previous work has\nevaluated the ability of LLMs in solving introductory-course programming\nassignments. The results have shown that LLMs are highly effective in\ngenerating code for introductory Computer Science (CS) courses. However, there\nis a gap in research on evaluating LLMs' ability to generate code that solves\nadvanced programming assignments. In this work, we evaluate the ability of four\nLLM tools to solve programming assignments from advanced CS courses in three\npopular programming languages, Java, Python, and C. We manually select 12\nproblems, three problems from introductory courses as the baseline and nine\nprogramming assignments from second- and third-year CS courses. To evaluate the\nLLM-generated code, we generate a test suite of 1000 test cases per problem and\nanalyze the program output. Our evaluation shows that although LLMs are highly\neffective in generating source code for introductory programming courses,\nsolving advanced programming assignments is more challenging. Nonetheless, in\nmany cases, LLMs identify the base problem and provide partial solutions that\nmay be useful to CS students. Furthermore, our results may provide useful\nguidance for teachers of advanced programming courses on how to design\nprogramming assignments.",
      "pdf_url": "http://arxiv.org/pdf/2504.14964v1",
      "published": "2025-04-21T08:45:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.14964v1",
      "categories": [
        "cs.AI",
        "cs.CY"
      ]
    },
    {
      "title": "Speaker Fuzzy Fingerprints: Benchmarking Text-Based Identification in Multiparty Dialogues",
      "authors": [
        "Rui Ribeiro",
        "Luísa Coheur",
        "Joao P. Carvalho"
      ],
      "abstract": "Speaker identification using voice recordings leverages unique acoustic\nfeatures, but this approach fails when only textual data is available. Few\napproaches have attempted to tackle the problem of identifying speakers solely\nfrom text, and the existing ones have primarily relied on traditional methods.\nIn this work, we explore the use of fuzzy fingerprints from large pre-trained\nmodels to improve text-based speaker identification. We integrate\nspeaker-specific tokens and context-aware modeling, demonstrating that\nconversational context significantly boosts accuracy, reaching 70.6% on the\nFriends dataset and 67.7% on the Big Bang Theory dataset. Additionally, we show\nthat fuzzy fingerprints can approximate full fine-tuning performance with fewer\nhidden units, offering improved interpretability. Finally, we analyze ambiguous\nutterances and propose a mechanism to detect speaker-agnostic lines. Our\nfindings highlight key challenges and provide insights for future improvements\nin text-based speaker identification.",
      "pdf_url": "http://arxiv.org/pdf/2504.14963v1",
      "published": "2025-04-21T08:44:33+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.14963v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CE",
        "cs.LG",
        "cs.NE"
      ]
    },
    {
      "title": "Generative Semantic Communications: Principles and Practices",
      "authors": [
        "Xiaojun Yuan",
        "Haoming Ma",
        "Yinuo Huang",
        "Zhoufan Hua",
        "Yong Zuo",
        "Zhi Ding"
      ],
      "abstract": "Semantic communication leverages artificial intelligence (AI) technologies to\nextract semantic information from data for efficient transmission, theraby\nsignificantly reducing communication cost. With the evolution towards\nartificial general intelligence (AGI), the increasing demands for AGI services\npose new challenges to semantic communication. In response, we propose a new\nparadigm for AGI-driven communications, called generative semantic\ncommunication (GSC), which utilizes advanced AI technologies such as foundation\nmodels and generative models. We first describe the basic concept of GSC and\nits difference from existing semantic communications, and then introduce a\ngeneral framework of GSC, followed by two case studies to verify the advantages\nof GSC in AGI-driven applications. Finally, open challenges and new research\ndirections are discussed to stimulate this line of research and pave the way\nfor practical applications.",
      "pdf_url": "http://arxiv.org/pdf/2504.14947v1",
      "published": "2025-04-21T08:10:59+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.14947v1",
      "categories": [
        "cs.AI",
        "eess.IV",
        "eess.SP"
      ]
    },
    {
      "title": "Learning to Reason under Off-Policy Guidance",
      "authors": [
        "Jianhao Yan",
        "Yafu Li",
        "Zican Hu",
        "Zhi Wang",
        "Ganqu Cui",
        "Xiaoye Qu",
        "Yu Cheng",
        "Yue Zhang"
      ],
      "abstract": "Recent advances in large reasoning models (LRMs) demonstrate that\nsophisticated behaviors such as multi-step reasoning and self-reflection can\nemerge via reinforcement learning (RL) with simple rule-based rewards. However,\nexisting zero-RL approaches are inherently ``on-policy'', limiting learning to\na model's own outputs and failing to acquire reasoning abilities beyond its\ninitial capabilities. We introduce LUFFY (Learning to reason Under oFF-policY\nguidance), a framework that augments zero-RL with off-policy reasoning traces.\nLUFFY dynamically balances imitation and exploration by combining off-policy\ndemonstrations with on-policy rollouts during training. Notably, we propose\npolicy shaping via regularized importance sampling to avoid superficial and\nrigid imitation during mixed-policy training. Remarkably, LUFFY achieves an\nover +7.0 average gain across six math benchmarks and an advantage of over +6.2\npoints in out-of-distribution tasks. It also substantially surpasses\nimitation-based supervised fine-tuning (SFT), particularly in generalization.\nAnalysis shows LUFFY not only imitates effectively but also explores beyond\ndemonstrations, offering a scalable path to train generalizable reasoning\nmodels with off-policy guidance.",
      "pdf_url": "http://arxiv.org/pdf/2504.14945v1",
      "published": "2025-04-21T08:09:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.14945v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    }
  ]
}