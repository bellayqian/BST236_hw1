{
  "last_updated": "2026-01-29T01:06:06.753490",
  "papers": [
    {
      "title": "M-SGWR: Multiscale Similarity and Geographically Weighted Regression",
      "authors": [
        "M. Naser Lessani",
        "Zhenlong Li",
        "Manzhu Yu",
        "Helen Greatrex",
        "Chan Shen"
      ],
      "abstract": "The first law of geography is a cornerstone of spatial analysis, emphasizing that nearby and related locations tend to be more similar, however, defining what constitutes \"near\" and \"related\" remains challenging, as different phenomena exhibit distinct spatial patterns. Traditional local regression models, such as Geographically Weighted Regression (GWR) and Multiscale GWR (MGWR), quantify spatial relationships solely through geographic proximity. In an era of globalization and digital connectivity, however, geographic proximity alone may be insufficient to capture how locations are interconnected. To address this limitation, we propose a new multiscale local regression framework, termed M-SGWR, which characterizes spatial interaction across two dimensions: geographic proximity and attribute (variable) similarity. For each predictor, geographic and attribute-based weight matrices are constructed separately and then combined using an optimized parameter, alpha, which governs their relative contribution to local model fitting. Analogous to variable-specific bandwidths in MGWR, the optimal alpha varies by predictor, allowing the model to flexibly account for geographic, mixed, or non-spatial (remote similarity) effects. Results from two simulation experiments and one empirical application demonstrate that M-SGWR consistently outperforms GWR, SGWR, and MGWR across all goodness-of-fit metrics.",
      "pdf_url": "https://arxiv.org/pdf/2601.19888v1",
      "published": "2026-01-27T18:55:12+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.19888v1",
      "categories": [
        "stat.ME",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "AI Cap-and-Trade: Efficiency Incentives for Accessibility and Sustainability",
      "authors": [
        "Marco Bornstein",
        "Amrit Singh Bedi"
      ],
      "abstract": "The race for artificial intelligence (AI) dominance often prioritizes scale over efficiency. Hyper-scaling is the common industry approach: larger models, more data, and as many computational resources as possible. Using more resources is a simpler path to improved AI performance. Thus, efficiency has been de-emphasized. Consequently, the need for costly computational resources has marginalized academics and smaller companies. Simultaneously, increased energy expenditure, due to growing AI use, has led to mounting environmental costs. In response to accessibility and sustainability concerns, we argue for research into, and implementation of, market-based methods that incentivize AI efficiency. We believe that incentivizing efficient operations and approaches will reduce emissions while opening new opportunities for academics and smaller companies. As a call to action, we propose a cap-and-trade system for AI. Our system provably reduces computations for AI deployment, thereby lowering emissions and monetizing efficiency to the benefit of of academics and smaller companies.",
      "pdf_url": "https://arxiv.org/pdf/2601.19886v1",
      "published": "2026-01-27T18:53:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.19886v1",
      "categories": [
        "econ.GN",
        "cs.AI",
        "cs.CY",
        "cs.GT"
      ]
    },
    {
      "title": "HARMONI: Multimodal Personalization of Multi-User Human-Robot Interactions with LLMs",
      "authors": [
        "Jeanne Malécot",
        "Hamed Rahimi",
        "Jeanne Cattoni",
        "Marie Samson",
        "Mouad Abrini",
        "Mahdi Khoramshahi",
        "Maribel Pino",
        "Mohamed Chetouani"
      ],
      "abstract": "Existing human-robot interaction systems often lack mechanisms for sustained personalization and dynamic adaptation in multi-user environments, limiting their effectiveness in real-world deployments. We present HARMONI, a multimodal personalization framework that leverages large language models to enable socially assistive robots to manage long-term multi-user interactions. The framework integrates four key modules: (i) a perception module that identifies active speakers and extracts multimodal input; (ii) a world modeling module that maintains representations of the environment and short-term conversational context; (iii) a user modeling module that updates long-term speaker-specific profiles; and (iv) a generation module that produces contextually grounded and ethically informed responses. Through extensive evaluation and ablation studies on four datasets, as well as a real-world scenario-driven user-study in a nursing home environment, we demonstrate that HARMONI supports robust speaker identification, online memory updating, and ethically aligned personalization, outperforming baseline LLM-driven approaches in user modeling accuracy, personalization quality, and user satisfaction.",
      "pdf_url": "https://arxiv.org/pdf/2601.19839v1",
      "published": "2026-01-27T17:45:04+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.19839v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.HC"
      ]
    },
    {
      "title": "Visual Generation Unlocks Human-Like Reasoning through Multimodal World Models",
      "authors": [
        "Jialong Wu",
        "Xiaoying Zhang",
        "Hongyi Yuan",
        "Xiangcheng Zhang",
        "Tianhao Huang",
        "Changjing He",
        "Chaoyi Deng",
        "Renrui Zhang",
        "Youbin Wu",
        "Mingsheng Long"
      ],
      "abstract": "Humans construct internal world models and reason by manipulating the concepts within these models. Recent advances in AI, particularly chain-of-thought (CoT) reasoning, approximate such human cognitive abilities, where world models are believed to be embedded within large language models. Expert-level performance in formal and abstract domains such as mathematics and programming has been achieved in current systems by relying predominantly on verbal reasoning. However, they still lag far behind humans in domains like physical and spatial intelligence, which require richer representations and prior knowledge. The emergence of unified multimodal models (UMMs) capable of both verbal and visual generation has therefore sparked interest in more human-like reasoning grounded in complementary multimodal pathways, though their benefits remain unclear. From a world-model perspective, this paper presents the first principled study of when and how visual generation benefits reasoning. Our key position is the visual superiority hypothesis: for certain tasks--particularly those grounded in the physical world--visual generation more naturally serves as world models, whereas purely verbal world models encounter bottlenecks arising from representational limitations or insufficient prior knowledge. Theoretically, we formalize internal world modeling as a core component of CoT reasoning and analyze distinctions among different forms of world models. Empirically, we identify tasks that necessitate interleaved visual-verbal CoT reasoning, constructing a new evaluation suite, VisWorld-Eval. Controlled experiments on a state-of-the-art UMM show that interleaved CoT significantly outperforms purely verbal CoT on tasks that favor visual world modeling, but offers no clear advantage otherwise. Together, this work clarifies the potential of multimodal world modeling for more powerful, human-like multimodal AI.",
      "pdf_url": "https://arxiv.org/pdf/2601.19834v1",
      "published": "2026-01-27T17:40:07+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.19834v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "When Iterative RAG Beats Ideal Evidence: A Diagnostic Study in Scientific Multi-hop Question Answering",
      "authors": [
        "Mahdi Astaraki",
        "Mohammad Arshi Saloot",
        "Ali Shiraee Kasmaee",
        "Hamidreza Mahyar",
        "Soheila Samiee"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) extends large language models (LLMs) beyond parametric knowledge, yet it is unclear when iterative retrieval-reasoning loops meaningfully outperform static RAG, particularly in scientific domains with multi-hop reasoning, sparse domain knowledge, and heterogeneous evidence. We provide the first controlled, mechanism-level diagnostic study of whether synchronized iterative retrieval and reasoning can surpass an idealized static upper bound (Gold Context) RAG. We benchmark eleven state-of-the-art LLMs under three regimes: (i) No Context, measuring reliance on parametric memory; (ii) Gold Context, where all oracle evidence is supplied at once; and (iii) Iterative RAG, a training-free controller that alternates retrieval, hypothesis refinement, and evidence-aware stopping. Using the chemistry-focused ChemKGMultiHopQA dataset, we isolate questions requiring genuine retrieval and analyze behavior with diagnostics spanning retrieval coverage gaps, anchor-carry drop, query quality, composition fidelity, and control calibration. Across models, Iterative RAG consistently outperforms Gold Context, with gains up to 25.6 percentage points, especially for non-reasoning fine-tuned models. Staged retrieval reduces late-hop failures, mitigates context overload, and enables dynamic correction of early hypothesis drift, but remaining failure modes include incomplete hop coverage, distractor latch trajectories, early stopping miscalibration, and high composition failure rates even with perfect retrieval. Overall, staged retrieval is often more influential than the mere presence of ideal evidence; we provide practical guidance for deploying and diagnosing RAG systems in specialized scientific settings and a foundation for more reliable, controllable iterative retrieval-reasoning frameworks.",
      "pdf_url": "https://arxiv.org/pdf/2601.19827v1",
      "published": "2026-01-27T17:35:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.19827v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ]
    },
    {
      "title": "Routing End User Queries to Enterprise Databases",
      "authors": [
        "Saikrishna Sudarshan",
        "Tanay Kulkarni",
        "Manasi Patwardhan",
        "Lovekesh Vig",
        "Ashwin Srinivasan",
        "Tanmay Tulsidas Verlekar"
      ],
      "abstract": "We address the task of routing natural language queries in multi-database enterprise environments. We construct realistic benchmarks by extending existing NL-to-SQL datasets. Our study shows that routing becomes increasingly challenging with larger, domain-overlapping DB repositories and ambiguous queries, motivating the need for more structured and robust reasoning-based solutions. By explicitly modelling schema coverage, structural connectivity, and fine-grained semantic alignment, the proposed modular, reasoning-driven reranking strategy consistently outperforms embedding-only and direct LLM-prompting baselines across all the metrics.",
      "pdf_url": "https://arxiv.org/pdf/2601.19825v1",
      "published": "2026-01-27T17:30:19+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.19825v1",
      "categories": [
        "cs.AI",
        "cs.DB"
      ]
    },
    {
      "title": "An Interpretable Recommendation Model for Psychometric Data, With an Application to Gerontological Primary Care",
      "authors": [
        "Andre Paulino de Lima",
        "Paula Castro",
        "Suzana Carvalho Vaz de Andrade",
        "Rosa Maria Marcucci",
        "Ruth Caldeira de Melo",
        "Marcelo Garcia Manzato"
      ],
      "abstract": "There are challenges that must be overcome to make recommender systems useful in healthcare settings. The reasons are varied: the lack of publicly available clinical data, the difficulty that users may have in understanding the reasons why a recommendation was made, the risks that may be involved in following that recommendation, and the uncertainty about its effectiveness. In this work, we address these challenges with a recommendation model that leverages the structure of psychometric data to provide visual explanations that are faithful to the model and interpretable by care professionals. We focus on a narrow healthcare niche, gerontological primary care, to show that the proposed recommendation model can assist the attending professional in the creation of personalised care plans. We report results of a comparative offline performance evaluation of the proposed model on healthcare datasets that were collected by research partners in Brazil, as well as the results of a user study that evaluates the interpretability of the visual explanations the model generates. The results suggest that the proposed model can advance the application of recommender systems in this healthcare niche, which is expected to grow in demand , opportunities, and information technology needs as demographic changes become more pronounced.",
      "pdf_url": "https://arxiv.org/pdf/2601.19824v1",
      "published": "2026-01-27T17:29:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.19824v1",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.IR",
        "cs.SI"
      ]
    },
    {
      "title": "Revisiting Incremental Stochastic Majorization-Minimization Algorithms with Applications to Mixture of Experts",
      "authors": [
        "TrungKhang Tran",
        "TrungTin Nguyen",
        "Gersende Fort",
        "Tung Doan",
        "Hien Duy Nguyen",
        "Binh T. Nguyen",
        "Florence Forbes",
        "Christopher Drovandi"
      ],
      "abstract": "Processing high-volume, streaming data is increasingly common in modern statistics and machine learning, where batch-mode algorithms are often impractical because they require repeated passes over the full dataset. This has motivated incremental stochastic estimation methods, including the incremental stochastic Expectation-Maximization (EM) algorithm formulated via stochastic approximation. In this work, we revisit and analyze an incremental stochastic variant of the Majorization-Minimization (MM) algorithm, which generalizes incremental stochastic EM as a special case. Our approach relaxes key EM requirements, such as explicit latent-variable representations, enabling broader applicability and greater algorithmic flexibility. We establish theoretical guarantees for the incremental stochastic MM algorithm, proving consistency in the sense that the iterates converge to a stationary point characterized by a vanishing gradient of the objective. We demonstrate these advantages on a softmax-gated mixture of experts (MoE) regression problem, for which no stochastic EM algorithm is available. Empirically, our method consistently outperforms widely used stochastic optimizers, including stochastic gradient descent, root mean square propagation, adaptive moment estimation, and second-order clipped stochastic optimization. These results support the development of new incremental stochastic algorithms, given the central role of softmax-gated MoE architectures in contemporary deep neural networks for heterogeneous data modeling. Beyond synthetic experiments, we also validate practical effectiveness on two real-world datasets, including a bioinformatics study of dent maize genotypes under drought stress that integrates high-dimensional proteomics with ecophysiological traits, where incremental stochastic MM yields stable gains in predictive performance.",
      "pdf_url": "https://arxiv.org/pdf/2601.19811v1",
      "published": "2026-01-27T17:12:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.19811v1",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "math.ST",
        "stat.ME"
      ]
    },
    {
      "title": "Unsupervised Learning of Efficient Exploration: Pre-training Adaptive Policies via Self-Imposed Goals",
      "authors": [
        "Octavio Pappalardo"
      ],
      "abstract": "Unsupervised pre-training can equip reinforcement learning agents with prior knowledge and accelerate learning in downstream tasks. A promising direction, grounded in human development, investigates agents that learn by setting and pursuing their own goals. The core challenge lies in how to effectively generate, select, and learn from such goals. Our focus is on broad distributions of downstream tasks where solving every task zero-shot is infeasible. Such settings naturally arise when the target tasks lie outside of the pre-training distribution or when their identities are unknown to the agent. In this work, we (i) optimize for efficient multi-episode exploration and adaptation within a meta-learning framework, and (ii) guide the training curriculum with evolving estimates of the agent's post-adaptation performance. We present ULEE, an unsupervised meta-learning method that combines an in-context learner with an adversarial goal-generation strategy that maintains training at the frontier of the agent's capabilities. On XLand-MiniGrid benchmarks, ULEE pre-training yields improved exploration and adaptation abilities that generalize to novel objectives, environment dynamics, and map structures. The resulting policy attains improved zero-shot and few-shot performance, and provides a strong initialization for longer fine-tuning processes. It outperforms learning from scratch, DIAYN pre-training, and alternative curricula.",
      "pdf_url": "https://arxiv.org/pdf/2601.19810v1",
      "published": "2026-01-27T17:10:29+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.19810v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ]
    },
    {
      "title": "CASTER: Breaking the Cost-Performance Barrier in Multi-Agent Orchestration via Context-Aware Strategy for Task Efficient Routing",
      "authors": [
        "Shanyv Liu",
        "Xuyang Yuan",
        "Tao Chen",
        "Zijun Zhan",
        "Zhu Han",
        "Danyang Zheng",
        "Weishan Zhang",
        "Shaohua Cao"
      ],
      "abstract": "Graph-based Multi-Agent Systems (MAS) enable complex cyclic workflows but suffer from inefficient static model allocation, where deploying strong models uniformly wastes computation on trivial sub-tasks. We propose CASTER (Context-Aware Strategy for Task Efficient Routing), a lightweight router for dynamic model selection in graph-based MAS. CASTER employs a Dual-Signal Router that combines semantic embeddings with structural meta-features to estimate task difficulty. During training, the router self-optimizes through a Cold Start to Iterative Evolution paradigm, learning from its own routing failures via on-policy negative feedback. Experiments using LLM-as-a-Judge evaluation across Software Engineering, Data Analysis, Scientific Discovery, and Cybersecurity demonstrate that CASTER reduces inference cost by up to 72.4% compared to strong-model baselines while matching their success rates, and consistently outperforms both heuristic routing and FrugalGPT across all domains.",
      "pdf_url": "https://arxiv.org/pdf/2601.19793v1",
      "published": "2026-01-27T16:52:47+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.19793v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "LVLMs and Humans Ground Differently in Referential Communication",
      "authors": [
        "Peter Zeng",
        "Weiling Li",
        "Amie Paige",
        "Zhengxiang Wang",
        "Panagiotis Kaliosis",
        "Dimitris Samaras",
        "Gregory Zelinsky",
        "Susan Brennan",
        "Owen Rambow"
      ],
      "abstract": "For generative AI agents to partner effectively with human users, the ability to accurately predict human intent is critical. But this ability to collaborate remains limited by a critical deficit: an inability to model common ground. Here, we present a referential communication experiment with a factorial design involving director-matcher pairs (human-human, human-AI, AI-human, and AI-AI) that interact with multiple turns in repeated rounds to match pictures of objects not associated with any obvious lexicalized labels. We release the online pipeline for data collection, the tools and analyses for accuracy, efficiency, and lexical overlap, and a corpus of 356 dialogues (89 pairs over 4 rounds each) that unmasks LVLMs' limitations in interactively resolving referring expressions, a crucial skill that underlies human language use.",
      "pdf_url": "https://arxiv.org/pdf/2601.19792v1",
      "published": "2026-01-27T16:52:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.19792v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ]
    },
    {
      "title": "Reimagining Peer Review Process Through Multi-Agent Mechanism Design",
      "authors": [
        "Ahmad Farooq",
        "Kamran Iqbal"
      ],
      "abstract": "The software engineering research community faces a systemic crisis: peer review is failing under growing submissions, misaligned incentives, and reviewer fatigue. Community surveys reveal that researchers perceive the process as \"broken.\" This position paper argues that these dysfunctions are mechanism design failures amenable to computational solutions. We propose modeling the research community as a stochastic multi-agent system and applying multi-agent reinforcement learning to design incentive-compatible protocols. We outline three interventions: a credit-based submission economy, MARL-optimized reviewer assignment, and hybrid verification of review consistency. We present threat models, equity considerations, and phased pilot metrics. This vision charts a research agenda toward sustainable peer review.",
      "pdf_url": "https://arxiv.org/pdf/2601.19778v1",
      "published": "2026-01-27T16:43:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.19778v1",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.CY",
        "cs.GT",
        "cs.SE"
      ]
    },
    {
      "title": "GAVEL: Towards rule-based safety through activation monitoring",
      "authors": [
        "Shir Rozenfeld",
        "Rahul Pankajakshan",
        "Itay Zloczower",
        "Eyal Lenga",
        "Gilad Gressel",
        "Yisroel Mirsky"
      ],
      "abstract": "Large language models (LLMs) are increasingly paired with activation-based monitoring to detect and prevent harmful behaviors that may not be apparent at the surface-text level. However, existing activation safety approaches, trained on broad misuse datasets, struggle with poor precision, limited flexibility, and lack of interpretability. This paper introduces a new paradigm: rule-based activation safety, inspired by rule-sharing practices in cybersecurity. We propose modeling activations as cognitive elements (CEs), fine-grained, interpretable factors such as ''making a threat'' and ''payment processing'', that can be composed to capture nuanced, domain-specific behaviors with higher precision. Building on this representation, we present a practical framework that defines predicate rules over CEs and detects violations in real time. This enables practitioners to configure and update safeguards without retraining models or detectors, while supporting transparency and auditability. Our results show that compositional rule-based activation safety improves precision, supports domain customization, and lays the groundwork for scalable, interpretable, and auditable AI governance. We will release GAVEL as an open-source framework and provide an accompanying automated rule creation tool.",
      "pdf_url": "https://arxiv.org/pdf/2601.19768v1",
      "published": "2026-01-27T16:31:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.19768v1",
      "categories": [
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ]
    },
    {
      "title": "Agentic Design Patterns: A System-Theoretic Framework",
      "authors": [
        "Minh-Dung Dao",
        "Quy Minh Le",
        "Hoang Thanh Lam",
        "Duc-Trong Le",
        "Quoc-Viet Pham",
        "Barry O'Sullivan",
        "Hoang D. Nguyen"
      ],
      "abstract": "With the development of foundation model (FM), agentic AI systems are getting more attention, yet their inherent issues like hallucination and poor reasoning, coupled with the frequent ad-hoc nature of system design, lead to unreliable and brittle applications. Existing efforts to characterise agentic design patterns often lack a rigorous systems-theoretic foundation, resulting in high-level or convenience-based taxonomies that are difficult to implement. This paper addresses this gap by introducing a principled methodology for engineering robust AI agents. We propose two primary contributions: first, a novel system-theoretic framework that deconstructs an agentic AI system into five core, interacting functional subsystems: Reasoning & World Model, Perception & Grounding, Action Execution, Learning & Adaptation, and Inter-Agent Communication. Second, derived from this architecture and directly mapped to a comprehensive taxonomy of agentic challenges, we present a collection of 12 agentic design patterns. These patterns - categorised as Foundational, Cognitive & Decisional, Execution & Interaction, and Adaptive & Learning - offer reusable, structural solutions to recurring problems in agent design. The utility of the framework is demonstrated by a case study on the ReAct framework, showing how the proposed patterns can rectify systemic architectural deficiencies. This work provides a foundational language and a structured methodology to standardise agentic design communication among researchers and engineers, leading to more modular, understandable, and reliable autonomous systems.",
      "pdf_url": "https://arxiv.org/pdf/2601.19752v1",
      "published": "2026-01-27T16:14:08+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.19752v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Veri-Sure: A Contract-Aware Multi-Agent Framework with Temporal Tracing and Formal Verification for Correct RTL Code Generation",
      "authors": [
        "Jiale Liu",
        "Taiyu Zhou",
        "Tianqi Jiang"
      ],
      "abstract": "In the rapidly evolving field of Electronic Design Automation (EDA), the deployment of Large Language Models (LLMs) for Register-Transfer Level (RTL) design has emerged as a promising direction. However, silicon-grade correctness remains bottlenecked by: (i) limited test coverage and reliability of simulation-centric evaluation, (ii) regressions and repair hallucinations introduced by iterative debugging, and (iii) semantic drift as intent is reinterpreted across agent handoffs. In this work, we propose Veri-Sure, a multi-agent framework that establishes a design contract to align agents' intent and uses a patching mechanism guided by static dependency slicing to perform precise, localized repairs. By integrating a multi-branch verification pipeline that combines trace-driven temporal analysis with formal verification consisting of assertion-based checking and boolean equivalence proofs, Veri-Sure enables functional correctness beyond pure simulations. We also introduce VerilogEval-v2-EXT, extending the original benchmark with 53 more industrial-grade design tasks and stratified difficulty levels, and show that Veri-Sure achieves state-of-the-art verified-correct RTL code generation performance, surpassing standalone LLMs and prior agentic systems.",
      "pdf_url": "https://arxiv.org/pdf/2601.19747v1",
      "published": "2026-01-27T16:10:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.19747v1",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.SE"
      ]
    },
    {
      "title": "TokenSeek: Memory Efficient Fine Tuning via Instance-Aware Token Ditching",
      "authors": [
        "Runjia Zeng",
        "Qifan Wang",
        "Qiang Guan",
        "Ruixiang Tang",
        "Lifu Huang",
        "Zhenting Wang",
        "Xueling Zhang",
        "Cheng Han",
        "Dongfang Liu"
      ],
      "abstract": "Fine tuning has been regarded as a de facto approach for adapting large language models (LLMs) to downstream tasks, but the high training memory consumption inherited from LLMs makes this process inefficient. Among existing memory efficient approaches, activation-related optimization has proven particularly effective, as activations consistently dominate overall memory consumption. Although prior arts offer various activation optimization strategies, their data-agnostic nature ultimately results in ineffective and unstable fine tuning. In this paper, we propose TokenSeek, a universal plugin solution for various transformer-based models through instance-aware token seeking and ditching, achieving significant fine-tuning memory savings (e.g., requiring only 14.8% of the memory on Llama3.2 1B) with on-par or even better performance. Furthermore, our interpretable token seeking process reveals the underlying reasons for its effectiveness, offering valuable insights for future research on token efficiency. Homepage: https://runjia.tech/iclr_tokenseek/",
      "pdf_url": "https://arxiv.org/pdf/2601.19739v1",
      "published": "2026-01-27T15:58:36+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.19739v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Quantum Circuit Pre-Synthesis: Learning Local Edits to Reduce $T$-count",
      "authors": [
        "Daniele Lizzio Bosco",
        "Lukasz Cincio",
        "Giuseppe Serra",
        "M. Cerezo"
      ],
      "abstract": "Compiling quantum circuits into Clifford+$T$ gates is a central task for fault-tolerant quantum computing using stabilizer codes. In the near term, $T$ gates will dominate the cost of fault tolerant implementations, and any reduction in the number of such expensive gates could mean the difference between being able to run a circuit or not. While exact synthesis is exponentially hard in the number of qubits, local synthesis approaches are commonly used to compile large circuits by decomposing them into substructures. However, composing local methods leads to suboptimal compilations in key metrics such as $T$-count or circuit depth, and their performance strongly depends on circuit representation. In this work, we address this challenge by proposing \\textsc{Q-PreSyn}, a strategy that, given a set of local edits preserving circuit equivalence, uses a RL agent to identify effective sequences of such actions and thereby obtain circuit representations that yield a reduced $T$-count upon synthesis. Experimental results of our proposed strategy, applied on top of well-known synthesis algorithms, show up to a $20\\%$ reduction in $T$-count on circuits with up to 25 qubits, without introducing any additional approximation error prior to synthesis.",
      "pdf_url": "https://arxiv.org/pdf/2601.19738v1",
      "published": "2026-01-27T15:58:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.19738v1",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "RvB: Automating AI System Hardening via Iterative Red-Blue Games",
      "authors": [
        "Lige Huang",
        "Zicheng Liu",
        "Jie Zhang",
        "Lewen Yan",
        "Dongrui Liu",
        "Jing Shao"
      ],
      "abstract": "The dual offensive and defensive utility of Large Language Models (LLMs) highlights a critical gap in AI security: the lack of unified frameworks for dynamic, iterative adversarial adaptation hardening. To bridge this gap, we propose the Red Team vs. Blue Team (RvB) framework, formulated as a training-free, sequential, imperfect-information game. In this process, the Red Team exposes vulnerabilities, driving the Blue Team to learning effective solutions without parameter updates. We validate our framework across two challenging domains: dynamic code hardening against CVEs and guardrail optimization against jailbreaks. Our empirical results show that this interaction compels the Blue Team to learn fundamental defensive principles, leading to robust remediations that are not merely overfitted to specific exploits. RvB achieves Defense Success Rates of 90\\% and 45\\% across the respective tasks while maintaining near 0\\% False Positive Rates, significantly surpassing baselines. This work establishes the iterative adversarial interaction framework as a practical paradigm that automates the continuous hardening of AI systems.",
      "pdf_url": "https://arxiv.org/pdf/2601.19726v1",
      "published": "2026-01-27T15:49:58+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.19726v1",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Component-Level Lesioning of Language Models Reveals Clinically Aligned Aphasia Phenotypes",
      "authors": [
        "Yifan Wang",
        "Jichen Zheng",
        "Jingyuan Sun",
        "Yunhao Zhang",
        "Chunyu Ye",
        "Jixing Li",
        "Chengqing Zong",
        "Shaonan Wang"
      ],
      "abstract": "Large language models (LLMs) increasingly exhibit human-like linguistic behaviors and internal representations that they could serve as computational simulators of language cognition. We ask whether LLMs can be systematically manipulated to reproduce language-production impairments characteristic of aphasia following focal brain lesions. Such models could provide scalable proxies for testing rehabilitation hypotheses, and offer a controlled framework for probing the functional organization of language. We introduce a clinically grounded, component-level framework that simulates aphasia by selectively perturbing functional components in LLMs, and apply it to both modular Mixture-of-Experts models and dense Transformers using a unified intervention interface. Our pipeline (i) identifies subtype-linked components for Broca's and Wernicke's aphasia, (ii) interprets these components with linguistic probing tasks, and (iii) induces graded impairments by progressively perturbing the top-k subtype-linked components, evaluating outcomes with Western Aphasia Battery (WAB) subtests summarized by Aphasia Quotient (AQ). Across architectures and lesioning strategies, subtype-targeted perturbations yield more systematic, aphasia-like regressions than size-matched random perturbations, and MoE modularity supports more localized and interpretable phenotype-to-component mappings. These findings suggest that modular LLMs, combined with clinically informed component perturbations, provide a promising platform for simulating aphasic language production and studying how distinct language functions degrade under targeted disruptions.",
      "pdf_url": "https://arxiv.org/pdf/2601.19723v1",
      "published": "2026-01-27T15:47:22+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.19723v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Hyperbolic Additive Margin Softmax with Hierarchical Information for Speaker Verification",
      "authors": [
        "Zhihua Fang",
        "Liang He"
      ],
      "abstract": "Speaker embedding learning based on Euclidean space has achieved significant progress, but it is still insufficient in modeling hierarchical information within speaker features. Hyperbolic space, with its negative curvature geometric properties, can efficiently represent hierarchical information within a finite volume, making it more suitable for the feature distribution of speaker embeddings. In this paper, we propose Hyperbolic Softmax (H-Softmax) and Hyperbolic Additive Margin Softmax (HAM-Softmax) based on hyperbolic space. H-Softmax incorporates hierarchical information into speaker embeddings by projecting embeddings and speaker centers into hyperbolic space and computing hyperbolic distances. HAM-Softmax further enhances inter-class separability by introducing margin constraint on this basis. Experimental results show that H-Softmax and HAM-Softmax achieve average relative EER reductions of 27.84% and 14.23% compared with standard Softmax and AM-Softmax, respectively, demonstrating that the proposed methods effectively improve speaker verification performance and at the same time preserve the capability of hierarchical structure modeling. The code will be released at https://github.com/PunkMale/HAM-Softmax.",
      "pdf_url": "https://arxiv.org/pdf/2601.19709v1",
      "published": "2026-01-27T15:33:47+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.19709v1",
      "categories": [
        "cs.SD",
        "cs.AI"
      ]
    },
    {
      "title": "SAM Audio Judge: A Unified Multimodal Framework for Perceptual Evaluation of Audio Separation",
      "authors": [
        "Helin Wang",
        "Bowen Shi",
        "Andros Tjandra",
        "John Hoffman",
        "Yi-Chiao Wu",
        "Apoorv Vyas",
        "Najim Dehak",
        "Ann Lee",
        "Wei-Ning Hsu"
      ],
      "abstract": "The performance evaluation remains a complex challenge in audio separation, and existing evaluation metrics are often misaligned with human perception, course-grained, relying on ground truth signals. On the other hand, subjective listening tests remain the gold standard for real-world evaluation, but they are expensive, time-consuming, and difficult to scale. This paper addresses the growing need for automated systems capable of evaluating audio separation without human intervention. The proposed evaluation metric, SAM Audio Judge (SAJ), is a multimodal fine-grained reference-free objective metric, which shows highly alignment with human perceptions. SAJ supports three audio domains (speech, music and general sound events) and three prompt inputs (text, visual and span), covering four different dimensions of evaluation (recall, percision, faithfulness, and overall). SAM Audio Judge also shows potential applications in data filtering, pseudo-labeling large datasets and reranking in audio separation models. We release our code and pre-trained models at: https://github.com/facebookresearch/sam-audio.",
      "pdf_url": "https://arxiv.org/pdf/2601.19702v1",
      "published": "2026-01-27T15:29:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.19702v1",
      "categories": [
        "eess.AS",
        "cs.AI"
      ]
    },
    {
      "title": "Out-of-Distribution Generalization via Invariant Trajectories for Multimodal Large Language Model Editing",
      "authors": [
        "Jiajie Su",
        "Haoyuan Wang",
        "Xiaohua Feng",
        "Yunshan Ma",
        "Xiaobo Xia",
        "Yuyuan Li",
        "Xiaolin Zheng",
        "Jianmao Xiao",
        "Chaochao Chen"
      ],
      "abstract": "Knowledge editing emerges as a crucial technique for efficiently correcting incorrect or outdated knowledge in large language models (LLM). Existing editing methods for unimodal LLM rely on a rigid parameter-to-output mapping, which causes causal-underfit and causal-overfit in cascaded reasoning for Multimodal LLM (MLLM). In this paper, we reformulate MLLM editing as an out-of-distribution (OOD) generalization problem, where the goal is to discern semantic shift with factual shift and thus achieve robust editing among diverse cross-modal prompting. The key challenge of this OOD problem lies in identifying invariant causal trajectories that generalize accurately while suppressing spurious correlations. To address it, we propose ODEdit, a plug-and-play invariant learning based framework that optimizes the tripartite OOD risk objective to simultaneously enhance editing reliability, locality, and generality.We further introduce an edit trajectory invariant learning method, which integrates a total variation penalty into the risk minimization objective to stabilize edit trajectories against environmental variations. Theoretical analysis and extensive experiments demonstrate the effectiveness of ODEdit.",
      "pdf_url": "https://arxiv.org/pdf/2601.19700v1",
      "published": "2026-01-27T15:25:07+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.19700v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "AlignCoder: Aligning Retrieval with Target Intent for Repository-Level Code Completion",
      "authors": [
        "Tianyue Jiang",
        "Yanli Wang",
        "Yanlin Wang",
        "Daya Guo",
        "Ensheng Shi",
        "Yuchi Ma",
        "Jiachi Chen",
        "Zibin Zheng"
      ],
      "abstract": "Repository-level code completion remains a challenging task for existing code large language models (code LLMs) due to their limited understanding of repository-specific context and domain knowledge. While retrieval-augmented generation (RAG) approaches have shown promise by retrieving relevant code snippets as cross-file context, they suffer from two fundamental problems: misalignment between the query and the target code in the retrieval process, and the inability of existing retrieval methods to effectively utilize the inference information. To address these challenges, we propose AlignCoder, a repository-level code completion framework that introduces a query enhancement mechanism and a reinforcement learning based retriever training method. Our approach generates multiple candidate completions to construct an enhanced query that bridges the semantic gap between the initial query and the target code. Additionally, we employ reinforcement learning to train an AlignRetriever that learns to leverage inference information in the enhanced query for more accurate retrieval. We evaluate AlignCoder on two widely-used benchmarks (CrossCodeEval and RepoEval) across five backbone code LLMs, demonstrating an 18.1% improvement in EM score compared to baselines on the CrossCodeEval benchmark. The results show that our framework achieves superior performance and exhibits high generalizability across various code LLMs and programming languages.",
      "pdf_url": "https://arxiv.org/pdf/2601.19697v1",
      "published": "2026-01-27T15:23:14+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.19697v1",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "Cross-Domain Offshore Wind Power Forecasting: Transfer Learning Through Meteorological Clusters",
      "authors": [
        "Dominic Weisser",
        "Chloé Hashimoto-Cullen",
        "Benjamin Guedj"
      ],
      "abstract": "Ambitious decarbonisation targets are catalysing growth in orders of new offshore wind farms. For these newly commissioned plants to run, accurate power forecasts are needed from the onset. These allow grid stability, good reserve management and efficient energy trading. Despite machine learning models having strong performances, they tend to require large volumes of site-specific data that new farms do not yet have. To overcome this data scarcity, we propose a novel transfer learning framework that clusters power output according to covariate meteorological features. Rather than training a single, general-purpose model, we thus forecast with an ensemble of expert models, each trained on a cluster. As these pre-trained models each specialise in a distinct weather pattern, they adapt efficiently to new sites and capture transferable, climate-dependent dynamics. Through the expert models' built-in calibration to seasonal and meteorological variability, we remove the industry-standard requirement of local measurements over a year. Our contributions are two-fold - we propose this novel framework and comprehensively evaluate it on eight offshore wind farms, achieving accurate cross-domain forecasting with under five months of site-specific data. Our experiments achieve a MAE of 3.52\\%, providing empirical verification that reliable forecasts do not require a full annual cycle. Beyond power forecasting, this climate-aware transfer learning method opens new opportunities for offshore wind applications such as early-stage wind resource assessment, where reducing data requirements can significantly accelerate project development whilst effectively mitigating its inherent risks.",
      "pdf_url": "https://arxiv.org/pdf/2601.19674v1",
      "published": "2026-01-27T14:54:27+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.19674v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.AP",
        "stat.ME"
      ]
    },
    {
      "title": "A Benchmark for Audio Reasoning Capabilities of Multimodal Large Language Models",
      "authors": [
        "Iwona Christop",
        "Mateusz Czyżnikiewicz",
        "Paweł Skórzewski",
        "Łukasz Bondaruk",
        "Jakub Kubiak",
        "Marcin Lewandowski",
        "Marek Kubis"
      ],
      "abstract": "The present benchmarks for testing the audio modality of multimodal large language models concentrate on testing various audio tasks such as speaker diarization or gender identification in isolation. Whether a multimodal model can answer the questions that require reasoning skills to combine audio tasks of different categories, cannot be verified with their use. To address this issue, we propose Audio Reasoning Tasks (ART), a new benchmark for assessing the ability of multimodal models to solve problems that require reasoning over audio signal.",
      "pdf_url": "https://arxiv.org/pdf/2601.19673v1",
      "published": "2026-01-27T14:54:10+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.19673v1",
      "categories": [
        "cs.SD",
        "cs.AI"
      ]
    },
    {
      "title": "ProToken: Token-Level Attribution for Federated Large Language Models",
      "authors": [
        "Waris Gill",
        "Ahmad Humayun",
        "Ali Anwar",
        "Muhammad Ali Gulzar"
      ],
      "abstract": "Federated Learning (FL) enables collaborative training of Large Language Models (LLMs) across distributed data sources while preserving privacy. However, when federated LLMs are deployed in critical applications, it remains unclear which client(s) contributed to specific generated responses, hindering debugging, malicious client identification, fair reward allocation, and trust verification. We present ProToken, a novel Provenance methodology for Token-level attribution in federated LLMs that addresses client attribution during autoregressive text generation while maintaining FL privacy constraints. ProToken leverages two key insights to enable provenance at each token: (1) transformer architectures concentrate task-specific signals in later blocks, enabling strategic layer selection for computational tractability, and (2) gradient-based relevance weighting filters out irrelevant neural activations, focusing attribution on neurons that directly influence token generation. We evaluate ProToken across 16 configurations spanning four LLM architectures (Gemma, Llama, Qwen, SmolLM) and four domains (medical, financial, mathematical, coding). ProToken achieves 98% average attribution accuracy in correctly localizing responsible client(s), and maintains high accuracy when the number of clients are scaled, validating its practical viability for real-world deployment settings.",
      "pdf_url": "https://arxiv.org/pdf/2601.19672v1",
      "published": "2026-01-27T14:53:12+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.19672v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SE"
      ]
    },
    {
      "title": "SynCABEL: Synthetic Contextualized Augmentation for Biomedical Entity Linking",
      "authors": [
        "Adam Remaki",
        "Christel Gérardin",
        "Eulàlia Farré-Maduell",
        "Martin Krallinger",
        "Xavier Tannier"
      ],
      "abstract": "We present SynCABEL (Synthetic Contextualized Augmentation for Biomedical Entity Linking), a framework that addresses a central bottleneck in supervised biomedical entity linking (BEL): the scarcity of expert-annotated training data. SynCABEL leverages large language models to generate context-rich synthetic training examples for all candidate concepts in a target knowledge base, providing broad supervision without manual annotation. We demonstrate that SynCABEL, when combined with decoder-only models and guided inference establish new state-of-the-art results across three widely used multilingual benchmarks: MedMentions for English, QUAERO for French, and SPACCC for Spanish. Evaluating data efficiency, we show that SynCABEL reaches the performance of full human supervision using up to 60% less annotated data, substantially reducing reliance on labor-intensive and costly expert labeling. Finally, acknowledging that standard evaluation based on exact code matching often underestimates clinically valid predictions due to ontology redundancy, we introduce an LLM-as-a-judge protocol. This analysis reveals that SynCABEL significantly improves the rate of clinically valid predictions. Our synthetic datasets, models, and code are released to support reproducibility and future research.",
      "pdf_url": "https://arxiv.org/pdf/2601.19667v1",
      "published": "2026-01-27T14:47:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.19667v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ]
    },
    {
      "title": "One Token Is Enough: Improving Diffusion Language Models with a Sink Token",
      "authors": [
        "Zihou Zhang",
        "Zheyong Xie",
        "Li Zhong",
        "Haifeng Liu",
        "Shaosheng Cao"
      ],
      "abstract": "Diffusion Language Models (DLMs) have emerged as a compelling alternative to autoregressive approaches, enabling parallel text generation with competitive performance. Despite these advantages, there is a critical instability in DLMs: the moving sink phenomenon. Our analysis indicates that sink tokens exhibit low-norm representations in the Transformer's value space, and that the moving sink phenomenon serves as a protective mechanism in DLMs to prevent excessive information mixing. However, their unpredictable positions across diffusion steps undermine inference robustness. To resolve this, we propose a simple but effective extra sink token implemented via a modified attention mask. Specifically, we introduce a special token constrained to attend solely to itself, while remaining globally visible to all other tokens. Experimental results demonstrate that introducing a single extra token stabilizes attention sinks, substantially improving model performance. Crucially, further analysis confirms that the effectiveness of this token is independent of its position and characterized by negligible semantic content, validating its role as a robust and dedicated structural sink.",
      "pdf_url": "https://arxiv.org/pdf/2601.19657v1",
      "published": "2026-01-27T14:32:36+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.19657v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Robustness of Constraint Automata for Description Logics with Concrete Domains",
      "authors": [
        "Stéphane Demri",
        "Tianwen Gu"
      ],
      "abstract": "Decidability or complexity issues about the consistency problem for description logics with concrete domains have already been analysed with tableaux-based or type elimination methods. Concrete domains in ontologies are essential to consider concrete objects and predefined relations. In this work, we expose an automata-based approach leading to the optimal upper bound EXPTIME, that is designed by enriching the transitions with symbolic constraints. We show that the nonemptiness problem for such automata belongs to EXPTIME if the concrete domains satisfy a few simple properties. Then, we provide a reduction from the consistency problem for ontologies, yielding EXPTIME-membership. Thanks to the expressivity of constraint automata, the results are extended to additional ingredients such as inverse roles, functional role names and constraint assertions, while maintaining EXPTIME-membership, which illustrates the robustness of the approach",
      "pdf_url": "https://arxiv.org/pdf/2601.19644v1",
      "published": "2026-01-27T14:19:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.19644v1",
      "categories": [
        "cs.LO",
        "cs.AI"
      ]
    },
    {
      "title": "Tracking Drift: Variation-Aware Entropy Scheduling for Non-Stationary Reinforcement Learning",
      "authors": [
        "Tongxi Wang",
        "Zhuoyang Xia",
        "Xinran Chen",
        "Shan Liu"
      ],
      "abstract": "Real-world reinforcement learning often faces environment drift, but most existing methods rely on static entropy coefficients/target entropy, causing over-exploration during stable periods and under-exploration after drift (thus slow recovery), and leaving unanswered the principled question of how exploration intensity should scale with drift magnitude. We prove that entropy scheduling under non-stationarity can be reduced to a one-dimensional, round-by-round trade-off, faster tracking of the optimal solution after drift vs. avoiding gratuitous randomness when the environment is stable, so exploration strength can be driven by measurable online drift signals. Building on this, we propose AES (Adaptive Entropy Scheduling), which adaptively adjusts the entropy coefficient/temperature online using observable drift proxies during training, requiring almost no structural changes and incurring minimal overhead. Across 4 algorithm variants, 12 tasks, and 4 drift modes, AES significantly reduces the fraction of performance degradation caused by drift and accelerates recovery after abrupt changes.",
      "pdf_url": "https://arxiv.org/pdf/2601.19624v1",
      "published": "2026-01-27T13:58:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.19624v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Algorithmic Prompt-Augmentation for Efficient LLM-Based Heuristic Design for A* Search",
      "authors": [
        "Thomas Bömer",
        "Nico Koltermann",
        "Max Disselnmeyer",
        "Bastian Amberg",
        "Anne Meyer"
      ],
      "abstract": "Heuristic functions are essential to the performance of tree search algorithms such as A*, where their accuracy and efficiency directly impact search outcomes. Traditionally, such heuristics are handcrafted, requiring significant expertise. Recent advances in large language models (LLMs) and evolutionary frameworks have opened the door to automating heuristic design. In this paper, we extend the Evolution of Heuristics (EoH) framework to investigate the automated generation of guiding heuristics for A* search. We introduce a novel domain-agnostic prompt augmentation strategy that includes the A* code into the prompt to leverage in-context learning, named Algorithmic - Contextual EoH (A-CEoH). To evaluate the effectiveness of A-CeoH, we study two problem domains: the Unit-Load Pre-Marshalling Problem (UPMP), a niche problem from warehouse logistics, and the classical sliding puzzle problem (SPP). Our computational experiments show that A-CEoH can significantly improve the quality of the generated heuristics and even outperform expert-designed heuristics.",
      "pdf_url": "https://arxiv.org/pdf/2601.19622v1",
      "published": "2026-01-27T13:55:58+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.19622v1",
      "categories": [
        "cs.AI",
        "math.OC"
      ]
    },
    {
      "title": "R^3: Replay, Reflection, and Ranking Rewards for LLM Reinforcement Learning",
      "authors": [
        "Zhizheng Jiang",
        "Kang Zhao",
        "Weikai Xu",
        "Xinkui Lin",
        "Wei Liu",
        "Jian Luan",
        "Shuo Shang",
        "Peng Han"
      ],
      "abstract": "Large reasoning models (LRMs) aim to solve diverse and complex problems through structured reasoning. Recent advances in group-based policy optimization methods have shown promise in enabling stable advantage estimation without reliance on process-level annotations. However, these methods rely on advantage gaps induced by high-quality samples within the same batch, which makes the training process fragile and inefficient when intra-group advantages collapse under challenging tasks. To address these problems, we propose a reinforcement learning mechanism named \\emph{\\textbf{R^3}} that along three directions: (1) a \\emph{cross-context \\underline{\\textbf{R}}eplay} strategy that maintains the intra-group advantage by recalling valuable examples from historical trajectories of the same query, (2) an \\emph{in-context self-\\underline{\\textbf{R}}eflection} mechanism enabling models to refine outputs by leveraging past failures, and (3) a \\emph{structural entropy \\underline{\\textbf{R}}anking reward}, which assigns relative rewards to truncated or failed samples by ranking responses based on token-level entropy patterns, capturing both local exploration and global stability. We implement our method on Deepseek-R1-Distill-Qwen-1.5B and train it on the DeepscaleR-40k in the math domain. Experiments demonstrate our method achieves SoTA performance on several math benchmarks, representing significant improvements and fewer reasoning tokens over the base models. Code and model will be released.",
      "pdf_url": "https://arxiv.org/pdf/2601.19620v1",
      "published": "2026-01-27T13:55:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.19620v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "The role of self-supervised pretraining in differentially private medical image analysis",
      "authors": [
        "Soroosh Tayebi Arasteh",
        "Mina Farajiamiri",
        "Mahshad Lotfinia",
        "Behrus Hinrichs-Puladi",
        "Jonas Bienzeisler",
        "Mohamed Alhaskir",
        "Mirabela Rusu",
        "Christiane Kuhl",
        "Sven Nebelung",
        "Daniel Truhn"
      ],
      "abstract": "Differential privacy (DP) provides formal protection for sensitive data but typically incurs substantial losses in diagnostic performance. Model initialization has emerged as a critical factor in mitigating this degradation, yet the role of modern self-supervised learning under full-model DP remains poorly understood. Here, we present a large-scale evaluation of initialization strategies for differentially private medical image analysis, using chest radiograph classification as a representative benchmark with more than 800,000 images. Using state-of-the-art ConvNeXt models trained with DP-SGD across realistic privacy regimes, we compare non-domain-specific supervised ImageNet initialization, non-domain-specific self-supervised DINOv3 initialization, and domain-specific supervised pretraining on MIMIC-CXR, the largest publicly available chest radiograph dataset. Evaluations are conducted across five external datasets spanning diverse institutions and acquisition settings. We show that DINOv3 initialization consistently improves diagnostic utility relative to ImageNet initialization under DP, but remains inferior to domain-specific supervised pretraining, which achieves performance closest to non-private baselines. We further demonstrate that initialization choice strongly influences demographic fairness, cross-dataset generalization, and robustness to data scale and model capacity under privacy constraints. The results establish initialization strategy as a central determinant of utility, fairness, and generalization in differentially private medical imaging.",
      "pdf_url": "https://arxiv.org/pdf/2601.19618v1",
      "published": "2026-01-27T13:50:43+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.19618v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Up to 36x Speedup: Mask-based Parallel Inference Paradigm for Key Information Extraction in MLLMs",
      "authors": [
        "Xinzhong Wang",
        "Ya Guo",
        "Jing Li",
        "Huan Chen",
        "Yi Tu",
        "Yijie Hong",
        "Gongshen Liu",
        "Huijia Zhu"
      ],
      "abstract": "Key Information Extraction (KIE) from visually-rich documents (VrDs) is a critical task, for which recent Large Language Models (LLMs) and Multi-Modal Large Language Models (MLLMs) have demonstrated strong potential. However, their reliance on autoregressive inference, which generates outputs sequentially, creates a significant efficiency bottleneck, especially as KIE tasks often involve extracting multiple, semantically independent fields. To overcome this limitation, we introduce PIP: a Parallel Inference Paradigm for KIE. Our approach reformulates the problem by using \"[mask]\" tokens as placeholders for all target values, enabling their simultaneous generation in a single forward pass. To facilitate this paradigm, we develop a tailored mask pre-training strategy and construct large-scale supervised datasets. Experimental results show that our PIP-models achieve a 5-36x inference speedup with negligible performance degradation compared to traditional autoregressive base models. By substantially improving efficiency while maintaining high accuracy, PIP paves the way for scalable and practical real-world KIE solutions.",
      "pdf_url": "https://arxiv.org/pdf/2601.19613v1",
      "published": "2026-01-27T13:45:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.19613v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Safe Exploration via Policy Priors",
      "authors": [
        "Manuel Wendl",
        "Yarden As",
        "Manish Prajapat",
        "Anton Pollak",
        "Stelian Coros",
        "Andreas Krause"
      ],
      "abstract": "Safe exploration is a key requirement for reinforcement learning (RL) agents to learn and adapt online, beyond controlled (e.g. simulated) environments. In this work, we tackle this challenge by utilizing suboptimal yet conservative policies (e.g., obtained from offline data or simulators) as priors. Our approach, SOOPER, uses probabilistic dynamics models to optimistically explore, yet pessimistically fall back to the conservative policy prior if needed. We prove that SOOPER guarantees safety throughout learning, and establish convergence to an optimal policy by bounding its cumulative regret. Extensive experiments on key safe RL benchmarks and real-world hardware demonstrate that SOOPER is scalable, outperforms the state-of-the-art and validate our theoretical guarantees in practice.",
      "pdf_url": "https://arxiv.org/pdf/2601.19612v1",
      "published": "2026-01-27T13:45:28+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.19612v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ]
    },
    {
      "title": "Explicit Multi-head Attention for Inter-head Interaction in Large Language Models",
      "authors": [
        "Runyu Peng",
        "Yunhua Zhou",
        "Demin Song",
        "Kai Lv",
        "Bo Wang",
        "Qipeng Guo",
        "Xipeng Qiu"
      ],
      "abstract": "In large language models built upon the Transformer architecture, recent studies have shown that inter-head interaction can enhance attention performance. Motivated by this, we propose Multi-head Explicit Attention (MEA), a simple yet effective attention variant that explicitly models cross-head interaction. MEA consists of two key components: a Head-level Linear Composition (HLC) module that separately applies learnable linear combinations to the key and value vectors across heads, thereby enabling rich inter-head communication; and a head-level Group Normalization layer that aligns the statistical properties of the recombined heads. MEA shows strong robustness in pretraining, which allows the use of larger learning rates that lead to faster convergence, ultimately resulting in lower validation loss and improved performance across a range of tasks. Furthermore, we explore the parameter efficiency of MEA by reducing the number of attention heads and leveraging HLC to reconstruct them using low-rank \"virtual heads\". This enables a practical key-value cache compression strategy that reduces KV-cache memory usage by 50% with negligible performance loss on knowledge-intensive and scientific reasoning tasks, and only a 3.59% accuracy drop for Olympiad-level mathematical benchmarks.",
      "pdf_url": "https://arxiv.org/pdf/2601.19611v1",
      "published": "2026-01-27T13:45:03+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.19611v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "ComAgent: Multi-LLM based Agentic AI Empowered Intelligent Wireless Networks",
      "authors": [
        "Haoyun Li",
        "Ming Xiao",
        "Kezhi Wang",
        "Robert Schober",
        "Dong In Kim",
        "Yong Liang Guan"
      ],
      "abstract": "Emerging 6G networks rely on complex cross-layer optimization, yet manually translating high-level intents into mathematical formulations remains a bottleneck. While Large Language Models (LLMs) offer promise, monolithic approaches often lack sufficient domain grounding, constraint awareness, and verification capabilities. To address this, we present ComAgent, a multi-LLM agentic AI framework. ComAgent employs a closed-loop Perception-Planning-Action-Reflection cycle, coordinating specialized agents for literature search, coding, and scoring to autonomously generate solver-ready formulations and reproducible simulations. By iteratively decomposing problems and self-correcting errors, the framework effectively bridges the gap between user intent and execution. Evaluations demonstrate that ComAgent achieves expert-comparable performance in complex beamforming optimization and outperforms monolithic LLMs across diverse wireless tasks, highlighting its potential for automating design in emerging wireless networks.",
      "pdf_url": "https://arxiv.org/pdf/2601.19607v1",
      "published": "2026-01-27T13:43:59+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.19607v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "GMS-CAVP: Improving Audio-Video Correspondence with Multi-Scale Contrastive and Generative Pretraining",
      "authors": [
        "Shentong Mo",
        "Zehua Chen",
        "Jun Zhu"
      ],
      "abstract": "Recent advances in video-audio (V-A) understanding and generation have increasingly relied on joint V-A embeddings, which serve as the foundation for tasks such as cross-modal retrieval and generation. While prior methods like CAVP effectively model semantic and temporal correspondences between modalities using contrastive objectives, their performance remains suboptimal. A key limitation is the insufficient modeling of the dense, multi-scale nature of both video and audio signals, correspondences often span fine- to coarse-grained spatial-temporal structures, which are underutilized in existing frameworks. To this end, we propose GMS-CAVP, a novel framework that combines Multi-Scale Video-Audio Alignment and Multi-Scale Spatial-Temporal Diffusion-based pretraining objectives to enhance V-A correspondence modeling. First, GMS-CAVP introduces a multi-scale contrastive learning strategy that captures semantic and temporal relations across varying granularities. Second, we go beyond traditional contrastive learning by incorporating a diffusion-based generative objective, enabling modality translation and synthesis between video and audio. This unified discriminative-generative formulation facilitates deeper cross-modal understanding and paves the way for high-fidelity generation. Extensive experiments on VGGSound, AudioSet, and Panda70M demonstrate that GMS-CAVP outperforms previous methods in generation and retrieval.",
      "pdf_url": "https://arxiv.org/pdf/2601.19606v1",
      "published": "2026-01-27T13:43:32+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.19606v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.SD",
        "eess.AS"
      ]
    },
    {
      "title": "Intersectional Fairness via Mixed-Integer Optimization",
      "authors": [
        "Jiří Němeček",
        "Mark Kozdoba",
        "Illia Kryvoviaz",
        "Tomáš Pevný",
        "Jakub Mareček"
      ],
      "abstract": "The deployment of Artificial Intelligence in high-risk domains, such as finance and healthcare, necessitates models that are both fair and transparent. While regulatory frameworks, including the EU's AI Act, mandate bias mitigation, they are deliberately vague about the definition of bias. In line with existing research, we argue that true fairness requires addressing bias at the intersections of protected groups. We propose a unified framework that leverages Mixed-Integer Optimization (MIO) to train intersectionally fair and intrinsically interpretable classifiers. We prove the equivalence of two measures of intersectional fairness (MSD and SPSF) in detecting the most unfair subgroup and empirically demonstrate that our MIO-based algorithm improves performance in finding bias. We train high-performing, interpretable classifiers that bound intersectional bias below an acceptable threshold, offering a robust solution for regulated industries and beyond.",
      "pdf_url": "https://arxiv.org/pdf/2601.19595v1",
      "published": "2026-01-27T13:29:25+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.19595v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC",
        "stat.ML"
      ]
    },
    {
      "title": "From Atoms to Chains: Divergence-Guided Reasoning Curriculum for Unlabeled LLM Domain Adaptation",
      "authors": [
        "Yongqi Wang",
        "Xiaofeng Ji",
        "Jie Wang",
        "Qingbin Li",
        "Xiao Xiong",
        "Zheming Yang",
        "Jian Xu",
        "Minghui Qiu",
        "Xinxiao Wu"
      ],
      "abstract": "Adapting Large Language Models (LLMs) to specialized domains without human-annotated data is a crucial yet formidable challenge. Widely adopted knowledge distillation methods often devolve into coarse-grained mimicry, where the student model inefficiently targets its own weaknesses and risks inheriting the teacher's reasoning flaws. This exposes a critical pedagogical dilemma: how to devise a reliable curriculum when the teacher itself is not an infallible expert. Our work resolves this by capitalizing on a key insight: while LLMs may exhibit fallibility in complex, holistic reasoning, they often exhibit high fidelity on focused, atomic sub-problems. Based on this, we propose Divergence-Guided Reasoning Curriculum (DGRC), which constructs a learning path from atomic knowledge to reasoning chains by dynamically deriving two complementary curricula from disagreements in reasoning pathways. When a student and teacher produce conflicting results, DGRC directs the teacher to perform a diagnostic analysis: it analyzes both reasoning paths to formulate atomic queries that target the specific points of divergence, and then self-answers these queries to create high-confidence atomic question-answer pairs. These pairs then serve a dual purpose: (1) providing an atomic curriculum to rectify the student's knowledge gaps, and (2) serving as factual criteria to filter the teacher's original reasoning chains, yielding a verified CoT curriculum that teaches the student how to integrate atomic knowledge into complete reasoning paths. Experiments across the medical and legal domains on student models of various sizes demonstrate the effectiveness of our DGRC framework. Notably, our method achieves a 7.76% relative improvement for the 1.5B student model in the medical domain over strong unlabeled baseline.",
      "pdf_url": "https://arxiv.org/pdf/2601.19588v1",
      "published": "2026-01-27T13:23:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.19588v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "LLM-Enhanced Reinforcement Learning for Long-Term User Satisfaction in Interactive Recommendation",
      "authors": [
        "Chongjun Xia",
        "Yanchun Peng",
        "Xianzhi Wang"
      ],
      "abstract": "Interactive recommender systems can dynamically adapt to user feedback, but often suffer from content homogeneity and filter bubble effects due to overfitting short-term user preferences. While recent efforts aim to improve content diversity, they predominantly operate in static or one-shot settings, neglecting the long-term evolution of user interests. Reinforcement learning provides a principled framework for optimizing long-term user satisfaction by modeling sequential decision-making processes. However, its application in recommendation is hindered by sparse, long-tailed user-item interactions and limited semantic planning capabilities. In this work, we propose LLM-Enhanced Reinforcement Learning (LERL), a novel hierarchical recommendation framework that integrates the semantic planning power of LLM with the fine-grained adaptability of RL. LERL consists of a high-level LLM-based planner that selects semantically diverse content categories, and a low-level RL policy that recommends personalized items within the selected semantic space. This hierarchical design narrows the action space, enhances planning efficiency, and mitigates overexposure to redundant content. Extensive experiments on real-world datasets demonstrate that LERL significantly improves long-term user satisfaction when compared with state-of-the-art baselines. The implementation of LERL is available at https://anonymous.4open.science/r/code3-18D3/.",
      "pdf_url": "https://arxiv.org/pdf/2601.19585v1",
      "published": "2026-01-27T13:22:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.19585v1",
      "categories": [
        "cs.IR",
        "cs.AI"
      ]
    },
    {
      "title": "Learning Adaptive Parallel Execution for Efficient Code Localization",
      "authors": [
        "Ke Xu",
        "Siyang Xiao",
        "Ming Liang",
        "Yichen Yu",
        "Zhixiang Wang",
        "Jingxuan Xu",
        "Dajun Chen",
        "Wei Jiang",
        "Yong Li"
      ],
      "abstract": "Code localization constitutes a key bottleneck in automated software development pipelines. While concurrent tool execution can enhance discovery speed, current agents demonstrate a 34.9\\% redundant invocation rate, which negates parallelism benefits. We propose \\textbf{FuseSearch}, reformulating parallel code localization as a \\textbf{joint quality-efficiency optimization} task. Through defining \\textbf{tool efficiency} -- the ratio of unique information gain to invocation count -- we utilize a two-phase SFT and RL training approach for learning adaptive parallel strategies. Different from fixed-breadth approaches, FuseSearch dynamically modulates search breadth according to task context, evolving from exploration phases to refinement stages. Evaluated on SWE-bench Verified, FuseSearch-4B achieves SOTA-level performance (84.7\\% file-level and 56.4\\% function-level $F_1$ scores) with 93.6\\% speedup, utilizing 67.7\\% fewer turns and 68.9\\% fewer tokens. Results indicate that efficiency-aware training naturally improves quality through eliminating noisy redundant signals, enabling high-performance cost-effective localization agents.",
      "pdf_url": "https://arxiv.org/pdf/2601.19568v1",
      "published": "2026-01-27T12:59:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.19568v1",
      "categories": [
        "cs.AI",
        "cs.SE"
      ]
    },
    {
      "title": "AROMMA: Unifying Olfactory Embeddings for Single Molecules and Mixtures",
      "authors": [
        "Dayoung Kang",
        "JongWon Kim",
        "Jiho Park",
        "Keonseock Lee",
        "Ji-Woong Choi",
        "Jinhyun So"
      ],
      "abstract": "Public olfaction datasets are small and fragmented across single molecules and mixtures, limiting learning of generalizable odor representations. Recent works either learn single-molecule embeddings or address mixtures via similarity or pairwise label prediction, leaving representations separate and unaligned. In this work, we propose AROMMA, a framework that learns a unified embedding space for single molecules and two-molecule mixtures. Each molecule is encoded by a chemical foundation model and the mixtures are composed by an attention-based aggregator, ensuring both permutation invariance and asymmetric molecular interactions. We further align odor descriptor sets using knowledge distillation and class-aware pseudo-labeling to enrich missing mixture annotations. AROMMA achieves state-of-the-art performance in both single-molecule and molecule-pair datasets, with up to 19.1% AUROC improvement, demonstrating a robust generalization in two domains.",
      "pdf_url": "https://arxiv.org/pdf/2601.19561v1",
      "published": "2026-01-27T12:54:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.19561v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Scale-Consistent State-Space Dynamics via Fractal of Stationary Transformations",
      "authors": [
        "Geunhyeok Yu",
        "Hyoseok Hwang"
      ],
      "abstract": "Recent deep learning models increasingly rely on depth without structural guarantees on the validity of intermediate representations, rendering early stopping and adaptive computation ill-posed. We address this limitation by formulating a structural requirement for state-space model's scale-consistent latent dynamics across iterative refinement, and derive Fractal of Stationary Transformations (FROST), which enforces a self-similar representation manifold through a fractal inductive bias. Under this geometry, intermediate states correspond to different resolutions of a shared representation, and we provide a geometric analysis establishing contraction and stable convergence across iterations. As a consequence of this scale-consistent structure, halting naturally admits a ranking-based formulation driven by intrinsic feature quality rather than extrinsic objectives. Controlled experiments on ImageNet-100 empirically verify the predicted scale-consistent behavior, showing that adaptive efficiency emerges from the aligned latent geometry.",
      "pdf_url": "https://arxiv.org/pdf/2601.19551v1",
      "published": "2026-01-27T12:44:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.19551v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "SLM-SS: Speech Language Model for Generative Speech Separation",
      "authors": [
        "Tianhua Li",
        "Chenda Li",
        "Wei Wang",
        "Xin Zhou",
        "Xihui Chen",
        "Jianqing Gao",
        "Yanmin Qian"
      ],
      "abstract": "Speech separation (SS) has advanced significantly with neural network-based methods, showing improved performance on signal-level metrics. However, these methods often struggle to maintain speech intelligibility in the separated signals, which can negatively affect the performance of downstream tasks such as speech recognition. In this work, we propose SLM-SS, a novel approach that applies speech language models to SS, aiming to enhance the intelligibility and coherence of the separated signals. We frame SS as discrete multi-codebook sequence generation, using Encoder-Decoder models to map quantized speech mixtures to target tokens. In addition to the autoregressive modeling strategy, we introduce a non-autoregressive model to improve decoding efficiency for residual tokens. Experimental results on the LibriMix dataset demonstrate that our approach shows significantly better preservation of speech intelligibility, leading to improved linguistic consistency in a variety of downstream tasks compared to existing approaches.",
      "pdf_url": "https://arxiv.org/pdf/2601.19533v1",
      "published": "2026-01-27T12:22:43+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.19533v1",
      "categories": [
        "cs.SD",
        "cs.AI"
      ]
    },
    {
      "title": "Benchmarks Saturate When The Model Gets Smarter Than The Judge",
      "authors": [
        "Marthe Ballon",
        "Andres Algaba",
        "Brecht Verbeken",
        "Vincent Ginis"
      ],
      "abstract": "Benchmarks are important tools to track progress in the development of Large Language Models (LLMs), yet inaccuracies in datasets and evaluation methods consistently undermine their effectiveness. Here, we present Omni-MATH-2, a manually revised version of the Omni-MATH dataset comprising a clean, exact-answer subset ($n{=}4181$) and a tagged, non-standard subset ($n{=}247$). Each problem was audited to ensure LaTeX compilability, solvability and verifiability, which involved adding missing figures or information, labeling problems requiring a proof, estimation or image, and removing clutter. This process significantly reduces dataset-induced noise, thereby providing a more precise assessment of model performance. The annotated dataset also allows us to evaluate judge-induced noise by comparing GPT-5 mini with the original Omni-Judge, revealing substantial discrepancies between judges on both the clean and tagged problem subsets. Expert annotations reveal that Omni-Judge is wrong in $96.4\\%$ of the judge disagreements, indicating its inability to differentiate between models' abilities, even well before saturation of the benchmark occurs. As problems become more challenging, we find that increasingly competent judges become essential in order to prevent judge errors from masking genuine differences between models. Finally, neither judge identifies the present failure modes for the subset of tagged problems, demonstrating that dataset quality and judge reliability are both critical to develop accurate benchmarks of model performance.",
      "pdf_url": "https://arxiv.org/pdf/2601.19532v1",
      "published": "2026-01-27T12:20:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.19532v1",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    },
    {
      "title": "Fuzzy expert system for the process of collecting and purifying acidic water: a digital twin approach",
      "authors": [
        "Temirbolat Maratuly",
        "Pakizar Shamoi",
        "Timur Samigulin"
      ],
      "abstract": "Purifying sour water is essential for reducing emissions, minimizing corrosion risks, enabling the reuse of treated water in industrial or domestic applications, and ultimately lowering operational costs. Moreover, automating the purification process helps reduce the risk of worker harm by limiting human involvement. Crude oil contains acidic components such as hydrogen sulfide, carbon dioxide, and other chemical compounds. During processing, these substances are partially released into sour water. If not properly treated, sour water poses serious environmental threats and accelerates the corrosion of pipelines and equipment. This paper presents a fuzzy expert system, combined with a custom-generated digital twin, developed from a documented industrial process to maintain key parameters at desired levels by mimicking human reasoning. The control strategy is designed to be simple and intuitive, allowing junior or non-expert personnel to interact with the system effectively. The digital twin was developed using Honeywell UniSim Design R492 to simulate real industrial behavior accurately. Valve dynamics were modeled through system identification in MATLAB, and real-time data exchange between the simulator and controller was established using OPC DA. The fuzzy controller applies split-range control to two valves and was tested under 21 different initial pressure conditions using five distinct defuzzification strategies, resulting in a total of 105 unique test scenarios. System performance was evaluated using both error-based metrics (MSE, RMSE, MAE, IAE, ISE, ITAE) and dynamic response metrics, including overshoot, undershoot, rise time, fall time, settling time, and steady-state error. A web-based simulation interface was developed in Python using the Streamlit framework. Although demonstrated here for sour water treatment, the proposed fuzzy expert system is general-purpose.",
      "pdf_url": "https://arxiv.org/pdf/2601.19527v1",
      "published": "2026-01-27T12:08:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.19527v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Mocap Anywhere: Towards Pairwise-Distance based Motion Capture in the Wild (for the Wild)",
      "authors": [
        "Ofir Abramovich",
        "Ariel Shamir",
        "Andreas Aristidou"
      ],
      "abstract": "We introduce a novel motion capture system that reconstructs full-body 3D motion using only sparse pairwise distance (PWD) measurements from body-mounted(UWB) sensors. Using time-of-flight ranging between wireless nodes, our method eliminates the need for external cameras, enabling robust operation in uncontrolled and outdoor environments. Unlike traditional optical or inertial systems, our approach is shape-invariant and resilient to environmental constraints such as lighting and magnetic interference. At the core of our system is Wild-Poser (WiP for short), a compact, real-time Transformer-based architecture that directly predicts 3D joint positions from noisy or corrupted PWD measurements, which can later be used for joint rotation reconstruction via learned methods. WiP generalizes across subjects of varying morphologies, including non-human species, without requiring individual body measurements or shape fitting. Operating in real time, WiP achieves low joint position error and demonstrates accurate 3D motion reconstruction for both human and animal subjects in-the-wild. Our empirical analysis highlights its potential for scalable, low-cost, and general purpose motion capture in real-world settings.",
      "pdf_url": "https://arxiv.org/pdf/2601.19519v1",
      "published": "2026-01-27T11:58:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.19519v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG"
      ]
    },
    {
      "title": "GradPruner: Gradient-Guided Layer Pruning Enabling Efficient Fine-Tuning and Inference for LLMs",
      "authors": [
        "Wei Huang",
        "Anda Cheng",
        "Yinggui Wang"
      ],
      "abstract": "Fine-tuning Large Language Models (LLMs) with downstream data is often considered time-consuming and expensive. Structured pruning methods are primarily employed to improve the inference efficiency of pre-trained models. Meanwhile, they often require additional time and memory for training, knowledge distillation, structure search, and other strategies, making efficient model fine-tuning challenging to achieve. To simultaneously enhance the training and inference efficiency of downstream task fine-tuning, we introduce GradPruner, which can prune layers of LLMs guided by gradients in the early stages of fine-tuning. GradPruner uses the cumulative gradients of each parameter during the initial phase of fine-tuning to compute the Initial Gradient Information Accumulation Matrix (IGIA-Matrix) to assess the importance of layers and perform pruning. We sparsify the pruned layers based on the IGIA-Matrix and merge them with the remaining layers. Only elements with the same sign are merged to reduce interference from sign variations. We conducted extensive experiments on two LLMs across eight downstream datasets. Including medical, financial, and general benchmark tasks. The results demonstrate that GradPruner has achieved a parameter reduction of 40% with only a 0.99% decrease in accuracy. Our code is publicly available.",
      "pdf_url": "https://arxiv.org/pdf/2601.19503v1",
      "published": "2026-01-27T11:41:26+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.19503v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Cortex-Grounded Diffusion Models for Brain Image Generation",
      "authors": [
        "Fabian Bongratz",
        "Yitong Li",
        "Sama Elbaroudy",
        "Christian Wachinger"
      ],
      "abstract": "Synthetic neuroimaging data can mitigate critical limitations of real-world datasets, including the scarcity of rare phenotypes, domain shifts across scanners, and insufficient longitudinal coverage. However, existing generative models largely rely on weak conditioning signals, such as labels or text, which lack anatomical grounding and often produce biologically implausible outputs. To this end, we introduce Cor2Vox, a cortex-grounded generative framework for brain magnetic resonance image (MRI) synthesis that ties image generation to continuous structural priors of the cerebral cortex. It leverages high-resolution cortical surfaces to guide a 3D shape-to-image Brownian bridge diffusion process, enabling topologically faithful synthesis and precise control over underlying anatomies. To support the generation of new, realistic brain shapes, we developed a large-scale statistical shape model of cortical morphology derived from over 33,000 UK Biobank scans. We validated the fidelity of Cor2Vox based on traditional image quality metrics, advanced cortical surface reconstruction, and whole-brain segmentation quality, outperforming many baseline methods. Across three applications, namely (i) anatomically consistent synthesis, (ii) simulation of progressive gray matter atrophy, and (iii) harmonization of in-house frontotemporal dementia scans with public datasets, Cor2Vox preserved fine-grained cortical morphology at the sub-voxel level, exhibiting remarkable robustness to variations in cortical geometry and disease phenotype without retraining.",
      "pdf_url": "https://arxiv.org/pdf/2601.19498v1",
      "published": "2026-01-27T11:34:43+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.19498v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    }
  ]
}