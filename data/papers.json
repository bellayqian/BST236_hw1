{
  "last_updated": "2025-04-04T00:47:31.476250",
  "papers": [
    {
      "title": "The LLM Wears Prada: Analysing Gender Bias and Stereotypes through Online Shopping Data",
      "authors": [
        "Massimiliano Luca",
        "Ciro Beneduce",
        "Bruno Lepri",
        "Jacopo Staiano"
      ],
      "abstract": "With the wide and cross-domain adoption of Large Language Models, it becomes\ncrucial to assess to which extent the statistical correlations in training\ndata, which underlie their impressive performance, hide subtle and potentially\ntroubling biases. Gender bias in LLMs has been widely investigated from the\nperspectives of works, hobbies, and emotions typically associated with a\nspecific gender. In this study, we introduce a novel perspective. We\ninvestigate whether LLMs can predict an individual's gender based solely on\nonline shopping histories and whether these predictions are influenced by\ngender biases and stereotypes. Using a dataset of historical online purchases\nfrom users in the United States, we evaluate the ability of six LLMs to\nclassify gender and we then analyze their reasoning and products-gender\nco-occurrences. Results indicate that while models can infer gender with\nmoderate accuracy, their decisions are often rooted in stereotypical\nassociations between product categories and gender. Furthermore, explicit\ninstructions to avoid bias reduce the certainty of model predictions, but do\nnot eliminate stereotypical patterns. Our findings highlight the persistent\nnature of gender biases in LLMs and emphasize the need for robust\nbias-mitigation strategies.",
      "pdf_url": "http://arxiv.org/pdf/2504.01951v1",
      "published": "2025-04-02T17:56:08+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.01951v1",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ]
    },
    {
      "title": "Efficient Federated Learning Tiny Language Models for Mobile Network Feature Prediction",
      "authors": [
        "Daniel Becking",
        "Ingo Friese",
        "Karsten Müller",
        "Thomas Buchholz",
        "Mandy Galkow-Schneider",
        "Wojciech Samek",
        "Detlev Marpe"
      ],
      "abstract": "In telecommunications, Autonomous Networks (ANs) automatically adjust\nconfigurations based on specific requirements (e.g., bandwidth) and available\nresources. These networks rely on continuous monitoring and intelligent\nmechanisms for self-optimization, self-repair, and self-protection, nowadays\nenhanced by Neural Networks (NNs) to enable predictive modeling and pattern\nrecognition. Here, Federated Learning (FL) allows multiple AN cells - each\nequipped with NNs - to collaboratively train models while preserving data\nprivacy. However, FL requires frequent transmission of large neural data and\nthus an efficient, standardized compression strategy for reliable\ncommunication. To address this, we investigate NNCodec, a Fraunhofer\nimplementation of the ISO/IEC Neural Network Coding (NNC) standard, within a\nnovel FL framework that integrates tiny language models (TLMs) for various\nmobile network feature prediction (e.g., ping, SNR or band frequency). Our\nexperimental results on the Berlin V2X dataset demonstrate that NNCodec\nachieves transparent compression (i.e., negligible performance loss) while\nreducing communication overhead to below 1%, showing the effectiveness of\ncombining NNC with FL in collaboratively learned autonomous mobile networks.",
      "pdf_url": "http://arxiv.org/pdf/2504.01947v1",
      "published": "2025-04-02T17:54:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.01947v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "eess.SP"
      ]
    },
    {
      "title": "Critical Thinking: Which Kinds of Complexity Govern Optimal Reasoning Length?",
      "authors": [
        "Celine Lee",
        "Alexander M. Rush",
        "Keyon Vafa"
      ],
      "abstract": "Large language models (LLMs) often benefit from verbalized reasoning at\ninference time, but it remains unclear which aspects of task difficulty these\nextra reasoning tokens address. To investigate this question, we formalize a\nframework using deterministic finite automata (DFAs). DFAs offer a formalism\nthrough which we can characterize task complexity through measurable properties\nsuch as run length (number of reasoning steps required) and state-space size\n(decision complexity). We first show that across different tasks and models of\ndifferent sizes and training paradigms, there exists an optimal amount of\nreasoning tokens such that the probability of producing a correct solution is\nmaximized. We then investigate which properties of complexity govern this\ncritical length: we find that task instances with longer corresponding\nunderlying DFA runs (i.e. demand greater latent state-tracking requirements)\ncorrelate with longer reasoning lengths, but, surprisingly, that DFA size (i.e.\nstate-space complexity) does not. We then demonstrate an implication of these\nfindings: being able to predict the optimal number of reasoning tokens for new\nproblems and filtering out non-optimal length answers results in consistent\naccuracy improvements.",
      "pdf_url": "http://arxiv.org/pdf/2504.01935v1",
      "published": "2025-04-02T17:45:58+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.01935v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "A thorough benchmark of automatic text classification: From traditional approaches to large language models",
      "authors": [
        "Washington Cunha",
        "Leonardo Rocha",
        "Marcos André Gonçalves"
      ],
      "abstract": "Automatic text classification (ATC) has experienced remarkable advancements\nin the past decade, best exemplified by recent small and large language models\n(SLMs and LLMs), leveraged by Transformer architectures. Despite recent\neffectiveness improvements, a comprehensive cost-benefit analysis investigating\nwhether the effectiveness gains of these recent approaches compensate their\nmuch higher costs when compared to more traditional text classification\napproaches such as SVMs and Logistic Regression is still missing in the\nliterature. In this context, this work's main contributions are twofold: (i) we\nprovide a scientifically sound comparative analysis of the cost-benefit of\ntwelve traditional and recent ATC solutions including five open LLMs, and (ii)\na large benchmark comprising {22 datasets}, including sentiment analysis and\ntopic classification, with their (train-validation-test) partitions based on\nfolded cross-validation procedures, along with documentation, and code. The\nrelease of code, data, and documentation enables the community to replicate\nexperiments and advance the field in a more scientifically sound manner. Our\ncomparative experimental results indicate that LLMs outperform traditional\napproaches (up to 26%-7.1% on average) and SLMs (up to 4.9%-1.9% on average) in\nterms of effectiveness. However, LLMs incur significantly higher computational\ncosts due to fine-tuning, being, on average 590x and 8.5x slower than\ntraditional methods and SLMs, respectively. Results suggests the following\nrecommendations: (1) LLMs for applications that require the best possible\neffectiveness and can afford the costs; (2) traditional methods such as\nLogistic Regression and SVM for resource-limited applications or those that\ncannot afford the cost of tuning large LLMs; and (3) SLMs like Roberta for\nnear-optimal effectiveness-efficiency trade-off.",
      "pdf_url": "http://arxiv.org/pdf/2504.01930v1",
      "published": "2025-04-02T17:40:08+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.01930v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Equivariant Spherical CNNs for Accurate Fiber Orientation Distribution Estimation in Neonatal Diffusion MRI with Reduced Acquisition Time",
      "authors": [
        "Haykel Snoussi",
        "Davood Karimi"
      ],
      "abstract": "Early and accurate assessment of brain microstructure using diffusion\nMagnetic Resonance Imaging (dMRI) is crucial for identifying neurodevelopmental\ndisorders in neonates, but remains challenging due to low signal-to-noise ratio\n(SNR), motion artifacts, and ongoing myelination. In this study, we propose a\nrotationally equivariant Spherical Convolutional Neural Network (sCNN)\nframework tailored for neonatal dMRI. We predict the Fiber Orientation\nDistribution (FOD) from multi-shell dMRI signals acquired with a reduced set of\ngradient directions (30% of the full protocol), enabling faster and more\ncost-effective acquisitions. We train and evaluate the performance of our sCNN\nusing real data from 43 neonatal dMRI datasets provided by the Developing Human\nConnectome Project (dHCP). Our results demonstrate that the sCNN achieves\nsignificantly lower mean squared error (MSE) and higher angular correlation\ncoefficient (ACC) compared to a Multi-Layer Perceptron (MLP) baseline,\nindicating improved accuracy in FOD estimation. Furthermore, tractography\nresults based on the sCNN-predicted FODs show improved anatomical plausibility,\ncoverage, and coherence compared to those from the MLP. These findings\nhighlight that sCNNs, with their inherent rotational equivariance, offer a\npromising approach for accurate and clinically efficient dMRI analysis, paving\nthe way for improved diagnostic capabilities and characterization of early\nbrain development.",
      "pdf_url": "http://arxiv.org/pdf/2504.01925v1",
      "published": "2025-04-02T17:36:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.01925v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Bridging the Linguistic Divide: A Survey on Leveraging Large Language Models for Machine Translation",
      "authors": [
        "Baban Gain",
        "Dibyanayan Bandyopadhyay",
        "Asif Ekbal"
      ],
      "abstract": "The advent of Large Language Models (LLMs) has significantly reshaped the\nlandscape of machine translation (MT), particularly for low-resource languages\nand domains that lack sufficient parallel corpora, linguistic tools, and\ncomputational infrastructure. This survey presents a comprehensive overview of\nrecent progress in leveraging LLMs for MT. We analyze techniques such as\nfew-shot prompting, cross-lingual transfer, and parameter-efficient fine-tuning\nthat enable effective adaptation to under-resourced settings. The paper also\nexplores synthetic data generation strategies using LLMs, including\nback-translation and lexical augmentation. Additionally, we compare LLM-based\ntranslation with traditional encoder-decoder models across diverse language\npairs, highlighting the strengths and limitations of each. We discuss\npersistent challenges such as hallucinations, evaluation inconsistencies, and\ninherited biases while also evaluating emerging LLM-driven metrics for\ntranslation quality. This survey offers practical insights and outlines future\ndirections for building robust, inclusive, and scalable MT systems in the era\nof large-scale generative models.",
      "pdf_url": "http://arxiv.org/pdf/2504.01919v1",
      "published": "2025-04-02T17:26:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.01919v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "FineLIP: Extending CLIP's Reach via Fine-Grained Alignment with Longer Text Inputs",
      "authors": [
        "Mothilal Asokan",
        "Kebin Wu",
        "Fatima Albreiki"
      ],
      "abstract": "As a pioneering vision-language model, CLIP (Contrastive Language-Image\nPre-training) has achieved significant success across various domains and a\nwide range of downstream vision-language tasks. However, the text encoders in\npopular CLIP models are limited to processing only 77 text tokens, which\nconstrains their ability to effectively handle longer, detail-rich captions.\nAdditionally, CLIP models often struggle to effectively capture detailed visual\nand textual information, which hampers their performance on tasks that require\nfine-grained analysis. To address these limitations, we present a novel\napproach, \\textbf{FineLIP}, that extends the capabilities of CLIP. FineLIP\nenhances cross-modal text-image mapping by incorporating \\textbf{Fine}-grained\nalignment with \\textbf{L}onger text input within the CL\\textbf{IP}-style\nframework. FineLIP first extends the positional embeddings to handle longer\ntext, followed by the dynamic aggregation of local image and text tokens. The\naggregated results are then used to enforce fine-grained token-to-token\ncross-modal alignment. We validate our model on datasets with long, detailed\ncaptions across two tasks: zero-shot cross-modal retrieval and text-to-image\ngeneration. Quantitative and qualitative experimental results demonstrate the\neffectiveness of FineLIP, outperforming existing state-of-the-art approaches.\nFurthermore, comprehensive ablation studies validate the benefits of key design\nelements within FineLIP.",
      "pdf_url": "http://arxiv.org/pdf/2504.01916v1",
      "published": "2025-04-02T17:19:59+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.01916v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Advancing AI-Scientist Understanding: Making LLM Think Like a Physicist with Interpretable Reasoning",
      "authors": [
        "Yinggan Xu",
        "Hana Kimlee",
        "Yijia Xiao",
        "Di Luo"
      ],
      "abstract": "Large Language Models (LLMs) are playing an expanding role in physics\nresearch by enhancing reasoning, symbolic manipulation, and numerical\ncomputation. However, ensuring the reliability and interpretability of their\noutputs remains a significant challenge. In our framework, we conceptualize the\ncollaboration between AI and human scientists as a dynamic interplay among\nthree modules: the reasoning module, the interpretation module, and the\nAI-scientist interaction module. Recognizing that effective physics reasoning\ndemands rigorous logical consistency, quantitative precision, and deep\nintegration with established theoretical models, we introduce the\ninterpretation module to improve the understanding of AI-generated outputs,\nwhich is not previously explored in the literature. This module comprises\nmultiple specialized agents, including summarizers, model builders, UI\nbuilders, and testers, which collaboratively structure LLM outputs within a\nphysically grounded framework, by constructing a more interpretable science\nmodel. A case study demonstrates that our approach enhances transparency,\nfacilitates validation, and strengthens AI-augmented reasoning in scientific\ndiscovery.",
      "pdf_url": "http://arxiv.org/pdf/2504.01911v1",
      "published": "2025-04-02T17:13:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.01911v1",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ]
    },
    {
      "title": "Benchmarking Synthetic Tabular Data: A Multi-Dimensional Evaluation Framework",
      "authors": [
        "Andrey Sidorenko",
        "Michael Platzer",
        "Mario Scriminaci",
        "Paul Tiwald"
      ],
      "abstract": "Evaluating the quality of synthetic data remains a key challenge for ensuring\nprivacy and utility in data-driven research. In this work, we present an\nevaluation framework that quantifies how well synthetic data replicates\noriginal distributional properties while ensuring privacy. The proposed\napproach employs a holdout-based benchmarking strategy that facilitates\nquantitative assessment through low- and high-dimensional distribution\ncomparisons, embedding-based similarity measures, and nearest-neighbor distance\nmetrics. The framework supports various data types and structures, including\nsequential and contextual information, and enables interpretable quality\ndiagnostics through a set of standardized metrics. These contributions aim to\nsupport reproducibility and methodological consistency in benchmarking of\nsynthetic data generation techniques. The code of the framework is available at\nhttps://github.com/mostly-ai/mostlyai-qa.",
      "pdf_url": "http://arxiv.org/pdf/2504.01908v1",
      "published": "2025-04-02T17:10:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.01908v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Accelerating IoV Intrusion Detection: Benchmarking GPU-Accelerated vs CPU-Based ML Libraries",
      "authors": [
        "Furkan Çolhak",
        "Hasan Coşkun",
        "Tsafac Nkombong Regine Cyrille",
        "Tedi Hoxa",
        "Mert İlhan Ecevit",
        "Mehmet Nafiz Aydın"
      ],
      "abstract": "The Internet of Vehicles (IoV) may face challenging cybersecurity attacks\nthat may require sophisticated intrusion detection systems, necessitating a\nrapid development and response system. This research investigates the\nperformance advantages of GPU-accelerated libraries (cuML) compared to\ntraditional CPU-based implementations (scikit-learn), focusing on the speed and\nefficiency required for machine learning models used in IoV threat detection\nenvironments. The comprehensive evaluations conducted employ four machine\nlearning approaches (Random Forest, KNN, Logistic Regression, XGBoost) across\nthree distinct IoV security datasets (OTIDS, GIDS, CICIoV2024). Our findings\ndemonstrate that GPU-accelerated implementations dramatically improved\ncomputational efficiency, with training times reduced by a factor of up to 159\nand prediction speeds accelerated by up to 95 times compared to traditional CPU\nprocessing, all while preserving detection accuracy. This remarkable\nperformance breakthrough empowers researchers and security specialists to\nharness GPU acceleration for creating faster, more effective threat detection\nsystems that meet the urgent real-time security demands of today's connected\nvehicle networks.",
      "pdf_url": "http://arxiv.org/pdf/2504.01905v2",
      "published": "2025-04-02T17:04:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.01905v2",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ]
    },
    {
      "title": "STAR-1: Safer Alignment of Reasoning LLMs with 1K Data",
      "authors": [
        "Zijun Wang",
        "Haoqin Tu",
        "Yuhan Wang",
        "Juncheng Wu",
        "Jieru Mei",
        "Brian R. Bartoldson",
        "Bhavya Kailkhura",
        "Cihang Xie"
      ],
      "abstract": "This paper introduces STAR-1, a high-quality, just-1k-scale safety dataset\nspecifically designed for large reasoning models (LRMs) like DeepSeek-R1. Built\non three core principles -- diversity, deliberative reasoning, and rigorous\nfiltering -- STAR-1 aims to address the critical needs for safety alignment in\nLRMs. Specifically, we begin by integrating existing open-source safety\ndatasets from diverse sources. Then, we curate safety policies to generate\npolicy-grounded deliberative reasoning samples. Lastly, we apply a GPT-4o-based\nsafety scoring system to select training examples aligned with best practices.\nExperimental results show that fine-tuning LRMs with STAR-1 leads to an average\n40% improvement in safety performance across four benchmarks, while only\nincurring a marginal decrease (e.g., an average of 1.1%) in reasoning ability\nmeasured across five reasoning tasks. Extensive ablation studies further\nvalidate the importance of our design principles in constructing STAR-1 and\nanalyze its efficacy across both LRMs and traditional LLMs. Our project page is\nhttps://ucsc-vlaa.github.io/STAR-1.",
      "pdf_url": "http://arxiv.org/pdf/2504.01903v1",
      "published": "2025-04-02T17:04:04+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.01903v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Graphically Speaking: Unmasking Abuse in Social Media with Conversation Insights",
      "authors": [
        "Célia Nouri",
        "Jean-Philippe Cointet",
        "Chloé Clavel"
      ],
      "abstract": "Detecting abusive language in social media conversations poses significant\nchallenges, as identifying abusiveness often depends on the conversational\ncontext, characterized by the content and topology of preceding comments.\nTraditional Abusive Language Detection (ALD) models often overlook this\ncontext, which can lead to unreliable performance metrics. Recent Natural\nLanguage Processing (NLP) methods that integrate conversational context often\ndepend on limited and simplified representations, and report inconsistent\nresults. In this paper, we propose a novel approach that utilize graph neural\nnetworks (GNNs) to model social media conversations as graphs, where nodes\nrepresent comments, and edges capture reply structures. We systematically\ninvestigate various graph representations and context windows to identify the\noptimal configuration for ALD. Our GNN model outperform both context-agnostic\nbaselines and linear context-aware methods, achieving significant improvements\nin F1 scores. These findings demonstrate the critical role of structured\nconversational context and establish GNNs as a robust framework for advancing\ncontext-aware abusive language detection.",
      "pdf_url": "http://arxiv.org/pdf/2504.01902v1",
      "published": "2025-04-02T17:03:37+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.01902v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Ross3D: Reconstructive Visual Instruction Tuning with 3D-Awareness",
      "authors": [
        "Haochen Wang",
        "Yucheng Zhao",
        "Tiancai Wang",
        "Haoqiang Fan",
        "Xiangyu Zhang",
        "Zhaoxiang Zhang"
      ],
      "abstract": "The rapid development of Large Multimodal Models (LMMs) for 2D images and\nvideos has spurred efforts to adapt these models for interpreting 3D scenes.\nHowever, the absence of large-scale 3D vision-language datasets has posed a\nsignificant obstacle. To address this issue, typical approaches focus on\ninjecting 3D awareness into 2D LMMs by designing 3D input-level scene\nrepresentations. This work provides a new perspective. We introduce\nreconstructive visual instruction tuning with 3D-awareness (Ross3D), which\nintegrates 3D-aware visual supervision into the training procedure.\nSpecifically, it incorporates cross-view and global-view reconstruction. The\nformer requires reconstructing masked views by aggregating overlapping\ninformation from other views. The latter aims to aggregate information from all\navailable views to recover Bird's-Eye-View images, contributing to a\ncomprehensive overview of the entire scene. Empirically, Ross3D achieves\nstate-of-the-art performance across various 3D scene understanding benchmarks.\nMore importantly, our semi-supervised experiments demonstrate significant\npotential in leveraging large amounts of unlabeled 3D vision-only data.",
      "pdf_url": "http://arxiv.org/pdf/2504.01901v1",
      "published": "2025-04-02T16:59:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.01901v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.RO"
      ]
    },
    {
      "title": "A novel gesture interaction control method for rehabilitation lower extremity exoskeleton",
      "authors": [
        "Shuang Qiu",
        "Zhongcai Pei",
        "Chen Wang",
        "Jing Zhang",
        "Zhiyong Tang"
      ],
      "abstract": "With the rapid development of Rehabilitation Lower Extremity Robotic\nExoskeletons (RLEEX) technology, significant advancements have been made in\nHuman-Robot Interaction (HRI) methods. These include traditional physical HRI\nmethods that are easily recognizable and various bio-electrical signal-based\nHRI methods that can visualize and predict actions. However, most of these HRI\nmethods are contact-based, facing challenges such as operational complexity,\nsensitivity to interference, risks associated with implantable devices, and,\nmost importantly, limitations in comfort. These challenges render the\ninteraction less intuitive and natural, which can negatively impact patient\nmotivation for rehabilitation. To address these issues, this paper proposes a\nnovel non-contact gesture interaction control method for RLEEX, based on RGB\nmonocular camera depth estimation. This method integrates three key steps:\ndetecting keypoints, recognizing gestures, and assessing distance, thereby\napplying gesture information and augmented reality triggering technology to\ncontrol gait movements of RLEEX. Results indicate that this approach provides a\nfeasible solution to the problems of poor comfort, low reliability, and high\nlatency in HRI for RLEEX platforms. Specifically, it achieves a\ngesture-controlled exoskeleton motion accuracy of 94.11\\% and an average system\nresponse time of 0.615 seconds through non-contact HRI. The proposed\nnon-contact HRI method represents a pioneering advancement in control\ninteractions for RLEEX, paving the way for further exploration and development\nin this field.",
      "pdf_url": "http://arxiv.org/pdf/2504.01888v1",
      "published": "2025-04-02T16:46:01+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.01888v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.HC"
      ]
    },
    {
      "title": "CoRAG: Collaborative Retrieval-Augmented Generation",
      "authors": [
        "Aashiq Muhamed",
        "Mona Diab",
        "Virginia Smith"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) models excel in knowledge-intensive\ntasks, especially under few-shot learning constraints. We introduce CoRAG, a\nframework extending RAG to collaborative settings, where clients jointly train\na shared model using a collaborative passage store. To evaluate CoRAG, we\nintroduce CRAB, a benchmark for collaborative homogeneous open-domain question\nanswering. Our experiments demonstrate that CoRAG consistently outperforms both\nparametric collaborative learning methods and locally trained RAG models in\nlow-resource scenarios. Further analysis reveals the critical importance of\nrelevant passages within the shared store, the surprising benefits of\nincorporating irrelevant passages, and the potential for hard negatives to\nnegatively impact performance. This introduces a novel consideration in\ncollaborative RAG: the trade-off between leveraging a collectively enriched\nknowledge base and the potential risk of incorporating detrimental passages\nfrom other clients. Our findings underscore the viability of CoRAG, while also\nhighlighting key design challenges and promising avenues for future research.",
      "pdf_url": "http://arxiv.org/pdf/2504.01883v1",
      "published": "2025-04-02T16:40:43+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.01883v1",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.IR",
        "cs.LG"
      ]
    },
    {
      "title": "Interpreting Emergent Planning in Model-Free Reinforcement Learning",
      "authors": [
        "Thomas Bush",
        "Stephen Chung",
        "Usman Anwar",
        "Adrià Garriga-Alonso",
        "David Krueger"
      ],
      "abstract": "We present the first mechanistic evidence that model-free reinforcement\nlearning agents can learn to plan. This is achieved by applying a methodology\nbased on concept-based interpretability to a model-free agent in Sokoban -- a\ncommonly used benchmark for studying planning. Specifically, we demonstrate\nthat DRC, a generic model-free agent introduced by Guez et al. (2019), uses\nlearned concept representations to internally formulate plans that both predict\nthe long-term effects of actions on the environment and influence action\nselection. Our methodology involves: (1) probing for planning-relevant\nconcepts, (2) investigating plan formation within the agent's representations,\nand (3) verifying that discovered plans (in the agent's representations) have a\ncausal effect on the agent's behavior through interventions. We also show that\nthe emergence of these plans coincides with the emergence of a planning-like\nproperty: the ability to benefit from additional test-time compute. Finally, we\nperform a qualitative analysis of the planning algorithm learned by the agent\nand discover a strong resemblance to parallelized bidirectional search. Our\nfindings advance understanding of the internal mechanisms underlying planning\nbehavior in agents, which is important given the recent trend of emergent\nplanning and reasoning capabilities in LLMs through RL",
      "pdf_url": "http://arxiv.org/pdf/2504.01871v1",
      "published": "2025-04-02T16:24:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.01871v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "From Code Generation to Software Testing: AI Copilot with Context-Based RAG",
      "authors": [
        "Yuchen Wang",
        "Shangxin Guo",
        "Chee Wei Tan"
      ],
      "abstract": "The rapid pace of large-scale software development places increasing demands\non traditional testing methodologies, often leading to bottlenecks in\nefficiency, accuracy, and coverage. We propose a novel perspective on software\ntesting by positing bug detection and coding with fewer bugs as two\ninterconnected problems that share a common goal, which is reducing bugs with\nlimited resources. We extend our previous work on AI-assisted programming,\nwhich supports code auto-completion and chatbot-powered Q&A, to the realm of\nsoftware testing. We introduce Copilot for Testing, an automated testing system\nthat synchronizes bug detection with codebase updates, leveraging context-based\nRetrieval Augmented Generation (RAG) to enhance the capabilities of large\nlanguage models (LLMs). Our evaluation demonstrates a 31.2% improvement in bug\ndetection accuracy, a 12.6% increase in critical test coverage, and a 10.5%\nhigher user acceptance rate, highlighting the transformative potential of\nAI-driven technologies in modern software development practices.",
      "pdf_url": "http://arxiv.org/pdf/2504.01866v1",
      "published": "2025-04-02T16:20:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.01866v1",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.PL"
      ]
    },
    {
      "title": "Cross-Lingual Consistency: A Novel Inference Framework for Advancing Reasoning in Large Language Models",
      "authors": [
        "Zhiwei Yu",
        "Tuo Li",
        "Changhong Wang",
        "Hui Chen",
        "Lang Zhou"
      ],
      "abstract": "Chain-of-thought (CoT) has emerged as a critical mechanism for enhancing\nreasoning capabilities in large language models (LLMs), with self-consistency\ndemonstrating notable promise in boosting performance. However, inherent\nlinguistic biases in multilingual training corpora frequently cause semantic\ndrift and logical inconsistencies, especially in sub-10B parameter LLMs\nhandling complex inference tasks. To overcome these constraints, we propose the\nCross-Lingual Consistency (CLC) framework, an innovative inference paradigm\nthat integrates multilingual reasoning paths through majority voting to elevate\nLLMs' reasoning capabilities. Empirical evaluations on the CMATH dataset reveal\nCLC's superiority over the conventional self-consistency method, delivering\n9.5%, 6.5%, and 6.0% absolute accuracy gains for DeepSeek-Math-7B-Instruct,\nQwen2.5-Math-7B-Instruct, and Gemma2-9B-Instruct respectively. Expanding CLC's\nlinguistic scope to 11 diverse languages implies two synergistic benefits: 1)\nneutralizing linguistic biases in multilingual training corpora through\nmultilingual ensemble voting, 2) escaping monolingual reasoning traps by\nexploring the broader multilingual solution space. This dual benefits\nempirically enables more globally optimal reasoning paths compared to\nmonolingual self-consistency baselines, as evidenced by the 4.1%-18.5% accuracy\ngains using Gemma2-9B-Instruct on the MGSM dataset.",
      "pdf_url": "http://arxiv.org/pdf/2504.01857v1",
      "published": "2025-04-02T16:09:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.01857v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Enhanced Diffusion Sampling via Extrapolation with Multiple ODE Solutions",
      "authors": [
        "Jinyoung Choi",
        "Junoh Kang",
        "Bohyung Han"
      ],
      "abstract": "Diffusion probabilistic models (DPMs), while effective in generating\nhigh-quality samples, often suffer from high computational costs due to their\niterative sampling process. To address this, we propose an enhanced ODE-based\nsampling method for DPMs inspired by Richardson extrapolation, which reduces\nnumerical error and improves convergence rates. Our method, RX-DPM, leverages\nmultiple ODE solutions at intermediate time steps to extrapolate the denoised\nprediction in DPMs. This significantly enhances the accuracy of estimations for\nthe final sample while maintaining the number of function evaluations (NFEs).\nUnlike standard Richardson extrapolation, which assumes uniform discretization\nof the time grid, we develop a more general formulation tailored to arbitrary\ntime step scheduling, guided by local truncation error derived from a baseline\nsampling method. The simplicity of our approach facilitates accurate estimation\nof numerical solutions without significant computational overhead, and allows\nfor seamless and convenient integration into various DPMs and solvers.\nAdditionally, RX-DPM provides explicit error estimates, effectively\ndemonstrating the faster convergence as the leading error term's order\nincreases. Through a series of experiments, we show that the proposed method\nimproves the quality of generated samples without requiring additional sampling\niterations.",
      "pdf_url": "http://arxiv.org/pdf/2504.01855v1",
      "published": "2025-04-02T16:06:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.01855v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Code Red! On the Harmfulness of Applying Off-the-shelf Large Language Models to Programming Tasks",
      "authors": [
        "Ali Al-Kaswan",
        "Sebastian Deatc",
        "Begüm Koç",
        "Arie van Deursen",
        "Maliheh Izadi"
      ],
      "abstract": "Nowadays, developers increasingly rely on solutions powered by Large Language\nModels (LLM) to assist them with their coding tasks. This makes it crucial to\nalign these tools with human values to prevent malicious misuse. In this paper,\nwe propose a comprehensive framework for assessing the potential harmfulness of\nLLMs within the software engineering domain. We begin by developing a taxonomy\nof potentially harmful software engineering scenarios and subsequently, create\na dataset of prompts based on this taxonomy. To systematically assess the\nresponses, we design and validate an automatic evaluator that classifies the\noutputs of a variety of LLMs both open-source and closed-source models, as well\nas general-purpose and code-specific LLMs. Furthermore, we investigate the\nimpact of models size, architecture family, and alignment strategies on their\ntendency to generate harmful content. The results show significant disparities\nin the alignment of various LLMs for harmlessness. We find that some models and\nmodel families, such as Openhermes, are more harmful than others and that\ncode-specific models do not perform better than their general-purpose\ncounterparts. Notably, some fine-tuned models perform significantly worse than\ntheir base-models due to their design choices. On the other side, we find that\nlarger models tend to be more helpful and are less likely to respond with\nharmful information. These results highlight the importance of targeted\nalignment strategies tailored to the unique challenges of software engineering\ntasks and provide a foundation for future work in this critical area.",
      "pdf_url": "http://arxiv.org/pdf/2504.01850v1",
      "published": "2025-04-02T16:00:14+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.01850v1",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "An Approach to Technical AGI Safety and Security",
      "authors": [
        "Rohin Shah",
        "Alex Irpan",
        "Alexander Matt Turner",
        "Anna Wang",
        "Arthur Conmy",
        "David Lindner",
        "Jonah Brown-Cohen",
        "Lewis Ho",
        "Neel Nanda",
        "Raluca Ada Popa",
        "Rishub Jain",
        "Rory Greig",
        "Samuel Albanie",
        "Scott Emmons",
        "Sebastian Farquhar",
        "Sébastien Krier",
        "Senthooran Rajamanoharan",
        "Sophie Bridgers",
        "Tobi Ijitoye",
        "Tom Everitt",
        "Victoria Krakovna",
        "Vikrant Varma",
        "Vladimir Mikulik",
        "Zachary Kenton",
        "Dave Orr",
        "Shane Legg",
        "Noah Goodman",
        "Allan Dafoe",
        "Four Flynn",
        "Anca Dragan"
      ],
      "abstract": "Artificial General Intelligence (AGI) promises transformative benefits but\nalso presents significant risks. We develop an approach to address the risk of\nharms consequential enough to significantly harm humanity. We identify four\nareas of risk: misuse, misalignment, mistakes, and structural risks. Of these,\nwe focus on technical approaches to misuse and misalignment. For misuse, our\nstrategy aims to prevent threat actors from accessing dangerous capabilities,\nby proactively identifying dangerous capabilities, and implementing robust\nsecurity, access restrictions, monitoring, and model safety mitigations. To\naddress misalignment, we outline two lines of defense. First, model-level\nmitigations such as amplified oversight and robust training can help to build\nan aligned model. Second, system-level security measures such as monitoring and\naccess control can mitigate harm even if the model is misaligned. Techniques\nfrom interpretability, uncertainty estimation, and safer design patterns can\nenhance the effectiveness of these mitigations. Finally, we briefly outline how\nthese ingredients could be combined to produce safety cases for AGI systems.",
      "pdf_url": "http://arxiv.org/pdf/2504.01849v1",
      "published": "2025-04-02T15:59:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.01849v1",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ]
    },
    {
      "title": "PaperBench: Evaluating AI's Ability to Replicate AI Research",
      "authors": [
        "Giulio Starace",
        "Oliver Jaffe",
        "Dane Sherburn",
        "James Aung",
        "Jun Shern Chan",
        "Leon Maksin",
        "Rachel Dias",
        "Evan Mays",
        "Benjamin Kinsella",
        "Wyatt Thompson",
        "Johannes Heidecke",
        "Amelia Glaese",
        "Tejal Patwardhan"
      ],
      "abstract": "We introduce PaperBench, a benchmark evaluating the ability of AI agents to\nreplicate state-of-the-art AI research. Agents must replicate 20 ICML 2024\nSpotlight and Oral papers from scratch, including understanding paper\ncontributions, developing a codebase, and successfully executing experiments.\nFor objective evaluation, we develop rubrics that hierarchically decompose each\nreplication task into smaller sub-tasks with clear grading criteria. In total,\nPaperBench contains 8,316 individually gradable tasks. Rubrics are co-developed\nwith the author(s) of each ICML paper for accuracy and realism. To enable\nscalable evaluation, we also develop an LLM-based judge to automatically grade\nreplication attempts against rubrics, and assess our judge's performance by\ncreating a separate benchmark for judges. We evaluate several frontier models\non PaperBench, finding that the best-performing tested agent, Claude 3.5 Sonnet\n(New) with open-source scaffolding, achieves an average replication score of\n21.0\\%. Finally, we recruit top ML PhDs to attempt a subset of PaperBench,\nfinding that models do not yet outperform the human baseline. We\n\\href{https://github.com/openai/preparedness}{open-source our code} to\nfacilitate future research in understanding the AI engineering capabilities of\nAI agents.",
      "pdf_url": "http://arxiv.org/pdf/2504.01848v1",
      "published": "2025-04-02T15:55:24+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.01848v1",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "YourBench: Easy Custom Evaluation Sets for Everyone",
      "authors": [
        "Sumuk Shashidhar",
        "Clémentine Fourrier",
        "Alina Lozovskia",
        "Thomas Wolf",
        "Gokhan Tur",
        "Dilek Hakkani-Tür"
      ],
      "abstract": "Evaluating large language models (LLMs) effectively remains a critical\nbottleneck, as traditional static benchmarks suffer from saturation and\ncontamination, while human evaluations are costly and slow. This hinders timely\nor domain-specific assessment, crucial for real-world applications. We\nintroduce YourBench, a novel, open-source framework that addresses these\nlimitations by enabling dynamic, automated generation of reliable, up-to-date,\nand domain-tailored benchmarks cheaply and without manual annotation, directly\nfrom user-provided documents. We demonstrate its efficacy by replicating 7\ndiverse MMLU subsets using minimal source text, achieving this for under 15 USD\nin total inference costs while perfectly preserving the relative model\nperformance rankings (Spearman Rho = 1) observed on the original benchmark. To\nensure that YourBench generates data grounded in provided input instead of\nrelying on posterior parametric knowledge in models, we also introduce\nTempora-0325, a novel dataset of over 7K diverse documents, published\nexclusively after March 2025. Our comprehensive analysis spans 26 SoTA models\nfrom 7 major families across varying scales (3-671B parameters) to validate the\nquality of generated evaluations through rigorous algorithmic checks (e.g.,\ncitation grounding) and human assessments. We release the YourBench library,\nthe Tempora-0325 dataset, 150k+ question answer pairs based on Tempora and all\nevaluation and inference traces to facilitate reproducible research and empower\nthe community to generate bespoke benchmarks on demand, fostering more relevant\nand trustworthy LLM evaluation.",
      "pdf_url": "http://arxiv.org/pdf/2504.01833v1",
      "published": "2025-04-02T15:40:24+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.01833v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.1"
      ]
    },
    {
      "title": "Implicit Bias Injection Attacks against Text-to-Image Diffusion Models",
      "authors": [
        "Huayang Huang",
        "Xiangye Jin",
        "Jiaxu Miao",
        "Yu Wu"
      ],
      "abstract": "The proliferation of text-to-image diffusion models (T2I DMs) has led to an\nincreased presence of AI-generated images in daily life. However, biased T2I\nmodels can generate content with specific tendencies, potentially influencing\npeople's perceptions. Intentional exploitation of these biases risks conveying\nmisleading information to the public. Current research on bias primarily\naddresses explicit biases with recognizable visual patterns, such as skin color\nand gender. This paper introduces a novel form of implicit bias that lacks\nexplicit visual features but can manifest in diverse ways across various\nsemantic contexts. This subtle and versatile nature makes this bias challenging\nto detect, easy to propagate, and adaptable to a wide range of scenarios. We\nfurther propose an implicit bias injection attack framework (IBI-Attacks)\nagainst T2I diffusion models by precomputing a general bias direction in the\nprompt embedding space and adaptively adjusting it based on different inputs.\nOur attack module can be seamlessly integrated into pre-trained diffusion\nmodels in a plug-and-play manner without direct manipulation of user input or\nmodel retraining. Extensive experiments validate the effectiveness of our\nscheme in introducing bias through subtle and diverse modifications while\npreserving the original semantics. The strong concealment and transferability\nof our attack across various scenarios further underscore the significance of\nour approach. Code is available at https://github.com/Hannah1102/IBI-attacks.",
      "pdf_url": "http://arxiv.org/pdf/2504.01819v1",
      "published": "2025-04-02T15:24:12+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.01819v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "A Novel Approach To Implementing Knowledge Distillation In Tsetlin Machines",
      "authors": [
        "Calvin Kinateder"
      ],
      "abstract": "The Tsetlin Machine (TM) is a propositional logic based model that uses\nconjunctive clauses to learn patterns from data. As with typical neural\nnetworks, the performance of a Tsetlin Machine is largely dependent on its\nparameter count, with a larger number of parameters producing higher accuracy\nbut slower execution. Knowledge distillation in neural networks transfers\ninformation from an already-trained teacher model to a smaller student model to\nincrease accuracy in the student without increasing execution time. We propose\na novel approach to implementing knowledge distillation in Tsetlin Machines by\nutilizing the probability distributions of each output sample in the teacher to\nprovide additional context to the student. Additionally, we propose a novel\nclause-transfer algorithm that weighs the importance of each clause in the\nteacher and initializes the student with only the most essential data. We find\nthat our algorithm can significantly improve performance in the student model\nwithout negatively impacting latency in the tested domains of image recognition\nand text classification.",
      "pdf_url": "http://arxiv.org/pdf/2504.01798v1",
      "published": "2025-04-02T15:06:27+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.01798v1",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.LO"
      ]
    },
    {
      "title": "Rethinking industrial artificial intelligence: a unified foundation framework",
      "authors": [
        "Jay Lee",
        "Hanqi Su"
      ],
      "abstract": "Recent advancement in industrial artificial intelligence (AI) is reshaping\nthe industry, driving smarter manufacturing, predictive maintenance, and\nintelligent decision-making. However, existing approaches often focus primarily\non algorithms and models, overlooking the importance of systematically\nintegrating domain knowledge, data, and models to ensure more comprehensive and\neffective AI solutions. Therefore, the effective development and deployment of\nIndustrial AI solutions require a more comprehensive and systematic approach.\nTo address this gap, this paper summarizes previous research and rethinks the\nrole of industrial AI and presents a unified industrial AI foundation framework\ncomprising three core modules: knowledge module, data module, and model module.\nThese modules help to extend and enhance the industrial AI methodology\nplatform, supporting various industrial applications. In addition, a case study\non rotating machinery diagnosis demonstrates the framework's effectiveness, and\nseveral future directions are highlighted for the development of the industrial\nAI foundation framework.",
      "pdf_url": "http://arxiv.org/pdf/2504.01797v1",
      "published": "2025-04-02T15:05:32+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.01797v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "CLaP -- State Detection from Time Series",
      "authors": [
        "Arik Ermshaus",
        "Patrick Schäfer",
        "Ulf Leser"
      ],
      "abstract": "The ever-growing amount of sensor data from machines, smart devices, and the\nenvironment leads to an abundance of high-resolution, unannotated time series\n(TS). These recordings encode the recognizable properties of latent states and\ntransitions from physical phenomena that can be modelled as abstract processes.\nThe unsupervised localization and identification of these states and their\ntransitions is the task of time series state detection (TSSD). We introduce\nCLaP, a new, highly accurate and efficient algorithm for TSSD. It leverages the\npredictive power of time series classification for TSSD in an unsupervised\nsetting by applying novel self-supervision techniques to detect whether data\nsegments emerge from the same state or not. To this end, CLaP cross-validates a\nclassifier with segment-labelled subsequences to quantify confusion between\nsegments. It merges labels from segments with high confusion, representing the\nsame latent state, if this leads to an increase in overall classification\nquality. We conducted an experimental evaluation using 391 TS from four\nbenchmarks and found CLaP to be significantly more precise in detecting states\nthan five state-of-the-art competitors. It achieves the best accuracy-runtime\ntradeoff and is scalable to large TS. We provide a Python implementation of\nCLaP, which can be deployed in TS analysis workflows.",
      "pdf_url": "http://arxiv.org/pdf/2504.01783v1",
      "published": "2025-04-02T14:46:42+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.01783v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DB"
      ]
    },
    {
      "title": "Enhancing Interpretability in Generative AI Through Search-Based Data Influence Analysis",
      "authors": [
        "Theodoros Aivalis",
        "Iraklis A. Klampanos",
        "Antonis Troumpoukis",
        "Joemon M. Jose"
      ],
      "abstract": "Generative AI models offer powerful capabilities but often lack transparency,\nmaking it difficult to interpret their output. This is critical in cases\ninvolving artistic or copyrighted content. This work introduces a\nsearch-inspired approach to improve the interpretability of these models by\nanalysing the influence of training data on their outputs. Our method provides\nobservational interpretability by focusing on a model's output rather than on\nits internal state. We consider both raw data and latent-space embeddings when\nsearching for the influence of data items in generated content. We evaluate our\nmethod by retraining models locally and by demonstrating the method's ability\nto uncover influential subsets in the training data. This work lays the\ngroundwork for future extensions, including user-based evaluations with domain\nexperts, which is expected to improve observational interpretability further.",
      "pdf_url": "http://arxiv.org/pdf/2504.01771v1",
      "published": "2025-04-02T14:29:37+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.01771v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Leveraging Embedding Techniques in Multimodal Machine Learning for Mental Illness Assessment",
      "authors": [
        "Abdelrahaman A. Hassan",
        "Abdelrahman A. Ali",
        "Aya E. Fouda",
        "Radwa J. Hanafy",
        "Mohammed E. Fouda"
      ],
      "abstract": "The increasing global prevalence of mental disorders, such as depression and\nPTSD, requires objective and scalable diagnostic tools. Traditional clinical\nassessments often face limitations in accessibility, objectivity, and\nconsistency. This paper investigates the potential of multimodal machine\nlearning to address these challenges, leveraging the complementary information\navailable in text, audio, and video data. Our approach involves a comprehensive\nanalysis of various data preprocessing techniques, including novel chunking and\nutterance-based formatting strategies. We systematically evaluate a range of\nstate-of-the-art embedding models for each modality and employ Convolutional\nNeural Networks (CNNs) and Bidirectional LSTM Networks (BiLSTMs) for feature\nextraction. We explore data-level, feature-level, and decision-level fusion\ntechniques, including a novel integration of Large Language Model (LLM)\npredictions. We also investigate the impact of replacing Multilayer Perceptron\nclassifiers with Support Vector Machines. We extend our analysis to severity\nprediction using PHQ-8 and PCL-C scores and multi-class classification\n(considering co-occurring conditions). Our results demonstrate that\nutterance-based chunking significantly improves performance, particularly for\ntext and audio modalities. Decision-level fusion, incorporating LLM\npredictions, achieves the highest accuracy, with a balanced accuracy of 94.8%\nfor depression and 96.2% for PTSD detection. The combination of CNN-BiLSTM\narchitectures with utterance-level chunking, coupled with the integration of\nexternal LLM, provides a powerful and nuanced approach to the detection and\nassessment of mental health conditions. Our findings highlight the potential of\nMMML for developing more accurate, accessible, and personalized mental\nhealthcare tools.",
      "pdf_url": "http://arxiv.org/pdf/2504.01767v1",
      "published": "2025-04-02T14:19:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.01767v1",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Dual-stream Transformer-GCN Model with Contextualized Representations Learning for Monocular 3D Human Pose Estimation",
      "authors": [
        "Mingrui Ye",
        "Lianping Yang",
        "Hegui Zhu",
        "Zenghao Zheng",
        "Xin Wang",
        "Yantao Lo"
      ],
      "abstract": "This paper introduces a novel approach to monocular 3D human pose estimation\nusing contextualized representation learning with the Transformer-GCN\ndual-stream model. Monocular 3D human pose estimation is challenged by depth\nambiguity, limited 3D-labeled training data, imbalanced modeling, and\nrestricted model generalization. To address these limitations, our work\nintroduces a groundbreaking motion pre-training method based on contextualized\nrepresentation learning. Specifically, our method involves masking 2D pose\nfeatures and utilizing a Transformer-GCN dual-stream model to learn\nhigh-dimensional representations through a self-distillation setup. By focusing\non contextualized representation learning and spatial-temporal modeling, our\napproach enhances the model's ability to understand spatial-temporal\nrelationships between postures, resulting in superior generalization.\nFurthermore, leveraging the Transformer-GCN dual-stream model, our approach\neffectively balances global and local interactions in video pose estimation.\nThe model adaptively integrates information from both the Transformer and GCN\nstreams, where the GCN stream effectively learns local relationships between\nadjacent key points and frames, while the Transformer stream captures\ncomprehensive global spatial and temporal features. Our model achieves\nstate-of-the-art performance on two benchmark datasets, with an MPJPE of 38.0mm\nand P-MPJPE of 31.9mm on Human3.6M, and an MPJPE of 15.9mm on MPI-INF-3DHP.\nFurthermore, visual experiments on public datasets and in-the-wild videos\ndemonstrate the robustness and generalization capabilities of our approach.",
      "pdf_url": "http://arxiv.org/pdf/2504.01764v1",
      "published": "2025-04-02T14:17:57+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.01764v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Style over Substance: Distilled Language Models Reason Via Stylistic Replication",
      "authors": [
        "Philip Lippmann",
        "Jie Yang"
      ],
      "abstract": "Specialized reasoning language models (RLMs) have demonstrated that scaling\ntest-time computation through detailed reasoning traces significantly enhances\nperformance. Although these traces effectively facilitate knowledge\ndistillation into smaller, instruction-tuned models, the precise nature of\ntransferred reasoning remains unclear. In this study, we investigate to what\nextent distilled models internalize replicated stylistic patterns during\nreasoning. To this end, we systematically analyze reasoning traces, identifying\nstructural and lexical patterns that characterize successful reasoning. We then\nintroduce two new datasets -- a dataset of emergent reasoning traces and a\nsynthetic dataset explicitly constructed to replicate these stylistic patterns\n-- to precisely examine their influence on distilled models' reasoning\ncapabilities. We find that models trained on the synthetic traces achieve\ncomparable performance, indicating that distilled reasoning abilities rely\nsignificantly on surface-level patterns. Surprisingly, we observe an increase\nin performance even when the synthetic traces are altered to lead to the wrong\nanswer. Our findings highlight how stylistic patterns can be leveraged to\nefficiently enhance LM reasoning across diverse model families.",
      "pdf_url": "http://arxiv.org/pdf/2504.01738v1",
      "published": "2025-04-02T13:50:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.01738v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "AdPO: Enhancing the Adversarial Robustness of Large Vision-Language Models with Preference Optimization",
      "authors": [
        "Chaohu Liu",
        "Tianyi Gui",
        "Yu Liu",
        "Linli Xu"
      ],
      "abstract": "Large Vision-Language Models (LVLMs), such as GPT-4o and LLaVA, have recently\nwitnessed remarkable advancements and are increasingly being deployed in\nreal-world applications. However, inheriting the sensitivity of visual neural\nnetworks, LVLMs remain vulnerable to adversarial attacks, which can result in\nerroneous or malicious outputs. While existing efforts utilize adversarial\nfine-tuning to enhance robustness, they often suffer from performance\ndegradation on clean inputs. In this paper, we proposes AdPO, a novel\nadversarial defense strategy for LVLMs based on preference optimization. For\nthe first time, we reframe adversarial training as a preference optimization\nproblem, aiming to enhance the model's preference for generating normal outputs\non clean inputs while rejecting the potential misleading outputs for\nadversarial examples. Notably, AdPO achieves this by solely modifying the image\nencoder, e.g., CLIP ViT, resulting in superior clean and adversarial\nperformance in a variety of downsream tasks. Considering that training involves\nlarge language models (LLMs), the computational cost increases significantly.\nWe validate that training on smaller LVLMs and subsequently transferring to\nlarger models can achieve competitive performance while maintaining efficiency\ncomparable to baseline methods. Our comprehensive experiments confirm the\neffectiveness of the proposed AdPO, which provides a novel perspective for\nfuture adversarial defense research.",
      "pdf_url": "http://arxiv.org/pdf/2504.01735v1",
      "published": "2025-04-02T13:43:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.01735v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Epistemic Skills: Reasoning about Knowledge and Oblivion",
      "authors": [
        "Xiaolong Liang",
        "Yì N. Wáng"
      ],
      "abstract": "This paper presents a class of epistemic logics that captures the dynamics of\nacquiring knowledge and descending into oblivion, while incorporating concepts\nof group knowledge. The approach is grounded in a system of weighted models,\nintroducing an ``epistemic skills'' metric to represent the epistemic\ncapacities tied to knowledge updates. Within this framework, knowledge\nacquisition is modeled as a process of upskilling, whereas oblivion is\nrepresented as a consequence of downskilling. The framework further enables\nexploration of ``knowability'' and ``forgettability,'' defined as the potential\nto gain knowledge through upskilling and to lapse into oblivion through\ndownskilling, respectively. Additionally, it supports a detailed analysis of\nthe distinctions between epistemic de re and de dicto expressions. The\ncomputational complexity of the model checking and satisfiability problems is\nexamined, offering insights into their theoretical foundations and practical\nimplications.",
      "pdf_url": "http://arxiv.org/pdf/2504.01733v1",
      "published": "2025-04-02T13:41:42+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.01733v1",
      "categories": [
        "cs.AI",
        "cs.CC",
        "cs.LO"
      ]
    },
    {
      "title": "DreamActor-M1: Holistic, Expressive and Robust Human Image Animation with Hybrid Guidance",
      "authors": [
        "Yuxuan Luo",
        "Zhengkun Rong",
        "Lizhen Wang",
        "Longhao Zhang",
        "Tianshu Hu",
        "Yongming Zhu"
      ],
      "abstract": "While recent image-based human animation methods achieve realistic body and\nfacial motion synthesis, critical gaps remain in fine-grained holistic\ncontrollability, multi-scale adaptability, and long-term temporal coherence,\nwhich leads to their lower expressiveness and robustness. We propose a\ndiffusion transformer (DiT) based framework, DreamActor-M1, with hybrid\nguidance to overcome these limitations. For motion guidance, our hybrid control\nsignals that integrate implicit facial representations, 3D head spheres, and 3D\nbody skeletons achieve robust control of facial expressions and body movements,\nwhile producing expressive and identity-preserving animations. For scale\nadaptation, to handle various body poses and image scales ranging from\nportraits to full-body views, we employ a progressive training strategy using\ndata with varying resolutions and scales. For appearance guidance, we integrate\nmotion patterns from sequential frames with complementary visual references,\nensuring long-term temporal coherence for unseen regions during complex\nmovements. Experiments demonstrate that our method outperforms the\nstate-of-the-art works, delivering expressive results for portraits,\nupper-body, and full-body generation with robust long-term consistency. Project\nPage: https://grisoon.github.io/DreamActor-M1/.",
      "pdf_url": "http://arxiv.org/pdf/2504.01724v1",
      "published": "2025-04-02T13:30:32+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.01724v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "InfiniteICL: Breaking the Limit of Context Window Size via Long Short-term Memory Transformation",
      "authors": [
        "Bowen Cao",
        "Deng Cai",
        "Wai Lam"
      ],
      "abstract": "In-context learning (ICL) is critical for large language models (LLMs), but\nits effectiveness is constrained by finite context windows, particularly in\nultra-long contexts. To overcome this, we introduce InfiniteICL, a framework\nthat parallels context and parameters in LLMs with short- and long-term memory\nin human cognitive systems, focusing on transforming temporary context\nknowledge into permanent parameter updates. This approach significantly reduces\nmemory usage, maintains robust performance across varying input lengths, and\ntheoretically enables infinite context integration through the principles of\ncontext knowledge elicitation, selection, and consolidation. Evaluations\ndemonstrate that our method reduces context length by 90% while achieving 103%\naverage performance of full-context prompting across fact recall, grounded\nreasoning, and skill acquisition tasks. When conducting sequential multi-turn\ntransformations on complex, real-world contexts (with length up to 2M tokens),\nour approach surpasses full-context prompting while using only 0.4% of the\noriginal contexts. These findings highlight InfiniteICL's potential to enhance\nthe scalability and efficiency of LLMs by breaking the limitations of\nconventional context window sizes.",
      "pdf_url": "http://arxiv.org/pdf/2504.01707v2",
      "published": "2025-04-02T13:15:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.01707v2",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Sky of Unlearning (SoUL): Rewiring Federated Machine Unlearning via Selective Pruning",
      "authors": [
        "Md Mahabub Uz Zaman",
        "Xiang Sun",
        "Jingjing Yao"
      ],
      "abstract": "The Internet of Drones (IoD), where drones collaborate in data collection and\nanalysis, has become essential for applications such as surveillance and\nenvironmental monitoring. Federated learning (FL) enables drones to train\nmachine learning models in a decentralized manner while preserving data\nprivacy. However, FL in IoD networks is susceptible to attacks like data\npoisoning and model inversion. Federated unlearning (FU) mitigates these risks\nby eliminating adversarial data contributions, preventing their influence on\nthe model. This paper proposes sky of unlearning (SoUL), a federated unlearning\nframework that efficiently removes the influence of unlearned data while\nmaintaining model performance. A selective pruning algorithm is designed to\nidentify and remove neurons influential in unlearning but minimally impact the\noverall performance of the model. Simulations demonstrate that SoUL outperforms\nexisting unlearning methods, achieves accuracy comparable to full retraining,\nand reduces computation and communication overhead, making it a scalable and\nefficient solution for resource-constrained IoD networks.",
      "pdf_url": "http://arxiv.org/pdf/2504.01705v1",
      "published": "2025-04-02T13:07:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.01705v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ]
    },
    {
      "title": "Reasoning LLMs for User-Aware Multimodal Conversational Agents",
      "authors": [
        "Hamed Rahimi",
        "Jeanne Cattoni",
        "Meriem Beghili",
        "Mouad Abrini",
        "Mahdi Khoramshahi",
        "Maribel Pino",
        "Mohamed Chetouani"
      ],
      "abstract": "Personalization in social robotics is critical for fostering effective\nhuman-robot interactions, yet systems often face the cold start problem, where\ninitial user preferences or characteristics are unavailable. This paper\nproposes a novel framework called USER-LLM R1 for a user-aware conversational\nagent that addresses this challenge through dynamic user profiling and model\ninitiation. Our approach integrates chain-of-thought (CoT) reasoning models to\niteratively infer user preferences and vision-language models (VLMs) to\ninitialize user profiles from multimodal inputs, enabling personalized\ninteractions from the first encounter. Leveraging a Retrieval-Augmented\nGeneration (RAG) architecture, the system dynamically refines user\nrepresentations within an inherent CoT process, ensuring contextually relevant\nand adaptive responses. Evaluations on the ElderlyTech-VQA Bench demonstrate\nsignificant improvements in ROUGE-1 (+23.2%), ROUGE-2 (+0.6%), and ROUGE-L\n(+8%) F1 scores over state-of-the-art baselines, with ablation studies\nunderscoring the impact of reasoning model size on performance. Human\nevaluations further validate the framework's efficacy, particularly for elderly\nusers, where tailored responses enhance engagement and trust. Ethical\nconsiderations, including privacy preservation and bias mitigation, are\nrigorously discussed and addressed to ensure responsible deployment.",
      "pdf_url": "http://arxiv.org/pdf/2504.01700v1",
      "published": "2025-04-02T13:00:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.01700v1",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.RO"
      ]
    },
    {
      "title": "ToM-RL: Reinforcement Learning Unlocks Theory of Mind in Small LLMs",
      "authors": [
        "Yi-Long Lu",
        "Chunhui Zhang",
        "Jiajun Song",
        "Lifeng Fan",
        "Wei Wang"
      ],
      "abstract": "Recent advancements in rule-based reinforcement learning (RL), applied during\nthe post-training phase of large language models (LLMs), have significantly\nenhanced their capabilities in structured reasoning tasks such as mathematics\nand logical inference. However, the effectiveness of RL in social reasoning,\nparticularly in Theory of Mind (ToM), the ability to infer others' mental\nstates, remains largely unexplored. In this study, we demonstrate that RL\nmethods effectively unlock ToM reasoning capabilities even in small-scale LLMs\n(0.5B to 7B parameters). Using a modest dataset comprising 3200 questions\nacross diverse scenarios, our RL-trained 7B model achieves 84.50\\% accuracy on\nthe Hi-ToM benchmark, surpassing models like GPT-4o and DeepSeek-v3 despite\nsignificantly fewer parameters. While smaller models ($\\leq$3B parameters)\nsuffer from reasoning collapse, larger models (7B parameters) maintain stable\nperformance through consistent belief tracking. Additionally, our RL-based\nmodels demonstrate robust generalization to higher-order, out-of-distribution\nToM problems, novel textual presentations, and previously unseen datasets.\nThese findings highlight RL's potential to enhance social cognitive reasoning,\nbridging the gap between structured problem-solving and nuanced social\ninference in LLMs.",
      "pdf_url": "http://arxiv.org/pdf/2504.01698v1",
      "published": "2025-04-02T12:58:42+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.01698v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Segmentation variability and radiomics stability for predicting Triple-Negative Breast Cancer subtype using Magnetic Resonance Imaging",
      "authors": [
        "Isabella Cama",
        "Alejandro Guzmán",
        "Cristina Campi",
        "Michele Piana",
        "Karim Lekadir",
        "Sara Garbarino",
        "Oliver Díaz"
      ],
      "abstract": "Most papers caution against using predictive models for disease\nstratification based on unselected radiomic features, as these features are\naffected by contouring variability. Instead, they advocate for the use of the\nIntraclass Correlation Coefficient (ICC) as a measure of stability for feature\nselection. However, the direct effect of segmentation variability on the\npredictive models is rarely studied. This study investigates the impact of\nsegmentation variability on feature stability and predictive performance in\nradiomics-based prediction of Triple-Negative Breast Cancer (TNBC) subtype\nusing Magnetic Resonance Imaging. A total of 244 images from the Duke dataset\nwere used, with segmentation variability introduced through modifications of\nmanual segmentations. For each mask, explainable radiomic features were\nselected using the Shapley Additive exPlanations method and used to train\nlogistic regression models. Feature stability across segmentations was assessed\nvia ICC, Pearson's correlation, and reliability scores quantifying the\nrelationship between feature stability and segmentation variability. Results\nindicate that segmentation accuracy does not significantly impact predictive\nperformance. While incorporating peritumoral information may reduce feature\nreproducibility, it does not diminish feature predictive capability. Moreover,\nfeature selection in predictive models is not inherently tied to feature\nstability with respect to segmentation, suggesting that an overreliance on ICC\nor reliability scores for feature selection might exclude valuable predictive\nfeatures.",
      "pdf_url": "http://arxiv.org/pdf/2504.01692v1",
      "published": "2025-04-02T12:48:01+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.01692v1",
      "categories": [
        "stat.AP",
        "cs.AI",
        "62P10 (Primary), 68T09 (Secondary)"
      ]
    },
    {
      "title": "Token Pruning in Audio Transformers: Optimizing Performance and Decoding Patch Importance",
      "authors": [
        "Taehan Lee",
        "Hyukjun Lee"
      ],
      "abstract": "Vision Transformers (ViTs) have achieved state-of-the-art performance across\nvarious computer vision tasks, but their high computational cost remains a\nchallenge. Token pruning has been proposed to reduce this cost by selectively\nremoving less important tokens. While effective in vision tasks by discarding\nnon-object regions, applying this technique to audio tasks presents unique\nchallenges, as distinguishing relevant from irrelevant regions in\ntime-frequency representations is less straightforward. In this study, for the\nfirst time, we applied token pruning to ViT-based audio classification models\nusing Mel-spectrograms and analyzed the trade-offs between model performance\nand computational cost: TopK token pruning can reduce MAC operations of\nAudioMAE and AST by 30-40%, with less than a 1% drop in classification\naccuracy. Our analysis reveals that while high-intensity tokens contribute\nsignificantly to model accuracy, low-intensity tokens remain important. In\nparticular, they play a more critical role in general audio classification\ntasks than in speech-specific tasks.",
      "pdf_url": "http://arxiv.org/pdf/2504.01690v1",
      "published": "2025-04-02T12:44:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.01690v1",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ]
    },
    {
      "title": "K-P Quantum Neural Networks",
      "authors": [
        "Elija Perrier"
      ],
      "abstract": "We present an extension of K-P time-optimal quantum control solutions using\nglobal Cartan $KAK$ decompositions for geodesic-based solutions. Extending\nrecent time-optimal \\emph{constant-$\\theta$} control results, we integrate\nCartan methods into equivariant quantum neural network (EQNN) for quantum\ncontrol tasks. We show that a finite-depth limited EQNN ansatz equipped with\nCartan layers can replicate the constant-$\\theta$ sub-Riemannian geodesics for\nK-P problems. We demonstrate how for certain classes of control problem on\nRiemannian symmetric spaces, gradient-based training using an appropriate cost\nfunction converges to certain global time-optimal solutions when satisfying\nsimple regularity conditions. This generalises prior geometric control theory\nmethods and clarifies how optimal geodesic estimation can be performed in\nquantum machine learning contexts.",
      "pdf_url": "http://arxiv.org/pdf/2504.01673v1",
      "published": "2025-04-02T12:22:18+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.01673v1",
      "categories": [
        "quant-ph",
        "cs.AI"
      ]
    },
    {
      "title": "Anomaly Detection for Hybrid Butterfly Subspecies via Probability Filtering",
      "authors": [
        "Bo-Kai Ruan",
        "Yi-Zeng Fang",
        "Hong-Han Shuai",
        "Juinn-Dar Huang"
      ],
      "abstract": "Detecting butterfly hybrids requires knowledge of the parent subspecies, and\nthe process can be tedious when encountering a new subspecies. This study\nfocuses on a specific scenario where a model trained to recognize hybrid\nspecies A can generalize to species B when B biologically mimics A. Since\nspecies A and B share similar patterns, we leverage BioCLIP as our feature\nextractor to capture features based on their taxonomy. Consequently, the\nalgorithm designed for species A can be transferred to B, as their hybrid and\nnon-hybrid patterns exhibit similar relationships. To determine whether a\nbutterfly is a hybrid, we adopt proposed probability filtering and color\njittering to augment and simulate the mimicry. With these approaches, we\nachieve second place in the official development phase. Our code is publicly\navailable at https://github.com/Justin900429/NSF-HDR-Challenge.",
      "pdf_url": "http://arxiv.org/pdf/2504.01671v1",
      "published": "2025-04-02T12:18:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.01671v1",
      "categories": [
        "cs.CE",
        "cs.AI"
      ]
    },
    {
      "title": "Market-Oriented Flow Allocation for Thermal Solar Plants: An Auction-Based Methodology with Artificial Intelligence",
      "authors": [
        "Sara Ruiz-Moreno",
        "Antonio J. Gallego",
        "Manuel Macías",
        "Eduardo F. Camacho"
      ],
      "abstract": "This paper presents a novel method to optimize thermal balance in parabolic\ntrough collector (PTC) plants. It uses a market-based system to distribute flow\namong loops combined with an artificial neural network (ANN) to reduce\ncomputation and data requirements. This auction-based approach balances loop\ntemperatures, accommodating varying thermal losses and collector efficiencies.\nValidation across different thermal losses, optical efficiencies, and\nirradiance conditions-sunny, partially cloudy, and cloudy-show improved thermal\npower output and intercept factors compared to a no-allocation system. It\ndemonstrates scalability and practicality for large solar thermal plants,\nenhancing overall performance. The method was first validated through\nsimulations on a realistic solar plant model, then adapted and successfully\ntested in a 50 MW solar trough plant, demonstrating its advantages.\nFurthermore, the algorithms have been implemented, commissioned, and are\ncurrently operating in 13 commercial solar trough plants.",
      "pdf_url": "http://arxiv.org/pdf/2504.01652v1",
      "published": "2025-04-02T12:01:41+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.01652v1",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY"
      ]
    },
    {
      "title": "Proposition of Affordance-Driven Environment Recognition Framework Using Symbol Networks in Large Language Models",
      "authors": [
        "Kazuma Arii",
        "Satoshi Kurihara"
      ],
      "abstract": "In the quest to enable robots to coexist with humans, understanding dynamic\nsituations and selecting appropriate actions based on common sense and\naffordances are essential. Conventional AI systems face challenges in applying\naffordance, as it represents implicit knowledge derived from common sense.\nHowever, large language models (LLMs) offer new opportunities due to their\nability to process extensive human knowledge. This study proposes a method for\nautomatic affordance acquisition by leveraging LLM outputs. The process\ninvolves generating text using LLMs, reconstructing the output into a symbol\nnetwork using morphological and dependency analysis, and calculating\naffordances based on network distances. Experiments using ``apple'' as an\nexample demonstrated the method's ability to extract context-dependent\naffordances with high explainability. The results suggest that the proposed\nsymbol network, reconstructed from LLM outputs, enables robots to interpret\naffordances effectively, bridging the gap between symbolized data and\nhuman-like situational understanding.",
      "pdf_url": "http://arxiv.org/pdf/2504.01644v1",
      "published": "2025-04-02T11:48:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.01644v1",
      "categories": [
        "cs.AI",
        "cs.RO"
      ]
    },
    {
      "title": "Bridge 2D-3D: Uncertainty-aware Hierarchical Registration Network with Domain Alignment",
      "authors": [
        "Zhixin Cheng",
        "Jiacheng Deng",
        "Xinjun Li",
        "Baoqun Yin",
        "Tianzhu Zhang"
      ],
      "abstract": "The method for image-to-point cloud registration typically determines the\nrigid transformation using a coarse-to-fine pipeline. However, directly and\nuniformly matching image patches with point cloud patches may lead to focusing\non incorrect noise patches during matching while ignoring key ones. Moreover,\ndue to the significant differences between image and point cloud modalities, it\nmay be challenging to bridge the domain gap without specific improvements in\ndesign. To address the above issues, we innovatively propose the\nUncertainty-aware Hierarchical Matching Module (UHMM) and the Adversarial Modal\nAlignment Module (AMAM). Within the UHMM, we model the uncertainty of critical\ninformation in image patches and facilitate multi-level fusion interactions\nbetween image and point cloud features. In the AMAM, we design an adversarial\napproach to reduce the domain gap between image and point cloud. Extensive\nexperiments and ablation studies on RGB-D Scene V2 and 7-Scenes benchmarks\ndemonstrate the superiority of our method, making it a state-of-the-art\napproach for image-to-point cloud registration tasks.",
      "pdf_url": "http://arxiv.org/pdf/2504.01641v1",
      "published": "2025-04-02T11:43:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.01641v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "LLM-mediated Dynamic Plan Generation with a Multi-Agent Approach",
      "authors": [
        "Reo Abe",
        "Akifumi Ito",
        "Kanata Takayasu",
        "Satoshi Kurihara"
      ],
      "abstract": "Planning methods with high adaptability to dynamic environments are crucial\nfor the development of autonomous and versatile robots. We propose a method for\nleveraging a large language model (GPT-4o) to automatically generate networks\ncapable of adapting to dynamic environments. The proposed method collects\nenvironmental \"status,\" representing conditions and goals, and uses them to\ngenerate agents. These agents are interconnected on the basis of specific\nconditions, resulting in networks that combine flexibility and generality. We\nconducted evaluation experiments to compare the networks automatically\ngenerated with the proposed method with manually constructed ones, confirming\nthe comprehensiveness of the proposed method's networks and their higher\ngenerality. This research marks a significant advancement toward the\ndevelopment of versatile planning methods applicable to robotics, autonomous\nvehicles, smart systems, and other complex environments.",
      "pdf_url": "http://arxiv.org/pdf/2504.01637v1",
      "published": "2025-04-02T11:42:49+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.01637v1",
      "categories": [
        "cs.AI",
        "cs.RO"
      ]
    },
    {
      "title": "Benchmarking the Spatial Robustness of DNNs via Natural and Adversarial Localized Corruptions",
      "authors": [
        "Giulia Marchiori Pietrosanti",
        "Giulio Rossolini",
        "Alessandro Biondi",
        "Giorgio Buttazzo"
      ],
      "abstract": "The robustness of DNNs is a crucial factor in safety-critical applications,\nparticularly in complex and dynamic environments where localized corruptions\ncan arise. While previous studies have evaluated the robustness of semantic\nsegmentation (SS) models under whole-image natural or adversarial corruptions,\na comprehensive investigation into the spatial robustness of dense vision\nmodels under localized corruptions remained underexplored. This paper fills\nthis gap by introducing specialized metrics for benchmarking the spatial\nrobustness of segmentation models, alongside with an evaluation framework to\nassess the impact of localized corruptions. Furthermore, we uncover the\ninherent complexity of characterizing worst-case robustness using a single\nlocalized adversarial perturbation. To address this, we propose region-aware\nmulti-attack adversarial analysis, a method that enables a deeper understanding\nof model robustness against adversarial perturbations applied to specific\nregions. The proposed metrics and analysis were evaluated on 15 segmentation\nmodels in driving scenarios, uncovering key insights into the effects of\nlocalized corruption in both natural and adversarial forms. The results reveal\nthat models respond to these two types of threats differently; for instance,\ntransformer-based segmentation models demonstrate notable robustness to\nlocalized natural corruptions but are highly vulnerable to adversarial ones and\nvice-versa for CNN-based models. Consequently, we also address the challenge of\nbalancing robustness to both natural and adversarial localized corruptions by\nmeans of ensemble models, thereby achieving a broader threat coverage and\nimproved reliability for dense vision tasks.",
      "pdf_url": "http://arxiv.org/pdf/2504.01632v1",
      "published": "2025-04-02T11:37:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.01632v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Horizon Scans can be accelerated using novel information retrieval and artificial intelligence tools",
      "authors": [
        "Lena Schmidt",
        "Oshin Sharma",
        "Chris Marshall",
        "Sonia Garcia Gonzalez Moral"
      ],
      "abstract": "Introduction: Horizon scanning in healthcare assesses early signals of\ninnovation, crucial for timely adoption. Current horizon scanning faces\nchallenges in efficient information retrieval and analysis, especially from\nunstructured sources like news, presenting a need for innovative tools.\nMethodology: The study introduces SCANAR and AIDOC, open-source Python-based\ntools designed to improve horizon scanning. SCANAR automates the retrieval and\nprocessing of news articles, offering functionalities such as de-duplication\nand unsupervised relevancy ranking. AIDOC aids filtration by leveraging AI to\nreorder textual data based on relevancy, employing neural networks for semantic\nsimilarity, and subsequently prioritizing likely relevant entries for human\nreview. Results: Twelve internal datasets from horizon scans and four external\nbenchmarking datasets were used. SCANAR improved retrieval efficiency by\nautomating processes previously dependent on manual labour. AIDOC displayed\nwork-saving potential, achieving around 62% reduction in manual review efforts\nat 95% recall. Comparative analysis with benchmarking data showed AIDOC's\nperformance was similar to existing systematic review automation tools, though\nperformance varied depending on dataset characteristics. A smaller case-study\non our news datasets shows the potential of ensembling large language models\nwithin the active-learning process for faster detection of relevant articles\nacross news datasets. Conclusion: The validation indicates that SCANAR and\nAIDOC show potential to enhance horizon scanning efficiency by streamlining\ndata retrieval and prioritisation. These tools may alleviate methodological\nlimitations and allow broader, swifter horizon scans. Further studies are\nsuggested to optimize these models and to design new workflows and validation\nprocesses that integrate large language models.",
      "pdf_url": "http://arxiv.org/pdf/2504.01627v1",
      "published": "2025-04-02T11:33:08+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.01627v1",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Text Speaks Louder than Vision: ASCII Art Reveals Textual Biases in Vision-Language Models",
      "authors": [
        "Zhaochen Wang",
        "Yujun Cai",
        "Zi Huang",
        "Bryan Hooi",
        "Yiwei Wang",
        "Ming-Hsuan Yang"
      ],
      "abstract": "Vision-language models (VLMs) have advanced rapidly in processing multimodal\ninformation, but their ability to reconcile conflicting signals across\nmodalities remains underexplored. This work investigates how VLMs process ASCII\nart, a unique medium where textual elements collectively form visual patterns,\npotentially creating semantic-visual conflicts. We introduce a novel evaluation\nframework that systematically challenges five state-of-the-art models\n(including GPT-4o, Claude, and Gemini) using adversarial ASCII art, where\ncharacter-level semantics deliberately contradict global visual patterns. Our\nexperiments reveal a strong text-priority bias: VLMs consistently prioritize\ntextual information over visual patterns, with visual recognition ability\ndeclining dramatically as semantic complexity increases. Various mitigation\nattempts through visual parameter tuning and prompt engineering yielded only\nmodest improvements, suggesting that this limitation requires\narchitectural-level solutions. These findings uncover fundamental flaws in how\ncurrent VLMs integrate multimodal information, providing important guidance for\nfuture model development while highlighting significant implications for\ncontent moderation systems vulnerable to adversarial examples.",
      "pdf_url": "http://arxiv.org/pdf/2504.01589v1",
      "published": "2025-04-02T10:47:07+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.01589v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Building Knowledge from Interactions: An LLM-Based Architecture for Adaptive Tutoring and Social Reasoning",
      "authors": [
        "Luca Garello",
        "Giulia Belgiovine",
        "Gabriele Russo",
        "Francesco Rea",
        "Alessandra Sciutti"
      ],
      "abstract": "Integrating robotics into everyday scenarios like tutoring or physical\ntraining requires robots capable of adaptive, socially engaging, and\ngoal-oriented interactions. While Large Language Models show promise in\nhuman-like communication, their standalone use is hindered by memory\nconstraints and contextual incoherence. This work presents a multimodal,\ncognitively inspired framework that enhances LLM-based autonomous\ndecision-making in social and task-oriented Human-Robot Interaction.\nSpecifically, we develop an LLM-based agent for a robot trainer, balancing\nsocial conversation with task guidance and goal-driven motivation. To further\nenhance autonomy and personalization, we introduce a memory system for\nselecting, storing and retrieving experiences, facilitating generalized\nreasoning based on knowledge built across different interactions. A preliminary\nHRI user study and offline experiments with a synthetic dataset validate our\napproach, demonstrating the system's ability to manage complex interactions,\nautonomously drive training tasks, and build and retrieve contextual memories,\nadvancing socially intelligent robotics.",
      "pdf_url": "http://arxiv.org/pdf/2504.01588v1",
      "published": "2025-04-02T10:45:41+00:00",
      "arxiv_url": "http://arxiv.org/abs/2504.01588v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    }
  ]
}