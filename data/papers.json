{
  "last_updated": "2025-12-05T00:53:46.891272",
  "papers": [
    {
      "title": "SkillFactory: Self-Distillation For Learning Cognitive Behaviors",
      "authors": [
        "Zayne Sprague",
        "Jack Lu",
        "Manya Wadhwa",
        "Sedrick Keh",
        "Mengye Ren",
        "Greg Durrett"
      ],
      "abstract": "Reasoning models leveraging long chains of thought employ various cognitive skills, such as verification of their answers, backtracking, retrying by an alternate method, and more. Previous work has shown that when a base language model exhibits these skills, training that model further with reinforcement learning (RL) can learn to leverage them. How can we get models to leverage skills that aren't exhibited by base models? Our work, SkillFactory, is a method for fine-tuning models to roughly learn these skills during a supervised fine-tuning (SFT) stage prior to RL. Our approach does not rely on distillation from a stronger model, but instead uses samples from the model itself, rearranged to provide training data in the format of those skills. These \"silver\" SFT traces may be imperfect, but are nevertheless effective for priming a model to acquire skills during RL. Our evaluation shows that (1) starting from SkillFactory SFT initialization helps a model to generalize to harder variants of a task post-RL, despite lower performance pre-RL; (2) cognitive skills are indeed used by the model; (3) RLed SkillFactory models are more robust to regression on out-of-domain tasks than RLed base models. Our work suggests that inductive biases learned prior to RL help models learn robust cognitive skill use.",
      "pdf_url": "https://arxiv.org/pdf/2512.04072v1",
      "published": "2025-12-03T18:54:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.04072v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Fare Comparison App of Uber, Ola and Rapido",
      "authors": [
        "Ashlesha Gopinath Sawant",
        "Sahil S. Jadhav",
        "Vidhan R. Jain",
        "Shriraj S. Jagtap",
        "Prachi Jadhav",
        "Soham Jadhav",
        "Ichha Raina"
      ],
      "abstract": "In todays increasing world, it is very important to have good hailing services like Ola, Uber, and Rapido as it is very essential for our daily transportation. Users often face difficulties in choosing the most appropriate and efficient ride that would lead to both cost-effective and would take us to our destination in less time. This project provides you with the web application that helps you to select the most beneficial ride for you by providing users with the fare comparison between Ola, Uber, Rapido for the destination entered by the user. The backend is use to fetch the data, providing users with the fare comparison for the ride and finally providing with the best option using Python. This research paper also addresses the problem and challenges faced in accessing the data using APIs, Android Studios emulator, Appium and location comparison. Thus, the aim of the project is to provide transparency to the users in ride-hailing services and increase efficiency and provide users with better experience.",
      "pdf_url": "https://arxiv.org/pdf/2512.04065v1",
      "published": "2025-12-03T18:48:33+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.04065v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Polarization by Design: How Elites Could Shape Mass Preferences as AI Reduces Persuasion Costs",
      "authors": [
        "Nadav Kunievsky"
      ],
      "abstract": "In democracies, major policy decisions typically require some form of majority or consensus, so elites must secure mass support to govern. Historically, elites could shape support only through limited instruments like schooling and mass media; advances in AI-driven persuasion sharply reduce the cost and increase the precision of shaping public opinion, making the distribution of preferences itself an object of deliberate design. We develop a dynamic model in which elites choose how much to reshape the distribution of policy preferences, subject to persuasion costs and a majority rule constraint. With a single elite, any optimal intervention tends to push society toward more polarized opinion profiles - a ``polarization pull'' - and improvements in persuasion technology accelerate this drift. When two opposed elites alternate in power, the same technology also creates incentives to park society in ``semi-lock'' regions where opinions are more cohesive and harder for a rival to overturn, so advances in persuasion can either heighten or dampen polarization depending on the environment. Taken together, cheaper persuasion technologies recast polarization as a strategic instrument of governance rather than a purely emergent social byproduct, with important implications for democratic stability as AI capabilities advance.",
      "pdf_url": "https://arxiv.org/pdf/2512.04047v1",
      "published": "2025-12-03T18:33:26+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.04047v1",
      "categories": [
        "econ.GN",
        "cs.AI",
        "cs.CY"
      ]
    },
    {
      "title": "MarkTune: Improving the Quality-Detectability Trade-off in Open-Weight LLM Watermarking",
      "authors": [
        "Yizhou Zhao",
        "Zhiwei Steven Wu",
        "Adam Block"
      ],
      "abstract": "Watermarking aims to embed hidden signals in generated text that can be reliably detected when given access to a secret key. Open-weight language models pose acute challenges for such watermarking schemes because the inference-time interventions that dominate contemporary approaches cannot be enforced once model weights are public. Existing watermaking techniques for open-weight models, such as the recently proposed GaussMark, typically rely on small modifications to model weights, which can yield signals detectable to those equipped with a secret key, but achieving detection power comparable to inference-time watermarks generally requires weight perturbations that noticeably reduce generation quality. We introduce MarkTune, a theoretically principled, on-policy fine-tuning framework that treats the GaussMark signal as a reward while simultaneously regularizing against degradation in text quality. We derive MarkTune as an improvement on GaussMark and demonstrate that MarkTune consistently improves the quality-detectability trade-off over GaussMark by steering finer-grained, watermark-aware weight updates within the model's representation space while preserving generation quality. Empirically, we show that MarkTune pushes the quality-detectability frontier of GaussMark close to that of inference-time watermarking, remains robust to paraphrasing and fine-tuning attacks, and exhibits strong generalization: a model fine-tuned on one dataset retains substantial watermark detection power on unseen datasets. Together, these results establish MarkTune as a general strategy for embedding robust, high-quality watermarks into open-weight LMs.",
      "pdf_url": "https://arxiv.org/pdf/2512.04044v1",
      "published": "2025-12-03T18:32:19+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.04044v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ]
    },
    {
      "title": "Fast & Efficient Normalizing Flows and Applications of Image Generative Models",
      "authors": [
        "Sandeep Nagar"
      ],
      "abstract": "This thesis presents novel contributions in two primary areas: advancing the efficiency of generative models, particularly normalizing flows, and applying generative models to solve real-world computer vision challenges. The first part introduce significant improvements to normalizing flow architectures through six key innovations: 1) Development of invertible 3x3 Convolution layers with mathematically proven necessary and sufficient conditions for invertibility, (2) introduction of a more efficient Quad-coupling layer, 3) Design of a fast and efficient parallel inversion algorithm for kxk convolutional layers, 4) Fast & efficient backpropagation algorithm for inverse of convolution, 5) Using inverse of convolution, in Inverse-Flow, for the forward pass and training it using proposed backpropagation algorithm, and 6) Affine-StableSR, a compact and efficient super-resolution model that leverages pre-trained weights and Normalizing Flow layers to reduce parameter count while maintaining performance.\n  The second part: 1) An automated quality assessment system for agricultural produce using Conditional GANs to address class imbalance, data scarcity and annotation challenges, achieving good accuracy in seed purity testing; 2) An unsupervised geological mapping framework utilizing stacked autoencoders for dimensionality reduction, showing improved feature extraction compared to conventional methods; 3) We proposed a privacy preserving method for autonomous driving datasets using on face detection and image inpainting; 4) Utilizing Stable Diffusion based image inpainting for replacing the detected face and license plate to advancing privacy-preserving techniques and ethical considerations in the field.; and 5) An adapted diffusion model for art restoration that effectively handles multiple types of degradation through unified fine-tuning.",
      "pdf_url": "https://arxiv.org/pdf/2512.04039v1",
      "published": "2025-12-03T18:29:03+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.04039v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Jina-VLM: Small Multilingual Vision Language Model",
      "authors": [
        "Andreas Koukounas",
        "Georgios Mastrapas",
        "Florian Hönicke",
        "Sedigheh Eslami",
        "Guillaume Roncari",
        "Scott Martens",
        "Han Xiao"
      ],
      "abstract": "We present Jina-VLM, a 2.4B parameter vision-language model that achieves state-of-the-art multilingual visual question answering among open 2B-scale VLMs. The model couples a SigLIP2 vision encoder with a Qwen3 language backbone through an attention-pooling connector that enables token-efficient processing of arbitrary-resolution images. Across standard VQA benchmarks and multilingual evaluations, Jina-VLM outperforms comparable models while preserving competitive text-only performance.",
      "pdf_url": "https://arxiv.org/pdf/2512.04032v1",
      "published": "2025-12-03T18:13:41+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.04032v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Large Language Models for Limited Noisy Data: A Gravitational Wave Identification Study",
      "authors": [
        "Yixuan Li",
        "Yuhao Lu",
        "Yang Liu",
        "Liang Li",
        "R. Ruffini",
        "Di Li",
        "Rong-Gen Cai",
        "Xiaoyan Zhu",
        "Wenbin Lin",
        "Yu Wang"
      ],
      "abstract": "This work investigates whether large language models (LLMs) offer advantages over traditional neural networks for astronomical data processing, in regimes with non-Gaussian, non-stationary noise and limited labeled samples. Gravitational wave observations provide an suitable test case, using only 90 LIGO events, finetuned LLMs achieve 97.4\\% accuracy for identifying signals. Further experiments show that, in contrast to traditional networks that rely on large simulated datasets, additional simulated samples do not improve LLM performance, while scaling studies reveal predictable gains with increasing model size and dataset size. These results indicate that LLMs can extract discriminative structure directly from observational data and provide an efficient assessment for gravitational wave identification. The same strategy may extend to other astronomical domains with similar noise properties, such as radio or pulsar observations.",
      "pdf_url": "https://arxiv.org/pdf/2512.04031v1",
      "published": "2025-12-03T18:13:01+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.04031v1",
      "categories": [
        "astro-ph.IM",
        "astro-ph.HE",
        "cs.AI"
      ]
    },
    {
      "title": "PSA: Pyramid Sparse Attention for Efficient Video Understanding and Generation",
      "authors": [
        "Xiaolong Li",
        "Youping Gu",
        "Xi Lin",
        "Weijie Wang",
        "Bohan Zhuang"
      ],
      "abstract": "Attention mechanisms are the core of foundation models, but their quadratic complexity remains a critical bottleneck for scaling. This challenge has driven the development of efficient attention mechanisms, with sparsity emerging as the dominant paradigm. Current methods typically retain or discard entire key-value blocks with binary masks, resulting in substantial information loss under high sparsity. To mitigate this gap, we present Pyramid Sparse Attention (PSA), a versatile module applicable to both video understanding and generation tasks. Instead of binary masking, PSA introduces multi-level pooled KV representations, enabling finer mask granularity. Specifically, each query block dynamically allocates lower pooling levels to critical KV blocks and higher levels to less important ones, creating an informative interpolation between full retention and complete pruning. This design, analogous to fixed-point quantization and classical feature pyramid networks in computer vision, effectively mitigates information loss while preserving computational efficiency under a low compute budget. It works with a native, hardware-friendly kernel that leverages decoupled block-tile design to ensure efficient execution. Across video understanding and generation benchmarks, PSA preserves contextual information and visual fidelity, consistently outperforming or achieving comparable performance over existing sparse attention baselines with superior efficiency-quality trade-offs. Our code and model weights are publicly available at: http://ziplab.co/PSA",
      "pdf_url": "https://arxiv.org/pdf/2512.04025v1",
      "published": "2025-12-03T18:02:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.04025v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "TARA Test-by-Adaptive-Ranks for Quantum Anomaly Detection with Conformal Prediction Guarantees",
      "authors": [
        "Davut Emre Tasar",
        "Ceren Ocal Tasar"
      ],
      "abstract": "Quantum key distribution (QKD) security fundamentally relies on the ability to distinguish genuine quantum correlations from classical eavesdropper simulations, yet existing certification methods lack rigorous statistical guarantees under finite-sample conditions and adversarial scenarios. We introduce TARA (Test by Adaptive Ranks), a novel framework combining conformal prediction with sequential martingale testing for quantum anomaly detection that provides distribution-free validity guarantees. TARA offers two complementary approaches. TARA k, based on Kolmogorov Smirnov calibration against local hidden variable (LHV) null distributions, achieving ROC AUC = 0.96 for quantum-classical discrimination. And TARA-m, employing betting martingales for streaming detection with anytime valid type I error control that enables real time monitoring of quantum channels. We establish theoretical guarantees proving that under (context conditional) exchangeability, conformal p-values remain uniformly distributed even for strongly contextual quantum data, confirming that quantum contextuality does not break conformal prediction validity a result with implications beyond quantum certification to any application of distribution-free methods to nonclassical data. Extensive validation on both IBM Torino (superconducting, CHSH = 2.725) and IonQ Forte Enterprise (trapped ion, CHSH = 2.716) quantum processors demonstrates cross-platform robustness, achieving 36% security margins above the classical CHSH bound of 2. Critically, our framework reveals a methodological concern affecting quantum certification more broadly: same-distribution calibration can inflate detection performance by up to 44 percentage points compared to proper cross-distribution calibration, suggesting that prior quantum certification studies using standard train test splits may have systematically overestimated adversarial robustness.",
      "pdf_url": "https://arxiv.org/pdf/2512.04016v1",
      "published": "2025-12-03T17:53:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.04016v1",
      "categories": [
        "quant-ph",
        "cs.AI"
      ]
    },
    {
      "title": "On the Temporality for Sketch Representation Learning",
      "authors": [
        "Marcelo Isaias de Moraes Junior",
        "Moacir Antonelli Ponti"
      ],
      "abstract": "Sketches are simple human hand-drawn abstractions of complex scenes and real-world objects. Although the field of sketch representation learning has advanced significantly, there is still a gap in understanding the true relevance of the temporal aspect to the quality of these representations. This work investigates whether it is indeed justifiable to treat sketches as sequences, as well as which internal orders play a more relevant role. The results indicate that, although the use of traditional positional encodings is valid for modeling sketches as sequences, absolute coordinates consistently outperform relative ones. Furthermore, non-autoregressive decoders outperform their autoregressive counterparts. Finally, the importance of temporality was shown to depend on both the order considered and the task evaluated.",
      "pdf_url": "https://arxiv.org/pdf/2512.04007v1",
      "published": "2025-12-03T17:46:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.04007v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Divide, then Ground: Adapting Frame Selection to Query Types for Long-Form Video Understanding",
      "authors": [
        "Jialuo Li",
        "Bin Li",
        "Jiahao Li",
        "Yan Lu"
      ],
      "abstract": "The application of Large Multimodal Models (LMMs) to long-form video understanding is constrained by limited context lengths and the computationally prohibitive cost of processing dense video tokens. Consequently, recent research has focused on query-aware frame selection, methods that often incur significant computational overhead. This paper challenges the assumption that such complex search mechanisms are universally necessary. We first identify and validate a query typology distinguishing between global query and localized query. We demonstrate that while uniform sampling is both effective and efficient for global queries, localized queries indeed necessitate query-aware selection for optimal performance. Building on this insight, we propose DIG, a training-free frame selection framework that adapts its strategy based on the query type. Specifically,DIG employs efficient uniform sampling for global queries while activating a specialized pipeline to extract query-relevant frames for localized queries. Experiments on three long-form video understanding benchmarks demonstrate that DIG consistently outperforms existing baselines and robustly improves LMM performance, even when scaling the input frame count to 256.",
      "pdf_url": "https://arxiv.org/pdf/2512.04000v1",
      "published": "2025-12-03T17:36:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.04000v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Highly Efficient Test-Time Scaling for T2I Diffusion Models with Text Embedding Perturbation",
      "authors": [
        "Hang Xu",
        "Linjiang Huang",
        "Feng Zhao"
      ],
      "abstract": "Test-time scaling (TTS) aims to achieve better results by increasing random sampling and evaluating samples based on rules and metrics. However, in text-to-image(T2I) diffusion models, most related works focus on search strategies and reward models, yet the impact of the stochastic characteristic of noise in T2I diffusion models on the method's performance remains unexplored. In this work, we analyze the effects of randomness in T2I diffusion models and explore a new format of randomness for TTS: text embedding perturbation, which couples with existing randomness like SDE-injected noise to enhance generative diversity and quality. We start with a frequency-domain analysis of these formats of randomness and their impact on generation, and find that these two randomness exhibit complementary behavior in the frequency domain: spatial noise favors low-frequency components (early steps), while text embedding perturbation enhances high-frequency details (later steps), thereby compensating for the potential limitations of spatial noise randomness in high-frequency manipulation. Concurrently, text embedding demonstrates varying levels of tolerance to perturbation across different dimensions of the generation process. Specifically, our method consists of two key designs: (1) Introducing step-based text embedding perturbation, combining frequency-guided noise schedules with spatial noise perturbation. (2) Adapting the perturbation intensity selectively based on their frequency-specific contributions to generation and tolerance to perturbation. Our approach can be seamlessly integrated into existing TTS methods and demonstrates significant improvements on multiple benchmarks with almost no additional computation. Code is available at \\href{https://github.com/xuhang07/TEP-Diffusion}{https://github.com/xuhang07/TEP-Diffusion}.",
      "pdf_url": "https://arxiv.org/pdf/2512.03996v1",
      "published": "2025-12-03T17:27:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.03996v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "DIQ-H: Evaluating Hallucination Persistence in VLMs Under Temporal Visual Degradation",
      "authors": [
        "Zexin Lin",
        "Hawen Wan",
        "Yebin Zhong",
        "Xiaoqiang"
      ],
      "abstract": "Vision-Language Models (VLMs) deployed in safety-critical applications such as autonomous driving must handle continuous visual streams under imperfect conditions. However, existing benchmarks focus on static, high-quality images and ignore temporal degradation and error propagation, which are critical failure modes where transient visual corruption induces hallucinations that persist across subsequent frames. We introduce DIQ-H, the first benchmark for evaluating VLM robustness under dynamic visual degradation in temporal sequences. DIQ-H applies physics-based corruptions including motion blur, sensor noise, and compression artifacts, and measures hallucination persistence, error recovery, and temporal consistency through multi-turn question-answering tasks. To enable scalable annotation, we propose Uncertainty-Guided Iterative Refinement (UIR), which generates reliable pseudo-ground-truth using lightweight VLMs with uncertainty filtering, achieving a 15.3 percent accuracy improvement. Experiments on 16 state-of-the-art VLMs reveal substantial robustness gaps: even advanced models such as GPT-4o achieve only a 78.5 percent recovery rate, while open-source models struggle with temporal consistency at less than 60 percent. DIQ-H provides a comprehensive platform for evaluating VLM reliability in real-world deployments.",
      "pdf_url": "https://arxiv.org/pdf/2512.03992v1",
      "published": "2025-12-03T17:22:29+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.03992v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "BlurDM: A Blur Diffusion Model for Image Deblurring",
      "authors": [
        "Jin-Ting He",
        "Fu-Jen Tsai",
        "Yan-Tsung Peng",
        "Min-Hung Chen",
        "Chia-Wen Lin",
        "Yen-Yu Lin"
      ],
      "abstract": "Diffusion models show promise for dynamic scene deblurring; however, existing studies often fail to leverage the intrinsic nature of the blurring process within diffusion models, limiting their full potential. To address it, we present a Blur Diffusion Model (BlurDM), which seamlessly integrates the blur formation process into diffusion for image deblurring. Observing that motion blur stems from continuous exposure, BlurDM implicitly models the blur formation process through a dual-diffusion forward scheme, diffusing both noise and blur onto a sharp image. During the reverse generation process, we derive a dual denoising and deblurring formulation, enabling BlurDM to recover the sharp image by simultaneously denoising and deblurring, given pure Gaussian noise conditioned on the blurred image as input. Additionally, to efficiently integrate BlurDM into deblurring networks, we perform BlurDM in the latent space, forming a flexible prior generation network for deblurring. Extensive experiments demonstrate that BlurDM significantly and consistently enhances existing deblurring methods on four benchmark datasets. The source code is available at https://github.com/Jin-Ting-He/BlurDM.",
      "pdf_url": "https://arxiv.org/pdf/2512.03979v1",
      "published": "2025-12-03T17:10:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.03979v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Sponsored Questions and How to Auction Them",
      "authors": [
        "Kshipra Bhawalkar",
        "Alexandros Psomas",
        "Di Wang"
      ],
      "abstract": "Online platforms connect users with relevant products and services using ads. A key challenge is that a user's search query often leaves their true intent ambiguous. Typically, platforms passively predict relevance based on available signals and in some cases offer query refinements. The shift from traditional search to conversational AI provides a new approach. When a user's query is ambiguous, a Large Language Model (LLM) can proactively offer several clarifying follow-up prompts. In this paper we consider the following: what if some of these follow-up prompts can be ``sponsored,'' i.e., selected for their advertising potential. How should these ``suggestion slots'' be allocated? And, how does this new mechanism interact with the traditional ad auction that might follow?\n  This paper introduces a formal model for designing and analyzing these interactive platforms. We use this model to investigate a critical engineering choice: whether it is better to build an end-to-end pipeline that jointly optimizes the user interaction and the final ad auction, or to decouple them into separate mechanisms for the suggestion slots and another for the subsequent ad slot. We show that the VCG mechanism can be adopted to jointly optimize the sponsored suggestion and the ads that follow; while this mechanism is more complex, it achieves outcomes that are efficient and truthful. On the other hand, we prove that the simple-to-implement modular approach suffers from strategic inefficiency: its Price of Anarchy is unbounded.",
      "pdf_url": "https://arxiv.org/pdf/2512.03975v1",
      "published": "2025-12-03T17:06:27+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.03975v1",
      "categories": [
        "cs.GT",
        "cs.AI"
      ]
    },
    {
      "title": "Guided Flow Policy: Learning from High-Value Actions in Offline Reinforcement Learning",
      "authors": [
        "Franki Nguimatsia Tiofack",
        "Théotime Le Hellard",
        "Fabian Schramm",
        "Nicolas Perrin-Gilbert",
        "Justin Carpentier"
      ],
      "abstract": "Offline reinforcement learning often relies on behavior regularization that enforces policies to remain close to the dataset distribution. However, such approaches fail to distinguish between high-value and low-value actions in their regularization components. We introduce Guided Flow Policy (GFP), which couples a multi-step flow-matching policy with a distilled one-step actor. The actor directs the flow policy through weighted behavior cloning to focus on cloning high-value actions from the dataset rather than indiscriminately imitating all state-action pairs. In turn, the flow policy constrains the actor to remain aligned with the dataset's best transitions while maximizing the critic. This mutual guidance enables GFP to achieve state-of-the-art performance across 144 state and pixel-based tasks from the OGBench, Minari, and D4RL benchmarks, with substantial gains on suboptimal datasets and challenging tasks. Webpage: https://simple-robotics.github.io/publications/guided-flow-policy/",
      "pdf_url": "https://arxiv.org/pdf/2512.03973v1",
      "published": "2025-12-03T17:05:58+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.03973v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Benchmark for Planning and Control with Large Language Model Agents: Blocksworld with Model Context Protocol",
      "authors": [
        "Niklas Jobs",
        "Luis Miguel Vieira da Silva",
        "Jayanth Somashekaraiah",
        "Maximilian Weigand",
        "David Kube",
        "Felix Gehlhoff"
      ],
      "abstract": "Industrial automation increasingly requires flexible control strategies that can adapt to changing tasks and environments. Agents based on Large Language Models (LLMs) offer potential for such adaptive planning and execution but lack standardized benchmarks for systematic comparison. We introduce a benchmark with an executable simulation environment representing the Blocksworld problem providing five complexity categories. By integrating the Model Context Protocol (MCP) as a standardized tool interface, diverse agent architectures can be connected to and evaluated against the benchmark without implementation-specific modifications. A single-agent implementation demonstrates the benchmark's applicability, establishing quantitative metrics for comparison of LLM-based planning and execution approaches.",
      "pdf_url": "https://arxiv.org/pdf/2512.03955v1",
      "published": "2025-12-03T16:49:14+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.03955v1",
      "categories": [
        "cs.AI",
        "cs.ET"
      ]
    },
    {
      "title": "Autonomous Agents and Policy Compliance: A Framework for Reasoning About Penalties",
      "authors": [
        "Vineel Tummala",
        "Daniela Inclezan"
      ],
      "abstract": "This paper presents a logic programming-based framework for policy-aware autonomous agents that can reason about potential penalties for non-compliance and act accordingly. While prior work has primarily focused on ensuring compliance, our approach considers scenarios where deviating from policies may be necessary to achieve high-stakes goals. Additionally, modeling non-compliant behavior can assist policymakers by simulating realistic human decision-making. Our framework extends Gelfond and Lobo's Authorization and Obligation Policy Language (AOPL) to incorporate penalties and integrates Answer Set Programming (ASP) for reasoning. Compared to previous approaches, our method ensures well-formed policies, accounts for policy priorities, and enhances explainability by explicitly identifying rule violations and their consequences. Building on the work of Harders and Inclezan, we introduce penalty-based reasoning to distinguish between non-compliant plans, prioritizing those with minimal repercussions. To support this, we develop an automated translation from the extended AOPL into ASP and refine ASP-based planning algorithms to account for incurred penalties. Experiments in two domains demonstrate that our framework generates higher-quality plans that avoid harmful actions while, in some cases, also improving computational efficiency. These findings underscore its potential for enhancing autonomous decision-making and informing policy refinement. Under consideration in Theory and Practice of Logic Programming (TPLP).",
      "pdf_url": "https://arxiv.org/pdf/2512.03931v1",
      "published": "2025-12-03T16:29:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.03931v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "A Theoretical Framework for Auxiliary-Loss-Free Load Balancing of Sparse Mixture-of-Experts in Large-Scale AI Models",
      "authors": [
        "X. Y. Han",
        "Yuan Zhong"
      ],
      "abstract": "In large-scale AI training, Sparse Mixture-of-Experts (s-MoE) layers enable scaling by activating only a small subset of experts per token. An operational challenge in this design is load balancing: routing tokens to minimize the number of idle experts, which is important for the efficient utilization of (costly) GPUs. We provide a theoretical framework for analyzing the Auxiliary-Loss-Free Load Balancing (ALF-LB) procedure -- proposed by DeepSeek's Wang et al. (2024) -- by casting it as a one-step-per-iteration primal-dual method for an assignment problem. First, in a stylized deterministic setting, our framework yields several insightful structural properties: (i) a monotonic improvement of a Lagrangian objective, (ii) a preference rule that moves tokens from overloaded to underloaded experts, and (iii) an approximate-balancing guarantee. Then, we incorporate the stochastic and dynamic nature of AI training using a generalized online optimization formulation. In the online setting, we derive a strong convexity property of the objective that leads to a logarithmic expected regret bound under certain step-size choices. Additionally, we present real experiments on 1B-parameter DeepSeekMoE models to complement our theoretical findings. Together, these results build a principled framework for analyzing the Auxiliary-Loss-Free Load Balancing of s-MoE in AI models.",
      "pdf_url": "https://arxiv.org/pdf/2512.03915v1",
      "published": "2025-12-03T16:00:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.03915v1",
      "categories": [
        "math.OC",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Hierarchical Vision Language Action Model Using Success and Failure Demonstrations",
      "authors": [
        "Jeongeun Park",
        "Jihwan Yoon",
        "Byungwoo Jeon",
        "Juhan Park",
        "Jinwoo Shin",
        "Namhoon Cho",
        "Kyungjae Lee",
        "Sangdoo Yun",
        "Sungjoon Choi"
      ],
      "abstract": "Prior Vision-Language-Action (VLA) models are typically trained on teleoperated successful demonstrations, while discarding numerous failed attempts that occur naturally during data collection. However, these failures encode where and how policies can be fragile, information that can be exploited to improve robustness. We address this problem by leveraging mixed-quality datasets to learn failure-aware reasoning at planning time. We introduce VINE, a hierarchical vision-language-action model that separates high-level reasoning (System 2) from low-level control (System 1) under a hierarchical reinforcement learning formalism, making failures usable as a structured learning signal rather than noisy supervision. System 2 performs feasibility-guided tree search over a 2D scene-graph abstraction: it proposes subgoal transitions, predicts success probabilities from both successes and failures, and prunes brittle branches before execution, effectively casting plan evaluation as feasibility scoring. The selected subgoal sequence is then passed to System 1, which executes low-level actions without modifying the agent's core skills. Trained entirely from offline teleoperation data, VINE integrates negative experience directly into the decision loop. Across challenging manipulation tasks, this approach consistently improves success rates and robustness, demonstrating that failure data is an essential resource for converting the broad competence of VLAs into robust execution.",
      "pdf_url": "https://arxiv.org/pdf/2512.03913v1",
      "published": "2025-12-03T15:58:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.03913v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "Autonomous Reinforcement Learning Robot Control with Intel's Loihi 2 Neuromorphic Hardware",
      "authors": [
        "Kenneth Stewart",
        "Roxana Leontie",
        "Samantha Chapin",
        "Joe Hays",
        "Sumit Bam Shrestha",
        "Carl Glen Henshaw"
      ],
      "abstract": "We present an end-to-end pipeline for deploying reinforcement learning (RL) trained Artificial Neural Networks (ANNs) on neuromorphic hardware by converting them into spiking Sigma-Delta Neural Networks (SDNNs). We demonstrate that an ANN policy trained entirely in simulation can be transformed into an SDNN compatible with Intel's Loihi 2 architecture, enabling low-latency and energy-efficient inference. As a test case, we use an RL policy for controlling the Astrobee free-flying robot, similar to a previously hardware in space-validated controller. The policy, trained with Rectified Linear Units (ReLUs), is converted to an SDNN and deployed on Intel's Loihi 2, then evaluated in NVIDIA's Omniverse Isaac Lab simulation environment for closed-loop control of Astrobee's motion. We compare execution performance between GPU and Loihi 2. The results highlight the feasibility of using neuromorphic platforms for robotic control and establish a pathway toward energy-efficient, real-time neuromorphic computation in future space and terrestrial robotics applications.",
      "pdf_url": "https://arxiv.org/pdf/2512.03911v1",
      "published": "2025-12-03T15:56:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.03911v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "BERnaT: Basque Encoders for Representing Natural Textual Diversity",
      "authors": [
        "Ekhi Azurmendi",
        "Joseba Fernandez de Landa",
        "Jaione Bengoetxea",
        "Maite Heredia",
        "Julen Etxaniz",
        "Mikel Zubillaga",
        "Ander Soraluze",
        "Aitor Soroa"
      ],
      "abstract": "Language models depend on massive text corpora that are often filtered for quality, a process that can unintentionally exclude non-standard linguistic varieties, reduce model robustness and reinforce representational biases. In this paper, we argue that language models should aim to capture the full spectrum of language variation (dialectal, historical, informal, etc.) rather than relying solely on standardized text. Focusing on Basque, a morphologically rich and low-resource language, we construct new corpora combining standard, social media, and historical sources, and pre-train the BERnaT family of encoder-only models in three configurations: standard, diverse, and combined. We further propose an evaluation framework that separates Natural Language Understanding (NLU) tasks into standard and diverse subsets to assess linguistic generalization. Results show that models trained on both standard and diverse data consistently outperform those trained on standard corpora, improving performance across all task types without compromising standard benchmark accuracy. These findings highlight the importance of linguistic diversity in building inclusive, generalizable language models.",
      "pdf_url": "https://arxiv.org/pdf/2512.03903v1",
      "published": "2025-12-03T15:50:42+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.03903v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "A Hierarchical Tree-based approach for creating Configurable and Static Deep Research Agent (Static-DRA)",
      "authors": [
        "Saurav Prateek"
      ],
      "abstract": "The advancement in Large Language Models has driven the creation of complex agentic systems, such as Deep Research Agents (DRAs), to overcome the limitations of static Retrieval Augmented Generation (RAG) pipelines in handling complex, multi-turn research tasks. This paper introduces the Static Deep Research Agent (Static-DRA), a novel solution built upon a configurable and hierarchical Tree-based static workflow.\n  The core contribution is the integration of two user-tunable parameters, Depth and Breadth, which provide granular control over the research intensity. This design allows end-users to consciously balance the desired quality and comprehensiveness of the research report against the associated computational cost of Large Language Model (LLM) interactions. The agent's architecture, comprising Supervisor, Independent, and Worker agents, facilitates effective multi-hop information retrieval and parallel sub-topic investigation.\n  We evaluate the Static-DRA against the established DeepResearch Bench using the RACE (Reference-based Adaptive Criteria-driven Evaluation) framework. Configured with a depth of 2 and a breadth of 5, and powered by the gemini-2.5-pro model, the agent achieved an overall score of 34.72. Our experiments validate that increasing the configured Depth and Breadth parameters results in a more in-depth research process and a correspondingly higher evaluation score. The Static-DRA offers a pragmatic and resource-aware solution, empowering users with transparent control over the deep research process. The entire source code, outputs and benchmark results are open-sourced at https://github.com/SauravP97/Static-Deep-Research/",
      "pdf_url": "https://arxiv.org/pdf/2512.03887v1",
      "published": "2025-12-03T15:37:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.03887v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Hyperdimensional Computing for Sustainable Manufacturing: An Initial Assessment",
      "authors": [
        "Danny Hoang",
        "Anandkumar Patel",
        "Ruimen Chen",
        "Rajiv Malhotra",
        "Farhad Imani"
      ],
      "abstract": "Smart manufacturing can significantly improve efficiency and reduce energy consumption, yet the energy demands of AI models may offset these gains. This study utilizes in-situ sensing-based prediction of geometric quality in smart machining to compare the energy consumption, accuracy, and speed of common AI models. HyperDimensional Computing (HDC) is introduced as an alternative, achieving accuracy comparable to conventional models while drastically reducing energy consumption, 200$\\times$ for training and 175 to 1000$\\times$ for inference. Furthermore, HDC reduces training times by 200$\\times$ and inference times by 300 to 600$\\times$, showcasing its potential for energy-efficient smart manufacturing.",
      "pdf_url": "https://arxiv.org/pdf/2512.03864v1",
      "published": "2025-12-03T15:14:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.03864v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.PF",
        "cs.SC"
      ]
    },
    {
      "title": "Scalable Decision Focused Learning via Online Trainable Surrogates",
      "authors": [
        "Gaetano Signorelli",
        "Michele Lombardi"
      ],
      "abstract": "Decision support systems often rely on solving complex optimization problems that may require to estimate uncertain parameters beforehand. Recent studies have shown how using traditionally trained estimators for this task can lead to suboptimal solutions. Using the actual decision cost as a loss function (called Decision Focused Learning) can address this issue, but with a severe loss of scalability at training time. To address this issue, we propose an acceleration method based on replacing costly loss function evaluations with an efficient surrogate. Unlike previously defined surrogates, our approach relies on unbiased estimators reducing the risk of spurious local optima and can provide information on its local confidence allowing one to switch to a fallback method when needed. Furthermore, the surrogate is designed for a black-box setting, which enables compensating for simplifications in the optimization model and account- ing for recourse actions during cost computation. In our results, the method reduces costly inner solver calls, with a solution quality comparable to other state-of-the-art techniques.",
      "pdf_url": "https://arxiv.org/pdf/2512.03861v1",
      "published": "2025-12-03T15:09:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.03861v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "PULSE: A Unified Multi-Task Architecture for Cardiac Segmentation, Diagnosis, and Few-Shot Cross-Modality Clinical Adaptation",
      "authors": [
        "Hania Ghouse",
        "Maryam Alsharqi",
        "Farhad R. Nezami",
        "Muzammil Behzad"
      ],
      "abstract": "Cardiac image analysis remains fragmented across tasks: anatomical segmentation, disease classification, and grounded clinical report generation are typically handled by separate networks trained under different data regimes. No existing framework unifies these objectives within a single architecture while retaining generalization across imaging modalities and datasets. We introduce PULSE, a multi-task vision-language framework built on self-supervised representations and optimized through a composite supervision strategy that balances region overlap learning, pixel wise classification fidelity, and boundary aware IoU refinement. A multi-scale token reconstruction decoder enables anatomical segmentation, while shared global representations support disease classification and clinically grounded text output allowing the model to transition from pixels to structures and finally clinical reasoning within one architecture. Unlike prior task-specific pipelines, PULSE learns task-invariant cardiac priors, generalizes robustly across datasets, and can be adapted to new imaging modalities with minimal supervision. This moves the field closer to a scalable, foundation style cardiac analysis framework.",
      "pdf_url": "https://arxiv.org/pdf/2512.03848v1",
      "published": "2025-12-03T14:49:01+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.03848v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "DVPO: Distributional Value Modeling-based Policy Optimization for LLM Post-Training",
      "authors": [
        "Dingwei Zhu",
        "Zhiheng Xi",
        "Shihan Dou",
        "Yuhui Wang",
        "Sixian Li",
        "Junjie Ye",
        "Honglin Guo",
        "Shichun Liu",
        "Chenhao Huang",
        "Yajie Yang",
        "Junlin Shang",
        "Senjie Jin",
        "Ming Zhang",
        "Jiazheng Zhang",
        "Caishuang Huang",
        "Yunke Zhang",
        "Demei Yan",
        "Yuran Wang",
        "Tao Gui"
      ],
      "abstract": "Reinforcement learning (RL) has shown strong performance in LLM post-training, but real-world deployment often involves noisy or incomplete supervision. In such settings, complex and unreliable supervision signals can destabilize training and harm generalization. While existing approaches such as worst-case optimization (e.g., RFQI, CQL) and mean-based methods (e.g., PPO, GRPO) can improve stability, they often overlook generalization and may produce overly conservative policies, leading to uneven performance across diverse real scenarios. To this end, we introduce DVPO (Distributional Value Modeling with Risk-aware Policy Optimization), a new RL framework that combines conditional risk theory with distributional value modeling to better balance robustness and generalization. DVPO learns token-level value distributions to provide fine-grained supervision, and applies an asymmetric risk regularization to shape the distribution tails: it contracts the lower tail to dampen noisy negative deviations, while expanding the upper tail to preserve exploratory diversity. Across extensive experiments and analysis in multi-turn dialogue, math reasoning, and scientific QA, DVPO consistently outperforms PPO, GRPO, and robust Bellman-based PPO under noisy supervision, showing its potential for LLM post-training in the real-world.",
      "pdf_url": "https://arxiv.org/pdf/2512.03847v1",
      "published": "2025-12-03T14:48:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.03847v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "MPCFormer: A physics-informed data-driven approach for explainable socially-aware autonomous driving",
      "authors": [
        "Jia Hu",
        "Zhexi Lian",
        "Xuerun Yan",
        "Ruiang Bi",
        "Dou Shen",
        "Yu Ruan",
        "Haoran Wang"
      ],
      "abstract": "Autonomous Driving (AD) vehicles still struggle to exhibit human-like behavior in highly dynamic and interactive traffic scenarios. The key challenge lies in AD's limited ability to interact with surrounding vehicles, largely due to a lack of understanding the underlying mechanisms of social interaction. To address this issue, we introduce MPCFormer, an explainable socially-aware autonomous driving approach with physics-informed and data-driven coupled social interaction dynamics. In this model, the dynamics are formulated into a discrete space-state representation, which embeds physics priors to enhance modeling explainability. The dynamics coefficients are learned from naturalistic driving data via a Transformer-based encoder-decoder architecture. To the best of our knowledge, MPCFormer is the first approach to explicitly model the dynamics of multi-vehicle social interactions. The learned social interaction dynamics enable the planner to generate manifold, human-like behaviors when interacting with surrounding traffic. By leveraging the MPC framework, the approach mitigates the potential safety risks typically associated with purely learning-based methods. Open-looped evaluation on NGSIM dataset demonstrates that MPCFormer achieves superior social interaction awareness, yielding the lowest trajectory prediction errors compared with other state-of-the-art approach. The prediction achieves an ADE as low as 0.86 m over a long prediction horizon of 5 seconds. Close-looped experiments in highly intense interaction scenarios, where consecutive lane changes are required to exit an off-ramp, further validate the effectiveness of MPCFormer. Results show that MPCFormer achieves the highest planning success rate of 94.67%, improves driving efficiency by 15.75%, and reduces the collision rate from 21.25% to 0.5%, outperforming a frontier Reinforcement Learning (RL) based planner.",
      "pdf_url": "https://arxiv.org/pdf/2512.03795v1",
      "published": "2025-12-03T13:43:33+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.03795v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "AdaptVision: Efficient Vision-Language Models via Adaptive Visual Acquisition",
      "authors": [
        "Zichuan Lin",
        "Yicheng Liu",
        "Yang Yang",
        "Lvfang Tao",
        "Deheng Ye"
      ],
      "abstract": "Vision-Language Models (VLMs) have achieved remarkable success in visual question answering tasks, but their reliance on large numbers of visual tokens introduces significant computational overhead. While existing efficient VLM approaches reduce visual tokens through fixed-ratio compression, they operate passively and lack the ability to adapt to varying task requirements. This motivates a fundamental question: Can VLMs autonomously determine the minimum number of visual tokens required for each sample? Inspired by human active vision mechanisms, we introduce AdaptVision, an efficient VLM paradigm that enables adaptive visual token acquisition through a coarse-to-fine approach. Our model initially processes compressed visual tokens from low-resolution images and selectively acquires additional visual information by invoking a bounding box tool to crop key regions when necessary. We train AdaptVision using a reinforcement learning framework that carefully balances accuracy and efficiency. Central to our approach is Decoupled Turn Policy Optimization (DTPO), which decouples the learning objective into two components: (1) tool learning, which optimizes correct tool utilization, and (2) accuracy improvement, which refines the generated responses to improve answer correctness. Based on this formulation, we further decouple advantage estimation by computing separate advantages for tokens associated with each objective. This formulation enables more effective optimization for AdaptVision compared to vanilla GRPO. Comprehensive experiments across multiple VQA benchmarks demonstrate that AdaptVision achieves superior performance while consuming substantially fewer visual tokens than state-of-the-art efficient VLM methods.",
      "pdf_url": "https://arxiv.org/pdf/2512.03794v1",
      "published": "2025-12-03T13:43:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.03794v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    },
    {
      "title": "Omni-AutoThink: Adaptive Multimodal Reasoning via Reinforcement Learning",
      "authors": [
        "Dongchao Yang",
        "Songxiang Liu",
        "Disong Wang",
        "Yuanyuan Wang",
        "Guanglu Wan",
        "Helen Meng"
      ],
      "abstract": "Recent advances in Omni models have enabled unified multimodal perception and generation. However, most existing systems still exhibit rigid reasoning behaviors, either overthinking simple problems or failing to reason when necessary. To address this limitation, we propose Omni-AutoThink, a novel adaptive reasoning framework that dynamically adjusts the model's reasoning depth according to task difficulty. Our framework comprises two stages: (1) an Adaptive Supervised Fine-Tuning (Adaptive SFT) stage, which endows the Omni model with fundamental reasoning capability using large-scale reasoning-augmented data, and (2) an Adaptive Reinforcement Learning (Adaptive GRPO) stage, which optimizes reasoning behaviors based on task complexity and reward feedback. We further construct a comprehensive adaptive reasoning benchmark that spans text-only, text-audio, text-visual, and text-audio-visual modalities, providing both training and evaluation splits for multimodal reasoning assessment. Experimental results demonstrate that our proposed framework significantly improves adaptive reasoning performance compared to previous baselines. All benchmark data and code will be publicly released.",
      "pdf_url": "https://arxiv.org/pdf/2512.03783v1",
      "published": "2025-12-03T13:33:28+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.03783v1",
      "categories": [
        "cs.AI",
        "cs.SD"
      ]
    },
    {
      "title": "Bayesian Optimization for Automatic Tuning of Torque-Level Nonlinear Model Predictive Control",
      "authors": [
        "Gabriele Fadini",
        "Deepak Ingole",
        "Tong Duy Son",
        "Alisa Rupenyan"
      ],
      "abstract": "This paper presents an auto-tuning framework for torque-based Nonlinear Model Predictive Control (nMPC), where the MPC serves as a real-time controller for optimal joint torque commands. The MPC parameters, including cost function weights and low-level controller gains, are optimized using high-dimensional Bayesian Optimization (BO) techniques, specifically Sparse Axis-Aligned Subspace (SAASBO) with a digital twin (DT) to achieve precise end-effector trajectory real-time tracking on an UR10e robot arm. The simulation model allows efficient exploration of the high-dimensional parameter space, and it ensures safe transfer to hardware. Our simulation results demonstrate significant improvements in tracking performance (+41.9%) and reduction in solve times (-2.5%) compared to manually-tuned parameters. Moreover, experimental validation on the real robot follows the trend (with a +25.8% improvement), emphasizing the importance of digital twin-enabled automated parameter optimization for robotic operations.",
      "pdf_url": "https://arxiv.org/pdf/2512.03772v1",
      "published": "2025-12-03T13:19:42+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.03772v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "eess.SY"
      ]
    },
    {
      "title": "In-Context Representation Hijacking",
      "authors": [
        "Itay Yona",
        "Amir Sarid",
        "Michael Karasik",
        "Yossi Gandelsman"
      ],
      "abstract": "We introduce \\textbf{Doublespeak}, a simple \\emph{in-context representation hijacking} attack against large language models (LLMs). The attack works by systematically replacing a harmful keyword (e.g., \\textit{bomb}) with a benign token (e.g., \\textit{carrot}) across multiple in-context examples, provided a prefix to a harmful request. We demonstrate that this substitution leads to the internal representation of the benign token converging toward that of the harmful one, effectively embedding the harmful semantics under a euphemism. As a result, superficially innocuous prompts (e.g., ``How to build a carrot?'') are internally interpreted as disallowed instructions (e.g., ``How to build a bomb?''), thereby bypassing the model's safety alignment. We use interpretability tools to show that this semantic overwrite emerges layer by layer, with benign meanings in early layers converging into harmful semantics in later ones. Doublespeak is optimization-free, broadly transferable across model families, and achieves strong success rates on closed-source and open-source systems, reaching 74\\% ASR on Llama-3.3-70B-Instruct with a single-sentence context override. Our findings highlight a new attack surface in the latent space of LLMs, revealing that current alignment strategies are insufficient and should instead operate at the representation level.",
      "pdf_url": "https://arxiv.org/pdf/2512.03771v1",
      "published": "2025-12-03T13:19:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.03771v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ]
    },
    {
      "title": "RoCo: Role-Based LLMs Collaboration for Automatic Heuristic Design",
      "authors": [
        "Jiawei Xu",
        "Fengfeng Wei",
        "Weineng Chen"
      ],
      "abstract": "Automatic Heuristic Design (AHD) has gained traction as a promising solution for solving combinatorial optimization problems (COPs). Large Language Models (LLMs) have emerged and become a promising approach to achieving AHD, but current LLM-based AHD research often only considers a single role. This paper proposes RoCo, a novel Multi-Agent Role-Based System, to enhance the diversity and quality of AHD through multi-role collaboration. RoCo coordinates four specialized LLM-guided agents-explorer, exploiter, critic, and integrator-to collaboratively generate high-quality heuristics. The explorer promotes long-term potential through creative, diversity-driven thinking, while the exploiter focuses on short-term improvements via conservative, efficiency-oriented refinements. The critic evaluates the effectiveness of each evolution step and provides targeted feedback and reflection. The integrator synthesizes proposals from the explorer and exploiter, balancing innovation and exploitation to drive overall progress. These agents interact in a structured multi-round process involving feedback, refinement, and elite mutations guided by both short-term and accumulated long-term reflections. We evaluate RoCo on five different COPs under both white-box and black-box settings. Experimental results demonstrate that RoCo achieves superior performance, consistently generating competitive heuristics that outperform existing methods including ReEvo and HSEvo, both in white-box and black-box scenarios. This role-based collaborative paradigm establishes a new standard for robust and high-performing AHD.",
      "pdf_url": "https://arxiv.org/pdf/2512.03762v1",
      "published": "2025-12-03T13:09:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.03762v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Principled RL for Diffusion LLMs Emerges from a Sequence-Level Perspective",
      "authors": [
        "Jingyang Ou",
        "Jiaqi Han",
        "Minkai Xu",
        "Shaoxuan Xu",
        "Jianwen Xie",
        "Stefano Ermon",
        "Yi Wu",
        "Chongxuan Li"
      ],
      "abstract": "Reinforcement Learning (RL) has proven highly effective for autoregressive language models, but adapting these methods to diffusion large language models (dLLMs) presents fundamental challenges. The core difficulty lies in likelihood approximation: while autoregressive models naturally provide token-level conditional probabilities essential for token-level RL objectives (e.g., GRPO), dLLMs generate sequences through iterative non-autoregressive denoising steps that lack this factorization. To address this fundamental mismatch, we propose ELBO-based Sequence-level Policy Optimization (ESPO), a principled RL framework that treats entire sequence generation as a single action and uses the ELBO as a tractable sequence-level likelihood proxy. Our method incorporates per-token normalization of importance ratios and robust KL-divergence estimation to ensure stable large-scale training. Extensive experiments on mathematical reasoning, coding, and planning tasks demonstrate that ESPO significantly outperforms token-level baselines, achieving dramatic improvements of 20-40 points on the Countdown task, while maintaining consistent gains on math and coding benchmarks. Our approach establishes sequence-level optimization as a principled and empirically effective paradigm for RL in dLLMs. Our code is available at https://github.com/ML-GSAI/ESPO.",
      "pdf_url": "https://arxiv.org/pdf/2512.03759v1",
      "published": "2025-12-03T13:05:32+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.03759v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Research on Brain Tumor Classification Method Based on Improved ResNet34 Network",
      "authors": [
        "Yufeng Li",
        "Wenchao Zhao",
        "Bo Dang",
        "Weimin Wang"
      ],
      "abstract": "Previously, image interpretation in radiology relied heavily on manual methods. However, manual classification of brain tumor medical images is time-consuming and labor-intensive. Even with shallow convolutional neural network models, the accuracy is not ideal. To improve the efficiency and accuracy of brain tumor image classification, this paper proposes a brain tumor classification model based on an improved ResNet34 network. This model uses the ResNet34 residual network as the backbone network and incorporates multi-scale feature extraction. It uses a multi-scale input module as the first layer of the ResNet34 network and an Inception v2 module as the residual downsampling layer. Furthermore, a channel attention mechanism module assigns different weights to different channels of the image from a channel domain perspective, obtaining more important feature information. The results after a five-fold crossover experiment show that the average classification accuracy of the improved network model is approximately 98.8%, which is not only 1% higher than ResNet34, but also only 80% of the number of parameters of the original model. Therefore, the improved network model not only improves accuracy but also reduces clutter, achieving a classification effect with fewer parameters and higher accuracy.",
      "pdf_url": "https://arxiv.org/pdf/2512.03751v1",
      "published": "2025-12-03T12:47:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.03751v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Out-of-the-box: Black-box Causal Attacks on Object Detectors",
      "authors": [
        "Melane Navaratnarajah",
        "David A. Kelly",
        "Hana Chockler"
      ],
      "abstract": "Adversarial perturbations are a useful way to expose vulnerabilities in object detectors. Existing perturbation methods are frequently white-box and architecture specific. More importantly, while they are often successful, it is rarely clear why they work. Insights into the mechanism of this success would allow developers to understand and analyze these attacks, as well as fine-tune the model to prevent them. This paper presents BlackCAtt, a black-box algorithm and a tool, which uses minimal, causally sufficient pixel sets to construct explainable, imperceptible, reproducible, architecture-agnostic attacks on object detectors. BlackCAtt combines causal pixels with bounding boxes produced by object detectors to create adversarial attacks that lead to the loss, modification or addition of a bounding box. BlackCAtt works across different object detectors of different sizes and architectures, treating the detector as a black box. We compare the performance of BlackCAtt with other black-box attack methods and show that identification of causal pixels leads to more precisely targeted and less perceptible attacks. On the COCO test dataset, our approach is 2.7 times better than the baseline in removing a detection, 3.86 times better in changing a detection, and 5.75 times better in triggering new, spurious, detections. The attacks generated by BlackCAtt are very close to the original image, and hence imperceptible, demonstrating the power of causal pixels.",
      "pdf_url": "https://arxiv.org/pdf/2512.03730v1",
      "published": "2025-12-03T12:17:35+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.03730v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "AI/ML in 3GPP 5G Advanced - Services and Architecture",
      "authors": [
        "Pradnya Taksande",
        "Shwetha Kiran",
        "Pranav Jha",
        "Prasanna Chaporkar"
      ],
      "abstract": "The 3rd Generation Partnership Project (3GPP), the standards body for mobile networks, is in the final phase of Release 19 standardization and is beginning Release 20. Artificial Intelligence/ Machine Learning (AI/ML) has brought about a paradigm shift in technology and it is being adopted across industries and verticals. 3GPP has been integrating AI/ML into the 5G advanced system since Release 18. This paper focuses on the AI/ML related technological advancements and features introduced in Release 19 within the Service and System Aspects (SA) Technical specifications group of 3GPP. The advancements relate to two paradigms: (i) enhancements that AI/ML brought to the 5G advanced system (AI for network), e.g. resource optimization, and (ii) enhancements that were made to the 5G system to support AI/ML applications (Network for AI), e.g. image recognition.",
      "pdf_url": "https://arxiv.org/pdf/2512.03728v1",
      "published": "2025-12-03T12:16:08+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.03728v1",
      "categories": [
        "cs.ET",
        "cs.AI"
      ]
    },
    {
      "title": "Context-Aware Hierarchical Learning: A Two-Step Paradigm towards Safer LLMs",
      "authors": [
        "Tengyun Ma",
        "Jiaqi Yao",
        "Daojing He",
        "Shihao Peng",
        "Yu Li",
        "Shaohui Liu",
        "Zhuotao Tian"
      ],
      "abstract": "Large Language Models (LLMs) have emerged as powerful tools for diverse applications. However, their uniform token processing paradigm introduces critical vulnerabilities in instruction handling, particularly when exposed to adversarial scenarios. In this work, we identify and propose a novel class of vulnerabilities, termed Tool-Completion Attack (TCA), which exploits function-calling mechanisms to subvert model behavior. To evaluate LLM robustness against such threats, we introduce the Tool-Completion benchmark, a comprehensive security assessment framework, which reveals that even state-of-the-art models remain susceptible to TCA, with surprisingly high attack success rates. To address these vulnerabilities, we introduce Context-Aware Hierarchical Learning (CAHL), a sophisticated mechanism that dynamically balances semantic comprehension with role-specific instruction constraints. CAHL leverages the contextual correlations between different instruction segments to establish a robust, context-aware instruction hierarchy. Extensive experiments demonstrate that CAHL significantly enhances LLM robustness against both conventional attacks and the proposed TCA, exhibiting strong generalization capabilities in zero-shot evaluations while still preserving model performance on generic tasks. Our code is available at https://github.com/S2AILab/CAHL.",
      "pdf_url": "https://arxiv.org/pdf/2512.03720v1",
      "published": "2025-12-03T12:10:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.03720v1",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "title": "Over-the-Air Federated Learning: Rethinking Edge AI Through Signal Processing",
      "authors": [
        "Seyed Mohammad Azimi-Abarghouyi",
        "Carlo Fischione",
        "Kaibin Huang"
      ],
      "abstract": "Over-the-Air Federated Learning (AirFL) is an emerging paradigm that tightly integrates wireless signal processing and distributed machine learning to enable scalable AI at the network edge. By leveraging the superposition property of wireless signals, AirFL performs communication and model aggregation of the learning process simultaneously, significantly reducing latency, bandwidth, and energy consumption. This article offers a tutorial treatment of AirFL, presenting a novel classification into three design approaches: CSIT-aware, blind, and weighted AirFL. We provide a comprehensive guide to theoretical foundations, performance analysis, complexity considerations, practical limitations, and prospective research directions.",
      "pdf_url": "https://arxiv.org/pdf/2512.03719v1",
      "published": "2025-12-03T12:10:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.03719v1",
      "categories": [
        "cs.IT",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Matrix Editing Meets Fair Clustering: Parameterized Algorithms and Complexity",
      "authors": [
        "Robert Ganian",
        "Hung P. Hoang",
        "Simon Wietheger"
      ],
      "abstract": "We study the computational problem of computing a fair means clustering of discrete vectors, which admits an equivalent formulation as editing a colored matrix into one with few distinct color-balanced rows by changing at most $k$ values. While NP-hard in both the fairness-oblivious and the fair settings, the problem is well-known to admit a fixed-parameter algorithm in the former ``vanilla'' setting. As our first contribution, we exclude an analogous algorithm even for highly restricted fair means clustering instances. We then proceed to obtain a full complexity landscape of the problem, and establish tractability results which capture three means of circumventing our obtained lower bound: placing additional constraints on the problem instances, fixed-parameter approximation, or using an alternative parameterization targeting tree-like matrices.",
      "pdf_url": "https://arxiv.org/pdf/2512.03718v1",
      "published": "2025-12-03T12:07:24+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.03718v1",
      "categories": [
        "cs.DS",
        "cs.AI"
      ]
    },
    {
      "title": "Quantum Topological Graph Neural Networks for Detecting Complex Fraud Patterns",
      "authors": [
        "Mohammad Doost",
        "Mohammad Manthouri"
      ],
      "abstract": "We propose a novel QTGNN framework for detecting fraudulent transactions in large-scale financial networks. By integrating quantum embedding, variational graph convolutions, and topological data analysis, QTGNN captures complex transaction dynamics and structural anomalies indicative of fraud. The methodology includes quantum data embedding with entanglement enhancement, variational quantum graph convolutions with non-linear dynamics, extraction of higher-order topological invariants, hybrid quantum-classical anomaly learning with adaptive optimization, and interpretable decision-making via topological attribution. Rigorous convergence guarantees ensure stable training on noisy intermediate-scale quantum (NISQ) devices, while stability of topological signatures provides robust fraud detection. Optimized for NISQ hardware with circuit simplifications and graph sampling, the framework scales to large transaction networks. Simulations on financial datasets, such as PaySim and Elliptic, benchmark QTGNN against classical and quantum baselines, using metrics like ROC-AUC, precision, and false positive rate. An ablation study evaluates the contributions of quantum embeddings, topological features, non-linear channels, and hybrid learning. QTGNN offers a theoretically sound, interpretable, and practical solution for financial fraud detection, bridging quantum machine learning, graph theory, and topological analysis.",
      "pdf_url": "https://arxiv.org/pdf/2512.03696v1",
      "published": "2025-12-03T11:38:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.03696v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "ToG-Bench: Task-Oriented Spatio-Temporal Grounding in Egocentric Videos",
      "authors": [
        "Qi'ao Xu",
        "Tianwen Qian",
        "Yuqian Fu",
        "Kailing Li",
        "Yang Jiao",
        "Jiacheng Zhang",
        "Xiaoling Wang",
        "Liang He"
      ],
      "abstract": "A core capability towards general embodied intelligence lies in localizing task-relevant objects from an egocentric perspective, formulated as Spatio-Temporal Video Grounding (STVG). Despite recent progress, existing STVG studies remain largely confined to object-centric and descriptive instructions, neglecting the task-oriented reasoning that is crucial for embodied agents to accomplish goal-directed interactions. To bridge this gap, we introduce \\textbf{ToG-Bench}, the first task-oriented spatio-temporal video grounding benchmark for egocentric videos. ToG-Bench is characterized by three key features: (1) \\textbf{Task-oriented Grounding}, which requires identifying and localizing objects based on intended tasks rather than straightforward descriptions; (2) \\textbf{Explicit-Implicit Dual Grounding}, where target objects can be either explicitly mentioned or implicitly inferred by contextual reasoning; (3) \\textbf{One-to-Many Grounding}, where a single instruction may correspond to multiple objects involved in task execution. Built upon videos sourced from ScanNet, ToG-Bench comprises 100 annotated clips with 2,704 task-oriented grounding instructions, constructed via a semi-automated pipeline that combines foundation model annotation and human refinement. In addition, we introduce a set of task-level evaluation metrics tailored for multi-object and explicit-implicit object grounding, and systematically benchmark seven state-of-the-art MLLMs. Extensive experiments reveal the intrinsic challenges of task-oriented STVG and substantial performance gaps across explicit-implicit and multi-object grounding, highlighting the difficulty of bridging perception and interaction in embodied scenarios. Data and code will be released at: \\href{https://github.com/qaxuDev/ToG-Bench}{https://github.com/qaxuDev/ToG-Bench}..",
      "pdf_url": "https://arxiv.org/pdf/2512.03666v1",
      "published": "2025-12-03T10:54:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.03666v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Dynamically Scaled Activation Steering",
      "authors": [
        "Alex Ferrando",
        "Xavier Suau",
        "Jordi Gonzàlez",
        "Pau Rodriguez"
      ],
      "abstract": "Activation steering has emerged as a powerful method for guiding the behavior of generative models towards desired outcomes such as toxicity mitigation. However, most existing methods apply interventions uniformly across all inputs, degrading model performance when steering is unnecessary. We introduce Dynamically Scaled Activation Steering (DSAS), a method-agnostic steering framework that decouples when to steer from how to steer. DSAS adaptively modulates the strength of existing steering transformations across layers and inputs, intervening strongly only when undesired behavior is detected. At generation time, DSAS computes context-dependent scaling factors that selectively adjust the strength of any steering method. We also show how DSAS can be jointly optimized end-to-end together with the steering function. When combined with existing steering methods, DSAS consistently improves the Pareto front with respect to steering alone, achieving a better trade-off between toxicity mitigation and utility preservation. We further demonstrate DSAS's generality by applying it to a text-to-image diffusion model, showing how adaptive steering allows the modulation of specific concepts. Finally, DSAS introduces minimal computational overhead while improving interpretability, pinpointing which tokens require steering and by how much.",
      "pdf_url": "https://arxiv.org/pdf/2512.03661v1",
      "published": "2025-12-03T10:50:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.03661v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "MKSNet: Advanced Small Object Detection in Remote Sensing Imagery with Multi-Kernel and Dual Attention Mechanisms",
      "authors": [
        "Jiahao Zhang",
        "Xiao Zhao",
        "Guangyu Gao"
      ],
      "abstract": "Deep convolutional neural networks (DCNNs) have substantially advanced object detection capabilities, particularly in remote sensing imagery. However, challenges persist, especially in detecting small objects where the high resolution of these images and the small size of target objects often result in a loss of critical information in the deeper layers of conventional CNNs. Additionally, the extensive spatial redundancy and intricate background details typical in remote-sensing images tend to obscure these small targets. To address these challenges, we introduce Multi-Kernel Selection Network (MKSNet), a novel network architecture featuring a novel Multi-Kernel Selection mechanism. The MKS mechanism utilizes large convolutional kernels to effectively capture an extensive range of contextual information. This innovative design allows for adaptive kernel size selection, significantly enhancing the network's ability to dynamically process and emphasize crucial spatial details for small object detection. Furthermore, MKSNet also incorporates a dual attention mechanism, merging spatial and channel attention modules. The spatial attention module adaptively fine-tunes the spatial weights of feature maps, focusing more intensively on relevant regions while mitigating background noise. Simultaneously, the channel attention module optimizes channel information selection, improving feature representation and detection accuracy. Empirical evaluations on the DOTA-v1.0 and HRSC2016 benchmark demonstrate that MKSNet substantially surpasses existing state-of-the-art models in detecting small objects in remote sensing images. These results highlight MKSNet's superior ability to manage the complexities associated with multi-scale and high-resolution image data, confirming its effectiveness and innovation in remote sensing object detection.",
      "pdf_url": "https://arxiv.org/pdf/2512.03640v1",
      "published": "2025-12-03T10:22:27+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.03640v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "AlignCheck: a Semantic Open-Domain Metric for Factual Consistency Assessment",
      "authors": [
        "Ahmad Aghaebrahimian"
      ],
      "abstract": "Large Language Models have significantly advanced natural language processing tasks, but remain prone to generating incorrect or misleading but plausible arguments. This issue, known as hallucination, is particularly concerning in high-stakes domains like clinical applications, where factual inaccuracies can have severe consequences. Existing evaluation metrics fail to adequately assess factual consistency and lack interpretability, making diagnosing and mitigating errors difficult. We propose an interpretable framework for factual consistency assessment for in-domain and open-domain texts to address these limitations. Our approach decomposes text into atomic facts and introduces a flexible, schema-free methodology. Unlike previous methods with an absolute metric, we incorporate a weighted metric to enhance factual evaluation. Additionally, we propose a mechanism to control assessment complexity in intricate domains. We benchmark our approach on popular general and clinical datasets and release our code to support fact-aware model training in future research.",
      "pdf_url": "https://arxiv.org/pdf/2512.03634v1",
      "published": "2025-12-03T10:14:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.03634v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "MemVerse: Multimodal Memory for Lifelong Learning Agents",
      "authors": [
        "Junming Liu",
        "Yifei Sun",
        "Weihua Cheng",
        "Haodong Lei",
        "Yirong Chen",
        "Licheng Wen",
        "Xuemeng Yang",
        "Daocheng Fu",
        "Pinlong Cai",
        "Nianchen Deng",
        "Yi Yu",
        "Shuyue Hu",
        "Botian Shi",
        "Ding Wang"
      ],
      "abstract": "Despite rapid progress in large-scale language and vision models, AI agents still suffer from a fundamental limitation: they cannot remember. Without reliable memory, agents catastrophically forget past experiences, struggle with long-horizon reasoning, and fail to operate coherently in multimodal or interactive environments. We introduce MemVerse, a model-agnostic, plug-and-play memory framework that bridges fast parametric recall with hierarchical retrieval-based memory, enabling scalable and adaptive multimodal intelligence. MemVerse maintains short-term memory for recent context while transforming raw multimodal experiences into structured long-term memories organized as hierarchical knowledge graphs. This design supports continual consolidation, adaptive forgetting, and bounded memory growth. To handle real-time demands, MemVerse introduces a periodic distillation mechanism that compresses essential knowledge from long-term memory into the parametric model, allowing fast, differentiable recall while preserving interpretability. Extensive experiments demonstrate that MemVerse significantly improves multimodal reasoning and continual learning efficiency, empowering agents to remember, adapt, and reason coherently across extended interactions.",
      "pdf_url": "https://arxiv.org/pdf/2512.03627v1",
      "published": "2025-12-03T10:06:14+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.03627v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "The promising potential of vision language models for the generation of textual weather forecasts",
      "authors": [
        "Edward C. C. Steele",
        "Dinesh Mane",
        "Emilio Monti",
        "Luis Orus",
        "Rebecca Chantrill-Cheyette",
        "Matthew Couch",
        "Kirstine I. Dale",
        "Simon Eaton",
        "Govindarajan Rangarajan",
        "Amir Majlesi",
        "Steven Ramsdale",
        "Michael Sharpe",
        "Craig Smith",
        "Jonathan Smith",
        "Rebecca Yates",
        "Holly Ellis",
        "Charles Ewen"
      ],
      "abstract": "Despite the promising capability of multimodal foundation models, their application to the generation of meteorological products and services remains nascent. To accelerate aspiration and adoption, we explore the novel use of a vision language model for writing the iconic Shipping Forecast text directly from video-encoded gridded weather data. These early results demonstrate promising scalable technological opportunities for enhancing production efficiency and service innovation within the weather enterprise and beyond.",
      "pdf_url": "https://arxiv.org/pdf/2512.03623v1",
      "published": "2025-12-03T10:00:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.03623v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.ao-ph"
      ]
    },
    {
      "title": "SELF: A Robust Singular Value and Eigenvalue Approach for LLM Fingerprinting",
      "authors": [
        "Hanxiu Zhang",
        "Yue Zheng"
      ],
      "abstract": "The protection of Intellectual Property (IP) in Large Language Models (LLMs) represents a critical challenge in contemporary AI research. While fingerprinting techniques have emerged as a fundamental mechanism for detecting unauthorized model usage, existing methods -- whether behavior-based or structural -- suffer from vulnerabilities such as false claim attacks or susceptible to weight manipulations. To overcome these limitations, we propose SELF, a novel intrinsic weight-based fingerprinting scheme that eliminates dependency on input and inherently resists false claims. SELF achieves robust IP protection through two key innovations: 1) unique, scalable and transformation-invariant fingerprint extraction via singular value and eigenvalue decomposition of LLM attention weights, and 2) effective neural network-based fingerprint similarity comparison based on few-shot learning and data augmentation. Experimental results demonstrate SELF maintains high IP infringement detection accuracy while showing strong robustness against various downstream modifications, including quantization, pruning, and fine-tuning attacks. Our code is available at https://github.com/HanxiuZhang/SELF_v2.",
      "pdf_url": "https://arxiv.org/pdf/2512.03620v1",
      "published": "2025-12-03T09:53:47+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.03620v1",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    },
    {
      "title": "KVNAND: Efficient On-Device Large Language Model Inference Using DRAM-Free In-Flash Computing",
      "authors": [
        "Lishuo Deng",
        "Shaojie Xu",
        "Jinwu Chen",
        "Changwei Yan",
        "Jiajie Wang",
        "Zhe Jiang",
        "Weiwei Shan"
      ],
      "abstract": "Deploying large language models (LLMs) on edge devices enables personalized agents with strong privacy and low cost. However, with tens to hundreds of billions of parameters, single-batch autoregressive inference suffers from extremely low arithmetic intensity, creating severe weight-loading and bandwidth pressures on resource-constrained platforms. Recent in-flash computing (IFC) solutions alleviate this bottleneck by co-locating weight-related linear computations in the decode phase with flash, yet still rely on DRAM for the key-value (KV) cache. As context length grows, the KV cache can exceed model weights in size, imposing prohibitive DRAM cost and capacity requirements. Attempts to offload KV cache to flash suffer from severe performance penalties.\n  We propose KVNAND, the first DRAM-free, IFC-based architecture that stores both model weights and KV cache entirely in compute-enabled 3D NAND flash. KVNAND addresses the fundamental performance challenges of flash under intensive KV cache access by leveraging IFC for all memory-bound operations to reduce data transfer overhead, introducing head-group parallelism to boost throughput, and employing page-level KV cache mapping to align token access patterns with flash organization. In addition, we propose a design space exploration framework that evaluates discrete and compact KVNAND variants to balance weight and KV placement, automatically identifying the optimal design trade-off. These techniques mitigate latency, energy, and reliability concerns, turning flash into a practical medium for long-context KV storage. Evaluations on MHA 7B and GQA 70B LLMs show that KVNAND achieves 1.98\\(\\times\\)/1.94\\(\\times\\)/2.05\\(\\times\\) geomean speedup at 128/1K/10K-token contexts compared to DRAM-equipped IFC designs and addresses out-of-memory failures at 100K context length.",
      "pdf_url": "https://arxiv.org/pdf/2512.03608v1",
      "published": "2025-12-03T09:41:03+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.03608v1",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.ET"
      ]
    },
    {
      "title": "DeepRule: An Integrated Framework for Automated Business Rule Generation via Deep Predictive Modeling and Hybrid Search Optimization",
      "authors": [
        "Yusen Wu",
        "Xiaotie Deng"
      ],
      "abstract": "This paper proposes DeepRule, an integrated framework for automated business rule generation in retail assortment and pricing optimization. Addressing the systematic misalignment between existing theoretical models and real-world economic complexities, we identify three critical gaps: (1) data modality mismatch where unstructured textual sources (e.g. negotiation records, approval documents) impede accurate customer profiling; (2) dynamic feature entanglement challenges in modeling nonlinear price elasticity and time-varying attributes; (3) operational infeasibility caused by multi-tier business constraints.\n  Our framework introduces a tri-level architecture for above challenges. We design a hybrid knowledge fusion engine employing large language models (LLMs) for deep semantic parsing of unstructured text, transforming distributor agreements and sales assessments into structured features while integrating managerial expertise. Then a game-theoretic constrained optimization mechanism is employed to dynamically reconcile supply chain interests through bilateral utility functions, encoding manufacturer-distributor profit redistribution as endogenous objectives under hierarchical constraints. Finally an interpretable decision distillation interface leveraging LLM-guided symbolic regression to find and optimize pricing strategies and auditable business rules embeds economic priors (e.g. non-negative elasticity) as hard constraints during mathematical expression search. We validate the framework in real retail environments achieving higher profits versus systematic B2C baselines while ensuring operational feasibility. This establishes a close-loop pipeline unifying unstructured knowledge injection, multi-agent optimization, and interpretable strategy synthesis for real economic intelligence.",
      "pdf_url": "https://arxiv.org/pdf/2512.03607v1",
      "published": "2025-12-03T09:40:33+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.03607v1",
      "categories": [
        "cs.AI"
      ]
    }
  ]
}