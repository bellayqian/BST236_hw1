{
  "last_updated": "2025-11-05T00:53:22.162319",
  "papers": [
    {
      "title": "Continuous Autoregressive Language Models",
      "authors": [
        "Chenze Shao",
        "Darren Li",
        "Fandong Meng",
        "Jie Zhou"
      ],
      "abstract": "The efficiency of large language models (LLMs) is fundamentally limited by\ntheir sequential, token-by-token generation process. We argue that overcoming\nthis bottleneck requires a new design axis for LLM scaling: increasing the\nsemantic bandwidth of each generative step. To this end, we introduce\nContinuous Autoregressive Language Models (CALM), a paradigm shift from\ndiscrete next-token prediction to continuous next-vector prediction. CALM uses\na high-fidelity autoencoder to compress a chunk of K tokens into a single\ncontinuous vector, from which the original tokens can be reconstructed with\nover 99.9\\% accuracy. This allows us to model language as a sequence of\ncontinuous vectors instead of discrete tokens, which reduces the number of\ngenerative steps by a factor of K. The paradigm shift necessitates a new\nmodeling toolkit; therefore, we develop a comprehensive likelihood-free\nframework that enables robust training, evaluation, and controllable sampling\nin the continuous domain. Experiments show that CALM significantly improves the\nperformance-compute trade-off, achieving the performance of strong discrete\nbaselines at a significantly lower computational cost. More importantly, these\nfindings establish next-vector prediction as a powerful and scalable pathway\ntowards ultra-efficient language models. Code:\nhttps://github.com/shaochenze/calm. Project:\nhttps://shaochenze.github.io/blog/2025/CALM.",
      "pdf_url": "http://arxiv.org/pdf/2510.27688v1",
      "published": "2025-10-31T17:58:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.27688v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "PETAR: Localized Findings Generation with Mask-Aware Vision-Language Modeling for PET Automated Reporting",
      "authors": [
        "Danyal Maqbool",
        "Changhee Lee",
        "Zachary Huemann",
        "Samuel D. Church",
        "Matthew E. Larson",
        "Scott B. Perlman",
        "Tomas A. Romero",
        "Joshua D. Warner",
        "Meghan Lubner",
        "Xin Tie",
        "Jameson Merkow",
        "Junjie Hu",
        "Steve Y. Cho",
        "Tyler J. Bradshaw"
      ],
      "abstract": "Recent advances in vision-language models (VLMs) have enabled impressive\nmultimodal reasoning, yet most medical applications remain limited to 2D\nimaging. In this work, we extend VLMs to 3D positron emission tomography and\ncomputed tomography (PET/CT), a domain characterized by large volumetric data,\nsmall and dispersed lesions, and lengthy radiology reports. We introduce a\nlarge-scale dataset comprising over 11,000 lesion-level descriptions paired\nwith 3D segmentations from more than 5,000 PET/CT exams, extracted via a hybrid\nrule-based and large language model (LLM) pipeline. Building upon this dataset,\nwe propose PETAR-4B, a 3D mask-aware vision-language model that integrates PET,\nCT, and lesion contours for spatially grounded report generation. PETAR bridges\nglobal contextual reasoning with fine-grained lesion awareness, producing\nclinically coherent and localized findings. Comprehensive automated and human\nevaluations demonstrate that PETAR substantially improves PET/CT report\ngeneration quality, advancing 3D medical vision-language understanding.",
      "pdf_url": "http://arxiv.org/pdf/2510.27680v1",
      "published": "2025-10-31T17:49:01+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.27680v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "MolChord: Structure-Sequence Alignment for Protein-Guided Drug Design",
      "authors": [
        "Wei Zhang",
        "Zekun Guo",
        "Yingce Xia",
        "Peiran Jin",
        "Shufang Xie",
        "Tao Qin",
        "Xiang-Yang Li"
      ],
      "abstract": "Structure-based drug design (SBDD), which maps target proteins to candidate\nmolecular ligands, is a fundamental task in drug discovery. Effectively\naligning protein structural representations with molecular representations, and\nensuring alignment between generated drugs and their pharmacological\nproperties, remains a critical challenge. To address these challenges, we\npropose MolChord, which integrates two key techniques: (1) to align protein and\nmolecule structures with their textual descriptions and sequential\nrepresentations (e.g., FASTA for proteins and SMILES for molecules), we\nleverage NatureLM, an autoregressive model unifying text, small molecules, and\nproteins, as the molecule generator, alongside a diffusion-based structure\nencoder; and (2) to guide molecules toward desired properties, we curate a\nproperty-aware dataset by integrating preference data and refine the alignment\nprocess using Direct Preference Optimization (DPO). Experimental results on\nCrossDocked2020 demonstrate that our approach achieves state-of-the-art\nperformance on key evaluation metrics, highlighting its potential as a\npractical tool for SBDD.",
      "pdf_url": "http://arxiv.org/pdf/2510.27671v1",
      "published": "2025-10-31T17:35:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.27671v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Challenges in Credit Assignment for Multi-Agent Reinforcement Learning in Open Agent Systems",
      "authors": [
        "Alireza Saleh Abadi",
        "Leen-Kiat Soh"
      ],
      "abstract": "In the rapidly evolving field of multi-agent reinforcement learning (MARL),\nunderstanding the dynamics of open systems is crucial. Openness in MARL refers\nto the dynam-ic nature of agent populations, tasks, and agent types with-in a\nsystem. Specifically, there are three types of openness as reported in (Eck et\nal. 2023) [2]: agent openness, where agents can enter or leave the system at\nany time; task openness, where new tasks emerge, and existing ones evolve or\ndisappear; and type openness, where the capabil-ities and behaviors of agents\nchange over time. This report provides a conceptual and empirical review,\nfocusing on the interplay between openness and the credit assignment problem\n(CAP). CAP involves determining the contribution of individual agents to the\noverall system performance, a task that becomes increasingly complex in open\nenviron-ments. Traditional credit assignment (CA) methods often assume static\nagent populations, fixed and pre-defined tasks, and stationary types, making\nthem inadequate for open systems. We first conduct a conceptual analysis,\nin-troducing new sub-categories of openness to detail how events like agent\nturnover or task cancellation break the assumptions of environmental\nstationarity and fixed team composition that underpin existing CAP methods. We\nthen present an empirical study using representative temporal and structural\nalgorithms in an open environment. The results demonstrate that openness\ndirectly causes credit misattribution, evidenced by unstable loss functions and\nsignificant performance degradation.",
      "pdf_url": "http://arxiv.org/pdf/2510.27659v1",
      "published": "2025-10-31T17:30:32+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.27659v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ]
    },
    {
      "title": "Community Detection on Model Explanation Graphs for Explainable AI",
      "authors": [
        "Ehsan Moradi"
      ],
      "abstract": "Feature-attribution methods (e.g., SHAP, LIME) explain individual predictions\nbut often miss higher-order structure: sets of features that act in concert. We\npropose Modules of Influence (MoI), a framework that (i) constructs a model\nexplanation graph from per-instance attributions, (ii) applies community\ndetection to find feature modules that jointly affect predictions, and (iii)\nquantifies how these modules relate to bias, redundancy, and causality\npatterns. Across synthetic and real datasets, MoI uncovers correlated feature\ngroups, improves model debugging via module-level ablations, and localizes bias\nexposure to specific modules. We release stability and synergy metrics, a\nreference implementation, and evaluation protocols to benchmark module\ndiscovery in XAI.",
      "pdf_url": "http://arxiv.org/pdf/2510.27655v1",
      "published": "2025-10-31T17:27:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.27655v1",
      "categories": [
        "cs.SI",
        "cs.AI"
      ]
    },
    {
      "title": "Information-Theoretic Greedy Layer-wise Training for Traffic Sign Recognition",
      "authors": [
        "Shuyan Lyu",
        "Zhanzimo Wu",
        "Junliang Du"
      ],
      "abstract": "Modern deep neural networks (DNNs) are typically trained with a global\ncross-entropy loss in a supervised end-to-end manner: neurons need to store\ntheir outgoing weights; training alternates between a forward pass\n(computation) and a top-down backward pass (learning) which is biologically\nimplausible. Alternatively, greedy layer-wise training eliminates the need for\ncross-entropy loss and backpropagation. By avoiding the computation of\nintermediate gradients and the storage of intermediate outputs, it reduces\nmemory usage and helps mitigate issues such as vanishing or exploding\ngradients. However, most existing layer-wise training approaches have been\nevaluated only on relatively small datasets with simple deep architectures. In\nthis paper, we first systematically analyze the training dynamics of popular\nconvolutional neural networks (CNNs) trained by stochastic gradient descent\n(SGD) through an information-theoretic lens. Our findings reveal that networks\nconverge layer-by-layer from bottom to top and that the flow of information\nadheres to a Markov information bottleneck principle. Building on these\nobservations, we propose a novel layer-wise training approach based on the\nrecently developed deterministic information bottleneck (DIB) and the\nmatrix-based R\\'enyi's $\\alpha$-order entropy functional. Specifically, each\nlayer is trained jointly with an auxiliary classifier that connects directly to\nthe output layer, enabling the learning of minimal sufficient task-relevant\nrepresentations. We empirically validate the effectiveness of our training\nprocedure on CIFAR-10 and CIFAR-100 using modern deep CNNs and further\ndemonstrate its applicability to a practical task involving traffic sign\nrecognition. Our approach not only outperforms existing layer-wise training\nbaselines but also achieves performance comparable to SGD.",
      "pdf_url": "http://arxiv.org/pdf/2510.27651v1",
      "published": "2025-10-31T17:24:58+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.27651v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "VessShape: Few-shot 2D blood vessel segmentation by leveraging shape priors from synthetic images",
      "authors": [
        "Cesar H. Comin",
        "Wesley N. Galvão"
      ],
      "abstract": "Semantic segmentation of blood vessels is an important task in medical image\nanalysis, but its progress is often hindered by the scarcity of large annotated\ndatasets and the poor generalization of models across different imaging\nmodalities. A key aspect is the tendency of Convolutional Neural Networks\n(CNNs) to learn texture-based features, which limits their performance when\napplied to new domains with different visual characteristics. We hypothesize\nthat leveraging geometric priors of vessel shapes, such as their tubular and\nbranching nature, can lead to more robust and data-efficient models. To\ninvestigate this, we introduce VessShape, a methodology for generating\nlarge-scale 2D synthetic datasets designed to instill a shape bias in\nsegmentation models. VessShape images contain procedurally generated tubular\ngeometries combined with a wide variety of foreground and background textures,\nencouraging models to learn shape cues rather than textures. We demonstrate\nthat a model pre-trained on VessShape images achieves strong few-shot\nsegmentation performance on two real-world datasets from different domains,\nrequiring only four to ten samples for fine-tuning. Furthermore, the model\nexhibits notable zero-shot capabilities, effectively segmenting vessels in\nunseen domains without any target-specific training. Our results indicate that\npre-training with a strong shape bias can be an effective strategy to overcome\ndata scarcity and improve model generalization in blood vessel segmentation.",
      "pdf_url": "http://arxiv.org/pdf/2510.27646v1",
      "published": "2025-10-31T17:19:33+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.27646v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Sketch-to-Layout: Sketch-Guided Multimodal Layout Generation",
      "authors": [
        "Riccardo Brioschi",
        "Aleksandr Alekseev",
        "Emanuele Nevali",
        "Berkay Döner",
        "Omar El Malki",
        "Blagoj Mitrevski",
        "Leandro Kieliger",
        "Mark Collier",
        "Andrii Maksai",
        "Jesse Berent",
        "Claudiu Musat",
        "Efi Kokiopoulou"
      ],
      "abstract": "Graphic layout generation is a growing research area focusing on generating\naesthetically pleasing layouts ranging from poster designs to documents. While\nrecent research has explored ways to incorporate user constraints to guide the\nlayout generation, these constraints often require complex specifications which\nreduce usability. We introduce an innovative approach exploiting user-provided\nsketches as intuitive constraints and we demonstrate empirically the\neffectiveness of this new guidance method, establishing the sketch-to-layout\nproblem as a promising research direction, which is currently under-explored.\nTo tackle the sketch-to-layout problem, we propose a multimodal\ntransformer-based solution using the sketch and the content assets as inputs to\nproduce high quality layouts. Since collecting sketch training data from human\nannotators to train our model is very costly, we introduce a novel and\nefficient method to synthetically generate training sketches at scale. We train\nand evaluate our model on three publicly available datasets: PubLayNet,\nDocLayNet and SlidesVQA, demonstrating that it outperforms state-of-the-art\nconstraint-based methods, while offering a more intuitive design experience. In\norder to facilitate future sketch-to-layout research, we release O(200k)\nsynthetically-generated sketches for the public datasets above. The datasets\nare available at https://github.com/google-deepmind/sketch_to_layout.",
      "pdf_url": "http://arxiv.org/pdf/2510.27632v1",
      "published": "2025-10-31T17:05:10+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.27632v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Interaction as Intelligence Part II: Asynchronous Human-Agent Rollout for Long-Horizon Task Training",
      "authors": [
        "Dayuan Fu",
        "Yunze Wu",
        "Xiaojie Cai",
        "Lyumanshan Ye",
        "Shijie Xia",
        "Zhen Huang",
        "Weiye Si",
        "Tianze Xu",
        "Jie Sun",
        "Keyu Li",
        "Mohan Jiang",
        "Junfei Wang",
        "Qishuo Hua",
        "Pengrui Lu",
        "Yang Xiao",
        "Pengfei Liu"
      ],
      "abstract": "Large Language Model (LLM) agents have recently shown strong potential in\ndomains such as automated coding, deep research, and graphical user interface\nmanipulation. However, training them to succeed on long-horizon,\ndomain-specialized tasks remains challenging. Current methods primarily fall\ninto two categories. The first relies on dense human annotations through\nbehavior cloning, which is prohibitively expensive for long-horizon tasks that\ncan take days or months. The second depends on outcome-driven sampling, which\noften collapses due to the rarity of valid positive trajectories on\ndomain-specialized tasks. We introduce Apollo, a sampling framework that\nintegrates asynchronous human guidance with action-level data filtering.\nInstead of requiring annotators to shadow every step, Apollo allows them to\nintervene only when the agent drifts from a promising trajectory, by providing\nprior knowledge, strategic advice, etc. This lightweight design makes it\npossible to sustain interactions for over 30 hours and produces valuable\ntrajectories at a lower cost. Apollo then applies supervision control to filter\nout sub-optimal actions and prevent error propagation. Together, these\ncomponents enable reliable and effective data collection in long-horizon\nenvironments. To demonstrate the effectiveness of Apollo, we evaluate it using\nInnovatorBench. Our experiments show that when applied to train the GLM-4.5\nmodel on InnovatorBench, Apollo achieves more than a 50% improvement over the\nuntrained baseline and a 28% improvement over a variant trained without human\ninteraction. These results highlight the critical role of human-in-the-loop\nsampling and the robustness of Apollo's design in handling long-horizon,\ndomain-specialized tasks.",
      "pdf_url": "http://arxiv.org/pdf/2510.27630v2",
      "published": "2025-10-31T17:00:22+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.27630v2",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Best Practices for Biorisk Evaluations on Open-Weight Bio-Foundation Models",
      "authors": [
        "Boyi Wei",
        "Zora Che",
        "Nathaniel Li",
        "Udari Madhushani Sehwag",
        "Jasper Götting",
        "Samira Nedungadi",
        "Julian Michael",
        "Summer Yue",
        "Dan Hendrycks",
        "Peter Henderson",
        "Zifan Wang",
        "Seth Donoughe",
        "Mantas Mazeika"
      ],
      "abstract": "Open-weight bio-foundation models present a dual-use dilemma. While holding\ngreat promise for accelerating scientific research and drug development, they\ncould also enable bad actors to develop more deadly bioweapons. To mitigate the\nrisk posed by these models, current approaches focus on filtering biohazardous\ndata during pre-training. However, the effectiveness of such an approach\nremains unclear, particularly against determined actors who might fine-tune\nthese models for malicious use. To address this gap, we propose \\eval, a\nframework to evaluate the robustness of procedures that are intended to reduce\nthe dual-use capabilities of bio-foundation models. \\eval assesses models'\nvirus understanding through three lenses, including sequence modeling,\nmutational effects prediction, and virulence prediction. Our results show that\ncurrent filtering practices may not be particularly effective: Excluded\nknowledge can be rapidly recovered in some cases via fine-tuning, and exhibits\nbroader generalizability in sequence modeling. Furthermore, dual-use signals\nmay already reside in the pretrained representations, and can be elicited via\nsimple linear probing. These findings highlight the challenges of data\nfiltering as a standalone procedure, underscoring the need for further research\ninto robust safety and security strategies for open-weight bio-foundation\nmodels.",
      "pdf_url": "http://arxiv.org/pdf/2510.27629v2",
      "published": "2025-10-31T17:00:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.27629v2",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "title": "Validity Is What You Need",
      "authors": [
        "Sebastian Benthall",
        "Andrew Clark"
      ],
      "abstract": "While AI agents have long been discussed and studied in computer science,\ntoday's Agentic AI systems are something new. We consider other definitions of\nAgentic AI and propose a new realist definition. Agentic AI is a software\ndelivery mechanism, comparable to software as a service (SaaS), which puts an\napplication to work autonomously in a complex enterprise setting. Recent\nadvances in large language models (LLMs) as foundation models have driven\nexcitement in Agentic AI. We note, however, that Agentic AI systems are\nprimarily applications, not foundations, and so their success depends on\nvalidation by end users and principal stakeholders. The tools and techniques\nneeded by the principal users to validate their applications are quite\ndifferent from the tools and techniques used to evaluate foundation models.\nIronically, with good validation measures in place, in many cases the\nfoundation models can be replaced with much simpler, faster, and more\ninterpretable models that handle core logic. When it comes to Agentic AI,\nvalidity is what you need. LLMs are one option that might achieve it.",
      "pdf_url": "http://arxiv.org/pdf/2510.27628v1",
      "published": "2025-10-31T17:00:04+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.27628v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Visual Backdoor Attacks on MLLM Embodied Decision Making via Contrastive Trigger Learning",
      "authors": [
        "Qiusi Zhan",
        "Hyeonjeong Ha",
        "Rui Yang",
        "Sirui Xu",
        "Hanyang Chen",
        "Liang-Yan Gui",
        "Yu-Xiong Wang",
        "Huan Zhang",
        "Heng Ji",
        "Daniel Kang"
      ],
      "abstract": "Multimodal large language models (MLLMs) have advanced embodied agents by\nenabling direct perception, reasoning, and planning task-oriented actions from\nvisual inputs. However, such vision driven embodied agents open a new attack\nsurface: visual backdoor attacks, where the agent behaves normally until a\nvisual trigger appears in the scene, then persistently executes an\nattacker-specified multi-step policy. We introduce BEAT, the first framework to\ninject such visual backdoors into MLLM-based embodied agents using objects in\nthe environments as triggers. Unlike textual triggers, object triggers exhibit\nwide variation across viewpoints and lighting, making them difficult to implant\nreliably. BEAT addresses this challenge by (1) constructing a training set that\nspans diverse scenes, tasks, and trigger placements to expose agents to trigger\nvariability, and (2) introducing a two-stage training scheme that first applies\nsupervised fine-tuning (SFT) and then our novel Contrastive Trigger Learning\n(CTL). CTL formulates trigger discrimination as preference learning between\ntrigger-present and trigger-free inputs, explicitly sharpening the decision\nboundaries to ensure precise backdoor activation. Across various embodied agent\nbenchmarks and MLLMs, BEAT achieves attack success rates up to 80%, while\nmaintaining strong benign task performance, and generalizes reliably to\nout-of-distribution trigger placements. Notably, compared to naive SFT, CTL\nboosts backdoor activation accuracy up to 39% under limited backdoor data.\nThese findings expose a critical yet unexplored security risk in MLLM-based\nembodied agents, underscoring the need for robust defenses before real-world\ndeployment.",
      "pdf_url": "http://arxiv.org/pdf/2510.27623v1",
      "published": "2025-10-31T16:50:49+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.27623v1",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ]
    },
    {
      "title": "VeriMoA: A Mixture-of-Agents Framework for Spec-to-HDL Generation",
      "authors": [
        "Heng Ping",
        "Arijit Bhattacharjee",
        "Peiyu Zhang",
        "Shixuan Li",
        "Wei Yang",
        "Anzhe Cheng",
        "Xiaole Zhang",
        "Jesse Thomason",
        "Ali Jannesari",
        "Nesreen Ahmed",
        "Paul Bogdan"
      ],
      "abstract": "Automation of Register Transfer Level (RTL) design can help developers meet\nincreasing computational demands. Large Language Models (LLMs) show promise for\nHardware Description Language (HDL) generation, but face challenges due to\nlimited parametric knowledge and domain-specific constraints. While prompt\nengineering and fine-tuning have limitations in knowledge coverage and training\ncosts, multi-agent architectures offer a training-free paradigm to enhance\nreasoning through collaborative generation. However, current multi-agent\napproaches suffer from two critical deficiencies: susceptibility to noise\npropagation and constrained reasoning space exploration. We propose VeriMoA, a\ntraining-free mixture-of-agents (MoA) framework with two synergistic\ninnovations. First, a quality-guided caching mechanism to maintain all\nintermediate HDL outputs and enables quality-based ranking and selection across\nthe entire generation process, encouraging knowledge accumulation over layers\nof reasoning. Second, a multi-path generation strategy that leverages C++ and\nPython as intermediate representations, decomposing specification-to-HDL\ntranslation into two-stage processes that exploit LLM fluency in high-resource\nlanguages while promoting solution diversity. Comprehensive experiments on\nVerilogEval 2.0 and RTLLM 2.0 benchmarks demonstrate that VeriMoA achieves\n15--30% improvements in Pass@1 across diverse LLM backbones, especially\nenabling smaller models to match larger models and fine-tuned alternatives\nwithout requiring costly training.",
      "pdf_url": "http://arxiv.org/pdf/2510.27617v1",
      "published": "2025-10-31T16:40:58+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.27617v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Spatial-SSRL: Enhancing Spatial Understanding via Self-Supervised Reinforcement Learning",
      "authors": [
        "Yuhong Liu",
        "Beichen Zhang",
        "Yuhang Zang",
        "Yuhang Cao",
        "Long Xing",
        "Xiaoyi Dong",
        "Haodong Duan",
        "Dahua Lin",
        "Jiaqi Wang"
      ],
      "abstract": "Spatial understanding remains a weakness of Large Vision-Language Models\n(LVLMs). Existing supervised fine-tuning (SFT) and recent reinforcement\nlearning with verifiable rewards (RLVR) pipelines depend on costly supervision,\nspecialized tools, or constrained environments that limit scale. We introduce\nSpatial-SSRL, a self-supervised RL paradigm that derives verifiable signals\ndirectly from ordinary RGB or RGB-D images. Spatial-SSRL automatically\nformulates five pretext tasks that capture 2D and 3D spatial structure:\nshuffled patch reordering, flipped patch recognition, cropped patch inpainting,\nregional depth ordering, and relative 3D position prediction. These tasks\nprovide ground-truth answers that are easy to verify and require no human or\nLVLM annotation. Training on our tasks substantially improves spatial reasoning\nwhile preserving general visual capabilities. On seven spatial understanding\nbenchmarks in both image and video settings, Spatial-SSRL delivers average\naccuracy gains of 4.63% (3B) and 3.89% (7B) over the Qwen2.5-VL baselines. Our\nresults show that simple, intrinsic supervision enables RLVR at scale and\nprovides a practical route to stronger spatial intelligence in LVLMs.",
      "pdf_url": "http://arxiv.org/pdf/2510.27606v1",
      "published": "2025-10-31T16:30:08+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.27606v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "InnovatorBench: Evaluating Agents' Ability to Conduct Innovative LLM Research",
      "authors": [
        "Yunze Wu",
        "Dayuan Fu",
        "Weiye Si",
        "Zhen Huang",
        "Mohan Jiang",
        "Keyu Li",
        "Shijie Xia",
        "Jie Sun",
        "Tianze Xu",
        "Xiangkun Hu",
        "Pengrui Lu",
        "Xiaojie Cai",
        "Lyumanshan Ye",
        "Wenhong Zhu",
        "Yang Xiao",
        "Pengfei Liu"
      ],
      "abstract": "AI agents could accelerate scientific discovery by automating hypothesis\nformation, experiment design, coding, execution, and analysis, yet existing\nbenchmarks probe narrow skills in simplified settings. To address this gap, we\nintroduce InnovatorBench, a benchmark-platform pair for realistic, end-to-end\nassessment of agents performing Large Language Model (LLM) research. It\ncomprises 20 tasks spanning Data Construction, Filtering, Augmentation, Loss\nDesign, Reward Design, and Scaffold Construction, which require runnable\nartifacts and assessment of correctness, performance, output quality, and\nuncertainty. To support agent operation, we develop ResearchGym, a research\nenvironment offering rich action spaces, distributed and long-horizon\nexecution, asynchronous monitoring, and snapshot saving. We also implement a\nlightweight ReAct agent that couples explicit reasoning with executable\nplanning using frontier models such as Claude-4, GPT-5, GLM-4.5, and Kimi-K2.\nOur experiments demonstrate that while frontier models show promise in\ncode-driven research tasks, they struggle with fragile algorithm-related tasks\nand long-horizon decision making, such as impatience, poor resource management,\nand overreliance on template-based reasoning. Furthermore, agents require over\n11 hours to achieve their best performance on InnovatorBench, underscoring the\nbenchmark's difficulty and showing the potential of InnovatorBench to be the\nnext generation of code-based research benchmark.",
      "pdf_url": "http://arxiv.org/pdf/2510.27598v2",
      "published": "2025-10-31T16:22:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.27598v2",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Towards Universal Video Retrieval: Generalizing Video Embedding via Synthesized Multimodal Pyramid Curriculum",
      "authors": [
        "Zhuoning Guo",
        "Mingxin Li",
        "Yanzhao Zhang",
        "Dingkun Long",
        "Pengjun Xie",
        "Xiaowen Chu"
      ],
      "abstract": "The prevailing video retrieval paradigm is structurally misaligned, as narrow\nbenchmarks incentivize correspondingly limited data and single-task training.\nTherefore, universal capability is suppressed due to the absence of a\ndiagnostic evaluation that defines and demands multi-dimensional\ngeneralization. To break this cycle, we introduce a framework built on the\nco-design of evaluation, data, and modeling. First, we establish the Universal\nVideo Retrieval Benchmark (UVRB), a suite of 16 datasets designed not only to\nmeasure performance but also to diagnose critical capability gaps across tasks\nand domains. Second, guided by UVRB's diagnostics, we introduce a scalable\nsynthesis workflow that generates 1.55 million high-quality pairs to populate\nthe semantic space required for universality. Finally, we devise the Modality\nPyramid, a curriculum that trains our General Video Embedder (GVE) by\nexplicitly leveraging the latent interconnections within our diverse data.\nExtensive experiments show GVE achieves state-of-the-art zero-shot\ngeneralization on UVRB. In particular, our analysis reveals that popular\nbenchmarks are poor predictors of general ability and that partially relevant\nretrieval is a dominant but overlooked scenario. Overall, our co-designed\nframework provides a practical path to escape the limited scope and advance\ntoward truly universal video retrieval.",
      "pdf_url": "http://arxiv.org/pdf/2510.27571v1",
      "published": "2025-10-31T15:54:48+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.27571v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.IR",
        "cs.LG"
      ]
    },
    {
      "title": "SIGMA: Search-Augmented On-Demand Knowledge Integration for Agentic Mathematical Reasoning",
      "authors": [
        "Ali Asgarov",
        "Umid Suleymanov",
        "Aadyant Khatri"
      ],
      "abstract": "Solving mathematical reasoning problems requires not only accurate access to\nrelevant knowledge but also careful, multi-step thinking. However, current\nretrieval-augmented models often rely on a single perspective, follow\ninflexible search strategies, and struggle to effectively combine information\nfrom multiple sources. We introduce SIGMA (Search-Augmented On-Demand Knowledge\nIntegration for AGentic Mathematical reAsoning), a unified framework that\norchestrates specialized agents to independently reason, perform targeted\nsearches, and synthesize findings through a moderator mechanism. Each agent\ngenerates hypothetical passages to optimize retrieval for its analytic\nperspective, ensuring knowledge integration is both context-sensitive and\ncomputation-efficient. When evaluated on challenging benchmarks such as\nMATH500, AIME, and PhD-level science QA GPQA, SIGMA consistently outperforms\nboth open- and closed-source systems, achieving an absolute performance\nimprovement of 7.4%. Our results demonstrate that multi-agent, on-demand\nknowledge integration significantly enhances both reasoning accuracy and\nefficiency, offering a scalable approach for complex, knowledge-intensive\nproblem-solving. We will release the code upon publication.",
      "pdf_url": "http://arxiv.org/pdf/2510.27568v1",
      "published": "2025-10-31T15:51:00+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.27568v1",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "CodeAlignBench: Assessing Code Generation Models on Developer-Preferred Code Adjustments",
      "authors": [
        "Forough Mehralian",
        "Ryan Shar",
        "James R. Rae",
        "Alireza Hashemi"
      ],
      "abstract": "As large language models become increasingly capable of generating code,\nevaluating their performance remains a complex and evolving challenge. Existing\nbenchmarks primarily focus on functional correctness, overlooking the diversity\nof real-world coding tasks and developer expectations. To this end, we\nintroduce a multi-language benchmark that evaluates LLM instruction-following\ncapabilities and is extensible to operate on any set of standalone coding\nproblems. Our benchmark evaluates instruction following in two key settings:\nadherence to pre-defined constraints specified with the initial problem, and\nthe ability to perform refinements based on follow-up instructions. For this\npaper's analysis, we empirically evaluated our benchmarking pipeline with\nprogramming tasks from LiveBench, that are also automatically translated from\nPython into Java and JavaScript. Our automated benchmark reveals that models\nexhibit differing levels of performance across multiple dimensions of\ninstruction-following. Our benchmarking pipeline provides a more comprehensive\nevaluation of code generation models, highlighting their strengths and\nlimitations across languages and generation goals.",
      "pdf_url": "http://arxiv.org/pdf/2510.27565v1",
      "published": "2025-10-31T15:47:07+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.27565v1",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.HC"
      ]
    },
    {
      "title": "Toward Accurate Long-Horizon Robotic Manipulation: Language-to-Action with Foundation Models via Scene Graphs",
      "authors": [
        "Sushil Samuel Dinesh",
        "Shinkyu Park"
      ],
      "abstract": "This paper presents a framework that leverages pre-trained foundation models\nfor robotic manipulation without domain-specific training. The framework\nintegrates off-the-shelf models, combining multimodal perception from\nfoundation models with a general-purpose reasoning model capable of robust task\nsequencing. Scene graphs, dynamically maintained within the framework, provide\nspatial awareness and enable consistent reasoning about the environment. The\nframework is evaluated through a series of tabletop robotic manipulation\nexperiments, and the results highlight its potential for building robotic\nmanipulation systems directly on top of off-the-shelf foundation models.",
      "pdf_url": "http://arxiv.org/pdf/2510.27558v1",
      "published": "2025-10-31T15:42:32+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.27558v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Sybil-Resistant Service Discovery for Agent Economies",
      "authors": [
        "David Shi",
        "Kevin Joo"
      ],
      "abstract": "x402 enables Hypertext Transfer Protocol (HTTP) services like application\nprogramming interfaces (APIs), data feeds, and inference providers to accept\ncryptocurrency payments for access. As agents increasingly consume these\nservices, discovery becomes critical: which swap interface should an agent\ntrust? Which data provider is the most reliable? We introduce TraceRank, a\nreputation-weighted ranking algorithm where payment transactions serve as\nendorsements. TraceRank seeds addresses with precomputed reputation metrics and\npropagates reputation through payment flows weighted by transaction value and\ntemporal recency. Applied to x402's payment graph, this surfaces services\npreferred by high-reputation users rather than those with high transaction\nvolume. Our system combines TraceRank with semantic search to respond to\nnatural language queries with high quality results. We argue that reputation\npropagation resists Sybil attacks by making spam services with many\nlow-reputation payers rank below legitimate services with few high-reputation\npayers. Ultimately, we aim to construct a search method for x402 enabled\nservices that avoids infrastructure bias and has better performance than purely\nvolume based or semantic methods.",
      "pdf_url": "http://arxiv.org/pdf/2510.27554v1",
      "published": "2025-10-31T15:29:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.27554v1",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.SI",
        "68T42, 68R10, 68M14, 68P20, 91D30",
        "H.3.3; H.2.8; I.2.11; K.4.4; G.2.2; C.2.4"
      ]
    },
    {
      "title": "EBT-Policy: Energy Unlocks Emergent Physical Reasoning Capabilities",
      "authors": [
        "Travis Davies",
        "Yiqi Huang",
        "Alexi Gladstone",
        "Yunxin Liu",
        "Xiang Chen",
        "Heng Ji",
        "Huxian Liu",
        "Luhui Hu"
      ],
      "abstract": "Implicit policies parameterized by generative models, such as Diffusion\nPolicy, have become the standard for policy learning and Vision-Language-Action\n(VLA) models in robotics. However, these approaches often suffer from high\ncomputational cost, exposure bias, and unstable inference dynamics, which lead\nto divergence under distribution shifts. Energy-Based Models (EBMs) address\nthese issues by learning energy landscapes end-to-end and modeling equilibrium\ndynamics, offering improved robustness and reduced exposure bias. Yet, policies\nparameterized by EBMs have historically struggled to scale effectively. Recent\nwork on Energy-Based Transformers (EBTs) demonstrates the scalability of EBMs\nto high-dimensional spaces, but their potential for solving core challenges in\nphysically embodied models remains underexplored. We introduce a new\nenergy-based architecture, EBT-Policy, that solves core issues in robotic and\nreal-world settings. Across simulated and real-world tasks, EBT-Policy\nconsistently outperforms diffusion-based policies, while requiring less\ntraining and inference computation. Remarkably, on some tasks it converges\nwithin just two inference steps, a 50x reduction compared to Diffusion Policy's\n100. Moreover, EBT-Policy exhibits emergent capabilities not seen in prior\nmodels, such as zero-shot recovery from failed action sequences using only\nbehavior cloning and without explicit retry training. By leveraging its scalar\nenergy for uncertainty-aware inference and dynamic compute allocation,\nEBT-Policy offers a promising path toward robust, generalizable robot behavior\nunder distribution shifts.",
      "pdf_url": "http://arxiv.org/pdf/2510.27545v1",
      "published": "2025-10-31T15:21:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.27545v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "Mechanics of Learned Reasoning 1: TempoBench, A Benchmark for Interpretable Deconstruction of Reasoning System Performance",
      "authors": [
        "Nikolaus Holzer",
        "William Fishell",
        "Baishakhi Ray",
        "Mark Santolucito"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly excelling and outpacing human\nperformance on many tasks. However, to improve LLM reasoning, researchers\neither rely on ad-hoc generated datasets or formal mathematical proof systems\nsuch as the Lean proof assistant. Whilst ad-hoc generated methods can capture\nthe decision chains of real-world reasoning processes, they may encode some\ninadvertent bias in the space of reasoning they cover; they also cannot be\nformally verified. On the other hand, systems like Lean can guarantee\nverifiability, but are not well-suited to capture the nature of agentic\ndecision chain-based tasks. This creates a gap both in performance for\nfunctions such as business agents or code assistants, and in the usefulness of\nLLM reasoning benchmarks, whereby these fall short in reasoning structure or\nreal-world alignment. We introduce TempoBench, the first formally grounded and\nverifiable diagnostic benchmark that parametrizes difficulty to systematically\nanalyze how LLMs perform reasoning. TempoBench uses two evaluation benchmarks\nto break down reasoning ability. First, temporal trace evaluation (TTE) tests\nthe ability of an LLM to understand and simulate the execution of a given\nmulti-step reasoning system. Subsequently, temporal causal evaluation (TCE)\ntests an LLM's ability to perform multi-step causal reasoning and to distill\ncause-and-effect relations from complex systems. We find that models score\n65.6% on TCE-normal, and 7.5% on TCE-hard. This shows that state-of-the-art\nLLMs clearly understand the TCE task but perform poorly as system complexity\nincreases. Our code is available at our\n\\href{https://github.com/nik-hz/tempobench}{GitHub repository}.",
      "pdf_url": "http://arxiv.org/pdf/2510.27544v1",
      "published": "2025-10-31T15:17:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.27544v1",
      "categories": [
        "cs.AI",
        "cs.FL"
      ]
    },
    {
      "title": "DialectalArabicMMLU: Benchmarking Dialectal Capabilities in Arabic and Multilingual Language Models",
      "authors": [
        "Malik H. Altakrori",
        "Nizar Habash",
        "Abdelhakim Freihat",
        "Younes Samih",
        "Kirill Chirkunov",
        "Muhammed AbuOdeh",
        "Radu Florian",
        "Teresa Lynn",
        "Preslav Nakov",
        "Alham Fikri Aji"
      ],
      "abstract": "We present DialectalArabicMMLU, a new benchmark for evaluating the\nperformance of large language models (LLMs) across Arabic dialects. While\nrecently developed Arabic and multilingual benchmarks have advanced LLM\nevaluation for Modern Standard Arabic (MSA), dialectal varieties remain\nunderrepresented despite their prevalence in everyday communication.\nDialectalArabicMMLU extends the MMLU-Redux framework through manual translation\nand adaptation of 3K multiple-choice question-answer pairs into five major\ndialects (Syrian, Egyptian, Emirati, Saudi, and Moroccan), yielding a total of\n15K QA pairs across 32 academic and professional domains (22K QA pairs when\nalso including English and MSA). The benchmark enables systematic assessment of\nLLM reasoning and comprehension beyond MSA, supporting both task-based and\nlinguistic analysis. We evaluate 19 open-weight Arabic and multilingual LLMs\n(1B-13B parameters) and report substantial performance variation across\ndialects, revealing persistent gaps in dialectal generalization.\nDialectalArabicMMLU provides the first unified, human-curated resource for\nmeasuring dialectal understanding in Arabic, thus promoting more inclusive\nevaluation and future model development.",
      "pdf_url": "http://arxiv.org/pdf/2510.27543v1",
      "published": "2025-10-31T15:17:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.27543v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "TetraJet-v2: Accurate NVFP4 Training for Large Language Models with Oscillation Suppression and Outlier Control",
      "authors": [
        "Yuxiang Chen",
        "Xiaoming Xu",
        "Pengle Zhang",
        "Michael Beyer",
        "Martin Rapp",
        "Jun Zhu",
        "Jianfei Chen"
      ],
      "abstract": "Large Language Models (LLMs) training is prohibitively expensive, driving\ninterest in low-precision fully-quantized training (FQT). While novel 4-bit\nformats like NVFP4 offer substantial efficiency gains, achieving near-lossless\ntraining at such low precision remains challenging. We introduce TetraJet-v2,\nan end-to-end 4-bit FQT method that leverages NVFP4 for activations, weights,\nand gradients in all linear layers. We identify two critical issues hindering\nlow-precision LLM training: weight oscillation and outliers. To address these,\nwe propose: 1) an unbiased double-block quantization method for NVFP4 linear\nlayers, 2) OsciReset, an algorithm to suppress weight oscillation, and 3)\nOutControl, an algorithm to retain outlier accuracy. TetraJet-v2 consistently\noutperforms prior FP4 training methods on pre-training LLMs across varying\nmodel sizes up to 370M and data sizes up to 200B tokens, reducing the\nperformance gap to full-precision training by an average of 51.3%.",
      "pdf_url": "http://arxiv.org/pdf/2510.27527v1",
      "published": "2025-10-31T14:57:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.27527v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Leveraging Generic Time Series Foundation Models for EEG Classification",
      "authors": [
        "Théo Gnassounou",
        "Yessin Moakher",
        "Shifeng Xie",
        "Vasilii Feofanov",
        "Ievgen Redko"
      ],
      "abstract": "Foundation models for time series are emerging as powerful general-purpose\nbackbones, yet their potential for domain-specific biomedical signals such as\nelectroencephalography (EEG) remains rather unexplored. In this work, we\ninvestigate the applicability a recently proposed time series classification\nfoundation model, to a different EEG tasks such as motor imagery classification\nand sleep stage prediction. We test two pretraining regimes: (a) pretraining on\nheterogeneous real-world time series from multiple domains, and (b) pretraining\non purely synthetic data. We find that both variants yield strong performance,\nconsistently outperforming EEGNet, a widely used convolutional baseline, and\nCBraMod, the most recent EEG-specific foundation model. These results suggest\nthat generalist time series foundation models, even when pretrained on data of\nnon-neural origin or on synthetic signals, can transfer effectively to EEG. Our\nfindings highlight the promise of leveraging cross-domain pretrained models for\nbrain signal analysis, suggesting that EEG may benefit from advances in the\nbroader time series literature.",
      "pdf_url": "http://arxiv.org/pdf/2510.27522v1",
      "published": "2025-10-31T14:49:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.27522v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Context-Gated Cross-Modal Perception with Visual Mamba for PET-CT Lung Tumor Segmentation",
      "authors": [
        "Elena Mulero Ayllón",
        "Linlin Shen",
        "Pierangelo Veltri",
        "Fabrizia Gelardi",
        "Arturo Chiti",
        "Paolo Soda",
        "Matteo Tortora"
      ],
      "abstract": "Accurate lung tumor segmentation is vital for improving diagnosis and\ntreatment planning, and effectively combining anatomical and functional\ninformation from PET and CT remains a major challenge. In this study, we\npropose vMambaX, a lightweight multimodal framework integrating PET and CT scan\nimages through a Context-Gated Cross-Modal Perception Module (CGM). Built on\nthe Visual Mamba architecture, vMambaX adaptively enhances inter-modality\nfeature interaction, emphasizing informative regions while suppressing noise.\nEvaluated on the PCLT20K dataset, the model outperforms baseline models while\nmaintaining lower computational complexity. These results highlight the\neffectiveness of adaptive cross-modal gating for multimodal tumor segmentation\nand demonstrate the potential of vMambaX as an efficient and scalable framework\nfor advanced lung cancer analysis. The code is available at\nhttps://github.com/arco-group/vMambaX.",
      "pdf_url": "http://arxiv.org/pdf/2510.27508v1",
      "published": "2025-10-31T14:29:52+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.27508v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "DP-FedPGN: Finding Global Flat Minima for Differentially Private Federated Learning via Penalizing Gradient Norm",
      "authors": [
        "Junkang Liu",
        "Yuxuan Tian",
        "Fanhua Shang",
        "Yuanyuan Liu",
        "Hongying Liu",
        "Junchao Zhou",
        "Daorui Ding"
      ],
      "abstract": "To prevent inference attacks in Federated Learning (FL) and reduce the\nleakage of sensitive information, Client-level Differentially Private Federated\nLearning (CL-DPFL) is widely used. However, current CL-DPFL methods usually\nresult in sharper loss landscapes, which leads to a decrease in model\ngeneralization after differential privacy protection. By using Sharpness Aware\nMinimization (SAM), the current popular federated learning methods are to find\na local flat minimum value to alleviate this problem. However, the local\nflatness may not reflect the global flatness in CL-DPFL. Therefore, to address\nthis issue and seek global flat minima of models, we propose a new CL-DPFL\nalgorithm, DP-FedPGN, in which we introduce a global gradient norm penalty to\nthe local loss to find the global flat minimum. Moreover, by using our global\ngradient norm penalty, we not only find a flatter global minimum but also\nreduce the locally updated norm, which means that we further reduce the error\nof gradient clipping. From a theoretical perspective, we analyze how DP-FedPGN\nmitigates the performance degradation caused by DP. Meanwhile, the proposed\nDP-FedPGN algorithm eliminates the impact of data heterogeneity and achieves\nfast convergence. We also use R\\'enyi DP to provide strict privacy guarantees\nand provide sensitivity analysis for local updates. Finally, we conduct\neffectiveness tests on both ResNet and Transformer models, and achieve\nsignificant improvements in six visual and natural language processing tasks\ncompared to existing state-of-the-art algorithms. The code is available at\nhttps://github.com/junkangLiu0/DP-FedPGN",
      "pdf_url": "http://arxiv.org/pdf/2510.27504v1",
      "published": "2025-10-31T14:28:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.27504v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "InertialAR: Autoregressive 3D Molecule Generation with Inertial Frames",
      "authors": [
        "Haorui Li",
        "Weitao Du",
        "Yuqiang Li",
        "Hongyu Guo",
        "Shengchao Liu"
      ],
      "abstract": "Transformer-based autoregressive models have emerged as a unifying paradigm\nacross modalities such as text and images, but their extension to 3D molecule\ngeneration remains underexplored. The gap stems from two fundamental\nchallenges: (1) tokenizing molecules into a canonical 1D sequence of tokens\nthat is invariant to both SE(3) transformations and atom index permutations,\nand (2) designing an architecture capable of modeling hybrid atom-based tokens\nthat couple discrete atom types with continuous 3D coordinates. To address\nthese challenges, we introduce InertialAR. InertialAR devises a canonical\ntokenization that aligns molecules to their inertial frames and reorders atoms\nto ensure SE(3) and permutation invariance. Moreover, InertialAR equips the\nattention mechanism with geometric awareness via geometric rotary positional\nencoding (GeoRoPE). In addition, it utilizes a hierarchical autoregressive\nparadigm to predict the next atom-based token, predicting the atom type first\nand then its 3D coordinates via Diffusion loss. Experimentally, InertialAR\nachieves state-of-the-art performance on 7 of the 10 evaluation metrics for\nunconditional molecule generation across QM9, GEOM-Drugs, and B3LYP. Moreover,\nit significantly outperforms strong baselines in controllable generation for\ntargeted chemical functionality, attaining state-of-the-art results across all\n5 metrics.",
      "pdf_url": "http://arxiv.org/pdf/2510.27497v1",
      "published": "2025-10-31T14:19:50+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.27497v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "FedAdamW: A Communication-Efficient Optimizer with Convergence and Generalization Guarantees for Federated Large Models",
      "authors": [
        "Junkang Liu",
        "Fanhua Shang",
        "Kewen Zhu",
        "Hongying Liu",
        "Yuanyuan Liu",
        "Jin Liu"
      ],
      "abstract": "AdamW has become one of the most effective optimizers for training\nlarge-scale models. We have also observed its effectiveness in the context of\nfederated learning (FL). However, directly applying AdamW in federated learning\nsettings poses significant challenges: (1) due to data heterogeneity, AdamW\noften yields high variance in the second-moment estimate $\\boldsymbol{v}$; (2)\nthe local overfitting of AdamW may cause client drift; and (3) Reinitializing\nmoment estimates ($\\boldsymbol{v}$, $\\boldsymbol{m}$) at each round slows down\nconvergence. To address these challenges, we propose the first\n\\underline{Fed}erated \\underline{AdamW} algorithm, called \\texttt{FedAdamW},\nfor training and fine-tuning various large models. \\texttt{FedAdamW} aligns\nlocal updates with the global update using both a \\textbf{local correction\nmechanism} and decoupled weight decay to mitigate local overfitting.\n\\texttt{FedAdamW} efficiently aggregates the \\texttt{mean} of the second-moment\nestimates to reduce their variance and reinitialize them. Theoretically, we\nprove that \\texttt{FedAdamW} achieves a linear speedup convergence rate of\n$\\mathcal{O}(\\sqrt{(L \\Delta \\sigma_l^2)/(S K R \\epsilon^2)}+(L \\Delta)/R)$\nwithout \\textbf{heterogeneity assumption}, where $S$ is the number of\nparticipating clients per round, $K$ is the number of local iterations, and $R$\nis the total number of communication rounds. We also employ PAC-Bayesian\ngeneralization analysis to explain the effectiveness of decoupled weight decay\nin local training. Empirically, we validate the effectiveness of\n\\texttt{FedAdamW} on language and vision Transformer models. Compared to\nseveral baselines, \\texttt{FedAdamW} significantly reduces communication rounds\nand improves test accuracy. The code is available in\nhttps://github.com/junkangLiu0/FedAdamW.",
      "pdf_url": "http://arxiv.org/pdf/2510.27486v1",
      "published": "2025-10-31T14:04:43+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.27486v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Thought Branches: Interpreting LLM Reasoning Requires Resampling",
      "authors": [
        "Uzay Macar",
        "Paul C. Bogdan",
        "Senthooran Rajamanoharan",
        "Neel Nanda"
      ],
      "abstract": "Most work interpreting reasoning models studies only a single\nchain-of-thought (CoT), yet these models define distributions over many\npossible CoTs. We argue that studying a single sample is inadequate for\nunderstanding causal influence and the underlying computation. Though fully\nspecifying this distribution is intractable, it can be understood by sampling.\nWe present case studies using resampling to investigate model decisions. First,\nwhen a model states a reason for its action, does that reason actually cause\nthe action? In \"agentic misalignment\" scenarios, we resample specific sentences\nto measure their downstream effects. Self-preservation sentences have small\ncausal impact, suggesting they do not meaningfully drive blackmail. Second, are\nartificial edits to CoT sufficient for steering reasoning? These are common in\nliterature, yet take the model off-policy. Resampling and selecting a\ncompletion with the desired property is a principled on-policy alternative. We\nfind off-policy interventions yield small and unstable effects compared to\nresampling in decision-making tasks. Third, how do we understand the effect of\nremoving a reasoning step when the model may repeat it post-edit? We introduce\na resilience metric that repeatedly resamples to prevent similar content from\nreappearing downstream. Critical planning statements resist removal but have\nlarge effects when eliminated. Fourth, since CoT is sometimes \"unfaithful\", can\nour methods teach us anything in these settings? Adapting causal mediation\nanalysis, we find that hints that have a causal effect on the output without\nbeing explicitly mentioned exert a subtle and cumulative influence on the CoT\nthat persists even if the hint is removed. Overall, studying distributions via\nresampling enables reliable causal analysis, clearer narratives of model\nreasoning, and principled CoT interventions.",
      "pdf_url": "http://arxiv.org/pdf/2510.27484v1",
      "published": "2025-10-31T14:02:37+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.27484v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "VCORE: Variance-Controlled Optimization-based Reweighting for Chain-of-Thought Supervision",
      "authors": [
        "Xuan Gong",
        "Senmiao Wang",
        "Hanbo Huang",
        "Ruoyu Sun",
        "Shiyu Liang"
      ],
      "abstract": "Supervised fine-tuning (SFT) on long chain-of-thought (CoT) trajectories has\nemerged as a crucial technique for enhancing the reasoning abilities of large\nlanguage models (LLMs). However, the standard cross-entropy loss treats all\ntokens equally, ignoring their heterogeneous contributions across a reasoning\ntrajectory. This uniform treatment leads to misallocated supervision and weak\ngeneralization, especially in complex, long-form reasoning tasks. To address\nthis, we introduce \\textbf{V}ariance-\\textbf{C}ontrolled\n\\textbf{O}ptimization-based \\textbf{RE}weighting (VCORE), a principled\nframework that reformulates CoT supervision as a constrained optimization\nproblem. By adopting an optimization-theoretic perspective, VCORE enables a\nprincipled and adaptive allocation of supervision across tokens, thereby\naligning the training objective more closely with the goal of robust reasoning\ngeneralization. Empirical evaluations demonstrate that VCORE consistently\noutperforms existing token reweighting methods. Across both in-domain and\nout-of-domain settings, VCORE achieves substantial performance gains on\nmathematical and coding benchmarks, using models from the Qwen3 series (4B, 8B,\n32B) and LLaMA-3.1-8B-Instruct. Moreover, we show that VCORE serves as a more\neffective initialization for subsequent reinforcement learning, establishing a\nstronger foundation for advancing the reasoning capabilities of LLMs. The Code\nwill be released at https://github.com/coder-gx/VCORE.",
      "pdf_url": "http://arxiv.org/pdf/2510.27462v1",
      "published": "2025-10-31T13:19:24+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.27462v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "GeoFM: Enhancing Geometric Reasoning of MLLMs via Synthetic Data Generation through Formal Language",
      "authors": [
        "Yuhao Zhang",
        "Dingxin Hu",
        "Tinghao Yu",
        "Hao Liu",
        "Yiting Liu"
      ],
      "abstract": "Multi-modal Large Language Models (MLLMs) have gained significant attention\nin both academia and industry for their capabilities in handling multi-modal\ntasks. However, these models face challenges in mathematical geometric\nreasoning due to the scarcity of high-quality geometric data. To address this\nissue, synthetic geometric data has become an essential strategy. Current\nmethods for generating synthetic geometric data involve rephrasing or expanding\nexisting problems and utilizing predefined rules and templates to create\ngeometric images and problems. However, these approaches often produce data\nthat lacks diversity or is prone to noise. Additionally, the geometric images\nsynthesized by existing methods tend to exhibit limited variation and deviate\nsignificantly from authentic geometric diagrams. To overcome these limitations,\nwe propose GeoFM, a novel method for synthesizing geometric data. GeoFM uses\nformal languages to explore combinations of conditions within metric space,\ngenerating high-fidelity geometric problems that differ from the originals\nwhile ensuring correctness through a symbolic engine. Experimental results show\nthat our synthetic data significantly outperforms existing methods. The model\ntrained with our data surpass the proprietary GPT-4o model by 18.7\\% on\ngeometry problem-solving tasks in MathVista and by 16.5\\% on GeoQA.\nAdditionally, it exceeds the performance of a leading open-source model by\n5.7\\% on MathVista and by 2.7\\% on GeoQA.",
      "pdf_url": "http://arxiv.org/pdf/2510.27448v1",
      "published": "2025-10-31T12:56:32+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.27448v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "CoMViT: An Efficient Vision Backbone for Supervised Classification in Medical Imaging",
      "authors": [
        "Aon Safdar",
        "Mohamed Saadeldin"
      ],
      "abstract": "Vision Transformers (ViTs) have demonstrated strong potential in medical\nimaging; however, their high computational demands and tendency to overfit on\nsmall datasets limit their applicability in real-world clinical scenarios. In\nthis paper, we present CoMViT, a compact and generalizable Vision Transformer\narchitecture optimized for resource-constrained medical image analysis. CoMViT\nintegrates a convolutional tokenizer, diagonal masking, dynamic temperature\nscaling, and pooling-based sequence aggregation to improve performance and\ngeneralization. Through systematic architectural optimization, CoMViT achieves\nrobust performance across twelve MedMNIST datasets while maintaining a\nlightweight design with only ~4.5M parameters. It matches or outperforms deeper\nCNN and ViT variants, offering up to 5-20x parameter reduction without\nsacrificing accuracy. Qualitative Grad-CAM analyses show that CoMViT\nconsistently attends to clinically relevant regions despite its compact size.\nThese results highlight the potential of principled ViT redesign for developing\nefficient and interpretable models in low-resource medical imaging settings.",
      "pdf_url": "http://arxiv.org/pdf/2510.27442v1",
      "published": "2025-10-31T12:49:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.27442v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.2.10"
      ]
    },
    {
      "title": "Mitigating Semantic Collapse in Partially Relevant Video Retrieval",
      "authors": [
        "WonJun Moon",
        "MinSeok Jung",
        "Gilhan Park",
        "Tae-Young Kim",
        "Cheol-Ho Cho",
        "Woojin Jun",
        "Jae-Pil Heo"
      ],
      "abstract": "Partially Relevant Video Retrieval (PRVR) seeks videos where only part of the\ncontent matches a text query. Existing methods treat every annotated text-video\npair as a positive and all others as negatives, ignoring the rich semantic\nvariation both within a single video and across different videos. Consequently,\nembeddings of both queries and their corresponding video-clip segments for\ndistinct events within the same video collapse together, while embeddings of\nsemantically similar queries and segments from different videos are driven\napart. This limits retrieval performance when videos contain multiple, diverse\nevents. This paper addresses the aforementioned problems, termed as semantic\ncollapse, in both the text and video embedding spaces. We first introduce Text\nCorrelation Preservation Learning, which preserves the semantic relationships\nencoded by the foundation model across text queries. To address collapse in\nvideo embeddings, we propose Cross-Branch Video Alignment (CBVA), a contrastive\nalignment method that disentangles hierarchical video representations across\ntemporal scales. Subsequently, we introduce order-preserving token merging and\nadaptive CBVA to enhance alignment by producing video segments that are\ninternally coherent yet mutually distinctive. Extensive experiments on PRVR\nbenchmarks demonstrate that our framework effectively prevents semantic\ncollapse and substantially improves retrieval accuracy.",
      "pdf_url": "http://arxiv.org/pdf/2510.27432v1",
      "published": "2025-10-31T12:39:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.27432v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Learning Soft Robotic Dynamics with Active Exploration",
      "authors": [
        "Hehui Zheng",
        "Bhavya Sukhija",
        "Chenhao Li",
        "Klemens Iten",
        "Andreas Krause",
        "Robert K. Katzschmann"
      ],
      "abstract": "Soft robots offer unmatched adaptability and safety in unstructured\nenvironments, yet their compliant, high-dimensional, and nonlinear dynamics\nmake modeling for control notoriously difficult. Existing data-driven\napproaches often fail to generalize, constrained by narrowly focused task\ndemonstrations or inefficient random exploration. We introduce SoftAE, an\nuncertainty-aware active exploration framework that autonomously learns\ntask-agnostic and generalizable dynamics models of soft robotic systems. SoftAE\nemploys probabilistic ensemble models to estimate epistemic uncertainty and\nactively guides exploration toward underrepresented regions of the state-action\nspace, achieving efficient coverage of diverse behaviors without task-specific\nsupervision. We evaluate SoftAE on three simulated soft robotic platforms -- a\ncontinuum arm, an articulated fish in fluid, and a musculoskeletal leg with\nhybrid actuation -- and on a pneumatically actuated continuum soft arm in the\nreal world. Compared with random exploration and task-specific model-based\nreinforcement learning, SoftAE produces more accurate dynamics models, enables\nsuperior zero-shot control on unseen tasks, and maintains robustness under\nsensing noise, actuation delays, and nonlinear material effects. These results\ndemonstrate that uncertainty-driven active exploration can yield scalable,\nreusable dynamics models across diverse soft robotic morphologies, representing\na step toward more autonomous, adaptable, and data-efficient control in\ncompliant robots.",
      "pdf_url": "http://arxiv.org/pdf/2510.27428v1",
      "published": "2025-10-31T12:35:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.27428v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "Who Does Your Algorithm Fail? Investigating Age and Ethnic Bias in the MAMA-MIA Dataset",
      "authors": [
        "Aditya Parikh",
        "Sneha Das",
        "Aasa Feragen"
      ],
      "abstract": "Deep learning models aim to improve diagnostic workflows, but fairness\nevaluation remains underexplored beyond classification, e.g., in image\nsegmentation. Unaddressed segmentation bias can lead to disparities in the\nquality of care for certain populations, potentially compounded across clinical\ndecision points and amplified through iterative model development. Here, we\naudit the fairness of the automated segmentation labels provided in the breast\ncancer tumor segmentation dataset MAMA-MIA. We evaluate automated segmentation\nquality across age, ethnicity, and data source. Our analysis reveals an\nintrinsic age-related bias against younger patients that continues to persist\neven after controlling for confounding factors, such as data source. We\nhypothesize that this bias may be linked to physiological factors, a known\nchallenge for both radiologists and automated systems. Finally, we show how\naggregating data from multiple data sources influences site-specific ethnic\nbiases, underscoring the necessity of investigating data at a granular level.",
      "pdf_url": "http://arxiv.org/pdf/2510.27421v1",
      "published": "2025-10-31T12:20:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.27421v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "DeepCompress: A Dual Reward Strategy for Dynamically Exploring and Compressing Reasoning Chains",
      "authors": [
        "Tian Liang",
        "Wenxiang Jiao",
        "Zhiwei He",
        "Jiahao Xu",
        "Haitao Mi",
        "Dong Yu"
      ],
      "abstract": "Large Reasoning Models (LRMs) have demonstrated impressive capabilities but\nsuffer from cognitive inefficiencies like ``overthinking'' simple problems and\n``underthinking'' complex ones. While existing methods that use supervised\nfine-tuning~(SFT) or reinforcement learning~(RL) with token-length rewards can\nimprove efficiency, they often do so at the cost of accuracy. This paper\nintroduces \\textbf{DeepCompress}, a novel framework that simultaneously\nenhances both the accuracy and efficiency of LRMs. We challenge the prevailing\napproach of consistently favoring shorter reasoning paths, showing that longer\nresponses can contain a broader range of correct solutions for difficult\nproblems. DeepCompress employs an adaptive length reward mechanism that\ndynamically classifies problems as ``Simple'' or ``Hard'' in real-time based on\nthe model's evolving capability. It encourages shorter, more efficient\nreasoning for ``Simple'' problems while promoting longer, more exploratory\nthought chains for ``Hard'' problems. This dual-reward strategy enables the\nmodel to autonomously adjust its Chain-of-Thought (CoT) length, compressing\nreasoning for well-mastered problems and extending it for those it finds\nchallenging. Experimental results on challenging mathematical benchmarks show\nthat DeepCompress consistently outperforms baseline methods, achieving superior\naccuracy while significantly improving token efficiency.",
      "pdf_url": "http://arxiv.org/pdf/2510.27419v1",
      "published": "2025-10-31T12:13:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.27419v1",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Atlas-Alignment: Making Interpretability Transferable Across Language Models",
      "authors": [
        "Bruno Puri",
        "Jim Berend",
        "Sebastian Lapuschkin",
        "Wojciech Samek"
      ],
      "abstract": "Interpretability is crucial for building safe, reliable, and controllable\nlanguage models, yet existing interpretability pipelines remain costly and\ndifficult to scale. Interpreting a new model typically requires costly training\nof model-specific sparse autoencoders, manual or semi-automated labeling of SAE\ncomponents, and their subsequent validation. We introduce Atlas-Alignment, a\nframework for transferring interpretability across language models by aligning\nunknown latent spaces to a Concept Atlas - a labeled, human-interpretable\nlatent space - using only shared inputs and lightweight representational\nalignment techniques. Once aligned, this enables two key capabilities in\npreviously opaque models: (1) semantic feature search and retrieval, and (2)\nsteering generation along human-interpretable atlas concepts. Through\nquantitative and qualitative evaluations, we show that simple representational\nalignment methods enable robust semantic retrieval and steerable generation\nwithout the need for labeled concept data. Atlas-Alignment thus amortizes the\ncost of explainable AI and mechanistic interpretability: by investing in one\nhigh-quality Concept Atlas, we can make many new models transparent and\ncontrollable at minimal marginal cost.",
      "pdf_url": "http://arxiv.org/pdf/2510.27413v1",
      "published": "2025-10-31T12:02:54+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.27413v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Dialogue as Discovery: Navigating Human Intent Through Principled Inquiry",
      "authors": [
        "Jianwen Sun",
        "Yukang Feng",
        "Yifan Chang",
        "Chuanhao Li",
        "Zizhen Li",
        "Jiaxin Ai",
        "Fanrui Zhang",
        "Yu Dai",
        "Kaipeng Zhang"
      ],
      "abstract": "A fundamental bottleneck in human-AI collaboration is the \"intention\nexpression gap,\" the difficulty for humans to effectively convey complex,\nhigh-dimensional thoughts to AI. This challenge often traps users in\ninefficient trial-and-error loops and is exacerbated by the diverse expertise\nlevels of users. We reframe this problem from passive instruction following to\na Socratic collaboration paradigm, proposing an agent that actively probes for\ninformation to resolve its uncertainty about user intent. we name the proposed\nagent Nous, trained to acquire proficiency in this inquiry policy. The core\nmechanism of Nous is a training framework grounded in the first principles of\ninformation theory. Within this framework, we define the information gain from\ndialogue as an intrinsic reward signal, which is fundamentally equivalent to\nthe reduction of Shannon entropy over a structured task space. This reward\ndesign enables us to avoid reliance on costly human preference annotations or\nexternal reward models. To validate our framework, we develop an automated\nsimulation pipeline to generate a large-scale, preference-based dataset for the\nchallenging task of scientific diagram generation. Comprehensive experiments,\nincluding ablations, subjective and objective evaluations, and tests across\nuser expertise levels, demonstrate the effectiveness of our proposed framework.\nNous achieves leading efficiency and output quality, while remaining robust to\nvarying user expertise. Moreover, its design is domain-agnostic, and we show\nevidence of generalization beyond diagram generation. Experimental results\nprove that our work offers a principled, scalable, and adaptive paradigm for\nresolving uncertainty about user intent in complex human-AI collaboration.",
      "pdf_url": "http://arxiv.org/pdf/2510.27410v1",
      "published": "2025-10-31T12:00:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.27410v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "FedMuon: Accelerating Federated Learning with Matrix Orthogonalization",
      "authors": [
        "Junkang Liu",
        "Fanhua Shang",
        "Junchao Zhou",
        "Hongying Liu",
        "Yuanyuan Liu",
        "Jin Liu"
      ],
      "abstract": "The core bottleneck of Federated Learning (FL) lies in the communication\nrounds. That is, how to achieve more effective local updates is crucial for\nreducing communication rounds. Existing FL methods still primarily use\nelement-wise local optimizers (Adam/SGD), neglecting the geometric structure of\nthe weight matrices. This often leads to the amplification of pathological\ndirections in the weights during local updates, leading deterioration in the\ncondition number and slow convergence. Therefore, we introduce the Muon\noptimizer in local, which has matrix orthogonalization to optimize\nmatrix-structured parameters. Experimental results show that, in IID setting,\nLocal Muon significantly accelerates the convergence of FL and reduces\ncommunication rounds compared to Local SGD and Local AdamW. However, in non-IID\nsetting, independent matrix orthogonalization based on the local distributions\nof each client induces strong client drift. Applying Muon in non-IID FL poses\nsignificant challenges: (1) client preconditioner leading to client drift; (2)\nmoment reinitialization. To address these challenges, we propose a novel\nFederated Muon optimizer (FedMuon), which incorporates two key techniques: (1)\nmomentum aggregation, where clients use the aggregated momentum for local\ninitialization; (2) local-global alignment, where the local gradients are\naligned with the global update direction to significantly reduce client drift.\nTheoretically, we prove that \\texttt{FedMuon} achieves a linear speedup\nconvergence rate without the heterogeneity assumption, where $S$ is the number\nof participating clients per round, $K$ is the number of local iterations, and\n$R$ is the total number of communication rounds. Empirically, we validate the\neffectiveness of FedMuon on language and vision models. Compared to several\nbaselines, FedMuon significantly reduces communication rounds and improves test\naccuracy.",
      "pdf_url": "http://arxiv.org/pdf/2510.27403v1",
      "published": "2025-10-31T11:41:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.27403v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Balancing Knowledge Updates: Toward Unified Modular Editing in LLMs",
      "authors": [
        "Jiahao Liu",
        "Zijian Wang",
        "Kuo Zhao",
        "Dong Hu"
      ],
      "abstract": "Knowledge editing has emerged as an efficient approach for updating factual\nknowledge in large language models (LLMs). It typically locates knowledge\nstorage modules and then modifies their parameters. However, most existing\nmethods focus on the weights of multilayer perceptron (MLP) modules, which are\noften identified as the main repositories of factual information. Other\ncomponents, such as attention (Attn) modules, are often ignored during editing.\nThis imbalance can leave residual outdated knowledge and limit editing\neffectiveness. We perform comprehensive knowledge localization experiments on\nadvanced LLMs and find that Attn modules play a substantial role in factual\nknowledge storage and retrieval, especially in earlier layers. Based on these\ninsights, we propose IntAttn-Edit, a method that extends the associative memory\nparadigm to jointly update both MLP and Attn modules. Our approach uses a\nknowledge balancing strategy that allocates update magnitudes in proportion to\neach module's measured contribution to knowledge storage. Experiments on\nstandard benchmarks show that IntAttn-Edit achieves higher edit success, better\ngeneralization, and stronger knowledge preservation than prior methods. Further\nanalysis shows that the balancing strategy keeps editing performance within an\noptimal range across diverse settings.",
      "pdf_url": "http://arxiv.org/pdf/2510.27400v1",
      "published": "2025-10-31T11:37:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.27400v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Realistic pedestrian-driver interaction modelling using multi-agent RL with human perceptual-motor constraints",
      "authors": [
        "Yueyang Wang",
        "Mehmet Dogar",
        "Gustav Markkula"
      ],
      "abstract": "Modelling pedestrian-driver interactions is critical for understanding human\nroad user behaviour and developing safe autonomous vehicle systems. Existing\napproaches often rely on rule-based logic, game-theoretic models, or\n'black-box' machine learning methods. However, these models typically lack\nflexibility or overlook the underlying mechanisms, such as sensory and motor\nconstraints, which shape how pedestrians and drivers perceive and act in\ninteractive scenarios. In this study, we propose a multi-agent reinforcement\nlearning (RL) framework that integrates both visual and motor constraints of\npedestrian and driver agents. Using a real-world dataset from an unsignalised\npedestrian crossing, we evaluate four model variants, one without constraints,\ntwo with either motor or visual constraints, and one with both, across\nbehavioural metrics of interaction realism. Results show that the combined\nmodel with both visual and motor constraints performs best. Motor constraints\nlead to smoother movements that resemble human speed adjustments during\ncrossing interactions. The addition of visual constraints introduces perceptual\nuncertainty and field-of-view limitations, leading the agents to exhibit more\ncautious and variable behaviour, such as less abrupt deceleration. In this\ndata-limited setting, our model outperforms a supervised behavioural cloning\nmodel, demonstrating that our approach can be effective without large training\ndatasets. Finally, our framework accounts for individual differences by\nmodelling parameters controlling the human constraints as population-level\ndistributions, a perspective that has not been explored in previous work on\npedestrian-vehicle interaction modelling. Overall, our work demonstrates that\nmulti-agent RL with human constraints is a promising modelling approach for\nsimulating realistic road user interactions.",
      "pdf_url": "http://arxiv.org/pdf/2510.27383v1",
      "published": "2025-10-31T11:18:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.27383v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Spiking Neural Networks: The Future of Brain-Inspired Computing",
      "authors": [
        "Sales G. Aribe Jr"
      ],
      "abstract": "Spiking Neural Networks (SNNs) represent the latest generation of neural\ncomputation, offering a brain-inspired alternative to conventional Artificial\nNeural Networks (ANNs). Unlike ANNs, which depend on continuous-valued signals,\nSNNs operate using distinct spike events, making them inherently more\nenergy-efficient and temporally dynamic. This study presents a comprehensive\nanalysis of SNN design models, training algorithms, and multi-dimensional\nperformance metrics, including accuracy, energy consumption, latency, spike\ncount, and convergence behavior. Key neuron models such as the Leaky\nIntegrate-and-Fire (LIF) and training strategies, including surrogate gradient\ndescent, ANN-to-SNN conversion, and Spike-Timing Dependent Plasticity (STDP),\nare examined in depth. Results show that surrogate gradient-trained SNNs\nclosely approximate ANN accuracy (within 1-2%), with faster convergence by the\n20th epoch and latency as low as 10 milliseconds. Converted SNNs also achieve\ncompetitive performance but require higher spike counts and longer simulation\nwindows. STDP-based SNNs, though slower to converge, exhibit the lowest spike\ncounts and energy consumption (as low as 5 millijoules per inference), making\nthem optimal for unsupervised and low-power tasks. These findings reinforce the\nsuitability of SNNs for energy-constrained, latency-sensitive, and adaptive\napplications such as robotics, neuromorphic vision, and edge AI systems. While\npromising, challenges persist in hardware standardization and scalable\ntraining. This study concludes that SNNs, with further refinement, are poised\nto propel the next phase of neuromorphic computing.",
      "pdf_url": "http://arxiv.org/pdf/2510.27379v1",
      "published": "2025-10-31T11:14:59+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.27379v1",
      "categories": [
        "cs.NE",
        "cs.AI"
      ]
    },
    {
      "title": "Measuring Chain-of-Thought Monitorability Through Faithfulness and Verbosity",
      "authors": [
        "Austin Meek",
        "Eitan Sprejer",
        "Iván Arcuschin",
        "Austin J. Brockmeier",
        "Steven Basart"
      ],
      "abstract": "Chain-of-thought (CoT) outputs let us read a model's step-by-step reasoning.\nSince any long, serial reasoning process must pass through this textual trace,\nthe quality of the CoT is a direct window into what the model is thinking. This\nvisibility could help us spot unsafe or misaligned behavior (monitorability),\nbut only if the CoT is transparent about its internal reasoning (faithfulness).\nFully measuring faithfulness is difficult, so researchers often focus on\nexamining the CoT in cases where the model changes its answer after adding a\ncue to the input. This proxy finds some instances of unfaithfulness but loses\ninformation when the model maintains its answer, and does not investigate\naspects of reasoning not tied to the cue. We extend these results to a more\nholistic sense of monitorability by introducing verbosity: whether the CoT\nlists every factor needed to solve the task. We combine faithfulness and\nverbosity into a single monitorability score that shows how well the CoT serves\nas the model's external `working memory', a property that many safety schemes\nbased on CoT monitoring depend on. We evaluate instruction-tuned and reasoning\nmodels on BBH, GPQA, and MMLU. Our results show that models can appear faithful\nyet remain hard to monitor when they leave out key factors, and that\nmonitorability differs sharply across model families. We release our evaluation\ncode using the Inspect library to support reproducible future work.",
      "pdf_url": "http://arxiv.org/pdf/2510.27378v1",
      "published": "2025-10-31T11:14:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.27378v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Fine-Tuning Open Video Generators for Cinematic Scene Synthesis: A Small-Data Pipeline with LoRA and Wan2.1 I2V",
      "authors": [
        "Meftun Akarsu",
        "Kerem Catay",
        "Sedat Bin Vedat",
        "Enes Kutay Yarkan",
        "Ilke Senturk",
        "Arda Sar",
        "Dafne Eksioglu"
      ],
      "abstract": "We present a practical pipeline for fine-tuning open-source video diffusion\ntransformers to synthesize cinematic scenes for television and film production\nfrom small datasets. The proposed two-stage process decouples visual style\nlearning from motion generation. In the first stage, Low-Rank Adaptation (LoRA)\nmodules are integrated into the cross-attention layers of the Wan2.1 I2V-14B\nmodel to adapt its visual representations using a compact dataset of short\nclips from Ay Yapim's historical television film El Turco. This enables\nefficient domain transfer within hours on a single GPU. In the second stage,\nthe fine-tuned model produces stylistically consistent keyframes that preserve\ncostume, lighting, and color grading, which are then temporally expanded into\ncoherent 720p sequences through the model's video decoder. We further apply\nlightweight parallelization and sequence partitioning strategies to accelerate\ninference without quality degradation. Quantitative and qualitative evaluations\nusing FVD, CLIP-SIM, and LPIPS metrics, supported by a small expert user study,\ndemonstrate measurable improvements in cinematic fidelity and temporal\nstability over the base model. The complete training and inference pipeline is\nreleased to support reproducibility and adaptation across cinematic domains.",
      "pdf_url": "http://arxiv.org/pdf/2510.27364v1",
      "published": "2025-10-31T10:51:35+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.27364v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "ToolScope: An Agentic Framework for Vision-Guided and Long-Horizon Tool Use",
      "authors": [
        "Mengjie Deng",
        "Guanting Dong",
        "Zhicheng Dou"
      ],
      "abstract": "Recently, large language models (LLMs) have demonstrated remarkable\nproblem-solving capabilities by autonomously integrating with external tools\nfor collaborative reasoning. However, due to the inherently complex and diverse\nnature of multimodal information, enabling multimodal large language models\n(MLLMs) to flexibly and efficiently utilize external tools during reasoning\nremains an underexplored challenge. In this work, we introduce ToolScope, an\nagentic framework designed to unify global planning with local multimodal\nperception, adopting a specialized Perceive tool to mitigates visual context\ndegradation in long-horizon VQA task. ToolScope comprises three primary\ncomponents: the Global Navigator, the Agentic Executor, and the Response\nSynthesizer. The Global Navigator functions as a \"telescope\", offering\nhigh-level strategic guidance. The Agentic Executor operates iteratively to\naugment MLLM with local perception through the integration of external\ntools-Search, Code, and Perceive. Finally, the Response Synthesizer\nconsolidates and organizes the reasoning process into a coherent, user-friendly\noutput. We evaluate ToolScope on four VQA benchmarks across diverse domains,\nincluding VQA 2.0, ScienceQA, MAT-Search and MathVista. It demonstrates strong\ngeneralization capabilities, achieving an average performance improvement of up\nto +6.69% across all datasets.",
      "pdf_url": "http://arxiv.org/pdf/2510.27363v1",
      "published": "2025-10-31T10:51:27+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.27363v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "An In-depth Study of LLM Contributions to the Bin Packing Problem",
      "authors": [
        "Julien Herrmann",
        "Guillaume Pallez"
      ],
      "abstract": "Recent studies have suggested that Large Language Models (LLMs) could provide\ninteresting ideas contributing to mathematical discovery. This claim was\nmotivated by reports that LLM-based genetic algorithms produced heuristics\noffering new insights into the online bin packing problem under uniform and\nWeibull distributions. In this work, we reassess this claim through a detailed\nanalysis of the heuristics produced by LLMs, examining both their behavior and\ninterpretability. Despite being human-readable, these heuristics remain largely\nopaque even to domain experts. Building on this analysis, we propose a new\nclass of algorithms tailored to these specific bin packing instances. The\nderived algorithms are significantly simpler, more efficient, more\ninterpretable, and more generalizable, suggesting that the considered instances\nare themselves relatively simple. We then discuss the limitations of the claim\nregarding LLMs' contribution to this problem, which appears to rest on the\nmistaken assumption that the instances had previously been studied. Our\nfindings instead emphasize the need for rigorous validation and\ncontextualization when assessing the scientific value of LLM-generated outputs.",
      "pdf_url": "http://arxiv.org/pdf/2510.27353v1",
      "published": "2025-10-31T10:39:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.27353v1",
      "categories": [
        "cs.AI",
        "I.2.8; F.2.2"
      ]
    },
    {
      "title": "Discriminative Rule Learning for Outcome-Guided Process Model Discovery",
      "authors": [
        "Ali Norouzifar",
        "Wil van der Aalst"
      ],
      "abstract": "Event logs extracted from information systems offer a rich foundation for\nunderstanding and improving business processes. In many real-world\napplications, it is possible to distinguish between desirable and undesirable\nprocess executions, where desirable traces reflect efficient or compliant\nbehavior, and undesirable ones may involve inefficiencies, rule violations,\ndelays, or resource waste. This distinction presents an opportunity to guide\nprocess discovery in a more outcome-aware manner. Discovering a single process\nmodel without considering outcomes can yield representations poorly suited for\nconformance checking and performance analysis, as they fail to capture critical\nbehavioral differences. Moreover, prioritizing one behavior over the other may\nobscure structural distinctions vital for understanding process outcomes. By\nlearning interpretable discriminative rules over control-flow features, we\ngroup traces with similar desirability profiles and apply process discovery\nseparately within each group. This results in focused and interpretable models\nthat reveal the drivers of both desirable and undesirable executions. The\napproach is implemented as a publicly available tool and it is evaluated on\nmultiple real-life event logs, demonstrating its effectiveness in isolating and\nvisualizing critical process patterns.",
      "pdf_url": "http://arxiv.org/pdf/2510.27343v1",
      "published": "2025-10-31T10:25:19+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.27343v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Reinforcement Learning for Long-Horizon Unordered Tasks: From Boolean to Coupled Reward Machines",
      "authors": [
        "Kristina Levina",
        "Nikolaos Pappas",
        "Athanasios Karapantelakis",
        "Aneta Vulgarakis Feljan",
        "Jendrik Seipp"
      ],
      "abstract": "Reward machines (RMs) inform reinforcement learning agents about the reward\nstructure of the environment. This is particularly advantageous for complex\nnon-Markovian tasks because agents with access to RMs can learn more\nefficiently from fewer samples. However, learning with RMs is ill-suited for\nlong-horizon problems in which a set of subtasks can be executed in any order.\nIn such cases, the amount of information to learn increases exponentially with\nthe number of unordered subtasks. In this work, we address this limitation by\nintroducing three generalisations of RMs: (1) Numeric RMs allow users to\nexpress complex tasks in a compact form. (2) In Agenda RMs, states are\nassociated with an agenda that tracks the remaining subtasks to complete. (3)\nCoupled RMs have coupled states associated with each subtask in the agenda.\nFurthermore, we introduce a new compositional learning algorithm that leverages\ncoupled RMs: Q-learning with coupled RMs (CoRM). Our experiments show that CoRM\nscales better than state-of-the-art RM algorithms for long-horizon problems\nwith unordered subtasks.",
      "pdf_url": "http://arxiv.org/pdf/2510.27329v1",
      "published": "2025-10-31T10:00:57+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.27329v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Generative Semantic Coding for Ultra-Low Bitrate Visual Communication and Analysis",
      "authors": [
        "Weiming Chen",
        "Yijia Wang",
        "Zhihan Zhu",
        "Zhihai He"
      ],
      "abstract": "We consider the problem of ultra-low bit rate visual communication for remote\nvision analysis, human interactions and control in challenging scenarios with\nvery low communication bandwidth, such as deep space exploration, battlefield\nintelligence, and robot navigation in complex environments. In this paper, we\nask the following important question: can we accurately reconstruct the visual\nscene using only a very small portion of the bit rate in existing coding\nmethods while not sacrificing the accuracy of vision analysis and performance\nof human interactions? Existing text-to-image generation models offer a new\napproach for ultra-low bitrate image description. However, they can only\nachieve a semantic-level approximation of the visual scene, which is far\ninsufficient for the purpose of visual communication and remote vision analysis\nand human interactions. To address this important issue, we propose to\nseamlessly integrate image generation with deep image compression, using joint\ntext and coding latent to guide the rectified flow models for precise\ngeneration of the visual scene. The semantic text description and coding latent\nare both encoded and transmitted to the decoder at a very small bit rate.\nExperimental results demonstrate that our method can achieve the same image\nreconstruction quality and vision analysis accuracy as existing methods while\nusing much less bandwidth. The code will be released upon paper acceptance.",
      "pdf_url": "http://arxiv.org/pdf/2510.27324v1",
      "published": "2025-10-31T09:49:42+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.27324v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    }
  ]
}