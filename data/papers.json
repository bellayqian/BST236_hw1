{
  "last_updated": "2025-03-11T00:46:17.668683",
  "papers": [
    {
      "title": "Multi-Fidelity Policy Gradient Algorithms",
      "authors": [
        "Xinjie Liu",
        "Cyrus Neary",
        "Kushagra Gupta",
        "Christian Ellis",
        "Ufuk Topcu",
        "David Fridovich-Keil"
      ],
      "abstract": "Many reinforcement learning (RL) algorithms require large amounts of data,\nprohibiting their use in applications where frequent interactions with\noperational systems are infeasible, or high-fidelity simulations are expensive\nor unavailable. Meanwhile, low-fidelity simulators--such as reduced-order\nmodels, heuristic reward functions, or generative world models--can cheaply\nprovide useful data for RL training, even if they are too coarse for direct\nsim-to-real transfer. We propose multi-fidelity policy gradients (MFPGs), an RL\nframework that mixes a small amount of data from the target environment with a\nlarge volume of low-fidelity simulation data to form unbiased, reduced-variance\nestimators (control variates) for on-policy policy gradients. We instantiate\nthe framework by developing multi-fidelity variants of two policy gradient\nalgorithms: REINFORCE and proximal policy optimization. Experimental results\nacross a suite of simulated robotics benchmark problems demonstrate that when\ntarget-environment samples are limited, MFPG achieves up to 3.9x higher reward\nand improves training stability when compared to baselines that only use\nhigh-fidelity data. Moreover, even when the baselines are given more\nhigh-fidelity samples--up to 10x as many interactions with the target\nenvironment--MFPG continues to match or outperform them. Finally, we observe\nthat MFPG is capable of training effective policies even when the low-fidelity\nenvironment is drastically different from the target environment. MFPG thus not\nonly offers a novel paradigm for efficient sim-to-real transfer but also\nprovides a principled approach to managing the trade-off between policy\nperformance and data collection costs.",
      "pdf_url": "http://arxiv.org/pdf/2503.05696v1",
      "published": "2025-03-07T18:58:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.05696v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ]
    },
    {
      "title": "BEHAVIOR Robot Suite: Streamlining Real-World Whole-Body Manipulation for Everyday Household Activities",
      "authors": [
        "Yunfan Jiang",
        "Ruohan Zhang",
        "Josiah Wong",
        "Chen Wang",
        "Yanjie Ze",
        "Hang Yin",
        "Cem Gokmen",
        "Shuran Song",
        "Jiajun Wu",
        "Li Fei-Fei"
      ],
      "abstract": "Real-world household tasks present significant challenges for mobile\nmanipulation robots. An analysis of existing robotics benchmarks reveals that\nsuccessful task performance hinges on three key whole-body control\ncapabilities: bimanual coordination, stable and precise navigation, and\nextensive end-effector reachability. Achieving these capabilities requires\ncareful hardware design, but the resulting system complexity further\ncomplicates visuomotor policy learning. To address these challenges, we\nintroduce the BEHAVIOR Robot Suite (BRS), a comprehensive framework for\nwhole-body manipulation in diverse household tasks. Built on a bimanual,\nwheeled robot with a 4-DoF torso, BRS integrates a cost-effective whole-body\nteleoperation interface for data collection and a novel algorithm for learning\nwhole-body visuomotor policies. We evaluate BRS on five challenging household\ntasks that not only emphasize the three core capabilities but also introduce\nadditional complexities, such as long-range navigation, interaction with\narticulated and deformable objects, and manipulation in confined spaces. We\nbelieve that BRS's integrated robotic embodiment, data collection interface,\nand learning framework mark a significant step toward enabling real-world\nwhole-body manipulation for everyday household tasks. BRS is open-sourced at\nhttps://behavior-robot-suite.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2503.05652v1",
      "published": "2025-03-07T18:15:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.05652v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ]
    },
    {
      "title": "dARt Vinci: Egocentric Data Collection for Surgical Robot Learning at Scale",
      "authors": [
        "Yihao Liu",
        "Yu-Chun Ku",
        "Jiaming Zhang",
        "Hao Ding",
        "Peter Kazanzides",
        "Mehran Armand"
      ],
      "abstract": "Data scarcity has long been an issue in the robot learning community.\nParticularly, in safety-critical domains like surgical applications, obtaining\nhigh-quality data can be especially difficult. It poses challenges to\nresearchers seeking to exploit recent advancements in reinforcement learning\nand imitation learning, which have greatly improved generalizability and\nenabled robots to conduct tasks autonomously. We introduce dARt Vinci, a\nscalable data collection platform for robot learning in surgical settings. The\nsystem uses Augmented Reality (AR) hand tracking and a high-fidelity physics\nengine to capture subtle maneuvers in primitive surgical tasks: By eliminating\nthe need for a physical robot setup and providing flexibility in terms of time,\nspace, and hardware resources-such as multiview sensors and\nactuators-specialized simulation is a viable alternative. At the same time, AR\nallows the robot data collection to be more egocentric, supported by its body\ntracking and content overlaying capabilities. Our user study confirms the\nproposed system's efficiency and usability, where we use widely-used primitive\ntasks for training teleoperation with da Vinci surgical robots. Data throughput\nimproves across all tasks compared to real robot settings by 41% on average.\nThe total experiment time is reduced by an average of 10%. The temporal demand\nin the task load survey is improved. These gains are statistically significant.\nAdditionally, the collected data is over 400 times smaller in size, requiring\nfar less storage while achieving double the frequency.",
      "pdf_url": "http://arxiv.org/pdf/2503.05646v1",
      "published": "2025-03-07T18:07:54+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.05646v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "Symbolic Mixture-of-Experts: Adaptive Skill-based Routing for Heterogeneous Reasoning",
      "authors": [
        "Justin Chih-Yao Chen",
        "Sukwon Yun",
        "Elias Stengel-Eskin",
        "Tianlong Chen",
        "Mohit Bansal"
      ],
      "abstract": "Combining existing pre-trained expert LLMs is a promising avenue for scalably\ntackling large-scale and diverse tasks. However, selecting experts at the task\nlevel is often too coarse-grained, as heterogeneous tasks may require different\nexpertise for each instance. To enable adaptive instance-level mixing of\npre-trained LLM experts, we propose Symbolic-MoE, a symbolic, text-based, and\ngradient-free Mixture-of-Experts framework. Symbolic-MoE takes a fine-grained\napproach to selection by emphasizing skills, e.g., algebra in math or molecular\nbiology in biomedical reasoning. We propose a skill-based recruiting strategy\nthat dynamically selects the most relevant set of expert LLMs for diverse\nreasoning tasks based on their strengths. Each selected expert then generates\nits own reasoning, resulting in k outputs from k experts, which are then\nsynthesized into a final high-quality response by an aggregator chosen based on\nits ability to integrate diverse reasoning outputs. We show that Symbolic-MoE's\ninstance-level expert selection improves performance by a large margin but --\nwhen implemented naively -- can introduce a high computational overhead due to\nthe need for constant model loading and offloading. To address this, we\nimplement a batch inference strategy that groups instances based on their\nassigned experts, loading each model only once. This allows us to integrate 16\nexpert models on 1 GPU with a time cost comparable to or better than prior\nmulti-agent baselines using 4 GPUs. Through extensive evaluations on diverse\nbenchmarks (MMLU-Pro, GPQA, AIME, and MedMCQA), we demonstrate that\nSymbolic-MoE outperforms strong LLMs like GPT4o-mini, as well as multi-agent\napproaches, with an absolute average improvement of 8.15% over the best\nmulti-agent baseline. Moreover, Symbolic-MoE removes the need for expensive\nmulti-round discussions, outperforming discussion baselines with less\ncomputation.",
      "pdf_url": "http://arxiv.org/pdf/2503.05641v1",
      "published": "2025-03-07T18:03:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.05641v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "VideoPainter: Any-length Video Inpainting and Editing with Plug-and-Play Context Control",
      "authors": [
        "Yuxuan Bian",
        "Zhaoyang Zhang",
        "Xuan Ju",
        "Mingdeng Cao",
        "Liangbin Xie",
        "Ying Shan",
        "Qiang Xu"
      ],
      "abstract": "Video inpainting, which aims to restore corrupted video content, has\nexperienced substantial progress. Despite these advances, existing methods,\nwhether propagating unmasked region pixels through optical flow and receptive\nfield priors, or extending image-inpainting models temporally, face challenges\nin generating fully masked objects or balancing the competing objectives of\nbackground context preservation and foreground generation in one model,\nrespectively. To address these limitations, we propose a novel dual-stream\nparadigm VideoPainter that incorporates an efficient context encoder\n(comprising only 6% of the backbone parameters) to process masked videos and\ninject backbone-aware background contextual cues to any pre-trained video DiT,\nproducing semantically consistent content in a plug-and-play manner. This\narchitectural separation significantly reduces the model's learning complexity\nwhile enabling nuanced integration of crucial background context. We also\nintroduce a novel target region ID resampling technique that enables any-length\nvideo inpainting, greatly enhancing our practical applicability. Additionally,\nwe establish a scalable dataset pipeline leveraging current vision\nunderstanding models, contributing VPData and VPBench to facilitate\nsegmentation-based inpainting training and assessment, the largest video\ninpainting dataset and benchmark to date with over 390K diverse clips. Using\ninpainting as a pipeline basis, we also explore downstream applications\nincluding video editing and video editing pair data generation, demonstrating\ncompetitive performance and significant practical potential. Extensive\nexperiments demonstrate VideoPainter's superior performance in both any-length\nvideo inpainting and editing, across eight key metrics, including video\nquality, mask region preservation, and textual coherence.",
      "pdf_url": "http://arxiv.org/pdf/2503.05639v1",
      "published": "2025-03-07T17:59:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.05639v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ]
    },
    {
      "title": "TrajectoryCrafter: Redirecting Camera Trajectory for Monocular Videos via Diffusion Models",
      "authors": [
        "Mark YU",
        "Wenbo Hu",
        "Jinbo Xing",
        "Ying Shan"
      ],
      "abstract": "We present TrajectoryCrafter, a novel approach to redirect camera\ntrajectories for monocular videos. By disentangling deterministic view\ntransformations from stochastic content generation, our method achieves precise\ncontrol over user-specified camera trajectories. We propose a novel dual-stream\nconditional video diffusion model that concurrently integrates point cloud\nrenders and source videos as conditions, ensuring accurate view transformations\nand coherent 4D content generation. Instead of leveraging scarce multi-view\nvideos, we curate a hybrid training dataset combining web-scale monocular\nvideos with static multi-view datasets, by our innovative double-reprojection\nstrategy, significantly fostering robust generalization across diverse scenes.\nExtensive evaluations on multi-view and large-scale monocular videos\ndemonstrate the superior performance of our method.",
      "pdf_url": "http://arxiv.org/pdf/2503.05638v1",
      "published": "2025-03-07T17:57:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.05638v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ]
    },
    {
      "title": "Exploring FMCW Radars and Feature Maps for Activity Recognition: A Benchmark Study",
      "authors": [
        "Ali Samimi Fard",
        "Mohammadreza Mashhadigholamali",
        "Samaneh Zolfaghari",
        "Hajar Abedi",
        "Mainak Chakraborty",
        "Luigi Borzì",
        "Masoud Daneshtalab",
        "George Shaker"
      ],
      "abstract": "Human Activity Recognition has gained significant attention due to its\ndiverse applications, including ambient assisted living and remote sensing.\nWearable sensor-based solutions often suffer from user discomfort and\nreliability issues, while video-based methods raise privacy concerns and\nperform poorly in low-light conditions or long ranges. This study introduces a\nFrequency-Modulated Continuous Wave radar-based framework for human activity\nrecognition, leveraging a 60 GHz radar and multi-dimensional feature maps.\nUnlike conventional approaches that process feature maps as images, this study\nfeeds multi-dimensional feature maps -- Range-Doppler, Range-Azimuth, and\nRange-Elevation -- as data vectors directly into the machine learning (SVM,\nMLP) and deep learning (CNN, LSTM, ConvLSTM) models, preserving the spatial and\ntemporal structures of the data. These features were extracted from a novel\ndataset with seven activity classes and validated using two different\nvalidation approaches. The ConvLSTM model outperformed conventional machine\nlearning and deep learning models, achieving an accuracy of 90.51% and an\nF1-score of 87.31% on cross-scene validation and an accuracy of 89.56% and an\nF1-score of 87.15% on leave-one-person-out cross-validation. The results\nhighlight the approach's potential for scalable, non-intrusive, and\nprivacy-preserving activity monitoring in real-world scenarios.",
      "pdf_url": "http://arxiv.org/pdf/2503.05629v1",
      "published": "2025-03-07T17:53:29+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.05629v1",
      "categories": [
        "cs.ET",
        "cs.AI"
      ]
    },
    {
      "title": "Superintelligence Strategy: Expert Version",
      "authors": [
        "Dan Hendrycks",
        "Eric Schmidt",
        "Alexandr Wang"
      ],
      "abstract": "Rapid advances in AI are beginning to reshape national security.\nDestabilizing AI developments could rupture the balance of power and raise the\nodds of great-power conflict, while widespread proliferation of capable AI\nhackers and virologists would lower barriers for rogue actors to cause\ncatastrophe. Superintelligence -- AI vastly better than humans at nearly all\ncognitive tasks -- is now anticipated by AI researchers. Just as nations once\ndeveloped nuclear strategies to secure their survival, we now need a coherent\nsuperintelligence strategy to navigate a new period of transformative change.\nWe introduce the concept of Mutual Assured AI Malfunction (MAIM): a deterrence\nregime resembling nuclear mutual assured destruction (MAD) where any state's\naggressive bid for unilateral AI dominance is met with preventive sabotage by\nrivals. Given the relative ease of sabotaging a destabilizing AI project --\nthrough interventions ranging from covert cyberattacks to potential kinetic\nstrikes on datacenters -- MAIM already describes the strategic picture AI\nsuperpowers find themselves in. Alongside this, states can increase their\ncompetitiveness by bolstering their economies and militaries through AI, and\nthey can engage in nonproliferation to rogue actors to keep weaponizable AI\ncapabilities out of their hands. Taken together, the three-part framework of\ndeterrence, nonproliferation, and competitiveness outlines a robust strategy to\nsuperintelligence in the years ahead.",
      "pdf_url": "http://arxiv.org/pdf/2503.05628v1",
      "published": "2025-03-07T17:53:24+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.05628v1",
      "categories": [
        "cs.CY",
        "cs.AI"
      ]
    },
    {
      "title": "FMT:A Multimodal Pneumonia Detection Model Based on Stacking MOE Framework",
      "authors": [
        "Jingyu Xu",
        "Yang Wang"
      ],
      "abstract": "Artificial intelligence has shown the potential to improve diagnostic\naccuracy through medical image analysis for pneumonia diagnosis. However,\ntraditional multimodal approaches often fail to address real-world challenges\nsuch as incomplete data and modality loss. In this study, a Flexible Multimodal\nTransformer (FMT) was proposed, which uses ResNet-50 and BERT for joint\nrepresentation learning, followed by a dynamic masked attention strategy that\nsimulates clinical modality loss to improve robustness; finally, a sequential\nmixture of experts (MOE) architecture was used to achieve multi-level decision\nrefinement. After evaluation on a small multimodal pneumonia dataset, FMT\nachieved state-of-the-art performance with 94% accuracy, 95% recall, and 93% F1\nscore, outperforming single-modal baselines (ResNet: 89%; BERT: 79%) and the\nmedical benchmark CheXMed (90%), providing a scalable solution for multimodal\ndiagnosis of pneumonia in resource-constrained medical settings.",
      "pdf_url": "http://arxiv.org/pdf/2503.05626v1",
      "published": "2025-03-07T17:52:12+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.05626v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Learning LLM Preference over Intra-Dialogue Pairs: A Framework for Utterance-level Understandings",
      "authors": [
        "Xuanqing Liu",
        "Luyang Kong",
        "Wei Niu",
        "Afshin Khashei",
        "Belinda Zeng",
        "Steve Johnson",
        "Jon Jay",
        "Davor Golac",
        "Matt Pope"
      ],
      "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities in\nhandling complex dialogue tasks without requiring use case-specific\nfine-tuning. However, analyzing live dialogues in real-time necessitates\nlow-latency processing systems, making it impractical to deploy models with\nbillions of parameters due to latency constraints. As a result, practitioners\noften prefer smaller models with millions of parameters, trained on\nhigh-quality, human-annotated datasets. Yet, curating such datasets is both\ntime-consuming and costly. Consequently, there is a growing need to combine the\nscalability of LLM-generated labels with the precision of human annotations,\nenabling fine-tuned smaller models to achieve both higher speed and accuracy\ncomparable to larger models. In this paper, we introduce a simple yet effective\nframework to address this challenge. Our approach is specifically designed for\nper-utterance classification problems, which encompass tasks such as intent\ndetection, dialogue state tracking, and more. To mitigate the impact of\nlabeling errors from LLMs -- the primary source of inaccuracies in student\nmodels -- we propose a noise-reduced preference learning loss. Experimental\nresults demonstrate that our method significantly improves accuracy across\nutterance-level dialogue tasks, including sentiment detection (over $2\\%$),\ndialogue act classification (over $1.5\\%$), etc.",
      "pdf_url": "http://arxiv.org/pdf/2503.05620v1",
      "published": "2025-03-07T17:46:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.05620v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "A Survey on Sparse Autoencoders: Interpreting the Internal Mechanisms of Large Language Models",
      "authors": [
        "Dong Shu",
        "Xuansheng Wu",
        "Haiyan Zhao",
        "Daking Rai",
        "Ziyu Yao",
        "Ninghao Liu",
        "Mengnan Du"
      ],
      "abstract": "Large Language Models (LLMs) have revolutionized natural language processing,\nyet their internal mechanisms remain largely opaque. Recently, mechanistic\ninterpretability has attracted significant attention from the research\ncommunity as a means to understand the inner workings of LLMs. Among various\nmechanistic interpretability approaches, Sparse Autoencoders (SAEs) have\nemerged as a particularly promising method due to their ability to disentangle\nthe complex, superimposed features within LLMs into more interpretable\ncomponents. This paper presents a comprehensive examination of SAEs as a\npromising approach to interpreting and understanding LLMs. We provide a\nsystematic overview of SAE principles, architectures, and applications\nspecifically tailored for LLM analysis, covering theoretical foundations,\nimplementation strategies, and recent developments in sparsity mechanisms. We\nalso explore how SAEs can be leveraged to explain the internal workings of\nLLMs, steer model behaviors in desired directions, and develop more transparent\ntraining methodologies for future models. Despite the challenges that remain\naround SAE implementation and scaling, they continue to provide valuable tools\nfor understanding the internal mechanisms of large language models.",
      "pdf_url": "http://arxiv.org/pdf/2503.05613v1",
      "published": "2025-03-07T17:38:00+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.05613v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "CACTUS: An Open Dataset and Framework for Automated Cardiac Assessment and Classification of Ultrasound Images Using Deep Transfer Learning",
      "authors": [
        "Hanae Elmekki",
        "Ahmed Alagha",
        "Hani Sami",
        "Amanda Spilkin",
        "Antonela Mariel Zanuttini",
        "Ehsan Zakeri",
        "Jamal Bentahar",
        "Lyes Kadem",
        "Wen-Fang Xie",
        "Philippe Pibarot",
        "Rabeb Mizouni",
        "Hadi Otrok",
        "Shakti Singh",
        "Azzam Mourad"
      ],
      "abstract": "Cardiac ultrasound (US) scanning is a commonly used techniques in cardiology\nto diagnose the health of the heart and its proper functioning. Therefore, it\nis necessary to consider ways to automate these tasks and assist medical\nprofessionals in classifying and assessing cardiac US images. Machine learning\n(ML) techniques are regarded as a prominent solution due to their success in\nnumerous applications aimed at enhancing the medical field, including\naddressing the shortage of echography technicians. However, the limited\navailability of medical data presents a significant barrier to applying ML in\ncardiology, particularly regarding US images of the heart. This paper addresses\nthis challenge by introducing the first open graded dataset for Cardiac\nAssessment and ClassificaTion of UltraSound (CACTUS), which is available\nonline. This dataset contains images obtained from scanning a CAE Blue Phantom\nand representing various heart views and different quality levels, exceeding\nthe conventional cardiac views typically found in the literature. Additionally,\nthe paper introduces a Deep Learning (DL) framework consisting of two main\ncomponents. The first component classifies cardiac US images based on the heart\nview using a Convolutional Neural Network (CNN). The second component uses\nTransfer Learning (TL) to fine-tune the knowledge from the first component and\ncreate a model for grading and assessing cardiac images. The framework\ndemonstrates high performance in both classification and grading, achieving up\nto 99.43% accuracy and as low as 0.3067 error, respectively. To showcase its\nrobustness, the framework is further fine-tuned using new images representing\nadditional cardiac views and compared to several other state-of-the-art\narchitectures. The framework's outcomes and performance in handling real-time\nscans were also assessed using a questionnaire answered by cardiac experts.",
      "pdf_url": "http://arxiv.org/pdf/2503.05604v1",
      "published": "2025-03-07T17:29:04+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.05604v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "R1-Searcher: Incentivizing the Search Capability in LLMs via Reinforcement Learning",
      "authors": [
        "Huatong Song",
        "Jinhao Jiang",
        "Yingqian Min",
        "Jie Chen",
        "Zhipeng Chen",
        "Wayne Xin Zhao",
        "Lei Fang",
        "Ji-Rong Wen"
      ],
      "abstract": "Existing Large Reasoning Models (LRMs) have shown the potential of\nreinforcement learning (RL) to enhance the complex reasoning capabilities of\nLarge Language Models~(LLMs). While they achieve remarkable performance on\nchallenging tasks such as mathematics and coding, they often rely on their\ninternal knowledge to solve problems, which can be inadequate for\ntime-sensitive or knowledge-intensive questions, leading to inaccuracies and\nhallucinations. To address this, we propose \\textbf{R1-Searcher}, a novel\ntwo-stage outcome-based RL approach designed to enhance the search capabilities\nof LLMs. This method allows LLMs to autonomously invoke external search systems\nto access additional knowledge during the reasoning process. Our framework\nrelies exclusively on RL, without requiring process rewards or distillation for\na cold start. % effectively generalizing to out-of-domain datasets and\nsupporting both Base and Instruct models. Our experiments demonstrate that our\nmethod significantly outperforms previous strong RAG methods, even when\ncompared to the closed-source GPT-4o-mini.",
      "pdf_url": "http://arxiv.org/pdf/2503.05592v1",
      "published": "2025-03-07T17:14:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.05592v1",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ]
    },
    {
      "title": "Quantifying the Robustness of Retrieval-Augmented Language Models Against Spurious Features in Grounding Data",
      "authors": [
        "Shiping Yang",
        "Jie Wu",
        "Wenbiao Ding",
        "Ning Wu",
        "Shining Liang",
        "Ming Gong",
        "Hengyuan Zhang",
        "Dongmei Zhang"
      ],
      "abstract": "Robustness has become a critical attribute for the deployment of RAG systems\nin real-world applications. Existing research focuses on robustness to explicit\nnoise (e.g., document semantics) but overlooks spurious features (a.k.a.\nimplicit noise). While previous works have explored spurious features in LLMs,\nthey are limited to specific features (e.g., formats) and narrow scenarios\n(e.g., ICL). In this work, we statistically confirm the presence of spurious\nfeatures in the RAG paradigm, a robustness problem caused by the sensitivity of\nLLMs to semantic-agnostic features. Moreover, we provide a comprehensive\ntaxonomy of spurious features and empirically quantify their impact through\ncontrolled experiments. Further analysis reveals that not all spurious features\nare harmful and they can even be beneficial sometimes. Extensive evaluation\nresults across multiple LLMs suggest that spurious features are a widespread\nand challenging problem in the field of RAG. The code and dataset will be\nreleased to facilitate future research. We release all codes and data at:\n$\\\\\\href{https://github.com/maybenotime/RAG-SpuriousFeatures}{https://github.com/maybenotime/RAG-SpuriousFeatures}$.",
      "pdf_url": "http://arxiv.org/pdf/2503.05587v1",
      "published": "2025-03-07T17:11:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.05587v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "InDRiVE: Intrinsic Disagreement based Reinforcement for Vehicle Exploration through Curiosity Driven Generalized World Model",
      "authors": [
        "Feeza Khan Khanzada",
        "Jaerock Kwon"
      ],
      "abstract": "Model-based Reinforcement Learning (MBRL) has emerged as a promising paradigm\nfor autonomous driving, where data efficiency and robustness are critical. Yet,\nexisting solutions often rely on carefully crafted, task specific extrinsic\nrewards, limiting generalization to new tasks or environments. In this paper,\nwe propose InDRiVE (Intrinsic Disagreement based Reinforcement for Vehicle\nExploration), a method that leverages purely intrinsic, disagreement based\nrewards within a Dreamer based MBRL framework. By training an ensemble of world\nmodels, the agent actively explores high uncertainty regions of environments\nwithout any task specific feedback. This approach yields a task agnostic latent\nrepresentation, allowing for rapid zero shot or few shot fine tuning on\ndownstream driving tasks such as lane following and collision avoidance.\nExperimental results in both seen and unseen environments demonstrate that\nInDRiVE achieves higher success rates and fewer infractions compared to\nDreamerV2 and DreamerV3 baselines despite using significantly fewer training\nsteps. Our findings highlight the effectiveness of purely intrinsic exploration\nfor learning robust vehicle control behaviors, paving the way for more scalable\nand adaptable autonomous driving systems.",
      "pdf_url": "http://arxiv.org/pdf/2503.05573v1",
      "published": "2025-03-07T16:56:00+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.05573v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.ET",
        "cs.LG",
        "cs.NE"
      ]
    },
    {
      "title": "Compliance of AI Systems",
      "authors": [
        "Julius Schöning",
        "Niklas Kruse"
      ],
      "abstract": "The increasing integration of artificial intelligence (AI) systems in various\nfields requires solid concepts to ensure compliance with upcoming legislation.\nThis paper systematically examines the compliance of AI systems with relevant\nlegislation, focusing on the EU's AI Act and the compliance of data sets. The\nanalysis highlighted many challenges associated with edge devices, which are\nincreasingly being used to deploy AI applications closer and closer to the data\nsources. Such devices often face unique issues due to their decentralized\nnature and limited computing resources for implementing sophisticated\ncompliance mechanisms. By analyzing AI implementations, the paper identifies\nchallenges and proposes the first best practices for legal compliance when\ndeveloping, deploying, and running AI. The importance of data set compliance is\nhighlighted as a cornerstone for ensuring the trustworthiness, transparency,\nand explainability of AI systems, which must be aligned with ethical standards\nset forth in regulatory frameworks such as the AI Act. The insights gained\nshould contribute to the ongoing discourse on the responsible development and\ndeployment of embedded AI systems.",
      "pdf_url": "http://arxiv.org/pdf/2503.05571v1",
      "published": "2025-03-07T16:53:36+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.05571v1",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.ET",
        "I.2.1; H.4.0"
      ]
    },
    {
      "title": "Impoola: The Power of Average Pooling for Image-Based Deep Reinforcement Learning",
      "authors": [
        "Raphael Trumpp",
        "Ansgar Schäfftlein",
        "Mirco Theile",
        "Marco Caccamo"
      ],
      "abstract": "As image-based deep reinforcement learning tackles more challenging tasks,\nincreasing model size has become an important factor in improving performance.\nRecent studies achieved this by focusing on the parameter efficiency of scaled\nnetworks, typically using Impala-CNN, a 15-layer ResNet-inspired network, as\nthe image encoder. However, while Impala-CNN evidently outperforms older CNN\narchitectures, potential advancements in network design for deep reinforcement\nlearning-specific image encoders remain largely unexplored. We find that\nreplacing the flattening of output feature maps in Impala-CNN with global\naverage pooling leads to a notable performance improvement. This approach\noutperforms larger and more complex models in the Procgen Benchmark,\nparticularly in terms of generalization. We call our proposed encoder model\nImpoola-CNN. A decrease in the network's translation sensitivity may be central\nto this improvement, as we observe the most significant gains in games without\nagent-centered observations. Our results demonstrate that network scaling is\nnot just about increasing model size - efficient network design is also an\nessential factor.",
      "pdf_url": "http://arxiv.org/pdf/2503.05546v1",
      "published": "2025-03-07T16:19:19+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.05546v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Post-Hoc Concept Disentanglement: From Correlated to Isolated Concept Representations",
      "authors": [
        "Eren Erogullari",
        "Sebastian Lapuschkin",
        "Wojciech Samek",
        "Frederik Pahde"
      ],
      "abstract": "Concept Activation Vectors (CAVs) are widely used to model\nhuman-understandable concepts as directions within the latent space of neural\nnetworks. They are trained by identifying directions from the activations of\nconcept samples to those of non-concept samples. However, this method often\nproduces similar, non-orthogonal directions for correlated concepts, such as\n\"beard\" and \"necktie\" within the CelebA dataset, which frequently co-occur in\nimages of men. This entanglement complicates the interpretation of concepts in\nisolation and can lead to undesired effects in CAV applications, such as\nactivation steering. To address this issue, we introduce a post-hoc concept\ndisentanglement method that employs a non-orthogonality loss, facilitating the\nidentification of orthogonal concept directions while preserving directional\ncorrectness. We evaluate our approach with real-world and controlled correlated\nconcepts in CelebA and a synthetic FunnyBirds dataset with VGG16 and ResNet18\narchitectures. We further demonstrate the superiority of orthogonalized concept\nrepresentations in activation steering tasks, allowing (1) the insertion of\nisolated concepts into input images through generative models and (2) the\nremoval of concepts for effective shortcut suppression with reduced impact on\ncorrelated concepts in comparison to baseline CAVs.",
      "pdf_url": "http://arxiv.org/pdf/2503.05522v1",
      "published": "2025-03-07T15:45:43+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.05522v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Cognitive Bias Detection Using Advanced Prompt Engineering",
      "authors": [
        "Frederic Lemieux",
        "Aisha Behr",
        "Clara Kellermann-Bryant",
        "Zaki Mohammed"
      ],
      "abstract": "Cognitive biases, systematic deviations from rationality in judgment, pose\nsignificant challenges in generating objective content. This paper introduces a\nnovel approach for real-time cognitive bias detection in user-generated text\nusing large language models (LLMs) and advanced prompt engineering techniques.\nThe proposed system analyzes textual data to identify common cognitive biases\nsuch as confirmation bias, circular reasoning, and hidden assumption. By\ndesigning tailored prompts, the system effectively leverages LLMs' capabilities\nto both recognize and mitigate these biases, improving the quality of\nhuman-generated content (e.g., news, media, reports). Experimental results\ndemonstrate the high accuracy of our approach in identifying cognitive biases,\noffering a valuable tool for enhancing content objectivity and reducing the\nrisks of biased decision-making.",
      "pdf_url": "http://arxiv.org/pdf/2503.05516v1",
      "published": "2025-03-07T15:35:37+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.05516v1",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ]
    },
    {
      "title": "Noise-Robust Radio Frequency Fingerprint Identification Using Denoise Diffusion Model",
      "authors": [
        "Guolin Yin",
        "Junqing Zhang",
        "Yuan Ding",
        "Simon Cotton"
      ],
      "abstract": "Securing Internet of Things (IoT) devices presents increasing challenges due\nto their limited computational and energy resources. Radio Frequency\nFingerprint Identification (RFFI) emerges as a promising authentication\ntechnique to identify wireless devices through hardware impairments. RFFI\nperformance under low signal-to-noise ratio (SNR) scenarios is significantly\ndegraded because the minute hardware features can be easily swamped in noise.\nIn this paper, we leveraged the diffusion model to effectively restore the RFF\nunder low SNR scenarios. Specifically, we trained a powerful noise predictor\nand tailored a noise removal algorithm to effectively reduce the noise level in\nthe received signal and restore the device fingerprints. We used Wi-Fi as a\ncase study and created a testbed involving 6 commercial off-the-shelf Wi-Fi\ndongles and a USRP N210 software-defined radio (SDR) platform. We conducted\nexperimental evaluations on various SNR scenarios. The experimental results\nshow that the proposed algorithm can improve the classification accuracy by up\nto 34.9%.",
      "pdf_url": "http://arxiv.org/pdf/2503.05514v1",
      "published": "2025-03-07T15:30:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.05514v1",
      "categories": [
        "eess.SP",
        "cs.AI"
      ]
    },
    {
      "title": "Grammar-Based Code Representation: Is It a Worthy Pursuit for LLMs?",
      "authors": [
        "Qingyuan Liang",
        "Zhao Zhang",
        "Zeyu Sun",
        "Zheng Lin",
        "Qi Luo",
        "Yueyi Xiao",
        "Yizhou Chen",
        "Yuqun Zhang",
        "Haotian Zhang",
        "Lu Zhang",
        "Bin Chen",
        "Yingfei Xiong"
      ],
      "abstract": "Grammar serves as a cornerstone in programming languages and software\nengineering, providing frameworks to define the syntactic space and program\nstructure. Existing research demonstrates the effectiveness of grammar-based\ncode representations in small-scale models, showing their ability to reduce\nsyntax errors and enhance performance. However, as language models scale to the\nbillion level or beyond, syntax-level errors become rare, making it unclear\nwhether grammar information still provides performance benefits. To explore\nthis, we develop a series of billion-scale GrammarCoder models, incorporating\ngrammar rules in the code generation process. Experiments on HumanEval (+) and\nMBPP (+) demonstrate a notable improvement in code generation accuracy. Further\nanalysis shows that grammar-based representations enhance LLMs' ability to\ndiscern subtle code differences, reducing semantic errors caused by minor\nvariations. These findings suggest that grammar-based code representations\nremain valuable even in billion-scale models, not only by maintaining syntax\ncorrectness but also by improving semantic differentiation.",
      "pdf_url": "http://arxiv.org/pdf/2503.05507v1",
      "published": "2025-03-07T15:23:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.05507v1",
      "categories": [
        "cs.PL",
        "cs.AI"
      ]
    },
    {
      "title": "EuroBERT: Scaling Multilingual Encoders for European Languages",
      "authors": [
        "Nicolas Boizard",
        "Hippolyte Gisserot-Boukhlef",
        "Duarte M. Alves",
        "André Martins",
        "Ayoub Hammal",
        "Caio Corro",
        "Céline Hudelot",
        "Emmanuel Malherbe",
        "Etienne Malaboeuf",
        "Fanny Jourdan",
        "Gabriel Hautreux",
        "João Alves",
        "Kevin El-Haddad",
        "Manuel Faysse",
        "Maxime Peyrard",
        "Nuno M. Guerreiro",
        "Patrick Fernandes",
        "Ricardo Rei",
        "Pierre Colombo"
      ],
      "abstract": "General-purpose multilingual vector representations, used in retrieval,\nregression and classification, are traditionally obtained from bidirectional\nencoder models. Despite their wide applicability, encoders have been recently\novershadowed by advances in generative decoder-only models. However, many\ninnovations driving this progress are not inherently tied to decoders. In this\npaper, we revisit the development of multilingual encoders through the lens of\nthese advances, and introduce EuroBERT, a family of multilingual encoders\ncovering European and widely spoken global languages. Our models outperform\nexisting alternatives across a diverse range of tasks, spanning multilingual\ncapabilities, mathematics, and coding, and natively supporting sequences of up\nto 8,192 tokens. We also examine the design decisions behind EuroBERT, offering\ninsights into our dataset composition and training pipeline. We publicly\nrelease the EuroBERT models, including intermediate training checkpoints,\ntogether with our training framework.",
      "pdf_url": "http://arxiv.org/pdf/2503.05500v1",
      "published": "2025-03-07T15:13:58+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.05500v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "FastMap: Fast Queries Initialization Based Vectorized HD Map Reconstruction Framework",
      "authors": [
        "Haotian Hu",
        "Jingwei Xu",
        "Fanyi Wang",
        "Toyota Li",
        "Yaonong Wang",
        "Laifeng Hu",
        "Zhiwang Zhang"
      ],
      "abstract": "Reconstruction of high-definition maps is a crucial task in perceiving the\nautonomous driving environment, as its accuracy directly impacts the\nreliability of prediction and planning capabilities in downstream modules.\nCurrent vectorized map reconstruction methods based on the DETR framework\nencounter limitations due to the redundancy in the decoder structure,\nnecessitating the stacking of six decoder layers to maintain performance, which\nsignificantly hampers computational efficiency. To tackle this issue, we\nintroduce FastMap, an innovative framework designed to reduce decoder\nredundancy in existing approaches. FastMap optimizes the decoder architecture\nby employing a single-layer, two-stage transformer that achieves multilevel\nrepresentation capabilities. Our framework eliminates the conventional practice\nof randomly initializing queries and instead incorporates a heatmap-guided\nquery generation module during the decoding phase, which effectively maps image\nfeatures into structured query vectors using learnable positional encoding.\nAdditionally, we propose a geometry-constrained point-to-line loss mechanism\nfor FastMap, which adeptly addresses the challenge of distinguishing highly\nhomogeneous features that often arise in traditional point-to-point loss\ncomputations. Extensive experiments demonstrate that FastMap achieves\nstate-of-the-art performance in both nuScenes and Argoverse2 datasets, with its\ndecoder operating 3.2 faster than the baseline. Code and more demos are\navailable at https://github.com/hht1996ok/FastMap.",
      "pdf_url": "http://arxiv.org/pdf/2503.05492v1",
      "published": "2025-03-07T15:01:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.05492v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Personalized Federated Learning via Learning Dynamic Graphs",
      "authors": [
        "Ziran Zhou",
        "Guanyu Gao",
        "Xiaohu Wu",
        "Yan Lyu"
      ],
      "abstract": "Personalized Federated Learning (PFL) aims to train a personalized model for\neach client that is tailored to its local data distribution, learning fails to\nperform well on individual clients due to variations in their local data\ndistributions. Most existing PFL methods focus on personalizing the aggregated\nglobal model for each client, neglecting the fundamental aspect of federated\nlearning: the regulation of how client models are aggregated. Additionally,\nalmost all of them overlook the graph structure formed by clients in federated\nlearning. In this paper, we propose a novel method, Personalized Federated\nLearning with Graph Attention Network (pFedGAT), which captures the latent\ngraph structure between clients and dynamically determines the importance of\nother clients for each client, enabling fine-grained control over the\naggregation process. We evaluate pFedGAT across multiple data distribution\nscenarios, comparing it with twelve state of the art methods on three datasets:\nFashion MNIST, CIFAR-10, and CIFAR-100, and find that it consistently performs\nwell.",
      "pdf_url": "http://arxiv.org/pdf/2503.05474v1",
      "published": "2025-03-07T14:47:03+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.05474v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "The Society of HiveMind: Multi-Agent Optimization of Foundation Model Swarms to Unlock the Potential of Collective Intelligence",
      "authors": [
        "Noah Mamie",
        "Susie Xi Rao"
      ],
      "abstract": "Multi-agent systems address issues of accessibility and scalability of\nartificial intelligence (AI) foundation models, which are often represented by\nlarge language models. We develop a framework - the \"Society of HiveMind\"\n(SOHM) - that orchestrates the interaction between multiple AI foundation\nmodels, imitating the observed behavior of animal swarms in nature by following\nmodern evolutionary theories. On the one hand, we find that the SOHM provides a\nnegligible benefit on tasks that mainly require real-world knowledge. On the\nother hand, we remark a significant improvement on tasks that require intensive\nlogical reasoning, indicating that multi-agent systems are capable of\nincreasing the reasoning capabilities of the collective compared to the\nindividual agents. Our findings demonstrate the potential of combining a\nmultitude of diverse AI foundation models to form an artificial swarm\nintelligence capable of self-improvement through interactions with a given\nenvironment.",
      "pdf_url": "http://arxiv.org/pdf/2503.05473v1",
      "published": "2025-03-07T14:45:03+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.05473v1",
      "categories": [
        "cs.NE",
        "cs.AI"
      ]
    },
    {
      "title": "Controllable Complementarity: Subjective Preferences in Human-AI Collaboration",
      "authors": [
        "Chase McDonald",
        "Cleotilde Gonzalez"
      ],
      "abstract": "Research on human-AI collaboration often prioritizes objective performance.\nHowever, understanding human subjective preferences is essential to improving\nhuman-AI complementarity and human experiences. We investigate human\npreferences for controllability in a shared workspace task with AI partners\nusing Behavior Shaping (BS), a reinforcement learning algorithm that allows\nhumans explicit control over AI behavior.\n  In one experiment, we validate the robustness of BS in producing effective AI\npolicies relative to self-play policies, when controls are hidden. In another\nexperiment, we enable human control, showing that participants perceive AI\npartners as more effective and enjoyable when they can directly dictate AI\nbehavior. Our findings highlight the need to design AI that prioritizes both\ntask performance and subjective human preferences. By aligning AI behavior with\nhuman preferences, we demonstrate how human-AI complementarity can extend\nbeyond objective outcomes to include subjective preferences.",
      "pdf_url": "http://arxiv.org/pdf/2503.05455v1",
      "published": "2025-03-07T14:27:48+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.05455v1",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.MA"
      ]
    },
    {
      "title": "Soft Policy Optimization: Online Off-Policy RL for Sequence Models",
      "authors": [
        "Taco Cohen",
        "David W. Zhang",
        "Kunhao Zheng",
        "Yunhao Tang",
        "Remi Munos",
        "Gabriel Synnaeve"
      ],
      "abstract": "RL-based post-training of language models is almost exclusively done using\non-policy methods such as PPO. These methods cannot learn from arbitrary\nsequences such as those produced earlier in training, in earlier runs, by human\nexperts or other policies, or by decoding and exploration methods. This results\nin severe sample inefficiency and exploration difficulties, as well as a\npotential loss of diversity in the policy responses. Moreover, asynchronous PPO\nimplementations require frequent and costly model transfers, and typically use\nvalue models which require a large amount of memory. In this paper we introduce\nSoft Policy Optimization (SPO), a simple, scalable and principled Soft RL\nmethod for sequence model policies that can learn from arbitrary online and\noffline trajectories and does not require a separate value model. In\nexperiments on code contests, we shows that SPO outperforms PPO on pass@10, is\nsignificantly faster and more memory efficient, is able to benefit from\noff-policy data, enjoys improved stability, and learns more diverse (i.e. soft)\npolicies.",
      "pdf_url": "http://arxiv.org/pdf/2503.05453v1",
      "published": "2025-03-07T14:23:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.05453v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "LLM-based Iterative Approach to Metamodeling in Automotive",
      "authors": [
        "Nenad Petrovic",
        "Fengjunjie Pan",
        "Vahid Zolfaghari",
        "Alois Knoll"
      ],
      "abstract": "In this paper, we introduce an automated approach to domain-specific\nmetamodel construction relying on Large Language Model (LLM). The main focus is\nadoption in automotive domain. As outcome, a prototype was implemented as web\nservice using Python programming language, while OpenAI's GPT-4o was used as\nthe underlying LLM. Based on the initial experiments, this approach\nsuccessfully constructs Ecore metamodel based on set of automotive requirements\nand visualizes it making use of PlantUML notation, so human experts can provide\nfeedback in order to refine the result. Finally, locally deployable solution is\nalso considered, including the limitations and additional steps required.",
      "pdf_url": "http://arxiv.org/pdf/2503.05449v1",
      "published": "2025-03-07T14:19:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.05449v1",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "Linear-MoE: Linear Sequence Modeling Meets Mixture-of-Experts",
      "authors": [
        "Weigao Sun",
        "Disen Lan",
        "Tong Zhu",
        "Xiaoye Qu",
        "Yu Cheng"
      ],
      "abstract": "Linear Sequence Modeling (LSM) like linear attention, state space models and\nlinear RNNs, and Mixture-of-Experts (MoE) have recently emerged as significant\narchitectural improvements. In this paper, we introduce Linear-MoE, a\nproduction-level system for modeling and training large-scale models that\nintegrate LSM with MoE. Linear-MoE leverages the advantages of both LSM modules\nfor linear-complexity sequence modeling and MoE layers for sparsely activation,\naiming to offer high performance with efficient training. The Linear-MoE system\ncomprises: 1) Modeling subsystem, which provides a unified framework supporting\nall instances of LSM. and 2) Training subsystem, which facilitates efficient\ntraining by incorporating various advanced parallelism technologies,\nparticularly Sequence Parallelism designed for Linear-MoE models. Additionally,\nwe explore hybrid models that combine Linear-MoE layers with standard\nTransformer-MoE layers with its Sequence Parallelism to further enhance model\nflexibility and performance. Evaluations on two model series, A0.3B-2B and\nA1B-7B, demonstrate Linear-MoE achieves efficiency gains while maintaining\ncompetitive performance on various benchmarks, showcasing its potential as a\nnext-generation foundational model architecture. Code:\nhttps://github.com/OpenSparseLLMs/Linear-MoE.",
      "pdf_url": "http://arxiv.org/pdf/2503.05447v1",
      "published": "2025-03-07T14:17:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.05447v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.DC"
      ]
    },
    {
      "title": "An Empirical Study of Conformal Prediction in LLM with ASP Scaffolds for Robust Reasoning",
      "authors": [
        "Navdeep Kaur",
        "Lachlan McPheat",
        "Alessandra Russo",
        "Anthony G Cohn",
        "Pranava Madhyastha"
      ],
      "abstract": "In this paper, we examine the use of Conformal Language Modelling (CLM)\nalongside Answer Set Programming (ASP) to enhance the performance of standard\nopen-weight LLMs on complex multi-step reasoning tasks. Using the StepGame\ndataset, which requires spatial reasoning, we apply CLM to generate sets of ASP\nprograms from an LLM, providing statistical guarantees on the correctness of\nthe outputs. Experimental results show that CLM significantly outperforms\nbaseline models that use standard sampling methods, achieving substantial\naccuracy improvements across different levels of reasoning complexity.\nAdditionally, the LLM-as-Judge metric enhances CLM's performance, especially in\nassessing structurally and logically correct ASP outputs. However, calibrating\nCLM with diverse calibration sets did not improve generalizability for tasks\nrequiring much longer reasoning steps, indicating limitations in handling more\ncomplex tasks.",
      "pdf_url": "http://arxiv.org/pdf/2503.05439v1",
      "published": "2025-03-07T14:10:10+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.05439v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Semantic Shift Estimation via Dual-Projection and Classifier Reconstruction for Exemplar-Free Class-Incremental Learning",
      "authors": [
        "Run He",
        "Di Fang",
        "Yicheng Xu",
        "Yawen Cui",
        "Ming Li",
        "Cen Chen",
        "Ziqian Zeng",
        "Huiping Zhuang"
      ],
      "abstract": "Exemplar-Free Class-Incremental Learning (EFCIL) aims to sequentially learn\nfrom distinct categories without retaining exemplars but easily suffers from\ncatastrophic forgetting of learned knowledge. While existing EFCIL methods\nleverage knowledge distillation to alleviate forgetting, they still face two\ncritical challenges: semantic shift and decision bias. Specifically, the\nembeddings of old tasks shift in the embedding space after learning new tasks,\nand the classifier becomes biased towards new tasks due to training solely with\nnew data, thereby hindering the balance between old and new knowledge. To\naddress these issues, we propose the Dual-Projection Shift Estimation and\nClassifier Reconstruction (DPCR) approach for EFCIL. DPCR effectively estimates\nsemantic shift through a dual-projection, which combines a learnable\ntransformation with a row-space projection to capture both task-wise and\ncategory-wise shifts. Furthermore, to mitigate decision bias, DPCR employs\nridge regression to reformulate classifier training as a reconstruction\nprocess. This reconstruction exploits previous information encoded in\ncovariance and prototype of each class after calibration with estimated shift,\nthereby reducing decision bias. Extensive experiments demonstrate that, across\nvarious datasets, DPCR effectively balances old and new tasks, outperforming\nstate-of-the-art EFCIL methods.",
      "pdf_url": "http://arxiv.org/pdf/2503.05423v1",
      "published": "2025-03-07T13:50:29+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.05423v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Static Program Analysis Guided LLM Based Unit Test Generation",
      "authors": [
        "Sujoy Roychowdhury",
        "Giriprasad Sridhara",
        "A K Raghavan",
        "Joy Bose",
        "Sourav Mazumdar",
        "Hamender Singh",
        "Srinivasan Bajji Sugumaran",
        "Ricardo Britto"
      ],
      "abstract": "We describe a novel approach to automating unit test generation for Java\nmethods using large language models (LLMs). Existing LLM-based approaches rely\non sample usage(s) of the method to test (focal method) and/or provide the\nentire class of the focal method as input prompt and context. The former\napproach is often not viable due to the lack of sample usages, especially for\nnewly written focal methods. The latter approach does not scale well enough;\nthe bigger the complexity of the focal method and larger associated class, the\nharder it is to produce adequate test code (due to factors such as exceeding\nthe prompt and context lengths of the underlying LLM). We show that augmenting\nprompts with \\emph{concise} and \\emph{precise} context information obtained by\nprogram analysis %of the focal method increases the effectiveness of generating\nunit test code through LLMs. We validate our approach on a large commercial\nJava project and a popular open-source Java project.",
      "pdf_url": "http://arxiv.org/pdf/2503.05394v1",
      "published": "2025-03-07T13:09:37+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.05394v1",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "Ontology Generation using Large Language Models",
      "authors": [
        "Anna Sofia Lippolis",
        "Mohammad Javad Saeedizade",
        "Robin Keskisärkkä",
        "Sara Zuppiroli",
        "Miguel Ceriani",
        "Aldo Gangemi",
        "Eva Blomqvist",
        "Andrea Giovanni Nuzzolese"
      ],
      "abstract": "The ontology engineering process is complex, time-consuming, and error-prone,\neven for experienced ontology engineers. In this work, we investigate the\npotential of Large Language Models (LLMs) to provide effective OWL ontology\ndrafts directly from ontological requirements described using user stories and\ncompetency questions. Our main contribution is the presentation and evaluation\nof two new prompting techniques for automated ontology development: Memoryless\nCQbyCQ and Ontogenia. We also emphasize the importance of three structural\ncriteria for ontology assessment, alongside expert qualitative evaluation,\nhighlighting the need for a multi-dimensional evaluation in order to capture\nthe quality and usability of the generated ontologies. Our experiments,\nconducted on a benchmark dataset of ten ontologies with 100 distinct CQs and 29\ndifferent user stories, compare the performance of three LLMs using the two\nprompting techniques. The results demonstrate improvements over the current\nstate-of-the-art in LLM-supported ontology engineering. More specifically, the\nmodel OpenAI o1-preview with Ontogenia produces ontologies of sufficient\nquality to meet the requirements of ontology engineers, significantly\noutperforming novice ontology engineers in modelling ability. However, we still\nnote some common mistakes and variability of result quality, which is important\nto take into account when using LLMs for ontology authoring support. We discuss\nthese limitations and propose directions for future research.",
      "pdf_url": "http://arxiv.org/pdf/2503.05388v1",
      "published": "2025-03-07T13:03:28+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.05388v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "VLMs Play StarCraft II: A Benchmark and Multimodal Decision Method",
      "authors": [
        "Weiyu Ma",
        "Yuqian Fu",
        "Zecheng Zhang",
        "Guohao Li"
      ],
      "abstract": "We introduce VLM-Attention, a multimodal StarCraft II environment that aligns\nartificial agent perception with the human gameplay experience. Traditional\nframeworks such as SMAC rely on abstract state representations that diverge\nsignificantly from human perception, limiting the ecological validity of agent\nbehavior. Our environment addresses this limitation by incorporating RGB visual\ninputs and natural language observations that more closely simulate human\ncognitive processes during gameplay. The VLM-Attention framework consists of\nthree integrated components: (1) a vision-language model enhanced with\nspecialized self-attention mechanisms for strategic unit targeting and\nbattlefield assessment, (2) a retrieval-augmented generation system that\nleverages domain-specific StarCraft II knowledge to inform tactical decisions,\nand (3) a dynamic role-based task distribution system that enables coordinated\nmulti-agent behavior. Our experimental evaluation across 21 custom scenarios\ndemonstrates that VLM-based agents powered by foundation models (specifically\nQwen-VL and GPT-4o) can execute complex tactical maneuvers without explicit\ntraining, achieving comparable performance to traditional MARL methods that\nrequire substantial training iterations. This work establishes a foundation for\ndeveloping human-aligned StarCraft II agents and advances the broader research\nagenda of multimodal game AI. Our implementation is available at\nhttps://github.com/camel-ai/VLM-Play-StarCraft2.",
      "pdf_url": "http://arxiv.org/pdf/2503.05383v1",
      "published": "2025-03-07T12:54:25+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.05383v1",
      "categories": [
        "cs.AI",
        "cs.MA"
      ]
    },
    {
      "title": "Shifting Perspectives: Steering Vector Ensembles for Robust Bias Mitigation in LLMs",
      "authors": [
        "Zara Siddique",
        "Irtaza Khalid",
        "Liam D. Turner",
        "Luis Espinosa-Anke"
      ],
      "abstract": "We present a novel approach to bias mitigation in large language models\n(LLMs) by applying steering vectors to modify model activations in forward\npasses. We employ Bayesian optimization to systematically identify effective\ncontrastive pair datasets across nine bias axes. When optimized on the BBQ\ndataset, our individually tuned steering vectors achieve average improvements\nof 12.2%, 4.7%, and 3.2% over the baseline for Mistral, Llama, and Qwen,\nrespectively. Building on these promising results, we introduce Steering Vector\nEnsembles (SVE), a method that averages multiple individually optimized\nsteering vectors, each targeting a specific bias axis such as age, race, or\ngender. By leveraging their collective strength, SVE outperforms individual\nsteering vectors in both bias reduction and maintaining model performance. The\nwork presents the first systematic investigation of steering vectors for bias\nmitigation, and we demonstrate that SVE is a powerful and computationally\nefficient strategy for reducing bias in LLMs, with broader implications for\nenhancing AI safety.",
      "pdf_url": "http://arxiv.org/pdf/2503.05371v1",
      "published": "2025-03-07T12:25:29+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.05371v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Improving Hate Speech Classification with Cross-Taxonomy Dataset Integration",
      "authors": [
        "Jan Fillies",
        "Adrian Paschke"
      ],
      "abstract": "Algorithmic hate speech detection faces significant challenges due to the\ndiverse definitions and datasets used in research and practice. Social media\nplatforms, legal frameworks, and institutions each apply distinct yet\noverlapping definitions, complicating classification efforts. This study\naddresses these challenges by demonstrating that existing datasets and\ntaxonomies can be integrated into a unified model, enhancing prediction\nperformance and reducing reliance on multiple specialized classifiers. The work\nintroduces a universal taxonomy and a hate speech classifier capable of\ndetecting a wide range of definitions within a single framework. Our approach\nis validated by combining two widely used but differently annotated datasets,\nshowing improved classification performance on an independent test set. This\nwork highlights the potential of dataset and taxonomy integration in advancing\nhate speech detection, increasing efficiency, and ensuring broader\napplicability across contexts.",
      "pdf_url": "http://arxiv.org/pdf/2503.05357v1",
      "published": "2025-03-07T12:01:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.05357v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.SI"
      ]
    },
    {
      "title": "On the Logical Content of Logic Programs",
      "authors": [
        "Alexader V. Gheorghiu"
      ],
      "abstract": "Logic programming (LP) is typically understood through operational semantics\n(e.g., SLD-resolution) or model-theoretic interpretations (e.g., the least\nHerbrand model). This paper introduces a novel perspective on LP by defining a\n``support'' relation that explicates what a program ``knows''. This\ninterpretation is shown to express classical and intuitionistic logic, as well\nas an intermediate logic, depending on certain choices regarding LP and the\nmeanings of disjunction and negation. These results are formalized using the\nidea of base-extension semantics within proof-theoretic semantics. Our approach\noffers new insights into the logical foundations of LP and has potential\napplications in knowledge representation, automated reasoning, and formal\nverification.",
      "pdf_url": "http://arxiv.org/pdf/2503.05355v1",
      "published": "2025-03-07T11:58:08+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.05355v1",
      "categories": [
        "cs.LO",
        "cs.AI"
      ]
    },
    {
      "title": "Spatial Distillation based Distribution Alignment (SDDA) for Cross-Headset EEG Classification",
      "authors": [
        "Dingkun Liu",
        "Siyang Li",
        "Ziwei Wang",
        "Wei Li",
        "Dongrui Wu"
      ],
      "abstract": "A non-invasive brain-computer interface (BCI) enables direct interaction\nbetween the user and external devices, typically via electroencephalogram (EEG)\nsignals. However, decoding EEG signals across different headsets remains a\nsignificant challenge due to differences in the number and locations of the\nelectrodes. To address this challenge, we propose a spatial distillation based\ndistribution alignment (SDDA) approach for heterogeneous cross-headset transfer\nin non-invasive BCIs. SDDA uses first spatial distillation to make use of the\nfull set of electrodes, and then input/feature/output space distribution\nalignments to cope with the significant differences between the source and\ntarget domains. To our knowledge, this is the first work to use knowledge\ndistillation in cross-headset transfers. Extensive experiments on six EEG\ndatasets from two BCI paradigms demonstrated that SDDA achieved superior\nperformance in both offline unsupervised domain adaptation and online\nsupervised domain adaptation scenarios, consistently outperforming 10 classical\nand state-of-the-art transfer learning algorithms.",
      "pdf_url": "http://arxiv.org/pdf/2503.05349v1",
      "published": "2025-03-07T11:44:49+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.05349v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.HC"
      ]
    },
    {
      "title": "AutoIOT: LLM-Driven Automated Natural Language Programming for AIoT Applications",
      "authors": [
        "Leming Shen",
        "Qiang Yang",
        "Yuanqing Zheng",
        "Mo Li"
      ],
      "abstract": "The advent of Large Language Models (LLMs) has profoundly transformed our\nlives, revolutionizing interactions with AI and lowering the barrier to AI\nusage. While LLMs are primarily designed for natural language interaction, the\nextensive embedded knowledge empowers them to comprehend digital sensor data.\nThis capability enables LLMs to engage with the physical world through IoT\nsensors and actuators, performing a myriad of AIoT tasks. Consequently, this\nevolution triggers a paradigm shift in conventional AIoT application\ndevelopment, democratizing its accessibility to all by facilitating the design\nand development of AIoT applications via natural language. However, some\nlimitations need to be addressed to unlock the full potential of LLMs in AIoT\napplication development. First, existing solutions often require transferring\nraw sensor data to LLM servers, which raises privacy concerns, incurs high\nquery fees, and is limited by token size. Moreover, the reasoning processes of\nLLMs are opaque to users, making it difficult to verify the robustness and\ncorrectness of inference results. This paper introduces AutoIOT, an LLM-based\nautomated program generator for AIoT applications. AutoIOT enables users to\nspecify their requirements using natural language (input) and automatically\nsynthesizes interpretable programs with documentation (output). AutoIOT\nautomates the iterative optimization to enhance the quality of generated code\nwith minimum user involvement. AutoIOT not only makes the execution of AIoT\ntasks more explainable but also mitigates privacy concerns and reduces token\ncosts with local execution of synthesized programs. Extensive experiments and\nuser studies demonstrate AutoIOT's remarkable capability in program synthesis\nfor various AIoT tasks. The synthesized programs can match and even outperform\nsome representative baselines.",
      "pdf_url": "http://arxiv.org/pdf/2503.05346v1",
      "published": "2025-03-07T11:40:52+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.05346v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SE"
      ]
    },
    {
      "title": "Toward an Evaluation Science for Generative AI Systems",
      "authors": [
        "Laura Weidinger",
        "Deb Raji",
        "Hanna Wallach",
        "Margaret Mitchell",
        "Angelina Wang",
        "Olawale Salaudeen",
        "Rishi Bommasani",
        "Sayash Kapoor",
        "Deep Ganguli",
        "Sanmi Koyejo",
        "William Isaac"
      ],
      "abstract": "There is an increasing imperative to anticipate and understand the\nperformance and safety of generative AI systems in real-world deployment\ncontexts. However, the current evaluation ecosystem is insufficient: Commonly\nused static benchmarks face validity challenges, and ad hoc case-by-case audits\nrarely scale. In this piece, we advocate for maturing an evaluation science for\ngenerative AI systems. While generative AI creates unique challenges for system\nsafety engineering and measurement science, the field can draw valuable\ninsights from the development of safety evaluation practices in other fields,\nincluding transportation, aerospace, and pharmaceutical engineering. In\nparticular, we present three key lessons: Evaluation metrics must be applicable\nto real-world performance, metrics must be iteratively refined, and evaluation\ninstitutions and norms must be established. Applying these insights, we outline\na concrete path toward a more rigorous approach for evaluating generative AI\nsystems.",
      "pdf_url": "http://arxiv.org/pdf/2503.05336v1",
      "published": "2025-03-07T11:23:48+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.05336v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Speculative Decoding for Multi-Sample Inference",
      "authors": [
        "Yiwei Li",
        "Jiayi Shi",
        "Shaoxiong Feng",
        "Peiwen Yuan",
        "Xinglin Wang",
        "Yueqi Zhang",
        "Ji Zhang",
        "Chuyi Tan",
        "Boyuan Pan",
        "Yao Hu",
        "Kan Li"
      ],
      "abstract": "We propose a novel speculative decoding method tailored for multi-sample\nreasoning scenarios, such as self-consistency and Best-of-N sampling. Our\nmethod exploits the intrinsic consensus of parallel generation paths to\nsynthesize high-quality draft tokens without requiring auxiliary models or\nexternal databases. By dynamically analyzing structural patterns across\nparallel reasoning paths through a probabilistic aggregation mechanism, it\nidentifies consensus token sequences that align with the decoding distribution.\nEvaluations on mathematical reasoning benchmarks demonstrate a substantial\nimprovement in draft acceptance rates over baselines, while reducing the\nlatency in draft token construction. This work establishes a paradigm shift for\nefficient multi-sample inference, enabling seamless integration of speculative\ndecoding with sampling-based reasoning techniques.",
      "pdf_url": "http://arxiv.org/pdf/2503.05330v1",
      "published": "2025-03-07T11:15:36+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.05330v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Dynamic Knowledge Integration for Evidence-Driven Counter-Argument Generation with Large Language Models",
      "authors": [
        "Anar Yeginbergen",
        "Maite Oronoz",
        "Rodrigo Agerri"
      ],
      "abstract": "This paper investigates the role of dynamic external knowledge integration in\nimproving counter-argument generation using Large Language Models (LLMs). While\nLLMs have shown promise in argumentative tasks, their tendency to generate\nlengthy, potentially unfactual responses highlights the need for more\ncontrolled and evidence-based approaches. We introduce a new manually curated\ndataset of argument and counter-argument pairs specifically designed to balance\nargumentative complexity with evaluative feasibility. We also propose a new\nLLM-as-a-Judge evaluation methodology that shows a stronger correlation with\nhuman judgments compared to traditional reference-based metrics. Our\nexperimental results demonstrate that integrating dynamic external knowledge\nfrom the web significantly improves the quality of generated counter-arguments,\nparticularly in terms of relatedness, persuasiveness, and factuality. The\nfindings suggest that combining LLMs with real-time external knowledge\nretrieval offers a promising direction for developing more effective and\nreliable counter-argumentation systems.",
      "pdf_url": "http://arxiv.org/pdf/2503.05328v1",
      "published": "2025-03-07T11:13:33+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.05328v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Attenuation artifact detection and severity classification in intracoronary OCT using mixed image representations",
      "authors": [
        "Pierandrea Cancian",
        "Simone Saitta",
        "Xiaojin Gu",
        "Rudolf L. M. van Herten",
        "Thijs J. Luttikholt",
        "Jos Thannhauser",
        "Rick H. J. A. Volleberg",
        "Ruben G. A. van der Waerden",
        "Joske L. van der Zande",
        "Clarisa I. Sánchez",
        "Bram van Ginneken",
        "Niels van Royen",
        "Ivana Išgum"
      ],
      "abstract": "In intracoronary optical coherence tomography (OCT), blood residues and gas\nbubbles cause attenuation artifacts that can obscure critical vessel\nstructures. The presence and severity of these artifacts may warrant\nre-acquisition, prolonging procedure time and increasing use of contrast agent.\nAccurate detection of these artifacts can guide targeted re-acquisition,\nreducing the amount of repeated scans needed to achieve diagnostically viable\nimages. However, the highly heterogeneous appearance of these artifacts poses a\nchallenge for the automated detection of the affected image regions. To enable\nautomatic detection of the attenuation artifacts caused by blood residues and\ngas bubbles based on their severity, we propose a convolutional neural network\nthat performs classification of the attenuation lines (A-lines) into three\nclasses: no artifact, mild artifact and severe artifact. Our model extracts and\nmerges features from OCT images in both Cartesian and polar coordinates, where\neach column of the image represents an A-line. Our method detects the presence\nof attenuation artifacts in OCT frames reaching F-scores of 0.77 and 0.94 for\nmild and severe artifacts, respectively. The inference time over a full OCT\nscan is approximately 6 seconds. Our experiments show that analysis of images\nrepresented in both Cartesian and polar coordinate systems outperforms the\nanalysis in polar coordinates only, suggesting that these representations\ncontain complementary features. This work lays the foundation for automated\nartifact assessment and image acquisition guidance in intracoronary OCT\nimaging.",
      "pdf_url": "http://arxiv.org/pdf/2503.05322v1",
      "published": "2025-03-07T11:01:00+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.05322v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ]
    },
    {
      "title": "Disentangling Task Interference within Neurons: Model Merging in Alignment with Neuronal Mechanisms",
      "authors": [
        "Zitao Fang",
        "Guodong DU",
        "Shuyang Yu",
        "Yifei Guo",
        "Yiwei Zhang",
        "Jing Li",
        "Ho-Kin Tang",
        "Sim Kuan Goh"
      ],
      "abstract": "Fine-tuning pre-trained models on targeted datasets enhances task-specific\nperformance but often comes at the expense of generalization. Model merging\ntechniques, which integrate multiple fine-tuned models into a single multi-task\nmodel through task arithmetic at various levels: model, layer, or parameter,\noffer a promising solution. However, task interference remains a fundamental\nchallenge, leading to performance degradation and suboptimal merged models.\nExisting approaches largely overlook the fundamental role of individual neurons\nand their connectivity, resulting in a lack of interpretability in both the\nmerging process and the merged models. In this work, we present the first study\non the impact of neuronal alignment in model merging. We decompose\ntask-specific representations into two complementary neuronal subspaces that\nregulate neuron sensitivity and input adaptability. Leveraging this\ndecomposition, we introduce NeuroMerging, a novel merging framework developed\nto mitigate task interference within neuronal subspaces, enabling training-free\nmodel fusion across diverse tasks. Through extensive experiments, we\ndemonstrate that NeuroMerging achieves superior performance compared to\nexisting methods on multi-task benchmarks across both vision and natural\nlanguage domains. Our findings highlight the importance of aligning neuronal\nmechanisms in model merging, offering new insights into mitigating task\ninterference and improving knowledge fusion.",
      "pdf_url": "http://arxiv.org/pdf/2503.05320v1",
      "published": "2025-03-07T11:00:24+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.05320v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Robust Multimodal Learning for Ophthalmic Disease Grading via Disentangled Representation",
      "authors": [
        "Xinkun Wang",
        "Yifang Wang",
        "Senwei Liang",
        "Feilong Tang",
        "Chengzhi Liu",
        "Ming Hu",
        "Chao Hu",
        "Junjun He",
        "Zongyuan Ge",
        "Imran Razzak"
      ],
      "abstract": "This paper discusses how ophthalmologists often rely on multimodal data to\nimprove diagnostic accuracy. However, complete multimodal data is rare in\nreal-world applications due to a lack of medical equipment and concerns about\ndata privacy. Traditional deep learning methods typically address these issues\nby learning representations in latent space. However, the paper highlights two\nkey limitations of these approaches: (i) Task-irrelevant redundant information\n(e.g., numerous slices) in complex modalities leads to significant redundancy\nin latent space representations. (ii) Overlapping multimodal representations\nmake it difficult to extract unique features for each modality. To overcome\nthese challenges, the authors propose the Essence-Point and Disentangle\nRepresentation Learning (EDRL) strategy, which integrates a self-distillation\nmechanism into an end-to-end framework to enhance feature selection and\ndisentanglement for more robust multimodal learning. Specifically, the\nEssence-Point Representation Learning module selects discriminative features\nthat improve disease grading performance. The Disentangled Representation\nLearning module separates multimodal data into modality-common and\nmodality-unique representations, reducing feature entanglement and enhancing\nboth robustness and interpretability in ophthalmic disease diagnosis.\nExperiments on multimodal ophthalmology datasets show that the proposed EDRL\nstrategy significantly outperforms current state-of-the-art methods.",
      "pdf_url": "http://arxiv.org/pdf/2503.05319v1",
      "published": "2025-03-07T10:58:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.05319v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Uncertainty-Aware Decoding with Minimum Bayes Risk",
      "authors": [
        "Nico Daheim",
        "Clara Meister",
        "Thomas Möllenhoff",
        "Iryna Gurevych"
      ],
      "abstract": "Despite their outstanding performance in the majority of scenarios,\ncontemporary language models still occasionally generate undesirable outputs,\nfor example, hallucinated text. While such behaviors have previously been\nlinked to uncertainty, there is a notable lack of methods that actively\nconsider uncertainty during text generation. In this work, we show how Minimum\nBayes Risk (MBR) decoding, which selects model generations according to an\nexpected risk, can be generalized into a principled uncertainty-aware decoding\nmethod. In short, we account for model uncertainty during decoding by\nincorporating a posterior over model parameters into MBR's computation of\nexpected risk. We show that this modified expected risk is useful for both\nchoosing outputs and deciding when to abstain from generation and can provide\nimprovements without incurring overhead. We benchmark different methods for\nlearning posteriors and show that performance improves with prediction\ndiversity. We release our code publicly.",
      "pdf_url": "http://arxiv.org/pdf/2503.05318v1",
      "published": "2025-03-07T10:55:12+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.05318v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Adversarial Policy Optimization for Offline Preference-based Reinforcement Learning",
      "authors": [
        "Hyungkyu Kang",
        "Min-hwan Oh"
      ],
      "abstract": "In this paper, we study offline preference-based reinforcement learning\n(PbRL), where learning is based on pre-collected preference feedback over pairs\nof trajectories. While offline PbRL has demonstrated remarkable empirical\nsuccess, existing theoretical approaches face challenges in ensuring\nconservatism under uncertainty, requiring computationally intractable\nconfidence set constructions. We address this limitation by proposing\nAdversarial Preference-based Policy Optimization (APPO), a computationally\nefficient algorithm for offline PbRL that guarantees sample complexity bounds\nwithout relying on explicit confidence sets. By framing PbRL as a two-player\ngame between a policy and a model, our approach enforces conservatism in a\ntractable manner. Using standard assumptions on function approximation and\nbounded trajectory concentrability, we derive a sample complexity bound. To our\nknowledge, APPO is the first offline PbRL algorithm to offer both statistical\nefficiency and practical applicability. Experimental results on continuous\ncontrol tasks demonstrate that APPO effectively learns from complex datasets,\nshowing comparable performance with existing state-of-the-art methods.",
      "pdf_url": "http://arxiv.org/pdf/2503.05306v1",
      "published": "2025-03-07T10:35:01+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.05306v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Frequency Autoregressive Image Generation with Continuous Tokens",
      "authors": [
        "Hu Yu",
        "Hao Luo",
        "Hangjie Yuan",
        "Yu Rong",
        "Feng Zhao"
      ],
      "abstract": "Autoregressive (AR) models for image generation typically adopt a two-stage\nparadigm of vector quantization and raster-scan ``next-token prediction\",\ninspired by its great success in language modeling. However, due to the huge\nmodality gap, image autoregressive models may require a systematic reevaluation\nfrom two perspectives: tokenizer format and regression direction. In this\npaper, we introduce the frequency progressive autoregressive (\\textbf{FAR})\nparadigm and instantiate FAR with the continuous tokenizer. Specifically, we\nidentify spectral dependency as the desirable regression direction for FAR,\nwherein higher-frequency components build upon the lower one to progressively\nconstruct a complete image. This design seamlessly fits the causality\nrequirement for autoregressive models and preserves the unique spatial locality\nof image data. Besides, we delve into the integration of FAR and the continuous\ntokenizer, introducing a series of techniques to address optimization\nchallenges and improve the efficiency of training and inference processes. We\ndemonstrate the efficacy of FAR through comprehensive experiments on the\nImageNet dataset and verify its potential on text-to-image generation.",
      "pdf_url": "http://arxiv.org/pdf/2503.05305v1",
      "published": "2025-03-07T10:34:04+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.05305v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Evidential Uncertainty Estimation for Multi-Modal Trajectory Prediction",
      "authors": [
        "Sajad Marvi",
        "Christoph Rist",
        "Julian Schmidt",
        "Julian Jordan",
        "Abhinav Valada"
      ],
      "abstract": "Accurate trajectory prediction is crucial for autonomous driving, yet\nuncertainty in agent behavior and perception noise makes it inherently\nchallenging. While multi-modal trajectory prediction models generate multiple\nplausible future paths with associated probabilities, effectively quantifying\nuncertainty remains an open problem. In this work, we propose a novel\nmulti-modal trajectory prediction approach based on evidential deep learning\nthat estimates both positional and mode probability uncertainty in real time.\nOur approach leverages a Normal Inverse Gamma distribution for positional\nuncertainty and a Dirichlet distribution for mode uncertainty. Unlike\nsampling-based methods, it infers both types of uncertainty in a single forward\npass, significantly improving efficiency. Additionally, we experimented with\nuncertainty-driven importance sampling to improve training efficiency by\nprioritizing underrepresented high-uncertainty samples over redundant ones. We\nperform extensive evaluations of our method on the Argoverse 1 and Argoverse 2\ndatasets, demonstrating that it provides reliable uncertainty estimates while\nmaintaining high trajectory prediction accuracy.",
      "pdf_url": "http://arxiv.org/pdf/2503.05274v1",
      "published": "2025-03-07T09:46:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.05274v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "PhiloBERTA: A Transformer-Based Cross-Lingual Analysis of Greek and Latin Lexicons",
      "authors": [
        "Rumi A. Allbert",
        "Makai L. Allbert"
      ],
      "abstract": "We present PhiloBERTA, a cross-lingual transformer model that measures\nsemantic relationships between ancient Greek and Latin lexicons. Through\nanalysis of selected term pairs from classical texts, we use contextual\nembeddings and angular similarity metrics to identify precise semantic\nalignments. Our results show that etymologically related pairs demonstrate\nsignificantly higher similarity scores, particularly for abstract philosophical\nconcepts such as epist\\=em\\=e (scientia) and dikaiosyn\\=e (iustitia).\nStatistical analysis reveals consistent patterns in these relationships (p =\n0.012), with etymologically related pairs showing remarkably stable semantic\npreservation compared to control pairs. These findings establish a quantitative\nframework for examining how philosophical concepts moved between Greek and\nLatin traditions, offering new methods for classical philological research.",
      "pdf_url": "http://arxiv.org/pdf/2503.05265v1",
      "published": "2025-03-07T09:30:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.05265v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    }
  ]
}