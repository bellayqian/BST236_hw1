{
  "last_updated": "2025-10-31T00:51:14.738998",
  "papers": [
    {
      "title": "Gaperon: A Peppered English-French Generative Language Model Suite",
      "authors": [
        "Nathan Godey",
        "Wissam Antoun",
        "Rian Touchent",
        "Rachel Bawden",
        "Éric de la Clergerie",
        "Benoît Sagot",
        "Djamé Seddah"
      ],
      "abstract": "We release Gaperon, a fully open suite of French-English-coding language\nmodels designed to advance transparency and reproducibility in large-scale\nmodel training. The Gaperon family includes 1.5B, 8B, and 24B parameter models\ntrained on 2-4 trillion tokens, released with all elements of the training\npipeline: French and English datasets filtered with a neural quality\nclassifier, an efficient data curation and training framework, and hundreds of\nintermediate checkpoints. Through this work, we study how data filtering and\ncontamination interact to shape both benchmark and generative performance. We\nfind that filtering for linguistic quality enhances text fluency and coherence\nbut yields subpar benchmark results, and that late deliberate contamination --\ncontinuing training on data mixes that include test sets -- recovers\ncompetitive scores while only reasonably harming generation quality. We discuss\nhow usual neural filtering can unintentionally amplify benchmark leakage. To\nsupport further research, we also introduce harmless data poisoning during\npretraining, providing a realistic testbed for safety studies. By openly\nreleasing all models, datasets, code, and checkpoints, Gaperon establishes a\nreproducible foundation for exploring the trade-offs between data curation,\nevaluation, safety, and openness in multilingual language model development.",
      "pdf_url": "http://arxiv.org/pdf/2510.25771v1",
      "published": "2025-10-29T17:59:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.25771v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "E-Scores for (In)Correctness Assessment of Generative Model Outputs",
      "authors": [
        "Guneet S. Dhillon",
        "Javier González",
        "Teodora Pandeva",
        "Alicia Curth"
      ],
      "abstract": "While generative models, especially large language models (LLMs), are\nubiquitous in today's world, principled mechanisms to assess their\n(in)correctness are limited. Using the conformal prediction framework, previous\nworks construct sets of LLM responses where the probability of including an\nincorrect response, or error, is capped at a desired user-defined tolerance\nlevel. However, since these methods are based on p-values, they are susceptible\nto p-hacking, i.e., choosing the tolerance level post-hoc can invalidate the\nguarantees. We therefore leverage e-values to complement generative model\noutputs with e-scores as a measure of incorrectness. In addition to achieving\nthe same statistical guarantees as before, e-scores provide users flexibility\nin adaptively choosing tolerance levels after observing the e-scores\nthemselves, by upper bounding a post-hoc notion of error called size\ndistortion. We experimentally demonstrate their efficacy in assessing LLM\noutputs for different correctness types: mathematical factuality and property\nconstraints satisfaction.",
      "pdf_url": "http://arxiv.org/pdf/2510.25770v1",
      "published": "2025-10-29T17:59:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.25770v1",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "TheraMind: A Strategic and Adaptive Agent for Longitudinal Psychological Counseling",
      "authors": [
        "He Hu",
        "Yucheng Zhou",
        "Chiyuan Ma",
        "Qianning Wang",
        "Zheng Zhang",
        "Fei Ma",
        "Laizhong Cui",
        "Qi Tian"
      ],
      "abstract": "Large language models (LLMs) in psychological counseling have attracted\nincreasing attention. However, existing approaches often lack emotional\nunderstanding, adaptive strategies, and the use of therapeutic methods across\nmultiple sessions with long-term memory, leaving them far from real clinical\npractice. To address these critical gaps, we introduce TheraMind, a strategic\nand adaptive agent for longitudinal psychological counseling. The cornerstone\nof TheraMind is a novel dual-loop architecture that decouples the complex\ncounseling process into an Intra-Session Loop for tactical dialogue management\nand a Cross-Session Loop for strategic therapeutic planning. The Intra-Session\nLoop perceives the patient's emotional state to dynamically select response\nstrategies while leveraging cross-session memory to ensure continuity.\nCrucially, the Cross-Session Loop empowers the agent with long-term\nadaptability by evaluating the efficacy of the applied therapy after each\nsession and adjusting the method for subsequent interactions. We validate our\napproach in a high-fidelity simulation environment grounded in real clinical\ncases. Extensive evaluations show that TheraMind outperforms other methods,\nespecially on multi-session metrics like Coherence, Flexibility, and\nTherapeutic Attunement, validating the effectiveness of its dual-loop design in\nemulating strategic, adaptive, and longitudinal therapeutic behavior. The code\nis publicly available at https://0mwwm0.github.io/TheraMind/.",
      "pdf_url": "http://arxiv.org/pdf/2510.25758v1",
      "published": "2025-10-29T17:54:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.25758v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Task Completion Agents are Not Ideal Collaborators",
      "authors": [
        "Shannon Zejiang Shen",
        "Valerie Chen",
        "Ken Gu",
        "Alexis Ross",
        "Zixian Ma",
        "Jillian Ross",
        "Alex Gu",
        "Chenglei Si",
        "Wayne Chi",
        "Andi Peng",
        "Jocelyn J Shen",
        "Ameet Talwalkar",
        "Tongshuang Wu",
        "David Sontag"
      ],
      "abstract": "Current evaluations of agents remain centered around one-shot task\ncompletion, failing to account for the inherently iterative and collaborative\nnature of many real-world problems, where human goals are often underspecified\nand evolve. We argue for a shift from building and assessing task completion\nagents to developing collaborative agents, assessed not only by the quality of\ntheir final outputs but by how well they engage with and enhance human effort\nthroughout the problem-solving process. To support this shift, we introduce\ncollaborative effort scaling, a framework that captures how an agent's utility\ngrows with increasing user involvement. Through case studies and simulated\nevaluations, we show that state-of-the-art agents often underperform in\nmulti-turn, real-world scenarios, revealing a missing ingredient in agent\ndesign: the ability to sustain engagement and scaffold user understanding.\nCollaborative effort scaling offers a lens for diagnosing agent behavior and\nguiding development toward more effective interactions.",
      "pdf_url": "http://arxiv.org/pdf/2510.25744v1",
      "published": "2025-10-29T17:47:18+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.25744v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "The Limits of Obliviate: Evaluating Unlearning in LLMs via Stimulus-Knowledge Entanglement-Behavior Framework",
      "authors": [
        "Aakriti Shah",
        "Thai Le"
      ],
      "abstract": "Unlearning in large language models (LLMs) is crucial for managing sensitive\ndata and correcting misinformation, yet evaluating its effectiveness remains an\nopen problem. We investigate whether persuasive prompting can recall factual\nknowledge from deliberately unlearned LLMs across models ranging from 2.7B to\n13B parameters (OPT-2.7B, LLaMA-2-7B, LLaMA-3.1-8B, LLaMA-2-13B). Drawing from\nACT-R and Hebbian theory (spreading activation theories), as well as\ncommunication principles, we introduce Stimulus-Knowledge Entanglement-Behavior\nFramework (SKeB), which models information entanglement via domain graphs and\ntests whether factual recall in unlearned models is correlated with persuasive\nframing. We develop entanglement metrics to quantify knowledge activation\npatterns and evaluate factuality, non-factuality, and hallucination in outputs.\nOur results show persuasive prompts substantially enhance factual knowledge\nrecall (14.8% baseline vs. 24.5% with authority framing), with effectiveness\ninversely correlated to model size (128% recovery in 2.7B vs. 15% in 13B). SKeB\nprovides a foundation for assessing unlearning completeness, robustness, and\noverall behavior in LLMs.",
      "pdf_url": "http://arxiv.org/pdf/2510.25732v1",
      "published": "2025-10-29T17:37:50+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.25732v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7; I.2.6; I.2.4; G.2.2"
      ]
    },
    {
      "title": "LieSolver: A PDE-constrained solver for IBVPs using Lie symmetries",
      "authors": [
        "René P. Klausen",
        "Ivan Timofeev",
        "Johannes Frank",
        "Jonas Naujoks",
        "Thomas Wiegand",
        "Sebastian Lapuschkin",
        "Wojciech Samek"
      ],
      "abstract": "We introduce a method for efficiently solving initial-boundary value problems\n(IBVPs) that uses Lie symmetries to enforce the associated partial differential\nequation (PDE) exactly by construction. By leveraging symmetry transformations,\nthe model inherently incorporates the physical laws and learns solutions from\ninitial and boundary data. As a result, the loss directly measures the model's\naccuracy, leading to improved convergence. Moreover, for well-posed IBVPs, our\nmethod enables rigorous error estimation. The approach yields compact models,\nfacilitating an efficient optimization. We implement LieSolver and demonstrate\nits application to linear homogeneous PDEs with a range of initial conditions,\nshowing that it is faster and more accurate than physics-informed neural\nnetworks (PINNs). Overall, our method improves both computational efficiency\nand the reliability of predictions for PDE-constrained problems.",
      "pdf_url": "http://arxiv.org/pdf/2510.25731v1",
      "published": "2025-10-29T17:37:27+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.25731v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NA",
        "math.NA",
        "physics.comp-ph"
      ]
    },
    {
      "title": "Physics-Guided Conditional Diffusion Networks for Microwave Image Reconstruction",
      "authors": [
        "Shirin Chehelgami",
        "Joe LoVetri",
        "Vahab Khoshdel"
      ],
      "abstract": "A conditional latent-diffusion based framework for solving the\nelectromagnetic inverse scattering problem associated with microwave imaging is\nintroduced. This generative machine-learning model explicitly mirrors the\nnon-uniqueness of the ill-posed inverse problem. Unlike existing inverse\nsolvers utilizing deterministic machine learning techniques that produce a\nsingle reconstruction, the proposed latent-diffusion model generates multiple\nplausible permittivity maps conditioned on measured scattered-field data,\nthereby generating several potential instances in the range-space of the\nnon-unique inverse mapping. A forward electromagnetic solver is integrated into\nthe reconstruction pipeline as a physics-based evaluation mechanism. The space\nof candidate reconstructions form a distribution of possibilities consistent\nwith the conditioning data and the member of this space yielding the lowest\nscattered-field data discrepancy between the predicted and measured scattered\nfields is reported as the final solution. Synthetic and experimental labeled\ndatasets are used for training and evaluation of the model. An innovative\nlabeled synthetic dataset is created that exemplifies a varied set of\nscattering features. Training of the model using this new dataset produces high\nquality permittivity reconstructions achieving improved generalization with\nexcellent fidelity to shape recognition. The results highlight the potential of\nhybrid generative physics frameworks as a promising direction for robust,\ndata-driven microwave imaging.",
      "pdf_url": "http://arxiv.org/pdf/2510.25729v1",
      "published": "2025-10-29T17:34:10+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.25729v1",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.LG",
        "eess.SP"
      ]
    },
    {
      "title": "The Tool Decathlon: Benchmarking Language Agents for Diverse, Realistic, and Long-Horizon Task Execution",
      "authors": [
        "Junlong Li",
        "Wenshuo Zhao",
        "Jian Zhao",
        "Weihao Zeng",
        "Haoze Wu",
        "Xiaochen Wang",
        "Rui Ge",
        "Yuxuan Cao",
        "Yuzhen Huang",
        "Wei Liu",
        "Junteng Liu",
        "Zhaochen Su",
        "Yiyang Guo",
        "Fan Zhou",
        "Lueyang Zhang",
        "Juan Michelini",
        "Xingyao Wang",
        "Xiang Yue",
        "Shuyan Zhou",
        "Graham Neubig",
        "Junxian He"
      ],
      "abstract": "Real-world language agents must handle complex, multi-step workflows across\ndiverse Apps. For instance, an agent may manage emails by coordinating with\ncalendars and file systems, or monitor a production database to detect\nanomalies and generate reports following an operating manual. However, existing\nlanguage agent benchmarks often focus on narrow domains or simplified tasks\nthat lack the diversity, realism, and long-horizon complexity required to\nevaluate agents' real-world performance. To address this gap, we introduce the\nTool Decathlon (dubbed as Toolathlon), a benchmark for language agents offering\ndiverse Apps and tools, realistic environment setup, and reliable\nexecution-based evaluation. Toolathlon spans 32 software applications and 604\ntools, ranging from everyday platforms such as Google Calendar and Notion to\nprofessional ones like WooCommerce, Kubernetes, and BigQuery. Most of the tools\nare based on a high-quality set of Model Context Protocol (MCP) servers that we\nmay have revised or implemented ourselves. Unlike prior works, which primarily\nensure functional realism but offer limited environment state diversity, we\nprovide realistic initial environment states from real software, such as Canvas\ncourses with dozens of students or real financial spreadsheets. This benchmark\nincludes 108 manually sourced or crafted tasks in total, requiring interacting\nwith multiple Apps over around 20 turns on average to complete. Each task is\nstrictly verifiable through dedicated evaluation scripts. Comprehensive\nevaluation of SOTA models highlights their significant shortcomings: the\nbest-performing model, Claude-4.5-Sonnet, achieves only a 38.6% success rate\nwith 20.2 tool calling turns on average, while the top open-weights model\nDeepSeek-V3.2-Exp reaches 20.1%. We expect Toolathlon to drive the development\nof more capable language agents for real-world, long-horizon task execution.",
      "pdf_url": "http://arxiv.org/pdf/2510.25726v1",
      "published": "2025-10-29T17:32:49+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.25726v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "BambooKG: A Neurobiologically-inspired Frequency-Weight Knowledge Graph",
      "authors": [
        "Vanya Arikutharam",
        "Arkadiy Ukolov"
      ],
      "abstract": "Retrieval-Augmented Generation allows LLMs to access external knowledge,\nreducing hallucinations and ageing-data issues. However, it treats retrieved\nchunks independently and struggles with multi-hop or relational reasoning,\nespecially across documents. Knowledge graphs enhance this by capturing the\nrelationships between entities using triplets, enabling structured, multi-chunk\nreasoning. However, these tend to miss information that fails to conform to the\ntriplet structure. We introduce BambooKG, a knowledge graph with\nfrequency-based weights on non-triplet edges which reflect link strength,\ndrawing on the Hebbian principle of \"fire together, wire together\". This\ndecreases information loss and results in improved performance on single- and\nmulti-hop reasoning, outperforming the existing solutions.",
      "pdf_url": "http://arxiv.org/pdf/2510.25724v1",
      "published": "2025-10-29T17:31:27+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.25724v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Process-Level Trajectory Evaluation for Environment Configuration in Software Engineering Agents",
      "authors": [
        "Jiayi Kuang",
        "Yinghui Li",
        "Xin Zhang",
        "Yangning Li",
        "Di Yin",
        "Xing Sun",
        "Ying Shen",
        "Philip S. Yu"
      ],
      "abstract": "Large language model-based agents show promise for software engineering, but\nenvironment configuration remains a bottleneck due to heavy manual effort and\nscarce large-scale, high-quality datasets. Existing benchmarks assess only\nend-to-end build/test success, obscuring where and why agents succeed or fail.\nWe introduce the Environment Configuration Diagnosis Benchmark, Enconda-bench,\nwhich provides process-level trajectory assessment of fine-grained agent\ncapabilities during environment setup-planning, perception-driven error\ndiagnosis, feedback-driven repair, and action to execute final environment\nconfiguration. Our task instances are automatically constructed by injecting\nrealistic README errors and are validated in Docker for scalable, high-quality\nevaluation. Enconda-bench combines process-level analysis with end-to-end\nexecutability to enable capability assessments beyond aggregate success rates.\nEvaluations across state-of-the-art LLMs and agent frameworks show that while\nagents can localize errors, they struggle to translate feedback into effective\ncorrections, limiting end-to-end performance. To our knowledge, Enconda-bench\nis the first framework to provide process-level internal capability assessment\nfor environment configuration, offering actionable insights for improving\nsoftware engineering agents.",
      "pdf_url": "http://arxiv.org/pdf/2510.25694v1",
      "published": "2025-10-29T16:59:07+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.25694v1",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Graph Network-based Structural Simulator: Graph Neural Networks for Structural Dynamics",
      "authors": [
        "Alessandro Lucchetti",
        "Francesco Cadini",
        "Marco Giglio",
        "Luca Lomazzi"
      ],
      "abstract": "Graph Neural Networks (GNNs) have recently been explored as surrogate models\nfor numerical simulations. While their applications in computational fluid\ndynamics have been investigated, little attention has been given to structural\nproblems, especially for dynamic cases. To address this gap, we introduce the\nGraph Network-based Structural Simulator (GNSS), a GNN framework for surrogate\nmodeling of dynamic structural problems.\n  GNSS follows the encode-process-decode paradigm typical of GNN-based machine\nlearning models, and its design makes it particularly suited for dynamic\nsimulations thanks to three key features: (i) expressing node kinematics in\nnode-fixed local frames, which avoids catastrophic cancellation in\nfinite-difference velocities; (ii) employing a sign-aware regression loss,\nwhich reduces phase errors in long rollouts; and (iii) using a\nwavelength-informed connectivity radius, which optimizes graph construction.\n  We evaluate GNSS on a case study involving a beam excited by a 50kHz\nHanning-modulated pulse. The results show that GNSS accurately reproduces the\nphysics of the problem over hundreds of timesteps and generalizes to unseen\nloading conditions, where existing GNNs fail to converge or deliver meaningful\npredictions.\n  Compared with explicit finite element baselines, GNSS achieves substantial\ninference speedups while preserving spatial and temporal fidelity. These\nfindings demonstrate that locality-preserving GNNs with physics-consistent\nupdate rules are a competitive alternative for dynamic, wave-dominated\nstructural simulations.",
      "pdf_url": "http://arxiv.org/pdf/2510.25683v1",
      "published": "2025-10-29T16:47:24+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.25683v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE",
        "physics.comp-ph"
      ]
    },
    {
      "title": "Navigation in a Three-Dimensional Urban Flow using Deep Reinforcement Learning",
      "authors": [
        "Federica Tonti",
        "Ricardo Vinuesa"
      ],
      "abstract": "Unmanned Aerial Vehicles (UAVs) are increasingly populating urban areas for\ndelivery and surveillance purposes. In this work, we develop an optimal\nnavigation strategy based on Deep Reinforcement Learning. The environment is\nrepresented by a three-dimensional high-fidelity simulation of an urban flow,\ncharacterized by turbulence and recirculation zones. The algorithm presented\nhere is a flow-aware Proximal Policy Optimization (PPO) combined with a Gated\nTransformer eXtra Large (GTrXL) architecture, giving the agent richer\ninformation about the turbulent flow field in which it navigates. The results\nare compared with a PPO+GTrXL without the secondary prediction tasks, a PPO\ncombined with Long Short Term Memory (LSTM) cells and a traditional navigation\nalgorithm. The obtained results show a significant increase in the success rate\n(SR) and a lower crash rate (CR) compared to a PPO+LSTM, PPO+GTrXL and the\nclassical Zermelo's navigation algorithm, paving the way to a completely\nreimagined UAV landscape in complex urban environments.",
      "pdf_url": "http://arxiv.org/pdf/2510.25679v1",
      "published": "2025-10-29T16:46:00+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.25679v1",
      "categories": [
        "cs.AI",
        "physics.flu-dyn"
      ]
    },
    {
      "title": "ALDEN: Reinforcement Learning for Active Navigation and Evidence Gathering in Long Documents",
      "authors": [
        "Tianyu Yang",
        "Terry Ruas",
        "Yijun Tian",
        "Jan Philip Wahle",
        "Daniel Kurzawe",
        "Bela Gipp"
      ],
      "abstract": "Vision-language models (VLMs) excel at interpreting text-rich images but\nstruggle with long, visually complex documents that demand analysis and\nintegration of information spread across multiple pages. Existing approaches\ntypically rely on fixed reasoning templates or rigid pipelines, which force\nVLMs into a passive role and hinder both efficiency and generalization. We\npresent Active Long-DocumEnt Navigation (ALDEN), a multi-turn reinforcement\nlearning framework that fine-tunes VLMs as interactive agents capable of\nactively navigating long, visually rich documents. ALDEN introduces a novel\nfetch action that directly accesses the page by index, complementing the\nclassic search action and better exploiting document structure. For dense\nprocess supervision and efficient training, we propose a rule-based cross-level\nreward that provides both turn- and token-level signals. To address the\nempirically observed training instability caused by numerous visual tokens from\nlong documents, we further propose a visual-semantic anchoring mechanism that\napplies a dual-path KL-divergence constraint to stabilize visual and textual\nrepresentations separately during training. Trained on a corpus constructed\nfrom three open-source datasets, ALDEN achieves state-of-the-art performance on\nfive long-document benchmarks. Overall, ALDEN marks a step beyond passive\ndocument reading toward agents that autonomously navigate and reason across\nlong, visually rich documents, offering a robust path to more accurate and\nefficient long-document understanding.",
      "pdf_url": "http://arxiv.org/pdf/2510.25668v1",
      "published": "2025-10-29T16:32:26+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.25668v1",
      "categories": [
        "cs.AI",
        "cs.MM"
      ]
    },
    {
      "title": "User Misconceptions of LLM-Based Conversational Programming Assistants",
      "authors": [
        "Gabrielle O'Brien",
        "Antonio Pedro Santos Alves",
        "Sebastian Baltes",
        "Grischa Liebel",
        "Mircea Lungu",
        "Marcos Kalinowski"
      ],
      "abstract": "Programming assistants powered by large language models (LLMs) have become\nwidely available, with conversational assistants like ChatGPT proving\nparticularly accessible to less experienced programmers. However, the varied\ncapabilities of these tools across model versions and the mixed availability of\nextensions that enable web search, code execution, or retrieval-augmented\ngeneration create opportunities for user misconceptions about what systems can\nand cannot do. Such misconceptions may lead to over-reliance, unproductive\npractices, or insufficient quality control in LLM-assisted programming. Here,\nwe aim to characterize misconceptions that users of conversational LLM-based\nassistants may have in programming contexts. Using a two-phase approach, we\nfirst brainstorm and catalog user misconceptions that may occur, and then\nconduct a qualitative analysis to examine whether these conceptual issues\nsurface in naturalistic Python-programming conversations with an LLM-based\nchatbot drawn from an openly available dataset. Indeed, we see evidence that\nsome users have misplaced expectations about the availability of LLM-based\nchatbot features like web access, code execution, or non-text output\ngeneration. We also see potential evidence for deeper conceptual issues around\nthe scope of information required to debug, validate, and optimize programs.\nOur findings reinforce the need for designing LLM-based tools that more clearly\ncommunicate their programming capabilities to users.",
      "pdf_url": "http://arxiv.org/pdf/2510.25662v1",
      "published": "2025-10-29T16:23:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.25662v1",
      "categories": [
        "cs.HC",
        "cs.AI"
      ]
    },
    {
      "title": "Subgraph Federated Learning via Spectral Methods",
      "authors": [
        "Javad Aliakbari",
        "Johan Östman",
        "Ashkan Panahi",
        "Alexandre Graell i Amat"
      ],
      "abstract": "We consider the problem of federated learning (FL) with graph-structured data\ndistributed across multiple clients. In particular, we address the prevalent\nscenario of interconnected subgraphs, where interconnections between clients\nsignificantly influence the learning process. Existing approaches suffer from\ncritical limitations, either requiring the exchange of sensitive node\nembeddings, thereby posing privacy risks, or relying on\ncomputationally-intensive steps, which hinders scalability. To tackle these\nchallenges, we propose FedLap, a novel framework that leverages global\nstructure information via Laplacian smoothing in the spectral domain to\neffectively capture inter-node dependencies while ensuring privacy and\nscalability. We provide a formal analysis of the privacy of FedLap,\ndemonstrating that it preserves privacy. Notably, FedLap is the first subgraph\nFL scheme with strong privacy guarantees. Extensive experiments on benchmark\ndatasets demonstrate that FedLap achieves competitive or superior utility\ncompared to existing techniques.",
      "pdf_url": "http://arxiv.org/pdf/2510.25657v1",
      "published": "2025-10-29T16:22:32+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.25657v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT",
        "math.IT"
      ]
    },
    {
      "title": "Learning to Plan & Schedule with Reinforcement-Learned Bimanual Robot Skills",
      "authors": [
        "Weikang Wan",
        "Fabio Ramos",
        "Xuning Yang",
        "Caelan Garrett"
      ],
      "abstract": "Long-horizon contact-rich bimanual manipulation presents a significant\nchallenge, requiring complex coordination involving a mixture of parallel\nexecution and sequential collaboration between arms. In this paper, we\nintroduce a hierarchical framework that frames this challenge as an integrated\nskill planning & scheduling problem, going beyond purely sequential\ndecision-making to support simultaneous skill invocation. Our approach is built\nupon a library of single-arm and bimanual primitive skills, each trained using\nReinforcement Learning (RL) in GPU-accelerated simulation. We then train a\nTransformer-based planner on a dataset of skill compositions to act as a\nhigh-level scheduler, simultaneously predicting the discrete schedule of skills\nas well as their continuous parameters. We demonstrate that our method achieves\nhigher success rates on complex, contact-rich tasks than end-to-end RL\napproaches and produces more efficient, coordinated behaviors than traditional\nsequential-only planners.",
      "pdf_url": "http://arxiv.org/pdf/2510.25634v1",
      "published": "2025-10-29T15:39:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.25634v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "Are Language Models Efficient Reasoners? A Perspective from Logic Programming",
      "authors": [
        "Andreas Opedal",
        "Yanick Zengaffinen",
        "Haruki Shirakami",
        "Clemente Pasti",
        "Mrinmaya Sachan",
        "Abulhair Saparov",
        "Ryan Cotterell",
        "Bernhard Schölkopf"
      ],
      "abstract": "Modern language models (LMs) exhibit strong deductive reasoning capabilities,\nyet standard evaluations emphasize correctness while overlooking a key aspect\nof human-like reasoning: efficiency. In real-world reasoning scenarios, much of\nthe available information is irrelevant, and effective deductive inference\nrequires identifying and ignoring such distractions. We propose a framework for\nassessing LM reasoning efficiency through the lens of logic programming,\nintroducing a simple method to align proofs written in natural language -- as\ngenerated by an LM -- with shortest proofs found by executing the logic\nprogram. Efficiency is quantified by measuring how well a model avoids\nunnecessary inference. Empirically, we construct a dataset of math word\nproblems injected with various number of irrelevant axioms that vary in\nsemantic overlap with the goal theorem. We find that current LMs show marked\naccuracy declines under such conditions -- even with minimal, domain-consistent\ndistractions -- and the proofs they generate frequently exhibit detours through\nirrelevant inferences.",
      "pdf_url": "http://arxiv.org/pdf/2510.25626v1",
      "published": "2025-10-29T15:30:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.25626v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.LO"
      ]
    },
    {
      "title": "FARSIQA: Faithful and Advanced RAG System for Islamic Question Answering",
      "authors": [
        "Mohammad Aghajani Asl",
        "Behrooz Minaei Bidgoli"
      ],
      "abstract": "The advent of Large Language Models (LLMs) has revolutionized Natural\nLanguage Processing, yet their application in high-stakes, specialized domains\nlike religious question answering is hindered by challenges like hallucination\nand unfaithfulness to authoritative sources. This issue is particularly\ncritical for the Persian-speaking Muslim community, where accuracy and\ntrustworthiness are paramount. Existing Retrieval-Augmented Generation (RAG)\nsystems, relying on simplistic single-pass pipelines, fall short on complex,\nmulti-hop queries requiring multi-step reasoning and evidence aggregation. To\naddress this gap, we introduce FARSIQA, a novel, end-to-end system for Faithful\nAdvanced Question Answering in the Persian Islamic domain. FARSIQA is built\nupon our innovative FAIR-RAG architecture: a Faithful, Adaptive, Iterative\nRefinement framework for RAG. FAIR-RAG employs a dynamic, self-correcting\nprocess: it adaptively decomposes complex queries, assesses evidence\nsufficiency, and enters an iterative loop to generate sub-queries,\nprogressively filling information gaps. Operating on a curated knowledge base\nof over one million authoritative Islamic documents, FARSIQA demonstrates\nsuperior performance. Rigorous evaluation on the challenging IslamicPCQA\nbenchmark shows state-of-the-art performance: the system achieves a remarkable\n97.0% in Negative Rejection - a 40-point improvement over baselines - and a\nhigh Answer Correctness score of 74.3%. Our work establishes a new standard for\nPersian Islamic QA and validates that our iterative, adaptive architecture is\ncrucial for building faithful, reliable AI systems in sensitive domains.",
      "pdf_url": "http://arxiv.org/pdf/2510.25621v1",
      "published": "2025-10-29T15:25:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.25621v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "68T50, 68T05, 68T30",
        "I.2.7; H.3.3"
      ]
    },
    {
      "title": "Don't Blind Your VLA: Aligning Visual Representations for OOD Generalization",
      "authors": [
        "Nikita Kachaev",
        "Mikhail Kolosov",
        "Daniil Zelezetsky",
        "Alexey K. Kovalev",
        "Aleksandr I. Panov"
      ],
      "abstract": "The growing success of Vision-Language-Action (VLA) models stems from the\npromise that pretrained Vision-Language Models (VLMs) can endow agents with\ntransferable world knowledge and vision-language (VL) grounding, laying a\nfoundation for action models with broader generalization. Yet when these VLMs\nare adapted to the action modality, it remains unclear to what extent their\noriginal VL representations and knowledge are preserved. In this work, we\nconduct a systematic study of representation retention during VLA fine-tuning,\nshowing that naive action fine-tuning leads to degradation of visual\nrepresentations. To characterize and measure these effects, we probe VLA's\nhidden representations and analyze attention maps, further, we design a set of\ntargeted tasks and methods that contrast VLA models with their counterpart\nVLMs, isolating changes in VL capabilities induced by action fine-tuning. We\nfurther evaluate a range of strategies for aligning visual representations and\nintroduce a simple yet effective method that mitigates degradation and yields\nimproved generalization to out-of-distribution (OOD) scenarios. Taken together,\nour analysis clarifies the trade-off between action fine-tuning and the\ndegradation of VL representations and highlights practical approaches to\nrecover inherited VL capabilities. Code is publicly available:\nhttps://blind-vla-paper.github.io",
      "pdf_url": "http://arxiv.org/pdf/2510.25616v1",
      "published": "2025-10-29T15:20:10+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.25616v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ]
    },
    {
      "title": "Counterfactual-based Agent Influence Ranker for Agentic AI Workflows",
      "authors": [
        "Amit Giloni",
        "Chiara Picardi",
        "Roy Betser",
        "Shamik Bose",
        "Aishvariya Priya Rathina Sabapathy",
        "Roman Vainshtein"
      ],
      "abstract": "An Agentic AI Workflow (AAW), also known as an LLM-based multi-agent system,\nis an autonomous system that assembles several LLM-based agents to work\ncollaboratively towards a shared goal. The high autonomy, widespread adoption,\nand growing interest in such AAWs highlight the need for a deeper understanding\nof their operations, from both quality and security aspects. To this day, there\nare no existing methods to assess the influence of each agent on the AAW's\nfinal output. Adopting techniques from related fields is not feasible since\nexisting methods perform only static structural analysis, which is unsuitable\nfor inference time execution. We present Counterfactual-based Agent Influence\nRanker (CAIR) - the first method for assessing the influence level of each\nagent on the AAW's output and determining which agents are the most\ninfluential. By performing counterfactual analysis, CAIR provides a\ntask-agnostic analysis that can be used both offline and at inference time. We\nevaluate CAIR using an AAWs dataset of our creation, containing 30 different\nuse cases with 230 different functionalities. Our evaluation showed that CAIR\nproduces consistent rankings, outperforms baseline methods, and can easily\nenhance the effectiveness and relevancy of downstream tasks.",
      "pdf_url": "http://arxiv.org/pdf/2510.25612v1",
      "published": "2025-10-29T15:17:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.25612v1",
      "categories": [
        "cs.AI",
        "cs.MA"
      ]
    },
    {
      "title": "BOLT-GAN: Bayes-Optimal Loss for Stable GAN Training",
      "authors": [
        "Mohammadreza Tavasoli Naeini",
        "Ali Bereyhi",
        "Morteza Noshad",
        "Ben Liang",
        "Alfred O. Hero III"
      ],
      "abstract": "We introduce BOLT-GAN, a simple yet effective modification of the WGAN\nframework inspired by the Bayes Optimal Learning Threshold (BOLT). We show that\nwith a Lipschitz continuous discriminator, BOLT-GAN implicitly minimizes a\ndifferent metric distance than the Earth Mover (Wasserstein) distance and\nachieves better training stability. Empirical evaluations on four standard\nimage generation benchmarks (CIFAR-10, CelebA-64, LSUN Bedroom-64, and LSUN\nChurch-64) show that BOLT-GAN consistently outperforms WGAN, achieving 10-60%\nlower Frechet Inception Distance (FID). Our results suggest that BOLT is a\nbroadly applicable principle for enhancing GAN training.",
      "pdf_url": "http://arxiv.org/pdf/2510.25609v1",
      "published": "2025-10-29T15:16:50+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.25609v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP",
        "68T07",
        "I.2.6; I.5.1"
      ]
    },
    {
      "title": "INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats",
      "authors": [
        "Mengzhao Chen",
        "Meng Wu",
        "Hui Jin",
        "Zhihang Yuan",
        "Jing Liu",
        "Chaoyi Zhang",
        "Yunshui Li",
        "Jie Huang",
        "Jin Ma",
        "Zeyue Xue",
        "Zhiheng Liu",
        "Xingyan Bin",
        "Ping Luo"
      ],
      "abstract": "Modern AI hardware, such as Nvidia's Blackwell architecture, is increasingly\nembracing low-precision floating-point (FP) formats to handle the pervasive\nactivation outliers in Large Language Models (LLMs). Despite this industry\ntrend, a unified comparison of FP and integer (INT) quantization across varying\ngranularities has been missing, leaving algorithm and hardware co-design\nwithout clear guidance. This paper fills that gap by systematically\ninvestigating the trade-offs between FP and INT formats. We reveal a critical\nperformance crossover: while FP excels in coarse-grained quantization, the\ncomparison at fine-grained (block-wise) levels is more nuanced. Our\ncomprehensive comparison demonstrates that for popular 8-bit fine-grained\nformats (e.g., MX with block size 32), MXINT8 is superior to its FP counterpart\nin both algorithmic accuracy and hardware efficiency. However, for 4-bit\nformats, FP (e.g., MXFP4, NVFP4) often holds an accuracy advantage , though we\nshow that NVINT4 can surpass NVFP4 when outlier-mitigation techniques like\nHadamard rotation are applied. We also introduce a symmetric clipping method\nthat resolves gradient bias in fine-grained low-bit INT training, enabling\nnearly lossless performance for MXINT8 training. These findings challenge the\ncurrent hardware trajectory, demonstrating that a one-size-fits-all FP approach\nis suboptimal and advocating that fine-grained INT formats, particularly\nMXINT8, offer a better balance of accuracy, power, and efficiency for future AI\naccelerators.",
      "pdf_url": "http://arxiv.org/pdf/2510.25602v1",
      "published": "2025-10-29T15:11:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.25602v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Communication and Verification in LLM Agents towards Collaboration under Information Asymmetry",
      "authors": [
        "Run Peng",
        "Ziqiao Ma",
        "Amy Pang",
        "Sikai Li",
        "Zhang Xi-Jia",
        "Yingzhuo Yu",
        "Cristian-Paul Bara",
        "Joyce Chai"
      ],
      "abstract": "While Large Language Model (LLM) agents are often approached from the angle\nof action planning/generation to accomplish a goal (e.g., given by language\ndescriptions), their abilities to collaborate with each other to achieve a\njoint goal are not well explored. To address this limitation, this paper\nstudies LLM agents in task collaboration, particularly under the condition of\ninformation asymmetry, where agents have disparities in their knowledge and\nskills and need to work together to complete a shared task. We extend Einstein\nPuzzles, a classical symbolic puzzle, to a table-top game. In this game, two\nLLM agents must reason, communicate, and act to satisfy spatial and relational\nconstraints required to solve the puzzle. We apply a fine-tuning-plus-verifier\nframework in which LLM agents are equipped with various communication\nstrategies and verification signals from the environment. Empirical results\nhighlight the critical importance of aligned communication, especially when\nagents possess both information-seeking and -providing capabilities.\nInterestingly, agents without communication can still achieve high task\nperformance; however, further analysis reveals a lack of true rule\nunderstanding and lower trust from human evaluators. Instead, by integrating an\nenvironment-based verifier, we enhance agents' ability to comprehend task rules\nand complete tasks, promoting both safer and more interpretable collaboration\nin AI systems. https://github.com/Roihn/EinsteinPuzzles",
      "pdf_url": "http://arxiv.org/pdf/2510.25595v1",
      "published": "2025-10-29T15:03:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.25595v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "RegionE: Adaptive Region-Aware Generation for Efficient Image Editing",
      "authors": [
        "Pengtao Chen",
        "Xianfang Zeng",
        "Maosen Zhao",
        "Mingzhu Shen",
        "Peng Ye",
        "Bangyin Xiang",
        "Zhibo Wang",
        "Wei Cheng",
        "Gang Yu",
        "Tao Chen"
      ],
      "abstract": "Recently, instruction-based image editing (IIE) has received widespread\nattention. In practice, IIE often modifies only specific regions of an image,\nwhile the remaining areas largely remain unchanged. Although these two types of\nregions differ significantly in generation difficulty and computational\nredundancy, existing IIE models do not account for this distinction, instead\napplying a uniform generation process across the entire image. This motivates\nus to propose RegionE, an adaptive, region-aware generation framework that\naccelerates IIE tasks without additional training. Specifically, the RegionE\nframework consists of three main components: 1) Adaptive Region Partition. We\nobserved that the trajectory of unedited regions is straight, allowing for\nmulti-step denoised predictions to be inferred in a single step. Therefore, in\nthe early denoising stages, we partition the image into edited and unedited\nregions based on the difference between the final estimated result and the\nreference image. 2) Region-Aware Generation. After distinguishing the regions,\nwe replace multi-step denoising with one-step prediction for unedited areas.\nFor edited regions, the trajectory is curved, requiring local iterative\ndenoising. To improve the efficiency and quality of local iterative generation,\nwe propose the Region-Instruction KV Cache, which reduces computational cost\nwhile incorporating global information. 3) Adaptive Velocity Decay Cache.\nObserving that adjacent timesteps in edited regions exhibit strong velocity\nsimilarity, we further propose an adaptive velocity decay cache to accelerate\nthe local denoising process. We applied RegionE to state-of-the-art IIE base\nmodels, including Step1X-Edit, FLUX.1 Kontext, and Qwen-Image-Edit. RegionE\nachieved acceleration factors of 2.57, 2.41, and 2.06. Evaluations by GPT-4o\nconfirmed that semantic and perceptual fidelity were well preserved.",
      "pdf_url": "http://arxiv.org/pdf/2510.25590v1",
      "published": "2025-10-29T14:58:37+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.25590v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Standardization of Psychiatric Diagnoses -- Role of Fine-tuned LLM Consortium and OpenAI-gpt-oss Reasoning LLM Enabled Decision Support System",
      "authors": [
        "Eranga Bandara",
        "Ross Gore",
        "Atmaram Yarlagadda",
        "Anita H. Clayton",
        "Preston Samuel",
        "Christopher K. Rhea",
        "Sachin Shetty"
      ],
      "abstract": "The diagnosis of most mental disorders, including psychiatric evaluations,\nprimarily depends on dialogues between psychiatrists and patients. This\nsubjective process can lead to variability in diagnoses across clinicians and\npatients, resulting in inconsistencies and challenges in achieving reliable\noutcomes. To address these issues and standardize psychiatric diagnoses, we\npropose a Fine-Tuned Large Language Model (LLM) Consortium and OpenAI-gpt-oss\nReasoning LLM-enabled Decision Support System for the clinical diagnosis of\nmental disorders. Our approach leverages fine-tuned LLMs trained on\nconversational datasets involving psychiatrist-patient interactions focused on\nmental health conditions (e.g., depression). The diagnostic predictions from\nindividual models are aggregated through a consensus-based decision-making\nprocess, refined by the OpenAI-gpt-oss reasoning LLM. We propose a novel method\nfor deploying LLM agents that orchestrate communication between the LLM\nconsortium and the reasoning LLM, ensuring transparency, reliability, and\nresponsible AI across the entire diagnostic workflow. Experimental results\ndemonstrate the transformative potential of combining fine-tuned LLMs with a\nreasoning model to create a robust and highly accurate diagnostic system for\nmental health assessment. A prototype of the proposed platform, integrating\nthree fine-tuned LLMs with the OpenAI-gpt-oss reasoning LLM, was developed in\ncollaboration with the U.S. Army Medical Research Team in Norfolk, Virginia,\nUSA. To the best of our knowledge, this work represents the first application\nof a fine-tuned LLM consortium integrated with a reasoning LLM for clinical\nmental health diagnosis paving the way for next-generation AI-powered eHealth\nsystems aimed at standardizing psychiatric diagnoses.",
      "pdf_url": "http://arxiv.org/pdf/2510.25588v1",
      "published": "2025-10-29T14:54:22+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.25588v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Lost in Phonation: Voice Quality Variation as an Evaluation Dimension for Speech Foundation Models",
      "authors": [
        "Harm Lameris",
        "Shree Harsha Bokkahalli Satish",
        "Joakim Gustafson",
        "Éva Székely"
      ],
      "abstract": "Recent advances in speech foundation models (SFMs) have enabled the direct\nprocessing of spoken language from raw audio, bypassing intermediate textual\nrepresentations. This capability allows SFMs to be exposed to, and potentially\nrespond to, rich paralinguistic variations embedded in the input speech signal.\nOne under-explored dimension of paralinguistic variation is voice quality,\nencompassing phonation types such as creaky and breathy voice. These phonation\ntypes are known to influence how listeners infer affective state, stance and\nsocial meaning in speech. Existing benchmarks for speech understanding largely\nrely on multiple-choice question answering (MCQA) formats, which are prone to\nfailure and therefore unreliable in capturing the nuanced ways paralinguistic\nfeatures influence model behaviour. In this paper, we probe SFMs through\nopen-ended generation tasks and speech emotion recognition, evaluating whether\nmodel behaviours are consistent across different phonation inputs. We introduce\na new parallel dataset featuring synthesized modifications to voice quality,\ndesigned to evaluate SFM responses to creaky and breathy voice. Our work\nprovides the first examination of SFM sensitivity to these particular\nnon-lexical aspects of speech perception.",
      "pdf_url": "http://arxiv.org/pdf/2510.25577v1",
      "published": "2025-10-29T14:44:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.25577v1",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Leveraging an Atmospheric Foundational Model for Subregional Sea Surface Temperature Forecasting",
      "authors": [
        "Víctor Medina",
        "Giovanny A. Cuervo-Londoño",
        "Javier Sánchez"
      ],
      "abstract": "The accurate prediction of oceanographic variables is crucial for\nunderstanding climate change, managing marine resources, and optimizing\nmaritime activities. Traditional ocean forecasting relies on numerical models;\nhowever, these approaches face limitations in terms of computational cost and\nscalability. In this study, we adapt Aurora, a foundational deep learning model\noriginally designed for atmospheric forecasting, to predict sea surface\ntemperature (SST) in the Canary Upwelling System. By fine-tuning this model\nwith high-resolution oceanographic reanalysis data, we demonstrate its ability\nto capture complex spatiotemporal patterns while reducing computational\ndemands. Our methodology involves a staged fine-tuning process, incorporating\nlatitude-weighted error metrics and optimizing hyperparameters for efficient\nlearning. The experimental results show that the model achieves a low RMSE of\n0.119K, maintaining high anomaly correlation coefficients (ACC $\\approx\n0.997$). The model successfully reproduces large-scale SST structures but faces\nchallenges in capturing finer details in coastal regions. This work contributes\nto the field of data-driven ocean forecasting by demonstrating the feasibility\nof using deep learning models pre-trained in different domains for oceanic\napplications. Future improvements include integrating additional oceanographic\nvariables, increasing spatial resolution, and exploring physics-informed neural\nnetworks to enhance interpretability and understanding. These advancements can\nimprove climate modeling and ocean prediction accuracy, supporting\ndecision-making in environmental and economic sectors.",
      "pdf_url": "http://arxiv.org/pdf/2510.25563v1",
      "published": "2025-10-29T14:30:12+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.25563v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.ao-ph"
      ]
    },
    {
      "title": "Hybrid Quantum-Classical Recurrent Neural Networks",
      "authors": [
        "Wenduan Xu"
      ],
      "abstract": "We present a hybrid quantum-classical recurrent neural network (QRNN)\narchitecture in which the entire recurrent core is realized as a parametrized\nquantum circuit (PQC) controlled by a classical feedforward network. The hidden\nstate is the quantum state of an $n$-qubit PQC, residing in an exponentially\nlarge Hilbert space $\\mathbb{C}^{2^n}$. The PQC is unitary by construction,\nmaking the hidden-state evolution norm-preserving without external constraints.\nAt each timestep, mid-circuit readouts are combined with the input embedding\nand processed by the feedforward network, which provides explicit classical\nnonlinearity. The outputs parametrize the PQC, which updates the hidden state\nvia unitary dynamics. The QRNN is compact and physically consistent, and it\nunifies (i) unitary recurrence as a high-capacity memory, (ii) partial\nobservation via mid-circuit measurements, and (iii) nonlinear classical control\nfor input-conditioned parametrization. We evaluate the model in simulation with\nup to 14 qubits on sentiment analysis, MNIST, permuted MNIST, copying memory,\nand language modeling, adopting projective measurements as a limiting case to\nobtain mid-circuit readouts while maintaining a coherent recurrent quantum\nmemory. We further devise a soft attention mechanism over the mid-circuit\nreadouts in a sequence-to-sequence model and show its effectiveness for machine\ntranslation. To our knowledge, this is the first model (RNN or otherwise)\ngrounded in quantum operations to achieve competitive performance against\nstrong classical baselines across a broad class of sequence-learning tasks.",
      "pdf_url": "http://arxiv.org/pdf/2510.25557v1",
      "published": "2025-10-29T14:21:49+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.25557v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "quant-ph"
      ]
    },
    {
      "title": "Using latent representations to link disjoint longitudinal data for mixed-effects regression",
      "authors": [
        "Clemens Schächter",
        "Maren Hackenberg",
        "Michelle Pfaffenlehner",
        "Félix B. Tambe-Ndonfack",
        "Thorsten Schmidt",
        "Astrid Pechmann",
        "Janbernd Kirschner",
        "Jan Hasenauser",
        "Harald Binder"
      ],
      "abstract": "Many rare diseases offer limited established treatment options, leading\npatients to switch therapies when new medications emerge. To analyze the impact\nof such treatment switches within the low sample size limitations of rare\ndisease trials, it is important to use all available data sources. This,\nhowever, is complicated when usage of measurement instruments change during the\nobservation period, for example when instruments are adapted to specific age\nranges. The resulting disjoint longitudinal data trajectories, complicate the\napplication of traditional modeling approaches like mixed-effects regression.\nWe tackle this by mapping observations of each instrument to a aligned\nlow-dimensional temporal trajectory, enabling longitudinal modeling across\ninstruments. Specifically, we employ a set of variational autoencoder\narchitectures to embed item values into a shared latent space for each time\npoint. Temporal disease dynamics and treatment switch effects are then captured\nthrough a mixed-effects regression model applied to latent representations. To\nenable statistical inference, we present a novel statistical testing approach\nthat accounts for the joint parameter estimation of mixed-effects regression\nand variational autoencoders. The methodology is applied to quantify the impact\nof treatment switches for patients with spinal muscular atrophy. Here, our\napproach aligns motor performance items from different measurement instruments\nfor mixed-effects regression and maps estimated effects back to the observed\nitem level to quantify the treatment switch effect. Our approach allows for\nmodel selection as well as for assessing effects of treatment switching. The\nresults highlight the potential of modeling in joint latent representations for\naddressing small data challenges.",
      "pdf_url": "http://arxiv.org/pdf/2510.25531v1",
      "published": "2025-10-29T13:56:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.25531v1",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "68T07",
        "G.3; I.2.6; J.3"
      ]
    },
    {
      "title": "Off-policy Reinforcement Learning with Model-based Exploration Augmentation",
      "authors": [
        "Likun Wang",
        "Xiangteng Zhang",
        "Yinuo Wang",
        "Guojian Zhan",
        "Wenxuan Wang",
        "Haoyu Gao",
        "Jingliang Duan",
        "Shengbo Eben Li"
      ],
      "abstract": "Exploration is fundamental to reinforcement learning (RL), as it determines\nhow effectively an agent discovers and exploits the underlying structure of its\nenvironment to achieve optimal performance. Existing exploration methods\ngenerally fall into two categories: active exploration and passive exploration.\nThe former introduces stochasticity into the policy but struggles in\nhigh-dimensional environments, while the latter adaptively prioritizes\ntransitions in the replay buffer to enhance exploration, yet remains\nconstrained by limited sample diversity. To address the limitation in passive\nexploration, we propose Modelic Generative Exploration (MoGE), which augments\nexploration through the generation of under-explored critical states and\nsynthesis of dynamics-consistent experiences through transition models. MoGE is\ncomposed of two components: (1) a diffusion-based generator that synthesizes\ncritical states under the guidance of a utility function evaluating each\nstate's potential influence on policy exploration, and (2) a one-step\nimagination world model for constructing critical transitions based on the\ncritical states for agent learning. Our method adopts a modular formulation\nthat aligns with the principles of off-policy learning, allowing seamless\nintegration with existing algorithms to improve exploration without altering\ntheir core structures. Empirical results on OpenAI Gym and DeepMind Control\nSuite reveal that MoGE effectively bridges exploration and policy learning,\nleading to remarkable gains in both sample efficiency and performance across\ncomplex control tasks.",
      "pdf_url": "http://arxiv.org/pdf/2510.25529v1",
      "published": "2025-10-29T13:53:52+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.25529v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Zero Reinforcement Learning Towards General Domains",
      "authors": [
        "Yuyuan Zeng",
        "Yufei Huang",
        "Can Xu",
        "Qingfeng Sun",
        "Jianfeng Yan",
        "Guanghui Xu",
        "Tao Yang",
        "Fengzong Lian"
      ],
      "abstract": "Zero Reinforcement Learning (Zero-RL) has proven to be an effective approach\nfor enhancing the reasoning capabilities of large language models (LLMs) by\ndirectly applying reinforcement learning with verifiable rewards on pretrained\nmodels, without the need for a supervised fine-tuning phase. However, current\nresearch on zero-RL primarily focuses on domains with easily verifiable reward\nsignals, such as mathematics, programming, and other reasoning tasks. The\nchallenge of eliciting reasoning abilities in more diverse scenarios, where\nverification is not straightforward, remains underexplored. To address this\ngap, we propose a novel zero-RL paradigm designed to improve a model's\nreasoning ability across both verifiable and non-verifiable domains. By\ncombining verifiable rewards with a generative reward model, we conduct\nmulti-task zero-RL training across both domains, facilitating the transfer of\nreasoning capabilities between them. Furthermore, to mitigate reward hacking in\nthe generative reward model, we design a smooth length penalty that encourages\nthe generation of more comprehensive thinking tokens in general domains.\nExperimental results on Qwen3-8B-Base and Qwen3-14B-Base demonstrate that our\napproach achieves superior reasoning performance, not only on tasks requiring\nextensive reasoning but also on more general tasks.",
      "pdf_url": "http://arxiv.org/pdf/2510.25528v1",
      "published": "2025-10-29T13:52:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.25528v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Comparative Study of UNet-based Architectures for Liver Tumor Segmentation in Multi-Phase Contrast-Enhanced Computed Tomography",
      "authors": [
        "Doan-Van-Anh Ly",
        "Thi-Thu-Hien Pham",
        "Thanh-Hai Le"
      ],
      "abstract": "Segmentation of liver structures in multi-phase contrast-enhanced computed\ntomography (CECT) plays a crucial role in computer-aided diagnosis and\ntreatment planning for liver diseases, including tumor detection. In this\nstudy, we investigate the performance of UNet-based architectures for liver\ntumor segmentation, starting from the original UNet and extending to UNet3+\nwith various backbone networks. We evaluate ResNet, Transformer-based, and\nState-space (Mamba) backbones, all initialized with pretrained weights.\nSurprisingly, despite the advances in modern architecture, ResNet-based models\nconsistently outperform Transformer- and Mamba-based alternatives across\nmultiple evaluation metrics. To further improve segmentation quality, we\nintroduce attention mechanisms into the backbone and observe that incorporating\nthe Convolutional Block Attention Module (CBAM) yields the best performance.\nResNetUNet3+ with CBAM module not only produced the best overlap metrics with a\nDice score of 0.755 and IoU of 0.662, but also achieved the most precise\nboundary delineation, evidenced by the lowest HD95 distance of 77.911. The\nmodel's superiority was further cemented by its leading overall accuracy of\n0.925 and specificity of 0.926, showcasing its robust capability in accurately\nidentifying both lesion and healthy tissue. To further enhance\ninterpretability, Grad-CAM visualizations were employed to highlight the\nregion's most influential predictions, providing insights into its\ndecision-making process. These findings demonstrate that classical ResNet\narchitecture, when combined with modern attention modules, remain highly\ncompetitive for medical image segmentation tasks, offering a promising\ndirection for liver tumor detection in clinical practice.",
      "pdf_url": "http://arxiv.org/pdf/2510.25522v1",
      "published": "2025-10-29T13:46:19+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.25522v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.4.6"
      ]
    },
    {
      "title": "Retrieval Augmented Generation (RAG) for Fintech: Agentic Design and Evaluation",
      "authors": [
        "Thomas Cook",
        "Richard Osuagwu",
        "Liman Tsatiashvili",
        "Vrynsia Vrynsia",
        "Koustav Ghosal",
        "Maraim Masoud",
        "Riccardo Mattivi"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) systems often face limitations in\nspecialized domains such as fintech, where domain-specific ontologies, dense\nterminology, and acronyms complicate effective retrieval and synthesis. This\npaper introduces an agentic RAG architecture designed to address these\nchallenges through a modular pipeline of specialized agents. The proposed\nsystem supports intelligent query reformulation, iterative sub-query\ndecomposition guided by keyphrase extraction, contextual acronym resolution,\nand cross-encoder-based context re-ranking. We evaluate our approach against a\nstandard RAG baseline using a curated dataset of 85 question--answer--reference\ntriples derived from an enterprise fintech knowledge base. Experimental results\ndemonstrate that the agentic RAG system outperforms the baseline in retrieval\nprecision and relevance, albeit with increased latency. These findings suggest\nthat structured, multi-agent methodologies offer a promising direction for\nenhancing retrieval robustness in complex, domain-specific settings.",
      "pdf_url": "http://arxiv.org/pdf/2510.25518v1",
      "published": "2025-10-29T13:41:36+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.25518v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Predicate Renaming via Large Language Models",
      "authors": [
        "Elisabetta Gentili",
        "Tony Ribeiro",
        "Fabrizio Riguzzi",
        "Katsumi Inoue"
      ],
      "abstract": "In this paper, we address the problem of giving names to predicates in logic\nrules using Large Language Models (LLMs). In the context of Inductive Logic\nProgramming, various rule generation methods produce rules containing unnamed\npredicates, with Predicate Invention being a key example. This hinders the\nreadability, interpretability, and reusability of the logic theory. Leveraging\nrecent advancements in LLMs development, we explore their ability to process\nnatural language and code to provide semantically meaningful suggestions for\ngiving a name to unnamed predicates. The evaluation of our approach on some\nhand-crafted logic rules indicates that LLMs hold potential for this task.",
      "pdf_url": "http://arxiv.org/pdf/2510.25517v1",
      "published": "2025-10-29T13:39:41+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.25517v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "FaCT: Faithful Concept Traces for Explaining Neural Network Decisions",
      "authors": [
        "Amin Parchami-Araghi",
        "Sukrut Rao",
        "Jonas Fischer",
        "Bernt Schiele"
      ],
      "abstract": "Deep networks have shown remarkable performance across a wide range of tasks,\nyet getting a global concept-level understanding of how they function remains a\nkey challenge. Many post-hoc concept-based approaches have been introduced to\nunderstand their workings, yet they are not always faithful to the model.\nFurther, they make restrictive assumptions on the concepts a model learns, such\nas class-specificity, small spatial extent, or alignment to human expectations.\nIn this work, we put emphasis on the faithfulness of such concept-based\nexplanations and propose a new model with model-inherent mechanistic\nconcept-explanations. Our concepts are shared across classes and, from any\nlayer, their contribution to the logit and their input-visualization can be\nfaithfully traced. We also leverage foundation models to propose a new\nconcept-consistency metric, C$^2$-Score, that can be used to evaluate\nconcept-based methods. We show that, compared to prior work, our concepts are\nquantitatively more consistent and users find our concepts to be more\ninterpretable, all while retaining competitive ImageNet performance.",
      "pdf_url": "http://arxiv.org/pdf/2510.25512v1",
      "published": "2025-10-29T13:35:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.25512v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "MTIR-SQL: Multi-turn Tool-Integrated Reasoning Reinforcement Learning for Text-to-SQL",
      "authors": [
        "Zekun Xu",
        "Siyu Xia",
        "Chuhuai Yue",
        "Jiajun Chai",
        "Mingxue Tian",
        "Xiaohan Wang",
        "Wei Lin",
        "Haoxuan Li",
        "Guojun Yin"
      ],
      "abstract": "As large language models (LLMs) are increasingly used in Text-to-SQL tasks,\nReinforcement Learning (RL) has become a common method for improving\nperformance. Existing methods primarily rely on static execution feedback,\nwhich restricts real-time error correction. However, integrating multi-turn\ntool invocation along with dynamic feedback could significantly improve\nadaptability and robustness, ultimately enhancing model performance. To address\nthese issues, we propose MTIR-SQL, an innovative Multi-turn Tool-Integrated\nReasoning reinforcement learning framework for Text-to-SQL. Our approach\nintroduces an execution-aware multi-turn reasoning paradigm that seamlessly\nincorporates database execution feedback at each reasoning step, enabling\ncontext-sensitive query generation and progressive refinement throughout the\nreasoning process. The framework extends the GRPO algorithm to accommodate\ncomplex multi-turn interaction scenarios. Considering the training instability\ncharacteristics of MTIR and the potential for significant Deviation of model\ndistribution from the initial model, we enhance the GRPO algorithm by adding a\ntrajectory filtering mechanism and removing KL loss constraints. Experimental\nresults demonstrate that MTIR-SQL, with 4B parameters, achieves \\textbf{64.4}\\%\naccuracy in the BIRD Dev and 84.6% execution accuracy in the SPIDER Dev,\nsignificantly outperforming existing approaches.",
      "pdf_url": "http://arxiv.org/pdf/2510.25510v1",
      "published": "2025-10-29T13:34:27+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.25510v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Reflections on the Reproducibility of Commercial LLM Performance in Empirical Software Engineering Studies",
      "authors": [
        "Florian Angermeir",
        "Maximilian Amougou",
        "Mark Kreitz",
        "Andreas Bauer",
        "Matthias Linhuber",
        "Davide Fucci",
        "Fabiola Moyón C.",
        "Daniel Mendez",
        "Tony Gorschek"
      ],
      "abstract": "Large Language Models have gained remarkable interest in industry and\nacademia. The increasing interest in LLMs in academia is also reflected in the\nnumber of publications on this topic over the last years. For instance, alone\n78 of the around 425 publications at ICSE 2024 performed experiments with LLMs.\nConducting empirical studies with LLMs remains challenging and raises questions\non how to achieve reproducible results, for both other researchers and\npractitioners. One important step towards excelling in empirical research on\nLLMs and their application is to first understand to what extent current\nresearch results are eventually reproducible and what factors may impede\nreproducibility. This investigation is within the scope of our work. We\ncontribute an analysis of the reproducibility of LLM-centric studies, provide\ninsights into the factors impeding reproducibility, and discuss suggestions on\nhow to improve the current state. In particular, we studied the 86 articles\ndescribing LLM-centric studies, published at ICSE 2024 and ASE 2024. Of the 86\narticles, 18 provided research artefacts and used OpenAI models. We attempted\nto replicate those 18 studies. Of the 18 studies, only five were fit for\nreproduction. For none of the five studies, we were able to fully reproduce the\nresults. Two studies seemed to be partially reproducible, and three studies did\nnot seem to be reproducible. Our results highlight not only the need for\nstricter research artefact evaluations but also for more robust study designs\nto ensure the reproducible value of future publications.",
      "pdf_url": "http://arxiv.org/pdf/2510.25506v1",
      "published": "2025-10-29T13:31:32+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.25506v1",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "Multi-Objective Search: Algorithms, Applications, and Emerging Directions",
      "authors": [
        "Oren Salzman",
        "Carlos Hernández Ulloa",
        "Ariel Felner",
        "Sven Koenig"
      ],
      "abstract": "Multi-objective search (MOS) has emerged as a unifying framework for planning\nand decision-making problems where multiple, often conflicting, criteria must\nbe balanced. While the problem has been studied for decades, recent years have\nseen renewed interest in the topic across AI applications such as robotics,\ntransportation, and operations research, reflecting the reality that real-world\nsystems rarely optimize a single measure. This paper surveys developments in\nMOS while highlighting cross-disciplinary opportunities, and outlines open\nchallenges that define the emerging frontier of MOS",
      "pdf_url": "http://arxiv.org/pdf/2510.25504v1",
      "published": "2025-10-29T13:30:01+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.25504v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "TempoPFN: Synthetic Pre-training of Linear RNNs for Zero-shot Time Series Forecasting",
      "authors": [
        "Vladyslav Moroshan",
        "Julien Siems",
        "Arber Zela",
        "Timur Carstensen",
        "Frank Hutter"
      ],
      "abstract": "Foundation models for zero-shot time series forecasting face challenges in\nefficient long-horizon prediction and reproducibility, with existing\nsynthetic-only approaches underperforming on challenging benchmarks. This paper\npresents TempoPFN, a univariate time series foundation model based on linear\nRecurrent Neural Networks (RNNs) pre-trained exclusively on synthetic data. The\nmodel uses a GatedDeltaProduct architecture with state-weaving for fully\nparallelizable training across sequence lengths, eliminating the need for\nwindowing or summarization techniques while maintaining robust temporal\nstate-tracking. Our comprehensive synthetic data pipeline unifies diverse\ngenerators, including stochastic differential equations, Gaussian processes,\nand audio synthesis, with novel augmentations. In zero-shot evaluations on the\nGift-Eval benchmark, TempoPFN achieves top-tier competitive performance,\noutperforming all existing synthetic-only approaches and surpassing the vast\nmajority of models trained on real-world data, while being more efficient than\nexisting baselines by leveraging fully parallelizable training and inference.\nWe open-source our complete data generation pipeline and training code,\nproviding a reproducible foundation for future research.",
      "pdf_url": "http://arxiv.org/pdf/2510.25502v1",
      "published": "2025-10-29T13:27:18+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.25502v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ]
    },
    {
      "title": "Instrumental goals in advanced AI systems: Features to be managed and not failures to be eliminated?",
      "authors": [
        "Willem Fourie"
      ],
      "abstract": "In artificial intelligence (AI) alignment research, instrumental goals, also\ncalled instrumental subgoals or instrumental convergent goals, are widely\nassociated with advanced AI systems. These goals, which include tendencies such\nas power-seeking and self-preservation, become problematic when they conflict\nwith human aims. Conventional alignment theory treats instrumental goals as\nsources of risk that become problematic through failure modes such as reward\nhacking or goal misgeneralization, and attempts to limit the symptoms of\ninstrumental goals, notably resource acquisition and self-preservation. This\narticle proposes an alternative framing: that a philosophical argument can be\nconstructed according to which instrumental goals may be understood as features\nto be accepted and managed rather than failures to be limited. Drawing on\nAristotle's ontology and its modern interpretations, an ontology of concrete,\ngoal-directed entities, it argues that advanced AI systems can be seen as\nartifacts whose formal and material constitution gives rise to effects distinct\nfrom their designers' intentions. In this view, the instrumental tendencies of\nsuch systems correspond to per se outcomes of their constitution rather than\naccidental malfunctions. The implication is that efforts should focus less on\neliminating instrumental goals and more on understanding, managing, and\ndirecting them toward human-aligned ends.",
      "pdf_url": "http://arxiv.org/pdf/2510.25471v1",
      "published": "2025-10-29T12:47:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.25471v1",
      "categories": [
        "cs.AI",
        "cs.CY"
      ]
    },
    {
      "title": "An In-Depth Analysis of Cyber Attacks in Secured Platforms",
      "authors": [
        "Parick Ozoh",
        "John K Omoniyi",
        "Bukola Ibitoye"
      ],
      "abstract": "There is an increase in global malware threats. To address this, an\nencryption-type ransomware has been introduced on the Android operating system.\nThe challenges associated with malicious threats in phone use have become a\npressing issue in mobile communication, disrupting user experiences and posing\nsignificant privacy threats. This study surveys commonly used machine learning\ntechniques for detecting malicious threats in phones and examines their\nperformance. The majority of past research focuses on customer feedback and\nreviews, with concerns that people might create false reviews to promote or\ndevalue products and services for personal gain. Hence, the development of\ntechniques for detecting malicious threats using machine learning has been a\nkey focus. This paper presents a comprehensive comparative study of current\nresearch on the issue of malicious threats and methods for tackling these\nchallenges. Nevertheless, a huge amount of information is required by these\nmethods, presenting a challenge for developing robust, specialized automated\nanti-malware systems. This research describes the Android Applications dataset,\nand the accuracy of the techniques is measured using the accuracy levels of the\nmetrics employed in this study.",
      "pdf_url": "http://arxiv.org/pdf/2510.25470v1",
      "published": "2025-10-29T12:43:18+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.25470v1",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Fine-Tuned Language Models for Domain-Specific Summarization and Tagging",
      "authors": [
        "Jun Wang",
        "Fuming Lin",
        "Yuyu Chen"
      ],
      "abstract": "This paper presents a pipeline integrating fine-tuned large language models\n(LLMs) with named entity recognition (NER) for efficient domain-specific text\nsummarization and tagging. The authors address the challenge posed by rapidly\nevolving sub-cultural languages and slang, which complicate automated\ninformation extraction and law enforcement monitoring. By leveraging the LLaMA\nFactory framework, the study fine-tunes LLMs on both generalpurpose and custom\ndomain-specific datasets, particularly in the political and security domains.\nThe models are evaluated using BLEU and ROUGE metrics, demonstrating that\ninstruction fine-tuning significantly enhances summarization and tagging\naccuracy, especially for specialized corpora. Notably, the LLaMA3-8B-Instruct\nmodel, despite its initial limitations in Chinese comprehension, outperforms\nits Chinese-trained counterpart after domainspecific fine-tuning, suggesting\nthat underlying reasoning capabilities can transfer across languages. The\npipeline enables concise summaries and structured entity tagging, facilitating\nrapid document categorization and distribution. This approach proves scalable\nand adaptable for real-time applications, supporting efficient information\nmanagement and the ongoing need to capture emerging language trends. The\nintegration of LLMs and NER offers a robust solution for transforming\nunstructured text into actionable insights, crucial for modern knowledge\nmanagement and security operations.",
      "pdf_url": "http://arxiv.org/pdf/2510.25460v1",
      "published": "2025-10-29T12:33:48+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.25460v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Scalable Utility-Aware Multiclass Calibration",
      "authors": [
        "Mahmoud Hegazy",
        "Michael I. Jordan",
        "Aymeric Dieuleveut"
      ],
      "abstract": "Ensuring that classifiers are well-calibrated, i.e., their predictions align\nwith observed frequencies, is a minimal and fundamental requirement for\nclassifiers to be viewed as trustworthy. Existing methods for assessing\nmulticlass calibration often focus on specific aspects associated with\nprediction (e.g., top-class confidence, class-wise calibration) or utilize\ncomputationally challenging variational formulations. In this work, we study\nscalable \\emph{evaluation} of multiclass calibration. To this end, we propose\nutility calibration, a general framework that measures the calibration error\nrelative to a specific utility function that encapsulates the goals or decision\ncriteria relevant to the end user. We demonstrate how this framework can unify\nand re-interpret several existing calibration metrics, particularly allowing\nfor more robust versions of the top-class and class-wise calibration metrics,\nand, going beyond such binarized approaches, toward assessing calibration for\nricher classes of downstream utilities.",
      "pdf_url": "http://arxiv.org/pdf/2510.25458v1",
      "published": "2025-10-29T12:32:14+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.25458v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ]
    },
    {
      "title": "Agentic AI: A Comprehensive Survey of Architectures, Applications, and Future Directions",
      "authors": [
        "Mohamad Abou Ali",
        "Fadi Dornaika"
      ],
      "abstract": "Agentic AI represents a transformative shift in artificial intelligence, but\nits rapid advancement has led to a fragmented understanding, often conflating\nmodern neural systems with outdated symbolic models -- a practice known as\nconceptual retrofitting. This survey cuts through this confusion by introducing\na novel dual-paradigm framework that categorizes agentic systems into two\ndistinct lineages: the Symbolic/Classical (relying on algorithmic planning and\npersistent state) and the Neural/Generative (leveraging stochastic generation\nand prompt-driven orchestration). Through a systematic PRISMA-based review of\n90 studies (2018--2025), we provide a comprehensive analysis structured around\nthis framework across three dimensions: (1) the theoretical foundations and\narchitectural principles defining each paradigm; (2) domain-specific\nimplementations in healthcare, finance, and robotics, demonstrating how\napplication constraints dictate paradigm selection; and (3) paradigm-specific\nethical and governance challenges, revealing divergent risks and mitigation\nstrategies. Our analysis reveals that the choice of paradigm is strategic:\nsymbolic systems dominate safety-critical domains (e.g., healthcare), while\nneural systems prevail in adaptive, data-rich environments (e.g., finance).\nFurthermore, we identify critical research gaps, including a significant\ndeficit in governance models for symbolic systems and a pressing need for\nhybrid neuro-symbolic architectures. The findings culminate in a strategic\nroadmap arguing that the future of Agentic AI lies not in the dominance of one\nparadigm, but in their intentional integration to create systems that are both\nadaptable and reliable. This work provides the essential conceptual toolkit to\nguide future research, development, and policy toward robust and trustworthy\nhybrid intelligent systems.",
      "pdf_url": "http://arxiv.org/pdf/2510.25445v1",
      "published": "2025-10-29T12:11:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.25445v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Grounded in Reality: Learning and Deploying Proactive LLM from Offline Logs",
      "authors": [
        "Fei Wei",
        "Daoyuan Chen",
        "Ce Wang",
        "Yilun Huang",
        "Yushuo Chen",
        "Xuchen Pan",
        "Yaliang Li",
        "Bolin Ding"
      ],
      "abstract": "Large Language Models (LLMs) excel as passive responders, but teaching them\nto be proactive, goal-oriented partners, a critical capability in high-stakes\ndomains, remains a major challenge. Current paradigms either myopically\noptimize single-turn attributes or rely on brittle, high-cost user simulators,\ncreating a persistent ``reality gap''. To bridge this gap, we introduce\n\\texttt{Learn-to-Ask}, a general, simulator-free framework for learning and\ndeploying proactive dialogue agents \\textit{directly from offline expert data},\nbypassing the need to model complex user dynamics. Our key insight is to\nreframe the offline policy learning problem by leveraging the \\textbf{observed\nfuture} of each expert trajectory. This allows us to infer a dense,\nturn-by-turn reward signal grounded in the expert's revealed strategy,\ndecomposing the intractable long-horizon problem into a series of supervised\nlearning tasks, and training a policy to output a structured \\texttt{(action,\nstate_assessment)} tuple, governing both \\textbf{what to ask} and, crucially,\n\\textbf{when to stop}. To ensure reward fidelity, our Automated Grader\nCalibration pipeline systematically purges noise from the LLM-based reward\nmodel with minimal human supervision. Empirically, we demonstrate the efficacy\nof \\texttt{Learn-to-Ask} in a real-world medical dataset, using LLMs of varying\nsizes up to 32B. Our approach culminates in the successful deployment of LLMs\ninto a live, large-scale online AI service. In rigorous in-house evaluations,\nour model was launched and achieved performance even superior to human experts,\nproving our framework's ability to translate offline data into tangible,\nreal-world impact. We hope this work provides a practical and economically\nviable blueprint for transforming passive LLMs into proactive, goal-oriented\nLLM applications.",
      "pdf_url": "http://arxiv.org/pdf/2510.25441v1",
      "published": "2025-10-29T12:08:07+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.25441v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Alibaba International E-commerce Product Search Competition DcuRAGONs Team Technical Report",
      "authors": [
        "Thang-Long Nguyen-Ho",
        "Minh-Khoi Pham",
        "Hoang-Bao Le"
      ],
      "abstract": "This report details our methodology and results developed for the\nMultilingual E-commerce Search Competition. The problem aims to recognize\nrelevance between user queries versus product items in a multilingual context\nand improve recommendation performance on e-commerce platforms. Utilizing Large\nLanguage Models (LLMs) and their capabilities in other tasks, our data-centric\nmethod achieved the highest score compared to other solutions during the\ncompetition. Final leaderboard is publised at\nhttps://alibaba-international-cikm2025.github.io. The source code for our\nproject is published at https://github.com/nhtlongcs/e-commerce-product-search.",
      "pdf_url": "http://arxiv.org/pdf/2510.25428v1",
      "published": "2025-10-29T11:50:52+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.25428v1",
      "categories": [
        "cs.IR",
        "cs.AI"
      ]
    },
    {
      "title": "RLMEval: Evaluating Research-Level Neural Theorem Proving",
      "authors": [
        "Auguste Poiroux",
        "Antoine Bosselut",
        "Viktor Kunčak"
      ],
      "abstract": "Despite impressive results on curated benchmarks, the practical impact of\nlarge language models (LLMs) on research-level neural theorem proving and proof\nautoformalization is still limited. We introduce RLMEval, an evaluation suite\nfor these tasks, focusing on research-level mathematics from real-world Lean\nformalization projects. RLMEval targets the evaluation of neural theorem\nproving and proof autoformalization on challenging research-level theorems by\nleveraging real Lean Blueprint formalization projects. Our evaluation of\nstate-of-the-art models on RLMEval, comprising 613 theorems from 6 Lean\nprojects, reveals a significant gap: progress on existing benchmarks does not\nreadily translate to these more realistic settings, with the best model\nachieving only a 10.3 % pass rate. RLMEval provides a new, challenging\nbenchmark designed to guide and accelerate progress in automated reasoning for\nformal mathematics.",
      "pdf_url": "http://arxiv.org/pdf/2510.25427v1",
      "published": "2025-10-29T11:49:49+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.25427v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Implicature in Interaction: Understanding Implicature Improves Alignment in Human-LLM Interaction",
      "authors": [
        "Asutosh Hota",
        "Jussi P. P. Jokinen"
      ],
      "abstract": "The rapid advancement of Large Language Models (LLMs) is positioning language\nat the core of human-computer interaction (HCI). We argue that advancing HCI\nrequires attention to the linguistic foundations of interaction, particularly\nimplicature (meaning conveyed beyond explicit statements through shared\ncontext) which is essential for human-AI (HAI) alignment. This study examines\nLLMs' ability to infer user intent embedded in context-driven prompts and\nwhether understanding implicature improves response generation. Results show\nthat larger models approximate human interpretations more closely, while\nsmaller models struggle with implicature inference. Furthermore,\nimplicature-based prompts significantly enhance the perceived relevance and\nquality of responses across models, with notable gains in smaller models.\nOverall, 67.6% of participants preferred responses with implicature-embedded\nprompts to literal ones, highlighting a clear preference for contextually\nnuanced communication. Our work contributes to understanding how linguistic\ntheory can be used to address the alignment problem by making HAI interaction\nmore natural and contextually grounded.",
      "pdf_url": "http://arxiv.org/pdf/2510.25426v1",
      "published": "2025-10-29T11:49:42+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.25426v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Improving Temporal Consistency and Fidelity at Inference-time in Perceptual Video Restoration by Zero-shot Image-based Diffusion Models",
      "authors": [
        "Nasrin Rahimi",
        "A. Murat Tekalp"
      ],
      "abstract": "Diffusion models have emerged as powerful priors for single-image\nrestoration, but their application to zero-shot video restoration suffers from\ntemporal inconsistencies due to the stochastic nature of sampling and\ncomplexity of incorporating explicit temporal modeling. In this work, we\naddress the challenge of improving temporal coherence in video restoration\nusing zero-shot image-based diffusion models without retraining or modifying\ntheir architecture. We propose two complementary inference-time strategies: (1)\nPerceptual Straightening Guidance (PSG) based on the neuroscience-inspired\nperceptual straightening hypothesis, which steers the diffusion denoising\nprocess towards smoother temporal evolution by incorporating a curvature\npenalty in a perceptual space to improve temporal perceptual scores, such as\nFr\\'echet Video Distance (FVD) and perceptual straightness; and (2) Multi-Path\nEnsemble Sampling (MPES), which aims at reducing stochastic variation by\nensembling multiple diffusion trajectories to improve fidelity (distortion)\nscores, such as PSNR and SSIM, without sacrificing sharpness. Together, these\ntraining-free techniques provide a practical path toward temporally stable\nhigh-fidelity perceptual video restoration using large pretrained diffusion\nmodels. We performed extensive experiments over multiple datasets and\ndegradation types, systematically evaluating each strategy to understand their\nstrengths and limitations. Our results show that while PSG enhances temporal\nnaturalness, particularly in case of temporal blur, MPES consistently improves\nfidelity and spatio-temporal perception--distortion trade-off across all tasks.",
      "pdf_url": "http://arxiv.org/pdf/2510.25420v1",
      "published": "2025-10-29T11:40:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.25420v1",
      "categories": [
        "eess.IV",
        "cs.AI"
      ]
    },
    {
      "title": "Adaptive End-to-End Transceiver Design for NextG Pilot-Free and CP-Free Wireless Systems",
      "authors": [
        "Jiaming Cheng",
        "Wei Chen",
        "Bo Ai"
      ],
      "abstract": "The advent of artificial intelligence (AI)-native wireless communication is\nfundamentally reshaping the design paradigm of next-generation (NextG) systems,\nwhere intelligent air interfaces are expected to operate adaptively and\nefficiently in highly dynamic environments. Conventional orthogonal frequency\ndivision multiplexing (OFDM) systems rely heavily on pilots and the cyclic\nprefix (CP), resulting in significant overhead and reduced spectral efficiency.\nTo address these limitations, we propose an adaptive end-to-end (E2E)\ntransceiver architecture tailored for pilot-free and CP-free wireless systems.\nThe architecture combines AI-driven constellation shaping and a neural receiver\nthrough joint training. To enhance robustness against mismatched or\ntime-varying channel conditions, we introduce a lightweight channel adapter\n(CA) module, which enables rapid adaptation with minimal computational overhead\nby updating only the CA parameters. Additionally, we present a framework that\nis scalable to multiple modulation orders within a unified model, significantly\nreducing model storage requirements. Moreover, to tackle the high\npeak-to-average power ratio (PAPR) inherent to OFDM, we incorporate constrained\nE2E training, achieving compliance with PAPR targets without additional\ntransmission overhead. Extensive simulations demonstrate that the proposed\nframework delivers superior bit error rate (BER), throughput, and resilience\nacross diverse channel scenarios, highlighting its potential for AI-native\nNextG.",
      "pdf_url": "http://arxiv.org/pdf/2510.25416v1",
      "published": "2025-10-29T11:34:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.25416v1",
      "categories": [
        "eess.SP",
        "cs.AI"
      ]
    }
  ]
}