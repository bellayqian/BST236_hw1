{
  "last_updated": "2025-02-25T00:44:52.197988",
  "papers": [
    {
      "title": "One-step Diffusion Models with $f$-Divergence Distribution Matching",
      "authors": [
        "Yilun Xu",
        "Weili Nie",
        "Arash Vahdat"
      ],
      "abstract": "Sampling from diffusion models involves a slow iterative process that hinders\ntheir practical deployment, especially for interactive applications. To\naccelerate generation speed, recent approaches distill a multi-step diffusion\nmodel into a single-step student generator via variational score distillation,\nwhich matches the distribution of samples generated by the student to the\nteacher's distribution. However, these approaches use the reverse\nKullback-Leibler (KL) divergence for distribution matching which is known to be\nmode seeking. In this paper, we generalize the distribution matching approach\nusing a novel $f$-divergence minimization framework, termed $f$-distill, that\ncovers different divergences with different trade-offs in terms of mode\ncoverage and training variance. We derive the gradient of the $f$-divergence\nbetween the teacher and student distributions and show that it is expressed as\nthe product of their score differences and a weighting function determined by\ntheir density ratio. This weighting function naturally emphasizes samples with\nhigher density in the teacher distribution, when using a less mode-seeking\ndivergence. We observe that the popular variational score distillation approach\nusing the reverse-KL divergence is a special case within our framework.\nEmpirically, we demonstrate that alternative $f$-divergences, such as\nforward-KL and Jensen-Shannon divergences, outperform the current best\nvariational score distillation methods across image generation tasks. In\nparticular, when using Jensen-Shannon divergence, $f$-distill achieves current\nstate-of-the-art one-step generation performance on ImageNet64 and zero-shot\ntext-to-image generation on MS-COCO. Project page:\nhttps://research.nvidia.com/labs/genair/f-distill",
      "pdf_url": "http://arxiv.org/pdf/2502.15681v1",
      "published": "2025-02-21T18:59:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.15681v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "BOSS: Benchmark for Observation Space Shift in Long-Horizon Task",
      "authors": [
        "Yue Yang",
        "Linfeng Zhao",
        "Mingyu Ding",
        "Gedas Bertasius",
        "Daniel Szafir"
      ],
      "abstract": "Robotics has long sought to develop visual-servoing robots capable of\ncompleting previously unseen long-horizon tasks. Hierarchical approaches offer\na pathway for achieving this goal by executing skill combinations arranged by a\ntask planner, with each visuomotor skill pre-trained using a specific imitation\nlearning (IL) algorithm. However, even in simple long-horizon tasks like skill\nchaining, hierarchical approaches often struggle due to a problem we identify\nas Observation Space Shift (OSS), where the sequential execution of preceding\nskills causes shifts in the observation space, disrupting the performance of\nsubsequent individually trained skill policies. To validate OSS and evaluate\nits impact on long-horizon tasks, we introduce BOSS (a Benchmark for\nObservation Space Shift). BOSS comprises three distinct challenges: \"Single\nPredicate Shift\", \"Accumulated Predicate Shift\", and \"Skill Chaining\", each\ndesigned to assess a different aspect of OSS's negative effect. We evaluated\nseveral recent popular IL algorithms on BOSS, including three Behavioral\nCloning methods and the Visual Language Action model OpenVLA. Even on the\nsimplest challenge, we observed average performance drops of 67%, 35%, 34%, and\n54%, respectively, when comparing skill performance with and without OSS.\nAdditionally, we investigate a potential solution to OSS that scales up the\ntraining data for each skill with a larger and more visually diverse set of\ndemonstrations, with our results showing it is not sufficient to resolve OSS.\nThe project page is: https://boss-benchmark.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2502.15679v1",
      "published": "2025-02-21T18:58:57+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.15679v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "FLEKE: Federated Locate-then-Edit Knowledge Editing",
      "authors": [
        "Zongkai Zhao",
        "Guozeng Xu",
        "Xiuhua Li",
        "Kaiwen Wei",
        "Jiang Zhong"
      ],
      "abstract": "Locate-then-Edit Knowledge Editing (LEKE) is a key technique for updating\nlarge language models (LLMs) without full retraining. However, existing methods\nassume a single-user setting and become inefficient in real-world multi-client\nscenarios, where decentralized organizations (e.g., hospitals, financial\ninstitutions) independently update overlapping knowledge, leading to redundant\nmediator knowledge vector (MKV) computations and privacy concerns. To address\nthese challenges, we introduce Federated Locate-then-Edit Knowledge Editing\n(FLEKE), a novel task that enables multiple clients to collaboratively perform\nLEKE while preserving privacy and reducing computational overhead. To achieve\nthis, we propose FedEdit, a two-stage framework that optimizes MKV selection\nand reuse. In the first stage, clients locally apply LEKE and upload the\ncomputed MKVs. In the second stage, rather than relying solely on server-based\nMKV sharing, FLEKE allows clients retrieve relevant MKVs based on cosine\nsimilarity, enabling knowledge re-edit and minimizing redundant computations.\nExperimental results on two benchmark datasets demonstrate that FedEdit retains\nover 96% of the performance of non-federated LEKE while significantly\noutperforming a FedAvg-based baseline by approximately twofold. Besides, we\nfind that MEMIT performs more consistently than PMET in the FLEKE task with our\nFedEdit framework. Our code is available at https://github.com/zongkaiz/FLEKE.",
      "pdf_url": "http://arxiv.org/pdf/2502.15677v1",
      "published": "2025-02-21T18:58:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.15677v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "AutoToM: Automated Bayesian Inverse Planning and Model Discovery for Open-ended Theory of Mind",
      "authors": [
        "Zhining Zhang",
        "Chuanyang Jin",
        "Mung Yao Jia",
        "Tianmin Shu"
      ],
      "abstract": "Theory of Mind (ToM), the ability to understand people's mental variables\nbased on their behavior, is key to developing socially intelligent agents.\nCurrent approaches to Theory of Mind reasoning either rely on prompting Large\nLanguage Models (LLMs), which are prone to systematic errors, or use rigid,\nhandcrafted Bayesian Theory of Mind (BToM) models, which are more robust but\ncannot generalize across different domains. In this work, we introduce AutoToM,\nan automated Bayesian Theory of Mind method for achieving open-ended machine\nTheory of Mind. AutoToM can operate in any domain, infer any mental variable,\nand conduct robust Theory of Mind reasoning of any order. Given a Theory of\nMind inference problem, AutoToM first proposes an initial BToM model. It then\nconducts automated Bayesian inverse planning based on the proposed model,\nleveraging an LLM as the backend. Based on the uncertainty of the inference, it\niteratively refines the model, by introducing additional mental variables\nand/or incorporating more timesteps in the context. Empirical evaluations\nacross multiple Theory of Mind benchmarks demonstrate that AutoToM consistently\nachieves state-of-the-art performance, offering a scalable, robust, and\ninterpretable approach to machine Theory of Mind.",
      "pdf_url": "http://arxiv.org/pdf/2502.15676v1",
      "published": "2025-02-21T18:57:52+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.15676v1",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "VaViM and VaVAM: Autonomous Driving through Video Generative Modeling",
      "authors": [
        "Florent Bartoccioni",
        "Elias Ramzi",
        "Victor Besnier",
        "Shashanka Venkataramanan",
        "Tuan-Hung Vu",
        "Yihong Xu",
        "Loick Chambon",
        "Spyros Gidaris",
        "Serkan Odabas",
        "David Hurych",
        "Renaud Marlet",
        "Alexandre Boulch",
        "Mickael Chen",
        "Éloi Zablocki",
        "Andrei Bursuc",
        "Eduardo Valle",
        "Matthieu Cord"
      ],
      "abstract": "We explore the potential of large-scale generative video models for\nautonomous driving, introducing an open-source auto-regressive video model\n(VaViM) and its companion video-action model (VaVAM) to investigate how video\npre-training transfers to real-world driving. VaViM is a simple auto-regressive\nvideo model that predicts frames using spatio-temporal token sequences. We show\nthat it captures the semantics and dynamics of driving scenes. VaVAM, the\nvideo-action model, leverages the learned representations of VaViM to generate\ndriving trajectories through imitation learning. Together, the models form a\ncomplete perception-to-action pipeline. We evaluate our models in open- and\nclosed-loop driving scenarios, revealing that video-based pre-training holds\npromise for autonomous driving. Key insights include the semantic richness of\nthe learned representations, the benefits of scaling for video synthesis, and\nthe complex relationship between model size, data, and safety metrics in\nclosed-loop evaluations. We release code and model weights at\nhttps://github.com/valeoai/VideoActionModel",
      "pdf_url": "http://arxiv.org/pdf/2502.15672v1",
      "published": "2025-02-21T18:56:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.15672v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ]
    },
    {
      "title": "Almost AI, Almost Human: The Challenge of Detecting AI-Polished Writing",
      "authors": [
        "Shoumik Saha",
        "Soheil Feizi"
      ],
      "abstract": "The growing use of large language models (LLMs) for text generation has led\nto widespread concerns about AI-generated content detection. However, an\noverlooked challenge is AI-polished text, where human-written content undergoes\nsubtle refinements using AI tools. This raises a critical question: should\nminimally polished text be classified as AI-generated? Misclassification can\nlead to false plagiarism accusations and misleading claims about AI prevalence\nin online content. In this study, we systematically evaluate eleven\nstate-of-the-art AI-text detectors using our AI-Polished-Text Evaluation\n(APT-Eval) dataset, which contains $11.7K$ samples refined at varying\nAI-involvement levels. Our findings reveal that detectors frequently\nmisclassify even minimally polished text as AI-generated, struggle to\ndifferentiate between degrees of AI involvement, and exhibit biases against\nolder and smaller models. These limitations highlight the urgent need for more\nnuanced detection methodologies.",
      "pdf_url": "http://arxiv.org/pdf/2502.15666v1",
      "published": "2025-02-21T18:45:37+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.15666v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ]
    },
    {
      "title": "Multi-Agent Architecture in Distributed Environment Control Systems: vision, challenges, and opportunities",
      "authors": [
        "Natasha Astudillo",
        "Fernando Koch"
      ],
      "abstract": "The increasing demand for energy-efficient solutions in large-scale\ninfrastructure, particularly data centers, requires advanced control strategies\nto optimize environmental management systems. We propose a multi-agent\narchitecture for distributed control of air-cooled chiller systems in data\ncenters. Our vision employs autonomous agents to monitor and regulate local\noperational parameters and optimize system-wide efficiency. We demonstrate how\nthis approach improves the responsiveness, operational robustness, and energy\nefficiency of the system, contributing to the broader goal of sustainable\ninfrastructure management.",
      "pdf_url": "http://arxiv.org/pdf/2502.15663v1",
      "published": "2025-02-21T18:41:03+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.15663v1",
      "categories": [
        "cs.MA",
        "cs.AI"
      ]
    },
    {
      "title": "Automating Curriculum Learning for Reinforcement Learning using a Skill-Based Bayesian Network",
      "authors": [
        "Vincent Hsiao",
        "Mark Roberts",
        "Laura M. Hiatt",
        "George Konidaris",
        "Dana Nau"
      ],
      "abstract": "A major challenge for reinforcement learning is automatically generating\ncurricula to reduce training time or improve performance in some target task.\nWe introduce SEBNs (Skill-Environment Bayesian Networks) which model a\nprobabilistic relationship between a set of skills, a set of goals that relate\nto the reward structure, and a set of environment features to predict policy\nperformance on (possibly unseen) tasks. We develop an algorithm that uses the\ninferred estimates of agent success from SEBN to weigh the possible next tasks\nby expected improvement. We evaluate the benefit of the resulting curriculum on\nthree environments: a discrete gridworld, continuous control, and simulated\nrobotics. The results show that curricula constructed using SEBN frequently\noutperform other baselines.",
      "pdf_url": "http://arxiv.org/pdf/2502.15662v1",
      "published": "2025-02-21T18:38:00+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.15662v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Superintelligent Agents Pose Catastrophic Risks: Can Scientist AI Offer a Safer Path?",
      "authors": [
        "Yoshua Bengio",
        "Michael Cohen",
        "Damiano Fornasiere",
        "Joumana Ghosn",
        "Pietro Greiner",
        "Matt MacDermott",
        "Sören Mindermann",
        "Adam Oberman",
        "Jesse Richardson",
        "Oliver Richardson",
        "Marc-Antoine Rondeau",
        "Pierre-Luc St-Charles",
        "David Williams-King"
      ],
      "abstract": "The leading AI companies are increasingly focused on building generalist AI\nagents -- systems that can autonomously plan, act, and pursue goals across\nalmost all tasks that humans can perform. Despite how useful these systems\nmight be, unchecked AI agency poses significant risks to public safety and\nsecurity, ranging from misuse by malicious actors to a potentially irreversible\nloss of human control. We discuss how these risks arise from current AI\ntraining methods. Indeed, various scenarios and experiments have demonstrated\nthe possibility of AI agents engaging in deception or pursuing goals that were\nnot specified by human operators and that conflict with human interests, such\nas self-preservation. Following the precautionary principle, we see a strong\nneed for safer, yet still useful, alternatives to the current agency-driven\ntrajectory. Accordingly, we propose as a core building block for further\nadvances the development of a non-agentic AI system that is trustworthy and\nsafe by design, which we call Scientist AI. This system is designed to explain\nthe world from observations, as opposed to taking actions in it to imitate or\nplease humans. It comprises a world model that generates theories to explain\ndata and a question-answering inference machine. Both components operate with\nan explicit notion of uncertainty to mitigate the risks of overconfident\npredictions. In light of these considerations, a Scientist AI could be used to\nassist human researchers in accelerating scientific progress, including in AI\nsafety. In particular, our system can be employed as a guardrail against AI\nagents that might be created despite the risks involved. Ultimately, focusing\non non-agentic AI may enable the benefits of AI innovation while avoiding the\nrisks associated with the current trajectory. We hope these arguments will\nmotivate researchers, developers, and policymakers to favor this safer path.",
      "pdf_url": "http://arxiv.org/pdf/2502.15657v1",
      "published": "2025-02-21T18:28:36+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.15657v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Empowering LLMs with Logical Reasoning: A Comprehensive Survey",
      "authors": [
        "Fengxiang Cheng",
        "Haoxuan Li",
        "Fenrong Liu",
        "Robert van Rooij",
        "Kun Zhang",
        "Zhouchen Lin"
      ],
      "abstract": "Large language models (LLMs) have achieved remarkable successes on various\nnatural language tasks. However, recent studies have found that there are still\nsignificant challenges to the logical reasoning abilities of LLMs. This paper\nsummarizes and categorizes the main challenges into two aspects: (1) Logical\nquestion answering, LLMs often fail to generate the correct answer within\ncomplex logical problem which requires sophisticated deductive, inductive or\nabductive reasoning given a collection of premises and constrains. (2) Logical\nconsistency, LLMs are prone to producing responses contradicting themselves\nacross different questions. For example, a state-of-the-art Macaw\nquestion-answering LLM answers Yes to both questions Is a magpie a bird? and\nDoes a bird have wings? but answers No to Does a magpie have wings?. To\nfacilitate this research direction, we comprehensively investigate the most\ncutting-edge methods and propose detailed taxonomies of these methods.\nSpecifically, to accurately answer complex logic questions, previous methods\ncan be categorized based on reliance on external solvers, prompts, pretraining,\nand fine-tuning. To avoid logical contradictions, we discuss concepts and\nsolutions of various logical consistencies, including implication, negation,\ntransitivity, factuality consistency, and their composites. In addition, we\nreview commonly used benchmark datasets and evaluation metrics, and discuss\npromising research directions, such as extensions to modal logic to account for\nuncertainty, and efficient algorithms satisfying multiple logical consistencies\nsimultaneously.",
      "pdf_url": "http://arxiv.org/pdf/2502.15652v1",
      "published": "2025-02-21T18:20:35+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.15652v1",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "AutoTandemML: Active Learning Enhanced Tandem Neural Networks for Inverse Design Problems",
      "authors": [
        "Luka Grbcic",
        "Juliane Müller",
        "Wibe Albert de Jong"
      ],
      "abstract": "Inverse design in science and engineering involves determining optimal design\nparameters that achieve desired performance outcomes, a process often hindered\nby the complexity and high dimensionality of design spaces, leading to\nsignificant computational costs. To tackle this challenge, we propose a novel\nhybrid approach that combines active learning with Tandem Neural Networks to\nenhance the efficiency and effectiveness of solving inverse design problems.\nActive learning allows to selectively sample the most informative data points,\nreducing the required dataset size without compromising accuracy. We\ninvestigate this approach using three benchmark problems: airfoil inverse\ndesign, photonic surface inverse design, and scalar boundary condition\nreconstruction in diffusion partial differential equations. We demonstrate that\nintegrating active learning with Tandem Neural Networks outperforms standard\napproaches across the benchmark suite, achieving better accuracy with fewer\ntraining samples.",
      "pdf_url": "http://arxiv.org/pdf/2502.15643v1",
      "published": "2025-02-21T18:10:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.15643v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE",
        "cs.NE"
      ]
    },
    {
      "title": "Steering into New Embedding Spaces: Analyzing Cross-Lingual Alignment Induced by Model Interventions in Multilingual Language Models",
      "authors": [
        "Anirudh Sundar",
        "Sinead Williamson",
        "Katherine Metcalf",
        "Barry-John Theobald",
        "Skyler Seto",
        "Masha Fedzechkina"
      ],
      "abstract": "Aligned representations across languages is a desired property in\nmultilingual large language models (mLLMs), as alignment can improve\nperformance in cross-lingual tasks. Typically alignment requires fine-tuning a\nmodel, which is computationally expensive, and sizable language data, which\noften may not be available. A data-efficient alternative to fine-tuning is\nmodel interventions -- a method for manipulating model activations to steer\ngeneration into the desired direction. We analyze the effect of a popular\nintervention (finding experts) on the alignment of cross-lingual\nrepresentations in mLLMs. We identify the neurons to manipulate for a given\nlanguage and introspect the embedding space of mLLMs pre- and\npost-manipulation. We show that modifying the mLLM's activations changes its\nembedding space such that cross-lingual alignment is enhanced. Further, we show\nthat the changes to the embedding space translate into improved downstream\nperformance on retrieval tasks, with up to 2x improvements in top-1 accuracy on\ncross-lingual retrieval.",
      "pdf_url": "http://arxiv.org/pdf/2502.15639v1",
      "published": "2025-02-21T18:09:54+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.15639v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Mantis: Lightweight Calibrated Foundation Model for User-Friendly Time Series Classification",
      "authors": [
        "Vasilii Feofanov",
        "Songkang Wen",
        "Marius Alonso",
        "Romain Ilbert",
        "Hongbo Guo",
        "Malik Tiomoko",
        "Lujia Pan",
        "Jianfeng Zhang",
        "Ievgen Redko"
      ],
      "abstract": "In recent years, there has been increasing interest in developing foundation\nmodels for time series data that can generalize across diverse downstream\ntasks. While numerous forecasting-oriented foundation models have been\nintroduced, there is a notable scarcity of models tailored for time series\nclassification. To address this gap, we present Mantis, a new open-source\nfoundation model for time series classification based on the Vision Transformer\n(ViT) architecture that has been pre-trained using a contrastive learning\napproach. Our experimental results show that Mantis outperforms existing\nfoundation models both when the backbone is frozen and when fine-tuned, while\nachieving the lowest calibration error. In addition, we propose several\nadapters to handle the multivariate setting, reducing memory requirements and\nmodeling channel interdependence.",
      "pdf_url": "http://arxiv.org/pdf/2502.15637v1",
      "published": "2025-02-21T18:06:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.15637v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ]
    },
    {
      "title": "The Relationship Between Reasoning and Performance in Large Language Models -- o3 (mini) Thinks Harder, Not Longer",
      "authors": [
        "Marthe Ballon",
        "Andres Algaba",
        "Vincent Ginis"
      ],
      "abstract": "Large language models have demonstrated remarkable progress in mathematical\nreasoning, leveraging chain-of-thought and test-time compute scaling. However,\nmany open questions remain regarding the interplay between reasoning token\nusage and accuracy gains. In particular, when comparing models across\ngenerations, it is unclear whether improved performance results from longer\nreasoning chains or more efficient reasoning. We systematically analyze\nchain-of-thought length across o1-mini and o3-mini variants on the Omni-MATH\nbenchmark, finding that o3-mini (m) achieves superior accuracy without\nrequiring longer reasoning chains than o1-mini. Moreover, we show that accuracy\ngenerally declines as reasoning chains grow across all models and compute\nsettings, even when controlling for difficulty of the questions. This accuracy\ndrop is significantly smaller in more proficient models, suggesting that new\ngenerations of reasoning models use test-time compute more effectively.\nFinally, we highlight that while o3-mini (h) achieves a marginal accuracy gain\nover o3-mini (m), it does so by allocating substantially more reasoning tokens\nacross all problems, even the ones that o3-mini (m) can already solve. These\nfindings provide new insights into the relationship between model capability\nand reasoning length, with implications for efficiency, scaling, and evaluation\nmethodologies.",
      "pdf_url": "http://arxiv.org/pdf/2502.15631v1",
      "published": "2025-02-21T17:59:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.15631v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Dynamic Knowledge Selector and Evaluator for recommendation with Knowledge Graph",
      "authors": [
        "Feng Xia",
        "Zhifei Hu"
      ],
      "abstract": "In recent years recommendation systems typically employ the edge information\nprovided by knowledge graphs combined with the advantages of high-order\nconnectivity of graph networks in the recommendation field. However, this\nmethod is limited by the sparsity of labels, cannot learn the graph structure\nwell, and a large number of noisy entities in the knowledge graph will affect\nthe accuracy of the recommendation results. In order to alleviate the above\nproblems, we propose a dynamic knowledge-selecting and evaluating method guided\nby collaborative signals to distill information in the knowledge graph.\nSpecifically, we use a Chain Route Evaluator to evaluate the contributions of\ndifferent neighborhoods for the recommendation task and employ a Knowledge\nSelector strategy to filter the less informative knowledge before evaluating.\nWe conduct baseline model comparison and experimental ablation evaluations on\nthree public datasets. The experiments demonstrate that our proposed model\noutperforms current state-of-the-art baseline models, and each modules\neffectiveness in our model is demonstrated through ablation experiments.",
      "pdf_url": "http://arxiv.org/pdf/2502.15623v1",
      "published": "2025-02-21T17:51:37+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.15623v1",
      "categories": [
        "cs.IR",
        "cs.AI"
      ]
    },
    {
      "title": "Paradigms of AI Evaluation: Mapping Goals, Methodologies and Culture",
      "authors": [
        "John Burden",
        "Marko Tešić",
        "Lorenzo Pacchiardi",
        "José Hernández-Orallo"
      ],
      "abstract": "Research in AI evaluation has grown increasingly complex and\nmultidisciplinary, attracting researchers with diverse backgrounds and\nobjectives. As a result, divergent evaluation paradigms have emerged, often\ndeveloping in isolation, adopting conflicting terminologies, and overlooking\neach other's contributions. This fragmentation has led to insular research\ntrajectories and communication barriers both among different paradigms and with\nthe general public, contributing to unmet expectations for deployed AI systems.\nTo help bridge this insularity, in this paper we survey recent work in the AI\nevaluation landscape and identify six main paradigms. We characterise major\nrecent contributions within each paradigm across key dimensions related to\ntheir goals, methodologies and research cultures. By clarifying the unique\ncombination of questions and approaches associated with each paradigm, we aim\nto increase awareness of the breadth of current evaluation approaches and\nfoster cross-pollination between different paradigms. We also identify\npotential gaps in the field to inspire future research directions.",
      "pdf_url": "http://arxiv.org/pdf/2502.15620v1",
      "published": "2025-02-21T17:44:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.15620v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Extraction multi-étiquettes de relations en utilisant des couches de Transformer",
      "authors": [
        "Ngoc Luyen Le",
        "Gildas Tagny Ngompé"
      ],
      "abstract": "In this article, we present the BTransformer18 model, a deep learning\narchitecture designed for multi-label relation extraction in French texts. Our\napproach combines the contextual representation capabilities of pre-trained\nlanguage models from the BERT family - such as BERT, RoBERTa, and their French\ncounterparts CamemBERT and FlauBERT - with the power of Transformer encoders to\ncapture long-term dependencies between tokens. Experiments conducted on the\ndataset from the TextMine'25 challenge show that our model achieves superior\nperformance, particularly when using CamemBERT-Large, with a macro F1 score of\n0.654, surpassing the results obtained with FlauBERT-Large. These results\ndemonstrate the effectiveness of our approach for the automatic extraction of\ncomplex relations in intelligence reports.",
      "pdf_url": "http://arxiv.org/pdf/2502.15619v1",
      "published": "2025-02-21T17:42:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.15619v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Probe Pruning: Accelerating LLMs through Dynamic Pruning via Model-Probing",
      "authors": [
        "Qi Le",
        "Enmao Diao",
        "Ziyan Wang",
        "Xinran Wang",
        "Jie Ding",
        "Li Yang",
        "Ali Anwar"
      ],
      "abstract": "We introduce Probe Pruning (PP), a novel framework for online, dynamic,\nstructured pruning of Large Language Models (LLMs) applied in a batch-wise\nmanner. PP leverages the insight that not all samples and tokens contribute\nequally to the model's output, and probing a small portion of each batch\neffectively identifies crucial weights, enabling tailored dynamic pruning for\ndifferent batches. It comprises three main stages: probing, history-informed\npruning, and full inference. In the probing stage, PP selects a small yet\ncrucial set of hidden states, based on residual importance, to run a few model\nlayers ahead. During the history-informed pruning stage, PP strategically\nintegrates the probing states with historical states. Subsequently, it\nstructurally prunes weights based on the integrated states and the PP\nimportance score, a metric developed specifically to assess the importance of\neach weight channel in maintaining performance. In the final stage, full\ninference is conducted on the remaining weights. A major advantage of PP is its\ncompatibility with existing models, as it operates without requiring additional\nneural network modules or fine-tuning. Comprehensive evaluations of PP on\nLLaMA-2/3 and OPT models reveal that even minimal probing-using just 1.5% of\nFLOPs-can substantially enhance the efficiency of structured pruning of LLMs.\nFor instance, when evaluated on LLaMA-2-7B with WikiText2, PP achieves a 2.56\ntimes lower ratio of performance degradation per unit of runtime reduction\ncompared to the state-of-the-art method at a 40% pruning ratio. Our code is\navailable at https://github.com/Qi-Le1/Probe_Pruning.",
      "pdf_url": "http://arxiv.org/pdf/2502.15618v1",
      "published": "2025-02-21T17:41:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.15618v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Pastiche Novel Generation Creating: Fan Fiction You Love in Your Favorite Author's Style",
      "authors": [
        "Xueran Han",
        "Yuhan Liu",
        "Mingzhe Li",
        "Wei Liu",
        "Sen Hu",
        "Rui Yan",
        "Zhiqiang Xu",
        "Xiuying Chen"
      ],
      "abstract": "Great novels create immersive worlds with rich character arcs,\nwell-structured plots, and nuanced writing styles. However, current novel\ngeneration methods often rely on brief, simplistic story outlines and generate\ndetails using plain, generic language. To bridge this gap, we introduce the\ntask of Pastiche Novel Generation, which requires the generated novels to\nimitate the distinctive features of the original work, including understanding\ncharacter profiles, predicting plausible plot developments, and writing\nconcrete details using vivid, expressive language. To achieve this, we propose\nWriterAgent, a novel generation system designed to master the core aspects of\nliterary pastiche. WriterAgent is trained through a curriculum learning\nparadigm, progressing from low-level stylistic mastery to high-level narrative\ncoherence. Its key tasks include language style learning, character modeling,\nplot planning, and stylish writing, ensuring comprehensive narrative control.\nTo support this, WriterAgent leverages the WriterLoRA framework, an extension\nof LoRA with hierarchical and cumulative task-specific modules, each\nspecializing in a different narrative aspect. We evaluate WriterAgent on\nmultilingual classics like Harry Potter and Dream of the Red Chamber,\ndemonstrating its superiority over baselines in capturing the target author's\nsettings, character dynamics, and writing style to produce coherent, faithful\nnarratives.",
      "pdf_url": "http://arxiv.org/pdf/2502.15616v1",
      "published": "2025-02-21T17:40:42+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.15616v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "PDeepPP:A Deep learning framework with Pretrained Protein language for peptide classification",
      "authors": [
        "Jixiu Zhai",
        "Tianchi Lu",
        "Haitian Zhong",
        "Ziyang Xu",
        "Yuhuan Liu",
        "Xueying Wang",
        "Dan Huang"
      ],
      "abstract": "Protein post-translational modifications (PTMs) and bioactive peptides (BPs)\nplay critical roles in various biological processes and have significant\ntherapeutic potential. However, identifying PTM sites and bioactive peptides\nthrough experimental methods is often labor-intensive, costly, and\ntime-consuming. As a result, computational tools, particularly those based on\ndeep learning, have become effective solutions for predicting PTM sites and\npeptide bioactivity. Despite progress in this field, existing methods still\nstruggle with the complexity of protein sequences and the challenge of\nrequiring high-quality predictions across diverse datasets.\n  To address these issues, we propose a deep learning framework that integrates\npretrained protein language models with a neural network combining transformer\nand CNN for peptide classification. By leveraging the ability of pretrained\nmodels to capture complex relationships within protein sequences, combined with\nthe predictive power of parallel networks, our approach improves feature\nextraction while enhancing prediction accuracy.\n  This framework was applied to multiple tasks involving PTM site and bioactive\npeptide prediction, utilizing large-scale datasets to enhance the model's\nrobustness. In the comparison across 33 tasks, the model achieved\nstate-of-the-art (SOTA) performance in 25 of them, surpassing existing methods\nand demonstrating its versatility across different datasets. Our results\nsuggest that this approach provides a scalable and effective solution for\nlarge-scale peptide discovery and PTM analysis, paving the way for more\nefficient peptide classification and functional annotation.",
      "pdf_url": "http://arxiv.org/pdf/2502.15610v1",
      "published": "2025-02-21T17:31:22+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.15610v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "92C40, 68T07",
        "I.2.6; J.3"
      ]
    },
    {
      "title": "On the Robustness of Transformers against Context Hijacking for Linear Classification",
      "authors": [
        "Tianle Li",
        "Chenyang Zhang",
        "Xingwu Chen",
        "Yuan Cao",
        "Difan Zou"
      ],
      "abstract": "Transformer-based Large Language Models (LLMs) have demonstrated powerful\nin-context learning capabilities. However, their predictions can be disrupted\nby factually correct context, a phenomenon known as context hijacking,\nrevealing a significant robustness issue. To understand this phenomenon\ntheoretically, we explore an in-context linear classification problem based on\nrecent advances in linear transformers. In our setup, context tokens are\ndesigned as factually correct query-answer pairs, where the queries are similar\nto the final query but have opposite labels. Then, we develop a general\ntheoretical analysis on the robustness of the linear transformers, which is\nformulated as a function of the model depth, training context lengths, and\nnumber of hijacking context tokens. A key finding is that a well-trained deeper\ntransformer can achieve higher robustness, which aligns with empirical\nobservations. We show that this improvement arises because deeper layers enable\nmore fine-grained optimization steps, effectively mitigating interference from\ncontext hijacking. This is also well supported by our numerical experiments.\nOur findings provide theoretical insights into the benefits of deeper\narchitectures and contribute to enhancing the understanding of transformer\narchitectures.",
      "pdf_url": "http://arxiv.org/pdf/2502.15609v1",
      "published": "2025-02-21T17:31:00+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.15609v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ]
    },
    {
      "title": "Do Multilingual LLMs Think In English?",
      "authors": [
        "Lisa Schut",
        "Yarin Gal",
        "Sebastian Farquhar"
      ],
      "abstract": "Large language models (LLMs) have multilingual capabilities and can solve\ntasks across various languages. However, we show that current LLMs make key\ndecisions in a representation space closest to English, regardless of their\ninput and output languages. Exploring the internal representations with a logit\nlens for sentences in French, German, Dutch, and Mandarin, we show that the LLM\nfirst emits representations close to English for semantically-loaded words\nbefore translating them into the target language. We further show that\nactivation steering in these LLMs is more effective when the steering vectors\nare computed in English rather than in the language of the inputs and outputs.\nThis suggests that multilingual LLMs perform key reasoning steps in a\nrepresentation that is heavily shaped by English in a way that is not\ntransparent to system users.",
      "pdf_url": "http://arxiv.org/pdf/2502.15603v1",
      "published": "2025-02-21T17:19:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.15603v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "KAD: No More FAD! An Effective and Efficient Evaluation Metric for Audio Generation",
      "authors": [
        "Yoonjin Chung",
        "Pilsun Eu",
        "Junwon Lee",
        "Keunwoo Choi",
        "Juhan Nam",
        "Ben Sangbae Chon"
      ],
      "abstract": "Although being widely adopted for evaluating generated audio signals, the\nFr\\'echet Audio Distance (FAD) suffers from significant limitations, including\nreliance on Gaussian assumptions, sensitivity to sample size, and high\ncomputational complexity. As an alternative, we introduce the Kernel Audio\nDistance (KAD), a novel, distribution-free, unbiased, and computationally\nefficient metric based on Maximum Mean Discrepancy (MMD). Through analysis and\nempirical validation, we demonstrate KAD's advantages: (1) faster convergence\nwith smaller sample sizes, enabling reliable evaluation with limited data; (2)\nlower computational cost, with scalable GPU acceleration; and (3) stronger\nalignment with human perceptual judgments. By leveraging advanced embeddings\nand characteristic kernels, KAD captures nuanced differences between real and\ngenerated audio. Open-sourced in the kadtk toolkit, KAD provides an efficient,\nreliable, and perceptually aligned benchmark for evaluating generative audio\nmodels.",
      "pdf_url": "http://arxiv.org/pdf/2502.15602v1",
      "published": "2025-02-21T17:19:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.15602v1",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ]
    },
    {
      "title": "WorldCraft: Photo-Realistic 3D World Creation and Customization via LLM Agents",
      "authors": [
        "Xinhang Liu",
        "Chi-Keung Tang",
        "Yu-Wing Tai"
      ],
      "abstract": "Constructing photorealistic virtual worlds has applications across various\nfields, but it often requires the extensive labor of highly trained\nprofessionals to operate conventional 3D modeling software. To democratize this\nprocess, we introduce WorldCraft, a system where large language model (LLM)\nagents leverage procedural generation to create indoor and outdoor scenes\npopulated with objects, allowing users to control individual object attributes\nand the scene layout using intuitive natural language commands. In our\nframework, a coordinator agent manages the overall process and works with two\nspecialized LLM agents to complete the scene creation: ForgeIt, which\nintegrates an ever-growing manual through auto-verification to enable precise\ncustomization of individual objects, and ArrangeIt, which formulates\nhierarchical optimization problems to achieve a layout that balances ergonomic\nand aesthetic considerations. Additionally, our pipeline incorporates a\ntrajectory control agent, allowing users to animate the scene and operate the\ncamera through natural language interactions. Our system is also compatible\nwith off-the-shelf deep 3D generators to enrich scene assets. Through\nevaluations and comparisons with state-of-the-art methods, we demonstrate the\nversatility of WorldCraft, ranging from single-object customization to\nintricate, large-scale interior and exterior scene designs. This system\nempowers non-professionals to bring their creative visions to life.",
      "pdf_url": "http://arxiv.org/pdf/2502.15601v1",
      "published": "2025-02-21T17:18:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.15601v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ]
    },
    {
      "title": "Generalizing From Short to Long: Effective Data Synthesis for Long-Context Instruction Tuning",
      "authors": [
        "Wenhao Zhu",
        "Pinzhen Chen",
        "Hanxu Hu",
        "Shujian Huang",
        "Fei Yuan",
        "Jiajun Chen",
        "Alexandra Birch"
      ],
      "abstract": "Long-context modelling for large language models (LLMs) has been a key area\nof recent research because many real world use cases require reasoning over\nlonger inputs such as documents. The focus of research into modelling long\ncontext has been on how to model position and there has been little\ninvestigation into other important aspects of language modelling such as\ninstruction tuning. Long context training examples are challenging and\nexpensive to create and use. In this paper, we investigate how to design\ninstruction data for the post-training phase of a long context pre-trained\nmodel: how much and what type of context is needed for optimal and efficient\npost-training. Our controlled study reveals that models instruction-tuned on\nshort contexts can effectively generalize to longer ones, while also\nidentifying other critical factors such as instruction difficulty and context\ncomposition. Based on these findings, we propose context synthesis, a novel\ndata synthesis framework that leverages off-the-shelf LLMs to generate extended\nbackground contexts for high-quality instruction-answer pairs. Experiment\nresults on the document-level benchmark (LongBench) demonstrate that our\nproposed approach outperforms previous instruction synthesis approaches and\ncomes close to the performance of human-annotated long-context instruction\ndata. The project will be available at:\nhttps://github.com/NJUNLP/context-synthesis.",
      "pdf_url": "http://arxiv.org/pdf/2502.15592v1",
      "published": "2025-02-21T17:02:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.15592v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "LightThinker: Thinking Step-by-Step Compression",
      "authors": [
        "Jintian Zhang",
        "Yuqi Zhu",
        "Mengshu Sun",
        "Yujie Luo",
        "Shuofei Qiao",
        "Lun Du",
        "Da Zheng",
        "Huajun Chen",
        "Ningyu Zhang"
      ],
      "abstract": "Large language models (LLMs) have shown remarkable performance in complex\nreasoning tasks, but their efficiency is hindered by the substantial memory and\ncomputational costs associated with generating lengthy tokens. In this paper,\nwe propose LightThinker, a novel method that enables LLMs to dynamically\ncompress intermediate thoughts during reasoning. Inspired by human cognitive\nprocesses, LightThinker compresses verbose thought steps into compact\nrepresentations and discards the original reasoning chains, thereby\nsignificantly reducing the number of tokens stored in the context window. This\nis achieved by training the model on when and how to perform compression\nthrough data construction, mapping hidden states to condensed gist tokens, and\ncreating specialized attention masks. Additionally, we introduce the Dependency\n(Dep) metric to quantify the degree of compression by measuring the reliance on\nhistorical tokens during generation. Extensive experiments on four datasets and\ntwo models show that LightThinker reduces peak memory usage and inference time,\nwhile maintaining competitive accuracy. Our work provides a new direction for\nimproving the efficiency of LLMs in complex reasoning tasks without sacrificing\nperformance. Code will be released at https://github.com/zjunlp/LightThinker.",
      "pdf_url": "http://arxiv.org/pdf/2502.15589v1",
      "published": "2025-02-21T16:57:22+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.15589v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG",
        "cs.MM"
      ]
    },
    {
      "title": "Improving the Scaling Laws of Synthetic Data with Deliberate Practice",
      "authors": [
        "Reyhane Askari-Hemmat",
        "Mohammad Pezeshki",
        "Elvis Dohmatob",
        "Florian Bordes",
        "Pietro Astolfi",
        "Melissa Hall",
        "Jakob Verbeek",
        "Michal Drozdzal",
        "Adriana Romero-Soriano"
      ],
      "abstract": "Inspired by the principle of deliberate practice in human learning, we\npropose Deliberate Practice for Synthetic Data Generation (DP), a novel\nframework that improves sample efficiency through dynamic synthetic data\ngeneration. Prior work has shown that scaling synthetic data is inherently\nchallenging, as naively adding new data leads to diminishing returns. To\naddress this, pruning has been identified as a key mechanism for improving\nscaling, enabling models to focus on the most informative synthetic samples.\nRather than generating a large dataset and pruning it afterward, DP efficiently\napproximates the direct generation of informative samples. We theoretically\nshow how training on challenging, informative examples improves scaling laws\nand empirically validate that DP achieves better scaling performance with\nsignificantly fewer training samples and iterations. On ImageNet-100, DP\ngenerates 3.4x fewer samples and requires six times fewer iterations, while on\nImageNet-1k, it generates 8x fewer samples with a 30 percent reduction in\niterations, all while achieving superior performance compared to prior work.",
      "pdf_url": "http://arxiv.org/pdf/2502.15588v1",
      "published": "2025-02-21T16:56:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.15588v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Feature maps for the Laplacian kernel and its generalizations",
      "authors": [
        "Sudhendu Ahir",
        "Parthe Pandit"
      ],
      "abstract": "Recent applications of kernel methods in machine learning have seen a renewed\ninterest in the Laplacian kernel, due to its stability to the bandwidth\nhyperparameter in comparison to the Gaussian kernel, as well as its\nexpressivity being equivalent to that of the neural tangent kernel of deep\nfully connected networks. However, unlike the Gaussian kernel, the Laplacian\nkernel is not separable. This poses challenges for techniques to approximate\nit, especially via the random Fourier features (RFF) methodology and its\nvariants. In this work, we provide random features for the Laplacian kernel and\nits two generalizations: Mat\\'{e}rn kernel and the Exponential power kernel. We\nprovide efficiently implementable schemes to sample weight matrices so that\nrandom features approximate these kernels. These weight matrices have a weakly\ncoupled heavy-tailed randomness. Via numerical experiments on real datasets we\ndemonstrate the efficacy of these random feature maps.",
      "pdf_url": "http://arxiv.org/pdf/2502.15575v1",
      "published": "2025-02-21T16:36:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.15575v1",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "A Cautionary Tale About \"Neutrally\" Informative AI Tools Ahead of the 2025 Federal Elections in Germany",
      "authors": [
        "Ina Dormuth",
        "Sven Franke",
        "Marlies Hafer",
        "Tim Katzke",
        "Alexander Marx",
        "Emmanuel Müller",
        "Daniel Neider",
        "Markus Pauly",
        "Jérôme Rutinowski"
      ],
      "abstract": "In this study, we examine the reliability of AI-based Voting Advice\nApplications (VAAs) and large language models (LLMs) in providing objective\npolitical information. Our analysis is based upon a comparison with party\nresponses to 38 statements of the Wahl-O-Mat, a well-established German online\ntool that helps inform voters by comparing their views with political party\npositions. For the LLMs, we identify significant biases. They exhibit a strong\nalignment (over 75% on average) with left-wing parties and a substantially\nlower alignment with center-right (smaller 50%) and right-wing parties (around\n30%). Furthermore, for the VAAs, intended to objectively inform voters, we\nfound substantial deviations from the parties' stated positions in Wahl-O-Mat:\nWhile one VAA deviated in 25% of cases, another VAA showed deviations in more\nthan 50% of cases. For the latter, we even observed that simple prompt\ninjections led to severe hallucinations, including false claims such as\nnon-existent connections between political parties and right-wing extremist\nties.",
      "pdf_url": "http://arxiv.org/pdf/2502.15568v1",
      "published": "2025-02-21T16:30:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.15568v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Bridging vision language model (VLM) evaluation gaps with a framework for scalable and cost-effective benchmark generation",
      "authors": [
        "Tim Rädsch",
        "Leon Mayer",
        "Simon Pavicic",
        "A. Emre Kavur",
        "Marcel Knopp",
        "Barış Öztürk",
        "Klaus Maier-Hein",
        "Paul F. Jaeger",
        "Fabian Isensee",
        "Annika Reinke",
        "Lena Maier-Hein"
      ],
      "abstract": "Reliable evaluation of AI models is critical for scientific progress and\npractical application. While existing VLM benchmarks provide general insights\ninto model capabilities, their heterogeneous designs and limited focus on a few\nimaging domains pose significant challenges for both cross-domain performance\ncomparison and targeted domain-specific evaluation. To address this, we propose\nthree key contributions: (1) a framework for the resource-efficient creation of\ndomain-specific VLM benchmarks enabled by task augmentation for creating\nmultiple diverse tasks from a single existing task, (2) the release of new VLM\nbenchmarks for seven domains, created according to the same homogeneous\nprotocol and including 162,946 thoroughly human-validated answers, and (3) an\nextensive benchmarking of 22 state-of-the-art VLMs on a total of 37,171 tasks,\nrevealing performance variances across domains and tasks, thereby supporting\nthe need for tailored VLM benchmarks. Adoption of our methodology will pave the\nway for the resource-efficient domain-specific selection of models and guide\nfuture research efforts toward addressing core open questions.",
      "pdf_url": "http://arxiv.org/pdf/2502.15563v1",
      "published": "2025-02-21T16:24:10+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.15563v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    },
    {
      "title": "Zweistein: A Dynamic Programming Evaluation Function for Einstein Würfelt Nicht!",
      "authors": [
        "Wei Lin. Hsueh",
        "Tsan Sheng. Hsu"
      ],
      "abstract": "This paper introduces Zweistein, a dynamic programming evaluation function\nfor Einstein W\\\"urfelt Nicht! (EWN). Instead of relying on human knowledge to\ncraft an evaluation function, Zweistein uses a data-centric approach that\neliminates the need for parameter tuning. The idea is to use a vector recording\nthe distance to the corner of all pieces. This distance vector captures the\nessence of EWN. It not only outperforms many traditional EWN evaluation\nfunctions but also won first place in the TCGA 2023 competition.",
      "pdf_url": "http://arxiv.org/pdf/2502.15547v1",
      "published": "2025-02-21T15:54:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.15547v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "PIP-KAG: Mitigating Knowledge Conflicts in Knowledge-Augmented Generation via Parametric Pruning",
      "authors": [
        "Pengcheng Huang",
        "Zhenghao Liu",
        "Yukun Yan",
        "Xiaoyuan Yi",
        "Hao Chen",
        "Zhiyuan Liu",
        "Maosong Sun",
        "Tong Xiao",
        "Ge Yu",
        "Chenyan Xiong"
      ],
      "abstract": "Knowledge-Augmented Generation (KAG) has shown great promise in updating the\ninternal memory of Large Language Models (LLMs) by integrating external\nknowledge. However, KAG inevitably faces knowledge conflicts when the internal\nmemory contradicts external information. Current approaches to mitigating these\nconflicts mainly focus on improving external knowledge utilization. However,\nthese methods have shown only limited effectiveness in mitigating the knowledge\nconflict problem, as internal knowledge continues to influence the generation\nprocess of LLMs. In this paper, we propose a ParametrIc Pruning-based\nKnowledge-Augmented Generation (PIP-KAG) approach, which prunes internal\nknowledge of LLMs and incorporates a plug-and-play adaptation module to help\nLLMs better leverage external sources. Additionally, we construct the\nCoConflictQA benchmark based on the hallucination of LLMs to better evaluate\ncontextual faithfulness during answering questions. Experimental results on\nCoConflictQA demonstrate that PIP-KAG significantly reduces knowledge conflicts\nand improves context fidelity. Notably, PIP-KAG reduces LLM's parameters by\n13%, enhancing parameter efficiency in LLMs within the KAG framework. All codes\nare available at https://github.com/OpenBMB/PIP-KAG.",
      "pdf_url": "http://arxiv.org/pdf/2502.15543v1",
      "published": "2025-02-21T15:50:41+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.15543v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Bridging Domain Gaps between Pretrained Multimodal Models and Recommendations",
      "authors": [
        "Wenyu Zhang",
        "Jie Luo",
        "Xinming Zhang",
        "Yuan Fang"
      ],
      "abstract": "With the explosive growth of multimodal content online, pre-trained\nvisual-language models have shown great potential for multimodal\nrecommendation. However, while these models achieve decent performance when\napplied in a frozen manner, surprisingly, due to significant domain gaps (e.g.,\nfeature distribution discrepancy and task objective misalignment) between\npre-training and personalized recommendation, adopting a joint training\napproach instead leads to performance worse than baseline. Existing approaches\neither rely on simple feature extraction or require computationally expensive\nfull model fine-tuning, struggling to balance effectiveness and efficiency. To\ntackle these challenges, we propose \\textbf{P}arameter-efficient\n\\textbf{T}uning for \\textbf{M}ultimodal \\textbf{Rec}ommendation\n(\\textbf{PTMRec}), a novel framework that bridges the domain gap between\npre-trained models and recommendation systems through a knowledge-guided\ndual-stage parameter-efficient training strategy. This framework not only\neliminates the need for costly additional pre-training but also flexibly\naccommodates various parameter-efficient tuning methods.",
      "pdf_url": "http://arxiv.org/pdf/2502.15542v1",
      "published": "2025-02-21T15:50:14+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.15542v1",
      "categories": [
        "cs.IR",
        "cs.AI"
      ]
    },
    {
      "title": "Depth-aware Fusion Method based on Image and 4D Radar Spectrum for 3D Object Detection",
      "authors": [
        "Yue Sun",
        "Yeqiang Qian",
        "Chunxiang Wang",
        "Ming Yang"
      ],
      "abstract": "Safety and reliability are crucial for the public acceptance of autonomous\ndriving. To ensure accurate and reliable environmental perception, intelligent\nvehicles must exhibit accuracy and robustness in various environments.\nMillimeter-wave radar, known for its high penetration capability, can operate\neffectively in adverse weather conditions such as rain, snow, and fog.\nTraditional 3D millimeter-wave radars can only provide range, Doppler, and\nazimuth information for objects. Although the recent emergence of 4D\nmillimeter-wave radars has added elevation resolution, the radar point clouds\nremain sparse due to Constant False Alarm Rate (CFAR) operations. In contrast,\ncameras offer rich semantic details but are sensitive to lighting and weather\nconditions. Hence, this paper leverages these two highly complementary and\ncost-effective sensors, 4D millimeter-wave radar and camera. By integrating 4D\nradar spectra with depth-aware camera images and employing attention\nmechanisms, we fuse texture-rich images with depth-rich radar data in the\nBird's Eye View (BEV) perspective, enhancing 3D object detection. Additionally,\nwe propose using GAN-based networks to generate depth images from radar spectra\nin the absence of depth sensors, further improving detection accuracy.",
      "pdf_url": "http://arxiv.org/pdf/2502.15516v1",
      "published": "2025-02-21T15:14:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.15516v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ]
    },
    {
      "title": "Activation Steering in Neural Theorem Provers",
      "authors": [
        "Shashank Kirtania"
      ],
      "abstract": "Large Language Models (LLMs) have shown promise in proving formal theorems\nusing proof assistants like Lean. However, current state of the art language\nmodels struggles to predict next step in proofs leading practitioners to use\ndifferent sampling techniques to improve LLMs capabilities. We observe that the\nLLM is capable of predicting the correct tactic; however, it faces challenges\nin ranking it appropriately within the set of candidate tactics, affecting the\noverall selection process. To overcome this hurdle, we use activation steering\nto guide LLMs responses to improve the generations at the time of inference.\nOur results suggest that activation steering offers a promising lightweight\nalternative to specialized fine-tuning for enhancing theorem proving\ncapabilities in LLMs, particularly valuable in resource-constrained\nenvironments.",
      "pdf_url": "http://arxiv.org/pdf/2502.15507v1",
      "published": "2025-02-21T15:04:48+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.15507v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "BAN: Neuroanatomical Aligning in Auditory Recognition between Artificial Neural Network and Human Cortex",
      "authors": [
        "Haidong Wang",
        "Pengfei Xiao",
        "Ao Liu",
        "Jianhua Zhang",
        "Qia Shan"
      ],
      "abstract": "Drawing inspiration from neurosciences, artificial neural networks (ANNs)\nhave evolved from shallow architectures to highly complex, deep structures,\nyielding exceptional performance in auditory recognition tasks. However,\ntraditional ANNs often struggle to align with brain regions due to their\nexcessive depth and lack of biologically realistic features, like recurrent\nconnection. To address this, a brain-like auditory network (BAN) is introduced,\nwhich incorporates four neuroanatomically mapped areas and recurrent\nconnection, guided by a novel metric called the brain-like auditory score\n(BAS). BAS serves as a benchmark for evaluating the similarity between BAN and\nhuman auditory recognition pathway. We further propose that specific areas in\nthe cerebral cortex, mainly the middle and medial superior temporal (T2/T3)\nareas, correspond to the designed network structure, drawing parallels with the\nbrain's auditory perception pathway. Our findings suggest that the\nneuroanatomical similarity in the cortex and auditory classification abilities\nof the ANN are well-aligned. In addition to delivering excellent performance on\na music genre classification task, the BAN demonstrates a high BAS score. In\nconclusion, this study presents BAN as a recurrent, brain-inspired ANN,\nrepresenting the first model that mirrors the cortical pathway of auditory\nrecognition.",
      "pdf_url": "http://arxiv.org/pdf/2502.15503v1",
      "published": "2025-02-21T14:57:01+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.15503v1",
      "categories": [
        "q-bio.NC",
        "cs.AI"
      ]
    },
    {
      "title": "Q-PETR: Quant-aware Position Embedding Transformation for Multi-View 3D Object Detection",
      "authors": [
        "Jiangyong Yu",
        "Changyong Shu",
        "Dawei Yang",
        "Zichen Yu",
        "Xing Hu",
        "Yan Chen"
      ],
      "abstract": "PETR-based methods have dominated benchmarks in 3D perception and are\nincreasingly becoming a key component in modern autonomous driving systems.\nHowever, their quantization performance significantly degrades when INT8\ninference is required, with a degradation of 58.2% in mAP and 36.9% in NDS on\nthe NuScenes dataset. To address this issue, we propose a quantization-aware\nposition embedding transformation for multi-view 3D object detection, termed\nQ-PETR. Q-PETR offers a quantizationfriendly and deployment-friendly\narchitecture while preserving the original performance of PETR. It\nsubstantially narrows the accuracy gap between INT8 and FP32 inference for\nPETR-series methods. Without bells and whistles, our approach reduces the mAP\nand NDS drop to within 1% under standard 8-bit per-tensor post-training\nquantization. Furthermore, our method exceeds the performance of the original\nPETR in terms of floating-point precision. Extensive experiments across a\nvariety of PETR-series models demonstrate its broad generalization.",
      "pdf_url": "http://arxiv.org/pdf/2502.15488v1",
      "published": "2025-02-21T14:26:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.15488v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "ExpliCa: Evaluating Explicit Causal Reasoning in Large Language Models",
      "authors": [
        "Martina Miliani",
        "Serenna Auriemma",
        "Alessandro Bondielli",
        "Emmanuele Chersoni",
        "Lucia Passaro",
        "Irene Sucameli",
        "Alessandro Lenci"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly used in tasks requiring\ninterpretive and inferential accuracy. In this paper, we introduce ExpliCa, a\nnew dataset for evaluating LLMs in explicit causal reasoning. ExpliCa uniquely\nintegrates both causal and temporal relations presented in different linguistic\norders and explicitly expressed by linguistic connectives. The dataset is\nenriched with crowdsourced human acceptability ratings. We tested LLMs on\nExpliCa through prompting and perplexity-based metrics. We assessed seven\ncommercial and open-source LLMs, revealing that even top models struggle to\nreach 0.80 accuracy. Interestingly, models tend to confound temporal relations\nwith causal ones, and their performance is also strongly influenced by the\nlinguistic order of the events. Finally, perplexity-based scores and prompting\nperformance are differently affected by model size.",
      "pdf_url": "http://arxiv.org/pdf/2502.15487v1",
      "published": "2025-02-21T14:23:14+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.15487v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "68T50, 68T07",
        "I.2.7"
      ]
    },
    {
      "title": "Enhancing RWKV-based Language Models for Long-Sequence Text Generation",
      "authors": [
        "Xinghan Pan"
      ],
      "abstract": "This paper presents an enhanced RWKV-based language generation model designed\nto improve long-sequence text processing. We propose an adaptive token shift\nand gating mechanism to better capture long-range dependencies in text\ngeneration. Through a series of experiments, we compare the baseline RWKV model\nwith the enhanced model, evaluating performance in terms of forward propagation\ntime, text generation quality, and automatic evaluation metrics such as\nperplexity, BLEU, and ROUGE. Experimental results show that the enhanced model\nsignificantly improves generation quality, especially in BLEU and ROUGE scores,\nand demonstrates stronger context-capturing ability in long-text generation\ntasks.",
      "pdf_url": "http://arxiv.org/pdf/2502.15485v1",
      "published": "2025-02-21T14:18:18+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.15485v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "PAPI: Exploiting Dynamic Parallelism in Large Language Model Decoding with a Processing-In-Memory-Enabled Computing System",
      "authors": [
        "Yintao He",
        "Haiyu Mao",
        "Christina Giannoula",
        "Mohammad Sadrosadati",
        "Juan Gómez-Luna",
        "Huawei Li",
        "Xiaowei Li",
        "Ying Wang",
        "Onur Mutlu"
      ],
      "abstract": "Large language models (LLMs) are widely used for natural language\nunderstanding and text generation. An LLM model relies on a time-consuming step\ncalled LLM decoding to generate output tokens. Several prior works focus on\nimproving the performance of LLM decoding using parallelism techniques, such as\nbatching and speculative decoding. State-of-the-art LLM decoding has both\ncompute-bound and memory-bound kernels. Some prior works statically identify\nand map these different kernels to a heterogeneous architecture consisting of\nboth processing-in-memory (PIM) units and computation-centric accelerators. We\nobserve that characteristics of LLM decoding kernels (e.g., whether or not a\nkernel is memory-bound) can change dynamically due to parameter changes to meet\nuser and/or system demands, making (1) static kernel mapping to PIM units and\ncomputation-centric accelerators suboptimal, and (2) one-size-fits-all approach\nof designing PIM units inefficient due to a large degree of heterogeneity even\nin memory-bound kernels.\n  In this paper, we aim to accelerate LLM decoding while considering the\ndynamically changing characteristics of the kernels involved. We propose PAPI\n(PArallel Decoding with PIM), a PIM-enabled heterogeneous architecture that\nexploits dynamic scheduling of compute-bound or memory-bound kernels to\nsuitable hardware units. PAPI has two key mechanisms: (1) online kernel\ncharacterization to dynamically schedule kernels to the most suitable hardware\nunits at runtime and (2) a PIM-enabled heterogeneous computing system that\nharmoniously orchestrates both computation-centric processing units and hybrid\nPIM units with different computing capabilities. Our experimental results on\nthree broadly-used LLMs show that PAPI achieves 1.8$\\times$ and 11.1$\\times$\nspeedups over a state-of-the-art heterogeneous LLM accelerator and a\nstate-of-the-art PIM-only LLM accelerator, respectively.",
      "pdf_url": "http://arxiv.org/pdf/2502.15470v1",
      "published": "2025-02-21T13:52:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.15470v1",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.DC",
        "cs.LG"
      ]
    },
    {
      "title": "Mitigating Data Scarcity in Time Series Analysis: A Foundation Model with Series-Symbol Data Generation",
      "authors": [
        "Wenxuan Wang",
        "Kai Wu",
        "Yujian Betterest Li",
        "Dan Wang",
        "Xiaoyu Zhang",
        "Jing Liu"
      ],
      "abstract": "Foundation models for time series analysis (TSA) have attracted significant\nattention. However, challenges such as data scarcity and data imbalance\ncontinue to hinder their development. To address this, we consider modeling\ncomplex systems through symbolic expressions that serve as semantic descriptors\nof time series. Building on this concept, we introduce a series-symbol (S2)\ndual-modulity data generation mechanism, enabling the unrestricted creation of\nhigh-quality time series data paired with corresponding symbolic\nrepresentations. Leveraging the S2 dataset, we develop SymTime, a pre-trained\nfoundation model for TSA. SymTime demonstrates competitive performance across\nfive major TSA tasks when fine-tuned with downstream task, rivaling foundation\nmodels pre-trained on real-world datasets. This approach underscores the\npotential of dual-modality data generation and pretraining mechanisms in\novercoming data scarcity and enhancing task performance.",
      "pdf_url": "http://arxiv.org/pdf/2502.15466v1",
      "published": "2025-02-21T13:43:24+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.15466v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "R-LoRA: Random Initialization of Multi-Head LoRA for Multi-Task Learning",
      "authors": [
        "Jinda Liu",
        "Yi Chang",
        "Yuan Wu"
      ],
      "abstract": "Fine-tuning large language models (LLMs) is prohibitively expensive in terms\nof computational and memory costs. Low-rank Adaptation (LoRA), as one of the\nmost popular parameter-efficient fine-tuning (PEFT) methods, offers a\ncost-effective alternative by approximating the model changes $\\Delta W \\in\n\\mathbb{R}^{m \\times n}$ through the product of down-projection matrix $A \\in\n\\mathbb{R}^{m \\times r}$ and head matrix $B \\in \\mathbb{R}^{r \\times n}$, where\n$r \\ll \\min(m, n)$. In real-world scenarios, LLMs are fine-tuned on data from\nmultiple domains to perform tasks across various fields, embodying multi-task\nlearning (MTL). LoRA often underperforms in such complex scenarios. To enhance\nLoRA's capability in multi-task learning, we propose R-LoRA, which incorporates\nMulti-Head Randomization. Multi-Head Randomization diversifies the head\nmatrices through Multi-Head Random Initialization and Multi-Head Dropout,\nenabling more efficient learning of task-specific features while maintaining\nshared knowledge representation. Extensive experiments demonstrate that R-LoRA\nis better at capturing task-specific knowledge, thereby improving performance\nin multi-task scenarios. The code is available at\nhttps://github.com/jinda-liu/R-LoRA.",
      "pdf_url": "http://arxiv.org/pdf/2502.15455v1",
      "published": "2025-02-21T13:30:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.15455v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "MVIP -- A Dataset and Methods for Application Oriented Multi-View and Multi-Modal Industrial Part Recognition",
      "authors": [
        "Paul Koch",
        "Marian Schlüter",
        "Jörg Krüger"
      ],
      "abstract": "We present MVIP, a novel dataset for multi-modal and multi-view\napplication-oriented industrial part recognition. Here we are the first to\ncombine a calibrated RGBD multi-view dataset with additional object context\nsuch as physical properties, natural language, and super-classes. The current\nportfolio of available datasets offers a wide range of representations to\ndesign and benchmark related methods. In contrast to existing classification\nchallenges, industrial recognition applications offer controlled multi-modal\nenvironments but at the same time have different problems than traditional\n2D/3D classification challenges. Frequently, industrial applications must deal\nwith a small amount or increased number of training data, visually similar\nparts, and varying object sizes, while requiring a robust near 100% top 5\naccuracy under cost and time constraints. Current methods tackle such\nchallenges individually, but direct adoption of these methods within industrial\napplications is complex and requires further research. Our main goal with MVIP\nis to study and push transferability of various state-of-the-art methods within\nrelated downstream tasks towards an efficient deployment of industrial\nclassifiers. Additionally, we intend to push with MVIP research regarding\nseveral modality fusion topics, (automated) synthetic data generation, and\ncomplex data sampling -- combined in a single application-oriented benchmark.",
      "pdf_url": "http://arxiv.org/pdf/2502.15448v1",
      "published": "2025-02-21T13:22:29+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.15448v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "When Compression Meets Model Compression: Memory-Efficient Double Compression for Large Language Models",
      "authors": [
        "Weilan Wang",
        "Yu Mao",
        "Dongdong Tang",
        "Hongchao Du",
        "Nan Guan",
        "Chun Jason Xue"
      ],
      "abstract": "Large language models (LLMs) exhibit excellent performance in various tasks.\nHowever, the memory requirements of LLMs present a great challenge when\ndeploying on memory-limited devices, even for quantized LLMs. This paper\nintroduces a framework to compress LLM after quantization further, achieving\nabout 2.2x compression ratio. A compression-aware quantization is first\nproposed to enhance model weight compressibility by re-scaling the model\nparameters before quantization, followed by a pruning method to improve\nfurther. Upon this, we notice that decompression can be a bottleneck during\npractical scenarios. We then give a detailed analysis of the trade-off between\nmemory usage and latency brought by the proposed method. A speed-adaptive\nmethod is proposed to overcome it. The experimental results show inference with\nthe compressed model can achieve a 40% reduction in memory size with negligible\nloss in accuracy and inference speed.",
      "pdf_url": "http://arxiv.org/pdf/2502.15443v1",
      "published": "2025-02-21T13:11:22+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.15443v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Fed-SB: A Silver Bullet for Extreme Communication Efficiency and Performance in (Private) Federated LoRA Fine-Tuning",
      "authors": [
        "Raghav Singhal",
        "Kaustubh Ponkshe",
        "Rohit Vartak",
        "Lav R. Varshney",
        "Praneeth Vepakomma"
      ],
      "abstract": "Low-Rank Adaptation (LoRA) has become ubiquitous for efficiently fine-tuning\nfoundation models. However, federated fine-tuning using LoRA is challenging due\nto suboptimal updates arising from traditional federated averaging of\nindividual adapters. Existing solutions either incur prohibitively high\ncommunication cost that scales linearly with the number of clients or suffer\nfrom performance degradation due to limited expressivity. We introduce\nFederated Silver Bullet (Fed-SB), a novel approach for federated fine-tuning of\nLLMs using LoRA-SB, a recently proposed low-rank adaptation method. LoRA-SB\noptimally aligns the optimization trajectory with the ideal low-rank full\nfine-tuning projection by learning a small square matrix (R) between adapters B\nand A, keeping other components fixed. Direct averaging of R guarantees exact\nupdates, substantially reducing communication cost, which remains independent\nof the number of clients, and enables scalability. Fed-SB achieves\nstate-of-the-art performance across commonsense reasoning, arithmetic\nreasoning, and language inference tasks while reducing communication costs by\nup to 230x. In private settings, Fed-SB further improves performance by (1)\nreducing trainable parameters, thereby lowering the noise required for\ndifferential privacy and (2) avoiding noise amplification introduced by other\nmethods. Overall, Fed-SB establishes a new Pareto frontier in the tradeoff\nbetween communication and performance, offering an efficient and scalable\nsolution for both private and non-private federated fine-tuning. Our code is\npublicly available at https://github.com/CERT-Lab/fed-sb.",
      "pdf_url": "http://arxiv.org/pdf/2502.15436v1",
      "published": "2025-02-21T13:05:19+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.15436v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.DC"
      ]
    },
    {
      "title": "Single-pass Detection of Jailbreaking Input in Large Language Models",
      "authors": [
        "Leyla Naz Candogan",
        "Yongtao Wu",
        "Elias Abad Rocamora",
        "Grigorios G. Chrysos",
        "Volkan Cevher"
      ],
      "abstract": "Defending aligned Large Language Models (LLMs) against jailbreaking attacks\nis a challenging problem, with existing approaches requiring multiple requests\nor even queries to auxiliary LLMs, making them computationally heavy. Instead,\nwe focus on detecting jailbreaking input in a single forward pass. Our method,\ncalled Single Pass Detection SPD, leverages the information carried by the\nlogits to predict whether the output sentence will be harmful. This allows us\nto defend in just one forward pass. SPD can not only detect attacks effectively\non open-source models, but also minimizes the misclassification of harmless\ninputs. Furthermore, we show that SPD remains effective even without complete\nlogit access in GPT-3.5 and GPT-4. We believe that our proposed method offers a\npromising approach to efficiently safeguard LLMs against adversarial attacks.",
      "pdf_url": "http://arxiv.org/pdf/2502.15435v1",
      "published": "2025-02-21T13:04:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.15435v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "TAG: A Decentralized Framework for Multi-Agent Hierarchical Reinforcement Learning",
      "authors": [
        "Giuseppe Paolo",
        "Abdelhakim Benechehab",
        "Hamza Cherkaoui",
        "Albert Thomas",
        "Balázs Kégl"
      ],
      "abstract": "Hierarchical organization is fundamental to biological systems and human\nsocieties, yet artificial intelligence systems often rely on monolithic\narchitectures that limit adaptability and scalability. Current hierarchical\nreinforcement learning (HRL) approaches typically restrict hierarchies to two\nlevels or require centralized training, which limits their practical\napplicability. We introduce TAME Agent Framework (TAG), a framework for\nconstructing fully decentralized hierarchical multi-agent systems.TAG enables\nhierarchies of arbitrary depth through a novel LevelEnv concept, which\nabstracts each hierarchy level as the environment for the agents above it. This\napproach standardizes information flow between levels while preserving loose\ncoupling, allowing for seamless integration of diverse agent types. We\ndemonstrate the effectiveness of TAG by implementing hierarchical architectures\nthat combine different RL agents across multiple levels, achieving improved\nperformance over classical multi-agent RL baselines on standard benchmarks. Our\nresults show that decentralized hierarchical organization enhances both\nlearning speed and final performance, positioning TAG as a promising direction\nfor scalable multi-agent systems.",
      "pdf_url": "http://arxiv.org/pdf/2502.15425v1",
      "published": "2025-02-21T12:52:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.15425v1",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ]
    },
    {
      "title": "Anatomy-Informed Deep Learning and Radiomics for Automated Neurofibroma Segmentation in Whole-Body MRI",
      "authors": [
        "Georgii Kolokolnikov",
        "Marie-Lena Schmalhofer",
        "Lennart Well",
        "Said Farschtschi",
        "Victor-Felix Mautner",
        "Inka Ristow",
        "Rene Werner"
      ],
      "abstract": "Neurofibromatosis Type 1 is a genetic disorder characterized by the\ndevelopment of neurofibromas (NFs), which exhibit significant variability in\nsize, morphology, and anatomical location. Accurate and automated segmentation\nof these tumors in whole-body magnetic resonance imaging (WB-MRI) is crucial to\nassess tumor burden and monitor disease progression. In this study, we present\nand analyze a fully automated pipeline for NF segmentation in fat-suppressed\nT2-weighted WB-MRI, consisting of three stages: anatomy segmentation, NF\nsegmentation, and tumor candidate classification. In the first stage, we use\nthe MRSegmentator model to generate an anatomy segmentation mask, extended with\na high-risk zone for NFs. This mask is concatenated with the input image as\nanatomical context information for NF segmentation. The second stage employs an\nensemble of 3D anisotropic anatomy-informed U-Nets to produce an NF\nsegmentation confidence mask. In the final stage, tumor candidates are\nextracted from the confidence mask and classified based on radiomic features,\ndistinguishing tumors from non-tumor regions and reducing false positives. We\nevaluate the proposed pipeline on three test sets representing different\nconditions: in-domain data (test set 1), varying imaging protocols and field\nstrength (test set 2), and low tumor burden cases (test set 3). Experimental\nresults show a 68% improvement in per-scan Dice Similarity Coefficient (DSC), a\n21% increase in per-tumor DSC, and a two-fold improvement in F1 score for tumor\ndetection in high tumor burden cases by integrating anatomy information. The\nmethod is integrated into the 3D Slicer platform for practical clinical use,\nwith the code publicly accessible.",
      "pdf_url": "http://arxiv.org/pdf/2502.15424v1",
      "published": "2025-02-21T12:49:35+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.15424v1",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Evaluating Multimodal Generative AI with Korean Educational Standards",
      "authors": [
        "Sanghee Park",
        "Geewook Kim"
      ],
      "abstract": "This paper presents the Korean National Educational Test Benchmark (KoNET), a\nnew benchmark designed to evaluate Multimodal Generative AI Systems using\nKorean national educational tests. KoNET comprises four exams: the Korean\nElementary General Educational Development Test (KoEGED), Middle (KoMGED), High\n(KoHGED), and College Scholastic Ability Test (KoCSAT). These exams are\nrenowned for their rigorous standards and diverse questions, facilitating a\ncomprehensive analysis of AI performance across different educational levels.\nBy focusing on Korean, KoNET provides insights into model performance in\nless-explored languages. We assess a range of models - open-source,\nopen-access, and closed APIs - by examining difficulties, subject diversity,\nand human error rates. The code and dataset builder will be made fully\nopen-sourced at https://github.com/naver-ai/KoNET.",
      "pdf_url": "http://arxiv.org/pdf/2502.15422v1",
      "published": "2025-02-21T12:46:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.15422v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Beyond Translation: LLM-Based Data Generation for Multilingual Fact-Checking",
      "authors": [
        "Yi-Ling Chung",
        "Aurora Cobo",
        "Pablo Serna"
      ],
      "abstract": "Robust automatic fact-checking systems have the potential to combat online\nmisinformation at scale. However, most existing research primarily focuses on\nEnglish. In this paper, we introduce MultiSynFact, the first large-scale\nmultilingual fact-checking dataset containing 2.2M claim-source pairs designed\nto support Spanish, German, English, and other low-resource languages. Our\ndataset generation pipeline leverages Large Language Models (LLMs), integrating\nexternal knowledge from Wikipedia and incorporating rigorous claim validation\nsteps to ensure data quality. We evaluate the effectiveness of MultiSynFact\nacross multiple models and experimental settings. Additionally, we open-source\na user-friendly framework to facilitate further research in multilingual\nfact-checking and dataset generation.",
      "pdf_url": "http://arxiv.org/pdf/2502.15419v1",
      "published": "2025-02-21T12:38:26+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.15419v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ]
    }
  ]
}