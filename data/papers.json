{
  "last_updated": "2025-06-23T00:57:11.598560",
  "papers": [
    {
      "title": "Dense SAE Latents Are Features, Not Bugs",
      "authors": [
        "Xiaoqing Sun",
        "Alessandro Stolfo",
        "Joshua Engels",
        "Ben Wu",
        "Senthooran Rajamanoharan",
        "Mrinmaya Sachan",
        "Max Tegmark"
      ],
      "abstract": "Sparse autoencoders (SAEs) are designed to extract interpretable features\nfrom language models by enforcing a sparsity constraint. Ideally, training an\nSAE would yield latents that are both sparse and semantically meaningful.\nHowever, many SAE latents activate frequently (i.e., are \\emph{dense}), raising\nconcerns that they may be undesirable artifacts of the training procedure. In\nthis work, we systematically investigate the geometry, function, and origin of\ndense latents and show that they are not only persistent but often reflect\nmeaningful model representations. We first demonstrate that dense latents tend\nto form antipodal pairs that reconstruct specific directions in the residual\nstream, and that ablating their subspace suppresses the emergence of new dense\nfeatures in retrained SAEs -- suggesting that high density features are an\nintrinsic property of the residual space. We then introduce a taxonomy of dense\nlatents, identifying classes tied to position tracking, context binding,\nentropy regulation, letter-specific output signals, part-of-speech, and\nprincipal component reconstruction. Finally, we analyze how these features\nevolve across layers, revealing a shift from structural features in early\nlayers, to semantic features in mid layers, and finally to output-oriented\nsignals in the last layers of the model. Our findings indicate that dense\nlatents serve functional roles in language model computation and should not be\ndismissed as training noise.",
      "pdf_url": "http://arxiv.org/pdf/2506.15679v1",
      "published": "2025-06-18T17:59:35+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.15679v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Embodied Web Agents: Bridging Physical-Digital Realms for Integrated Agent Intelligence",
      "authors": [
        "Yining Hong",
        "Rui Sun",
        "Bingxuan Li",
        "Xingcheng Yao",
        "Maxine Wu",
        "Alexander Chien",
        "Da Yin",
        "Ying Nian Wu",
        "Zhecan James Wang",
        "Kai-Wei Chang"
      ],
      "abstract": "AI agents today are mostly siloed - they either retrieve and reason over vast\namount of digital information and knowledge obtained online; or interact with\nthe physical world through embodied perception, planning and action - but\nrarely both. This separation limits their ability to solve tasks that require\nintegrated physical and digital intelligence, such as cooking from online\nrecipes, navigating with dynamic map data, or interpreting real-world landmarks\nusing web knowledge. We introduce Embodied Web Agents, a novel paradigm for AI\nagents that fluidly bridge embodiment and web-scale reasoning. To\noperationalize this concept, we first develop the Embodied Web Agents task\nenvironments, a unified simulation platform that tightly integrates realistic\n3D indoor and outdoor environments with functional web interfaces. Building\nupon this platform, we construct and release the Embodied Web Agents Benchmark,\nwhich encompasses a diverse suite of tasks including cooking, navigation,\nshopping, tourism, and geolocation - all requiring coordinated reasoning across\nphysical and digital realms for systematic assessment of cross-domain\nintelligence. Experimental results reveal significant performance gaps between\nstate-of-the-art AI systems and human capabilities, establishing both\nchallenges and opportunities at the intersection of embodied cognition and\nweb-scale knowledge access. All datasets, codes and websites are publicly\navailable at our project page https://embodied-web-agent.github.io/.",
      "pdf_url": "http://arxiv.org/pdf/2506.15677v1",
      "published": "2025-06-18T17:58:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.15677v1",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.MM",
        "cs.RO"
      ]
    },
    {
      "title": "Sekai: A Video Dataset towards World Exploration",
      "authors": [
        "Zhen Li",
        "Chuanhao Li",
        "Xiaofeng Mao",
        "Shaoheng Lin",
        "Ming Li",
        "Shitian Zhao",
        "Zhaopan Xu",
        "Xinyue Li",
        "Yukang Feng",
        "Jianwen Sun",
        "Zizhen Li",
        "Fanrui Zhang",
        "Jiaxin Ai",
        "Zhixiang Wang",
        "Yuwei Wu",
        "Tong He",
        "Jiangmiao Pang",
        "Yu Qiao",
        "Yunde Jia",
        "Kaipeng Zhang"
      ],
      "abstract": "Video generation techniques have made remarkable progress, promising to be\nthe foundation of interactive world exploration. However, existing video\ngeneration datasets are not well-suited for world exploration training as they\nsuffer from some limitations: limited locations, short duration, static scenes,\nand a lack of annotations about exploration and the world. In this paper, we\nintroduce Sekai (meaning ``world'' in Japanese), a high-quality first-person\nview worldwide video dataset with rich annotations for world exploration. It\nconsists of over 5,000 hours of walking or drone view (FPV and UVA) videos from\nover 100 countries and regions across 750 cities. We develop an efficient and\neffective toolbox to collect, pre-process and annotate videos with location,\nscene, weather, crowd density, captions, and camera trajectories. Experiments\ndemonstrate the quality of the dataset. And, we use a subset to train an\ninteractive video world exploration model, named YUME (meaning ``dream'' in\nJapanese). We believe Sekai will benefit the area of video generation and world\nexploration, and motivate valuable applications.",
      "pdf_url": "http://arxiv.org/pdf/2506.15675v1",
      "published": "2025-06-18T17:57:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.15675v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Leaky Thoughts: Large Reasoning Models Are Not Private Thinkers",
      "authors": [
        "Tommaso Green",
        "Martin Gubri",
        "Haritz Puerto",
        "Sangdoo Yun",
        "Seong Joon Oh"
      ],
      "abstract": "We study privacy leakage in the reasoning traces of large reasoning models\nused as personal agents. Unlike final outputs, reasoning traces are often\nassumed to be internal and safe. We challenge this assumption by showing that\nreasoning traces frequently contain sensitive user data, which can be extracted\nvia prompt injections or accidentally leak into outputs. Through probing and\nagentic evaluations, we demonstrate that test-time compute approaches,\nparticularly increased reasoning steps, amplify such leakage. While increasing\nthe budget of those test-time compute approaches makes models more cautious in\ntheir final answers, it also leads them to reason more verbosely and leak more\nin their own thinking. This reveals a core tension: reasoning improves utility\nbut enlarges the privacy attack surface. We argue that safety efforts must\nextend to the model's internal thinking, not just its outputs.",
      "pdf_url": "http://arxiv.org/pdf/2506.15674v1",
      "published": "2025-06-18T17:57:01+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.15674v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR"
      ]
    },
    {
      "title": "SwarmAgentic: Towards Fully Automated Agentic System Generation via Swarm Intelligence",
      "authors": [
        "Yao Zhang",
        "Chenyang Lin",
        "Shijie Tang",
        "Haokun Chen",
        "Shijie Zhou",
        "Yunpu Ma",
        "Volker Tresp"
      ],
      "abstract": "The rapid progress of Large Language Models has advanced agentic systems in\ndecision-making, coordination, and task execution. Yet, existing agentic system\ngeneration frameworks lack full autonomy, missing from-scratch agent\ngeneration, self-optimizing agent functionality, and collaboration, limiting\nadaptability and scalability. We propose SwarmAgentic, a framework for fully\nautomated agentic system generation that constructs agentic systems from\nscratch and jointly optimizes agent functionality and collaboration as\ninterdependent components through language-driven exploration. To enable\nefficient search over system-level structures, SwarmAgentic maintains a\npopulation of candidate systems and evolves them via feedback-guided updates,\ndrawing inspiration from Particle Swarm Optimization (PSO). We evaluate our\nmethod on six real-world, open-ended, and exploratory tasks involving\nhigh-level planning, system-level coordination, and creative reasoning. Given\nonly a task description and an objective function, SwarmAgentic outperforms all\nbaselines, achieving a +261.8% relative improvement over ADAS on the\nTravelPlanner benchmark, highlighting the effectiveness of full automation in\nstructurally unconstrained tasks. This framework marks a significant step\ntoward scalable and autonomous agentic system design, bridging swarm\nintelligence with fully automated system multi-agent generation. Our code is\npublicly released at https://yaoz720.github.io/SwarmAgentic/.",
      "pdf_url": "http://arxiv.org/pdf/2506.15672v1",
      "published": "2025-06-18T17:54:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.15672v1",
      "categories": [
        "cs.AI",
        "cs.MA"
      ]
    },
    {
      "title": "AutoRule: Reasoning Chain-of-thought Extracted Rule-based Rewards Improve Preference Learning",
      "authors": [
        "Tevin Wang",
        "Chenyan Xiong"
      ],
      "abstract": "Rule-based rewards offer a promising strategy for improving reinforcement\nlearning from human feedback (RLHF), but current approaches often rely on\nmanual rule engineering. We present AutoRule, a fully automated method for\nextracting rules from preference feedback and formulating them into rule-based\nrewards. AutoRule extraction operates in three stages: it leverages a reasoning\nmodel to interpret user preferences, identifies candidate rules from the\nreasoning chain of these interpretations, and synthesizes them into a unified\nrule set. Leveraging the finalized rule set, we employ language-model verifiers\nto compute the fraction of rules satisfied by each output, using this metric as\nan auxiliary reward alongside the learned reward model during policy\noptimization. Training a Llama-3-8B model with AutoRule results in a 28.6\\%\nrelative improvement in length-controlled win rate on AlpacaEval2.0, and a\n6.1\\% relative gain in second-turn performance on a held-out MT-Bench subset,\ncompared to a GRPO baseline trained with the same learned reward model but\nwithout the rule-based auxiliary reward. Our analysis confirms that the\nextracted rules exhibit good agreement with dataset preference. We find that\nAutoRule demonstrates reduced reward hacking compared to a learned reward model\nwhen run over two episodes. Finally, our case study suggests that the extracted\nrules capture unique qualities valued in different datasets. The extracted\nrules are provided in the appendix, and the code is open-sourced at\nhttps://github.com/cxcscmu/AutoRule.",
      "pdf_url": "http://arxiv.org/pdf/2506.15651v1",
      "published": "2025-06-18T17:29:19+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.15651v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Exploring and Exploiting the Inherent Efficiency within Large Reasoning Models for Self-Guided Efficiency Enhancement",
      "authors": [
        "Weixiang Zhao",
        "Jiahe Guo",
        "Yang Deng",
        "Xingyu Sui",
        "Yulin Hu",
        "Yanyan Zhao",
        "Wanxiang Che",
        "Bing Qin",
        "Tat-Seng Chua",
        "Ting Liu"
      ],
      "abstract": "Recent advancements in large reasoning models (LRMs) have significantly\nenhanced language models' capabilities in complex problem-solving by emulating\nhuman-like deliberative thinking. However, these models often exhibit\noverthinking (i.e., the generation of unnecessarily verbose and redundant\ncontent), which hinders efficiency and inflates inference cost. In this work,\nwe explore the representational and behavioral origins of this inefficiency,\nrevealing that LRMs inherently possess the capacity for more concise reasoning.\nEmpirical analyses show that correct reasoning paths vary significantly in\nlength, and the shortest correct responses often suffice, indicating untapped\nefficiency potential. Exploiting these findings, we propose two lightweight\nmethods to enhance LRM efficiency. First, we introduce Efficiency Steering, a\ntraining-free activation steering technique that modulates reasoning behavior\nvia a single direction in the model's representation space. Second, we develop\nSelf-Rewarded Efficiency RL, a reinforcement learning framework that\ndynamically balances task accuracy and brevity by rewarding concise correct\nsolutions. Extensive experiments on seven LRM backbones across multiple\nmathematical reasoning benchmarks demonstrate that our methods significantly\nreduce reasoning length while preserving or improving task performance. Our\nresults highlight that reasoning efficiency can be improved by leveraging and\nguiding the intrinsic capabilities of existing models in a self-guided manner.",
      "pdf_url": "http://arxiv.org/pdf/2506.15647v1",
      "published": "2025-06-18T17:18:12+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.15647v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Demystifying the Visual Quality Paradox in Multimodal Large Language Models",
      "authors": [
        "Shuo Xing",
        "Lanqing Guo",
        "Hongyuan Hua",
        "Seoyoung Lee",
        "Peiran Li",
        "Yufei Wang",
        "Zhangyang Wang",
        "Zhengzhong Tu"
      ],
      "abstract": "Recent Multimodal Large Language Models (MLLMs) excel on benchmark\nvision-language tasks, yet little is known about how input visual quality\nshapes their responses. Does higher perceptual quality of images already\ntranslate to better MLLM understanding? We conduct the first systematic study\nspanning leading MLLMs and a suite of vision-language benchmarks, applying\ncontrolled degradations and stylistic shifts to each image. Surprisingly, we\nuncover a visual-quality paradox: model, task, and even individual-instance\nperformance can improve when images deviate from human-perceived fidelity.\nOff-the-shelf restoration pipelines fail to reconcile these idiosyncratic\npreferences. To close the gap, we introduce Visual-Quality Test-Time Tuning\n(VQ-TTT)-a lightweight adaptation module that: (1) inserts a learnable,\nlow-rank kernel before the frozen vision encoder to modulate frequency content;\nand (2) fine-tunes only shallow vision-encoder layers via LoRA. VQ-TTT\ndynamically adjusts each input image in a single forward pass, aligning it with\ntask-specific model preferences. Across the evaluated MLLMs and all datasets,\nVQ-TTT lifts significant average accuracy, with no external models, cached\nfeatures, or extra training data. These findings redefine ``better'' visual\ninputs for MLLMs and highlight the need for adaptive, rather than universally\n``clean'', imagery, in the new era of AI being the main data customer.",
      "pdf_url": "http://arxiv.org/pdf/2506.15645v1",
      "published": "2025-06-18T17:14:07+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.15645v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "The AI Policy Module: Developing Computer Science Student Competency in AI Ethics and Policy",
      "authors": [
        "James Weichert",
        "Daniel Dunlap",
        "Mohammed Farghally",
        "Hoda Eldardiry"
      ],
      "abstract": "As artificial intelligence (AI) further embeds itself into many settings\nacross personal and professional contexts, increasing attention must be paid\nnot only to AI ethics, but also to the governance and regulation of AI\ntechnologies through AI policy. However, the prevailing post-secondary\ncomputing curriculum is currently ill-equipped to prepare future AI\npractitioners to confront increasing demands to implement abstract ethical\nprinciples and normative policy preferences into the design and development of\nAI systems. We believe that familiarity with the 'AI policy landscape' and the\nability to translate ethical principles to practices will in the future\nconstitute an important responsibility for even the most technically-focused AI\nengineers.\n  Toward preparing current computer science (CS) students for these new\nexpectations, we developed an AI Policy Module to introduce discussions of AI\npolicy into the CS curriculum. Building on a successful pilot in fall 2024, in\nthis innovative practice full paper we present an updated and expanded version\nof the module, including a technical assignment on \"AI regulation\". We present\nthe findings from our pilot of the AI Policy Module 2.0, evaluating student\nattitudes towards AI ethics and policy through pre- and post-module surveys.\nFollowing the module, students reported increased concern about the ethical\nimpacts of AI technologies while also expressing greater confidence in their\nabilities to engage in discussions about AI regulation. Finally, we highlight\nthe AI Regulation Assignment as an effective and engaging tool for exploring\nthe limits of AI alignment and emphasizing the role of 'policy' in addressing\nethical challenges.",
      "pdf_url": "http://arxiv.org/pdf/2506.15639v1",
      "published": "2025-06-18T17:09:58+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.15639v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Revisiting Compositional Generalization Capability of Large Language Models Considering Instruction Following Ability",
      "authors": [
        "Yusuke Sakai",
        "Hidetaka Kamigaito",
        "Taro Watanabe"
      ],
      "abstract": "In generative commonsense reasoning tasks such as CommonGen, generative large\nlanguage models (LLMs) compose sentences that include all given concepts.\nHowever, when focusing on instruction-following capabilities, if a prompt\nspecifies a concept order, LLMs must generate sentences that adhere to the\nspecified order. To address this, we propose Ordered CommonGen, a benchmark\ndesigned to evaluate the compositional generalization and instruction-following\nabilities of LLMs. This benchmark measures ordered coverage to assess whether\nconcepts are generated in the specified order, enabling a simultaneous\nevaluation of both abilities. We conducted a comprehensive analysis using 36\nLLMs and found that, while LLMs generally understand the intent of\ninstructions, biases toward specific concept order patterns often lead to\nlow-diversity outputs or identical results even when the concept order is\naltered. Moreover, even the most instruction-compliant LLM achieved only about\n75% ordered coverage, highlighting the need for improvements in both\ninstruction-following and compositional generalization capabilities.",
      "pdf_url": "http://arxiv.org/pdf/2506.15629v1",
      "published": "2025-06-18T17:00:54+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.15629v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Federated Learning for MRI-based BrainAGE: a multicenter study on post-stroke functional outcome prediction",
      "authors": [
        "Vincent Roca",
        "Marc Tommasi",
        "Paul Andrey",
        "Aurélien Bellet",
        "Markus D. Schirmer",
        "Hilde Henon",
        "Laurent Puy",
        "Julien Ramon",
        "Grégory Kuchcinski",
        "Martin Bretzner",
        "Renaud Lopes"
      ],
      "abstract": "$\\textbf{Objective:}$ Brain-predicted age difference (BrainAGE) is a\nneuroimaging biomarker reflecting brain health. However, training robust\nBrainAGE models requires large datasets, often restricted by privacy concerns.\nThis study evaluates the performance of federated learning (FL) for BrainAGE\nestimation in ischemic stroke patients treated with mechanical thrombectomy,\nand investigates its association with clinical phenotypes and functional\noutcomes.\n  $\\textbf{Methods:}$ We used FLAIR brain images from 1674 stroke patients\nacross 16 hospital centers. We implemented standard machine learning and deep\nlearning models for BrainAGE estimates under three data management strategies:\ncentralized learning (pooled data), FL (local training at each site), and\nsingle-site learning. We reported prediction errors and examined associations\nbetween BrainAGE and vascular risk factors (e.g., diabetes mellitus,\nhypertension, smoking), as well as functional outcomes at three months\npost-stroke. Logistic regression evaluated BrainAGE's predictive value for\nthese outcomes, adjusting for age, sex, vascular risk factors, stroke severity,\ntime between MRI and arterial puncture, prior intravenous thrombolysis, and\nrecanalisation outcome.\n  $\\textbf{Results:}$ While centralized learning yielded the most accurate\npredictions, FL consistently outperformed single-site models. BrainAGE was\nsignificantly higher in patients with diabetes mellitus across all models.\nComparisons between patients with good and poor functional outcomes, and\nmultivariate predictions of these outcomes showed the significance of the\nassociation between BrainAGE and post-stroke recovery.\n  $\\textbf{Conclusion:}$ FL enables accurate age predictions without data\ncentralization. The strong association between BrainAGE, vascular risk factors,\nand post-stroke recovery highlights its potential for prognostic modeling in\nstroke care.",
      "pdf_url": "http://arxiv.org/pdf/2506.15626v2",
      "published": "2025-06-18T16:56:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.15626v2",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ]
    },
    {
      "title": "The Effect of State Representation on LLM Agent Behavior in Dynamic Routing Games",
      "authors": [
        "Lyle Goodyear",
        "Rachel Guo",
        "Ramesh Johari"
      ],
      "abstract": "Large Language Models (LLMs) have shown promise as decision-makers in dynamic\nsettings, but their stateless nature necessitates creating a natural language\nrepresentation of history. We present a unifying framework for systematically\nconstructing natural language \"state\" representations for prompting LLM agents\nin repeated multi-agent games. Previous work on games with LLM agents has taken\nan ad hoc approach to encoding game history, which not only obscures the impact\nof state representation on agents' behavior, but also limits comparability\nbetween studies. Our framework addresses these gaps by characterizing methods\nof state representation along three axes: action informativeness (i.e., the\nextent to which the state representation captures actions played); reward\ninformativeness (i.e., the extent to which the state representation describes\nrewards obtained); and prompting style (or natural language compression, i.e.,\nthe extent to which the full text history is summarized).\n  We apply this framework to a dynamic selfish routing game, chosen because it\nadmits a simple equilibrium both in theory and in human subject experiments\n\\cite{rapoport_choice_2009}. Despite the game's relative simplicity, we find\nthat there are key dependencies of LLM agent behavior on the natural language\nstate representation. In particular, we observe that representations which\nprovide agents with (1) summarized, rather than complete, natural language\nrepresentations of past history; (2) information about regrets, rather than raw\npayoffs; and (3) limited information about others' actions lead to behavior\nthat more closely matches game theoretic equilibrium predictions, and with more\nstable game play by the agents. By contrast, other representations can exhibit\neither large deviations from equilibrium, higher variation in dynamic game play\nover time, or both.",
      "pdf_url": "http://arxiv.org/pdf/2506.15624v1",
      "published": "2025-06-18T16:53:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.15624v1",
      "categories": [
        "cs.AI",
        "I.2.11; I.6.4; F.1.2; F.2.2; G.3; J.7"
      ]
    },
    {
      "title": "GFLC: Graph-based Fairness-aware Label Correction for Fair Classification",
      "authors": [
        "Modar Sulaiman",
        "Kallol Roy"
      ],
      "abstract": "Fairness in machine learning (ML) has a critical importance for building\ntrustworthy machine learning system as artificial intelligence (AI) systems\nincreasingly impact various aspects of society, including healthcare decisions\nand legal judgments. Moreover, numerous studies demonstrate evidence of unfair\noutcomes in ML and the need for more robust fairness-aware methods. However,\nthe data we use to train and develop debiasing techniques often contains biased\nand noisy labels. As a result, the label bias in the training data affects\nmodel performance and misrepresents the fairness of classifiers during testing.\nTo tackle this problem, our paper presents Graph-based Fairness-aware Label\nCorrection (GFLC), an efficient method for correcting label noise while\npreserving demographic parity in datasets. In particular, our approach combines\nthree key components: prediction confidence measure, graph-based regularization\nthrough Ricci-flow-optimized graph Laplacians, and explicit demographic parity\nincentives. Our experimental findings show the effectiveness of our proposed\napproach and show significant improvements in the trade-off between performance\nand fairness metrics compared to the baseline.",
      "pdf_url": "http://arxiv.org/pdf/2506.15620v1",
      "published": "2025-06-18T16:51:26+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.15620v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "The Compositional Architecture of Regret in Large Language Models",
      "authors": [
        "Xiangxiang Cui",
        "Shu Yang",
        "Tianjin Huang",
        "Wanyu Lin",
        "Lijie Hu",
        "Di Wang"
      ],
      "abstract": "Regret in Large Language Models refers to their explicit regret expression\nwhen presented with evidence contradicting their previously generated\nmisinformation. Studying the regret mechanism is crucial for enhancing model\nreliability and helps in revealing how cognition is coded in neural networks.\nTo understand this mechanism, we need to first identify regret expressions in\nmodel outputs, then analyze their internal representation. This analysis\nrequires examining the model's hidden states, where information processing\noccurs at the neuron level. However, this faces three key challenges: (1) the\nabsence of specialized datasets capturing regret expressions, (2) the lack of\nmetrics to find the optimal regret representation layer, and (3) the lack of\nmetrics for identifying and analyzing regret neurons. Addressing these\nlimitations, we propose: (1) a workflow for constructing a comprehensive regret\ndataset through strategically designed prompting scenarios, (2) the Supervised\nCompression-Decoupling Index (S-CDI) metric to identify optimal regret\nrepresentation layers, and (3) the Regret Dominance Score (RDS) metric to\nidentify regret neurons and the Group Impact Coefficient (GIC) to analyze\nactivation patterns. Our experimental results successfully identified the\noptimal regret representation layer using the S-CDI metric, which significantly\nenhanced performance in probe classification experiments. Additionally, we\ndiscovered an M-shaped decoupling pattern across model layers, revealing how\ninformation processing alternates between coupling and decoupling phases.\nThrough the RDS metric, we categorized neurons into three distinct functional\ngroups: regret neurons, non-regret neurons, and dual neurons.",
      "pdf_url": "http://arxiv.org/pdf/2506.15617v1",
      "published": "2025-06-18T16:50:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.15617v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "LoX: Low-Rank Extrapolation Robustifies LLM Safety Against Fine-tuning",
      "authors": [
        "Gabrel J. Perin",
        "Runjin Chen",
        "Xuxi Chen",
        "Nina S. T. Hirata",
        "Zhangyang Wang",
        "Junyuan Hong"
      ],
      "abstract": "Large Language Models (LLMs) have become indispensable in real-world\napplications. However, their widespread adoption raises significant safety\nconcerns, particularly in responding to socially harmful questions. Despite\nsubstantial efforts to improve model safety through alignment, aligned models\ncan still have their safety protections undermined by subsequent fine-tuning -\neven when the additional training data appears benign. In this paper, we\nempirically demonstrate that this vulnerability stems from the sensitivity of\nsafety-critical low-rank subspaces in LLM parameters to fine-tuning. Building\non this insight, we propose a novel training-free method, termed Low-Rank\nExtrapolation (LoX), to enhance safety robustness by extrapolating the safety\nsubspace of an aligned LLM. Our experimental results confirm the effectiveness\nof LoX, demonstrating significant improvements in robustness against both\nbenign and malicious fine-tuning attacks while preserving the model's\nadaptability to new tasks. For instance, LoX leads to 11% to 54% absolute\nreductions in attack success rates (ASR) facing benign or malicious fine-tuning\nattacks. By investigating the ASR landscape of parameters, we attribute the\nsuccess of LoX to that the extrapolation moves LLM parameters to a flatter\nzone, thereby less sensitive to perturbations. The code is available at\ngithub.com/VITA-Group/LoX.",
      "pdf_url": "http://arxiv.org/pdf/2506.15606v1",
      "published": "2025-06-18T16:30:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.15606v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "From Model to Classroom: Evaluating Generated MCQs for Portuguese with Narrative and Difficulty Concerns",
      "authors": [
        "Bernardo Leite",
        "Henrique Lopes Cardoso",
        "Pedro Pinto",
        "Abel Ferreira",
        "Luís Abreu",
        "Isabel Rangel",
        "Sandra Monteiro"
      ],
      "abstract": "While MCQs are valuable for learning and evaluation, manually creating them\nwith varying difficulty levels and targeted reading skills remains a\ntime-consuming and costly task. Recent advances in generative AI provide an\nopportunity to automate MCQ generation efficiently. However, assessing the\nactual quality and reliability of generated MCQs has received limited attention\n-- particularly regarding cases where generation fails. This aspect becomes\nparticularly important when the generated MCQs are meant to be applied in\nreal-world settings. Additionally, most MCQ generation studies focus on\nEnglish, leaving other languages underexplored. This paper investigates the\ncapabilities of current generative models in producing MCQs for reading\ncomprehension in Portuguese, a morphologically rich language. Our study focuses\non generating MCQs that align with curriculum-relevant narrative elements and\nspan different difficulty levels. We evaluate these MCQs through expert review\nand by analyzing the psychometric properties extracted from student responses\nto assess their suitability for elementary school students. Our results show\nthat current models can generate MCQs of comparable quality to human-authored\nones. However, we identify issues related to semantic clarity and\nanswerability. Also, challenges remain in generating distractors that engage\nstudents and meet established criteria for high-quality MCQ option design.",
      "pdf_url": "http://arxiv.org/pdf/2506.15598v1",
      "published": "2025-06-18T16:19:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.15598v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "WikiMixQA: A Multimodal Benchmark for Question Answering over Tables and Charts",
      "authors": [
        "Negar Foroutan",
        "Angelika Romanou",
        "Matin Ansaripour",
        "Julian Martin Eisenschlos",
        "Karl Aberer",
        "Rémi Lebret"
      ],
      "abstract": "Documents are fundamental to preserving and disseminating information, often\nincorporating complex layouts, tables, and charts that pose significant\nchallenges for automatic document understanding (DU). While vision-language\nlarge models (VLLMs) have demonstrated improvements across various tasks, their\neffectiveness in processing long-context vision inputs remains unclear. This\npaper introduces WikiMixQA, a benchmark comprising 1,000 multiple-choice\nquestions (MCQs) designed to evaluate cross-modal reasoning over tables and\ncharts extracted from 4,000 Wikipedia pages spanning seven distinct topics.\nUnlike existing benchmarks, WikiMixQA emphasizes complex reasoning by requiring\nmodels to synthesize information from multiple modalities. We evaluate 12\nstate-of-the-art vision-language models, revealing that while proprietary\nmodels achieve ~70% accuracy when provided with direct context, their\nperformance deteriorates significantly when retrieval from long documents is\nrequired. Among these, GPT-4-o is the only model exceeding 50% accuracy in this\nsetting, whereas open-source models perform considerably worse, with a maximum\naccuracy of 27%. These findings underscore the challenges of long-context,\nmulti-modal reasoning and establish WikiMixQA as a crucial benchmark for\nadvancing document understanding research.",
      "pdf_url": "http://arxiv.org/pdf/2506.15594v1",
      "published": "2025-06-18T16:09:18+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.15594v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "One-Step Diffusion for Detail-Rich and Temporally Consistent Video Super-Resolution",
      "authors": [
        "Yujing Sun",
        "Lingchen Sun",
        "Shuaizheng Liu",
        "Rongyuan Wu",
        "Zhengqiang Zhang",
        "Lei Zhang"
      ],
      "abstract": "It is a challenging problem to reproduce rich spatial details while\nmaintaining temporal consistency in real-world video super-resolution\n(Real-VSR), especially when we leverage pre-trained generative models such as\nstable diffusion (SD) for realistic details synthesis. Existing SD-based\nReal-VSR methods often compromise spatial details for temporal coherence,\nresulting in suboptimal visual quality. We argue that the key lies in how to\neffectively extract the degradation-robust temporal consistency priors from the\nlow-quality (LQ) input video and enhance the video details while maintaining\nthe extracted consistency priors. To achieve this, we propose a Dual LoRA\nLearning (DLoRAL) paradigm to train an effective SD-based one-step diffusion\nmodel, achieving realistic frame details and temporal consistency\nsimultaneously. Specifically, we introduce a Cross-Frame Retrieval (CFR) module\nto aggregate complementary information across frames, and train a\nConsistency-LoRA (C-LoRA) to learn robust temporal representations from\ndegraded inputs. After consistency learning, we fix the CFR and C-LoRA modules\nand train a Detail-LoRA (D-LoRA) to enhance spatial details while aligning with\nthe temporal space defined by C-LoRA to keep temporal coherence. The two phases\nalternate iteratively for optimization, collaboratively delivering consistent\nand detail-rich outputs. During inference, the two LoRA branches are merged\ninto the SD model, allowing efficient and high-quality video restoration in a\nsingle diffusion step. Experiments show that DLoRAL achieves strong performance\nin both accuracy and speed. Code and models are available at\nhttps://github.com/yjsunnn/DLoRAL.",
      "pdf_url": "http://arxiv.org/pdf/2506.15591v1",
      "published": "2025-06-18T16:06:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.15591v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Managing Complex Failure Analysis Workflows with LLM-based Reasoning and Acting Agents",
      "authors": [
        "Aline Dobrovsky",
        "Konstantin Schekotihin",
        "Christian Burmer"
      ],
      "abstract": "Failure Analysis (FA) is a highly intricate and knowledge-intensive process.\nThe integration of AI components within the computational infrastructure of FA\nlabs has the potential to automate a variety of tasks, including the detection\nof non-conformities in images, the retrieval of analogous cases from diverse\ndata sources, and the generation of reports from annotated images. However, as\nthe number of deployed AI models increases, the challenge lies in orchestrating\nthese components into cohesive and efficient workflows that seamlessly\nintegrate with the FA process.\n  This paper investigates the design and implementation of a Large Language\nModel (LLM)-based Planning Agent (LPA) to assist FA engineers in solving their\nanalysis cases. The LPA integrates LLMs with advanced planning capabilities and\nexternal tool utilization, enabling autonomous processing of complex queries,\nretrieval of relevant data from external systems, and generation of\nhuman-readable responses. Evaluation results demonstrate the agent's\noperational effectiveness and reliability in supporting FA tasks.",
      "pdf_url": "http://arxiv.org/pdf/2506.15567v1",
      "published": "2025-06-18T15:43:10+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.15567v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Towards Explainable Indoor Localization: Interpreting Neural Network Learning on Wi-Fi Fingerprints Using Logic Gates",
      "authors": [
        "Danish Gufran",
        "Sudeep Pasricha"
      ],
      "abstract": "Indoor localization using deep learning (DL) has demonstrated strong accuracy\nin mapping Wi-Fi RSS fingerprints to physical locations; however, most existing\nDL frameworks function as black-box models, offering limited insight into how\npredictions are made or how models respond to real-world noise over time. This\nlack of interpretability hampers our ability to understand the impact of\ntemporal variations - caused by environmental dynamics - and to adapt models\nfor long-term reliability. To address this, we introduce LogNet, a novel logic\ngate-based framework designed to interpret and enhance DL-based indoor\nlocalization. LogNet enables transparent reasoning by identifying which access\npoints (APs) are most influential for each reference point (RP) and reveals how\nenvironmental noise disrupts DL-driven localization decisions. This\ninterpretability allows us to trace and diagnose model failures and adapt DL\nsystems for more stable long-term deployments. Evaluations across multiple\nreal-world building floorplans and over two years of temporal variation show\nthat LogNet not only interprets the internal behavior of DL models but also\nimproves performance-achieving up to 1.1x to 2.8x lower localization error,\n3.4x to 43.3x smaller model size, and 1.5x to 3.6x lower latency compared to\nprior DL-based models.",
      "pdf_url": "http://arxiv.org/pdf/2506.15559v1",
      "published": "2025-06-18T15:34:41+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.15559v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "DAILOC: Domain-Incremental Learning for Indoor Localization using Smartphones",
      "authors": [
        "Akhil Singampalli",
        "Danish Gufran",
        "Sudeep Pasricha"
      ],
      "abstract": "Wi-Fi fingerprinting-based indoor localization faces significant challenges\nin real-world deployments due to domain shifts arising from device\nheterogeneity and temporal variations within indoor environments. Existing\napproaches often address these issues independently, resulting in poor\ngeneralization and susceptibility to catastrophic forgetting over time. In this\nwork, we propose DAILOC, a novel domain-incremental learning framework that\njointly addresses both temporal and device-induced domain shifts. DAILOC\nintroduces a novel disentanglement strategy that separates domain shifts from\nlocation-relevant features using a multi-level variational autoencoder.\nAdditionally, we introduce a novel memory-guided class latent alignment\nmechanism to address the effects of catastrophic forgetting over time.\nExperiments across multiple smartphones, buildings, and time instances\ndemonstrate that DAILOC significantly outperforms state-of-the-art methods,\nachieving up to 2.74x lower average error and 4.6x lower worst-case error.",
      "pdf_url": "http://arxiv.org/pdf/2506.15554v1",
      "published": "2025-06-18T15:27:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.15554v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "CLAIM: Clinically-Guided LGE Augmentation for Realistic and Diverse Myocardial Scar Synthesis and Segmentation",
      "authors": [
        "Farheen Ramzan",
        "Yusuf Kiberu",
        "Nikesh Jathanna",
        "Shahnaz Jamil-Copley",
        "Richard H. Clayton",
        "Chen",
        "Chen"
      ],
      "abstract": "Deep learning-based myocardial scar segmentation from late gadolinium\nenhancement (LGE) cardiac MRI has shown great potential for accurate and timely\ndiagnosis and treatment planning for structural cardiac diseases. However, the\nlimited availability and variability of LGE images with high-quality scar\nlabels restrict the development of robust segmentation models. To address this,\nwe introduce CLAIM: \\textbf{C}linically-Guided \\textbf{L}GE\n\\textbf{A}ugmentation for Real\\textbf{i}stic and Diverse \\textbf{M}yocardial\nScar Synthesis and Segmentation framework, a framework for anatomically\ngrounded scar generation and segmentation. At its core is the SMILE module\n(Scar Mask generation guided by cLinical knowledgE), which conditions a\ndiffusion-based generator on the clinically adopted AHA 17-segment model to\nsynthesize images with anatomically consistent and spatially diverse scar\npatterns. In addition, CLAIM employs a joint training strategy in which the\nscar segmentation network is optimized alongside the generator, aiming to\nenhance both the realism of synthesized scars and the accuracy of the scar\nsegmentation performance. Experimental results show that CLAIM produces\nanatomically coherent scar patterns and achieves higher Dice similarity with\nreal scar distributions compared to baseline models. Our approach enables\ncontrollable and realistic myocardial scar synthesis and has demonstrated\nutility for downstream medical imaging task.",
      "pdf_url": "http://arxiv.org/pdf/2506.15549v1",
      "published": "2025-06-18T15:21:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.15549v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Learning Algorithms in the Limit",
      "authors": [
        "Hristo Papazov",
        "Nicolas Flammarion"
      ],
      "abstract": "This paper studies the problem of learning computable functions in the limit\nby extending Gold's inductive inference framework to incorporate\n\\textit{computational observations} and \\textit{restricted input sources}.\nComplimentary to the traditional Input-Output Observations, we introduce\nTime-Bound Observations, and Policy-Trajectory Observations to study the\nlearnability of general recursive functions under more realistic constraints.\nWhile input-output observations do not suffice for learning the class of\ngeneral recursive functions in the limit, we overcome this learning barrier by\nimposing computational complexity constraints or supplementing with approximate\ntime-bound observations. Further, we build a formal framework around\nobservations of \\textit{computational agents} and show that learning computable\nfunctions from policy trajectories reduces to learning rational functions from\ninput and output, thereby revealing interesting connections to finite-state\ntransducer inference. On the negative side, we show that computable or\npolynomial-mass characteristic sets cannot exist for the class of linear-time\ncomputable functions even for policy-trajectory observations.",
      "pdf_url": "http://arxiv.org/pdf/2506.15543v1",
      "published": "2025-06-18T15:17:03+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.15543v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DS",
        "cs.FL"
      ]
    },
    {
      "title": "Intrinsic and Extrinsic Organized Attention: Softmax Invariance and Network Sparsity",
      "authors": [
        "Oluwadamilola Fasina",
        "Ruben V. C. Pohle",
        "Pei-Chun Su",
        "Ronald R. Coifman"
      ],
      "abstract": "We examine the intrinsic (within the attention head) and extrinsic (amongst\nthe attention heads) structure of the self-attention mechanism in transformers.\nTheoretical evidence for invariance of the self-attention mechanism to softmax\nactivation is obtained by appealing to paradifferential calculus, (and is\nsupported by computational examples), which relies on the intrinsic\norganization of the attention heads. Furthermore, we use an existing\nmethodology for hierarchical organization of tensors to examine network\nstructure by constructing hierarchal partition trees with respect to the query,\nkey, and head axes of network 3-tensors. Such an organization is consequential\nsince it allows one to profitably execute common signal processing tasks on a\ngeometry where the organized network 3-tensors exhibit regularity. We exemplify\nthis qualitatively, by visualizing the hierarchical organization of the tree\ncomprised of attention heads and the diffusion map embeddings, and\nquantitatively by investigating network sparsity with the expansion\ncoefficients of individual attention heads and the entire network with respect\nto the bi and tri-haar bases (respectively) on the space of queries, keys, and\nheads of the network. To showcase the utility of our theoretical and\nmethodological findings, we provide computational examples using vision and\nlanguage transformers. The ramifications of these findings are two-fold: (1) a\nsubsequent step in interpretability analysis is theoretically admitted, and can\nbe exploited empirically for downstream interpretability tasks (2) one can use\nthe network 3-tensor organization for empirical network applications such as\nmodel pruning (by virtue of network sparsity) and network architecture\ncomparison.",
      "pdf_url": "http://arxiv.org/pdf/2506.15541v1",
      "published": "2025-06-18T15:14:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.15541v1",
      "categories": [
        "math.NA",
        "cs.AI",
        "cs.NA"
      ]
    },
    {
      "title": "Capturing Polysemanticity with PRISM: A Multi-Concept Feature Description Framework",
      "authors": [
        "Laura Kopf",
        "Nils Feldhus",
        "Kirill Bykov",
        "Philine Lou Bommer",
        "Anna Hedström",
        "Marina M. -C. Höhne",
        "Oliver Eberle"
      ],
      "abstract": "Automated interpretability research aims to identify concepts encoded in\nneural network features to enhance human understanding of model behavior.\nCurrent feature description methods face two critical challenges: limited\nrobustness and the flawed assumption that each neuron encodes only a single\nconcept (monosemanticity), despite growing evidence that neurons are often\npolysemantic. This assumption restricts the expressiveness of feature\ndescriptions and limits their ability to capture the full range of behaviors\nencoded in model internals. To address this, we introduce Polysemantic FeatuRe\nIdentification and Scoring Method (PRISM), a novel framework that captures the\ninherent complexity of neural network features. Unlike prior approaches that\nassign a single description per feature, PRISM provides more nuanced\ndescriptions for both polysemantic and monosemantic features. We apply PRISM to\nlanguage models and, through extensive benchmarking against existing methods,\ndemonstrate that our approach produces more accurate and faithful feature\ndescriptions, improving both overall description quality (via a description\nscore) and the ability to capture distinct concepts when polysemanticity is\npresent (via a polysemanticity score).",
      "pdf_url": "http://arxiv.org/pdf/2506.15538v1",
      "published": "2025-06-18T15:13:07+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.15538v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "RePCS: Diagnosing Data Memorization in LLM-Powered Retrieval-Augmented Generation",
      "authors": [
        "Le Vu Anh",
        "Nguyen Viet Anh",
        "Mehmet Dik",
        "Luong Van Nghia"
      ],
      "abstract": "Retrieval-augmented generation (RAG) has become a common strategy for\nupdating large language model (LLM) responses with current, external\ninformation. However, models may still rely on memorized training data, bypass\nthe retrieved evidence, and produce contaminated outputs. We introduce\nRetrieval-Path Contamination Scoring (RePCS), a diagnostic method that detects\nsuch behavior without requiring model access or retraining. RePCS compares two\ninference paths: (i) a parametric path using only the query, and (ii) a\nretrieval-augmented path using both the query and retrieved context by\ncomputing the Kullback-Leibler (KL) divergence between their output\ndistributions. A low divergence suggests that the retrieved context had minimal\nimpact, indicating potential memorization. This procedure is model-agnostic,\nrequires no gradient or internal state access, and adds only a single\nadditional forward pass. We further derive PAC-style guarantees that link the\nKL threshold to user-defined false positive and false negative rates. On the\nPrompt-WNQA benchmark, RePCS achieves a ROC-AUC of 0.918. This result\noutperforms the strongest prior method by 6.5 percentage points while keeping\nlatency overhead below 4.7% on an NVIDIA T4 GPU. RePCS offers a lightweight,\nblack-box safeguard to verify whether a RAG system meaningfully leverages\nretrieval, making it especially valuable in safety-critical applications.",
      "pdf_url": "http://arxiv.org/pdf/2506.15513v1",
      "published": "2025-06-18T14:48:19+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.15513v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Optimizing Web-Based AI Query Retrieval with GPT Integration in LangChain A CoT-Enhanced Prompt Engineering Approach",
      "authors": [
        "Wenqi Guan",
        "Yang Fang"
      ],
      "abstract": "Large Language Models have brought a radical change in the process of remote\nlearning students, among other aspects of educative activities. Current\nretrieval of remote learning resources lacks depth in contextual meaning that\nprovides comprehensive information on complex student queries. This work\nproposes a novel approach to enhancing remote learning retrieval by integrating\nGPT-based models within the LangChain framework. We achieve this system in a\nmore intuitive and productive manner using CoT reasoning and prompt\nengineering. The framework we propose puts much emphasis on increasing the\nprecision and relevance of the retrieval results to return comprehensive and\ncontextually enriched explanations and resources that best suit each student's\nneeds. We also assess the effectiveness of our approach against paradigmatic\nLLMs and report improvements in user satisfaction and learning outcomes.",
      "pdf_url": "http://arxiv.org/pdf/2506.15512v1",
      "published": "2025-06-18T14:47:59+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.15512v1",
      "categories": [
        "cs.HC",
        "cs.AI"
      ]
    },
    {
      "title": "Over-squashing in Spatiotemporal Graph Neural Networks",
      "authors": [
        "Ivan Marisca",
        "Jacob Bamberger",
        "Cesare Alippi",
        "Michael M. Bronstein"
      ],
      "abstract": "Graph Neural Networks (GNNs) have achieved remarkable success across various\ndomains. However, recent theoretical advances have identified fundamental\nlimitations in their information propagation capabilities, such as\nover-squashing, where distant nodes fail to effectively exchange information.\nWhile extensively studied in static contexts, this issue remains unexplored in\nSpatiotemporal GNNs (STGNNs), which process sequences associated with graph\nnodes. Nonetheless, the temporal dimension amplifies this challenge by\nincreasing the information that must be propagated. In this work, we formalize\nthe spatiotemporal over-squashing problem and demonstrate its distinct\ncharacteristics compared to the static case. Our analysis reveals that\ncounterintuitively, convolutional STGNNs favor information propagation from\npoints temporally distant rather than close in time. Moreover, we prove that\narchitectures that follow either time-and-space or time-then-space processing\nparadigms are equally affected by this phenomenon, providing theoretical\njustification for computationally efficient implementations. We validate our\nfindings on synthetic and real-world datasets, providing deeper insights into\ntheir operational dynamics and principled guidance for more effective designs.",
      "pdf_url": "http://arxiv.org/pdf/2506.15507v1",
      "published": "2025-06-18T14:45:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.15507v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Pixel-level Certified Explanations via Randomized Smoothing",
      "authors": [
        "Alaa Anani",
        "Tobias Lorenz",
        "Mario Fritz",
        "Bernt Schiele"
      ],
      "abstract": "Post-hoc attribution methods aim to explain deep learning predictions by\nhighlighting influential input pixels. However, these explanations are highly\nnon-robust: small, imperceptible input perturbations can drastically alter the\nattribution map while maintaining the same prediction. This vulnerability\nundermines their trustworthiness and calls for rigorous robustness guarantees\nof pixel-level attribution scores. We introduce the first certification\nframework that guarantees pixel-level robustness for any black-box attribution\nmethod using randomized smoothing. By sparsifying and smoothing attribution\nmaps, we reformulate the task as a segmentation problem and certify each\npixel's importance against $\\ell_2$-bounded perturbations. We further propose\nthree evaluation metrics to assess certified robustness, localization, and\nfaithfulness. An extensive evaluation of 12 attribution methods across 5\nImageNet models shows that our certified attributions are robust,\ninterpretable, and faithful, enabling reliable use in downstream tasks. Our\ncode is at https://github.com/AlaaAnani/certified-attributions.",
      "pdf_url": "http://arxiv.org/pdf/2506.15499v1",
      "published": "2025-06-18T14:41:24+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.15499v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "SPARE: Single-Pass Annotation with Reference-Guided Evaluation for Automatic Process Supervision and Reward Modelling",
      "authors": [
        "Md Imbesat Hassan Rizvi",
        "Xiaodan Zhu",
        "Iryna Gurevych"
      ],
      "abstract": "Process or step-wise supervision has played a crucial role in advancing\ncomplex multi-step reasoning capabilities of Large Language Models (LLMs).\nHowever, efficient, high-quality automated process annotation remains a\nsignificant challenge. To address this, we introduce Single-Pass Annotation\nwith Reference-Guided Evaluation (SPARE), a novel structured framework that\nenables single-pass, per-step annotation by aligning each solution step to one\nor multiple steps in a reference solution, accompanied by explicit reasoning\nfor evaluation. We show that reference-guided step-level evaluation effectively\nfacilitates process supervision on four datasets spanning three domains:\nmathematical reasoning, multi-hop compositional question answering, and spatial\nreasoning. We demonstrate that SPARE, when compared to baselines, improves\nreasoning performance when used for: (1) fine-tuning models in an offline RL\nsetup for inference-time greedy-decoding, and (2) training reward models for\nranking/aggregating multiple LLM-generated outputs. Additionally, SPARE\nachieves competitive performance on challenging mathematical datasets while\noffering 2.6 times greater efficiency, requiring only 38% of the runtime,\ncompared to tree search-based automatic annotation. The codebase, along with a\ntrained SPARE-PRM model, is publicly released to facilitate further research\nand reproducibility.",
      "pdf_url": "http://arxiv.org/pdf/2506.15498v1",
      "published": "2025-06-18T14:37:59+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.15498v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "GenHOI: Generalizing Text-driven 4D Human-Object Interaction Synthesis for Unseen Objects",
      "authors": [
        "Shujia Li",
        "Haiyu Zhang",
        "Xinyuan Chen",
        "Yaohui Wang",
        "Yutong Ban"
      ],
      "abstract": "While diffusion models and large-scale motion datasets have advanced\ntext-driven human motion synthesis, extending these advances to 4D human-object\ninteraction (HOI) remains challenging, mainly due to the limited availability\nof large-scale 4D HOI datasets. In our study, we introduce GenHOI, a novel\ntwo-stage framework aimed at achieving two key objectives: 1) generalization to\nunseen objects and 2) the synthesis of high-fidelity 4D HOI sequences. In the\ninitial stage of our framework, we employ an Object-AnchorNet to reconstruct\nsparse 3D HOI keyframes for unseen objects, learning solely from 3D HOI\ndatasets, thereby mitigating the dependence on large-scale 4D HOI datasets.\nSubsequently, we introduce a Contact-Aware Diffusion Model (ContactDM) in the\nsecond stage to seamlessly interpolate sparse 3D HOI keyframes into densely\ntemporally coherent 4D HOI sequences. To enhance the quality of generated 4D\nHOI sequences, we propose a novel Contact-Aware Encoder within ContactDM to\nextract human-object contact patterns and a novel Contact-Aware HOI Attention\nto effectively integrate the contact signals into diffusion models.\nExperimental results show that we achieve state-of-the-art results on the\npublicly available OMOMO and 3D-FUTURE datasets, demonstrating strong\ngeneralization abilities to unseen objects, while enabling high-fidelity 4D HOI\ngeneration.",
      "pdf_url": "http://arxiv.org/pdf/2506.15483v1",
      "published": "2025-06-18T14:17:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.15483v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Context-Informed Grounding Supervision",
      "authors": [
        "Hyunji Lee",
        "Seunghyun Yoon",
        "Yunjae Won",
        "Hanseok Oh",
        "Geewook Kim",
        "Trung Bui",
        "Franck Dernoncourt",
        "Elias Stengel-Eskin",
        "Mohit Bansal",
        "Minjoon Seo"
      ],
      "abstract": "Large language models (LLMs) are often supplemented with external knowledge\nto provide information not encoded in their parameters or to reduce\nhallucination. In such cases, we expect the model to generate responses by\ngrounding its response in the provided external context. However, prior work\nhas shown that simply appending context at inference time does not ensure\ngrounded generation. To address this, we propose Context-INformed Grounding\nSupervision (CINGS), a post-training supervision in which the model is trained\nwith relevant context prepended to the response, while computing the loss only\nover the response tokens and masking out the context. Our experiments\ndemonstrate that models trained with CINGS exhibit stronger grounding in both\ntextual and visual domains compared to standard instruction-tuned models. In\nthe text domain, CINGS outperforms other training methods across 11\ninformation-seeking datasets and is complementary to inference-time grounding\ntechniques. In the vision-language domain, replacing a vision-language model's\nLLM backbone with a CINGS-trained model reduces hallucinations across four\nbenchmarks and maintains factual consistency throughout the generated response.\nThis improved grounding comes without degradation in general downstream\nperformance. Finally, we analyze the mechanism underlying the enhanced\ngrounding in CINGS and find that it induces a shift in the model's prior\nknowledge and behavior, implicitly encouraging greater reliance on the external\ncontext.",
      "pdf_url": "http://arxiv.org/pdf/2506.15480v1",
      "published": "2025-06-18T14:13:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.15480v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Co-Creative Learning via Metropolis-Hastings Interaction between Humans and AI",
      "authors": [
        "Ryota Okumura",
        "Tadahiro Taniguchi",
        "Akira Taniguchi",
        "Yoshinobu Hagiwara"
      ],
      "abstract": "We propose co-creative learning as a novel paradigm where humans and AI,\ni.e., biological and artificial agents, mutually integrate their partial\nperceptual information and knowledge to construct shared external\nrepresentations, a process we interpret as symbol emergence. Unlike traditional\nAI teaching based on unilateral knowledge transfer, this addresses the\nchallenge of integrating information from inherently different modalities. We\nempirically test this framework using a human-AI interaction model based on the\nMetropolis-Hastings naming game (MHNG), a decentralized Bayesian inference\nmechanism. In an online experiment, 69 participants played a joint attention\nnaming game (JA-NG) with one of three computer agent types (MH-based,\nalways-accept, or always-reject) under partial observability. Results show that\nhuman-AI pairs with an MH-based agent significantly improved categorization\naccuracy through interaction and achieved stronger convergence toward a shared\nsign system. Furthermore, human acceptance behavior aligned closely with the\nMH-derived acceptance probability. These findings provide the first empirical\nevidence for co-creative learning emerging in human-AI dyads via MHNG-based\ninteraction. This suggests a promising path toward symbiotic AI systems that\nlearn with humans, rather than from them, by dynamically aligning perceptual\nexperiences, opening a new venue for symbiotic AI alignment.",
      "pdf_url": "http://arxiv.org/pdf/2506.15468v1",
      "published": "2025-06-18T13:58:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.15468v1",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "RE-IMAGINE: Symbolic Benchmark Synthesis for Reasoning Evaluation",
      "authors": [
        "Xinnuo Xu",
        "Rachel Lawrence",
        "Kshitij Dubey",
        "Atharva Pandey",
        "Risa Ueno",
        "Fabian Falck",
        "Aditya V. Nori",
        "Rahul Sharma",
        "Amit Sharma",
        "Javier Gonzalez"
      ],
      "abstract": "Recent Large Language Models (LLMs) have reported high accuracy on reasoning\nbenchmarks. However, it is still unclear whether the observed results arise\nfrom true reasoning or from statistical recall of the training set. Inspired by\nthe ladder of causation (Pearl, 2009) and its three levels (associations,\ninterventions and counterfactuals), this paper introduces RE-IMAGINE, a\nframework to characterize a hierarchy of reasoning ability in LLMs, alongside\nan automated pipeline to generate problem variations at different levels of the\nhierarchy. By altering problems in an intermediate symbolic representation,\nRE-IMAGINE generates arbitrarily many problems that are not solvable using\nmemorization alone. Moreover, the framework is general and can work across\nreasoning domains, including math, code, and logic. We demonstrate our\nframework on four widely-used benchmarks to evaluate several families of LLMs,\nand observe reductions in performance when the models are queried with problem\nvariations. These assessments indicate a degree of reliance on statistical\nrecall for past performance, and open the door to further research targeting\nskills across the reasoning hierarchy.",
      "pdf_url": "http://arxiv.org/pdf/2506.15455v1",
      "published": "2025-06-18T13:35:47+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.15455v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Uncovering Intention through LLM-Driven Code Snippet Description Generation",
      "authors": [
        "Yusuf Sulistyo Nugroho",
        "Farah Danisha Salam",
        "Brittany Reid",
        "Raula Gaikovina Kula",
        "Kazumasa Shimari",
        "Kenichi Matsumoto"
      ],
      "abstract": "Documenting code snippets is essential to pinpoint key areas where both\ndevelopers and users should pay attention. Examples include usage examples and\nother Application Programming Interfaces (APIs), which are especially important\nfor third-party libraries. With the rise of Large Language Models (LLMs), the\nkey goal is to investigate the kinds of description developers commonly use and\nevaluate how well an LLM, in this case Llama, can support description\ngeneration. We use NPM Code Snippets, consisting of 185,412 packages with\n1,024,579 code snippets. From there, we use 400 code snippets (and their\ndescriptions) as samples. First, our manual classification found that the\nmajority of original descriptions (55.5%) highlight example-based usage. This\nfinding emphasizes the importance of clear documentation, as some descriptions\nlacked sufficient detail to convey intent. Second, the LLM correctly identified\nthe majority of original descriptions as \"Example\" (79.75%), which is identical\nto our manual finding, showing a propensity for generalization. Third, compared\nto the originals, the produced description had an average similarity score of\n0.7173, suggesting relevance but room for improvement. Scores below 0.9\nindicate some irrelevance. Our results show that depending on the task of the\ncode snippet, the intention of the document may differ from being instructions\nfor usage, installations, or descriptive learning examples for any user of a\nlibrary.",
      "pdf_url": "http://arxiv.org/pdf/2506.15453v1",
      "published": "2025-06-18T13:33:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.15453v1",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "Warping and Matching Subsequences Between Time Series",
      "authors": [
        "Simiao Lin",
        "Wannes Meert",
        "Pieter Robberechts",
        "Hendrik Blockeel"
      ],
      "abstract": "Comparing time series is essential in various tasks such as clustering and\nclassification. While elastic distance measures that allow warping provide a\nrobust quantitative comparison, a qualitative comparison on top of them is\nmissing. Traditional visualizations focus on point-to-point alignment and do\nnot convey the broader structural relationships at the level of subsequences.\nThis limitation makes it difficult to understand how and where one time series\nshifts, speeds up or slows down with respect to another. To address this, we\npropose a novel technique that simplifies the warping path to highlight,\nquantify and visualize key transformations (shift, compression, difference in\namplitude). By offering a clearer representation of how subsequences match\nbetween time series, our method enhances interpretability in time series\ncomparison.",
      "pdf_url": "http://arxiv.org/pdf/2506.15452v1",
      "published": "2025-06-18T13:25:48+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.15452v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ]
    },
    {
      "title": "Zero-Shot Reinforcement Learning Under Partial Observability",
      "authors": [
        "Scott Jeen",
        "Tom Bewley",
        "Jonathan M. Cullen"
      ],
      "abstract": "Recent work has shown that, under certain assumptions, zero-shot\nreinforcement learning (RL) methods can generalise to any unseen task in an\nenvironment after reward-free pre-training. Access to Markov states is one such\nassumption, yet, in many real-world applications, the Markov state is only\npartially observable. Here, we explore how the performance of standard\nzero-shot RL methods degrades when subjected to partially observability, and\nshow that, as in single-task RL, memory-based architectures are an effective\nremedy. We evaluate our memory-based zero-shot RL methods in domains where the\nstates, rewards and a change in dynamics are partially observed, and show\nimproved performance over memory-free baselines. Our code is open-sourced via:\nhttps://enjeeneer.io/projects/bfms-with-memory/.",
      "pdf_url": "http://arxiv.org/pdf/2506.15446v1",
      "published": "2025-06-18T13:18:36+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.15446v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Hunyuan3D 2.1: From Images to High-Fidelity 3D Assets with Production-Ready PBR Material",
      "authors": [
        "Team Hunyuan3D",
        "Shuhui Yang",
        "Mingxin Yang",
        "Yifei Feng",
        "Xin Huang",
        "Sheng Zhang",
        "Zebin He",
        "Di Luo",
        "Haolin Liu",
        "Yunfei Zhao",
        "Qingxiang Lin",
        "Zeqiang Lai",
        "Xianghui Yang",
        "Huiwen Shi",
        "Zibo Zhao",
        "Bowen Zhang",
        "Hongyu Yan",
        "Lifu Wang",
        "Sicong Liu",
        "Jihong Zhang",
        "Meng Chen",
        "Liang Dong",
        "Yiwen Jia",
        "Yulin Cai",
        "Jiaao Yu",
        "Yixuan Tang",
        "Dongyuan Guo",
        "Junlin Yu",
        "Hao Zhang",
        "Zheng Ye",
        "Peng He",
        "Runzhou Wu",
        "Shida Wei",
        "Chao Zhang",
        "Yonghao Tan",
        "Yifu Sun",
        "Lin Niu",
        "Shirui Huang",
        "Bojian Zheng",
        "Shu Liu",
        "Shilin Chen",
        "Xiang Yuan",
        "Xiaofeng Yang",
        "Kai Liu",
        "Jianchen Zhu",
        "Peng Chen",
        "Tian Liu",
        "Di Wang",
        "Yuhong Liu",
        "Linus",
        "Jie Jiang",
        "Jingwei Huang",
        "Chunchao Guo"
      ],
      "abstract": "3D AI-generated content (AIGC) is a passionate field that has significantly\naccelerated the creation of 3D models in gaming, film, and design. Despite the\ndevelopment of several groundbreaking models that have revolutionized 3D\ngeneration, the field remains largely accessible only to researchers,\ndevelopers, and designers due to the complexities involved in collecting,\nprocessing, and training 3D models. To address these challenges, we introduce\nHunyuan3D 2.1 as a case study in this tutorial. This tutorial offers a\ncomprehensive, step-by-step guide on processing 3D data, training a 3D\ngenerative model, and evaluating its performance using Hunyuan3D 2.1, an\nadvanced system for producing high-resolution, textured 3D assets. The system\ncomprises two core components: the Hunyuan3D-DiT for shape generation and the\nHunyuan3D-Paint for texture synthesis. We will explore the entire workflow,\nincluding data preparation, model architecture, training strategies, evaluation\nmetrics, and deployment. By the conclusion of this tutorial, you will have the\nknowledge to finetune or develop a robust 3D generative model suitable for\napplications in gaming, virtual reality, and industrial design.",
      "pdf_url": "http://arxiv.org/pdf/2506.15442v1",
      "published": "2025-06-18T13:14:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.15442v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Reward Models in Deep Reinforcement Learning: A Survey",
      "authors": [
        "Rui Yu",
        "Shenghua Wan",
        "Yucen Wang",
        "Chen-Xiao Gao",
        "Le Gan",
        "Zongzhang Zhang",
        "De-Chuan Zhan"
      ],
      "abstract": "In reinforcement learning (RL), agents continually interact with the\nenvironment and use the feedback to refine their behavior. To guide policy\noptimization, reward models are introduced as proxies of the desired\nobjectives, such that when the agent maximizes the accumulated reward, it also\nfulfills the task designer's intentions. Recently, significant attention from\nboth academic and industrial researchers has focused on developing reward\nmodels that not only align closely with the true objectives but also facilitate\npolicy optimization. In this survey, we provide a comprehensive review of\nreward modeling techniques within the deep RL literature. We begin by outlining\nthe background and preliminaries in reward modeling. Next, we present an\noverview of recent reward modeling approaches, categorizing them based on the\nsource, the mechanism, and the learning paradigm. Building on this\nunderstanding, we discuss various applications of these reward modeling\ntechniques and review methods for evaluating reward models. Finally, we\nconclude by highlighting promising research directions in reward modeling.\nAltogether, this survey includes both established and emerging methods, filling\nthe vacancy of a systematic review of reward models in current literature.",
      "pdf_url": "http://arxiv.org/pdf/2506.15421v1",
      "published": "2025-06-18T12:46:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.15421v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Unifying VXAI: A Systematic Review and Framework for the Evaluation of Explainable AI",
      "authors": [
        "David Dembinsky",
        "Adriano Lucieri",
        "Stanislav Frolov",
        "Hiba Najjar",
        "Ko Watanabe",
        "Andreas Dengel"
      ],
      "abstract": "Modern AI systems frequently rely on opaque black-box models, most notably\nDeep Neural Networks, whose performance stems from complex architectures with\nmillions of learned parameters. While powerful, their complexity poses a major\nchallenge to trustworthiness, particularly due to a lack of transparency.\nExplainable AI (XAI) addresses this issue by providing human-understandable\nexplanations of model behavior. However, to ensure their usefulness and\ntrustworthiness, such explanations must be rigorously evaluated. Despite the\ngrowing number of XAI methods, the field lacks standardized evaluation\nprotocols and consensus on appropriate metrics. To address this gap, we conduct\na systematic literature review following the Preferred Reporting Items for\nSystematic Reviews and Meta-Analyses (PRISMA) guidelines and introduce a\nunified framework for the eValuation of XAI (VXAI). We identify 362 relevant\npublications and aggregate their contributions into 41 functionally similar\nmetric groups. In addition, we propose a three-dimensional categorization\nscheme spanning explanation type, evaluation contextuality, and explanation\nquality desiderata. Our framework provides the most comprehensive and\nstructured overview of VXAI to date. It supports systematic metric selection,\npromotes comparability across methods, and offers a flexible foundation for\nfuture extensions.",
      "pdf_url": "http://arxiv.org/pdf/2506.15408v1",
      "published": "2025-06-18T12:25:37+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.15408v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "MCOO-SLAM: A Multi-Camera Omnidirectional Object SLAM System",
      "authors": [
        "Miaoxin Pan",
        "Jinnan Li",
        "Yaowen Zhang",
        "Yi Yang",
        "Yufeng Yue"
      ],
      "abstract": "Object-level SLAM offers structured and semantically meaningful environment\nrepresentations, making it more interpretable and suitable for high-level\nrobotic tasks. However, most existing approaches rely on RGB-D sensors or\nmonocular views, which suffer from narrow fields of view, occlusion\nsensitivity, and limited depth perception-especially in large-scale or outdoor\nenvironments. These limitations often restrict the system to observing only\npartial views of objects from limited perspectives, leading to inaccurate\nobject modeling and unreliable data association. In this work, we propose\nMCOO-SLAM, a novel Multi-Camera Omnidirectional Object SLAM system that fully\nleverages surround-view camera configurations to achieve robust, consistent,\nand semantically enriched mapping in complex outdoor scenarios. Our approach\nintegrates point features and object-level landmarks enhanced with\nopen-vocabulary semantics. A semantic-geometric-temporal fusion strategy is\nintroduced for robust object association across multiple views, leading to\nimproved consistency and accurate object modeling, and an omnidirectional loop\nclosure module is designed to enable viewpoint-invariant place recognition\nusing scene-level descriptors. Furthermore, the constructed map is abstracted\ninto a hierarchical 3D scene graph to support downstream reasoning tasks.\nExtensive experiments in real-world demonstrate that MCOO-SLAM achieves\naccurate localization and scalable object-level mapping with improved\nrobustness to occlusion, pose variation, and environmental complexity.",
      "pdf_url": "http://arxiv.org/pdf/2506.15402v1",
      "published": "2025-06-18T12:20:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.15402v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "A Real-time Endoscopic Image Denoising System",
      "authors": [
        "Yu Xing",
        "Shishi Huang",
        "Meng Lv",
        "Guo Chen",
        "Huailiang Wang",
        "Lingzhi Sui"
      ],
      "abstract": "Endoscopes featuring a miniaturized design have significantly enhanced\noperational flexibility, portability, and diagnostic capability while\nsubstantially reducing the invasiveness of medical procedures. Recently,\nsingle-use endoscopes equipped with an ultra-compact analogue image sensor\nmeasuring less than 1mm x 1mm bring revolutionary advancements to medical\ndiagnosis. They reduce the structural redundancy and large capital expenditures\nassociated with reusable devices, eliminate the risk of patient infections\ncaused by inadequate disinfection, and alleviate patient suffering. However,\nthe limited photosensitive area results in reduced photon capture per pixel,\nrequiring higher photon sensitivity settings to maintain adequate brightness.\nIn high-contrast medical imaging scenarios, the small-sized sensor exhibits a\nconstrained dynamic range, making it difficult to simultaneously capture\ndetails in both highlights and shadows, and additional localized digital gain\nis required to compensate. Moreover, the simplified circuit design and analog\nsignal transmission introduce additional noise sources. These factors\ncollectively contribute to significant noise issues in processed endoscopic\nimages. In this work, we developed a comprehensive noise model for analog image\nsensors in medical endoscopes, addressing three primary noise types:\nfixed-pattern noise, periodic banding noise, and mixed Poisson-Gaussian noise.\nBuilding on this analysis, we propose a hybrid denoising system that\nsynergistically combines traditional image processing algorithms with advanced\nlearning-based techniques for captured raw frames from sensors. Experiments\ndemonstrate that our approach effectively reduces image noise without fine\ndetail loss or color distortion, while achieving real-time performance on FPGA\nplatforms and an average PSNR improvement from 21.16 to 33.05 on our test\ndataset.",
      "pdf_url": "http://arxiv.org/pdf/2506.15395v1",
      "published": "2025-06-18T12:12:10+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.15395v1",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Evaluation Pipeline for systematically searching for Anomaly Detection Systems",
      "authors": [
        "Florian Rokohl",
        "Alexander Lehnert",
        "Marc Reichenbach"
      ],
      "abstract": "Digitalization in the medical world provides major benefits while making it a\ntarget for attackers and thus hard to secure. To deal with network intruders we\npropose an anomaly detection system on hardware to detect malicious clients in\nreal-time. We meet real-time and power restrictions using FPGAs. Overall system\nperformance is achieved via the presented holistic system evaluation.",
      "pdf_url": "http://arxiv.org/pdf/2506.15388v1",
      "published": "2025-06-18T12:03:49+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.15388v1",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "title": "Efficient and Generalizable Environmental Understanding for Visual Navigation",
      "authors": [
        "Ruoyu Wang",
        "Xinshu Li",
        "Chen Wang",
        "Lina Yao"
      ],
      "abstract": "Visual Navigation is a core task in Embodied AI, enabling agents to navigate\ncomplex environments toward given objectives. Across diverse settings within\nNavigation tasks, many necessitate the modelling of sequential data accumulated\nfrom preceding time steps. While existing methods perform well, they typically\nprocess all historical observations simultaneously, overlooking the internal\nassociation structure within the data, which may limit the potential for\nfurther improvements in task performance. We address this by examining the\nunique characteristics of Navigation tasks through the lens of causality,\nintroducing a causal framework to highlight the limitations of conventional\nsequential methods. Leveraging this insight, we propose Causality-Aware\nNavigation (CAN), which incorporates a Causal Understanding Module to enhance\nthe agent's environmental understanding capability. Empirical evaluations show\nthat our approach consistently outperforms baselines across various tasks and\nsimulation environments. Extensive ablations studies attribute these gains to\nthe Causal Understanding Module, which generalizes effectively in both\nReinforcement and Supervised Learning settings without computational overhead.",
      "pdf_url": "http://arxiv.org/pdf/2506.15377v1",
      "published": "2025-06-18T11:47:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.15377v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Open-World Object Counting in Videos",
      "authors": [
        "Niki Amini-Naieni",
        "Andrew Zisserman"
      ],
      "abstract": "We introduce a new task of open-world object counting in videos: given a text\ndescription, or an image example, that specifies the target object, the\nobjective is to enumerate all the unique instances of the target objects in the\nvideo. This task is especially challenging in crowded scenes with occlusions\nand similar objects, where avoiding double counting and identifying\nreappearances is crucial. To this end, we make the following contributions: we\nintroduce a model, CountVid, for this task. It leverages an image-based\ncounting model, and a promptable video segmentation and tracking model to\nenable automated, open-world object counting across video frames. To evaluate\nits performance, we introduce VideoCount, a new dataset for our novel task\nbuilt from the TAO and MOT20 tracking datasets, as well as from videos of\npenguins and metal alloy crystallization captured by x-rays. Using this\ndataset, we demonstrate that CountVid provides accurate object counts, and\nsignificantly outperforms strong baselines. The VideoCount dataset, the\nCountVid model, and all the code are available at\nhttps://github.com/niki-amini-naieni/CountVid/.",
      "pdf_url": "http://arxiv.org/pdf/2506.15368v1",
      "published": "2025-06-18T11:35:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.15368v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "When and How Unlabeled Data Provably Improve In-Context Learning",
      "authors": [
        "Yingcong Li",
        "Xiangyu Chang",
        "Muti Kara",
        "Xiaofeng Liu",
        "Amit Roy-Chowdhury",
        "Samet Oymak"
      ],
      "abstract": "Recent research shows that in-context learning (ICL) can be effective even\nwhen demonstrations have missing or incorrect labels. To shed light on this\ncapability, we examine a canonical setting where the demonstrations are drawn\naccording to a binary Gaussian mixture model (GMM) and a certain fraction of\nthe demonstrations have missing labels. We provide a comprehensive theoretical\nstudy to show that: (1) The loss landscape of one-layer linear attention models\nrecover the optimal fully-supervised estimator but completely fail to exploit\nunlabeled data; (2) In contrast, multilayer or looped transformers can\neffectively leverage unlabeled data by implicitly constructing estimators of\nthe form $\\sum_{i\\ge 0} a_i (X^\\top X)^iX^\\top y$ with $X$ and $y$ denoting\nfeatures and partially-observed labels (with missing entries set to zero). We\ncharacterize the class of polynomials that can be expressed as a function of\ndepth and draw connections to Expectation Maximization, an iterative\npseudo-labeling algorithm commonly used in semi-supervised learning.\nImportantly, the leading polynomial power is exponential in depth, so mild\namount of depth/looping suffices. As an application of theory, we propose\nlooping off-the-shelf tabular foundation models to enhance their\nsemi-supervision capabilities. Extensive evaluations on real-world datasets\nshow that our method significantly improves the semisupervised tabular learning\nperformance over the standard single pass inference.",
      "pdf_url": "http://arxiv.org/pdf/2506.15329v1",
      "published": "2025-06-18T10:01:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.15329v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "math.OC"
      ]
    },
    {
      "title": "J3DAI: A tiny DNN-Based Edge AI Accelerator for 3D-Stacked CMOS Image Sensor",
      "authors": [
        "Benoit Tain",
        "Raphael Millet",
        "Romain Lemaire",
        "Michal Szczepanski",
        "Laurent Alacoque",
        "Emmanuel Pluchart",
        "Sylvain Choisnet",
        "Rohit Prasad",
        "Jerome Chossat",
        "Pascal Pierunek",
        "Pascal Vivet",
        "Sebastien Thuries"
      ],
      "abstract": "This paper presents J3DAI, a tiny deep neural network-based hardware\naccelerator for a 3-layer 3D-stacked CMOS image sensor featuring an artificial\nintelligence (AI) chip integrating a Deep Neural Network (DNN)-based\naccelerator. The DNN accelerator is designed to efficiently perform neural\nnetwork tasks such as image classification and segmentation. This paper focuses\non the digital system of J3DAI, highlighting its Performance-Power-Area (PPA)\ncharacteristics and showcasing advanced edge AI capabilities on a CMOS image\nsensor. To support hardware, we utilized the Aidge comprehensive software\nframework, which enables the programming of both the host processor and the DNN\naccelerator. Aidge supports post-training quantization, significantly reducing\nmemory footprint and computational complexity, making it crucial for deploying\nmodels on resource-constrained hardware like J3DAI. Our experimental results\ndemonstrate the versatility and efficiency of this innovative design in the\nfield of edge AI, showcasing its potential to handle both simple and\ncomputationally intensive tasks. Future work will focus on further optimizing\nthe architecture and exploring new applications to fully leverage the\ncapabilities of J3DAI. As edge AI continues to grow in importance, innovations\nlike J3DAI will play a crucial role in enabling real-time, low-latency, and\nenergy-efficient AI processing at the edge.",
      "pdf_url": "http://arxiv.org/pdf/2506.15316v1",
      "published": "2025-06-18T09:46:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.15316v1",
      "categories": [
        "cs.AR",
        "cs.AI"
      ]
    },
    {
      "title": "MapFM: Foundation Model-Driven HD Mapping with Multi-Task Contextual Learning",
      "authors": [
        "Leonid Ivanov",
        "Vasily Yuryev",
        "Dmitry Yudin"
      ],
      "abstract": "In autonomous driving, high-definition (HD) maps and semantic maps in\nbird's-eye view (BEV) are essential for accurate localization, planning, and\ndecision-making. This paper introduces an enhanced End-to-End model named MapFM\nfor online vectorized HD map generation. We show significantly boost feature\nrepresentation quality by incorporating powerful foundation model for encoding\ncamera images. To further enrich the model's understanding of the environment\nand improve prediction quality, we integrate auxiliary prediction heads for\nsemantic segmentation in the BEV representation. This multi-task learning\napproach provides richer contextual supervision, leading to a more\ncomprehensive scene representation and ultimately resulting in higher accuracy\nand improved quality of the predicted vectorized HD maps. The source code is\navailable at https://github.com/LIvanoff/MapFM.",
      "pdf_url": "http://arxiv.org/pdf/2506.15313v1",
      "published": "2025-06-18T09:42:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.15313v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Active Learning-Guided Seq2Seq Variational Autoencoder for Multi-target Inhibitor Generation",
      "authors": [
        "Júlia Vilalta-Mor",
        "Alexis Molina",
        "Laura Ortega Varga",
        "Isaac Filella-Merce",
        "Victor Guallar"
      ],
      "abstract": "Simultaneously optimizing molecules against multiple therapeutic targets\nremains a profound challenge in drug discovery, particularly due to sparse\nrewards and conflicting design constraints. We propose a structured active\nlearning (AL) paradigm integrating a sequence-to-sequence (Seq2Seq) variational\nautoencoder (VAE) into iterative loops designed to balance chemical diversity,\nmolecular quality, and multi-target affinity. Our method alternates between\nexpanding chemically feasible regions of latent space and progressively\nconstraining molecules based on increasingly stringent multi-target docking\nthresholds. In a proof-of-concept study targeting three related coronavirus\nmain proteases (SARS-CoV-2, SARS-CoV, MERS-CoV), our approach efficiently\ngenerated a structurally diverse set of pan-inhibitor candidates. We\ndemonstrate that careful timing and strategic placement of chemical filters\nwithin this active learning pipeline markedly enhance exploration of beneficial\nchemical space, transforming the sparse-reward, multi-objective drug design\nproblem into an accessible computational task. Our framework thus provides a\ngeneralizable roadmap for efficiently navigating complex polypharmacological\nlandscapes.",
      "pdf_url": "http://arxiv.org/pdf/2506.15309v1",
      "published": "2025-06-18T09:39:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.15309v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.BM"
      ]
    },
    {
      "title": "ConLID: Supervised Contrastive Learning for Low-Resource Language Identification",
      "authors": [
        "Negar Foroutan",
        "Jakhongir Saydaliev",
        "Ye Eun Kim",
        "Antoine Bosselut"
      ],
      "abstract": "Language identification (LID) is a critical step in curating multilingual LLM\npretraining corpora from web crawls. While many studies on LID model training\nfocus on collecting diverse training data to improve performance, low-resource\nlanguages -- often limited to single-domain data, such as the Bible -- continue\nto perform poorly. To resolve these class imbalance and bias issues, we propose\na novel supervised contrastive learning (SCL) approach to learn\ndomain-invariant representations for low-resource languages. Through an\nextensive analysis, we show that our approach improves LID performance on\nout-of-domain data for low-resource languages by 3.2%, demonstrating its\neffectiveness in enhancing LID models.",
      "pdf_url": "http://arxiv.org/pdf/2506.15304v1",
      "published": "2025-06-18T09:35:33+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.15304v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    }
  ]
}