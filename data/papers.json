{
  "last_updated": "2025-08-01T01:04:17.051147",
  "papers": [
    {
      "title": "Where to show Demos in Your Prompt: A Positional Bias of In-Context Learning",
      "authors": [
        "Kwesi Cobbina",
        "Tianyi Zhou"
      ],
      "abstract": "In-context learning (ICL) is a critical emerging capability of large language\nmodels (LLMs), enabling few-shot learning during inference by including a few\ndemonstrations (demos) in the prompt. However, it has been found that ICL's\nperformance can be sensitive to the choices of demos and their order. This\npaper investigates an unexplored new positional bias of ICL for the first time:\nwe observe that the predictions and accuracy can drift drastically when the\npositions of demos, the system prompt, and the user message in LLM input are\nvaried. We refer to this bias as DEMOS' POSITION IN PROMPT (DPP) bias. We\ndesign a systematic evaluation pipeline to study this type of positional bias\nacross classification, question answering, summarization, and reasoning tasks.\nWe introduce two metrics, ACCURACY-CHANGE and PREDICTION-CHANGE, to quantify\nnet gains and output volatility induced by changes in the demos' position.\nExtensive experiments on ten LLMs from four open-source model families (QWEN,\nLLAMA3, MISTRAL, COHERE) verify that the bias significantly affects their\naccuracy and predictions: placing demos at the start of the prompt yields the\nmost stable and accurate outputs with gains of up to +6 points. In contrast,\nplacing demos at the end of the user message flips over 30\\% of predictions\nwithout improving correctness on QA tasks. Smaller models are most affected by\nthis sensitivity, though even large models remain marginally affected on\ncomplex tasks.",
      "pdf_url": "http://arxiv.org/pdf/2507.22887v1",
      "published": "2025-07-30T17:59:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.22887v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Automatically discovering heuristics in a complex SAT solver with large language models",
      "authors": [
        "Yiwen Sun",
        "Furong Ye",
        "Zhihan Chen",
        "Ke Wei",
        "Shaowei Cai"
      ],
      "abstract": "Satisfiability problem (SAT) is a cornerstone of computational complexity\nwith broad industrial applications, and it remains challenging to optimize\nmodern SAT solvers in real-world settings due to their intricate architectures.\nWhile automatic configuration frameworks have been developed, they rely on\nmanually constrained search spaces and yield limited performance gains. This\nwork introduces a novel paradigm which effectively optimizes complex SAT\nsolvers via Large Language Models (LLMs), and a tool called AutoModSAT is\ndeveloped. Three fundamental challenges are addressed in order to achieve\nsuperior performance: (1) LLM-friendly solver: Systematic guidelines are\nproposed for developing a modularized solver to meet LLMs' compatibility,\nemphasizing code simplification, information share and bug reduction; (2)\nAutomatic prompt optimization: An unsupervised automatic prompt optimization\nmethod is introduced to advance the diversity of LLMs' output; (3) Efficient\nsearch strategy: We design a presearch strategy and an EA evolutionary\nalgorithm for the final efficient and effective discovery of heuristics.\nExtensive experiments across a wide range of datasets demonstrate that\nAutoModSAT achieves 50% performance improvement over the baseline solver and\nachieves 30% superiority against the state-of-the-art (SOTA) solvers. Moreover,\nAutoModSAT attains a 20% speedup on average compared to parameter-tuned\nalternatives of the SOTA solvers, showcasing the enhanced capability in\nhandling complex problem instances. This work bridges the gap between AI-driven\nheuristics discovery and mission-critical system optimization, and provides\nboth methodological advancements and empirically validated results for\nnext-generation complex solver development.",
      "pdf_url": "http://arxiv.org/pdf/2507.22876v1",
      "published": "2025-07-30T17:52:25+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.22876v1",
      "categories": [
        "cs.AI",
        "cs.LO"
      ]
    },
    {
      "title": "A Bit of Freedom Goes a Long Way: Classical and Quantum Algorithms for Reinforcement Learning under a Generative Model",
      "authors": [
        "Andris Ambainis",
        "Joao F. Doriguello",
        "Debbie Lim"
      ],
      "abstract": "We propose novel classical and quantum online algorithms for learning\nfinite-horizon and infinite-horizon average-reward Markov Decision Processes\n(MDPs). Our algorithms are based on a hybrid exploration-generative\nreinforcement learning (RL) model wherein the agent can, from time to time,\nfreely interact with the environment in a generative sampling fashion, i.e., by\nhaving access to a \"simulator\". By employing known classical and new quantum\nalgorithms for approximating optimal policies under a generative model within\nour learning algorithms, we show that it is possible to avoid several paradigms\nfrom RL like \"optimism in the face of uncertainty\" and \"posterior sampling\" and\ninstead compute and use optimal policies directly, which yields better regret\nbounds compared to previous works. For finite-horizon MDPs, our quantum\nalgorithms obtain regret bounds which only depend logarithmically on the number\nof time steps $T$, thus breaking the $O(\\sqrt{T})$ classical barrier. This\nmatches the time dependence of the prior quantum works of Ganguly et al.\n(arXiv'23) and Zhong et al. (ICML'24), but with improved dependence on other\nparameters like state space size $S$ and action space size $A$. For\ninfinite-horizon MDPs, our classical and quantum bounds still maintain the\n$O(\\sqrt{T})$ dependence but with better $S$ and $A$ factors. Nonetheless, we\npropose a novel measure of regret for infinite-horizon MDPs with respect to\nwhich our quantum algorithms have $\\operatorname{poly}\\log{T}$ regret,\nexponentially better compared to classical algorithms. Finally, we generalise\nall of our results to compact state spaces.",
      "pdf_url": "http://arxiv.org/pdf/2507.22854v1",
      "published": "2025-07-30T17:24:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.22854v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC",
        "quant-ph",
        "stat.ML"
      ]
    },
    {
      "title": "Repair-R1: Better Test Before Repair",
      "authors": [
        "Haichuan Hu",
        "Xiaochen Xie",
        "Quanjun Zhang"
      ],
      "abstract": "APR (Automated Program Repair) aims to automatically locate program defects,\ngenerate patches and validate the repairs. Existing techniques for APR are\noften combined with LLMs (Large Language Models), which leverages the\ncode-related knowledge of LLMs to improve repair effectiveness. Current\nLLM-based APR methods typically utilize test cases only during the inference\nstage, adopting an iterative approach that performs repair first and validates\nit through test execution afterward. This conventional paradigm neglects two\nimportant aspects: the potential contribution of test cases in the training\nphase, and the possibility of leveraging testing prior to repair. To address\nthis, we propose Repair-R1, which introduces test cases into the model's\ntraining phase and shifts test generation to precede repair. The model is\nrequired to first generate discriminative test cases that can distinguish\ndefective behaviors, and then perform repair based on these tests. This enables\nthe model to better locate defects and understand the underlying causes of\ndefects, thereby improving repair effectiveness. We implement Repair-R1 with\nthree different backbone models, using RL (reinforcement learning) to\nco-optimize test generation and bug repair. Experimental results on four widely\nadopted benchmarks demonstrate the superiority of Repair-R1. Specially,\ncompared to vanilla models, Repair-R1 improves repair success rate by 2.68\\% to\n48.29\\%, test generation success rate by 16.38\\% to 53.28\\%, and test coverage\nby 0.78\\% to 53.96\\%. We publish the code and weights at\nhttps://github.com/Tomsawyerhu/APR-RL and\nhttps://huggingface.co/tomhu/Qwen3-4B-RL-5000-step.",
      "pdf_url": "http://arxiv.org/pdf/2507.22853v1",
      "published": "2025-07-30T17:24:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.22853v1",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "The Incomplete Bridge: How AI Research (Mis)Engages with Psychology",
      "authors": [
        "Han Jiang",
        "Pengda Wang",
        "Xiaoyuan Yi",
        "Xing Xie",
        "Ziang Xiao"
      ],
      "abstract": "Social sciences have accumulated a rich body of theories and methodologies\nfor investigating the human mind and behaviors, while offering valuable\ninsights into the design and understanding of Artificial Intelligence (AI)\nsystems. Focusing on psychology as a prominent case, this study explores the\ninterdisciplinary synergy between AI and the field by analyzing 1,006\nLLM-related papers published in premier AI venues between 2023 and 2025, along\nwith the 2,544 psychology publications they cite. Through our analysis, we\nidentify key patterns of interdisciplinary integration, locate the psychology\ndomains most frequently referenced, and highlight areas that remain\nunderexplored. We further examine how psychology theories/frameworks are\noperationalized and interpreted, identify common types of misapplication, and\noffer guidance for more effective incorporation. Our work provides a\ncomprehensive map of interdisciplinary engagement between AI and psychology,\nthereby facilitating deeper collaboration and advancing AI systems.",
      "pdf_url": "http://arxiv.org/pdf/2507.22847v1",
      "published": "2025-07-30T17:03:59+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.22847v1",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ]
    },
    {
      "title": "RLVMR: Reinforcement Learning with Verifiable Meta-Reasoning Rewards for Robust Long-Horizon Agents",
      "authors": [
        "Zijing Zhang",
        "Ziyang Chen",
        "Mingxiao Li",
        "Zhaopeng Tu",
        "Xiaolong Li"
      ],
      "abstract": "The development of autonomous agents for complex, long-horizon tasks is a\ncentral goal in AI. However, dominant training paradigms face a critical\nlimitation: reinforcement learning (RL) methods that optimize solely for final\ntask success often reinforce flawed or inefficient reasoning paths, a problem\nwe term inefficient exploration. This leads to agents that are brittle and fail\nto generalize, as they learn to find solutions without learning how to reason\ncoherently. To address this, we introduce RLVMR, a novel framework that\nintegrates dense, process-level supervision into end-to-end RL by rewarding\nverifiable, meta-reasoning behaviors. RLVMR equips an agent to explicitly tag\nits cognitive steps, such as planning, exploration, and reflection, and\nprovides programmatic, rule-based rewards for actions that contribute to\neffective problem-solving. These process-centric rewards are combined with the\nfinal outcome signal and optimized using a critic-free policy gradient method.\nOn the challenging ALFWorld and ScienceWorld benchmarks, RLVMR achieves new\nstate-of-the-art results, with our 7B model reaching an 83.6% success rate on\nthe most difficult unseen task split. Our analysis confirms these gains stem\nfrom improved reasoning quality, including significant reductions in redundant\nactions and enhanced error recovery, leading to more robust, efficient, and\ninterpretable agents.",
      "pdf_url": "http://arxiv.org/pdf/2507.22844v1",
      "published": "2025-07-30T17:00:48+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.22844v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "CapRecover: A Cross-Modality Feature Inversion Attack Framework on Vision Language Models",
      "authors": [
        "Kedong Xiu",
        "Saiqian Zhang"
      ],
      "abstract": "As Vision-Language Models (VLMs) are increasingly deployed in split-DNN\nconfigurations--with visual encoders (e.g., ResNet, ViT) operating on user\ndevices and sending intermediate features to the cloud--there is a growing\nprivacy risk from semantic information leakage. Existing approaches to\nreconstructing images from these intermediate features often result in blurry,\nsemantically ambiguous images. To directly address semantic leakage, we propose\nCapRecover, a cross-modality inversion framework that recovers high-level\nsemantic content, such as labels or captions, directly from intermediate\nfeatures without image reconstruction.\n  We evaluate CapRecover on multiple datasets and victim models, demonstrating\nstrong performance in semantic recovery. Specifically, CapRecover achieves up\nto 92.71% Top-1 label accuracy on CIFAR-10 and generates fluent captions from\nResNet50 features on COCO2017 with ROUGE-L scores up to 0.52. Our analysis\nfurther reveals that deeper convolutional layers encode significantly more\nsemantic information compared to shallow layers. To mitigate semantic leakage,\nwe introduce a simple yet effective protection method: adding random noise to\nintermediate features at each layer and removing the noise in the next layer.\nExperimental results show that this approach prevents semantic leakage without\nadditional training costs.",
      "pdf_url": "http://arxiv.org/pdf/2507.22828v1",
      "published": "2025-07-30T16:42:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.22828v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "MoCHA: Advanced Vision-Language Reasoning with MoE Connector and Hierarchical Group Attention",
      "authors": [
        "Yuqi Pang",
        "Bowen Yang",
        "Yun Cao",
        "Fan Rong",
        "Xiaoyu Li",
        "Chen He"
      ],
      "abstract": "Vision large language models (VLLMs) are focusing primarily on handling\ncomplex and fine-grained visual information by incorporating advanced vision\nencoders and scaling up visual models. However, these approaches face high\ntraining and inference costs, as well as challenges in extracting visual\ndetails, effectively bridging across modalities. In this work, we propose a\nnovel visual framework, MoCHA, to address these issues. Our framework\nintegrates four vision backbones (i.e., CLIP, SigLIP, DINOv2 and ConvNeXt) to\nextract complementary visual features and is equipped with a sparse Mixture of\nExperts Connectors (MoECs) module to dynamically select experts tailored to\ndifferent visual dimensions. To mitigate redundant or insufficient use of the\nvisual information encoded by the MoECs module, we further design a\nHierarchical Group Attention (HGA) with intra- and inter-group operations and\nan adaptive gating strategy for encoded visual features. We train MoCHA on two\nmainstream LLMs (e.g., Phi2-2.7B and Vicuna-7B) and evaluate their performance\nacross various benchmarks. Notably, MoCHA outperforms state-of-the-art\nopen-weight models on various tasks. For example, compared to CuMo\n(Mistral-7B), our MoCHA (Phi2-2.7B) presents outstanding abilities to mitigate\nhallucination by showing improvements of 3.25% in POPE and to follow visual\ninstructions by raising 153 points on MME. Finally, ablation studies further\nconfirm the effectiveness and robustness of the proposed MoECs and HGA in\nimproving the overall performance of MoCHA.",
      "pdf_url": "http://arxiv.org/pdf/2507.22805v1",
      "published": "2025-07-30T16:15:22+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.22805v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Advancing Fetal Ultrasound Image Quality Assessment in Low-Resource Settings",
      "authors": [
        "Dongli He",
        "Hu Wang",
        "Mohammad Yaqub"
      ],
      "abstract": "Accurate fetal biometric measurements, such as abdominal circumference, play\na vital role in prenatal care. However, obtaining high-quality ultrasound\nimages for these measurements heavily depends on the expertise of sonographers,\nposing a significant challenge in low-income countries due to the scarcity of\ntrained personnel. To address this issue, we leverage FetalCLIP, a\nvision-language model pretrained on a curated dataset of over 210,000 fetal\nultrasound image-caption pairs, to perform automated fetal ultrasound image\nquality assessment (IQA) on blind-sweep ultrasound data. We introduce\nFetalCLIP$_{CLS}$, an IQA model adapted from FetalCLIP using Low-Rank\nAdaptation (LoRA), and evaluate it on the ACOUSLIC-AI dataset against six CNN\nand Transformer baselines. FetalCLIP$_{CLS}$ achieves the highest F1 score of\n0.757. Moreover, we show that an adapted segmentation model, when repurposed\nfor classification, further improves performance, achieving an F1 score of\n0.771. Our work demonstrates how parameter-efficient fine-tuning of fetal\nultrasound foundation models can enable task-specific adaptations, advancing\nprenatal care in resource-limited settings. The experimental code is available\nat: https://github.com/donglihe-hub/FetalCLIP-IQA.",
      "pdf_url": "http://arxiv.org/pdf/2507.22802v1",
      "published": "2025-07-30T16:09:29+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.22802v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "G-Core: A Simple, Scalable and Balanced RLHF Trainer",
      "authors": [
        "Junyu Wu",
        "Weiming Chang",
        "Xiaotao Liu",
        "Guanyou He",
        "Haoqiang Hong",
        "Boqi Liu",
        "Hongtao Tian",
        "Tao Yang",
        "Yunsheng Shi",
        "Feng Lin",
        "Ting Yao"
      ],
      "abstract": "Reinforcement Learning from Human Feedback (RLHF) has become an increasingly\npopular paradigm for training large language models (LLMs) and diffusion\nmodels. While existing RLHF training systems have enabled significant progress,\nthey often face challenges in scaling to multi-modal and diffusion workflows\nand adapting to dynamic workloads. In particular, current approaches may\nencounter limitations in controller scalability, flexible resource placement,\nand efficient orchestration when handling complex RLHF pipelines, especially in\nscenarios involving dynamic sampling or generative reward modeling. In this\npaper, we present \\textbf{G-Core}, a simple, scalable, and balanced RLHF\ntraining framework designed to address these challenges. G-Core introduces a\nparallel controller programming model, enabling flexible and efficient\norchestration of complex RLHF workflows without the bottlenecks of a single\ncentralized controller. Furthermore, we propose a dynamic placement schema that\nadaptively partitions resources and schedules workloads, significantly reducing\nhardware idle time and improving utilization, even under highly variable\ntraining conditions. G-Core has successfully trained models that support WeChat\nproduct features serving a large-scale user base, demonstrating its\neffectiveness and robustness in real-world scenarios. Our results show that\nG-Core advances the state of the art in RLHF training, providing a solid\nfoundation for future research and deployment of large-scale, human-aligned\nmodels.",
      "pdf_url": "http://arxiv.org/pdf/2507.22789v2",
      "published": "2025-07-30T15:55:08+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.22789v2",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Enhancing Multi-Agent Collaboration with Attention-Based Actor-Critic Policies",
      "authors": [
        "Hugo Garrido-Lestache",
        "Jeremy Kedziora"
      ],
      "abstract": "This paper introduces Team-Attention-Actor-Critic (TAAC), a reinforcement\nlearning algorithm designed to enhance multi-agent collaboration in cooperative\nenvironments. TAAC employs a Centralized Training/Centralized Execution scheme\nincorporating multi-headed attention mechanisms in both the actor and critic.\nThis design facilitates dynamic, inter-agent communication, allowing agents to\nexplicitly query teammates, thereby efficiently managing the exponential growth\nof joint-action spaces while ensuring a high degree of collaboration. We\nfurther introduce a penalized loss function which promotes diverse yet\ncomplementary roles among agents. We evaluate TAAC in a simulated soccer\nenvironment against benchmark algorithms representing other multi-agent\nparadigms, including Proximal Policy Optimization and Multi-Agent\nActor-Attention-Critic. We find that TAAC exhibits superior performance and\nenhanced collaborative behaviors across a variety of metrics (win rates, goal\ndifferentials, Elo ratings, inter-agent connectivity, balanced spatial\ndistributions, and frequent tactical interactions such as ball possession\nswaps).",
      "pdf_url": "http://arxiv.org/pdf/2507.22782v2",
      "published": "2025-07-30T15:48:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.22782v2",
      "categories": [
        "cs.AI",
        "cs.LG",
        "I.2.0; I.2.8"
      ]
    },
    {
      "title": "ASP-FZN: A Translation-based Constraint Answer Set Solver",
      "authors": [
        "Thomas Eiter",
        "Tobias Geibinger",
        "Tobias Kaminski",
        "Nysret Musliu",
        "Johannes Oetsch"
      ],
      "abstract": "We present the solver asp-fzn for Constraint Answer Set Programming (CASP),\nwhich extends ASP with linear constraints. Our approach is based on translating\nCASP programs into the solver-independent FlatZinc language that supports\nseveral Constraint Programming and Integer Programming backend solvers. Our\nsolver supports a rich language of linear constraints, including some common\nglobal constraints. As for evaluation, we show that asp-fzn is competitive with\nstate-of-the-art ASP solvers on benchmarks taken from past ASP competitions.\nFurthermore, we evaluate it on several CASP problems from the literature and\ncompare its performance with clingcon, which is a prominent CASP solver that\nsupports most of the asp-fzn language. The performance of asp-fzn is very\npromising as it is already competitive on plain ASP and even outperforms\nclingcon on some CASP benchmarks.",
      "pdf_url": "http://arxiv.org/pdf/2507.22774v1",
      "published": "2025-07-30T15:36:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.22774v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Empirical Evaluation of Concept Drift in ML-Based Android Malware Detection",
      "authors": [
        "Ahmed Sabbah",
        "Radi Jarrar",
        "Samer Zein",
        "David Mohaisen"
      ],
      "abstract": "Despite outstanding results, machine learning-based Android malware detection\nmodels struggle with concept drift, where rapidly evolving malware\ncharacteristics degrade model effectiveness. This study examines the impact of\nconcept drift on Android malware detection, evaluating two datasets and nine\nmachine learning and deep learning algorithms, as well as Large Language Models\n(LLMs). Various feature types--static, dynamic, hybrid, semantic, and\nimage-based--were considered. The results showed that concept drift is\nwidespread and significantly affects model performance. Factors influencing the\ndrift include feature types, data environments, and detection methods.\nBalancing algorithms helped with class imbalance but did not fully address\nconcept drift, which primarily stems from the dynamic nature of the malware\nlandscape. No strong link was found between the type of algorithm used and\nconcept drift, the impact was relatively minor compared to other variables\nsince hyperparameters were not fine-tuned, and the default algorithm\nconfigurations were used. While LLMs using few-shot learning demonstrated\npromising detection performance, they did not fully mitigate concept drift,\nhighlighting the need for further investigation.",
      "pdf_url": "http://arxiv.org/pdf/2507.22772v1",
      "published": "2025-07-30T15:35:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.22772v1",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Teaching the Teacher: Improving Neural Network Distillability for Symbolic Regression via Jacobian Regularization",
      "authors": [
        "Soumyadeep Dhar",
        "Kei Sen Fong",
        "Mehul Motani"
      ],
      "abstract": "Distilling large neural networks into simple, human-readable symbolic\nformulas is a promising path toward trustworthy and interpretable AI. However,\nthis process is often brittle, as the complex functions learned by standard\nnetworks are poor targets for symbolic discovery, resulting in low-fidelity\nstudent models. In this work, we propose a novel training paradigm to address\nthis challenge. Instead of passively distilling a pre-trained network, we\nintroduce a \\textbf{Jacobian-based regularizer} that actively encourages the\n``teacher'' network to learn functions that are not only accurate but also\ninherently smoother and more amenable to distillation. We demonstrate through\nextensive experiments on a suite of real-world regression benchmarks that our\nmethod is highly effective. By optimizing the regularization strength for each\nproblem, we improve the $R^2$ score of the final distilled symbolic model by an\naverage of \\textbf{120\\% (relative)} compared to the standard distillation\npipeline, all while maintaining the teacher's predictive accuracy. Our work\npresents a practical and principled method for significantly improving the\nfidelity of interpretable models extracted from complex neural networks.",
      "pdf_url": "http://arxiv.org/pdf/2507.22767v1",
      "published": "2025-07-30T15:32:18+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.22767v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Bayesian Optimization of Process Parameters of a Sensor-Based Sorting System using Gaussian Processes as Surrogate Models",
      "authors": [
        "Felix Kronenwett",
        "Georg Maier",
        "Thomas Laengle"
      ],
      "abstract": "Sensor-based sorting systems enable the physical separation of a material\nstream into two fractions. The sorting decision is based on the image data\nevaluation of the sensors used and is carried out using actuators. Various\nprocess parameters must be set depending on the properties of the material\nstream, the dimensioning of the system, and the required sorting accuracy.\nHowever, continuous verification and re-adjustment are necessary due to\nchanging requirements and material stream compositions. In this paper, we\nintroduce an approach for optimizing, recurrently monitoring and adjusting the\nprocess parameters of a sensor-based sorting system. Based on Bayesian\nOptimization, Gaussian process regression models are used as surrogate models\nto achieve specific requirements for system behavior with the uncertainties\ncontained therein. This method minimizes the number of necessary experiments\nwhile simultaneously considering two possible optimization targets based on the\nrequirements for both material output streams. In addition, uncertainties are\nconsidered during determining sorting accuracies in the model calculation. We\nevaluated the method with three example process parameters.",
      "pdf_url": "http://arxiv.org/pdf/2507.22766v1",
      "published": "2025-07-30T15:31:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.22766v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ]
    },
    {
      "title": "Of Good Demons and Bad Angels: Guaranteeing Safe Control under Finite Precision",
      "authors": [
        "Samuel Teuber",
        "Debasmita Lohar",
        "Bernhard Beckert"
      ],
      "abstract": "As neural networks (NNs) become increasingly prevalent in safety-critical\nneural network-controlled cyber-physical systems (NNCSs), formally guaranteeing\ntheir safety becomes crucial. For these systems, safety must be ensured\nthroughout their entire operation, necessitating infinite-time horizon\nverification. To verify the infinite-time horizon safety of NNCSs, recent\napproaches leverage Differential Dynamic Logic (dL). However, these dL-based\nguarantees rely on idealized, real-valued NN semantics and fail to account for\nroundoff errors introduced by finite-precision implementations. This paper\nbridges the gap between theoretical guarantees and real-world implementations\nby incorporating robustness under finite-precision perturbations -- in sensing,\nactuation, and computation -- into the safety verification. We model the\nproblem as a hybrid game between a good Demon, responsible for control actions,\nand a bad Angel, introducing perturbations. This formulation enables formal\nproofs of robustness w.r.t. a given (bounded) perturbation. Leveraging this\nbound, we employ state-of-the-art mixed-precision fixed-point tuners to\nsynthesize sound and efficient implementations, thus providing a complete\nend-to-end solution. We evaluate our approach on case studies from the\nautomotive and aeronautics domains, producing efficient NN implementations with\nrigorous infinite-time horizon safety guarantees.",
      "pdf_url": "http://arxiv.org/pdf/2507.22760v1",
      "published": "2025-07-30T15:21:22+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.22760v1",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.LG",
        "cs.LO",
        "cs.SY"
      ]
    },
    {
      "title": "Reducing Hallucinations in Summarization via Reinforcement Learning with Entity Hallucination Index",
      "authors": [
        "Praveenkumar Katwe",
        "Rakesh Chandra",
        "Balabantaray Kali",
        "Prasad Vittala"
      ],
      "abstract": "Reducing hallucinations in abstractive summarization remains a critical\nchallenge for deploying language models (LMs) in real-world settings. In this\nwork, we introduce a rewarddriven fine-tuning framework that explicitly\noptimizes for Entity Hallucination Index (EHI), a metric designed to quantify\nthe presence, correctness, and grounding of named entities in generated\nsummaries. Given a corpus of meeting transcripts, we first generate baseline\nsummaries using a pre-trained LM and compute EHI scores via automatic entity\nextraction and matching. We then apply reinforcement learning to fine-tune the\nmodel parameters, using EHI as a reward signal to bias generation toward\nentity-faithful outputs. Our approach does not rely on human-written factuality\nannotations, enabling scalable fine-tuning. Experiments demonstrate consistent\nimprovements in EHI across datasets, with qualitative analysis revealing a\nsignificant reduction in entity-level hallucinations without degradation in\nfluency or informativeness. We release a reproducible Colab pipeline,\nfacilitating further research on hallucination-aware model fine-tuning using\nlightweight, hallucintion metrics like EHI.",
      "pdf_url": "http://arxiv.org/pdf/2507.22744v1",
      "published": "2025-07-30T15:00:00+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.22744v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "68T50",
        "I.2.7"
      ]
    },
    {
      "title": "OFCnetLLM: Large Language Model for Network Monitoring and Alertness",
      "authors": [
        "Hong-Jun Yoon",
        "Mariam Kiran",
        "Danial Ebling",
        "Joe Breen"
      ],
      "abstract": "The rapid evolution of network infrastructure is bringing new challenges and\nopportunities for efficient network management, optimization, and security.\nWith very large monitoring databases becoming expensive to explore, the use of\nAI and Generative AI can help reduce costs of managing these datasets. This\npaper explores the use of Large Language Models (LLMs) to revolutionize network\nmonitoring management by addressing the limitations of query finding and\npattern analysis. We leverage LLMs to enhance anomaly detection, automate\nroot-cause analysis, and automate incident analysis to build a well-monitored\nnetwork management team using AI. Through a real-world example of developing\nour own OFCNetLLM, based on the open-source LLM model, we demonstrate practical\napplications of OFCnetLLM in the OFC conference network. Our model is developed\nas a multi-agent approach and is still evolving, and we present early results\nhere.",
      "pdf_url": "http://arxiv.org/pdf/2507.22711v1",
      "published": "2025-07-30T14:22:42+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.22711v1",
      "categories": [
        "cs.NI",
        "cs.AI"
      ]
    },
    {
      "title": "Bifröst: Spatial Networking with Bigraphs",
      "authors": [
        "Josh Millar",
        "Ryan Gibb",
        "Roy Ang",
        "Anil Madhavapeddy",
        "Hamed Haddadi"
      ],
      "abstract": "Modern networked environments increasingly rely on spatial reasoning, but\nlack a coherent representation for coordinating physical space. Consequently,\ntasks such as enforcing spatial access policies remain fragile and manual. We\nfirst propose a unifying representation based on bigraphs, capturing spatial,\nsocial, and communication relationships within a single formalism, with\nuser-facing tools to generate bigraphs from physical environments. Second, we\npresent a hierarchical agent architecture for distributed spatial reasoning,\nwith runtimes for agentic processes to interact the spatial representation, and\na context-aware execution model that scopes reasoning to the smallest viable\nsubspace. Together, these enable private, reliable, and low-latency spatial\nnetworking that can safely interact with agentic workflows.",
      "pdf_url": "http://arxiv.org/pdf/2507.22687v1",
      "published": "2025-07-30T13:49:12+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.22687v1",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.LO",
        "cs.MA"
      ]
    },
    {
      "title": "Hydra-Bench: A Benchmark for Multi-Modal Leaf Wetness Sensing",
      "authors": [
        "Yimeng Liu",
        "Maolin Gan",
        "Yidong Ren",
        "Gen Li",
        "Jingkai Lin",
        "Younsuk Dong",
        "Zhichao Cao"
      ],
      "abstract": "Leaf wetness detection is a crucial task in agricultural monitoring, as it\ndirectly impacts the prediction and protection of plant diseases. However,\nexisting sensing systems suffer from limitations in robustness, accuracy, and\nenvironmental resilience when applied to natural leaves under dynamic\nreal-world conditions. To address these challenges, we introduce a new\nmulti-modal dataset specifically designed for evaluating and advancing machine\nlearning algorithms in leaf wetness detection. Our dataset comprises\nsynchronized mmWave raw data, Synthetic Aperture Radar (SAR) images, and RGB\nimages collected over six months from five diverse plant species in both\ncontrolled and outdoor field environments. We provide detailed benchmarks using\nthe Hydra model, including comparisons against single modality baselines and\nmultiple fusion strategies, as well as performance under varying scan\ndistances. Additionally, our dataset can serve as a benchmark for future SAR\nimaging algorithm optimization, enabling a systematic evaluation of detection\naccuracy under diverse conditions.",
      "pdf_url": "http://arxiv.org/pdf/2507.22685v1",
      "published": "2025-07-30T13:47:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.22685v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Designing for Self-Regulation in Informal Programming Learning: Insights from a Storytelling-Centric Approach",
      "authors": [
        "Sami Saeed Alghamdi",
        "Christopher Bull",
        "Ahmed Kharrufa"
      ],
      "abstract": "Many people learn programming independently from online resources and often\nreport struggles in achieving their personal learning goals. Learners\nfrequently describe their experiences as isolating and frustrating, challenged\nby abundant uncertainties, information overload, and distraction, compounded by\nlimited guidance. At the same time, social media serves as a personal space\nwhere many engage in diverse self-regulation practices, including help-seeking,\nusing external memory aids (e.g., self-notes), self-reflection, emotion\nregulation, and self-motivation. For instance, learners often mark achievements\nand set milestones through their posts. In response, we developed a system\nconsisting of a web platform and browser extensions to support self-regulation\nonline. The design aims to add learner-defined structure to otherwise\nunstructured experiences and bring meaning to curation and reflection\nactivities by translating them into learning stories with AI-generated\nfeedback. We position storytelling as an integrative approach to design that\nconnects resource curation, reflective and sensemaking practice, and narrative\npractices learners already use across social platforms. We recruited 15\ninformal programming learners who are regular social media users to engage with\nthe system in a self-paced manner; participation concluded upon submitting a\nlearning story and survey. We used three quantitative scales and a qualitative\nsurvey to examine users' characteristics and perceptions of the system's\nsupport for their self-regulation. User feedback suggests the system's\nviability as a self-regulation aid. Learners particularly valued in-situ\nreflection, automated story feedback, and video annotation, while other\nfeatures received mixed views. We highlight perceived benefits, friction\npoints, and design opportunities for future AI-augmented self-regulation tools.",
      "pdf_url": "http://arxiv.org/pdf/2507.22671v1",
      "published": "2025-07-30T13:30:04+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.22671v1",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY",
        "cs.SE",
        "H.5.2; H.5.4"
      ]
    },
    {
      "title": "RobEthiChor: Automated Context-aware Ethics-based Negotiation for Autonomous Robots",
      "authors": [
        "Mashal Afzal Memon",
        "Gianluca Filippone",
        "Gian Luca Scoccia",
        "Marco Autili",
        "Paola Inverardi"
      ],
      "abstract": "The presence of autonomous systems is growing at a fast pace and it is\nimpacting many aspects of our lives. Designed to learn and act independently,\nthese systems operate and perform decision-making without human intervention.\nHowever, they lack the ability to incorporate users' ethical preferences, which\nare unique for each individual in society and are required to personalize the\ndecision-making processes. This reduces user trust and prevents autonomous\nsystems from behaving according to the moral beliefs of their end-users. When\nmultiple systems interact with differing ethical preferences, they must\nnegotiate to reach an agreement that satisfies the ethical beliefs of all the\nparties involved and adjust their behavior consequently. To address this\nchallenge, this paper proposes RobEthiChor, an approach that enables autonomous\nsystems to incorporate user ethical preferences and contextual factors into\ntheir decision-making through ethics-based negotiation. RobEthiChor features a\ndomain-agnostic reference architecture for designing autonomous systems capable\nof ethic-based negotiating. The paper also presents RobEthiChor-Ros, an\nimplementation of RobEthiChor within the Robot Operating System (ROS), which\ncan be deployed on robots to provide them with ethics-based negotiation\ncapabilities. To evaluate our approach, we deployed RobEthiChor-Ros on real\nrobots and ran scenarios where a pair of robots negotiate upon resource\ncontention. Experimental results demonstrate the feasibility and effectiveness\nof the system in realizing ethics-based negotiation. RobEthiChor allowed robots\nto reach an agreement in more than 73\\% of the scenarios with an acceptable\nnegotiation time (0.67s on average). Experiments also demonstrate that the\nnegotiation approach implemented in RobEthiChor is scalable.",
      "pdf_url": "http://arxiv.org/pdf/2507.22664v1",
      "published": "2025-07-30T13:21:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.22664v1",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "A Systematic Literature Review on Detecting Software Vulnerabilities with Large Language Models",
      "authors": [
        "Sabrina Kaniewski",
        "Fabian Schmidt",
        "Markus Enzweiler",
        "Michael Menth",
        "Tobias Heer"
      ],
      "abstract": "The increasing adoption of Large Language Models (LLMs) in software\nengineering has sparked interest in their use for software vulnerability\ndetection. However, the rapid development of this field has resulted in a\nfragmented research landscape, with diverse studies that are difficult to\ncompare due to differences in, e.g., system designs and dataset usage. This\nfragmentation makes it difficult to obtain a clear overview of the\nstate-of-the-art or compare and categorize studies meaningfully. In this work,\nwe present a comprehensive systematic literature review (SLR) of LLM-based\nsoftware vulnerability detection. We analyze 227 studies published between\nJanuary 2020 and June 2025, categorizing them by task formulation, input\nrepresentation, system architecture, and adaptation techniques. Further, we\nanalyze the datasets used, including their characteristics, vulnerability\ncoverage, and diversity. We present a fine-grained taxonomy of vulnerability\ndetection approaches, identify key limitations, and outline actionable future\nresearch opportunities. By providing a structured overview of the field, this\nreview improves transparency and serves as a practical guide for researchers\nand practitioners aiming to conduct more comparable and reproducible research.\nWe publicly release all artifacts and maintain a living repository of LLM-based\nsoftware vulnerability detection studies.",
      "pdf_url": "http://arxiv.org/pdf/2507.22659v1",
      "published": "2025-07-30T13:17:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.22659v1",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "Safe Deployment of Offline Reinforcement Learning via Input Convex Action Correction",
      "authors": [
        "Alex Durkin",
        "Jasper Stolte",
        "Matthew Jones",
        "Raghuraman Pitchumani",
        "Bei Li",
        "Christian Michler",
        "Mehmet Mercangöz"
      ],
      "abstract": "Offline reinforcement learning (offline RL) offers a promising framework for\ndeveloping control strategies in chemical process systems using historical\ndata, without the risks or costs of online experimentation. This work\ninvestigates the application of offline RL to the safe and efficient control of\nan exothermic polymerisation continuous stirred-tank reactor. We introduce a\nGymnasium-compatible simulation environment that captures the reactor's\nnonlinear dynamics, including reaction kinetics, energy balances, and\noperational constraints. The environment supports three industrially relevant\nscenarios: startup, grade change down, and grade change up. It also includes\nreproducible offline datasets generated from proportional-integral controllers\nwith randomised tunings, providing a benchmark for evaluating offline RL\nalgorithms in realistic process control tasks.\n  We assess behaviour cloning and implicit Q-learning as baseline algorithms,\nhighlighting the challenges offline agents face, including steady-state offsets\nand degraded performance near setpoints. To address these issues, we propose a\nnovel deployment-time safety layer that performs gradient-based action\ncorrection using input convex neural networks (PICNNs) as learned cost models.\nThe PICNN enables real-time, differentiable correction of policy actions by\ndescending a convex, state-conditioned cost surface, without requiring\nretraining or environment interaction.\n  Experimental results show that offline RL, particularly when combined with\nconvex action correction, can outperform traditional control approaches and\nmaintain stability across all scenarios. These findings demonstrate the\nfeasibility of integrating offline RL with interpretable and safety-aware\ncorrections for high-stakes chemical process control, and lay the groundwork\nfor more reliable data-driven automation in industrial systems.",
      "pdf_url": "http://arxiv.org/pdf/2507.22640v1",
      "published": "2025-07-30T12:58:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.22640v1",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "stat.ML"
      ]
    },
    {
      "title": "H2Tune: Federated Foundation Model Fine-Tuning with Hybrid Heterogeneity",
      "authors": [
        "Wei Guo",
        "Siyuan Lu",
        "Yiqi Tong",
        "Zhaojun Hu",
        "Fuzhen Zhuang",
        "Xiao Zhang",
        "Tao Fan",
        "Jin Dong"
      ],
      "abstract": "Different from existing federated fine-tuning (FFT) methods for foundation\nmodels, hybrid heterogeneous federated fine-tuning (HHFFT) is an under-explored\nscenario where clients exhibit double heterogeneity in model architectures and\ndownstream tasks. This hybrid heterogeneity introduces two significant\nchallenges: 1) heterogeneous matrix aggregation, where clients adopt different\nlarge-scale foundation models based on their task requirements and resource\nlimitations, leading to dimensional mismatches during LoRA parameter\naggregation; and 2) multi-task knowledge interference, where local shared\nparameters, trained with both task-shared and task-specific knowledge, cannot\nensure only task-shared knowledge is transferred between clients. To address\nthese challenges, we propose H2Tune, a federated foundation model fine-tuning\nwith hybrid heterogeneity. Our framework H2Tune consists of three key\ncomponents: (i) sparsified triple matrix decomposition to align hidden\ndimensions across clients through constructing rank-consistent middle matrices,\nwith adaptive sparsification based on client resources; (ii) relation-guided\nmatrix layer alignment to handle heterogeneous layer structures and\nrepresentation capabilities; and (iii) alternating task-knowledge\ndisentanglement mechanism to decouple shared and specific knowledge of local\nmodel parameters through alternating optimization. Theoretical analysis proves\na convergence rate of O(1/\\sqrt{T}). Extensive experiments show our method\nachieves up to 15.4% accuracy improvement compared to state-of-the-art\nbaselines. Our code is available at\nhttps://anonymous.4open.science/r/H2Tune-1407.",
      "pdf_url": "http://arxiv.org/pdf/2507.22633v2",
      "published": "2025-07-30T12:53:18+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.22633v2",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "LOTS of Fashion! Multi-Conditioning for Image Generation via Sketch-Text Pairing",
      "authors": [
        "Federico Girella",
        "Davide Talon",
        "Ziyue Liu",
        "Zanxi Ruan",
        "Yiming Wang",
        "Marco Cristani"
      ],
      "abstract": "Fashion design is a complex creative process that blends visual and textual\nexpressions. Designers convey ideas through sketches, which define spatial\nstructure and design elements, and textual descriptions, capturing material,\ntexture, and stylistic details. In this paper, we present LOcalized Text and\nSketch for fashion image generation (LOTS), an approach for compositional\nsketch-text based generation of complete fashion outlooks. LOTS leverages a\nglobal description with paired localized sketch + text information for\nconditioning and introduces a novel step-based merging strategy for diffusion\nadaptation. First, a Modularized Pair-Centric representation encodes sketches\nand text into a shared latent space while preserving independent localized\nfeatures; then, a Diffusion Pair Guidance phase integrates both local and\nglobal conditioning via attention-based guidance within the diffusion model's\nmulti-step denoising process. To validate our method, we build on Fashionpedia\nto release Sketchy, the first fashion dataset where multiple text-sketch pairs\nare provided per image. Quantitative results show LOTS achieves\nstate-of-the-art image generation performance on both global and localized\nmetrics, while qualitative examples and a human evaluation study highlight its\nunprecedented level of design customization.",
      "pdf_url": "http://arxiv.org/pdf/2507.22627v1",
      "published": "2025-07-30T12:48:29+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.22627v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Enhancing Manufacturing Knowledge Access with LLMs and Context-aware Prompting",
      "authors": [
        "Sebastian Monka",
        "Irlan Grangel-González",
        "Stefan Schmid",
        "Lavdim Halilaj",
        "Marc Rickart",
        "Oliver Rudolph",
        "Rui Dias"
      ],
      "abstract": "Knowledge graphs (KGs) have transformed data management within the\nmanufacturing industry, offering effective means for integrating disparate data\nsources through shared and structured conceptual schemas. However, harnessing\nthe power of KGs can be daunting for non-experts, as it often requires\nformulating complex SPARQL queries to retrieve specific information. With the\nadvent of Large Language Models (LLMs), there is a growing potential to\nautomatically translate natural language queries into the SPARQL format, thus\nbridging the gap between user-friendly interfaces and the sophisticated\narchitecture of KGs. The challenge remains in adequately informing LLMs about\nthe relevant context and structure of domain-specific KGs, e.g., in\nmanufacturing, to improve the accuracy of generated queries. In this paper, we\nevaluate multiple strategies that use LLMs as mediators to facilitate\ninformation retrieval from KGs. We focus on the manufacturing domain,\nparticularly on the Bosch Line Information System KG and the I40 Core\nInformation Model. In our evaluation, we compare various approaches for feeding\nrelevant context from the KG to the LLM and analyze their proficiency in\ntransforming real-world questions into SPARQL queries. Our findings show that\nLLMs can significantly improve their performance on generating correct and\ncomplete queries when provided only the adequate context of the KG schema. Such\ncontext-aware prompting techniques help LLMs to focus on the relevant parts of\nthe ontology and reduce the risk of hallucination. We anticipate that the\nproposed techniques help LLMs to democratize access to complex data\nrepositories and empower informed decision-making in manufacturing settings.",
      "pdf_url": "http://arxiv.org/pdf/2507.22619v1",
      "published": "2025-07-30T12:39:01+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.22619v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Adaptive Duration Model for Text Speech Alignment",
      "authors": [
        "Junjie Cao"
      ],
      "abstract": "Speech-to-text alignment is a critical component of neural text to-speech\n(TTS) models. Autoregressive TTS models typically use an attention mechanism to\nlearn these alignments on-line. However, these alignments tend to be brittle\nand often fail to generalize to long utterances and out-of-domain text, leading\nto missing or repeating words. Most non-autoregressive end to-end TTS models\nrely on durations extracted from external sources, using additional duration\nmodels for alignment. In this paper, we propose a novel duration prediction\nframework that can give compromising phoneme-level duration distribution with\ngiven text. In our experiments, the proposed duration model has more precise\nprediction and condition adaptation ability compared to previous baseline\nmodels. Numerically, it has roughly a 11.3 percents immprovement on alignment\naccuracy, and makes the performance of zero-shot TTS models more robust to the\nmismatch between prompt audio and input audio.",
      "pdf_url": "http://arxiv.org/pdf/2507.22612v1",
      "published": "2025-07-30T12:31:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.22612v1",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ]
    },
    {
      "title": "Metamorphic Testing of Deep Code Models: A Systematic Literature Review",
      "authors": [
        "Ali Asgari",
        "Milan de Koning",
        "Pouria Derakhshanfar",
        "Annibale Panichella"
      ],
      "abstract": "Large language models and deep learning models designed for code intelligence\nhave revolutionized the software engineering field due to their ability to\nperform various code-related tasks. These models can process source code and\nsoftware artifacts with high accuracy in tasks such as code completion, defect\ndetection, and code summarization; therefore, they can potentially become an\nintegral part of modern software engineering practices. Despite these\ncapabilities, robustness remains a critical quality attribute for deep-code\nmodels as they may produce different results under varied and adversarial\nconditions (e.g., variable renaming). Metamorphic testing has become a widely\nused approach to evaluate models' robustness by applying semantic-preserving\ntransformations to input programs and analyzing the stability of model outputs.\nWhile prior research has explored testing deep learning models, this systematic\nliterature review focuses specifically on metamorphic testing for deep code\nmodels. By studying 45 primary papers, we analyze the transformations,\ntechniques, and evaluation methods used to assess robustness. Our review\nsummarizes the current landscape, identifying frequently evaluated models,\nprogramming tasks, datasets, target languages, and evaluation metrics, and\nhighlights key challenges and future directions for advancing the field.",
      "pdf_url": "http://arxiv.org/pdf/2507.22610v1",
      "published": "2025-07-30T12:25:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.22610v1",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "VL-Cogito: Progressive Curriculum Reinforcement Learning for Advanced Multimodal Reasoning",
      "authors": [
        "Ruifeng Yuan",
        "Chenghao Xiao",
        "Sicong Leng",
        "Jianyu Wang",
        "Long Li",
        "Weiwen Xu",
        "Hou Pong Chan",
        "Deli Zhao",
        "Tingyang Xu",
        "Zhongyu Wei",
        "Hao Zhang",
        "Yu Rong"
      ],
      "abstract": "Reinforcement learning has proven its effectiveness in enhancing the\nreasoning capabilities of large language models. Recent research efforts have\nprogressively extended this paradigm to multimodal reasoning tasks. Due to the\ninherent complexity and diversity of multimodal tasks, especially in semantic\ncontent and problem formulations, existing models often exhibit unstable\nperformance across various domains and difficulty levels. To address these\nlimitations, we propose VL-Cogito, an advanced multimodal reasoning model\ntrained via a novel multi-stage Progressive Curriculum Reinforcement Learning\n(PCuRL) framework. PCuRL systematically guides the model through tasks of\ngradually increasing difficulty, substantially improving its reasoning\nabilities across diverse multimodal contexts. The framework introduces two key\ninnovations: (1) an online difficulty soft weighting mechanism, dynamically\nadjusting training difficulty across successive RL training stages; and (2) a\ndynamic length reward mechanism, which encourages the model to adaptively\nregulate its reasoning path length according to task complexity, thus balancing\nreasoning efficiency with correctness. Experimental evaluations demonstrate\nthat VL-Cogito consistently matches or surpasses existing reasoning-oriented\nmodels across mainstream multimodal benchmarks spanning mathematics, science,\nlogic, and general understanding, validating the effectiveness of our approach.",
      "pdf_url": "http://arxiv.org/pdf/2507.22607v2",
      "published": "2025-07-30T12:23:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.22607v2",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "MetaAgent: Automatically Constructing Multi-Agent Systems Based on Finite State Machines",
      "authors": [
        "Yaolun Zhang",
        "Xiaogeng Liu",
        "Chaowei Xiao"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated the ability to solve a wide\nrange of practical tasks within multi-agent systems. However, existing\nhuman-designed multi-agent frameworks are typically limited to a small set of\npre-defined scenarios, while current automated design methods suffer from\nseveral limitations, such as the lack of tool integration, dependence on\nexternal training data, and rigid communication structures. In this paper, we\npropose MetaAgent, a finite state machine based framework that can\nautomatically generate a multi-agent system. Given a task description,\nMetaAgent will design a multi-agent system and polish it through an\noptimization algorithm. When the multi-agent system is deployed, the finite\nstate machine will control the agent's actions and the state transitions. To\nevaluate our framework, we conduct experiments on both text-based tasks and\npractical tasks. The results indicate that the generated multi-agent system\nsurpasses other auto-designed methods and can achieve a comparable performance\nwith the human-designed multi-agent system, which is optimized for those\nspecific tasks.",
      "pdf_url": "http://arxiv.org/pdf/2507.22606v1",
      "published": "2025-07-30T12:22:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.22606v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "BALSAM: A Platform for Benchmarking Arabic Large Language Models",
      "authors": [
        "Rawan Al-Matham",
        "Kareem Darwish",
        "Raghad Al-Rasheed",
        "Waad Alshammari",
        "Muneera Alhoshan",
        "Amal Almazrua",
        "Asma Al Wazrah",
        "Mais Alheraki",
        "Firoj Alam",
        "Preslav Nakov",
        "Norah Alzahrani",
        "Eman alBilali",
        "Nizar Habash",
        "Abdelrahman El-Sheikh",
        "Muhammad Elmallah",
        "Haonan Li",
        "Hamdy Mubarak",
        "Mohamed Anwar",
        "Zaid Alyafeai",
        "Ahmed Abdelali",
        "Nora Altwairesh",
        "Maram Hasanain",
        "Abdulmohsen Al Thubaity",
        "Shady Shehata",
        "Bashar Alhafni",
        "Injy Hamed",
        "Go Inoue",
        "Khalid Elmadani",
        "Ossama Obeid",
        "Fatima Haouari",
        "Tamer Elsayed",
        "Emad Alghamdi",
        "Khalid Almubarak",
        "Saied Alshahrani",
        "Ola Aljarrah",
        "Safa Alajlan",
        "Areej Alshaqarawi",
        "Maryam Alshihri",
        "Sultana Alghurabi",
        "Atikah Alzeghayer",
        "Afrah Altamimi",
        "Abdullah Alfaifi",
        "Abdulrahman AlOsaimy"
      ],
      "abstract": "The impressive advancement of Large Language Models (LLMs) in English has not\nbeen matched across all languages. In particular, LLM performance in Arabic\nlags behind, due to data scarcity, linguistic diversity of Arabic and its\ndialects, morphological complexity, etc. Progress is further hindered by the\nquality of Arabic benchmarks, which typically rely on static, publicly\navailable data, lack comprehensive task coverage, or do not provide dedicated\nplatforms with blind test sets. This makes it challenging to measure actual\nprogress and to mitigate data contamination. Here, we aim to bridge these gaps.\nIn particular, we introduce BALSAM, a comprehensive, community-driven benchmark\naimed at advancing Arabic LLM development and evaluation. It includes 78 NLP\ntasks from 14 broad categories, with 52K examples divided into 37K test and 15K\ndevelopment, and a centralized, transparent platform for blind evaluation. We\nenvision BALSAM as a unifying platform that sets standards and promotes\ncollaborative research to advance Arabic LLM capabilities.",
      "pdf_url": "http://arxiv.org/pdf/2507.22603v1",
      "published": "2025-07-30T12:16:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.22603v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "RePaCA: Leveraging Reasoning Large Language Models for Static Automated Patch Correctness Assessment",
      "authors": [
        "Marcos Fuster-Pena",
        "David de-Fitero-Dominguez",
        "Antonio Garcia-Cabot",
        "Eva Garcia-Lopez"
      ],
      "abstract": "Automated Program Repair (APR) seeks to automatically correct software bugs\nwithout requiring human intervention. However, existing tools tend to generate\npatches that satisfy test cases without fixing the underlying bug, those are\nknown as overfitting patches. To address this issue, Automated Patch\nCorrectness Assessment (APCA) attempts to identify overfitting patches\ngenerated by APR tools. It can be solved as a static approach, meaning that no\nadditional information is needed beyond the original and fixed code snippets.\nCurrent static techniques often struggle with reliability, flexibility and\ntransparency. To address these issues, we introduce RePaCA, a novel static APCA\ntechnique that leverages Large Language Models (LLMs) specialized in thinking\ntasks. Our model is prompted with both buggy and fixed code snippets and guided\nto generate a Chain of Thought that analyses code differences, reasons about\nhow the patch addresses the root cause, and ultimately provides a binary\nclassification: correct or overfitting. To enhance these reasoning capabilities\nfor the APCA task specifically, the LLM is finetuned using Reinforcement\nLearning with the Group Relative Policy Optimization algorithm. When evaluated\non a standard Defects4J-derived test, our approach achieves state-of-the-art\nperformance, with 83.1% accuracy and an 84.8% F1-score. Furthermore, our model\ndemonstrates superior generalization capabilities when trained on different\ndatasets, outperforming the leading technique. This reasoning capability also\nprovides enhanced explainability for the patch assessment. These findings\nunderscore the considerable promise of finetuned, reasoning LLMs to advance\nstatic APCA by enhancing accuracy, generalization, and explainability.",
      "pdf_url": "http://arxiv.org/pdf/2507.22580v1",
      "published": "2025-07-30T11:21:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.22580v1",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "A Mean-Field Theory of $Θ$-Expectations",
      "authors": [
        "Qian Qi"
      ],
      "abstract": "The canonical theory of sublinear expectations, a foundation of stochastic\ncalculus under ambiguity, is insensitive to the non-convex geometry of\nprimitive uncertainty models. This paper develops a new stochastic calculus for\na structured class of such non-convex models. We introduce a class of fully\ncoupled Mean-Field Forward-Backward Stochastic Differential Equations where the\nBSDE driver is defined by a pointwise maximization over a law-dependent,\nnon-convex set. Mathematical tractability is achieved via a uniform strong\nconcavity assumption on the driver with respect to the control variable, which\nensures the optimization admits a unique and stable solution. A central\ncontribution is to establish the Lipschitz stability of this optimizer from\nprimitive geometric and regularity conditions, which underpins the entire\nwell-posedness theory. We prove local and global well-posedness theorems for\nthe FBSDE system. The resulting valuation functional, the $\\Theta$-Expectation,\nis shown to be dynamically consistent and, most critically, to violate the\naxiom of sub-additivity. This, along with its failure to be translation\ninvariant, demonstrates its fundamental departure from the convex paradigm.\nThis work provides a rigorous foundation for stochastic calculus under a class\nof non-convex, endogenous ambiguity.",
      "pdf_url": "http://arxiv.org/pdf/2507.22577v1",
      "published": "2025-07-30T11:08:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.22577v1",
      "categories": [
        "math.PR",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "COOkeD: Ensemble-based OOD detection in the era of zero-shot CLIP",
      "authors": [
        "Galadrielle Humblot-Renaux",
        "Gianni Franchi",
        "Sergio Escalera",
        "Thomas B. Moeslund"
      ],
      "abstract": "Out-of-distribution (OOD) detection is an important building block in\ntrustworthy image recognition systems as unknown classes may arise at\ntest-time. OOD detection methods typically revolve around a single classifier,\nleading to a split in the research field between the classical supervised\nsetting (e.g. ResNet18 classifier trained on CIFAR100) vs. the zero-shot\nsetting (class names fed as prompts to CLIP). In both cases, an overarching\nchallenge is that the OOD detection performance is implicitly constrained by\nthe classifier's capabilities on in-distribution (ID) data. In this work, we\nshow that given a little open-mindedness from both ends, remarkable OOD\ndetection can be achieved by instead creating a heterogeneous ensemble - COOkeD\ncombines the predictions of a closed-world classifier trained end-to-end on a\nspecific dataset, a zero-shot CLIP classifier, and a linear probe classifier\ntrained on CLIP image features. While bulky at first sight, this approach is\nmodular, post-hoc and leverages the availability of pre-trained VLMs, thus\nintroduces little overhead compared to training a single standard classifier.\nWe evaluate COOkeD on popular CIFAR100 and ImageNet benchmarks, but also\nconsider more challenging, realistic settings ranging from training-time label\nnoise, to test-time covariate shift, to zero-shot shift which has been\npreviously overlooked. Despite its simplicity, COOkeD achieves state-of-the-art\nperformance and greater robustness compared to both classical and CLIP-based\nOOD detection methods. Code is available at https://github.com/glhr/COOkeD",
      "pdf_url": "http://arxiv.org/pdf/2507.22576v1",
      "published": "2025-07-30T11:02:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.22576v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Explaining Deep Network Classification of Matrices: A Case Study on Monotonicity",
      "authors": [
        "Leandro Farina",
        "Sergey Korotov"
      ],
      "abstract": "This work demonstrates a methodology for using deep learning to discover\nsimple, practical criteria for classifying matrices based on abstract algebraic\nproperties. By combining a high-performance neural network with explainable AI\n(XAI) techniques, we can distill a model's learned strategy into\nhuman-interpretable rules. We apply this approach to the challenging case of\nmonotone matrices, defined by the condition that their inverses are entrywise\nnonnegative. Despite their simple definition, an easy characterization in terms\nof the matrix elements or the derived parameters is not known. Here, we\npresent, to the best of our knowledge, the first systematic machine-learning\napproach for deriving a practical criterion that distinguishes monotone from\nnon-monotone matrices. After establishing a labelled dataset by randomly\ngenerated monotone and non-monotone matrices uniformly on $(-1,1)$, we employ\ndeep neural network algorithms for classifying the matrices as monotone or\nnon-monotone, using both their entries and a comprehensive set of matrix\nfeatures. By saliency methods, such as integrated gradients, we identify among\nall features, two matrix parameters which alone provide sufficient information\nfor the matrix classification, with $95\\%$ accuracy, namely the absolute values\nof the two lowest-order coefficients, $c_0$ and $c_1$ of the matrix's\ncharacteristic polynomial. A data-driven study of 18,000 random $7\\times7$\nmatrices shows that the monotone class obeys $\\lvert c_{0}/c_{1}\\rvert\\le0.18$\nwith probability $>99.98\\%$; because $\\lvert c_{0}/c_{1}\\rvert =\n1/\\mathrm{tr}(A^{-1})$ for monotone $A$, this is equivalent to the simple bound\n$\\mathrm{tr}(A^{-1})\\ge5.7$.",
      "pdf_url": "http://arxiv.org/pdf/2507.22570v1",
      "published": "2025-07-30T10:55:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.22570v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NA",
        "math.NA",
        "15B48, 68T07, 15A18, 62G32",
        "I.2.6; I.5.2; G.1.3"
      ]
    },
    {
      "title": "Efficient Differentially Private Fine-Tuning of LLMs via Reinforcement Learning",
      "authors": [
        "Afshin Khadangi",
        "Amir Sartipi",
        "Igor Tchappi",
        "Ramin Bahmani",
        "Gilbert Fridgen"
      ],
      "abstract": "The tension between data privacy and model utility has become the defining\nbottleneck for the practical deployment of large language models (LLMs) trained\non sensitive corpora including healthcare. Differentially private stochastic\ngradient descent (DP-SGD) guarantees formal privacy, yet it does so at a\npronounced cost: gradients are forcibly clipped and perturbed with noise,\ndegrading sample efficiency and final accuracy. Numerous variants have been\nproposed to soften this trade-off, but they all share a handicap: their control\nknobs are hard-coded, global, and oblivious to the evolving optimization\nlandscape. Consequently, practitioners are forced either to over-spend privacy\nbudget in pursuit of utility, or to accept mediocre models in order to stay\nwithin privacy constraints. We present RLDP, the first framework to cast DP\noptimization itself as a closed-loop control problem amenable to modern deep\nreinforcement learning (RL). RLDP continuously senses rich statistics of the\nlearning dynamics and acts by selecting fine-grained per parameter\ngradient-clipping thresholds as well as the magnitude of injected Gaussian\nnoise. A soft actor-critic (SAC) hyper-policy is trained online during language\nmodel fine-tuning; it learns, from scratch, how to allocate the privacy budget\nwhere it matters and when it matters. Across more than 1,600 ablation\nexperiments on GPT2-small, Llama-1B, Llama-3B, and Mistral-7B, RLDP delivers\nperplexity reductions of 1.3-30.5% (mean 5.4%) and an average 5.6% downstream\nutility gain. RLDP reaches each baseline's final utility after only 13-43% of\nthe gradient-update budget (mean speed-up 71%), all while honoring the same\n($\\epsilon$, $\\delta$)-DP contract and exhibiting equal or lower susceptibility\nto membership-inference and canary-extraction attacks.",
      "pdf_url": "http://arxiv.org/pdf/2507.22565v1",
      "published": "2025-07-30T10:46:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.22565v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Exploiting Synergistic Cognitive Biases to Bypass Safety in LLMs",
      "authors": [
        "Xikang Yang",
        "Biyu Zhou",
        "Xuehai Tang",
        "Jizhong Han",
        "Songlin Hu"
      ],
      "abstract": "Large Language Models (LLMs) demonstrate impressive capabilities across a\nwide range of tasks, yet their safety mechanisms remain susceptible to\nadversarial attacks that exploit cognitive biases -- systematic deviations from\nrational judgment. Unlike prior jailbreaking approaches focused on prompt\nengineering or algorithmic manipulation, this work highlights the overlooked\npower of multi-bias interactions in undermining LLM safeguards. We propose\nCognitiveAttack, a novel red-teaming framework that systematically leverages\nboth individual and combined cognitive biases. By integrating supervised\nfine-tuning and reinforcement learning, CognitiveAttack generates prompts that\nembed optimized bias combinations, effectively bypassing safety protocols while\nmaintaining high attack success rates. Experimental results reveal significant\nvulnerabilities across 30 diverse LLMs, particularly in open-source models.\nCognitiveAttack achieves a substantially higher attack success rate compared to\nthe SOTA black-box method PAP (60.1% vs. 31.6%), exposing critical limitations\nin current defense mechanisms. These findings highlight multi-bias interactions\nas a powerful yet underexplored attack vector. This work introduces a novel\ninterdisciplinary perspective by bridging cognitive science and LLM safety,\npaving the way for more robust and human-aligned AI systems.",
      "pdf_url": "http://arxiv.org/pdf/2507.22564v1",
      "published": "2025-07-30T10:40:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.22564v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "aLLoyM: A large language model for alloy phase diagram prediction",
      "authors": [
        "Yuna Oikawa",
        "Guillaume Deffrennes",
        "Taichi Abe",
        "Ryo Tamura",
        "Koji Tsuda"
      ],
      "abstract": "Large Language Models (LLMs) are general-purpose tools with wide-ranging\napplications, including in materials science. In this work, we introduce\naLLoyM, a fine-tuned LLM specifically trained on alloy compositions,\ntemperatures, and their corresponding phase information. To develop aLLoyM, we\ncurated question-and-answer (Q&A) pairs for binary and ternary phase diagrams\nusing the open-source Computational Phase Diagram Database (CPDDB) and\nassessments based on CALPHAD (CALculation of PHAse Diagrams). We fine-tuned\nMistral, an open-source pre-trained LLM, for two distinct Q&A formats:\nmultiple-choice and short-answer. Benchmark evaluations demonstrate that\nfine-tuning substantially enhances performance on multiple-choice phase diagram\nquestions. Moreover, the short-answer model of aLLoyM exhibits the ability to\ngenerate novel phase diagrams from its components alone, underscoring its\npotential to accelerate the discovery of previously unexplored materials\nsystems. To promote further research and adoption, we have publicly released\nthe short-answer fine-tuned version of aLLoyM, along with the complete\nbenchmarking Q&A dataset, on Hugging Face.",
      "pdf_url": "http://arxiv.org/pdf/2507.22558v1",
      "published": "2025-07-30T10:32:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.22558v1",
      "categories": [
        "cond-mat.mtrl-sci",
        "cs.AI"
      ]
    },
    {
      "title": "RainbowPrompt: Diversity-Enhanced Prompt-Evolving for Continual Learning",
      "authors": [
        "Kiseong Hong",
        "Gyeong-hyeon Kim",
        "Eunwoo Kim"
      ],
      "abstract": "Prompt-based continual learning provides a rehearsal-free solution by tuning\nsmall sets of parameters while keeping pre-trained models frozen. To meet the\ncomplex demands of sequential tasks, it is crucial to integrate task-specific\nknowledge within prompts effectively. However, existing works rely on either\nfixed learned prompts (i.e., prompts whose representations remain unchanged\nduring new task learning) or on prompts generated from an entangled task-shared\nspace, limiting the representational diversity of the integrated prompt. To\naddress this issue, we propose a novel prompt-evolving mechanism to adaptively\naggregate base prompts (i.e., task-specific prompts) into a unified prompt\nwhile ensuring diversity. By transforming and aligning base prompts, both\npreviously learned and newly introduced, our approach continuously evolves\naccumulated knowledge to facilitate learning new tasks. We further introduce a\nlearnable probabilistic gate that adaptively determines which layers to\nactivate during the evolution process. We validate our method on image\nclassification and video action recognition tasks in class-incremental\nlearning, achieving average gains of 9.07% and 7.40% over existing methods\nacross all scenarios.",
      "pdf_url": "http://arxiv.org/pdf/2507.22553v1",
      "published": "2025-07-30T10:25:28+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.22553v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "A surrogate model for topology optimisation of elastic structures via parametric autoencoders",
      "authors": [
        "Matteo Giacomini",
        "Antonio Huerta"
      ],
      "abstract": "A surrogate-based topology optimisation algorithm for linear elastic\nstructures under parametric loads and boundary conditions is proposed. Instead\nof learning the parametric solution of the state (and adjoint) problems or the\noptimisation trajectory as a function of the iterations, the proposed approach\ndevises a surrogate version of the entire optimisation pipeline. First, the\nmethod predicts a quasi-optimal topology for a given problem configuration as a\nsurrogate model of high-fidelity topologies optimised with the homogenisation\nmethod. This is achieved by means of a feed-forward net learning the mapping\nbetween the input parameters characterising the system setup and a latent space\ndetermined by encoder/decoder blocks reducing the dimensionality of the\nparametric topology optimisation problem and reconstructing a high-dimensional\nrepresentation of the topology. Then, the predicted topology is used as an\neducated initial guess for a computationally efficient algorithm penalising the\nintermediate values of the design variable, while enforcing the governing\nequations of the system. This step allows the method to correct potential\nerrors introduced by the surrogate model, eliminate artifacts, and refine the\ndesign in order to produce topologies consistent with the underlying physics.\nDifferent architectures are proposed and the approximation and generalisation\ncapabilities of the resulting models are numerically evaluated. The\nquasi-optimal topologies allow to outperform the high-fidelity optimiser by\nreducing the average number of optimisation iterations by $53\\%$ while\nachieving discrepancies below $4\\%$ in the optimal value of the objective\nfunctional, even in the challenging scenario of testing the model to\nextrapolate beyond the training and validation domain.",
      "pdf_url": "http://arxiv.org/pdf/2507.22539v1",
      "published": "2025-07-30T10:07:42+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.22539v1",
      "categories": [
        "math.NA",
        "cs.AI",
        "cs.CE",
        "cs.LG",
        "cs.NA",
        "math.OC",
        "49M41, 74P05, 74P15, 74S05, 65M60, 65M30"
      ]
    },
    {
      "title": "CliCARE: Grounding Large Language Models in Clinical Guidelines for Decision Support over Longitudinal Cancer Electronic Health Records",
      "authors": [
        "Dongchen Li",
        "Jitao Liang",
        "Wei Li",
        "Xiaoyu Wang",
        "Longbing Cao",
        "Kun Yu"
      ],
      "abstract": "Large Language Models (LLMs) hold significant promise for improving clinical\ndecision support and reducing physician burnout by synthesizing complex,\nlongitudinal cancer Electronic Health Records (EHRs). However, their\nimplementation in this critical field faces three primary challenges: the\ninability to effectively process the extensive length and multilingual nature\nof patient records for accurate temporal analysis; a heightened risk of\nclinical hallucination, as conventional grounding techniques such as\nRetrieval-Augmented Generation (RAG) do not adequately incorporate\nprocess-oriented clinical guidelines; and unreliable evaluation metrics that\nhinder the validation of AI systems in oncology. To address these issues, we\npropose CliCARE, a framework for Grounding Large Language Models in Clinical\nGuidelines for Decision Support over Longitudinal Cancer Electronic Health\nRecords. The framework operates by transforming unstructured, longitudinal EHRs\ninto patient-specific Temporal Knowledge Graphs (TKGs) to capture long-range\ndependencies, and then grounding the decision support process by aligning these\nreal-world patient trajectories with a normative guideline knowledge graph.\nThis approach provides oncologists with evidence-grounded decision support by\ngenerating a high-fidelity clinical summary and an actionable recommendation.\nWe validated our framework using large-scale, longitudinal data from a private\nChinese cancer dataset and the public English MIMIC-IV dataset. In these\ndiverse settings, CliCARE significantly outperforms strong baselines, including\nleading long-context LLMs and Knowledge Graph-enhanced RAG methods. The\nclinical validity of our results is supported by a robust evaluation protocol,\nwhich demonstrates a high correlation with assessments made by expert\noncologists.",
      "pdf_url": "http://arxiv.org/pdf/2507.22533v1",
      "published": "2025-07-30T10:02:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.22533v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "HRVVS: A High-resolution Video Vasculature Segmentation Network via Hierarchical Autoregressive Residual Priors",
      "authors": [
        "Xincheng Yao",
        "Yijun Yang",
        "Kangwei Guo",
        "Ruiqiang Xiao",
        "Haipeng Zhou",
        "Haisu Tao",
        "Jian Yang",
        "Lei Zhu"
      ],
      "abstract": "The segmentation of the hepatic vasculature in surgical videos holds\nsubstantial clinical significance in the context of hepatectomy procedures.\nHowever, owing to the dearth of an appropriate dataset and the inherently\ncomplex task characteristics, few researches have been reported in this domain.\nTo address this issue, we first introduce a high quality frame-by-frame\nannotated hepatic vasculature dataset containing 35 long hepatectomy videos and\n11442 high-resolution frames. On this basis, we propose a novel high-resolution\nvideo vasculature segmentation network, dubbed as HRVVS. We innovatively embed\na pretrained visual autoregressive modeling (VAR) model into different layers\nof the hierarchical encoder as prior information to reduce the information\ndegradation generated during the downsampling process. In addition, we designed\na dynamic memory decoder on a multi-view segmentation network to minimize the\ntransmission of redundant information while preserving more details between\nframes. Extensive experiments on surgical video datasets demonstrate that our\nproposed HRVVS significantly outperforms the state-of-the-art methods. The\nsource code and dataset will be publicly available at\n\\{https://github.com/scott-yjyang/HRVVS}.",
      "pdf_url": "http://arxiv.org/pdf/2507.22530v2",
      "published": "2025-07-30T09:57:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.22530v2",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Accident-Driven Congestion Prediction and Simulation: An Explainable Framework Using Advanced Clustering and Bayesian Networks",
      "authors": [
        "Kranthi Kumar Talluri",
        "Galia Weidl",
        "Vaishnavi Kasuluru"
      ],
      "abstract": "Traffic congestion due to uncertainties, such as accidents, is a significant\nissue in urban areas, as the ripple effect of accidents causes longer delays,\nincreased emissions, and safety concerns. To address this issue, we propose a\nrobust framework for predicting the impact of accidents on congestion. We\nimplement Automated Machine Learning (AutoML)-enhanced Deep Embedding\nClustering (DEC) to assign congestion labels to accident data and predict\ncongestion probability using a Bayesian Network (BN). The Simulation of Urban\nMobility (SUMO) simulation is utilized to evaluate the correctness of BN\npredictions using evidence-based scenarios. Results demonstrate that the\nAutoML-enhanced DEC has outperformed traditional clustering approaches. The\nperformance of the proposed BN model achieved an overall accuracy of 95.6%,\nindicating its ability to understand the complex relationship of accidents\ncausing congestion. Validation in SUMO with evidence-based scenarios\ndemonstrated that the BN model's prediction of congestion states closely\nmatches those of SUMO, indicating the high reliability of the proposed BN model\nin ensuring smooth urban mobility.",
      "pdf_url": "http://arxiv.org/pdf/2507.22529v1",
      "published": "2025-07-30T09:57:08+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.22529v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Recognizing Actions from Robotic View for Natural Human-Robot Interaction",
      "authors": [
        "Ziyi Wang",
        "Peiming Li",
        "Hong Liu",
        "Zhichao Deng",
        "Can Wang",
        "Jun Liu",
        "Junsong Yuan",
        "Mengyuan Liu"
      ],
      "abstract": "Natural Human-Robot Interaction (N-HRI) requires robots to recognize human\nactions at varying distances and states, regardless of whether the robot itself\nis in motion or stationary. This setup is more flexible and practical than\nconventional human action recognition tasks. However, existing benchmarks\ndesigned for traditional action recognition fail to address the unique\ncomplexities in N-HRI due to limited data, modalities, task categories, and\ndiversity of subjects and environments. To address these challenges, we\nintroduce ACTIVE (Action from Robotic View), a large-scale dataset tailored\nspecifically for perception-centric robotic views prevalent in mobile service\nrobots. ACTIVE comprises 30 composite action categories, 80 participants, and\n46,868 annotated video instances, covering both RGB and point cloud modalities.\nParticipants performed various human actions in diverse environments at\ndistances ranging from 3m to 50m, while the camera platform was also mobile,\nsimulating real-world scenarios of robot perception with varying camera heights\ndue to uneven ground. This comprehensive and challenging benchmark aims to\nadvance action and attribute recognition research in N-HRI. Furthermore, we\npropose ACTIVE-PC, a method that accurately perceives human actions at long\ndistances using Multilevel Neighborhood Sampling, Layered Recognizers, Elastic\nEllipse Query, and precise decoupling of kinematic interference from human\nactions. Experimental results demonstrate the effectiveness of ACTIVE-PC. Our\ncode is available at:\nhttps://github.com/wangzy01/ACTIVE-Action-from-Robotic-View.",
      "pdf_url": "http://arxiv.org/pdf/2507.22522v1",
      "published": "2025-07-30T09:48:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.22522v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ]
    },
    {
      "title": "Collaborative Medical Triage under Uncertainty: A Multi-Agent Dynamic Matching Approach",
      "authors": [
        "Hongyan Cheng",
        "Chengzhang Yu",
        "Yanshu Shi",
        "Chiyue Wang",
        "Cong Liu",
        "Zhanpeng Jin"
      ],
      "abstract": "The post-pandemic surge in healthcare demand, coupled with critical nursing\nshortages, has placed unprecedented pressure on emergency department triage\nsystems, necessitating innovative AI-driven solutions. We present a multi-agent\ninteractive intelligent system for medical triage that addresses three\nfundamental challenges in current AI-based triage systems: insufficient medical\nspecialization leading to hallucination-induced misclassifications,\nheterogeneous department structures across healthcare institutions, and\ninefficient detail-oriented questioning that impedes rapid triage decisions.\nOur system employs three specialized agents - RecipientAgent, InquirerAgent,\nand DepartmentAgent - that collaborate through structured inquiry mechanisms\nand department-specific guidance rules to transform unstructured patient\nsymptoms into accurate department recommendations. To ensure robust evaluation,\nwe constructed a comprehensive Chinese medical triage dataset from a medical\nwebsite, comprising 3,360 real-world cases spanning 9 primary departments and\n62 secondary departments. Through systematic data imputation using large\nlanguage models, we address the prevalent issue of incomplete medical records\nin real-world data. Experimental results demonstrate that our multi-agent\nsystem achieves 89.2% accuracy in primary department classification and 73.9%\naccuracy in secondary department classification after four rounds of patient\ninteraction. The system's pattern-matching-based guidance mechanisms enable\nefficient adaptation to diverse hospital configurations while maintaining high\ntriage accuracy. Our work provides a scalable framework for deploying\nAI-assisted triage systems that can accommodate the organizational\nheterogeneity of healthcare institutions while ensuring clinically sound\ndecision-making.",
      "pdf_url": "http://arxiv.org/pdf/2507.22504v1",
      "published": "2025-07-30T09:21:59+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.22504v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "LoReUn: Data Itself Implicitly Provides Cues to Improve Machine Unlearning",
      "authors": [
        "Xiang Li",
        "Qianli Shen",
        "Haonan Wang",
        "Kenji Kawaguchi"
      ],
      "abstract": "Recent generative models face significant risks of producing harmful content,\nwhich has underscored the importance of machine unlearning (MU) as a critical\ntechnique for eliminating the influence of undesired data. However, existing MU\nmethods typically assign the same weight to all data to be forgotten, which\nmakes it difficult to effectively forget certain data that is harder to unlearn\nthan others. In this paper, we empirically demonstrate that the loss of data\nitself can implicitly reflect its varying difficulty. Building on this insight,\nwe introduce Loss-based Reweighting Unlearning (LoReUn), a simple yet effective\nplug-and-play strategy that dynamically reweights data during the unlearning\nprocess with minimal additional computational overhead. Our approach\nsignificantly reduces the gap between existing MU methods and exact unlearning\nin both image classification and generation tasks, effectively enhancing the\nprevention of harmful content generation in text-to-image diffusion models.",
      "pdf_url": "http://arxiv.org/pdf/2507.22499v1",
      "published": "2025-07-30T09:12:25+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.22499v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Robust Adverse Weather Removal via Spectral-based Spatial Grouping",
      "authors": [
        "Yuhwan Jeong",
        "Yunseo Yang",
        "Youngho Yoon",
        "Kuk-Jin Yoon"
      ],
      "abstract": "Adverse weather conditions cause diverse and complex degradation patterns,\ndriving the development of All-in-One (AiO) models. However, recent AiO\nsolutions still struggle to capture diverse degradations, since global\nfiltering methods like direct operations on the frequency domain fail to handle\nhighly variable and localized distortions. To address these issue, we propose\nSpectral-based Spatial Grouping Transformer (SSGformer), a novel approach that\nleverages spectral decomposition and group-wise attention for multi-weather\nimage restoration. SSGformer decomposes images into high-frequency edge\nfeatures using conventional edge detection and low-frequency information via\nSingular Value Decomposition. We utilize multi-head linear attention to\neffectively model the relationship between these features. The fused features\nare integrated with the input to generate a grouping-mask that clusters regions\nbased on the spatial similarity and image texture. To fully leverage this mask,\nwe introduce a group-wise attention mechanism, enabling robust adverse weather\nremoval and ensuring consistent performance across diverse weather conditions.\nWe also propose a Spatial Grouping Transformer Block that uses both channel\nattention and spatial attention, effectively balancing feature-wise\nrelationships and spatial dependencies. Extensive experiments show the\nsuperiority of our approach, validating its effectiveness in handling the\nvaried and intricate adverse weather degradations.",
      "pdf_url": "http://arxiv.org/pdf/2507.22498v2",
      "published": "2025-07-30T09:08:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.22498v2",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "LVM-GP: Uncertainty-Aware PDE Solver via coupling latent variable model and Gaussian process",
      "authors": [
        "Xiaodong Feng",
        "Ling Guo",
        "Xiaoliang Wan",
        "Hao Wu",
        "Tao Zhou",
        "Wenwen Zhou"
      ],
      "abstract": "We propose a novel probabilistic framework, termed LVM-GP, for uncertainty\nquantification in solving forward and inverse partial differential equations\n(PDEs) with noisy data. The core idea is to construct a stochastic mapping from\nthe input to a high-dimensional latent representation, enabling\nuncertainty-aware prediction of the solution. Specifically, the architecture\nconsists of a confidence-aware encoder and a probabilistic decoder. The encoder\nimplements a high-dimensional latent variable model based on a Gaussian process\n(LVM-GP), where the latent representation is constructed by interpolating\nbetween a learnable deterministic feature and a Gaussian process prior, with\nthe interpolation strength adaptively controlled by a confidence function\nlearned from data. The decoder defines a conditional Gaussian distribution over\nthe solution field, where the mean is predicted by a neural operator applied to\nthe latent representation, allowing the model to learn flexible\nfunction-to-function mapping. Moreover, physical laws are enforced as soft\nconstraints in the loss function to ensure consistency with the underlying PDE\nstructure. Compared to existing approaches such as Bayesian physics-informed\nneural networks (B-PINNs) and deep ensembles, the proposed framework can\nefficiently capture functional dependencies via merging a latent Gaussian\nprocess and neural operator, resulting in competitive predictive accuracy and\nrobust uncertainty quantification. Numerical experiments demonstrate the\neffectiveness and reliability of the method.",
      "pdf_url": "http://arxiv.org/pdf/2507.22493v1",
      "published": "2025-07-30T09:00:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.22493v1",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Proto-EVFL: Enhanced Vertical Federated Learning via Dual Prototype with Extremely Unaligned Data",
      "authors": [
        "Wei Guo",
        "Yiyang Duan",
        "Zhaojun Hu",
        "Yiqi Tong",
        "Fuzhen Zhuang",
        "Xiao Zhang",
        "Jin Dong",
        "Ruofan Wu",
        "Tengfei Liu",
        "Yifan Sun"
      ],
      "abstract": "In vertical federated learning (VFL), multiple enterprises address aligned\nsample scarcity by leveraging massive locally unaligned samples to facilitate\ncollaborative learning. However, unaligned samples across different parties in\nVFL can be extremely class-imbalanced, leading to insufficient feature\nrepresentation and limited model prediction space. Specifically,\nclass-imbalanced problems consist of intra-party class imbalance and\ninter-party class imbalance, which can further cause local model bias and\nfeature contribution inconsistency issues, respectively. To address the above\nchallenges, we propose Proto-EVFL, an enhanced VFL framework via dual\nprototypes. We first introduce class prototypes for each party to learn\nrelationships between classes in the latent space, allowing the active party to\npredict unseen classes. We further design a probabilistic dual prototype\nlearning scheme to dynamically select unaligned samples by conditional optimal\ntransport cost with class prior probability. Moreover, a mixed prior guided\nmodule guides this selection process by combining local and global class prior\nprobabilities. Finally, we adopt an \\textit{adaptive gated feature aggregation\nstrategy} to mitigate feature contribution inconsistency by dynamically\nweighting and aggregating local features across different parties. We proved\nthat Proto-EVFL, as the first bi-level optimization framework in VFL, has a\nconvergence rate of 1/\\sqrt T. Extensive experiments on various datasets\nvalidate the superiority of our Proto-EVFL. Even in a zero-shot scenario with\none unseen class, it outperforms baselines by at least 6.97%",
      "pdf_url": "http://arxiv.org/pdf/2507.22488v1",
      "published": "2025-07-30T08:48:33+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.22488v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    }
  ]
}