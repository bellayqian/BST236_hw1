{
  "last_updated": "2025-06-12T00:53:03.148967",
  "papers": [
    {
      "title": "ALE-Bench: A Benchmark for Long-Horizon Objective-Driven Algorithm Engineering",
      "authors": [
        "Yuki Imajuku",
        "Kohki Horie",
        "Yoichi Iwata",
        "Kensho Aoki",
        "Naohiro Takahashi",
        "Takuya Akiba"
      ],
      "abstract": "How well do AI systems perform in algorithm engineering for hard optimization\nproblems in domains such as package-delivery routing, crew scheduling, factory\nproduction planning, and power-grid balancing? We introduce ALE-Bench, a new\nbenchmark for evaluating AI systems on score-based algorithmic programming\ncontests. Drawing on real tasks from the AtCoder Heuristic Contests, ALE-Bench\npresents optimization problems that are computationally hard and admit no known\nexact solution. Unlike short-duration, pass/fail coding benchmarks, ALE-Bench\nencourages iterative solution refinement over long time horizons. Our software\nframework supports interactive agent architectures that leverage test-run\nfeedback and visualizations. Our evaluation of frontier LLMs revealed that\nwhile they demonstrate high performance on specific problems, a notable gap\nremains compared to humans in terms of consistency across problems and\nlong-horizon problem-solving capabilities. This highlights the need for this\nbenchmark to foster future AI advancements.",
      "pdf_url": "http://arxiv.org/pdf/2506.09050v1",
      "published": "2025-06-10T17:59:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.09050v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "VIKI-R: Coordinating Embodied Multi-Agent Cooperation via Reinforcement Learning",
      "authors": [
        "Li Kang",
        "Xiufeng Song",
        "Heng Zhou",
        "Yiran Qin",
        "Jie Yang",
        "Xiaohong Liu",
        "Philip Torr",
        "Lei Bai",
        "Zhenfei Yin"
      ],
      "abstract": "Coordinating multiple embodied agents in dynamic environments remains a core\nchallenge in artificial intelligence, requiring both perception-driven\nreasoning and scalable cooperation strategies. While recent works have\nleveraged large language models (LLMs) for multi-agent planning, a few have\nbegun to explore vision-language models (VLMs) for visual reasoning. However,\nthese VLM-based approaches remain limited in their support for diverse\nembodiment types. In this work, we introduce VIKI-Bench, the first hierarchical\nbenchmark tailored for embodied multi-agent cooperation, featuring three\nstructured levels: agent activation, task planning, and trajectory perception.\nVIKI-Bench includes diverse robot embodiments, multi-view visual observations,\nand structured supervision signals to evaluate reasoning grounded in visual\ninputs. To demonstrate the utility of VIKI-Bench, we propose VIKI-R, a\ntwo-stage framework that fine-tunes a pretrained vision-language model (VLM)\nusing Chain-of-Thought annotated demonstrations, followed by reinforcement\nlearning under multi-level reward signals. Our extensive experiments show that\nVIKI-R significantly outperforms baselines method across all task levels.\nFurthermore, we show that reinforcement learning enables the emergence of\ncompositional cooperation patterns among heterogeneous agents. Together,\nVIKI-Bench and VIKI-R offer a unified testbed and method for advancing\nmulti-agent, visual-driven cooperation in embodied AI systems.",
      "pdf_url": "http://arxiv.org/pdf/2506.09049v1",
      "published": "2025-06-10T17:59:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.09049v1",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.RO"
      ]
    },
    {
      "title": "Agentic Neural Networks: Self-Evolving Multi-Agent Systems via Textual Backpropagation",
      "authors": [
        "Xiaowen Ma",
        "Chenyang Lin",
        "Yao Zhang",
        "Volker Tresp",
        "Yunpu Ma"
      ],
      "abstract": "Leveraging multiple Large Language Models(LLMs) has proven effective for\naddressing complex, high-dimensional tasks, but current approaches often rely\non static, manually engineered multi-agent configurations. To overcome these\nconstraints, we present the Agentic Neural Network(ANN), a framework that\nconceptualizes multi-agent collaboration as a layered neural network\narchitecture. In this design, each agent operates as a node, and each layer\nforms a cooperative \"team\" focused on a specific subtask. Agentic Neural\nNetwork follows a two-phase optimization strategy: (1) Forward Phase-Drawing\ninspiration from neural network forward passes, tasks are dynamically\ndecomposed into subtasks, and cooperative agent teams with suitable aggregation\nmethods are constructed layer by layer. (2) Backward Phase-Mirroring\nbackpropagation, we refine both global and local collaboration through\niterative feedback, allowing agents to self-evolve their roles, prompts, and\ncoordination. This neuro-symbolic approach enables ANN to create new or\nspecialized agent teams post-training, delivering notable gains in accuracy and\nadaptability. Across four benchmark datasets, ANN surpasses leading multi-agent\nbaselines under the same configurations, showing consistent performance\nimprovements. Our findings indicate that ANN provides a scalable, data-driven\nframework for multi-agent systems, combining the collaborative capabilities of\nLLMs with the efficiency and flexibility of neural network principles. We plan\nto open-source the entire framework.",
      "pdf_url": "http://arxiv.org/pdf/2506.09046v1",
      "published": "2025-06-10T17:59:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.09046v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ]
    },
    {
      "title": "Autoregressive Semantic Visual Reconstruction Helps VLMs Understand Better",
      "authors": [
        "Dianyi Wang",
        "Wei Song",
        "Yikun Wang",
        "Siyuan Wang",
        "Kaicheng Yu",
        "Zhongyu Wei",
        "Jiaqi Wang"
      ],
      "abstract": "Typical large vision-language models (LVLMs) apply autoregressive supervision\nsolely to textual sequences, without fully incorporating the visual modality\ninto the learning process. This results in three key limitations: (1) an\ninability to utilize images without accompanying captions, (2) the risk that\ncaptions omit critical visual details, and (3) the challenge that certain\nvision-centric content cannot be adequately conveyed through text. As a result,\ncurrent LVLMs often prioritize vision-to-language alignment while potentially\noverlooking fine-grained visual information. While some prior works have\nexplored autoregressive image generation, effectively leveraging autoregressive\nvisual supervision to enhance image understanding remains an open challenge. In\nthis paper, we introduce Autoregressive Semantic Visual Reconstruction (ASVR),\nwhich enables joint learning of visual and textual modalities within a unified\nautoregressive framework. We show that autoregressively reconstructing the raw\nvisual appearance of images does not enhance and may even impair multimodal\nunderstanding. In contrast, autoregressively reconstructing the semantic\nrepresentation of images consistently improves comprehension. Notably, we find\nthat even when models are given continuous image features as input, they can\neffectively reconstruct discrete semantic tokens, resulting in stable and\nconsistent improvements across a wide range of multimodal understanding\nbenchmarks. Our approach delivers significant performance gains across varying\ndata scales (556k-2M) and types of LLM bacbones. Specifically, ASVR improves\nLLaVA-1.5 by 5% in average scores across 14 multimodal benchmarks. The code is\navailable at https://github.com/AlenjandroWang/ASVR.",
      "pdf_url": "http://arxiv.org/pdf/2506.09040v1",
      "published": "2025-06-10T17:57:50+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.09040v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "AbstentionBench: Reasoning LLMs Fail on Unanswerable Questions",
      "authors": [
        "Polina Kirichenko",
        "Mark Ibrahim",
        "Kamalika Chaudhuri",
        "Samuel J. Bell"
      ],
      "abstract": "For Large Language Models (LLMs) to be reliably deployed in both everyday and\nhigh-stakes domains, knowing when not to answer is equally critical as\nanswering correctly. Real-world user queries, which can be underspecified,\nill-posed, or fundamentally unanswerable, require LLMs to reason about\nuncertainty and selectively abstain -- i.e., refuse to answer definitively.\nHowever, abstention remains understudied, without a systematic evaluation\nframework for modern LLMs. In this work, we introduce AbstentionBench, a\nlarge-scale benchmark for holistically evaluating abstention across 20 diverse\ndatasets, including questions with unknown answers, underspecification, false\npremises, subjective interpretations, and outdated information. Evaluating 20\nfrontier LLMs reveals abstention is an unsolved problem, and one where scaling\nmodels is of little use. While recent reasoning LLMs have shown impressive\nresults in complex problem solving, surprisingly, we find that reasoning\nfine-tuning degrades abstention (by $24\\%$ on average), even for math and\nscience domains on which reasoning models are explicitly trained. We find that\nwhile a carefully crafted system prompt can boost abstention in practice, it\ndoes not resolve models' fundamental inability to reason about uncertainty. We\nrelease AbstentionBench to foster research into advancing LLM reliability.",
      "pdf_url": "http://arxiv.org/pdf/2506.09038v1",
      "published": "2025-06-10T17:57:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.09038v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "FZOO: Fast Zeroth-Order Optimizer for Fine-Tuning Large Language Models towards Adam-Scale Speed",
      "authors": [
        "Sizhe Dang",
        "Yangyang Guo",
        "Yanjun Zhao",
        "Haishan Ye",
        "Xiaodong Zheng",
        "Guang Dai",
        "Ivor Tsang"
      ],
      "abstract": "Fine-tuning large language models (LLMs) often faces GPU memory bottlenecks:\nthe backward pass of first-order optimizers like Adam increases memory usage to\nmore than 10 times the inference level (e.g., 633 GB for OPT-30B). Zeroth-order\n(ZO) optimizers avoid this cost by estimating gradients only from forward\npasses, yet existing methods like MeZO usually require many more steps to\nconverge. Can this trade-off between speed and memory in ZO be fundamentally\nimproved? Normalized-SGD demonstrates strong empirical performance with greater\nmemory efficiency than Adam. In light of this, we introduce FZOO, a Fast\nZeroth-Order Optimizer toward Adam-Scale Speed. FZOO reduces the total forward\npasses needed for convergence by employing batched one-sided estimates that\nadapt step sizes based on the standard deviation of batch losses. It also\naccelerates per-batch computation through the use of Rademacher random vector\nperturbations coupled with CUDA's parallel processing. Extensive experiments on\ndiverse models, including RoBERTa-large, OPT (350M-66B), Phi-2, and Llama3,\nacross 11 tasks validate FZOO's effectiveness. On average, FZOO outperforms\nMeZO by 3 percent in accuracy while requiring 3 times fewer forward passes. For\nRoBERTa-large, FZOO achieves average improvements of 5.6 percent in accuracy\nand an 18 times reduction in forward passes compared to MeZO, achieving\nconvergence speeds comparable to Adam. We also provide theoretical analysis\nproving FZOO's formal equivalence to a normalized-SGD update rule and its\nconvergence guarantees. FZOO integrates smoothly into PEFT techniques, enabling\neven larger memory savings. Overall, our results make single-GPU, high-speed,\nfull-parameter fine-tuning practical and point toward future work on\nmemory-efficient pre-training.",
      "pdf_url": "http://arxiv.org/pdf/2506.09034v1",
      "published": "2025-06-10T17:56:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.09034v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Router-R1: Teaching LLMs Multi-Round Routing and Aggregation via Reinforcement Learning",
      "authors": [
        "Haozhen Zhang",
        "Tao Feng",
        "Jiaxuan You"
      ],
      "abstract": "The rapid emergence of diverse large language models (LLMs) has spurred the\ndevelopment of LLM routers that assign user queries to the most suitable model.\nHowever, existing LLM routers typically perform a single-round, one-to-one\nmapping (\\textit{i.e.}, assigning each query to a single model in isolation),\nwhich limits their capability to tackle complex tasks that demand the\ncomplementary strengths of multiple LLMs. In this paper, we present\n\\textbf{Router-R1}, a reinforcement learning (RL)-based framework that\nformulates multi-LLM routing and aggregation as a sequential decision process.\nRouter-R1 instantiates the router itself as a capable LLM, leveraging its\nreasoning ability to interleave \"think\" actions (internal deliberation) with\n\"route\" actions (dynamic model invocation), and integrates each response into\nits evolving context. To guide learning, we employ a lightweight rule-based\nreward comprising format rewards, final outcome rewards, and a novel cost\nreward for performance and cost trade-off optimization, opening a pathway\ntoward optimizing performance-cost tradeoffs via RL. Router-R1 also conditions\nonly on simple model descriptors such as pricing, latency, and example\nperformance, enabling strong generalization to unseen model selection.\nExperiments on seven general and multi-hop QA benchmarks show that Router-R1\noutperforms over several strong baselines, achieving superior performance while\nmaintaining robust generalization and cost management.Code is available at\nhttps://github.com/ulab-uiuc/Router-R1.",
      "pdf_url": "http://arxiv.org/pdf/2506.09033v1",
      "published": "2025-06-10T17:56:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.09033v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Diffuse and Disperse: Image Generation with Representation Regularization",
      "authors": [
        "Runqian Wang",
        "Kaiming He"
      ],
      "abstract": "The development of diffusion-based generative models over the past decade has\nlargely proceeded independently of progress in representation learning. These\ndiffusion models typically rely on regression-based objectives and generally\nlack explicit regularization. In this work, we propose \\textit{Dispersive\nLoss}, a simple plug-and-play regularizer that effectively improves\ndiffusion-based generative models. Our loss function encourages internal\nrepresentations to disperse in the hidden space, analogous to contrastive\nself-supervised learning, with the key distinction that it requires no positive\nsample pairs and therefore does not interfere with the sampling process used\nfor regression. Compared to the recent method of representation alignment\n(REPA), our approach is self-contained and minimalist, requiring no\npre-training, no additional parameters, and no external data. We evaluate\nDispersive Loss on the ImageNet dataset across a range of models and report\nconsistent improvements over widely used and strong baselines. We hope our work\nwill help bridge the gap between generative modeling and representation\nlearning.",
      "pdf_url": "http://arxiv.org/pdf/2506.09027v1",
      "published": "2025-06-10T17:53:29+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.09027v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Edit Flows: Flow Matching with Edit Operations",
      "authors": [
        "Marton Havasi",
        "Brian Karrer",
        "Itai Gat",
        "Ricky T. Q. Chen"
      ],
      "abstract": "Autoregressive generative models naturally generate variable-length\nsequences, while non-autoregressive models struggle, often imposing rigid,\ntoken-wise structures. We propose Edit Flows, a non-autoregressive model that\novercomes these limitations by defining a discrete flow over sequences through\nedit operations-insertions, deletions, and substitutions. By modeling these\noperations within a Continuous-time Markov Chain over the sequence space, Edit\nFlows enable flexible, position-relative generation that aligns more closely\nwith the structure of sequence data. Our training method leverages an expanded\nstate space with auxiliary variables, making the learning process efficient and\ntractable. Empirical results show that Edit Flows outperforms both\nautoregressive and mask models on image captioning and significantly\noutperforms the mask construction in text and code generation.",
      "pdf_url": "http://arxiv.org/pdf/2506.09018v1",
      "published": "2025-06-10T17:44:19+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.09018v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Employing self-supervised learning models for cross-linguistic child speech maturity classification",
      "authors": [
        "Theo Zhang",
        "Madurya Suresh",
        "Anne S. Warlaumont",
        "Kasia Hitczenko",
        "Alejandrina Cristia",
        "Margaret Cychosz"
      ],
      "abstract": "Speech technology systems struggle with many downstream tasks for child\nspeech due to small training corpora and the difficulties that child speech\npose. We apply a novel dataset, SpeechMaturity, to state-of-the-art transformer\nmodels to address a fundamental classification task: identifying child\nvocalizations. Unlike previous corpora, our dataset captures maximally\necologically-valid child vocalizations across an unprecedented sample,\ncomprising children acquiring 25+ languages in the U.S., Bolivia, Vanuatu,\nPapua New Guinea, Solomon Islands, and France. The dataset contains 242,004\nlabeled vocalizations, magnitudes larger than previous work. Models were\ntrained to distinguish between cry, laughter, mature (consonant+vowel), and\nimmature speech (just consonant or vowel). Models trained on the dataset\noutperform state-of-the-art models trained on previous datasets, achieved\nclassification accuracy comparable to humans, and were robust across rural and\nurban settings.",
      "pdf_url": "http://arxiv.org/pdf/2506.08999v1",
      "published": "2025-06-10T17:20:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.08999v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Efficient Medical Vision-Language Alignment Through Adapting Masked Vision Models",
      "authors": [
        "Chenyu Lian",
        "Hong-Yu Zhou",
        "Dongyun Liang",
        "Jing Qin",
        "Liansheng Wang"
      ],
      "abstract": "Medical vision-language alignment through cross-modal contrastive learning\nshows promising performance in image-text matching tasks, such as retrieval and\nzero-shot classification. However, conventional cross-modal contrastive\nlearning (CLIP-based) methods suffer from suboptimal visual representation\ncapabilities, which also limits their effectiveness in vision-language\nalignment. In contrast, although the models pretrained via multimodal masked\nmodeling struggle with direct cross-modal matching, they excel in visual\nrepresentation. To address this contradiction, we propose ALTA (ALign Through\nAdapting), an efficient medical vision-language alignment method that utilizes\nonly about 8% of the trainable parameters and less than 1/5 of the\ncomputational consumption required for masked record modeling. ALTA achieves\nsuperior performance in vision-language matching tasks like retrieval and\nzero-shot classification by adapting the pretrained vision model from masked\nrecord modeling. Additionally, we integrate temporal-multiview radiograph\ninputs to enhance the information consistency between radiographs and their\ncorresponding descriptions in reports, further improving the vision-language\nalignment. Experimental evaluations show that ALTA outperforms the\nbest-performing counterpart by over 4% absolute points in text-to-image\naccuracy and approximately 6% absolute points in image-to-text retrieval\naccuracy. The adaptation of vision-language models during efficient alignment\nalso promotes better vision and language understanding. Code is publicly\navailable at https://github.com/DopamineLcy/ALTA.",
      "pdf_url": "http://arxiv.org/pdf/2506.08990v1",
      "published": "2025-06-10T17:02:27+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.08990v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Propositional Logic for Probing Generalization in Neural Networks",
      "authors": [
        "Anna Langedijk",
        "Jaap Jumelet",
        "Willem Zuidema"
      ],
      "abstract": "The extent to which neural networks are able to acquire and represent\nsymbolic rules remains a key topic of research and debate. Much current work\nfocuses on the impressive capabilities of large language models, as well as\ntheir often ill-understood failures on a wide range of reasoning tasks. In this\npaper, in contrast, we investigate the generalization behavior of three key\nneural architectures (Transformers, Graph Convolution Networks and LSTMs) in a\ncontrolled task rooted in propositional logic. The task requires models to\ngenerate satisfying assignments for logical formulas, making it a structured\nand interpretable setting for studying compositionality. We introduce a\nbalanced extension of an existing dataset to eliminate superficial patterns and\nenable testing on unseen operator combinations. Using this dataset, we evaluate\nthe ability of the three architectures to generalize beyond the training\ndistribution. While all models perform well in-distribution, we find that\ngeneralization to unseen patterns, particularly those involving negation,\nremains a significant challenge. Transformers fail to apply negation\ncompositionally, unless structural biases are introduced. Our findings\nhighlight persistent limitations in the ability of standard architectures to\nlearn systematic representations of logical operators, suggesting the need for\nstronger inductive biases to support robust rule-based reasoning.",
      "pdf_url": "http://arxiv.org/pdf/2506.08978v1",
      "published": "2025-06-10T16:46:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.08978v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Tailored Architectures for Time Series Forecasting: Evaluating Deep Learning Models on Gaussian Process-Generated Data",
      "authors": [
        "Victoria Hankemeier",
        "Malte Schilling"
      ],
      "abstract": "Developments in Deep Learning have significantly improved time series\nforecasting by enabling more accurate modeling of complex temporal dependencies\ninherent in sequential data. The effectiveness of such models is often\ndemonstrated on limited sets of specific real-world data. Although this allows\nfor comparative analysis, it still does not demonstrate how specific data\ncharacteristics align with the architectural strengths of individual models.\nOur research aims at uncovering clear connections between time series\ncharacteristics and particular models. We introduce a novel dataset generated\nusing Gaussian Processes, specifically designed to display distinct, known\ncharacteristics for targeted evaluations of model adaptability to them.\nFurthermore, we present TimeFlex, a new model that incorporates a modular\narchitecture tailored to handle diverse temporal dynamics, including trends and\nperiodic patterns. This model is compared to current state-of-the-art models,\noffering a deeper understanding of how models perform under varied time series\nconditions.",
      "pdf_url": "http://arxiv.org/pdf/2506.08977v1",
      "published": "2025-06-10T16:46:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.08977v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "A Survey of Link Prediction in N-ary Knowledge Graphs",
      "authors": [
        "Jiyao Wei",
        "Saiping Guan",
        "Da Li",
        "Xiaolong Jin",
        "Jiafeng Guo",
        "Xueqi Cheng"
      ],
      "abstract": "N-ary Knowledge Graphs (NKGs) are a specialized type of knowledge graph\ndesigned to efficiently represent complex real-world facts. Unlike traditional\nknowledge graphs, where a fact typically involves two entities, NKGs can\ncapture n-ary facts containing more than two entities. Link prediction in NKGs\naims to predict missing elements within these n-ary facts, which is essential\nfor completing NKGs and improving the performance of downstream applications.\nThis task has recently gained significant attention. In this paper, we present\nthe first comprehensive survey of link prediction in NKGs, providing an\noverview of the field, systematically categorizing existing methods, and\nanalyzing their performance and application scenarios. We also outline\npromising directions for future research.",
      "pdf_url": "http://arxiv.org/pdf/2506.08970v1",
      "published": "2025-06-10T16:44:27+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.08970v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "GFRIEND: Generative Few-shot Reward Inference through EfficieNt DPO",
      "authors": [
        "Yiyang Zhao",
        "Huiyu Bai",
        "Xuejiao Zhao"
      ],
      "abstract": "The ability to train high-performing reward models with few-shot data is\ncritical for enhancing the efficiency and scalability of Reinforcement Learning\nfrom Human Feedback (RLHF). We propose a data augmentation and expansion\nframework that enables generative reward models trained on small datasets to\nachieve comparable performance to those trained on large-scale datasets.\nTraditional methods to train a generative reward model, such as Direct\nPreference Optimization (DPO), are constrained by inefficiencies in sample\npairing and limited data diversity. This work introduces preference refinement,\nwhich employs Chain-of-Thought (CoT) sampling to uncover diverse and\nhigh-quality preference relationships. It also incorporates a perplexity-based\nscoring mechanism to assign nuanced preference levels and utilizes Multi-level\nDirect Preference Optimization (M-DPO) to enable the model to capture\nfiner-grained preference differences between samples. Experimental results\ndemonstrate that the proposed method significantly enhances data efficiency and\nmodel performance, enabling reward models trained in a few-shot setting to\nachieve results on par with those trained on large-scale datasets. This study\nunderscores the potential of data-efficient strategies in advancing reward\nmodel optimization, offering a robust solution for low-resource RLHF\napplications.",
      "pdf_url": "http://arxiv.org/pdf/2506.08965v1",
      "published": "2025-06-10T16:37:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.08965v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Evaluating Generative Vehicle Trajectory Models for Traffic Intersection Dynamics",
      "authors": [
        "Yash Ranjan",
        "Rahul Sengupta",
        "Anand Rangarajan",
        "Sanjay Ranka"
      ],
      "abstract": "Traffic Intersections are vital to urban road networks as they regulate the\nmovement of people and goods. However, they are regions of conflicting\ntrajectories and are prone to accidents. Deep Generative models of traffic\ndynamics at signalized intersections can greatly help traffic authorities\nbetter understand the efficiency and safety aspects. At present, models are\nevaluated on computational metrics that primarily look at trajectory\nreconstruction errors. They are not evaluated online in a `live'\nmicrosimulation scenario. Further, these metrics do not adequately consider\ntraffic engineering-specific concerns such as red-light violations, unallowed\nstoppage, etc. In this work, we provide a comprehensive analytics tool to\ntrain, run, and evaluate models with metrics that give better insights into\nmodel performance from a traffic engineering point of view. We train a\nstate-of-the-art multi-vehicle trajectory forecasting model on a large dataset\ncollected by running a calibrated scenario of a real-world urban intersection.\nWe then evaluate the performance of the prediction models, online in a\nmicrosimulator, under unseen traffic conditions. We show that despite using\nideally-behaved trajectories as input, and achieving low trajectory\nreconstruction errors, the generated trajectories show behaviors that break\ntraffic rules. We introduce new metrics to evaluate such undesired behaviors\nand present our results.",
      "pdf_url": "http://arxiv.org/pdf/2506.08963v1",
      "published": "2025-06-10T16:36:42+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.08963v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "WIP: Large Language Model-Enhanced Smart Tutor for Undergraduate Circuit Analysis",
      "authors": [
        "Liangliang Chen",
        "Huiru Xie",
        "Jacqueline Rohde",
        "Ying Zhang"
      ],
      "abstract": "This research-to-practice work-in-progress (WIP) paper presents an AI-enabled\nsmart tutor designed to provide homework assessment and feedback for students\nin an undergraduate circuit analysis course. We detail the tutor's design\nphilosophy and core components, including open-ended question answering and\nhomework feedback generation. The prompts are carefully crafted to optimize\nresponses across different problems. The smart tutor was deployed on the\nMicrosoft Azure platform and is currently in use in an undergraduate circuit\nanalysis course at the School of Electrical and Computer Engineering in a\nlarge, public, research-intensive institution in the Southeastern United\nStates. Beyond offering personalized instruction and feedback, the tutor\ncollects student interaction data, which is summarized and shared with the\ncourse instructor. To evaluate its effectiveness, we collected student\nfeedback, with 90.9% of responses indicating satisfaction with the tutor.\nAdditionally, we analyze a subset of collected data on preliminary circuit\nanalysis topics to assess tutor usage frequency for each problem and identify\nfrequently asked questions. These insights help instructors gain real-time\nawareness of student difficulties, enabling more targeted classroom\ninstruction. In future work, we will release a full analysis once the complete\ndataset is available after the Spring 2025 semester. We also explore the\npotential applications of this smart tutor across a broader range of\nengineering disciplines by developing improved prompts, diagram-recognition\nmethods, and database management strategies, which remain ongoing areas of\nresearch.",
      "pdf_url": "http://arxiv.org/pdf/2506.08962v1",
      "published": "2025-06-10T16:35:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.08962v1",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ]
    },
    {
      "title": "Towards Robust Deep Reinforcement Learning against Environmental State Perturbation",
      "authors": [
        "Chenxu Wang",
        "Huaping Liu"
      ],
      "abstract": "Adversarial attacks and robustness in Deep Reinforcement Learning (DRL) have\nbeen widely studied in various threat models; however, few consider\nenvironmental state perturbations, which are natural in embodied scenarios. To\nimprove the robustness of DRL agents, we formulate the problem of environmental\nstate perturbation, introducing a preliminary non-targeted attack method as a\ncalibration adversary, and then propose a defense framework, named Boosted\nAdversarial Training (BAT), which first tunes the agents via supervised\nlearning to avoid catastrophic failure and subsequently adversarially trains\nthe agent with reinforcement learning. Extensive experimental results\nsubstantiate the vulnerability of mainstream agents under environmental state\nperturbations and the effectiveness of our proposed attack. The defense results\ndemonstrate that while existing robust reinforcement learning algorithms may\nnot be suitable, our BAT framework can significantly enhance the robustness of\nagents against environmental state perturbations across various situations.",
      "pdf_url": "http://arxiv.org/pdf/2506.08961v1",
      "published": "2025-06-10T16:32:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.08961v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "IntTrajSim: Trajectory Prediction for Simulating Multi-Vehicle driving at Signalized Intersections",
      "authors": [
        "Yash Ranjan",
        "Rahul Sengupta",
        "Anand Rangarajan",
        "Sanjay Ranka"
      ],
      "abstract": "Traffic simulators are widely used to study the operational efficiency of\nroad infrastructure, but their rule-based approach limits their ability to\nmimic real-world driving behavior. Traffic intersections are critical\ncomponents of the road infrastructure, both in terms of safety risk (nearly 28%\nof fatal crashes and 58% of nonfatal crashes happen at intersections) as well\nas the operational efficiency of a road corridor. This raises an important\nquestion: can we create a data-driven simulator that can mimic the macro- and\nmicro-statistics of the driving behavior at a traffic intersection? Deep\nGenerative Modeling-based trajectory prediction models provide a good starting\npoint to model the complex dynamics of vehicles at an intersection. But they\nare not tested in a \"live\" micro-simulation scenario and are not evaluated on\ntraffic engineering-related metrics. In this study, we propose traffic\nengineering-related metrics to evaluate generative trajectory prediction models\nand provide a simulation-in-the-loop pipeline to do so. We also provide a\nmulti-headed self-attention-based trajectory prediction model that incorporates\nthe signal information, which outperforms our previous models on the evaluation\nmetrics.",
      "pdf_url": "http://arxiv.org/pdf/2506.08957v1",
      "published": "2025-06-10T16:27:42+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.08957v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Segment Concealed Objects with Incomplete Supervision",
      "authors": [
        "Chunming He",
        "Kai Li",
        "Yachao Zhang",
        "Ziyun Yang",
        "Youwei Pang",
        "Longxiang Tang",
        "Chengyu Fang",
        "Yulun Zhang",
        "Linghe Kong",
        "Xiu Li",
        "Sina Farsiu"
      ],
      "abstract": "Incompletely-Supervised Concealed Object Segmentation (ISCOS) involves\nsegmenting objects that seamlessly blend into their surrounding environments,\nutilizing incompletely annotated data, such as weak and semi-annotations, for\nmodel training. This task remains highly challenging due to (1) the limited\nsupervision provided by the incompletely annotated training data, and (2) the\ndifficulty of distinguishing concealed objects from the background, which\narises from the intrinsic similarities in concealed scenarios. In this paper,\nwe introduce the first unified method for ISCOS to address these challenges. To\ntackle the issue of incomplete supervision, we propose a unified mean-teacher\nframework, SEE, that leverages the vision foundation model, ``\\emph{Segment\nAnything Model (SAM)}'', to generate pseudo-labels using coarse masks produced\nby the teacher model as prompts. To mitigate the effect of low-quality\nsegmentation masks, we introduce a series of strategies for pseudo-label\ngeneration, storage, and supervision. These strategies aim to produce\ninformative pseudo-labels, store the best pseudo-labels generated, and select\nthe most reliable components to guide the student model, thereby ensuring\nrobust network training. Additionally, to tackle the issue of intrinsic\nsimilarity, we design a hybrid-granularity feature grouping module that groups\nfeatures at different granularities and aggregates these results. By clustering\nsimilar features, this module promotes segmentation coherence, facilitating\nmore complete segmentation for both single-object and multiple-object images.\nWe validate the effectiveness of our approach across multiple ISCOS tasks, and\nexperimental results demonstrate that our method achieves state-of-the-art\nperformance. Furthermore, SEE can serve as a plug-and-play solution, enhancing\nthe performance of existing models.",
      "pdf_url": "http://arxiv.org/pdf/2506.08955v1",
      "published": "2025-06-10T16:25:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.08955v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Can LLMs Ground when they (Don't) Know: A Study on Direct and Loaded Political Questions",
      "authors": [
        "Clara Lachenmaier",
        "Judith Sieker",
        "Sina Zarrieß"
      ],
      "abstract": "Communication among humans relies on conversational grounding, allowing\ninterlocutors to reach mutual understanding even when they do not have perfect\nknowledge and must resolve discrepancies in each other's beliefs. This paper\ninvestigates how large language models (LLMs) manage common ground in cases\nwhere they (don't) possess knowledge, focusing on facts in the political domain\nwhere the risk of misinformation and grounding failure is high. We examine the\nability of LLMs to answer direct knowledge questions and loaded questions that\npresuppose misinformation. We evaluate whether loaded questions lead LLMs to\nengage in active grounding and correct false user beliefs, in connection to\ntheir level of knowledge and their political bias. Our findings highlight\nsignificant challenges in LLMs' ability to engage in grounding and reject false\nuser beliefs, raising concerns about their role in mitigating misinformation in\npolitical discourse.",
      "pdf_url": "http://arxiv.org/pdf/2506.08952v2",
      "published": "2025-06-10T16:20:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.08952v2",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Can A Gamer Train A Mathematical Reasoning Model?",
      "authors": [
        "Andrew Shin"
      ],
      "abstract": "While large language models (LLMs) have achieved remarkable performance in\nvarious tasks including mathematical reasoning, their development typically\ndemands prohibitive computational resources. Recent advancements have reduced\ncosts for training capable models, yet even these approaches rely on high-end\nhardware clusters. In this paper, we demonstrate that a single average gaming\nGPU can train a solid mathematical reasoning model, by integrating\nreinforcement learning and memory optimization techniques. Specifically, we\ntrain a 1.5B parameter mathematical reasoning model on RTX 3080 Ti of 16GB\nmemory that achieves comparable or better performance on mathematical reasoning\nbenchmarks than models several times larger, in resource-constrained\nenvironments. Our results challenge the paradigm that state-of-the-art\nmathematical reasoning necessitates massive infrastructure, democratizing\naccess to high-performance AI research.\nhttps://github.com/shinandrew/YouronMath.",
      "pdf_url": "http://arxiv.org/pdf/2506.08935v1",
      "published": "2025-06-10T16:00:12+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.08935v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Socratic-MCTS: Test-Time Visual Reasoning by Asking the Right Questions",
      "authors": [
        "David Acuna",
        "Ximing Lu",
        "Jaehun Jung",
        "Hyunwoo Kim",
        "Amlan Kar",
        "Sanja Fidler",
        "Yejin Choi"
      ],
      "abstract": "Recent research in vision-language models (VLMs) has centered around the\npossibility of equipping them with implicit long-form chain-of-thought\nreasoning -- akin to the success observed in language models -- via\ndistillation and reinforcement learning. But what about the non-reasoning\nmodels already trained and deployed across the internet? Should we simply\nabandon them, or is there hope for a search mechanism that can elicit hidden\nknowledge and induce long reasoning traces -- without any additional training\nor supervision? In this paper, we explore this possibility using a Monte Carlo\nTree Search (MCTS)-inspired algorithm, which injects subquestion-subanswer\npairs into the model's output stream. We show that framing reasoning as a\nsearch process -- where subquestions act as latent decisions within a broader\ninference trajectory -- helps the model \"connect the dots\" between fragmented\nknowledge and produce extended reasoning traces in non-reasoning models. We\nevaluate our method across three benchmarks and observe consistent\nimprovements. Notably, our approach yields a 2% overall improvement on\nMMMU-PRO, including a significant 9% gain in Liberal Arts.",
      "pdf_url": "http://arxiv.org/pdf/2506.08927v1",
      "published": "2025-06-10T15:51:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.08927v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "PropMEND: Hypernetworks for Knowledge Propagation in LLMs",
      "authors": [
        "Zeyu Leo Liu",
        "Greg Durrett",
        "Eunsol Choi"
      ],
      "abstract": "Knowledge editing techniques for large language models (LLMs) can inject\nknowledge that is later reproducible verbatim, but they fall short on\npropagating that knowledge: models cannot answer questions that require\nreasoning with the injected knowledge. We present a hypernetwork-based approach\nfor knowledge propagation, named PropMEND, where we meta-learn how to modify\ngradients of a language modeling loss to encourage injected information to\npropagate. Our approach extends the meta-objective of MEND [29] so that\ngradient updates on knowledge are transformed to enable answering multi-hop\nquestions involving that knowledge. We show improved performance on the\nRippleEdit dataset, showing almost 2x accuracy on challenging multi-hop\nquestions whose answers are not explicitly stated in the injected fact. We\nfurther introduce a new dataset, Controlled RippleEdit, to evaluate the\ngeneralization of our hypernetwork, testing knowledge propagation along\nrelations and entities unseen during hypernetwork training. PropMEND still\noutperforms existing approaches in unseen entity-relation pairs, yet the\nperformance gap decreases substantially, suggesting future work in propagating\nknowledge to a wide range of relations.",
      "pdf_url": "http://arxiv.org/pdf/2506.08920v1",
      "published": "2025-06-10T15:44:19+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.08920v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Quantum Adiabatic Generation of Human-Like Passwords",
      "authors": [
        "Sascha Mücke",
        "Raoul Heese",
        "Thore Gerlach",
        "David Biesner",
        "Loong Kuan Lee",
        "Nico Piatkowski"
      ],
      "abstract": "Generative Artificial Intelligence (GenAI) for Natural Language Processing\n(NLP) is the predominant AI technology to date. An important perspective for\nQuantum Computing (QC) is the question whether QC has the potential to reduce\nthe vast resource requirements for training and operating GenAI models. While\nlarge-scale generative NLP tasks are currently out of reach for practical\nquantum computers, the generation of short semantic structures such as\npasswords is not. Generating passwords that mimic real user behavior has many\napplications, for example to test an authentication system against realistic\nthreat models. Classical password generation via deep learning have recently\nbeen investigated with significant progress in their ability to generate novel,\nrealistic password candidates. In the present work we investigate the utility\nof adiabatic quantum computers for this task. More precisely, we study\ndifferent encodings of token strings and propose novel approaches based on the\nQuadratic Unconstrained Binary Optimization (QUBO) and the Unit-Disk Maximum\nIndependent Set (UD-MIS) problems. Our approach allows us to estimate the token\ndistribution from data and adiabatically prepare a quantum state from which we\neventually sample the generated passwords via measurements. Our results show\nthat relatively small samples of 128 passwords, generated on the QuEra Aquila\n256-qubit neutral atom quantum computer, contain human-like passwords such as\n\"Tunas200992\" or \"teedem28iglove\".",
      "pdf_url": "http://arxiv.org/pdf/2506.08917v1",
      "published": "2025-06-10T15:43:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.08917v1",
      "categories": [
        "quant-ph",
        "cs.AI"
      ]
    },
    {
      "title": "Inherently Faithful Attention Maps for Vision Transformers",
      "authors": [
        "Ananthu Aniraj",
        "Cassio F. Dantas",
        "Dino Ienco",
        "Diego Marcos"
      ],
      "abstract": "We introduce an attention-based method that uses learned binary attention\nmasks to ensure that only attended image regions influence the prediction.\nContext can strongly affect object perception, sometimes leading to biased\nrepresentations, particularly when objects appear in out-of-distribution\nbackgrounds. At the same time, many image-level object-centric tasks require\nidentifying relevant regions, often requiring context. To address this\nconundrum, we propose a two-stage framework: stage 1 processes the full image\nto discover object parts and identify task-relevant regions, while stage 2\nleverages input attention masking to restrict its receptive field to these\nregions, enabling a focused analysis while filtering out potentially spurious\ninformation. Both stages are trained jointly, allowing stage 2 to refine stage\n1. Extensive experiments across diverse benchmarks demonstrate that our\napproach significantly improves robustness against spurious correlations and\nout-of-distribution backgrounds.",
      "pdf_url": "http://arxiv.org/pdf/2506.08915v1",
      "published": "2025-06-10T15:41:22+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.08915v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Intention-Conditioned Flow Occupancy Models",
      "authors": [
        "Chongyi Zheng",
        "Seohong Park",
        "Sergey Levine",
        "Benjamin Eysenbach"
      ],
      "abstract": "Large-scale pre-training has fundamentally changed how machine learning\nresearch is done today: large foundation models are trained once, and then can\nbe used by anyone in the community (including those without data or compute\nresources to train a model from scratch) to adapt and fine-tune to specific\ntasks. Applying this same framework to reinforcement learning (RL) is appealing\nbecause it offers compelling avenues for addressing core challenges in RL,\nincluding sample efficiency and robustness. However, there remains a\nfundamental challenge to pre-train large models in the context of RL: actions\nhave long-term dependencies, so training a foundation model that reasons across\ntime is important. Recent advances in generative AI have provided new tools for\nmodeling highly complex distributions. In this paper, we build a probabilistic\nmodel to predict which states an agent will visit in the temporally distant\nfuture (i.e., an occupancy measure) using flow matching. As large datasets are\noften constructed by many distinct users performing distinct tasks, we include\nin our model a latent variable capturing the user intention. This intention\nincreases the expressivity of our model, and enables adaptation with\ngeneralized policy improvement. We call our proposed method\nintention-conditioned flow occupancy models (InFOM). Comparing with alternative\nmethods for pre-training, our experiments on $36$ state-based and $4$\nimage-based benchmark tasks demonstrate that the proposed method achieves $1.8\n\\times$ median improvement in returns and increases success rates by $36\\%$.\nWebsite: https://chongyi-zheng.github.io/infom Code:\nhttps://github.com/chongyi-zheng/infom",
      "pdf_url": "http://arxiv.org/pdf/2506.08902v1",
      "published": "2025-06-10T15:27:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.08902v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "From Legal Texts to Defeasible Deontic Logic via LLMs: A Study in Automated Semantic Analysis",
      "authors": [
        "Elias Horner",
        "Cristinel Mateis",
        "Guido Governatori",
        "Agata Ciabattoni"
      ],
      "abstract": "We present a novel approach to the automated semantic analysis of legal texts\nusing large language models (LLMs), targeting their transformation into formal\nrepresentations in Defeasible Deontic Logic (DDL). We propose a structured\npipeline that segments complex normative language into atomic snippets,\nextracts deontic rules, and evaluates them for syntactic and semantic\ncoherence. Our methodology is evaluated across various LLM configurations,\nincluding prompt engineering strategies, fine-tuned models, and multi-stage\npipelines, focusing on legal norms from the Australian Telecommunications\nConsumer Protections Code. Empirical results demonstrate promising alignment\nbetween machine-generated and expert-crafted formalizations, showing that LLMs\n- particularly when prompted effectively - can significantly contribute to\nscalable legal informatics.",
      "pdf_url": "http://arxiv.org/pdf/2506.08899v1",
      "published": "2025-06-10T15:25:19+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.08899v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LO"
      ]
    },
    {
      "title": "Preference-Driven Multi-Objective Combinatorial Optimization with Conditional Computation",
      "authors": [
        "Mingfeng Fan",
        "Jianan Zhou",
        "Yifeng Zhang",
        "Yaoxin Wu",
        "Jinbiao Chen",
        "Guillaume Adrien Sartoretti"
      ],
      "abstract": "Recent deep reinforcement learning methods have achieved remarkable success\nin solving multi-objective combinatorial optimization problems (MOCOPs) by\ndecomposing them into multiple subproblems, each associated with a specific\nweight vector. However, these methods typically treat all subproblems equally\nand solve them using a single model, hindering the effective exploration of the\nsolution space and thus leading to suboptimal performance. To overcome the\nlimitation, we propose POCCO, a novel plug-and-play framework that enables\nadaptive selection of model structures for subproblems, which are subsequently\noptimized based on preference signals rather than explicit reward values.\nSpecifically, we design a conditional computation block that routes subproblems\nto specialized neural architectures. Moreover, we propose a preference-driven\noptimization algorithm that learns pairwise preferences between winning and\nlosing solutions. We evaluate the efficacy and versatility of POCCO by applying\nit to two state-of-the-art neural methods for MOCOPs. Experimental results\nacross four classic MOCOP benchmarks demonstrate its significant superiority\nand strong generalization.",
      "pdf_url": "http://arxiv.org/pdf/2506.08898v1",
      "published": "2025-06-10T15:25:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.08898v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "PlantBert: An Open Source Language Model for Plant Science",
      "authors": [
        "Hiba Khey",
        "Amine Lakhder",
        "Salma Rouichi",
        "Imane El Ghabi",
        "Kamal Hejjaoui",
        "Younes En-nahli",
        "Fahd Kalloubi",
        "Moez Amri"
      ],
      "abstract": "The rapid advancement of transformer-based language models has catalyzed\nbreakthroughs in biomedical and clinical natural language processing; however,\nplant science remains markedly underserved by such domain-adapted tools. In\nthis work, we present PlantBert, a high-performance, open-source language model\nspecifically tailored for extracting structured knowledge from plant\nstress-response literature. Built upon the DeBERTa architecture-known for its\ndisentangled attention and robust contextual encoding-PlantBert is fine-tuned\non a meticulously curated corpus of expert-annotated abstracts, with a primary\nfocus on lentil (Lens culinaris) responses to diverse abiotic and biotic\nstressors. Our methodology combines transformer-based modeling with\nrule-enhanced linguistic post-processing and ontology-grounded entity\nnormalization, enabling PlantBert to capture biologically meaningful\nrelationships with precision and semantic fidelity. The underlying corpus is\nannotated using a hierarchical schema aligned with the Crop Ontology,\nencompassing molecular, physiological, biochemical, and agronomic dimensions of\nplant adaptation. PlantBert exhibits strong generalization capabilities across\nentity types and demonstrates the feasibility of robust domain adaptation in\nlow-resource scientific fields. By providing a scalable and reproducible\nframework for high-resolution entity recognition, PlantBert bridges a critical\ngap in agricultural NLP and paves the way for intelligent, data-driven systems\nin plant genomics, phenomics, and agronomic knowledge discovery. Our model is\npublicly released to promote transparency and accelerate cross-disciplinary\ninnovation in computational plant science.",
      "pdf_url": "http://arxiv.org/pdf/2506.08897v1",
      "published": "2025-06-10T15:24:03+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.08897v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Product of Experts for Visual Generation",
      "authors": [
        "Yunzhi Zhang",
        "Carson Murtuza-Lanier",
        "Zizhang Li",
        "Yilun Du",
        "Jiajun Wu"
      ],
      "abstract": "Modern neural models capture rich priors and have complementary knowledge\nover shared data domains, e.g., images and videos. Integrating diverse\nknowledge from multiple sources -- including visual generative models, visual\nlanguage models, and sources with human-crafted knowledge such as graphics\nengines and physics simulators -- remains under-explored. We propose a Product\nof Experts (PoE) framework that performs inference-time knowledge composition\nfrom heterogeneous models. This training-free approach samples from the product\ndistribution across experts via Annealed Importance Sampling (AIS). Our\nframework shows practical benefits in image and video synthesis tasks, yielding\nbetter controllability than monolithic methods and additionally providing\nflexible user interfaces for specifying visual generation goals.",
      "pdf_url": "http://arxiv.org/pdf/2506.08894v1",
      "published": "2025-06-10T15:21:14+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.08894v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "SeerAttention-R: Sparse Attention Adaptation for Long Reasoning",
      "authors": [
        "Yizhao Gao",
        "Shuming Guo",
        "Shijie Cao",
        "Yuqing Xia",
        "Yu Cheng",
        "Lei Wang",
        "Lingxiao Ma",
        "Yutao Sun",
        "Tianzhu Ye",
        "Li Dong",
        "Hayden Kwok-Hay So",
        "Yu Hua",
        "Ting Cao",
        "Fan Yang",
        "Mao Yang"
      ],
      "abstract": "We introduce SeerAttention-R, a sparse attention framework specifically\ntailored for the long decoding of reasoning models. Extended from\nSeerAttention, SeerAttention-R retains the design of learning attention\nsparsity through a self-distilled gating mechanism, while removing query\npooling to accommodate auto-regressive decoding. With a lightweight plug-in\ngating, SeerAttention-R is flexible and can be easily integrated into existing\npretrained model without modifying the original parameters. We demonstrate that\nSeerAttention-R, trained on just 0.4B tokens, maintains near-lossless reasoning\naccuracy with 4K token budget in AIME benchmark under large sparse attention\nblock sizes (64/128). Using TileLang, we develop a highly optimized sparse\ndecoding kernel that achieves near-theoretical speedups of up to 9x over\nFlashAttention-3 on H100 GPU at 90% sparsity. Code is available at:\nhttps://github.com/microsoft/SeerAttention.",
      "pdf_url": "http://arxiv.org/pdf/2506.08889v1",
      "published": "2025-06-10T15:17:26+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.08889v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Your Brain on ChatGPT: Accumulation of Cognitive Debt when Using an AI Assistant for Essay Writing Task",
      "authors": [
        "Nataliya Kosmyna",
        "Eugene Hauptmann",
        "Ye Tong Yuan",
        "Jessica Situ",
        "Xian-Hao Liao",
        "Ashly Vivian Beresnitzky",
        "Iris Braunstein",
        "Pattie Maes"
      ],
      "abstract": "This study explores the neural and behavioral consequences of LLM-assisted\nessay writing. Participants were divided into three groups: LLM, Search Engine,\nand Brain-only (no tools). Each completed three sessions under the same\ncondition. In a fourth session, LLM users were reassigned to Brain-only group\n(LLM-to-Brain), and Brain-only users were reassigned to LLM condition\n(Brain-to-LLM). A total of 54 participants took part in Sessions 1-3, with 18\ncompleting session 4. We used electroencephalography (EEG) to assess cognitive\nload during essay writing, and analyzed essays using NLP, as well as scoring\nessays with the help from human teachers and an AI judge. Across groups, NERs,\nn-gram patterns, and topic ontology showed within-group homogeneity. EEG\nrevealed significant differences in brain connectivity: Brain-only participants\nexhibited the strongest, most distributed networks; Search Engine users showed\nmoderate engagement; and LLM users displayed the weakest connectivity.\nCognitive activity scaled down in relation to external tool use. In session 4,\nLLM-to-Brain participants showed reduced alpha and beta connectivity,\nindicating under-engagement. Brain-to-LLM users exhibited higher memory recall\nand activation of occipito-parietal and prefrontal areas, similar to Search\nEngine users. Self-reported ownership of essays was the lowest in the LLM group\nand the highest in the Brain-only group. LLM users also struggled to accurately\nquote their own work. While LLMs offer immediate convenience, our findings\nhighlight potential cognitive costs. Over four months, LLM users consistently\nunderperformed at neural, linguistic, and behavioral levels. These results\nraise concerns about the long-term educational implications of LLM reliance and\nunderscore the need for deeper inquiry into AI's role in learning.",
      "pdf_url": "http://arxiv.org/pdf/2506.08872v1",
      "published": "2025-06-10T15:04:28+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.08872v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "On The Impact of Merge Request Deviations on Code Review Practices",
      "authors": [
        "Samah Kansab",
        "Francis Bordeleau",
        "Ali Tizghadam"
      ],
      "abstract": "Code review is a key practice in software engineering, ensuring quality and\ncollaboration. However, industrial Merge Request (MR) workflows often deviate\nfrom standardized review processes, with many MRs serving non-review purposes\n(e.g., drafts, rebases, or dependency updates). We term these cases deviations\nand hypothesize that ignoring them biases analytics and undermines ML models\nfor review analysis.\n  We identify seven deviation categories, occurring in 37.02% of MRs, and\npropose a few-shot learning detection method (91% accuracy). By excluding\ndeviations, ML models predicting review completion time improve performance in\n53.33% of cases (up to 2.25x) and exhibit significant shifts in feature\nimportance (47% overall, 60% top-*k*).\n  Our contributions include: (1) a taxonomy of MR deviations, (2) an AI-driven\ndetection approach, and (3) empirical evidence of their impact on ML-based\nreview analytics. This work aids practitioners in optimizing review efforts and\nensuring reliable insights.",
      "pdf_url": "http://arxiv.org/pdf/2506.08860v2",
      "published": "2025-06-10T14:51:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.08860v2",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Spatial Transcriptomics Expression Prediction from Histopathology Based on Cross-Modal Mask Reconstruction and Contrastive Learning",
      "authors": [
        "Junzhuo Liu",
        "Markus Eckstein",
        "Zhixiang Wang",
        "Friedrich Feuerhake",
        "Dorit Merhof"
      ],
      "abstract": "Spatial transcriptomics is a technology that captures gene expression levels\nat different spatial locations, widely used in tumor microenvironment analysis\nand molecular profiling of histopathology, providing valuable insights into\nresolving gene expression and clinical diagnosis of cancer. Due to the high\ncost of data acquisition, large-scale spatial transcriptomics data remain\nchallenging to obtain. In this study, we develop a contrastive learning-based\ndeep learning method to predict spatially resolved gene expression from\nwhole-slide images. Evaluation across six different disease datasets\ndemonstrates that, compared to existing studies, our method improves Pearson\nCorrelation Coefficient (PCC) in the prediction of highly expressed genes,\nhighly variable genes, and marker genes by 6.27%, 6.11%, and 11.26%\nrespectively. Further analysis indicates that our method preserves gene-gene\ncorrelations and applies to datasets with limited samples. Additionally, our\nmethod exhibits potential in cancer tissue localization based on biomarker\nexpression.",
      "pdf_url": "http://arxiv.org/pdf/2506.08854v1",
      "published": "2025-06-10T14:42:03+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.08854v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "CulturalFrames: Assessing Cultural Expectation Alignment in Text-to-Image Models and Evaluation Metrics",
      "authors": [
        "Shravan Nayak",
        "Mehar Bhatia",
        "Xiaofeng Zhang",
        "Verena Rieser",
        "Lisa Anne Hendricks",
        "Sjoerd van Steenkiste",
        "Yash Goyal",
        "Karolina Stańczak",
        "Aishwarya Agrawal"
      ],
      "abstract": "The increasing ubiquity of text-to-image (T2I) models as tools for visual\ncontent generation raises concerns about their ability to accurately represent\ndiverse cultural contexts. In this work, we present the first study to\nsystematically quantify the alignment of T2I models and evaluation metrics with\nrespect to both explicit as well as implicit cultural expectations. To this\nend, we introduce CulturalFrames, a novel benchmark designed for rigorous human\nevaluation of cultural representation in visual generations. Spanning 10\ncountries and 5 socio-cultural domains, CulturalFrames comprises 983 prompts,\n3637 corresponding images generated by 4 state-of-the-art T2I models, and over\n10k detailed human annotations. We find that T2I models not only fail to meet\nthe more challenging implicit expectations but also the less challenging\nexplicit expectations. Across models and countries, cultural expectations are\nmissed an average of 44% of the time. Among these failures, explicit\nexpectations are missed at a surprisingly high average rate of 68%, while\nimplicit expectation failures are also significant, averaging 49%. Furthermore,\nwe demonstrate that existing T2I evaluation metrics correlate poorly with human\njudgments of cultural alignment, irrespective of their internal reasoning.\nCollectively, our findings expose critical gaps, providing actionable\ndirections for developing more culturally informed T2I models and evaluation\nmethodologies.",
      "pdf_url": "http://arxiv.org/pdf/2506.08835v1",
      "published": "2025-06-10T14:21:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.08835v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "The impact of fine tuning in LLaMA on hallucinations for named entity extraction in legal documentation",
      "authors": [
        "Francisco Vargas",
        "Alejandro González Coene",
        "Gaston Escalante",
        "Exequiel Lobón",
        "Manuel Pulido"
      ],
      "abstract": "The extraction of information about traffic accidents from legal documents is\ncrucial for quantifying insurance company costs. Extracting entities such as\npercentages of physical and/or psychological disability and the involved\ncompensation amounts is a challenging process, even for experts, due to the\nsubtle arguments and reasoning in the court decision. A two-step procedure is\nproposed: first, segmenting the document identifying the most relevant\nsegments, and then extracting the entities. For text segmentation, two\nmethodologies are compared: a classic method based on regular expressions and a\nsecond approach that divides the document into blocks of n-tokens, which are\nthen vectorized using multilingual models for semantic searches\n(text-embedding-ada-002/MiniLM-L12-v2 ). Subsequently, large language models\n(LLaMA-2 7b, 70b, LLaMA-3 8b, and GPT-4 Turbo) are applied with prompting to\nthe selected segments for entity extraction. For the LLaMA models, fine-tuning\nis performed using LoRA. LLaMA-2 7b, even with zero temperature, shows a\nsignificant number of hallucinations in extractions which are an important\ncontention point for named entity extraction. This work shows that these\nhallucinations are substantially reduced after finetuning the model. The\nperformance of the methodology based on segment vectorization and subsequent\nuse of LLMs significantly surpasses the classic method which achieves an\naccuracy of 39.5%. Among open-source models, LLaMA-2 70B with finetuning\nachieves the highest accuracy 79.4%, surpassing its base version 61.7%.\nNotably, the base LLaMA-3 8B model already performs comparably to the finetuned\nLLaMA-2 70B model, achieving 76.6%, highlighting the rapid progress in model\ndevelopment. Meanwhile, GPT-4 Turbo achieves the highest accuracy at 86.1%.",
      "pdf_url": "http://arxiv.org/pdf/2506.08827v1",
      "published": "2025-06-10T14:17:12+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.08827v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "FreqPolicy: Efficient Flow-based Visuomotor Policy via Frequency Consistency",
      "authors": [
        "Yifei Su",
        "Ning Liu",
        "Dong Chen",
        "Zhen Zhao",
        "Kun Wu",
        "Meng Li",
        "Zhiyuan Xu",
        "Zhengping Che",
        "Jian Tang"
      ],
      "abstract": "Generative modeling-based visuomotor policies have been widely adopted in\nrobotic manipulation attributed to their ability to model multimodal action\ndistributions. However, the high inference cost of multi-step sampling limits\ntheir applicability in real-time robotic systems. To address this issue,\nexisting approaches accelerate the sampling process in generative\nmodeling-based visuomotor policies by adapting acceleration techniques\noriginally developed for image generation. Despite this progress, a major\ndistinction remains: image generation typically involves producing independent\nsamples without temporal dependencies, whereas robotic manipulation involves\ngenerating time-series action trajectories that require continuity and temporal\ncoherence. To effectively exploit temporal information in robotic manipulation,\nwe propose FreqPolicy, a novel approach that first imposes frequency\nconsistency constraints on flow-based visuomotor policies. Our work enables the\naction model to capture temporal structure effectively while supporting\nefficient, high-quality one-step action generation. We introduce a frequency\nconsistency constraint that enforces alignment of frequency-domain action\nfeatures across different timesteps along the flow, thereby promoting\nconvergence of one-step action generation toward the target distribution. In\naddition, we design an adaptive consistency loss to capture structural temporal\nvariations inherent in robotic manipulation tasks. We assess FreqPolicy on 53\ntasks across 3 simulation benchmarks, proving its superiority over existing\none-step action generators. We further integrate FreqPolicy into the\nvision-language-action (VLA) model and achieve acceleration without performance\ndegradation on the 40 tasks of Libero. Besides, we show efficiency and\neffectiveness in real-world robotic scenarios with an inference frequency\n93.5Hz. The code will be publicly available.",
      "pdf_url": "http://arxiv.org/pdf/2506.08822v1",
      "published": "2025-06-10T14:12:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.08822v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "Measuring Data Science Automation: A Survey of Evaluation Tools for AI Assistants and Agents",
      "authors": [
        "Irene Testini",
        "José Hernández-Orallo",
        "Lorenzo Pacchiardi"
      ],
      "abstract": "Data science aims to extract insights from data to support decision-making\nprocesses. Recently, Large Language Models (LLMs) are increasingly used as\nassistants for data science, by suggesting ideas, techniques and small code\nsnippets, or for the interpretation of results and reporting. Proper automation\nof some data-science activities is now promised by the rise of LLM agents,\ni.e., AI systems powered by an LLM equipped with additional affordances--such\nas code execution and knowledge bases--that can perform self-directed actions\nand interact with digital environments. In this paper, we survey the evaluation\nof LLM assistants and agents for data science. We find (1) a dominant focus on\na small subset of goal-oriented activities, largely ignoring data management\nand exploratory activities; (2) a concentration on pure assistance or fully\nautonomous agents, without considering intermediate levels of human-AI\ncollaboration; and (3) an emphasis on human substitution, therefore neglecting\nthe possibility of higher levels of automation thanks to task transformation.",
      "pdf_url": "http://arxiv.org/pdf/2506.08800v1",
      "published": "2025-06-10T13:47:22+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.08800v1",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Towards Biosignals-Free Autonomous Prosthetic Hand Control via Imitation Learning",
      "authors": [
        "Kaijie Shi",
        "Wanglong Lu",
        "Hanli Zhao",
        "Vinicius Prado da Fonseca",
        "Ting Zou",
        "Xianta Jiang"
      ],
      "abstract": "Limb loss affects millions globally, impairing physical function and reducing\nquality of life. Most traditional surface electromyographic (sEMG) and\nsemi-autonomous methods require users to generate myoelectric signals for each\ncontrol, imposing physically and mentally taxing demands. This study aims to\ndevelop a fully autonomous control system that enables a prosthetic hand to\nautomatically grasp and release objects of various shapes using only a camera\nattached to the wrist. By placing the hand near an object, the system will\nautomatically execute grasping actions with a proper grip force in response to\nthe hand's movements and the environment. To release the object being grasped,\njust naturally place the object close to the table and the system will\nautomatically open the hand. Such a system would provide individuals with limb\nloss with a very easy-to-use prosthetic control interface and greatly reduce\nmental effort while using. To achieve this goal, we developed a teleoperation\nsystem to collect human demonstration data for training the prosthetic hand\ncontrol model using imitation learning, which mimics the prosthetic hand\nactions from human. Through training the model using only a few objects' data\nfrom one single participant, we have shown that the imitation learning\nalgorithm can achieve high success rates, generalizing to more individuals and\nunseen objects with a variation of weights. The demonstrations are available at\n\\href{https://sites.google.com/view/autonomous-prosthetic-hand}{https://sites.google.com/view/autonomous-prosthetic-hand}",
      "pdf_url": "http://arxiv.org/pdf/2506.08795v1",
      "published": "2025-06-10T13:44:08+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.08795v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "Do Generative AI Tools Ensure Green Code? An Investigative Study",
      "authors": [
        "Samarth Sikand",
        "Rohit Mehra",
        "Vibhu Saujanya Sharma",
        "Vikrant Kaulgud",
        "Sanjay Podder",
        "Adam P. Burden"
      ],
      "abstract": "Software sustainability is emerging as a primary concern, aiming to optimize\nresource utilization, minimize environmental impact, and promote a greener,\nmore resilient digital ecosystem. The sustainability or \"greenness\" of software\nis typically determined by the adoption of sustainable coding practices. With a\nmaturing ecosystem around generative AI, many software developers now rely on\nthese tools to generate code using natural language prompts. Despite their\npotential advantages, there is a significant lack of studies on the\nsustainability aspects of AI-generated code. Specifically, how environmentally\nfriendly is the AI-generated code based upon its adoption of sustainable coding\npractices? In this paper, we present the results of an early investigation into\nthe sustainability aspects of AI-generated code across three popular generative\nAI tools - ChatGPT, BARD, and Copilot. The results highlight the default\nnon-green behavior of tools for generating code, across multiple rules and\nscenarios. It underscores the need for further in-depth investigations and\neffective remediation strategies.",
      "pdf_url": "http://arxiv.org/pdf/2506.08790v1",
      "published": "2025-06-10T13:38:41+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.08790v1",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CY"
      ]
    },
    {
      "title": "POLARON: Precision-aware On-device Learning and Adaptive Runtime-cONfigurable AI acceleration",
      "authors": [
        "Mukul Lokhande",
        "Santosh Kumar Vishvakarma"
      ],
      "abstract": "The increasing complexity of AI models requires flexible hardware capable of\nsupporting diverse precision formats, particularly for energy-constrained edge\nplatforms. This work presents PARV-CE, a SIMD-enabled, multi-precision MAC\nengine that performs efficient multiply-accumulate operations using a unified\ndata-path for 4/8/16-bit fixed-point, floating point, and posit formats. The\narchitecture incorporates a layer adaptive precision strategy to align\ncomputational accuracy with workload sensitivity, optimizing both performance\nand energy usage. PARV-CE integrates quantization-aware execution with a\nreconfigurable SIMD pipeline, enabling high-throughput processing with minimal\noverhead through hardware-software co-design. The results demonstrate up to 2x\nimprovement in PDP and 3x reduction in resource usage compared to SoTA designs,\nwhile retaining accuracy within 1.8% FP32 baseline. The architecture supports\nboth on-device training and inference across a range of workloads, including\nDNNs, RNNs, RL, and Transformer models. The empirical analysis establish PARVCE\nincorporated POLARON as a scalable and energy-efficient solution for\nprecision-adaptive AI acceleration at edge.",
      "pdf_url": "http://arxiv.org/pdf/2506.08785v1",
      "published": "2025-06-10T13:33:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.08785v1",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.CC",
        "eess.IV"
      ]
    },
    {
      "title": "Multimodal Representation Alignment for Cross-modal Information Retrieval",
      "authors": [
        "Fan Xu",
        "Luis A. Leiva"
      ],
      "abstract": "Different machine learning models can represent the same underlying concept\nin different ways. This variability is particularly valuable for in-the-wild\nmultimodal retrieval, where the objective is to identify the corresponding\nrepresentation in one modality given another modality as input. This challenge\ncan be effectively framed as a feature alignment problem. For example, given a\nsentence encoded by a language model, retrieve the most semantically aligned\nimage based on features produced by an image encoder, or vice versa. In this\nwork, we first investigate the geometric relationships between visual and\ntextual embeddings derived from both vision-language models and combined\nunimodal models. We then align these representations using four standard\nsimilarity metrics as well as two learned ones, implemented via neural\nnetworks. Our findings indicate that the Wasserstein distance can serve as an\ninformative measure of the modality gap, while cosine similarity consistently\noutperforms alternative metrics in feature alignment tasks. Furthermore, we\nobserve that conventional architectures such as multilayer perceptrons are\ninsufficient for capturing the complex interactions between image and text\nrepresentations. Our study offers novel insights and practical considerations\nfor researchers working in multimodal information retrieval, particularly in\nreal-world, cross-modal applications.",
      "pdf_url": "http://arxiv.org/pdf/2506.08774v1",
      "published": "2025-06-10T13:16:26+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.08774v1",
      "categories": [
        "cs.IR",
        "cs.AI"
      ]
    },
    {
      "title": "Paths to Causality: Finding Informative Subgraphs Within Knowledge Graphs for Knowledge-Based Causal Discovery",
      "authors": [
        "Yuni Susanti",
        "Michael Färber"
      ],
      "abstract": "Inferring causal relationships between variable pairs is crucial for\nunderstanding multivariate interactions in complex systems. Knowledge-based\ncausal discovery -- which involves inferring causal relationships by reasoning\nover the metadata of variables (e.g., names or textual context) -- offers a\ncompelling alternative to traditional methods that rely on observational data.\nHowever, existing methods using Large Language Models (LLMs) often produce\nunstable and inconsistent results, compromising their reliability for causal\ninference. To address this, we introduce a novel approach that integrates\nKnowledge Graphs (KGs) with LLMs to enhance knowledge-based causal discovery.\nOur approach identifies informative metapath-based subgraphs within KGs and\nfurther refines the selection of these subgraphs using Learning-to-Rank-based\nmodels. The top-ranked subgraphs are then incorporated into zero-shot prompts,\nimproving the effectiveness of LLMs in inferring the causal relationship.\nExtensive experiments on biomedical and open-domain datasets demonstrate that\nour method outperforms most baselines by up to 44.4 points in F1 scores,\nevaluated across diverse LLMs and KGs. Our code and datasets are available on\nGitHub: https://github.com/susantiyuni/path-to-causality",
      "pdf_url": "http://arxiv.org/pdf/2506.08771v1",
      "published": "2025-06-10T13:13:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.08771v1",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.IR",
        "cs.LG"
      ]
    },
    {
      "title": "Bayesian Inverse Physics for Neuro-Symbolic Robot Learning",
      "authors": [
        "Octavio Arriaga",
        "Rebecca Adam",
        "Melvin Laux",
        "Lisa Gutzeit",
        "Marco Ragni",
        "Jan Peters",
        "Frank Kirchner"
      ],
      "abstract": "Real-world robotic applications, from autonomous exploration to assistive\ntechnologies, require adaptive, interpretable, and data-efficient learning\nparadigms. While deep learning architectures and foundation models have driven\nsignificant advances in diverse robotic applications, they remain limited in\ntheir ability to operate efficiently and reliably in unknown and dynamic\nenvironments. In this position paper, we critically assess these limitations\nand introduce a conceptual framework for combining data-driven learning with\ndeliberate, structured reasoning. Specifically, we propose leveraging\ndifferentiable physics for efficient world modeling, Bayesian inference for\nuncertainty-aware decision-making, and meta-learning for rapid adaptation to\nnew tasks. By embedding physical symbolic reasoning within neural models,\nrobots could generalize beyond their training data, reason about novel\nsituations, and continuously expand their knowledge. We argue that such hybrid\nneuro-symbolic architectures are essential for the next generation of\nautonomous systems, and to this end, we provide a research roadmap to guide and\naccelerate their development.",
      "pdf_url": "http://arxiv.org/pdf/2506.08756v1",
      "published": "2025-06-10T12:53:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.08756v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "Factors affecting the in-context learning abilities of LLMs for dialogue state tracking",
      "authors": [
        "Pradyoth Hegde",
        "Santosh Kesiraju",
        "Jan Švec",
        "Šimon Sedláček",
        "Bolaji Yusuf",
        "Oldřich Plchot",
        "Deepak K T",
        "Jan Černocký"
      ],
      "abstract": "This study explores the application of in-context learning (ICL) to the\ndialogue state tracking (DST) problem and investigates the factors that\ninfluence its effectiveness. We use a sentence embedding based k-nearest\nneighbour method to retrieve the suitable demonstrations for ICL. The selected\ndemonstrations, along with the test samples, are structured within a template\nas input to the LLM. We then conduct a systematic study to analyse the impact\nof factors related to demonstration selection and prompt context on DST\nperformance. This work is conducted using the MultiWoZ2.4 dataset and focuses\nprimarily on the OLMo-7B-instruct, Mistral-7B-Instruct-v0.3, and\nLlama3.2-3B-Instruct models. Our findings provide several useful insights on\nin-context learning abilities of LLMs for dialogue state tracking.",
      "pdf_url": "http://arxiv.org/pdf/2506.08753v1",
      "published": "2025-06-10T12:46:26+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.08753v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "A Sample Efficient Conditional Independence Test in the Presence of Discretization",
      "authors": [
        "Boyang Sun",
        "Yu Yao",
        "Xinshuai Dong",
        "Zongfang Liu",
        "Tongliang Liu",
        "Yumou Qiu",
        "Kun Zhang"
      ],
      "abstract": "In many real-world scenarios, interested variables are often represented as\ndiscretized values due to measurement limitations. Applying Conditional\nIndependence (CI) tests directly to such discretized data, however, can lead to\nincorrect conclusions. To address this, recent advancements have sought to\ninfer the correct CI relationship between the latent variables through\nbinarizing observed data. However, this process inevitably results in a loss of\ninformation, which degrades the test's performance. Motivated by this, this\npaper introduces a sample-efficient CI test that does not rely on the\nbinarization process. We find that the independence relationships of latent\ncontinuous variables can be established by addressing an over-identifying\nrestriction problem with Generalized Method of Moments (GMM). Based on this\ninsight, we derive an appropriate test statistic and establish its asymptotic\ndistribution correctly reflecting CI by leveraging nodewise regression.\nTheoretical findings and Empirical results across various datasets demonstrate\nthat the superiority and effectiveness of our proposed test. Our code\nimplementation is provided in https://github.com/boyangaaaaa/DCT",
      "pdf_url": "http://arxiv.org/pdf/2506.08747v1",
      "published": "2025-06-10T12:41:26+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.08747v1",
      "categories": [
        "cs.AI",
        "stat.ML"
      ]
    },
    {
      "title": "Consistent Paths Lead to Truth: Self-Rewarding Reinforcement Learning for LLM Reasoning",
      "authors": [
        "Kongcheng Zhang",
        "Qi Yao",
        "Shunyu Liu",
        "Yingjie Wang",
        "Baisheng Lai",
        "Jieping Ye",
        "Mingli Song",
        "Dacheng Tao"
      ],
      "abstract": "Recent advances of Reinforcement Learning (RL) have highlighted its potential\nin complex reasoning tasks, yet effective training often relies on external\nsupervision, which limits the broader applicability. In this work, we propose a\nnovel self-rewarding reinforcement learning framework to enhance Large Language\nModel (LLM) reasoning by leveraging the consistency of intermediate reasoning\nstates across different reasoning trajectories. Our key insight is that correct\nresponses often exhibit consistent trajectory patterns in terms of model\nlikelihood: their intermediate reasoning states tend to converge toward their\nown final answers (high consistency) with minimal deviation toward other\ncandidates (low volatility). Inspired by this observation, we introduce CoVo,\nan intrinsic reward mechanism that integrates Consistency and Volatility via a\nrobust vector-space aggregation strategy, complemented by a curiosity bonus to\npromote diverse exploration. CoVo enables LLMs to perform RL in a\nself-rewarding manner, offering a scalable pathway for learning to reason\nwithout external supervision. Extensive experiments on diverse reasoning\nbenchmarks show that CoVo achieves performance comparable to or even surpassing\nsupervised RL. Our code is available at https://github.com/sastpg/CoVo.",
      "pdf_url": "http://arxiv.org/pdf/2506.08745v1",
      "published": "2025-06-10T12:40:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.08745v1",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Bridging RDF Knowledge Graphs with Graph Neural Networks for Semantically-Rich Recommender Systems",
      "authors": [
        "Michael Färber",
        "David Lamprecht",
        "Yuni Susanti"
      ],
      "abstract": "Graph Neural Networks (GNNs) have substantially advanced the field of\nrecommender systems. However, despite the creation of more than a thousand\nknowledge graphs (KGs) under the W3C standard RDF, their rich semantic\ninformation has not yet been fully leveraged in GNN-based recommender systems.\nTo address this gap, we propose a comprehensive integration of RDF KGs with\nGNNs that utilizes both the topological information from RDF object properties\nand the content information from RDF datatype properties. Our main focus is an\nin-depth evaluation of various GNNs, analyzing how different semantic feature\ninitializations and types of graph structure heterogeneity influence their\nperformance in recommendation tasks. Through experiments across multiple\nrecommendation scenarios involving multi-million-node RDF graphs, we\ndemonstrate that harnessing the semantic richness of RDF KGs significantly\nimproves recommender systems and lays the groundwork for GNN-based recommender\nsystems for the Linked Open Data cloud. The code and data are available on our\nGitHub repository: https://github.com/davidlamprecht/rdf-gnn-recommendation",
      "pdf_url": "http://arxiv.org/pdf/2506.08743v1",
      "published": "2025-06-10T12:38:24+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.08743v1",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.DB",
        "cs.LG"
      ]
    },
    {
      "title": "Societal AI Research Has Become Less Interdisciplinary",
      "authors": [
        "Dror Kris Markus",
        "Fabrizio Gilardi",
        "Daria Stetsenko"
      ],
      "abstract": "As artificial intelligence (AI) systems become deeply embedded in everyday\nlife, calls to align AI development with ethical and societal values have\nintensified. Interdisciplinary collaboration is often championed as a key\npathway for fostering such engagement. Yet it remains unclear whether\ninterdisciplinary research teams are actually leading this shift in practice.\nThis study analyzes over 100,000 AI-related papers published on ArXiv between\n2014 and 2024 to examine how ethical values and societal concerns are\nintegrated into technical AI research. We develop a classifier to identify\nsocietal content and measure the extent to which research papers express these\nconsiderations. We find a striking shift: while interdisciplinary teams remain\nmore likely to produce societally-oriented research, computer science-only\nteams now account for a growing share of the field's overall societal output.\nThese teams are increasingly integrating societal concerns into their papers\nand tackling a wide range of domains - from fairness and safety to healthcare\nand misinformation. These findings challenge common assumptions about the\ndrivers of societal AI and raise important questions. First, what are the\nimplications for emerging understandings of AI safety and governance if most\nsocietally-oriented research is being undertaken by exclusively technical\nteams? Second, for scholars in the social sciences and humanities: in a\ntechnical field increasingly responsive to societal demands, what distinctive\nperspectives can we still offer to help shape the future of AI?",
      "pdf_url": "http://arxiv.org/pdf/2506.08738v2",
      "published": "2025-06-10T12:34:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.08738v2",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ]
    }
  ]
}