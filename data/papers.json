{
  "last_updated": "2025-04-03T00:47:29.124633",
  "papers": [
    {
      "title": "RIG: Synergizing Reasoning and Imagination in End-to-End Generalist Policy",
      "authors": [
        "Zhonghan Zhao",
        "Wenwei Zhang",
        "Haian Huang",
        "Kuikun Liu",
        "Jianfei Gao",
        "Gaoang Wang",
        "Kai Chen"
      ],
      "abstract": "Reasoning before action and imagining potential outcomes (i.e., world models)\nare essential for embodied agents operating in complex open-world environments.\nYet, prior work either incorporates only one of these abilities in an\nend-to-end agent or integrates multiple specialized models into an agent\nsystem, limiting the learning efficiency and generalization of the policy.\nThus, this paper makes the first attempt to synergize Reasoning and Imagination\nin an end-to-end Generalist policy, termed RIG. To train RIG in an end-to-end\nmanner, we construct a data pipeline that progressively integrates and enriches\nthe content of imagination and reasoning in the trajectories collected from\nexisting agents. The joint learning of reasoning and next image generation\nexplicitly models the inherent correlation between reasoning, action, and\ndynamics of environments, and thus exhibits more than $17\\times$ sample\nefficiency improvements and generalization in comparison with previous works.\nDuring inference, RIG first reasons about the next action, produces potential\naction, and then predicts the action outcomes, which offers the agent a chance\nto review and self-correct based on the imagination before taking real actions.\nExperimental results show that the synergy of reasoning and imagination not\nonly improves the robustness, generalization, and interoperability of\ngeneralist policy but also enables test-time scaling to enhance overall\nperformance.",
      "pdf_url": "http://arxiv.org/pdf/2503.24388v1",
      "published": "2025-03-31T17:59:52+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.24388v1",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG"
      ]
    },
    {
      "title": "UniOcc: A Unified Benchmark for Occupancy Forecasting and Prediction in Autonomous Driving",
      "authors": [
        "Yuping Wang",
        "Xiangyu Huang",
        "Xiaokang Sun",
        "Mingxuan Yan",
        "Shuo Xing",
        "Zhengzhong Tu",
        "Jiachen Li"
      ],
      "abstract": "We introduce UniOcc, a comprehensive, unified benchmark for occupancy\nforecasting (i.e., predicting future occupancies based on historical\ninformation) and current-frame occupancy prediction from camera images. UniOcc\nunifies data from multiple real-world datasets (i.e., nuScenes, Waymo) and\nhigh-fidelity driving simulators (i.e., CARLA, OpenCOOD), which provides 2D/3D\noccupancy labels with per-voxel flow annotations and support for cooperative\nautonomous driving. In terms of evaluation, unlike existing studies that rely\non suboptimal pseudo labels for evaluation, UniOcc incorporates novel metrics\nthat do not depend on ground-truth occupancy, enabling robust assessment of\nadditional aspects of occupancy quality. Through extensive experiments on\nstate-of-the-art models, we demonstrate that large-scale, diverse training data\nand explicit flow information significantly enhance occupancy prediction and\nforecasting performance.",
      "pdf_url": "http://arxiv.org/pdf/2503.24381v1",
      "published": "2025-03-31T17:59:24+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.24381v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MA",
        "cs.RO"
      ]
    },
    {
      "title": "Any2Caption:Interpreting Any Condition to Caption for Controllable Video Generation",
      "authors": [
        "Shengqiong Wu",
        "Weicai Ye",
        "Jiahao Wang",
        "Quande Liu",
        "Xintao Wang",
        "Pengfei Wan",
        "Di Zhang",
        "Kun Gai",
        "Shuicheng Yan",
        "Hao Fei",
        "Tat-Seng Chua"
      ],
      "abstract": "To address the bottleneck of accurate user intent interpretation within the\ncurrent video generation community, we present Any2Caption, a novel framework\nfor controllable video generation under any condition. The key idea is to\ndecouple various condition interpretation steps from the video synthesis step.\nBy leveraging modern multimodal large language models (MLLMs), Any2Caption\ninterprets diverse inputs--text, images, videos, and specialized cues such as\nregion, motion, and camera poses--into dense, structured captions that offer\nbackbone video generators with better guidance. We also introduce Any2CapIns, a\nlarge-scale dataset with 337K instances and 407K conditions for\nany-condition-to-caption instruction tuning. Comprehensive evaluations\ndemonstrate significant improvements of our system in controllability and video\nquality across various aspects of existing video generation models. Project\nPage: https://sqwu.top/Any2Cap/",
      "pdf_url": "http://arxiv.org/pdf/2503.24379v1",
      "published": "2025-03-31T17:59:01+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.24379v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "ACPBench Hard: Unrestrained Reasoning about Action, Change, and Planning",
      "authors": [
        "Harsha Kokel",
        "Michael Katz",
        "Kavitha Srinivas",
        "Shirin Sohrabi"
      ],
      "abstract": "The ACPBench dataset provides atomic reasoning tasks required for efficient\nplanning. The dataset is aimed at distilling the complex plan generation task\ninto separate atomic reasoning tasks in their easiest possible form, boolean or\nmultiple-choice questions, where the model has to choose the right answer from\nthe provided options. While the aim of ACPBench is to test the simplest form of\nreasoning about action and change, when tasked with planning, a model does not\ntypically have options to choose from and thus the reasoning required for\nplanning dictates an open-ended, generative form for these tasks. To that end,\nwe introduce ACPBench Hard, a generative version of ACPBench, with open-ended\nquestions which the model needs to answer. Models that perform well on these\ntasks could in principle be integrated into a planner or be used directly as a\npolicy. We discuss the complexity of these tasks as well as the complexity of\nvalidating the correctness of their answers and present validation algorithms\nfor each task. Equipped with these validators, we test the performance of a\nvariety of models on our tasks and find that for most of these tasks the\nperformance of even the largest models is still subpar. Our experiments show\nthat no model outperforms another in these tasks and with a few exceptions all\ntested language models score below 65%, indicating that even the current\nfrontier language models have a long way to go before they can reliably reason\nabout planning. In fact, even the so-called reasoning models struggle with\nsolving these reasoning tasks. ACPBench Hard collection is available at the\nfollowing link: https://ibm.github.io/ACPBench",
      "pdf_url": "http://arxiv.org/pdf/2503.24378v1",
      "published": "2025-03-31T17:58:25+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.24378v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Harnessing the Reasoning Economy: A Survey of Efficient Reasoning for Large Language Models",
      "authors": [
        "Rui Wang",
        "Hongru Wang",
        "Boyang Xue",
        "Jianhui Pang",
        "Shudong Liu",
        "Yi Chen",
        "Jiahao Qiu",
        "Derek Fai Wong",
        "Heng Ji",
        "Kam-Fai Wong"
      ],
      "abstract": "Recent advancements in Large Language Models (LLMs) have significantly\nenhanced their ability to perform complex reasoning tasks, transitioning from\nfast and intuitive thinking (System 1) to slow and deep reasoning (System 2).\nWhile System 2 reasoning improves task accuracy, it often incurs substantial\ncomputational costs due to its slow thinking nature and inefficient or\nunnecessary reasoning behaviors. In contrast, System 1 reasoning is\ncomputationally efficient but leads to suboptimal performance. Consequently, it\nis critical to balance the trade-off between performance (benefits) and\ncomputational costs (budgets), giving rise to the concept of reasoning economy.\nIn this survey, we provide a comprehensive analysis of reasoning economy in\nboth the post-training and test-time inference stages of LLMs, encompassing i)\nthe cause of reasoning inefficiency, ii) behavior analysis of different\nreasoning patterns, and iii) potential solutions to achieve reasoning economy.\nBy offering actionable insights and highlighting open challenges, we aim to\nshed light on strategies for improving the reasoning economy of LLMs, thereby\nserving as a valuable resource for advancing research in this evolving area. We\nalso provide a public repository to continually track developments in this\nfast-evolving field.",
      "pdf_url": "http://arxiv.org/pdf/2503.24377v1",
      "published": "2025-03-31T17:58:07+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.24377v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Exploring the Effect of Reinforcement Learning on Video Understanding: Insights from SEED-Bench-R1",
      "authors": [
        "Yi Chen",
        "Yuying Ge",
        "Rui Wang",
        "Yixiao Ge",
        "Lu Qiu",
        "Ying Shan",
        "Xihui Liu"
      ],
      "abstract": "Recent advancements in Chain of Thought (COT) generation have significantly\nimproved the reasoning capabilities of Large Language Models (LLMs), with\nreinforcement learning (RL) emerging as an effective post-training approach.\nMultimodal Large Language Models (MLLMs) inherit this reasoning potential but\nremain underexplored in tasks requiring both perception and logical reasoning.\nTo address this, we introduce SEED-Bench-R1, a benchmark designed to\nsystematically evaluate post-training methods for MLLMs in video understanding.\nIt includes intricate real-world videos and complex everyday planning tasks in\nthe format of multiple-choice questions, requiring sophisticated perception and\nreasoning. SEED-Bench-R1 assesses generalization through a three-level\nhierarchy: in-distribution, cross-environment, and cross-environment-task\nscenarios, equipped with a large-scale training dataset with easily verifiable\nground-truth answers. Using Qwen2-VL-Instruct-7B as a base model, we compare RL\nwith supervised fine-tuning (SFT), demonstrating RL's data efficiency and\nsuperior performance on both in-distribution and out-of-distribution tasks,\neven outperforming SFT on general video understanding benchmarks like\nLongVideoBench. Our detailed analysis reveals that RL enhances visual\nperception but often produces less logically coherent reasoning chains. We\nidentify key limitations such as inconsistent reasoning and overlooked visual\ncues, and suggest future improvements in base model reasoning, reward modeling,\nand RL robustness against noisy signals.",
      "pdf_url": "http://arxiv.org/pdf/2503.24376v1",
      "published": "2025-03-31T17:55:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.24376v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    },
    {
      "title": "Effectively Controlling Reasoning Models through Thinking Intervention",
      "authors": [
        "Tong Wu",
        "Chong Xiang",
        "Jiachen T. Wang",
        "Prateek Mittal"
      ],
      "abstract": "Reasoning-enhanced large language models (LLMs) explicitly generate\nintermediate reasoning steps prior to generating final answers, helping the\nmodel excel in complex problem-solving. In this paper, we demonstrate that this\nemerging generation framework offers a unique opportunity for more fine-grained\ncontrol over model behavior. We propose Thinking Intervention, a novel paradigm\ndesigned to explicitly guide the internal reasoning processes of LLMs by\nstrategically inserting or revising specific thinking tokens. We conduct\ncomprehensive evaluations across multiple tasks, including instruction\nfollowing on IFEval, instruction hierarchy on SEP, and safety alignment on\nXSTest and SORRY-Bench. Our results demonstrate that Thinking Intervention\nsignificantly outperforms baseline prompting approaches, achieving up to 6.7%\naccuracy gains in instruction-following scenarios, 15.4% improvements in\nreasoning about instruction hierarchies, and a 40.0% increase in refusal rates\nfor unsafe prompts using open-source DeepSeek R1 models. Overall, our work\nopens a promising new research avenue for controlling reasoning LLMs.",
      "pdf_url": "http://arxiv.org/pdf/2503.24370v1",
      "published": "2025-03-31T17:50:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.24370v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Which LIME should I trust? Concepts, Challenges, and Solutions",
      "authors": [
        "Patrick Knab",
        "Sascha Marton",
        "Udo Schlegel",
        "Christian Bartelt"
      ],
      "abstract": "As neural networks become dominant in essential systems, Explainable\nArtificial Intelligence (XAI) plays a crucial role in fostering trust and\ndetecting potential misbehavior of opaque models. LIME (Local Interpretable\nModel-agnostic Explanations) is among the most prominent model-agnostic\napproaches, generating explanations by approximating the behavior of black-box\nmodels around specific instances. Despite its popularity, LIME faces challenges\nrelated to fidelity, stability, and applicability to domain-specific problems.\nNumerous adaptations and enhancements have been proposed to address these\nissues, but the growing number of developments can be overwhelming,\ncomplicating efforts to navigate LIME-related research. To the best of our\nknowledge, this is the first survey to comprehensively explore and collect\nLIME's foundational concepts and known limitations. We categorize and compare\nits various enhancements, offering a structured taxonomy based on intermediate\nsteps and key issues. Our analysis provides a holistic overview of advancements\nin LIME, guiding future research and helping practitioners identify suitable\napproaches. Additionally, we provide a continuously updated interactive website\n(https://patrick-knab.github.io/which-lime-to-trust/), offering a concise and\naccessible overview of the survey.",
      "pdf_url": "http://arxiv.org/pdf/2503.24365v1",
      "published": "2025-03-31T17:44:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.24365v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Sim-and-Real Co-Training: A Simple Recipe for Vision-Based Robotic Manipulation",
      "authors": [
        "Abhiram Maddukuri",
        "Zhenyu Jiang",
        "Lawrence Yunliang Chen",
        "Soroush Nasiriany",
        "Yuqi Xie",
        "Yu Fang",
        "Wenqi Huang",
        "Zu Wang",
        "Zhenjia Xu",
        "Nikita Chernyadev",
        "Scott Reed",
        "Ken Goldberg",
        "Ajay Mandlekar",
        "Linxi Fan",
        "Yuke Zhu"
      ],
      "abstract": "Large real-world robot datasets hold great potential to train generalist\nrobot models, but scaling real-world human data collection is time-consuming\nand resource-intensive. Simulation has great potential in supplementing\nlarge-scale data, especially with recent advances in generative AI and\nautomated data generation tools that enable scalable creation of robot behavior\ndatasets. However, training a policy solely in simulation and transferring it\nto the real world often demands substantial human effort to bridge the reality\ngap. A compelling alternative is to co-train the policy on a mixture of\nsimulation and real-world datasets. Preliminary studies have recently shown\nthis strategy to substantially improve the performance of a policy over one\ntrained on a limited amount of real-world data. Nonetheless, the community\nlacks a systematic understanding of sim-and-real co-training and what it takes\nto reap the benefits of simulation data for real-robot learning. This work\npresents a simple yet effective recipe for utilizing simulation data to solve\nvision-based robotic manipulation tasks. We derive this recipe from\ncomprehensive experiments that validate the co-training strategy on various\nsimulation and real-world datasets. Using two domains--a robot arm and a\nhumanoid--across diverse tasks, we demonstrate that simulation data can enhance\nreal-world task performance by an average of 38%, even with notable differences\nbetween the simulation and real-world data. Videos and additional results can\nbe found at https://co-training.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2503.24361v1",
      "published": "2025-03-31T17:39:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.24361v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "SQuat: Subspace-orthogonal KV Cache Quantization",
      "authors": [
        "Hao Wang",
        "Ligong Han",
        "Kai Xu",
        "Akash Srivastava"
      ],
      "abstract": "The key-value (KV) cache accelerates LLMs decoding by storing KV tensors from\npreviously generated tokens. It reduces redundant computation at the cost of\nincreased memory usage. To mitigate this overhead, existing approaches compress\nKV tensors into lower-bit representations; however, quantization errors can\naccumulate as more tokens are generated, potentially resulting in undesired\noutputs. In this paper, we introduce SQuat (Subspace-orthogonal KV cache\nquantization). It first constructs a subspace spanned by query tensors to\ncapture the most critical task-related information. During key tensor\nquantization, it enforces that the difference between the (de)quantized and\noriginal keys remains orthogonal to this subspace, minimizing the impact of\nquantization errors on the attention mechanism's outputs. SQuat requires no\nmodel fine-tuning, no additional calibration dataset for offline learning, and\nis grounded in a theoretical framework we develop. Through numerical\nexperiments, we show that our method reduces peak memory by 2.17 to 2.82,\nimproves throughput by 2.45 to 3.60, and achieves more favorable benchmark\nscores than existing KV cache quantization algorithms.",
      "pdf_url": "http://arxiv.org/pdf/2503.24358v1",
      "published": "2025-03-31T17:37:32+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.24358v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.IT",
        "math.IT"
      ]
    },
    {
      "title": "ORAL: Prompting Your Large-Scale LoRAs via Conditional Recurrent Diffusion",
      "authors": [
        "Rana Muhammad Shahroz Khan",
        "Dongwen Tang",
        "Pingzhi Li",
        "Kai Wang",
        "Tianlong Chen"
      ],
      "abstract": "Parameter generation has emerged as a novel paradigm for neural network\ndevelopment, offering an alternative to traditional neural network training by\nsynthesizing high-quality model weights directly. In the context of Low-Rank\nAdaptation (LoRA) for evolving ($\\textit{i.e.}$, constantly updated) large\nlanguage models (LLMs), this approach promises efficient adaptation without\ncostly retraining. However, existing methods face critical limitations in\nsimultaneously achieving scalability and controllability. In this paper, we\nintroduce $\\texttt{ORAL}$, a novel $\\textbf{conditional recurrent diffusion}$\nframework that addresses these challenges. $\\texttt{ORAL}$ incorporates a novel\nconditioning mechanism that integrates model architecture and textual task\nspecifications, enabling the generation of task-specific LoRA parameters that\ncan seamlessly transfer across evolving foundation models. Our approach\nsuccessfully scales to billions-of-parameter LLMs and maintains\ncontrollability. Through extensive experiments across seven language tasks,\nfour vision tasks, and three multimodal tasks using five pre-trained LLMs, we\ndemonstrate that $\\texttt{ORAL}$ generates high-quality LoRA parameters that\nachieve comparable or superior performance to vanilla trained counterparts.",
      "pdf_url": "http://arxiv.org/pdf/2503.24354v1",
      "published": "2025-03-31T17:34:59+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.24354v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ]
    },
    {
      "title": "Contextual Preference Collaborative Measure Framework Based on Belief System",
      "authors": [
        "Hang Yu",
        "Wei Wei",
        "Zheng Tan",
        "Jing-lei Liu"
      ],
      "abstract": "To reduce the human intervention in the preference measure process,this\narticle proposes a preference collaborative measure framework based on an\nupdated belief system,which is also capable of improving the accuracy and\nefficiency of preferen-ce measure algorithms.Firstly,the distance of rules and\nthe average internal distance of rulesets are proposed for specifying the\nrelationship between the rules.For discovering the most representative\npreferences that are common in all users,namely common preference,a algorithm\nbased on average internal distance of ruleset,PRA algorithm,is proposed,which\naims to finish the discoveryprocess with minimum information loss\nrate.Furthermore,the concept of Common belief is proposed to update the belief\nsystem,and the common preferences are the evidences of updated belief\nsystem.Then,under the belief system,the proposed belief degree and deviation\ndegree are used to determine whether a rule confirms the belief system or not\nand classify the preference rules into two kinds(generalized or\npersonalized),and eventually filters out Top-K interesting rules relying on\nbelief degree and deviation degree.Based on above,a scalable interestingness\ncalculation framework that can apply various formulas is proposed for\naccurately calculating interestingness in different conditions.At last,IMCos\nalgorithm and IMCov algorithm are proposed as exemplars to verify the accuracy\nand efficiency of the framework by using weighted cosine similarity and\ncorrelation coefficients as belief degree.In experiments,the proposed\nalgorithms are compared to two state-of-the-art algorithms and the results show\nthat IMCos and IMCov outperform than the other two in most aspects.",
      "pdf_url": "http://arxiv.org/pdf/2503.24328v1",
      "published": "2025-03-31T17:17:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.24328v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Pro-Routing: Proactive Routing of Autonomous Multi-Capacity Robots for Pickup-and-Delivery Tasks",
      "authors": [
        "Daniel Garces",
        "Stephanie Gil"
      ],
      "abstract": "We consider a multi-robot setting, where we have a fleet of multi-capacity\nautonomous robots that must service spatially distributed pickup-and-delivery\nrequests with fixed maximum wait times. Requests can be either scheduled ahead\nof time or they can enter the system in real-time. In this setting, stability\nfor a routing policy is defined as the cost of the policy being uniformly\nbounded over time. Most previous work either solve the problem offline to\ntheoretically maintain stability or they consider dynamically arriving requests\nat the expense of the theoretical guarantees on stability. In this paper, we\naim to bridge this gap by proposing a novel proactive rollout-based routing\nframework that adapts to real-time demand while still provably maintaining the\nstability of the learned routing policy. We derive provable stability\nguarantees for our method by proposing a fleet sizing algorithm that obtains a\nsufficiently large fleet that ensures stability by construction. To validate\nour theoretical results, we consider a case study on real ride requests for\nHarvard's evening Van System. We also evaluate the performance of our framework\nusing the currently deployed smaller fleet size. In this smaller setup, we\ncompare against the currently deployed routing algorithm, greedy heuristics,\nand Monte-Carlo-Tree-Search-based algorithms. Our empirical results show that\nour framework maintains stability when we use the sufficiently large fleet size\nfound in our theoretical results. For the smaller currently deployed fleet\nsize, our method services 6% more requests than the closest baseline while\nreducing median passenger wait times by 33%.",
      "pdf_url": "http://arxiv.org/pdf/2503.24325v1",
      "published": "2025-03-31T17:14:07+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.24325v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.MA"
      ]
    },
    {
      "title": "BEATS: Bias Evaluation and Assessment Test Suite for Large Language Models",
      "authors": [
        "Alok Abhishek",
        "Lisa Erickson",
        "Tushar Bandopadhyay"
      ],
      "abstract": "In this research, we introduce BEATS, a novel framework for evaluating Bias,\nEthics, Fairness, and Factuality in Large Language Models (LLMs). Building upon\nthe BEATS framework, we present a bias benchmark for LLMs that measure\nperformance across 29 distinct metrics. These metrics span a broad range of\ncharacteristics, including demographic, cognitive, and social biases, as well\nas measures of ethical reasoning, group fairness, and factuality related\nmisinformation risk. These metrics enable a quantitative assessment of the\nextent to which LLM generated responses may perpetuate societal prejudices that\nreinforce or expand systemic inequities. To achieve a high score on this\nbenchmark a LLM must show very equitable behavior in their responses, making it\na rigorous standard for responsible AI evaluation. Empirical results based on\ndata from our experiment show that, 37.65\\% of outputs generated by industry\nleading models contained some form of bias, highlighting a substantial risk of\nusing these models in critical decision making systems. BEATS framework and\nbenchmark offer a scalable and statistically rigorous methodology to benchmark\nLLMs, diagnose factors driving biases, and develop mitigation strategies. With\nthe BEATS framework, our goal is to help the development of more socially\nresponsible and ethically aligned AI models.",
      "pdf_url": "http://arxiv.org/pdf/2503.24310v1",
      "published": "2025-03-31T16:56:52+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.24310v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "68T01 (Primary), 68T50 (Secondary)",
        "I.2.0; I.2.7"
      ]
    },
    {
      "title": "A Systematic Evaluation of LLM Strategies for Mental Health Text Analysis: Fine-tuning vs. Prompt Engineering vs. RAG",
      "authors": [
        "Arshia Kermani",
        "Veronica Perez-Rosas",
        "Vangelis Metsis"
      ],
      "abstract": "This study presents a systematic comparison of three approaches for the\nanalysis of mental health text using large language models (LLMs): prompt\nengineering, retrieval augmented generation (RAG), and fine-tuning. Using LLaMA\n3, we evaluate these approaches on emotion classification and mental health\ncondition detection tasks across two datasets. Fine-tuning achieves the highest\naccuracy (91% for emotion classification, 80% for mental health conditions) but\nrequires substantial computational resources and large training sets, while\nprompt engineering and RAG offer more flexible deployment with moderate\nperformance (40-68% accuracy). Our findings provide practical insights for\nimplementing LLM-based solutions in mental health applications, highlighting\nthe trade-offs between accuracy, computational requirements, and deployment\nflexibility.",
      "pdf_url": "http://arxiv.org/pdf/2503.24307v1",
      "published": "2025-03-31T16:54:04+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.24307v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ]
    },
    {
      "title": "Evaluating machine learning models for predicting pesticides toxicity to honey bees",
      "authors": [
        "Jakub Adamczyk",
        "Jakub Poziemski",
        "Pawel Siedlecki"
      ],
      "abstract": "Small molecules play a critical role in the biomedical, environmental, and\nagrochemical domains, each with distinct physicochemical requirements and\nsuccess criteria. Although biomedical research benefits from extensive datasets\nand established benchmarks, agrochemical data remain scarce, particularly with\nrespect to species-specific toxicity. This work focuses on ApisTox, the most\ncomprehensive dataset of experimentally validated chemical toxicity to the\nhoney bee (Apis mellifera), an ecologically vital pollinator. We evaluate\nApisTox using a diverse suite of machine learning approaches, including\nmolecular fingerprints, graph kernels, and graph neural networks, as well as\npretrained models. Comparative analysis with medicinal datasets from the\nMoleculeNet benchmark reveals that ApisTox represents a distinct chemical\nspace. Performance degradation on non-medicinal datasets, such as ApisTox,\ndemonstrates their limited generalizability of current state-of-the-art\nalgorithms trained solely on biomedical data. Our study highlights the need for\nmore diverse datasets and for targeted model development geared toward the\nagrochemical domain.",
      "pdf_url": "http://arxiv.org/pdf/2503.24305v2",
      "published": "2025-03-31T16:51:12+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.24305v2",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Shape Expressions with Inheritance",
      "authors": [
        "Iovka Boneva",
        "Jose Emilio Labra Gayo",
        "Eric Prud'hommeaux",
        "Katherine Thornton",
        "Andra Waagmeester"
      ],
      "abstract": "We formally introduce an inheritance mechanism for the Shape Expressions\nlanguage (ShEx). It is inspired by inheritance in object-oriented programming\nlanguages, and provides similar advantages such as reuse, modularity, and more\nflexible data modelling. Using an example, we explain the main features of the\ninheritance mechanism. We present its syntax and formal semantics. The\nsemantics is an extension of the semantics of ShEx 2.1. It also directly yields\na validation algorithm as an extension of the previous ShEx validation\nalgorithms, while maintaining the same algorithmic complexity.",
      "pdf_url": "http://arxiv.org/pdf/2503.24299v1",
      "published": "2025-03-31T16:42:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.24299v1",
      "categories": [
        "cs.DB",
        "cs.AI"
      ]
    },
    {
      "title": "Value of Information-based Deceptive Path Planning Under Adversarial Interventions",
      "authors": [
        "Wesley A. Suttle",
        "Jesse Milzman",
        "Mustafa O. Karabag",
        "Brian M. Sadler",
        "Ufuk Topcu"
      ],
      "abstract": "Existing methods for deceptive path planning (DPP) address the problem of\ndesigning paths that conceal their true goal from a passive, external observer.\nSuch methods do not apply to problems where the observer has the ability to\nperform adversarial interventions to impede the path planning agent. In this\npaper, we propose a novel Markov decision process (MDP)-based model for the DPP\nproblem under adversarial interventions and develop new value of information\n(VoI) objectives to guide the design of DPP policies. Using the VoI objectives\nwe propose, path planning agents deceive the adversarial observer into choosing\nsuboptimal interventions by selecting trajectories that are of low\ninformational value to the observer. Leveraging connections to the linear\nprogramming theory for MDPs, we derive computationally efficient solution\nmethods for synthesizing policies for performing DPP under adversarial\ninterventions. In our experiments, we illustrate the effectiveness of the\nproposed solution method in achieving deceptiveness under adversarial\ninterventions and demonstrate the superior performance of our approach to both\nexisting DPP methods and conservative path planning approaches on illustrative\ngridworld problems.",
      "pdf_url": "http://arxiv.org/pdf/2503.24284v1",
      "published": "2025-03-31T16:31:29+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.24284v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ]
    },
    {
      "title": "AutoEval: Autonomous Evaluation of Generalist Robot Manipulation Policies in the Real World",
      "authors": [
        "Zhiyuan Zhou",
        "Pranav Atreya",
        "You Liang Tan",
        "Karl Pertsch",
        "Sergey Levine"
      ],
      "abstract": "Scalable and reproducible policy evaluation has been a long-standing\nchallenge in robot learning. Evaluations are critical to assess progress and\nbuild better policies, but evaluation in the real world, especially at a scale\nthat would provide statistically reliable results, is costly in terms of human\ntime and hard to obtain. Evaluation of increasingly generalist robot policies\nrequires an increasingly diverse repertoire of evaluation environments, making\nthe evaluation bottleneck even more pronounced. To make real-world evaluation\nof robotic policies more practical, we propose AutoEval, a system to\nautonomously evaluate generalist robot policies around the clock with minimal\nhuman intervention. Users interact with AutoEval by submitting evaluation jobs\nto the AutoEval queue, much like how software jobs are submitted with a cluster\nscheduling system, and AutoEval will schedule the policies for evaluation\nwithin a framework supplying automatic success detection and automatic scene\nresets. We show that AutoEval can nearly fully eliminate human involvement in\nthe evaluation process, permitting around the clock evaluations, and the\nevaluation results correspond closely to ground truth evaluations conducted by\nhand. To facilitate the evaluation of generalist policies in the robotics\ncommunity, we provide public access to multiple AutoEval scenes in the popular\nBridgeData robot setup with WidowX robot arms. In the future, we hope that\nAutoEval scenes can be set up across institutions to form a diverse and\ndistributed evaluation network.",
      "pdf_url": "http://arxiv.org/pdf/2503.24278v1",
      "published": "2025-03-31T16:23:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.24278v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "Evaluating and Designing Sparse Autoencoders by Approximating Quasi-Orthogonality",
      "authors": [
        "Sewoong Lee",
        "Adam Davies",
        "Marc E. Canby",
        "Julia Hockenmaier"
      ],
      "abstract": "Sparse autoencoders (SAEs) have emerged as a workhorse of modern mechanistic\ninterpretability, but leading SAE approaches with top-$k$ style activation\nfunctions lack theoretical grounding for selecting the hyperparameter $k$. SAEs\nare based on the linear representation hypothesis (LRH), which assumes that the\nrepresentations of large language models (LLMs) are linearly encoded, and the\nsuperposition hypothesis (SH), which states that there can be more features in\nthe model than its dimensionality. We show that, based on the formal\ndefinitions of the LRH and SH, the magnitude of sparse feature vectors (the\nlatent representations learned by SAEs of the dense embeddings of LLMs) can be\napproximated using their corresponding dense vector with a closed-form error\nbound. To visualize this, we propose the ZF plot, which reveals a previously\nunknown relationship between LLM hidden embeddings and SAE feature vectors,\nallowing us to make the first empirical measurement of the extent to which\nfeature vectors of pre-trained SAEs are over- or under-activated for a given\ninput. Correspondingly, we introduce Approximate Feature Activation (AFA),\nwhich approximates the magnitude of the ground-truth sparse feature vector, and\npropose a new evaluation metric derived from AFA to assess the alignment\nbetween inputs and activations. We also leverage AFA to introduce a novel SAE\narchitecture, the top-AFA SAE, leading to SAEs that: (a) are more in line with\ntheoretical justifications; and (b) obviate the need to tune SAE sparsity\nhyperparameters. Finally, we empirically demonstrate that top-AFA SAEs achieve\nreconstruction loss comparable to that of state-of-the-art top-k SAEs, without\nrequiring the hyperparameter $k$ to be tuned. Our code is available at:\nhttps://github.com/SewoongLee/top-afa-sae.",
      "pdf_url": "http://arxiv.org/pdf/2503.24277v1",
      "published": "2025-03-31T16:22:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.24277v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Visual Acoustic Fields",
      "authors": [
        "Yuelei Li",
        "Hyunjin Kim",
        "Fangneng Zhan",
        "Ri-Zhao Qiu",
        "Mazeyu Ji",
        "Xiaojun Shan",
        "Xueyan Zou",
        "Paul Liang",
        "Hanspeter Pfister",
        "Xiaolong Wang"
      ],
      "abstract": "Objects produce different sounds when hit, and humans can intuitively infer\nhow an object might sound based on its appearance and material properties.\nInspired by this intuition, we propose Visual Acoustic Fields, a framework that\nbridges hitting sounds and visual signals within a 3D space using 3D Gaussian\nSplatting (3DGS). Our approach features two key modules: sound generation and\nsound localization. The sound generation module leverages a conditional\ndiffusion model, which takes multiscale features rendered from a\nfeature-augmented 3DGS to generate realistic hitting sounds. Meanwhile, the\nsound localization module enables querying the 3D scene, represented by the\nfeature-augmented 3DGS, to localize hitting positions based on the sound\nsources. To support this framework, we introduce a novel pipeline for\ncollecting scene-level visual-sound sample pairs, achieving alignment between\ncaptured images, impact locations, and corresponding sounds. To the best of our\nknowledge, this is the first dataset to connect visual and acoustic signals in\na 3D context. Extensive experiments on our dataset demonstrate the\neffectiveness of Visual Acoustic Fields in generating plausible impact sounds\nand accurately localizing impact sources. Our project page is at\nhttps://yuelei0428.github.io/projects/Visual-Acoustic-Fields/.",
      "pdf_url": "http://arxiv.org/pdf/2503.24270v2",
      "published": "2025-03-31T16:16:10+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.24270v2",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "New Statistical Framework for Extreme Error Probability in High-Stakes Domains for Reliable Machine Learning",
      "authors": [
        "Umberto Michelucci",
        "Francesca Venturini"
      ],
      "abstract": "Machine learning is vital in high-stakes domains, yet conventional validation\nmethods rely on averaging metrics like mean squared error (MSE) or mean\nabsolute error (MAE), which fail to quantify extreme errors. Worst-case\nprediction failures can have substantial consequences, but current frameworks\nlack statistical foundations for assessing their probability. In this work a\nnew statistical framework, based on Extreme Value Theory (EVT), is presented\nthat provides a rigorous approach to estimating worst-case failures. Applying\nEVT to synthetic and real-world datasets, this method is shown to enable robust\nestimation of catastrophic failure probabilities, overcoming the fundamental\nlimitations of standard cross-validation. This work establishes EVT as a\nfundamental tool for assessing model reliability, ensuring safer AI deployment\nin new technologies where uncertainty quantification is central to\ndecision-making or scientific analysis.",
      "pdf_url": "http://arxiv.org/pdf/2503.24262v1",
      "published": "2025-03-31T16:08:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.24262v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME",
        "stat.ML"
      ]
    },
    {
      "title": "Beyond a Single Mode: GAN Ensembles for Diverse Medical Data Generation",
      "authors": [
        "Lorenzo Tronchin",
        "Tommy LÃ¶fstedt",
        "Paolo Soda",
        "Valerio Guarrasi"
      ],
      "abstract": "The advancement of generative AI, particularly in medical imaging, confronts\nthe trilemma of ensuring high fidelity, diversity, and efficiency in synthetic\ndata generation. While Generative Adversarial Networks (GANs) have shown\npromise across various applications, they still face challenges like mode\ncollapse and insufficient coverage of real data distributions. This work\nexplores the use of GAN ensembles to overcome these limitations, specifically\nin the context of medical imaging. By solving a multi-objective optimisation\nproblem that balances fidelity and diversity, we propose a method for selecting\nan optimal ensemble of GANs tailored for medical data. The selected ensemble is\ncapable of generating diverse synthetic medical images that are representative\nof true data distributions and computationally efficient. Each model in the\nensemble brings a unique contribution, ensuring minimal redundancy. We\nconducted a comprehensive evaluation using three distinct medical datasets,\ntesting 22 different GAN architectures with various loss functions and\nregularisation techniques. By sampling models at different training epochs, we\ncrafted 110 unique configurations. The results highlight the capability of GAN\nensembles to enhance the quality and utility of synthetic medical images,\nthereby improving the efficacy of downstream tasks such as diagnostic\nmodelling.",
      "pdf_url": "http://arxiv.org/pdf/2503.24258v1",
      "published": "2025-03-31T16:06:01+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.24258v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Spatio-temporal Prediction of Fine-Grained Origin-Destination Matrices with Applications in Ridesharing",
      "authors": [
        "Run Yang",
        "Runpeng Dai",
        "Siran Gao",
        "Xiaocheng Tang",
        "Fan Zhou",
        "Hongtu Zhu"
      ],
      "abstract": "Accurate spatial-temporal prediction of network-based travelers' requests is\ncrucial for the effective policy design of ridesharing platforms. Having\nknowledge of the total demand between various locations in the upcoming time\nslots enables platforms to proactively prepare adequate supplies, thereby\nincreasing the likelihood of fulfilling travelers' requests and redistributing\nidle drivers to areas with high potential demand to optimize the global\nsupply-demand equilibrium. This paper delves into the prediction of\nOrigin-Destination (OD) demands at a fine-grained spatial level, especially\nwhen confronted with an expansive set of local regions. While this task holds\nimmense practical value, it remains relatively unexplored within the research\ncommunity. To fill this gap, we introduce a novel prediction model called\nOD-CED, which comprises an unsupervised space coarsening technique to alleviate\ndata sparsity and an encoder-decoder architecture to capture both semantic and\ngeographic dependencies. Through practical experimentation, OD-CED has\ndemonstrated remarkable results. It achieved an impressive reduction of up to\n45% reduction in root-mean-square error and 60% in weighted mean absolute\npercentage error over traditional statistical methods when dealing with OD\nmatrices exhibiting a sparsity exceeding 90%.",
      "pdf_url": "http://arxiv.org/pdf/2503.24237v1",
      "published": "2025-03-31T15:52:27+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.24237v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ]
    },
    {
      "title": "What, How, Where, and How Well? A Survey on Test-Time Scaling in Large Language Models",
      "authors": [
        "Qiyuan Zhang",
        "Fuyuan Lyu",
        "Zexu Sun",
        "Lei Wang",
        "Weixu Zhang",
        "Zhihan Guo",
        "Yufei Wang",
        "Irwin King",
        "Xue Liu",
        "Chen Ma"
      ],
      "abstract": "As enthusiasm for scaling computation (data and parameters) in the\npretraining era gradually diminished, test-time scaling (TTS), also referred to\nas ``test-time computing'' has emerged as a prominent research focus. Recent\nstudies demonstrate that TTS can further elicit the problem-solving\ncapabilities of large language models (LLMs), enabling significant\nbreakthroughs not only in specialized reasoning tasks, such as mathematics and\ncoding, but also in general tasks like open-ended Q&A. However, despite the\nexplosion of recent efforts in this area, there remains an urgent need for a\ncomprehensive survey offering a systemic understanding. To fill this gap, we\npropose a unified, multidimensional framework structured along four core\ndimensions of TTS research: what to scale, how to scale, where to scale, and\nhow well to scale. Building upon this taxonomy, we conduct an extensive review\nof methods, application scenarios, and assessment aspects, and present an\norganized decomposition that highlights the unique functional roles of\nindividual techniques within the broader TTS landscape. From this analysis, we\ndistill the major developmental trajectories of TTS to date and offer hands-on\nguidelines for practical deployment. Furthermore, we identify several open\nchallenges and offer insights into promising future directions, including\nfurther scaling, clarifying the functional essence of techniques, generalizing\nto more tasks, and more attributions.",
      "pdf_url": "http://arxiv.org/pdf/2503.24235v1",
      "published": "2025-03-31T15:46:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.24235v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "PAARS: Persona Aligned Agentic Retail Shoppers",
      "authors": [
        "Saab Mansour",
        "Leonardo Perelli",
        "Lorenzo Mainetti",
        "George Davidson",
        "Stefano D'Amato"
      ],
      "abstract": "In e-commerce, behavioral data is collected for decision making which can be\ncostly and slow. Simulation with LLM powered agents is emerging as a promising\nalternative for representing human population behavior. However, LLMs are known\nto exhibit certain biases, such as brand bias, review rating bias and limited\nrepresentation of certain groups in the population, hence they need to be\ncarefully benchmarked and aligned to user behavior. Ultimately, our goal is to\nsynthesise an agent population and verify that it collectively approximates a\nreal sample of humans. To this end, we propose a framework that: (i) creates\nsynthetic shopping agents by automatically mining personas from anonymised\nhistorical shopping data, (ii) equips agents with retail-specific tools to\nsynthesise shopping sessions and (iii) introduces a novel alignment suite\nmeasuring distributional differences between humans and shopping agents at the\ngroup (i.e. population) level rather than the traditional \"individual\" level.\nExperimental results demonstrate that using personas improves performance on\nthe alignment suite, though a gap remains to human behaviour. We showcase an\ninitial application of our framework for automated agentic A/B testing and\ncompare the findings to human results. Finally, we discuss applications,\nlimitations and challenges setting the stage for impactful future work.",
      "pdf_url": "http://arxiv.org/pdf/2503.24228v1",
      "published": "2025-03-31T15:41:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.24228v1",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.MA"
      ]
    },
    {
      "title": "MB-ORES: A Multi-Branch Object Reasoner for Visual Grounding in Remote Sensing",
      "authors": [
        "Karim Radouane",
        "Hanane Azzag",
        "Mustapha lebbah"
      ],
      "abstract": "We propose a unified framework that integrates object detection (OD) and\nvisual grounding (VG) for remote sensing (RS) imagery. To support conventional\nOD and establish an intuitive prior for VG task, we fine-tune an open-set\nobject detector using referring expression data, framing it as a partially\nsupervised OD task. In the first stage, we construct a graph representation of\neach image, comprising object queries, class embeddings, and proposal\nlocations. Then, our task-aware architecture processes this graph to perform\nthe VG task. The model consists of: (i) a multi-branch network that integrates\nspatial, visual, and categorical features to generate task-aware proposals, and\n(ii) an object reasoning network that assigns probabilities across proposals,\nfollowed by a soft selection mechanism for final referring object localization.\nOur model demonstrates superior performance on the OPT-RSVG and DIOR-RSVG\ndatasets, achieving significant improvements over state-of-the-art methods\nwhile retaining classical OD capabilities. The code will be available in our\nrepository: \\url{https://github.com/rd20karim/MB-ORES}.",
      "pdf_url": "http://arxiv.org/pdf/2503.24219v1",
      "published": "2025-03-31T15:36:41+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.24219v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.MM"
      ]
    },
    {
      "title": "All You Need is Sally-Anne: ToM in AI Strongly Supported After Surpassing Tests for 3-Year-Olds",
      "authors": [
        "Nitay Alon",
        "Joseph Barnby",
        "Reuth Mirsky",
        "Stefan Sarkadi"
      ],
      "abstract": "Theory of Mind (ToM) is a hallmark of human cognition, allowing individuals\nto reason about others' beliefs and intentions. Engineers behind recent\nadvances in Artificial Intelligence (AI) have claimed to demonstrate comparable\ncapabilities. This paper presents a model that surpasses traditional ToM tests\ndesigned for 3-year-old children, providing strong support for the presence of\nToM in AI systems.",
      "pdf_url": "http://arxiv.org/pdf/2503.24215v1",
      "published": "2025-03-31T15:32:10+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.24215v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "DiET-GS: Diffusion Prior and Event Stream-Assisted Motion Deblurring 3D Gaussian Splatting",
      "authors": [
        "Seungjun Lee",
        "Gim Hee Lee"
      ],
      "abstract": "Reconstructing sharp 3D representations from blurry multi-view images are\nlong-standing problem in computer vision. Recent works attempt to enhance\nhigh-quality novel view synthesis from the motion blur by leveraging\nevent-based cameras, benefiting from high dynamic range and microsecond\ntemporal resolution. However, they often reach sub-optimal visual quality in\neither restoring inaccurate color or losing fine-grained details. In this\npaper, we present DiET-GS, a diffusion prior and event stream-assisted motion\ndeblurring 3DGS. Our framework effectively leverages both blur-free event\nstreams and diffusion prior in a two-stage training strategy. Specifically, we\nintroduce the novel framework to constraint 3DGS with event double integral,\nachieving both accurate color and well-defined details. Additionally, we\npropose a simple technique to leverage diffusion prior to further enhance the\nedge details. Qualitative and quantitative results on both synthetic and\nreal-world data demonstrate that our DiET-GS is capable of producing\nsignificantly better quality of novel views compared to the existing baselines.\nOur project page is https://diet-gs.github.io",
      "pdf_url": "http://arxiv.org/pdf/2503.24210v1",
      "published": "2025-03-31T15:27:07+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.24210v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ]
    },
    {
      "title": "Agent-Based Simulations of Online Political Discussions: A Case Study on Elections in Germany",
      "authors": [
        "Abdul Sittar",
        "Simon MÃ¼nker",
        "Fabio Sartori",
        "Andreas Reitenbach",
        "Achim Rettinger",
        "Michael MÃ¤s",
        "Alenka GuÄek",
        "Marko Grobelnik"
      ],
      "abstract": "User engagement on social media platforms is influenced by historical\ncontext, time constraints, and reward-driven interactions. This study presents\nan agent-based simulation approach that models user interactions, considering\npast conversation history, motivation, and resource constraints. Utilizing\nGerman Twitter data on political discourse, we fine-tune AI models to generate\nposts and replies, incorporating sentiment analysis, irony detection, and\noffensiveness classification. The simulation employs a myopic best-response\nmodel to govern agent behavior, accounting for decision-making based on\nexpected rewards. Our results highlight the impact of historical context on\nAI-generated responses and demonstrate how engagement evolves under varying\nconstraints.",
      "pdf_url": "http://arxiv.org/pdf/2503.24199v1",
      "published": "2025-03-31T15:17:04+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.24199v1",
      "categories": [
        "cs.AI",
        "cs.CY"
      ]
    },
    {
      "title": "Output Constraints as Attack Surface: Exploiting Structured Generation to Bypass LLM Safety Mechanisms",
      "authors": [
        "Shuoming Zhang",
        "Jiacheng Zhao",
        "Ruiyuan Xu",
        "Xiaobing Feng",
        "Huimin Cui"
      ],
      "abstract": "Content Warning: This paper may contain unsafe or harmful content generated\nby LLMs that may be offensive to readers. Large Language Models (LLMs) are\nextensively used as tooling platforms through structured output APIs to ensure\nsyntax compliance so that robust integration with existing softwares like agent\nsystems, could be achieved. However, the feature enabling functionality of\ngrammar-guided structured output presents significant security vulnerabilities.\nIn this work, we reveal a critical control-plane attack surface orthogonal to\ntraditional data-plane vulnerabilities. We introduce Constrained Decoding\nAttack (CDA), a novel jailbreak class that weaponizes structured output\nconstraints to bypass safety mechanisms. Unlike prior attacks focused on input\nprompts, CDA operates by embedding malicious intent in schema-level grammar\nrules (control-plane) while maintaining benign surface prompts (data-plane). We\ninstantiate this with a proof-of-concept Chain Enum Attack, achieves 96.2%\nattack success rates across proprietary and open-weight LLMs on five safety\nbenchmarks with a single query, including GPT-4o and Gemini-2.0-flash. Our\nfindings identify a critical security blind spot in current LLM architectures\nand urge a paradigm shift in LLM safety to address control-plane\nvulnerabilities, as current mechanisms focused solely on data-plane threats\nleave critical systems exposed.",
      "pdf_url": "http://arxiv.org/pdf/2503.24191v1",
      "published": "2025-03-31T15:08:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.24191v1",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "title": "Predicting Targeted Therapy Resistance in Non-Small Cell Lung Cancer Using Multimodal Machine Learning",
      "authors": [
        "Peiying Hua",
        "Andrea Olofson",
        "Faraz Farhadi",
        "Liesbeth Hondelink",
        "Gregory Tsongalis",
        "Konstantin Dragnev",
        "Dagmar Hoegemann Savellano",
        "Arief Suriawinata",
        "Laura Tafe",
        "Saeed Hassanpour"
      ],
      "abstract": "Lung cancer is the primary cause of cancer death globally, with non-small\ncell lung cancer (NSCLC) emerging as its most prevalent subtype. Among NSCLC\npatients, approximately 32.3% have mutations in the epidermal growth factor\nreceptor (EGFR) gene. Osimertinib, a third-generation EGFR-tyrosine kinase\ninhibitor (TKI), has demonstrated remarkable efficacy in the treatment of NSCLC\npatients with activating and T790M resistance EGFR mutations. Despite its\nestablished efficacy, drug resistance poses a significant challenge for\npatients to fully benefit from osimertinib. The absence of a standard tool to\naccurately predict TKI resistance, including that of osimertinib, remains a\ncritical obstacle. To bridge this gap, in this study, we developed an\ninterpretable multimodal machine learning model designed to predict patient\nresistance to osimertinib among late-stage NSCLC patients with activating EGFR\nmutations, achieving a c-index of 0.82 on a multi-institutional dataset. This\nmachine learning model harnesses readily available data routinely collected\nduring patient visits and medical assessments to facilitate precision lung\ncancer management and informed treatment decisions. By integrating various data\ntypes such as histology images, next generation sequencing (NGS) data,\ndemographics data, and clinical records, our multimodal model can generate\nwell-informed recommendations. Our experiment results also demonstrated the\nsuperior performance of the multimodal model over single modality models\n(c-index 0.82 compared with 0.75 and 0.77), thus underscoring the benefit of\ncombining multiple modalities in patient outcome prediction.",
      "pdf_url": "http://arxiv.org/pdf/2503.24165v1",
      "published": "2025-03-31T14:47:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.24165v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Learning a Canonical Basis of Human Preferences from Binary Ratings",
      "authors": [
        "Kailas Vodrahalli",
        "Wei Wei",
        "James Zou"
      ],
      "abstract": "Recent advances in generative AI have been driven by alignment techniques\nsuch as reinforcement learning from human feedback (RLHF). RLHF and related\ntechniques typically involve constructing a dataset of binary or ranked choice\nhuman preferences and subsequently fine-tuning models to align with these\npreferences. This paper shifts the focus to understanding the preferences\nencoded in such datasets and identifying common human preferences. We find that\na small subset of 21 preference categories (selected from a set of nearly 5,000\ndistinct preferences) captures >89% of preference variation across individuals.\nThis small set of preferences is analogous to a canonical basis of human\npreferences, similar to established findings that characterize human variation\nin psychology or facial recognition studies. Through both synthetic and\nempirical evaluations, we confirm that our low-rank, canonical set of human\npreferences generalizes across the entire dataset and within specific topics.\nWe further demonstrate our preference basis' utility in model evaluation, where\nour preference categories offer deeper insights into model alignment, and in\nmodel training, where we show that fine-tuning on preference-defined subsets\nsuccessfully aligns the model accordingly.",
      "pdf_url": "http://arxiv.org/pdf/2503.24150v1",
      "published": "2025-03-31T14:35:48+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.24150v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.HC"
      ]
    },
    {
      "title": "Resonance: Drawing from Memories to Imagine Positive Futures through AI-Augmented Journaling",
      "authors": [
        "Wazeer Zulfikar",
        "Treyden Chiaravalloti",
        "Jocelyn Shen",
        "Rosalind Picard",
        "Pattie Maes"
      ],
      "abstract": "People inherently use experiences of their past while imagining their future,\na capability that plays a crucial role in mental health. Resonance is an\nAI-powered journaling tool designed to augment this ability by offering\nAI-generated, action-oriented suggestions for future activities based on the\nuser's own past memories. Suggestions are offered when a new memory is logged\nand are followed by a prompt for the user to imagine carrying out the\nsuggestion. In a two-week randomized controlled study (N=55), we found that\nusing Resonance significantly improved mental health outcomes, reducing the\nusers' PHQ8 scores, a measure of current depression, and increasing their daily\npositive affect, particularly when they would likely act on the suggestion.\nNotably, the effectiveness of the suggestions was higher when they were\npersonal, novel, and referenced the user's logged memories. Finally, through\nopen-ended feedback, we discuss the factors that encouraged or hindered the use\nof the tool.",
      "pdf_url": "http://arxiv.org/pdf/2503.24145v1",
      "published": "2025-03-31T14:30:47+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.24145v1",
      "categories": [
        "cs.HC",
        "cs.AI"
      ]
    },
    {
      "title": "Graph Neural Network-Based Predictive Modeling for Robotic Plaster Printing",
      "authors": [
        "Diego Machain Rivera",
        "Selen Ercan Jenny",
        "Ping Hsun Tsai",
        "Ena Lloret-Fritschi",
        "Luis Salamanca",
        "Fernando Perez-Cruz",
        "Konstantinos E. Tatsis"
      ],
      "abstract": "This work proposes a Graph Neural Network (GNN) modeling approach to predict\nthe resulting surface from a particle based fabrication process. The latter\nconsists of spray-based printing of cementitious plaster on a wall and is\nfacilitated with the use of a robotic arm. The predictions are computed using\nthe robotic arm trajectory features, such as position, velocity and direction,\nas well as the printing process parameters. The proposed approach, based on a\nparticle representation of the wall domain and the end effector, allows for the\nadoption of a graph-based solution. The GNN model consists of an\nencoder-processor-decoder architecture and is trained using data from\nlaboratory tests, while the hyperparameters are optimized by means of a\nBayesian scheme. The aim of this model is to act as a simulator of the printing\nprocess, and ultimately used for the generation of the robotic arm trajectory\nand the optimization of the printing parameters, towards the materialization of\nan autonomous plastering process. The performance of the proposed model is\nassessed in terms of the prediction error against unseen ground truth data,\nwhich shows its generality in varied scenarios, as well as in comparison with\nthe performance of an existing benchmark model. The results demonstrate a\nsignificant improvement over the benchmark model, with notably better\nperformance and enhanced error scaling across prediction steps.",
      "pdf_url": "http://arxiv.org/pdf/2503.24130v1",
      "published": "2025-03-31T14:15:00+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.24130v1",
      "categories": [
        "cs.CE",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ]
    },
    {
      "title": "Grounding Agent Reasoning in Image Schemas: A Neurosymbolic Approach to Embodied Cognition",
      "authors": [
        "FranÃ§ois Olivier",
        "Zied Bouraoui"
      ],
      "abstract": "Despite advances in embodied AI, agent reasoning systems still struggle to\ncapture the fundamental conceptual structures that humans naturally use to\nunderstand and interact with their environment. To address this, we propose a\nnovel framework that bridges embodied cognition theory and agent systems by\nleveraging a formal characterization of image schemas, which are defined as\nrecurring patterns of sensorimotor experience that structure human cognition.\nBy customizing LLMs to translate natural language descriptions into formal\nrepresentations based on these sensorimotor patterns, we will be able to create\na neurosymbolic system that grounds the agent's understanding in fundamental\nconceptual structures. We argue that such an approach enhances both efficiency\nand interpretability while enabling more intuitive human-agent interactions\nthrough shared embodied understanding.",
      "pdf_url": "http://arxiv.org/pdf/2503.24110v1",
      "published": "2025-03-31T14:01:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.24110v1",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "PolypSegTrack: Unified Foundation Model for Colonoscopy Video Analysis",
      "authors": [
        "Anwesa Choudhuri",
        "Zhongpai Gao",
        "Meng Zheng",
        "Benjamin Planche",
        "Terrence Chen",
        "Ziyan Wu"
      ],
      "abstract": "Early detection, accurate segmentation, classification and tracking of polyps\nduring colonoscopy are critical for preventing colorectal cancer. Many existing\ndeep-learning-based methods for analyzing colonoscopic videos either require\ntask-specific fine-tuning, lack tracking capabilities, or rely on\ndomain-specific pre-training. In this paper, we introduce\n\\textit{PolypSegTrack}, a novel foundation model that jointly addresses polyp\ndetection, segmentation, classification and unsupervised tracking in\ncolonoscopic videos. Our approach leverages a novel conditional mask loss,\nenabling flexible training across datasets with either pixel-level segmentation\nmasks or bounding box annotations, allowing us to bypass task-specific\nfine-tuning. Our unsupervised tracking module reliably associates polyp\ninstances across frames using object queries, without relying on any\nheuristics. We leverage a robust vision foundation model backbone that is\npre-trained unsupervisedly on natural images, thereby removing the need for\ndomain-specific pre-training. Extensive experiments on multiple polyp\nbenchmarks demonstrate that our method significantly outperforms existing\nstate-of-the-art approaches in detection, segmentation, classification, and\ntracking.",
      "pdf_url": "http://arxiv.org/pdf/2503.24108v1",
      "published": "2025-03-31T14:00:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.24108v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Artificial Conversations, Real Results: Fostering Language Detection with Synthetic Data",
      "authors": [
        "Fatemeh Mohammadi",
        "Tommaso Romano",
        "Samira Maghool",
        "Paolo Ceravolo"
      ],
      "abstract": "Collecting high-quality training data is essential for fine-tuning Large\nLanguage Models (LLMs). However, acquiring such data is often costly and\ntime-consuming, especially for non-English languages such as Italian. Recently,\nresearchers have begun to explore the use of LLMs to generate synthetic\ndatasets as a viable alternative. This study proposes a pipeline for generating\nsynthetic data and a comprehensive approach for investigating the factors that\ninfluence the validity of synthetic data generated by LLMs by examining how\nmodel performance is affected by metrics such as prompt strategy, text length\nand target position in a specific task, i.e. inclusive language detection in\nItalian job advertisements. Our results show that, in most cases and across\ndifferent metrics, the fine-tuned models trained on synthetic data consistently\noutperformed other models on both real and synthetic test datasets. The study\ndiscusses the practical implications and limitations of using synthetic data\nfor language detection tasks with LLMs.",
      "pdf_url": "http://arxiv.org/pdf/2503.24062v1",
      "published": "2025-03-31T13:22:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.24062v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Towards Scientific Intelligence: A Survey of LLM-based Scientific Agents",
      "authors": [
        "Shuo Ren",
        "Pu Jian",
        "Zhenjiang Ren",
        "Chunlin Leng",
        "Can Xie",
        "Jiajun Zhang"
      ],
      "abstract": "As scientific research becomes increasingly complex, innovative tools are\nneeded to manage vast data, facilitate interdisciplinary collaboration, and\naccelerate discovery. Large language models (LLMs) are now evolving into\nLLM-based scientific agents that automate critical tasks, ranging from\nhypothesis generation and experiment design to data analysis and simulation.\nUnlike general-purpose LLMs, these specialized agents integrate domain-specific\nknowledge, advanced tool sets, and robust validation mechanisms, enabling them\nto handle complex data types, ensure reproducibility, and drive scientific\nbreakthroughs. This survey provides a focused review of the architectures,\ndesign, benchmarks, applications, and ethical considerations surrounding\nLLM-based scientific agents. We highlight why they differ from general agents\nand the ways in which they advance research across various scientific fields.\nBy examining their development and challenges, this survey offers a\ncomprehensive roadmap for researchers and practitioners to harness these agents\nfor more efficient, reliable, and ethically sound scientific discovery.",
      "pdf_url": "http://arxiv.org/pdf/2503.24047v1",
      "published": "2025-03-31T13:11:28+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.24047v1",
      "categories": [
        "cs.AI",
        "cs.MA"
      ]
    },
    {
      "title": "Pay More Attention to the Robustness of Prompt for Instruction Data Mining",
      "authors": [
        "Qiang Wang",
        "Dawei Feng",
        "Xu Zhang",
        "Ao Shen",
        "Yang Xu",
        "Bo Ding",
        "Huaimin Wang"
      ],
      "abstract": "Instruction tuning has emerged as a paramount method for tailoring the\nbehaviors of LLMs. Recent work has unveiled the potential for LLMs to achieve\nhigh performance through fine-tuning with a limited quantity of high-quality\ninstruction data. Building upon this approach, we further explore the impact of\nprompt's robustness on the selection of high-quality instruction data. This\npaper proposes a pioneering framework of high-quality online instruction data\nmining for instruction tuning, focusing on the impact of prompt's robustness on\nthe data mining process. Our notable innovation, is to generate the adversarial\ninstruction data by conducting the attack for the prompt of online instruction\ndata. Then, we introduce an Adversarial Instruction-Following Difficulty metric\nto measure how much help the adversarial instruction data can provide to the\ngeneration of the corresponding response. Apart from it, we propose a novel\nAdversarial Instruction Output Embedding Consistency approach to select\nhigh-quality online instruction data. We conduct extensive experiments on two\nbenchmark datasets to assess the performance. The experimental results serve to\nunderscore the effectiveness of our proposed two methods. Moreover, the results\nunderscore the critical practical significance of considering prompt's\nrobustness.",
      "pdf_url": "http://arxiv.org/pdf/2503.24028v1",
      "published": "2025-03-31T12:53:08+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.24028v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Bayesian Predictive Coding",
      "authors": [
        "Alexander Tschantz",
        "Magnus Koudahl",
        "Hampus Linander",
        "Lancelot Da Costa",
        "Conor Heins",
        "Jeff Beck",
        "Christopher Buckley"
      ],
      "abstract": "Predictive coding (PC) is an influential theory of information processing in\nthe brain, providing a biologically plausible alternative to backpropagation.\nIt is motivated in terms of Bayesian inference, as hidden states and parameters\nare optimised via gradient descent on variational free energy. However,\nimplementations of PC rely on maximum \\textit{a posteriori} (MAP) estimates of\nhidden states and maximum likelihood (ML) estimates of parameters, limiting\ntheir ability to quantify epistemic uncertainty. In this work, we investigate a\nBayesian extension to PC that estimates a posterior distribution over network\nparameters. This approach, termed Bayesian Predictive coding (BPC), preserves\nthe locality of PC and results in closed-form Hebbian weight updates. Compared\nto PC, our BPC algorithm converges in fewer epochs in the full-batch setting\nand remains competitive in the mini-batch setting. Additionally, we demonstrate\nthat BPC offers uncertainty quantification comparable to existing methods in\nBayesian deep learning, while also improving convergence properties. Together,\nthese results suggest that BPC provides a biologically plausible method for\nBayesian learning in the brain, as well as an attractive approach to\nuncertainty quantification in deep learning.",
      "pdf_url": "http://arxiv.org/pdf/2503.24016v1",
      "published": "2025-03-31T12:40:50+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.24016v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ]
    },
    {
      "title": "Learning 3D-Gaussian Simulators from RGB Videos",
      "authors": [
        "Mikel Zhobro",
        "Andreas RenÃ© Geist",
        "Georg Martius"
      ],
      "abstract": "Learning physics simulations from video data requires maintaining spatial and\ntemporal consistency, a challenge often addressed with strong inductive biases\nor ground-truth 3D information -- limiting scalability and generalization. We\nintroduce 3DGSim, a 3D physics simulator that learns object dynamics end-to-end\nfrom multi-view RGB videos. It encodes images into a 3D Gaussian particle\nrepresentation, propagates dynamics via a transformer, and renders frames using\n3D Gaussian splatting. By jointly training inverse rendering with a dynamics\ntransformer using a temporal encoding and merging layer, 3DGSimembeds physical\nproperties into point-wise latent vectors without enforcing explicit\nconnectivity constraints. This enables the model to capture diverse physical\nbehaviors, from rigid to elastic and cloth-like interactions, along with\nrealistic lighting effects that also generalize to unseen multi-body\ninteractions and novel scene edits.",
      "pdf_url": "http://arxiv.org/pdf/2503.24009v1",
      "published": "2025-03-31T12:33:59+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.24009v1",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.RO"
      ]
    },
    {
      "title": "H2VU-Benchmark: A Comprehensive Benchmark for Hierarchical Holistic Video Understanding",
      "authors": [
        "Qi Wu",
        "Quanlong Zheng",
        "Yanhao Zhang",
        "Junlin Xie",
        "Jinguo Luo",
        "Kuo Wang",
        "Peng Liu",
        "Qingsong Xie",
        "Ru Zhen",
        "Haonan Lu",
        "Zhenyu Yang"
      ],
      "abstract": "With the rapid development of multimodal models, the demand for assessing\nvideo understanding capabilities has been steadily increasing. However,\nexisting benchmarks for evaluating video understanding exhibit significant\nlimitations in coverage, task diversity, and scene adaptability. These\nshortcomings hinder the accurate assessment of models' comprehensive video\nunderstanding capabilities. To tackle this challenge, we propose a hierarchical\nand holistic video understanding (H2VU) benchmark designed to evaluate both\ngeneral video and online streaming video comprehension. This benchmark\ncontributes three key features:\n  Extended video duration: Spanning videos from brief 3-second clips to\ncomprehensive 1.5-hour recordings, thereby bridging the temporal gaps found in\ncurrent benchmarks. Comprehensive assessment tasks: Beyond traditional\nperceptual and reasoning tasks, we have introduced modules for\ncountercommonsense comprehension and trajectory state tracking. These additions\ntest the models' deep understanding capabilities beyond mere prior knowledge.\nEnriched video data: To keep pace with the rapid evolution of current AI\nagents, we have expanded first-person streaming video datasets. This expansion\nallows for the exploration of multimodal models' performance in understanding\nstreaming videos from a first-person perspective. Extensive results from H2VU\nreveal that existing multimodal large language models (MLLMs) possess\nsubstantial potential for improvement in our newly proposed evaluation tasks.\nWe expect that H2VU will facilitate advancements in video understanding\nresearch by offering a comprehensive and in-depth analysis of MLLMs.",
      "pdf_url": "http://arxiv.org/pdf/2503.24008v1",
      "published": "2025-03-31T12:32:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.24008v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "CITRAS: Covariate-Informed Transformer for Time Series Forecasting",
      "authors": [
        "Yosuke Yamaguchi",
        "Issei Suemitsu",
        "Wenpeng Wei"
      ],
      "abstract": "Covariates play an indispensable role in practical time series forecasting,\noffering rich context from the past and sometimes extending into the future.\nHowever, their availability varies depending on the scenario, and situations\noften involve multiple target variables simultaneously. Moreover, the\ncross-variate dependencies between them are multi-granular, with some\ncovariates having a short-term impact on target variables and others showing\nlong-term correlations. This heterogeneity and the intricate dependencies\narising in covariate-informed forecasting present significant challenges to\nexisting deep models. To address these issues, we propose CITRAS, a patch-based\nTransformer that flexibly leverages multiple targets and covariates covering\nboth the past and the future forecasting horizon. While preserving the strong\nautoregressive capabilities of the canonical Transformer, CITRAS introduces two\nnovel mechanisms in patch-wise cross-variate attention: Key-Value (KV) Shift\nand Attention Score Smoothing. KV Shift seamlessly incorporates future known\ncovariates into the forecasting of target variables based on their concurrent\ndependencies. Additionally, Attention Score Smoothing transforms locally\naccurate patch-wise cross-variate dependencies into global variate-level\ndependencies by smoothing the past series of attention scores. Experimentally,\nCITRAS achieves state-of-the-art performance in both covariate-informed and\nmultivariate forecasting, demonstrating its versatile ability to leverage\ncross-variate dependency for improved forecasting accuracy.",
      "pdf_url": "http://arxiv.org/pdf/2503.24007v1",
      "published": "2025-03-31T12:32:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.24007v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Rethinking Key-Value Cache Compression Techniques for Large Language Model Serving",
      "authors": [
        "Wei Gao",
        "Xinyu Zhou",
        "Peng Sun",
        "Tianwei Zhang",
        "Yonggang Wen"
      ],
      "abstract": "Key-Value cache (\\texttt{KV} \\texttt{cache}) compression has emerged as a\npromising technique to optimize Large Language Model (LLM) serving. It\nprimarily decreases the memory consumption of \\texttt{KV} \\texttt{cache} to\nreduce the computation cost. Despite the development of many compression\nalgorithms, their applications in production environments are still not\nprevalent. In this paper, we revisit mainstream \\texttt{KV} \\texttt{cache}\ncompression solutions from a practical perspective. Our contributions are\nthree-fold. First, we comprehensively review existing algorithmic designs and\nbenchmark studies for \\texttt{KV} \\texttt{cache} compression and identify\nmissing pieces in their performance measurement, which could hinder their\nadoption in practice. Second, we empirically evaluate representative\n\\texttt{KV} \\texttt{cache} compression methods to uncover two key issues that\naffect the computational efficiency: (1) while compressing \\texttt{KV}\n\\texttt{cache} can reduce memory consumption, current implementations (e.g.,\nFlashAttention, PagedAttention) do not optimize for production-level LLM\nserving, resulting in suboptimal throughput performance; (2) compressing\n\\texttt{KV} \\texttt{cache} may lead to longer outputs, resulting in increased\nend-to-end latency. We further investigate the accuracy performance of\nindividual samples rather than the overall performance, revealing the intrinsic\nlimitations in \\texttt{KV} \\texttt{cache} compression when handling specific\nLLM tasks. Third, we provide tools to shed light on future \\texttt{KV}\n\\texttt{cache} compression studies and facilitate their practical deployment in\nproduction. They are open-sourced in\n\\href{https://github.com/LLMkvsys/rethink-kv-compression}{https://github.com/LLMkvsys/rethink-kv-compression}.",
      "pdf_url": "http://arxiv.org/pdf/2503.24000v1",
      "published": "2025-03-31T12:23:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.24000v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "DenseFormer: Learning Dense Depth Map from Sparse Depth and Image via Conditional Diffusion Model",
      "authors": [
        "Ming Yuan",
        "Sichao Wang",
        "Chuang Zhang",
        "Lei He",
        "Qing Xu",
        "Jianqiang Wang"
      ],
      "abstract": "The depth completion task is a critical problem in autonomous driving,\ninvolving the generation of dense depth maps from sparse depth maps and RGB\nimages. Most existing methods employ a spatial propagation network to\niteratively refine the depth map after obtaining an initial dense depth. In\nthis paper, we propose DenseFormer, a novel method that integrates the\ndiffusion model into the depth completion task. By incorporating the denoising\nmechanism of the diffusion model, DenseFormer generates the dense depth map by\nprogressively refining an initial random depth distribution through multiple\niterations. We propose a feature extraction module that leverages a feature\npyramid structure, along with multi-layer deformable attention, to effectively\nextract and integrate features from sparse depth maps and RGB images, which\nserve as the guiding condition for the diffusion process. Additionally, this\npaper presents a depth refinement module that applies multi-step iterative\nrefinement across various ranges to the dense depth results generated by the\ndiffusion process. The module utilizes image features enriched with multi-scale\ninformation and sparse depth input to further enhance the accuracy of the\npredicted depth map. Extensive experiments on the KITTI outdoor scene dataset\ndemonstrate that DenseFormer outperforms classical depth completion methods.",
      "pdf_url": "http://arxiv.org/pdf/2503.23993v1",
      "published": "2025-03-31T12:11:01+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.23993v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Rubric Is All You Need: Enhancing LLM-based Code Evaluation With Question-Specific Rubrics",
      "authors": [
        "Aditya Pathak",
        "Rachit Gandhi",
        "Vaibhav Uttam",
        "Devansh",
        "Yashwanth Nakka",
        "Aaryan Raj Jindal",
        "Pratyush Ghosh",
        "Arnav Ramamoorthy",
        "Shreyash Verma",
        "Aditya Mittal",
        "Aashna Ased",
        "Chirag Khatri",
        "Jagat Sesh Challa",
        "Dhruv Kumar"
      ],
      "abstract": "Since the disruption in LLM technology brought about by the release of GPT-3\nand ChatGPT, LLMs have shown remarkable promise in programming-related tasks.\nWhile code generation remains a popular field of research, code evaluation\nusing LLMs remains a problem with no conclusive solution. In this paper, we\nfocus on LLM-based code evaluation and attempt to fill in the existing gaps. We\npropose multi-agentic novel approaches using question-specific rubrics tailored\nto the problem statement, arguing that these perform better for logical\nassessment than the existing approaches that use question-agnostic rubrics. To\naddress the lack of suitable evaluation datasets, we introduce two datasets: a\nData Structures and Algorithms dataset containing 150 student submissions from\na popular Data Structures and Algorithms practice website, and an Object\nOriented Programming dataset comprising 80 student submissions from\nundergraduate computer science courses. In addition to using standard metrics\n(Spearman Correlation, Cohen's Kappa), we additionally propose a new metric\ncalled as Leniency, which quantifies evaluation strictness relative to expert\nassessment. Our comprehensive analysis demonstrates that question-specific\nrubrics significantly enhance logical assessment of code in educational\nsettings, providing better feedback aligned with instructional goals beyond\nmere syntactic correctness.",
      "pdf_url": "http://arxiv.org/pdf/2503.23989v1",
      "published": "2025-03-31T11:59:43+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.23989v1",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "Deep Learning Model Deployment in Multiple Cloud Providers: an Exploratory Study Using Low Computing Power Environments",
      "authors": [
        "Elayne Lemos",
        "Rodrigo Oliveira",
        "Jairson Rodrigues",
        "Rosalvo F. Oliveira Neto"
      ],
      "abstract": "The deployment of Machine Learning models at cloud have grown by tech\ncompanies. Hardware requirements are higher when these models involve Deep\nLearning (DL) techniques and the cloud providers' costs may be a barrier. We\nexplore deploying DL models using for experiments the GECToR model, a DL\nsolution for Grammatical Error Correction, across three of the major cloud\nplatforms (AWS, Google Cloud, Azure). We evaluate real-time latency, hardware\nusage and cost at each cloud provider by 7 execution environments with 10\nexperiments reproduced. We found that while GPUs excel in performance, they had\nan average cost 300% higher than solutions without GPU. Our analysis also\nidentifies that processor cache size is crucial for cost-effective CPU\ndeployments, enabling over 50% of cost reduction compared to GPUs. This study\ndemonstrates the feasibility and affordability of cloud-based DL inference\nsolutions without GPUs, benefiting resource-constrained users like startups.",
      "pdf_url": "http://arxiv.org/pdf/2503.23988v1",
      "published": "2025-03-31T11:58:37+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.23988v1",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.PF",
        "68T07, 68U01",
        "C.4; I.2.0; B.8.2"
      ]
    },
    {
      "title": "Deep Nets as Hamiltonians",
      "authors": [
        "Mike Winer",
        "Boris Hanin"
      ],
      "abstract": "Neural networks are complex functions of both their inputs and parameters.\nMuch prior work in deep learning theory analyzes the distribution of network\noutputs at a fixed a set of inputs (e.g. a training dataset) over random\ninitializations of the network parameters. The purpose of this article is to\nconsider the opposite situation: we view a randomly initialized Multi-Layer\nPerceptron (MLP) as a Hamiltonian over its inputs. For typical realizations of\nthe network parameters, we study the properties of the energy landscape induced\nby this Hamiltonian, focusing on the structure of near-global minimum in the\nlimit of infinite width. Specifically, we use the replica trick to perform an\nexact analytic calculation giving the entropy (log volume of space) at a given\nenergy. We further derive saddle point equations that describe the overlaps\nbetween inputs sampled iid from the Gibbs distribution induced by the random\nMLP. For linear activations we solve these saddle point equations exactly. But\nwe also solve them numerically for a variety of depths and activation\nfunctions, including $\\tanh, \\sin, \\text{ReLU}$, and shaped non-linearities. We\nfind even at infinite width a rich range of behaviors. For some\nnon-linearities, such as $\\sin$, for instance, we find that the landscapes of\nrandom MLPs exhibit full replica symmetry breaking, while shallow $\\tanh$ and\nReLU networks or deep shaped MLPs are instead replica symmetric.",
      "pdf_url": "http://arxiv.org/pdf/2503.23982v1",
      "published": "2025-03-31T11:51:10+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.23982v1",
      "categories": [
        "cond-mat.dis-nn",
        "cond-mat.stat-mech",
        "cs.AI",
        "cs.LG",
        "math.PR"
      ]
    },
    {
      "title": "Noise-based reward-modulated learning",
      "authors": [
        "JesÃºs GarcÃ­a FernÃ¡ndez",
        "Nasir Ahmad",
        "Marcel van Gerven"
      ],
      "abstract": "Recent advances in reinforcement learning (RL) have led to significant\nimprovements in task performance. However, training neural networks in an RL\nregime is typically achieved in combination with backpropagation, limiting\ntheir applicability in resource-constrained environments or when using\nnon-differentiable neural networks. While noise-based alternatives like\nreward-modulated Hebbian learning (RMHL) have been proposed, their performance\nhas remained limited, especially in scenarios with delayed rewards, which\nrequire retrospective credit assignment over time. Here, we derive a novel\nnoise-based learning rule that addresses these challenges. Our approach\ncombines directional derivative theory with Hebbian-like updates to enable\nefficient, gradient-free learning in RL. It features stochastic noisy neurons\nwhich can approximate gradients, and produces local synaptic updates modulated\nby a global reward signal. Drawing on concepts from neuroscience, our method\nuses reward prediction error as its optimization target to generate\nincreasingly advantageous behavior, and incorporates an eligibility trace to\nfacilitate temporal credit assignment in environments with delayed rewards. Its\nformulation relies on local information alone, making it compatible with\nimplementations in neuromorphic hardware. Experimental validation shows that\nour approach significantly outperforms RMHL and is competitive with BP-based\nbaselines, highlighting the promise of noise-based, biologically inspired\nlearning for low-power and real-time applications.",
      "pdf_url": "http://arxiv.org/pdf/2503.23972v1",
      "published": "2025-03-31T11:35:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.23972v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    }
  ]
}