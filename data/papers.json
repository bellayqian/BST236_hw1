{
  "last_updated": "2025-05-30T00:52:05.872305",
  "papers": [
    {
      "title": "Maximizing Confidence Alone Improves Reasoning",
      "authors": [
        "Mihir Prabhudesai",
        "Lili Chen",
        "Alex Ippoliti",
        "Katerina Fragkiadaki",
        "Hao Liu",
        "Deepak Pathak"
      ],
      "abstract": "Reinforcement learning (RL) has enabled machine learning models to achieve\nsignificant advances in many fields. Most recently, RL has empowered frontier\nlanguage models to solve challenging math, science, and coding problems.\nHowever, central to any RL algorithm is the reward function, and reward\nengineering is a notoriously difficult problem in any domain. In this paper, we\npropose RENT: Reinforcement Learning via Entropy Minimization -- a fully\nunsupervised RL method that requires no external reward or ground-truth\nanswers, and instead uses the model's entropy of its underlying distribution as\nan intrinsic reward. We find that by reinforcing the chains of thought that\nyield high model confidence on its generated answers, the model improves its\nreasoning ability. In our experiments, we showcase these improvements on an\nextensive suite of commonly-used reasoning benchmarks, including GSM8K,\nMATH500, AMC, AIME, and GPQA, and models of varying sizes from the Qwen and\nMistral families. The generality of our unsupervised learning method lends\nitself to applicability in a wide range of domains where external supervision\nis limited or unavailable.",
      "pdf_url": "http://arxiv.org/pdf/2505.22660v1",
      "published": "2025-05-28T17:59:37+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.22660v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "3DLLM-Mem: Long-Term Spatial-Temporal Memory for Embodied 3D Large Language Model",
      "authors": [
        "Wenbo Hu",
        "Yining Hong",
        "Yanjun Wang",
        "Leison Gao",
        "Zibu Wei",
        "Xingcheng Yao",
        "Nanyun Peng",
        "Yonatan Bitton",
        "Idan Szpektor",
        "Kai-Wei Chang"
      ],
      "abstract": "Humans excel at performing complex tasks by leveraging long-term memory\nacross temporal and spatial experiences. In contrast, current Large Language\nModels (LLMs) struggle to effectively plan and act in dynamic, multi-room 3D\nenvironments. We posit that part of this limitation is due to the lack of\nproper 3D spatial-temporal memory modeling in LLMs. To address this, we first\nintroduce 3DMem-Bench, a comprehensive benchmark comprising over 26,000\ntrajectories and 2,892 embodied tasks, question-answering and captioning,\ndesigned to evaluate an agent's ability to reason over long-term memory in 3D\nenvironments. Second, we propose 3DLLM-Mem, a novel dynamic memory management\nand fusion model for embodied spatial-temporal reasoning and actions in LLMs.\nOur model uses working memory tokens, which represents current observations, as\nqueries to selectively attend to and fuse the most useful spatial and temporal\nfeatures from episodic memory, which stores past observations and interactions.\nOur approach allows the agent to focus on task-relevant information while\nmaintaining memory efficiency in complex, long-horizon environments.\nExperimental results demonstrate that 3DLLM-Mem achieves state-of-the-art\nperformance across various tasks, outperforming the strongest baselines by\n16.5% in success rate on 3DMem-Bench's most challenging in-the-wild embodied\ntasks.",
      "pdf_url": "http://arxiv.org/pdf/2505.22657v1",
      "published": "2025-05-28T17:59:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.22657v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    },
    {
      "title": "Position: Uncertainty Quantification Needs Reassessment for Large-language Model Agents",
      "authors": [
        "Michael Kirchhof",
        "Gjergji Kasneci",
        "Enkelejda Kasneci"
      ],
      "abstract": "Large-language models (LLMs) and chatbot agents are known to provide wrong\noutputs at times, and it was recently found that this can never be fully\nprevented. Hence, uncertainty quantification plays a crucial role, aiming to\nquantify the level of ambiguity in either one overall number or two numbers for\naleatoric and epistemic uncertainty. This position paper argues that this\ntraditional dichotomy of uncertainties is too limited for the open and\ninteractive setup that LLM agents operate in when communicating with a user,\nand that we need to research avenues that enrich uncertainties in this novel\nscenario. We review the literature and find that popular definitions of\naleatoric and epistemic uncertainties directly contradict each other and lose\ntheir meaning in interactive LLM agent settings. Hence, we propose three novel\nresearch directions that focus on uncertainties in such human-computer\ninteractions: Underspecification uncertainties, for when users do not provide\nall information or define the exact task at the first go, interactive learning,\nto ask follow-up questions and reduce the uncertainty about the current\ncontext, and output uncertainties, to utilize the rich language and speech\nspace to express uncertainties as more than mere numbers. We expect that these\nnew ways of dealing with and communicating uncertainties will lead to LLM agent\ninteractions that are more transparent, trustworthy, and intuitive.",
      "pdf_url": "http://arxiv.org/pdf/2505.22655v1",
      "published": "2025-05-28T17:59:08+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.22655v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Pre-training for Recommendation Unlearning",
      "authors": [
        "Guoxuan Chen",
        "Lianghao Xia",
        "Chao Huang"
      ],
      "abstract": "Modern recommender systems powered by Graph Neural Networks (GNNs) excel at\nmodeling complex user-item interactions, yet increasingly face scenarios\nrequiring selective forgetting of training data. Beyond user requests to remove\nspecific interactions due to privacy concerns or preference changes, regulatory\nframeworks mandate recommender systems' ability to eliminate the influence of\ncertain user data from models. This recommendation unlearning challenge\npresents unique difficulties as removing connections within interaction graphs\ncreates ripple effects throughout the model, potentially impacting\nrecommendations for numerous users. Traditional approaches suffer from\nsignificant drawbacks: fragmentation methods damage graph structure and\ndiminish performance, while influence function techniques make assumptions that\nmay not hold in complex GNNs, particularly with self-supervised or random\narchitectures. To address these limitations, we propose a novel model-agnostic\npre-training paradigm UnlearnRec that prepares systems for efficient unlearning\noperations. Our Influence Encoder takes unlearning requests together with\nexisting model parameters and directly produces updated parameters of unlearned\nmodel with little fine-tuning, avoiding complete retraining while preserving\nmodel performance characteristics. Extensive evaluation on public benchmarks\ndemonstrates that our method delivers exceptional unlearning effectiveness\nwhile providing more than 10x speedup compared to retraining approaches. We\nrelease our method implementation at: https://github.com/HKUDS/UnlearnRec.",
      "pdf_url": "http://arxiv.org/pdf/2505.22649v2",
      "published": "2025-05-28T17:57:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.22649v2",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "FastTD3: Simple, Fast, and Capable Reinforcement Learning for Humanoid Control",
      "authors": [
        "Younggyo Seo",
        "Carmelo Sferrazza",
        "Haoran Geng",
        "Michal Nauman",
        "Zhao-Heng Yin",
        "Pieter Abbeel"
      ],
      "abstract": "Reinforcement learning (RL) has driven significant progress in robotics, but\nits complexity and long training times remain major bottlenecks. In this\nreport, we introduce FastTD3, a simple, fast, and capable RL algorithm that\nsignificantly speeds up training for humanoid robots in popular suites such as\nHumanoidBench, IsaacLab, and MuJoCo Playground. Our recipe is remarkably\nsimple: we train an off-policy TD3 agent with several modifications -- parallel\nsimulation, large-batch updates, a distributional critic, and carefully tuned\nhyperparameters. FastTD3 solves a range of HumanoidBench tasks in under 3 hours\non a single A100 GPU, while remaining stable during training. We also provide a\nlightweight and easy-to-use implementation of FastTD3 to accelerate RL research\nin robotics.",
      "pdf_url": "http://arxiv.org/pdf/2505.22642v1",
      "published": "2025-05-28T17:55:26+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.22642v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Learning Composable Chains-of-Thought",
      "authors": [
        "Fangcong Yin",
        "Zeyu Leo Liu",
        "Liu Leqi",
        "Xi Ye",
        "Greg Durrett"
      ],
      "abstract": "A common approach for teaching large language models (LLMs) to reason is to\ntrain on chain-of-thought (CoT) traces of in-distribution reasoning problems,\nbut such annotated data is costly to obtain for every problem of interest. We\nwant reasoning models to generalize beyond their training distribution, and\nideally to generalize compositionally: combine atomic reasoning skills to solve\nharder, unseen reasoning tasks. We take a step towards compositional\ngeneralization of reasoning skills when addressing a target compositional task\nthat has no labeled CoT data. We find that simply training models on CoT data\nof atomic tasks leads to limited generalization, but minimally modifying CoT\nformats of constituent atomic tasks to be composable can lead to improvements.\nWe can train \"atomic CoT\" models on the atomic tasks with Composable CoT data\nand combine them with multitask learning or model merging for better zero-shot\nperformance on the target compositional task. Such a combined model can be\nfurther bootstrapped on a small amount of compositional data using rejection\nsampling fine-tuning (RFT). Results on string operations and natural language\nskill compositions show that training LLMs on Composable CoT outperforms\nmultitask learning and continued fine-tuning baselines within a given training\ndata budget.",
      "pdf_url": "http://arxiv.org/pdf/2505.22635v1",
      "published": "2025-05-28T17:51:10+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.22635v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Spatial Knowledge Graph-Guided Multimodal Synthesis",
      "authors": [
        "Yida Xue",
        "Zhen Bi",
        "Jinnan Yang",
        "Jungang Lou",
        "Huajun Chen",
        "Ningyu Zhang"
      ],
      "abstract": "Recent advances in multimodal large language models (MLLMs) have\nsignificantly enhanced their capabilities; however, their spatial perception\nabilities remain a notable limitation. To address this challenge, multimodal\ndata synthesis offers a promising solution. Yet, ensuring that synthesized data\nadhere to spatial common sense is a non-trivial task. In this work, we\nintroduce SKG2Data, a novel multimodal synthesis approach guided by spatial\nknowledge graphs, grounded in the concept of knowledge-to-data generation.\nSKG2Data automatically constructs a Spatial Knowledge Graph (SKG) to emulate\nhuman-like perception of spatial directions and distances, which is\nsubsequently utilized to guide multimodal data synthesis. Extensive experiments\ndemonstrate that data synthesized from diverse types of spatial knowledge,\nincluding direction and distance, not only enhance the spatial perception and\nreasoning abilities of MLLMs but also exhibit strong generalization\ncapabilities. We hope that the idea of knowledge-based data synthesis can\nadvance the development of spatial intelligence.",
      "pdf_url": "http://arxiv.org/pdf/2505.22633v1",
      "published": "2025-05-28T17:50:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.22633v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.MM"
      ]
    },
    {
      "title": "SCIZOR: A Self-Supervised Approach to Data Curation for Large-Scale Imitation Learning",
      "authors": [
        "Yu Zhang",
        "Yuqi Xie",
        "Huihan Liu",
        "Rutav Shah",
        "Michael Wan",
        "Linxi Fan",
        "Yuke Zhu"
      ],
      "abstract": "Imitation learning advances robot capabilities by enabling the acquisition of\ndiverse behaviors from human demonstrations. However, large-scale datasets used\nfor policy training often introduce substantial variability in quality, which\ncan negatively impact performance. As a result, automatically curating datasets\nby filtering low-quality samples to improve quality becomes essential. Existing\nrobotic curation approaches rely on costly manual annotations and perform\ncuration at a coarse granularity, such as the dataset or trajectory level,\nfailing to account for the quality of individual state-action pairs. To address\nthis, we introduce SCIZOR, a self-supervised data curation framework that\nfilters out low-quality state-action pairs to improve the performance of\nimitation learning policies. SCIZOR targets two complementary sources of\nlow-quality data: suboptimal data, which hinders learning with undesirable\nactions, and redundant data, which dilutes training with repetitive patterns.\nSCIZOR leverages a self-supervised task progress predictor for suboptimal data\nto remove samples lacking task progression, and a deduplication module\noperating on joint state-action representation for samples with redundant\npatterns. Empirically, we show that SCIZOR enables imitation learning policies\nto achieve higher performance with less data, yielding an average improvement\nof 15.4% across multiple benchmarks. More information is available at:\nhttps://ut-austin-rpl.github.io/SCIZOR/",
      "pdf_url": "http://arxiv.org/pdf/2505.22626v1",
      "published": "2025-05-28T17:45:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.22626v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "The Entropy Mechanism of Reinforcement Learning for Reasoning Language Models",
      "authors": [
        "Ganqu Cui",
        "Yuchen Zhang",
        "Jiacheng Chen",
        "Lifan Yuan",
        "Zhi Wang",
        "Yuxin Zuo",
        "Haozhan Li",
        "Yuchen Fan",
        "Huayu Chen",
        "Weize Chen",
        "Zhiyuan Liu",
        "Hao Peng",
        "Lei Bai",
        "Wanli Ouyang",
        "Yu Cheng",
        "Bowen Zhou",
        "Ning Ding"
      ],
      "abstract": "This paper aims to overcome a major obstacle in scaling RL for reasoning with\nLLMs, namely the collapse of policy entropy. Such phenomenon is consistently\nobserved across vast RL runs without entropy intervention, where the policy\nentropy dropped sharply at the early training stage, this diminished\nexploratory ability is always accompanied with the saturation of policy\nperformance. In practice, we establish a transformation equation R=-a*e^H+b\nbetween entropy H and downstream performance R. This empirical law strongly\nindicates that, the policy performance is traded from policy entropy, thus\nbottlenecked by its exhaustion, and the ceiling is fully predictable H=0,\nR=-a+b. Our finding necessitates entropy management for continuous exploration\ntoward scaling compute for RL. To this end, we investigate entropy dynamics\nboth theoretically and empirically. Our derivation highlights that, the change\nin policy entropy is driven by the covariance between action probability and\nthe change in logits, which is proportional to its advantage when using Policy\nGradient-like algorithms. Empirical study shows that, the values of covariance\nterm and entropy differences matched exactly, supporting the theoretical\nconclusion. Moreover, the covariance term stays mostly positive throughout\ntraining, further explaining why policy entropy would decrease monotonically.\nThrough understanding the mechanism behind entropy dynamics, we motivate to\ncontrol entropy by restricting the update of high-covariance tokens.\nSpecifically, we propose two simple yet effective techniques, namely Clip-Cov\nand KL-Cov, which clip and apply KL penalty to tokens with high covariances\nrespectively. Experiments show that these methods encourage exploration, thus\nhelping policy escape entropy collapse and achieve better downstream\nperformance.",
      "pdf_url": "http://arxiv.org/pdf/2505.22617v1",
      "published": "2025-05-28T17:38:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.22617v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "RICO: Improving Accuracy and Completeness in Image Recaptioning via Visual Reconstruction",
      "authors": [
        "Yuchi Wang",
        "Yishuo Cai",
        "Shuhuai Ren",
        "Sihan Yang",
        "Linli Yao",
        "Yuanxin Liu",
        "Yuanxing Zhang",
        "Pengfei Wan",
        "Xu Sun"
      ],
      "abstract": "Image recaptioning is widely used to generate training datasets with enhanced\nquality for various multimodal tasks. Existing recaptioning methods typically\nrely on powerful multimodal large language models (MLLMs) to enhance textual\ndescriptions, but often suffer from inaccuracies due to hallucinations and\nincompleteness caused by missing fine-grained details. To address these\nlimitations, we propose RICO, a novel framework that refines captions through\nvisual reconstruction. Specifically, we leverage a text-to-image model to\nreconstruct a caption into a reference image, and prompt an MLLM to identify\ndiscrepancies between the original and reconstructed images to refine the\ncaption. This process is performed iteratively, further progressively promoting\nthe generation of more faithful and comprehensive descriptions. To mitigate the\nadditional computational cost induced by the iterative process, we introduce\nRICO-Flash, which learns to generate captions like RICO using DPO. Extensive\nexperiments demonstrate that our approach significantly improves caption\naccuracy and completeness, outperforms most baselines by approximately 10% on\nboth CapsBench and CompreCap. Code released at\nhttps://github.com/wangyuchi369/RICO.",
      "pdf_url": "http://arxiv.org/pdf/2505.22613v1",
      "published": "2025-05-28T17:29:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.22613v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Effective and Efficient One-pass Compression of Speech Foundation Models Using Sparsity-aware Self-pinching Gates",
      "authors": [
        "Haoning Xu",
        "Zhaoqing Li",
        "Youjun Chen",
        "Huimeng Wang",
        "Guinan Li",
        "Mengzhe Geng",
        "Chengxi Deng",
        "Xunying Liu"
      ],
      "abstract": "This paper presents a novel approach for speech foundation models compression\nthat tightly integrates model pruning and parameter update into a single stage.\nHighly compact layer-level tied self-pinching gates each containing only a\nsingle learnable threshold are jointly trained with uncompressed models and\nused in fine-grained neuron level pruning. Experiments conducted on the\nLibriSpeech-100hr corpus suggest that our approach reduces the number of\nparameters of wav2vec2.0-base and HuBERT-large models by 65% and 60%\nrespectively, while incurring no statistically significant word error rate\n(WER) increase on the test-clean dataset. Compared to previously published\nmethods on the same task, our approach not only achieves the lowest WER of\n7.05% on the test-clean dataset under a comparable model compression ratio of\n4.26x, but also operates with at least 25% less model compression time.",
      "pdf_url": "http://arxiv.org/pdf/2505.22608v1",
      "published": "2025-05-28T17:24:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.22608v1",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ]
    },
    {
      "title": "One Rank at a Time: Cascading Error Dynamics in Sequential Learning",
      "authors": [
        "Mahtab Alizadeh Vandchali",
        "Fangshuo",
        "Liao",
        "Anastasios Kyrillidis"
      ],
      "abstract": "Sequential learning -- where complex tasks are broken down into simpler,\nhierarchical components -- has emerged as a paradigm in AI. This paper views\nsequential learning through the lens of low-rank linear regression, focusing\nspecifically on how errors propagate when learning rank-1 subspaces\nsequentially. We present an analysis framework that decomposes the learning\nprocess into a series of rank-1 estimation problems, where each subsequent\nestimation depends on the accuracy of previous steps. Our contribution is a\ncharacterization of the error propagation in this sequential process,\nestablishing bounds on how errors -- e.g., due to limited computational budgets\nand finite precision -- affect the overall model accuracy. We prove that these\nerrors compound in predictable ways, with implications for both algorithmic\ndesign and stability guarantees.",
      "pdf_url": "http://arxiv.org/pdf/2505.22602v1",
      "published": "2025-05-28T17:16:24+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.22602v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ]
    },
    {
      "title": "Machine Unlearning under Overparameterization",
      "authors": [
        "Jacob L. Block",
        "Aryan Mokhtari",
        "Sanjay Shakkottai"
      ],
      "abstract": "Machine unlearning algorithms aim to remove the influence of specific\ntraining samples, ideally recovering the model that would have resulted from\ntraining on the remaining data alone. We study unlearning in the\noverparameterized setting, where many models interpolate the data, and defining\nthe unlearning solution as any loss minimizer over the retained\nset$\\unicode{x2013}$as in prior work in the underparameterized\nsetting$\\unicode{x2013}$is inadequate, since the original model may already\ninterpolate the retained data and satisfy this condition. In this regime, loss\ngradients vanish, rendering prior methods based on gradient perturbations\nineffective, motivating both new unlearning definitions and algorithms. For\nthis setting, we define the unlearning solution as the minimum-complexity\ninterpolator over the retained data and propose a new algorithmic framework\nthat only requires access to model gradients on the retained set at the\noriginal solution. We minimize a regularized objective over perturbations\nconstrained to be orthogonal to these model gradients, a first-order relaxation\nof the interpolation condition. For different model classes, we provide exact\nand approximate unlearning guarantees, and we demonstrate that an\nimplementation of our framework outperforms existing baselines across various\nunlearning experiments.",
      "pdf_url": "http://arxiv.org/pdf/2505.22601v1",
      "published": "2025-05-28T17:14:57+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.22601v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "On the performance of machine-learning-assisted Monte Carlo in sampling from simple statistical physics models",
      "authors": [
        "Luca Maria Del Bono",
        "Federico Ricci-Tersenghi",
        "Francesco Zamponi"
      ],
      "abstract": "Recent years have seen a rise in the application of machine learning\ntechniques to aid the simulation of hard-to-sample systems that cannot be\nstudied using traditional methods. Despite the introduction of many different\narchitectures and procedures, a wide theoretical understanding is still\nlacking, with the risk of suboptimal implementations. As a first step to\naddress this gap, we provide here a complete analytic study of the widely-used\nSequential Tempering procedure applied to a shallow MADE architecture for the\nCurie-Weiss model. The contribution of this work is twofold: firstly, we give a\ndescription of the optimal weights and of the training under Gradient Descent\noptimization. Secondly, we compare what happens in Sequential Tempering with\nand without the addition of local Metropolis Monte Carlo steps. We are thus\nable to give theoretical predictions on the best procedure to apply in this\ncase. This work establishes a clear theoretical basis for the integration of\nmachine learning techniques into Monte Carlo sampling and optimization.",
      "pdf_url": "http://arxiv.org/pdf/2505.22598v2",
      "published": "2025-05-28T17:13:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.22598v2",
      "categories": [
        "cond-mat.dis-nn",
        "cond-mat.stat-mech",
        "cs.AI",
        "cs.LG",
        "physics.comp-ph"
      ]
    },
    {
      "title": "HDDLGym: A Tool for Studying Multi-Agent Hierarchical Problems Defined in HDDL with OpenAI Gym",
      "authors": [
        "Ngoc La",
        "Ruaridh Mon-Williams",
        "Julie A. Shah"
      ],
      "abstract": "In recent years, reinforcement learning (RL) methods have been widely tested\nusing tools like OpenAI Gym, though many tasks in these environments could also\nbenefit from hierarchical planning. However, there is a lack of a tool that\nenables seamless integration of hierarchical planning with RL. Hierarchical\nDomain Definition Language (HDDL), used in classical planning, introduces a\nstructured approach well-suited for model-based RL to address this gap. To\nbridge this integration, we introduce HDDLGym, a Python-based tool that\nautomatically generates OpenAI Gym environments from HDDL domains and problems.\nHDDLGym serves as a link between RL and hierarchical planning, supporting\nmulti-agent scenarios and enabling collaborative planning among agents. This\npaper provides an overview of HDDLGym's design and implementation, highlighting\nthe challenges and design choices involved in integrating HDDL with the Gym\ninterface, and applying RL policies to support hierarchical planning. We also\nprovide detailed instructions and demonstrations for using the HDDLGym\nframework, including how to work with existing HDDL domains and problems from\nInternational Planning Competitions, exemplified by the Transport domain.\nAdditionally, we offer guidance on creating new HDDL domains for multi-agent\nscenarios and demonstrate the practical use of HDDLGym in the Overcooked\ndomain. By leveraging the advantages of HDDL and Gym, HDDLGym aims to be a\nvaluable tool for studying RL in hierarchical planning, particularly in\nmulti-agent contexts.",
      "pdf_url": "http://arxiv.org/pdf/2505.22597v1",
      "published": "2025-05-28T17:10:43+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.22597v1",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ]
    },
    {
      "title": "Self-Error-Instruct: Generalizing from Errors for LLMs Mathematical Reasoning",
      "authors": [
        "Erxin Yu",
        "Jing Li",
        "Ming Liao",
        "Qi Zhu",
        "Boyang Xue",
        "Minghui Xu",
        "Baojun Wang",
        "Lanqing Hong",
        "Fei Mi",
        "Lifeng Shang"
      ],
      "abstract": "Although large language models demonstrate strong performance across various\ndomains, they still struggle with numerous bad cases in mathematical reasoning.\nPrevious approaches to learning from errors synthesize training data by solely\nextrapolating from isolated bad cases, thereby failing to generalize the\nextensive patterns inherent within these cases. This paper presents\nSelf-Error-Instruct (SEI), a framework that addresses these model weaknesses\nand synthesizes more generalized targeted training data. Specifically, we\nexplore a target model on two mathematical datasets, GSM8K and MATH, to\npinpoint bad cases. Then, we generate error keyphrases for these cases based on\nthe instructor model's (GPT-4o) analysis and identify error types by clustering\nthese keyphrases. Next, we sample a few bad cases during each generation for\neach identified error type and input them into the instructor model, which\nsynthesizes additional training data using a self-instruct approach. This new\ndata is refined through a one-shot learning process to ensure that only the\nmost effective examples are kept. Finally, we use these curated data to\nfine-tune the target model, iteratively repeating the process to enhance\nperformance. We apply our framework to various models and observe improvements\nin their reasoning abilities across both in-domain and out-of-domain\nmathematics datasets. These results demonstrate the effectiveness of self-error\ninstruction in improving LLMs' mathematical reasoning through error\ngeneralization.",
      "pdf_url": "http://arxiv.org/pdf/2505.22591v1",
      "published": "2025-05-28T17:02:47+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.22591v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "GitGoodBench: A Novel Benchmark For Evaluating Agentic Performance On Git",
      "authors": [
        "Tobias Lindenbauer",
        "Egor Bogomolov",
        "Yaroslav Zharov"
      ],
      "abstract": "Benchmarks for Software Engineering (SE) AI agents, most notably SWE-bench,\nhave catalyzed progress in programming capabilities of AI agents. However, they\noverlook critical developer workflows such as Version Control System (VCS)\noperations. To address this issue, we present GitGoodBench, a novel benchmark\nfor evaluating AI agent performance on VCS tasks. GitGoodBench covers three\ncore Git scenarios extracted from permissive open-source Python, Java, and\nKotlin repositories. Our benchmark provides three datasets: a comprehensive\nevaluation suite (900 samples), a rapid prototyping version (120 samples), and\na training corpus (17,469 samples). We establish baseline performance on the\nprototyping version of our benchmark using GPT-4o equipped with custom tools,\nachieving a 21.11% solve rate overall. We expect GitGoodBench to serve as a\ncrucial stepping stone toward truly comprehensive SE agents that go beyond mere\nprogramming.",
      "pdf_url": "http://arxiv.org/pdf/2505.22583v1",
      "published": "2025-05-28T16:56:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.22583v1",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "Tell me Habibi, is it Real or Fake?",
      "authors": [
        "Kartik Kuckreja",
        "Parul Gupta",
        "Injy Hamed",
        "Thamar Solorio",
        "Muhammad Haris Khan",
        "Abhinav Dhall"
      ],
      "abstract": "Deepfake generation methods are evolving fast, making fake media harder to\ndetect and raising serious societal concerns. Most deepfake detection and\ndataset creation research focuses on monolingual content, often overlooking the\nchallenges of multilingual and code-switched speech, where multiple languages\nare mixed within the same discourse. Code-switching, especially between Arabic\nand English, is common in the Arab world and is widely used in digital\ncommunication. This linguistic mixing poses extra challenges for deepfake\ndetection, as it can confuse models trained mostly on monolingual data. To\naddress this, we introduce \\textbf{ArEnAV}, the first large-scale\nArabic-English audio-visual deepfake dataset featuring intra-utterance\ncode-switching, dialectal variation, and monolingual Arabic content. It\n\\textbf{contains 387k videos and over 765 hours of real and fake videos}. Our\ndataset is generated using a novel pipeline integrating four Text-To-Speech and\ntwo lip-sync models, enabling comprehensive analysis of multilingual multimodal\ndeepfake detection. We benchmark our dataset against existing monolingual and\nmultilingual datasets, state-of-the-art deepfake detection models, and a human\nevaluation, highlighting its potential to advance deepfake research. The\ndataset can be accessed\n\\href{https://huggingface.co/datasets/kartik060702/ArEnAV-Full}{here}.",
      "pdf_url": "http://arxiv.org/pdf/2505.22581v1",
      "published": "2025-05-28T16:54:36+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.22581v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Fusion Steering: Prompt-Specific Activation Control",
      "authors": [
        "Waldemar Chang",
        "Alhassan Yasin"
      ],
      "abstract": "We present Fusion Steering, an activation steering methodology that improves\nfactual accuracy in large language models (LLMs) for question-answering (QA)\ntasks. This approach introduces flexible steering configurations, including\nfull-layer steering and segmented steering. Unlike traditional methods\nconstrained to single-layer or fixed-layer operations, Fusion Steering employs\ndynamic injection of prompt-specific activation deltas across all transformer\nlayers. These activation deltas are derived from reference completions that\ncombine the ground-truth answer with a model-generated explanation to\nfacilitate semantically enriched, example-specific steering. The injection\nweights are optimized per prompt using Optuna, targeting a joint objective that\nbalances token overlap (factual alignment) and perplexity (fluency proxy).\nEvaluation employs a composite score integrating token overlap and LLM-graded\nquality, encompassing factual accuracy, coherence, and relevance. Empirical\nresults on 260 SimpleQA prompts (selected from 500 where the baseline failed)\nshowcase the efficacy of segmented steering. Using Gemma-2-2B-IT with 8-bit\nquantization, segmented steering achieves an accuracy of 25.4% (outputs scoring\n$\\geq 0.6$), outperforming the baseline at 3.5% and full-layer steering at\n16.2%. Under the stricter SimpleQA rubric, segmented steering boosts fully\ncorrect responses from 0.0% to 13.1%. These findings highlight the strengths of\nsegmented, dynamic intervention strategies and the promise of per-prompt,\nfull-network activation control. Fusion Steering is also amenable to sparse\nrepresentations, such as Neuronpedia or sparse crosscoders, suggesting a\npromising direction for interpretable and scalable activation-level control in\nLLMs.",
      "pdf_url": "http://arxiv.org/pdf/2505.22572v1",
      "published": "2025-05-28T16:46:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.22572v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Agent-UniRAG: A Trainable Open-Source LLM Agent Framework for Unified Retrieval-Augmented Generation Systems",
      "authors": [
        "Hoang Pham",
        "Thuy-Duong Nguyen",
        "Khac-Hoai Nam Bui"
      ],
      "abstract": "This paper presents a novel approach for unified retrieval-augmented\ngeneration (RAG) systems using the recent emerging large language model (LLM)\nagent concept. Specifically, Agent LLM, which utilizes LLM as fundamental\ncontrollers, has become a promising approach to enable the interpretability of\nRAG tasks, especially for complex reasoning question-answering systems (e.g.,\nmulti-hop queries). Nonetheless, previous works mainly focus on solving RAG\nsystems with either single-hop or multi-hop approaches separately, which limits\nthe application of those approaches to real-world applications. In this study,\nwe propose a trainable agent framework called Agent-UniRAG for unified\nretrieval-augmented LLM systems, which enhances the effectiveness and\ninterpretability of RAG systems. The main idea is to design an LLM agent\nframework to solve RAG tasks step-by-step based on the complexity of the\ninputs, simultaneously including single-hop and multi-hop queries in an\nend-to-end manner. Furthermore, we introduce SynAgent-RAG, a synthetic dataset\nto enable the proposed agent framework for small open-source LLMs (e.g.,\nLlama-3-8B). The results show comparable performances with closed-source and\nlarger open-source LLMs across various RAG benchmarks. Our source code and\ndataset are publicly available for further exploitation.",
      "pdf_url": "http://arxiv.org/pdf/2505.22571v2",
      "published": "2025-05-28T16:46:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.22571v2",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DB",
        "cs.IR"
      ]
    },
    {
      "title": "Universal Visuo-Tactile Video Understanding for Embodied Interaction",
      "authors": [
        "Yifan Xie",
        "Mingyang Li",
        "Shoujie Li",
        "Xingting Li",
        "Guangyu Chen",
        "Fei Ma",
        "Fei Richard Yu",
        "Wenbo Ding"
      ],
      "abstract": "Tactile perception is essential for embodied agents to understand physical\nattributes of objects that cannot be determined through visual inspection\nalone. While existing approaches have made progress in visual and language\nmodalities for physical understanding, they fail to effectively incorporate\ntactile information that provides crucial haptic feedback for real-world\ninteraction. In this paper, we present VTV-LLM, the first multi-modal large\nlanguage model for universal Visuo-Tactile Video (VTV) understanding that\nbridges the gap between tactile perception and natural language. To address the\nchallenges of cross-sensor and cross-modal integration, we contribute VTV150K,\na comprehensive dataset comprising 150,000 video frames from 100 diverse\nobjects captured across three different tactile sensors (GelSight Mini, DIGIT,\nand Tac3D), annotated with four fundamental tactile attributes (hardness,\nprotrusion, elasticity, and friction). We develop a novel three-stage training\nparadigm that includes VTV enhancement for robust visuo-tactile representation,\nVTV-text alignment for cross-modal correspondence, and text prompt finetuning\nfor natural language generation. Our framework enables sophisticated tactile\nreasoning capabilities including feature assessment, comparative analysis,\nscenario-based decision making and so on. Experimental evaluations demonstrate\nthat VTV-LLM achieves superior performance in tactile video understanding\ntasks, establishing a foundation for more intuitive human-machine interaction\nin tactile domains.",
      "pdf_url": "http://arxiv.org/pdf/2505.22566v1",
      "published": "2025-05-28T16:43:01+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.22566v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "PRISM: Video Dataset Condensation with Progressive Refinement and Insertion for Sparse Motion",
      "authors": [
        "Jaehyun Choi",
        "Jiwan Hur",
        "Gyojin Han",
        "Jaemyung Yu",
        "Junmo Kim"
      ],
      "abstract": "Video dataset condensation has emerged as a critical technique for addressing\nthe computational challenges associated with large-scale video data processing\nin deep learning applications. While significant progress has been made in\nimage dataset condensation, the video domain presents unique challenges due to\nthe complex interplay between spatial content and temporal dynamics. This paper\nintroduces PRISM, Progressive Refinement and Insertion for Sparse Motion, for\nvideo dataset condensation, a novel approach that fundamentally reconsiders how\nvideo data should be condensed. Unlike the previous method that separates\nstatic content from dynamic motion, our method preserves the essential\ninterdependence between these elements. Our approach progressively refines and\ninserts frames to fully accommodate the motion in an action while achieving\nbetter performance but less storage, considering the relation of gradients for\neach frame. Extensive experiments across standard video action recognition\nbenchmarks demonstrate that PRISM outperforms existing disentangled approaches\nwhile maintaining compact representations suitable for resource-constrained\nenvironments.",
      "pdf_url": "http://arxiv.org/pdf/2505.22564v1",
      "published": "2025-05-28T16:42:10+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.22564v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "ClaimPKG: Enhancing Claim Verification via Pseudo-Subgraph Generation with Lightweight Specialized LLM",
      "authors": [
        "Hoang Pham",
        "Thanh-Do Nguyen",
        "Khac-Hoai Nam Bui"
      ],
      "abstract": "Integrating knowledge graphs (KGs) to enhance the reasoning capabilities of\nlarge language models (LLMs) is an emerging research challenge in claim\nverification. While KGs provide structured, semantically rich representations\nwell-suited for reasoning, most existing verification methods rely on\nunstructured text corpora, limiting their ability to effectively leverage KGs.\nAdditionally, despite possessing strong reasoning abilities, modern LLMs\nstruggle with multi-step modular pipelines and reasoning over KGs without\nadaptation. To address these challenges, we propose ClaimPKG, an end-to-end\nframework that seamlessly integrates LLM reasoning with structured knowledge\nfrom KGs. Specifically, the main idea of ClaimPKG is to employ a lightweight,\nspecialized LLM to represent the input claim as pseudo-subgraphs, guiding a\ndedicated subgraph retrieval module to identify relevant KG subgraphs. These\nretrieved subgraphs are then processed by a general-purpose LLM to produce the\nfinal verdict and justification. Extensive experiments on the FactKG dataset\ndemonstrate that ClaimPKG achieves state-of-the-art performance, outperforming\nstrong baselines in this research field by 9%-12% accuracy points across\nmultiple categories. Furthermore, ClaimPKG exhibits zero-shot generalizability\nto unstructured datasets such as HoVer and FEVEROUS, effectively combining\nstructured knowledge from KGs with LLM reasoning across various LLM backbones.",
      "pdf_url": "http://arxiv.org/pdf/2505.22552v1",
      "published": "2025-05-28T16:34:14+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.22552v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DB"
      ]
    },
    {
      "title": "Scaling-up Perceptual Video Quality Assessment",
      "authors": [
        "Ziheng Jia",
        "Zicheng Zhang",
        "Zeyu Zhang",
        "Yingji Liang",
        "Xiaorong Zhu",
        "Chunyi Li",
        "Jinliang Han",
        "Haoning Wu",
        "Bin Wang",
        "Haoran Zhang",
        "Guanyu Zhu",
        "Qiyong Zhao",
        "Xiaohong Liu",
        "Guangtao Zhai",
        "Xiongkuo Min"
      ],
      "abstract": "The data scaling law has been shown to significantly enhance the performance\nof large multi-modal models (LMMs) across various downstream tasks. However, in\nthe domain of perceptual video quality assessment (VQA), the potential of\nscaling law remains unprecedented due to the scarcity of labeled resources and\nthe insufficient scale of datasets. To address this, we propose\n\\textbf{OmniVQA}, an efficient framework designed to efficiently build\nhigh-quality, human-in-the-loop VQA multi-modal instruction databases (MIDBs).\nWe then scale up to create \\textbf{OmniVQA-Chat-400K}, the largest MIDB in the\nVQA field concurrently. Our focus is on the technical and aesthetic quality\ndimensions, with abundant in-context instruction data to provide fine-grained\nVQA knowledge. Additionally, we have built the \\textbf{OmniVQA-MOS-20K} dataset\nto enhance the model's quantitative quality rating capabilities. We then\nintroduce a \\textbf{complementary} training strategy that effectively leverages\nthe knowledge from datasets for quality understanding and quality rating tasks.\nFurthermore, we propose the \\textbf{OmniVQA-FG (fine-grain)-Benchmark} to\nevaluate the fine-grained performance of the models. Our results demonstrate\nthat our models achieve state-of-the-art performance in both quality\nunderstanding and rating tasks.",
      "pdf_url": "http://arxiv.org/pdf/2505.22543v1",
      "published": "2025-05-28T16:24:52+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.22543v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "TabularQGAN: A Quantum Generative Model for Tabular Data",
      "authors": [
        "Pallavi Bhardwaj",
        "Caitlin Jones",
        "Lasse Dierich",
        "Aleksandar Vučković"
      ],
      "abstract": "In this paper, we introduce a novel quantum generative model for synthesizing\ntabular data. Synthetic data is valuable in scenarios where real-world data is\nscarce or private, it can be used to augment or replace existing datasets.\nReal-world enterprise data is predominantly tabular and heterogeneous, often\ncomprising a mixture of categorical and numerical features, making it highly\nrelevant across various industries such as healthcare, finance, and software.\nWe propose a quantum generative adversarial network architecture with flexible\ndata encoding and a novel quantum circuit ansatz to effectively model tabular\ndata. The proposed approach is tested on the MIMIC III healthcare and Adult\nCensus datasets, with extensive benchmarking against leading classical models,\nCTGAN, and CopulaGAN. Experimental results demonstrate that our quantum model\noutperforms classical models by an average of 8.5% with respect to an overall\nsimilarity score from SDMetrics, while using only 0.072% of the parameters of\nthe classical models. Additionally, we evaluate the generalization capabilities\nof the models using two custom-designed metrics that demonstrate the ability of\nthe proposed quantum model to generate useful and novel samples. To our\nknowledge, this is one of the first demonstrations of a successful quantum\ngenerative model for handling tabular data, indicating that this task could be\nwell-suited to quantum computers.",
      "pdf_url": "http://arxiv.org/pdf/2505.22533v1",
      "published": "2025-05-28T16:19:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.22533v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "quant-ph"
      ]
    },
    {
      "title": "Training RL Agents for Multi-Objective Network Defense Tasks",
      "authors": [
        "Andres Molina-Markham",
        "Luis Robaina",
        "Sean Steinle",
        "Akash Trivedi",
        "Derek Tsui",
        "Nicholas Potteiger",
        "Lauren Brandt",
        "Ransom Winder",
        "Ahmed Ridley"
      ],
      "abstract": "Open-ended learning (OEL) -- which emphasizes training agents that achieve\nbroad capability over narrow competency -- is emerging as a paradigm to develop\nartificial intelligence (AI) agents to achieve robustness and generalization.\nHowever, despite promising results that demonstrate the benefits of OEL,\napplying OEL to develop autonomous agents for real-world cybersecurity\napplications remains a challenge.\n  We propose a training approach, inspired by OEL, to develop autonomous\nnetwork defenders. Our results demonstrate that like in other domains, OEL\nprinciples can translate into more robust and generalizable agents for cyber\ndefense. To apply OEL to network defense, it is necessary to address several\ntechnical challenges. Most importantly, it is critical to provide a task\nrepresentation approach over a broad universe of tasks that maintains a\nconsistent interface over goals, rewards and action spaces. This way, the\nlearning agent can train with varying network conditions, attacker behaviors,\nand defender goals while being able to build on previously gained knowledge.\n  With our tools and results, we aim to fundamentally impact research that\napplies AI to solve cybersecurity problems. Specifically, as researchers\ndevelop gyms and benchmarks for cyber defense, it is paramount that they\nconsider diverse tasks with consistent representations, such as those we\npropose in our work.",
      "pdf_url": "http://arxiv.org/pdf/2505.22531v1",
      "published": "2025-05-28T16:18:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.22531v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ]
    },
    {
      "title": "Thinking with Generated Images",
      "authors": [
        "Ethan Chern",
        "Zhulin Hu",
        "Steffi Chern",
        "Siqi Kou",
        "Jiadi Su",
        "Yan Ma",
        "Zhijie Deng",
        "Pengfei Liu"
      ],
      "abstract": "We present Thinking with Generated Images, a novel paradigm that\nfundamentally transforms how large multimodal models (LMMs) engage with visual\nreasoning by enabling them to natively think across text and vision modalities\nthrough spontaneous generation of intermediate visual thinking steps. Current\nvisual reasoning with LMMs is constrained to either processing fixed\nuser-provided images or reasoning solely through text-based chain-of-thought\n(CoT). Thinking with Generated Images unlocks a new dimension of cognitive\ncapability where models can actively construct intermediate visual thoughts,\ncritique their own visual hypotheses, and refine them as integral components of\ntheir reasoning process. We demonstrate the effectiveness of our approach\nthrough two complementary mechanisms: (1) vision generation with intermediate\nvisual subgoals, where models decompose complex visual tasks into manageable\ncomponents that are generated and integrated progressively, and (2) vision\ngeneration with self-critique, where models generate an initial visual\nhypothesis, analyze its shortcomings through textual reasoning, and produce\nrefined outputs based on their own critiques. Our experiments on vision\ngeneration benchmarks show substantial improvements over baseline approaches,\nwith our models achieving up to 50% (from 38% to 57%) relative improvement in\nhandling complex multi-object scenarios. From biochemists exploring novel\nprotein structures, and architects iterating on spatial designs, to forensic\nanalysts reconstructing crime scenes, and basketball players envisioning\nstrategic plays, our approach enables AI models to engage in the kind of visual\nimagination and iterative refinement that characterizes human creative,\nanalytical, and strategic thinking. We release our open-source suite at\nhttps://github.com/GAIR-NLP/thinking-with-generated-images.",
      "pdf_url": "http://arxiv.org/pdf/2505.22525v1",
      "published": "2025-05-28T16:12:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.22525v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Evaluating Supervised Learning Models for Fraud Detection: A Comparative Study of Classical and Deep Architectures on Imbalanced Transaction Data",
      "authors": [
        "Chao Wang",
        "Chuanhao Nie",
        "Yunbo Liu"
      ],
      "abstract": "Fraud detection remains a critical task in high-stakes domains such as\nfinance and e-commerce, where undetected fraudulent transactions can lead to\nsignificant economic losses. In this study, we systematically compare the\nperformance of four supervised learning models - Logistic Regression, Random\nForest, Light Gradient Boosting Machine (LightGBM), and a Gated Recurrent Unit\n(GRU) network - on a large-scale, highly imbalanced online transaction dataset.\nWhile ensemble methods such as Random Forest and LightGBM demonstrated superior\nperformance in both overall and class-specific metrics, Logistic Regression\noffered a reliable and interpretable baseline. The GRU model showed strong\nrecall for the minority fraud class, though at the cost of precision,\nhighlighting a trade-off relevant for real-world deployment. Our evaluation\nemphasizes not only weighted averages but also per-class precision, recall, and\nF1-scores, providing a nuanced view of each model's effectiveness in detecting\nrare but consequential fraudulent activity. The findings underscore the\nimportance of choosing models based on the specific risk tolerance and\noperational needs of fraud detection systems.",
      "pdf_url": "http://arxiv.org/pdf/2505.22521v1",
      "published": "2025-05-28T16:08:04+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.22521v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Strengthening Proportionality in Temporal Voting",
      "authors": [
        "Bradley Phillips",
        "Edith Elkind",
        "Nicholas Teh",
        "Tomasz Wąs"
      ],
      "abstract": "We study proportional representation in the framework of temporal voting with\napproval ballots. Prior work adapted basic proportional representation concepts\n-- justified representation (JR), proportional JR (PJR), and extended JR (EJR)\n-- from the multiwinner setting to the temporal setting. Our work introduces\nand examines ways of going beyond EJR. Specifically, we consider stronger\nvariants of JR, PJR, and EJR, and introduce temporal adaptations of more\ndemanding multiwinner axioms, such as EJR+, full JR (FJR), full proportional JR\n(FPJR), and the Core. For each of these concepts, we investigate its existence\nand study its relationship to existing notions, thereby establishing a rich\nhierarchy of proportionality concepts. Notably, we show that two of our\nproposed axioms -- EJR+ and FJR -- strengthen EJR while remaining satisfiable\nin every temporal election.",
      "pdf_url": "http://arxiv.org/pdf/2505.22513v1",
      "published": "2025-05-28T16:02:52+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.22513v1",
      "categories": [
        "cs.GT",
        "cs.AI"
      ]
    },
    {
      "title": "From Strangers to Assistants: Fast Desire Alignment for Embodied Agent-User Adaptation",
      "authors": [
        "Yuanfei Wang",
        "Xinju Huang",
        "Fangwei Zhong",
        "Yaodong Yang",
        "Yizhou Wang",
        "Yuanpei Chen",
        "Hao Dong"
      ],
      "abstract": "While embodied agents have made significant progress in performing complex\nphysical tasks, real-world applications demand more than pure task execution.\nThe agents must collaborate with unfamiliar agents and human users, whose goals\nare often vague and implicit. In such settings, interpreting ambiguous\ninstructions and uncovering underlying desires is essential for effective\nassistance. Therefore, fast and accurate desire alignment becomes a critical\ncapability for embodied agents. In this work, we first develop a home\nassistance simulation environment HA-Desire that integrates an LLM-driven human\nuser agent exhibiting realistic value-driven goal selection and communication.\nThe ego agent must interact with this proxy user to infer and adapt to the\nuser's latent desires. To achieve this, we present a novel framework FAMER for\nfast desire alignment, which introduces a desire-based mental reasoning\nmechanism to identify user intent and filter desire-irrelevant actions. We\nfurther design a reflection-based communication module that reduces redundant\ninquiries, and incorporate goal-relevant information extraction with memory\npersistence to improve information reuse and reduce unnecessary exploration.\nExtensive experiments demonstrate that our framework significantly enhances\nboth task execution and communication efficiency, enabling embodied agents to\nquickly adapt to user-specific desires in complex embodied environments.",
      "pdf_url": "http://arxiv.org/pdf/2505.22503v1",
      "published": "2025-05-28T15:51:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.22503v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.MA"
      ]
    },
    {
      "title": "Demystifying the Paradox of Importance Sampling with an Estimated History-Dependent Behavior Policy in Off-Policy Evaluation",
      "authors": [
        "Hongyi Zhou",
        "Josiah P. Hanna",
        "Jin Zhu",
        "Ying Yang",
        "Chengchun Shi"
      ],
      "abstract": "This paper studies off-policy evaluation (OPE) in reinforcement learning with\na focus on behavior policy estimation for importance sampling. Prior work has\nshown empirically that estimating a history-dependent behavior policy can lead\nto lower mean squared error (MSE) even when the true behavior policy is\nMarkovian. However, the question of why the use of history should lower MSE\nremains open. In this paper, we theoretically demystify this paradox by\nderiving a bias-variance decomposition of the MSE of ordinary importance\nsampling (IS) estimators, demonstrating that history-dependent behavior policy\nestimation decreases their asymptotic variances while increasing their\nfinite-sample biases. Additionally, as the estimated behavior policy conditions\non a longer history, we show a consistent decrease in variance. We extend these\nfindings to a range of other OPE estimators, including the sequential IS\nestimator, the doubly robust estimator and the marginalized IS estimator, with\nthe behavior policy estimated either parametrically or non-parametrically.",
      "pdf_url": "http://arxiv.org/pdf/2505.22492v1",
      "published": "2025-05-28T15:42:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.22492v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ]
    },
    {
      "title": "On the Surprising Effectiveness of Large Learning Rates under Standard Width Scaling",
      "authors": [
        "Moritz Haas",
        "Sebastian Bordt",
        "Ulrike von Luxburg",
        "Leena Chennuru Vankadara"
      ],
      "abstract": "The dominant paradigm for training large-scale vision and language models is\nHe initialization and a single global learning rate (\\textit{standard\nparameterization}, SP). Despite its practical success, standard parametrization\nremains poorly understood from a theoretical perspective: Existing\ninfinite-width theory would predict instability under large learning rates and\nvanishing feature learning under stable learning rates. However, empirically\noptimal learning rates consistently decay much slower than theoretically\npredicted. By carefully studying neural network training dynamics, we\ndemonstrate that this discrepancy is not fully explained by finite-width\nphenomena such as catapult effects or a lack of alignment between weights and\nincoming activations. We instead show that the apparent contradiction can be\nfundamentally resolved by taking the loss function into account: In contrast to\nMean Squared Error (MSE) loss, we prove that under cross-entropy (CE) loss, an\nintermediate \\textit{controlled divergence} regime emerges, where logits\ndiverge but loss, gradients, and activations remain stable. Stable training\nunder large learning rates enables persistent feature evolution at scale in all\nhidden layers, which is crucial for the practical success of SP. In experiments\nacross optimizers (SGD, Adam), architectures (MLPs, GPT) and data modalities\n(vision, language), we validate that neural networks operate in this controlled\ndivergence regime under CE loss but not under MSE loss. Our empirical evidence\nsuggests that width-scaling considerations are surprisingly useful for\npredicting empirically optimal learning rate exponents. Finally, our analysis\nclarifies the effectiveness and limitations of recently proposed layerwise\nlearning rate scalings for standard initialization.",
      "pdf_url": "http://arxiv.org/pdf/2505.22491v1",
      "published": "2025-05-28T15:40:48+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.22491v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ]
    },
    {
      "title": "A Closer Look at Multimodal Representation Collapse",
      "authors": [
        "Abhra Chaudhuri",
        "Anjan Dutta",
        "Tu Bui",
        "Serban Georgescu"
      ],
      "abstract": "We aim to develop a fundamental understanding of modality collapse, a\nrecently observed empirical phenomenon wherein models trained for multimodal\nfusion tend to rely only on a subset of the modalities, ignoring the rest. We\nshow that modality collapse happens when noisy features from one modality are\nentangled, via a shared set of neurons in the fusion head, with predictive\nfeatures from another, effectively masking out positive contributions from the\npredictive features of the former modality and leading to its collapse. We\nfurther prove that cross-modal knowledge distillation implicitly disentangles\nsuch representations by freeing up rank bottlenecks in the student encoder,\ndenoising the fusion-head outputs without negatively impacting the predictive\nfeatures from either modality. Based on the above findings, we propose an\nalgorithm that prevents modality collapse through explicit basis reallocation,\nwith applications in dealing with missing modalities. Extensive experiments on\nmultiple multimodal benchmarks validate our theoretical claims. Project page:\nhttps://abhrac.github.io/mmcollapse/.",
      "pdf_url": "http://arxiv.org/pdf/2505.22483v1",
      "published": "2025-05-28T15:31:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.22483v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Human-Centered Human-AI Collaboration (HCHAC)",
      "authors": [
        "Qi Gao",
        "Wei Xu",
        "Hanxi Pan",
        "Mowei Shen",
        "Zaifeng Gao"
      ],
      "abstract": "In the intelligent era, the interaction between humans and intelligent\nsystems fundamentally involves collaboration with autonomous intelligent\nagents. Human-AI Collaboration (HAC) represents a novel type of human-machine\nrelationship facilitated by autonomous intelligent machines equipped with AI\ntechnologies. In this paradigm, AI agents serve not only as auxiliary tools but\nalso as active teammates, partnering with humans to accomplish tasks\ncollaboratively. Human-centered AI (HCAI) emphasizes that humans play critical\nleadership roles in the collaboration. This human-led collaboration imparts new\ndimensions to the human-machine relationship, necessitating innovative research\nperspectives, paradigms, and agenda to address the unique challenges posed by\nHAC. This chapter delves into the essence of HAC from the human-centered\nperspective, outlining its core concepts and distinguishing features. It\nreviews the current research methodologies and research agenda within the HAC\nfield from the HCAI perspective, highlighting advancements and ongoing studies.\nFurthermore, a framework for human-centered HAC (HCHAC) is proposed by\nintegrating these reviews and analyses. A case study of HAC in the context of\nautonomous vehicles is provided, illustrating practical applications and the\nsynergistic interactions between humans and AI agents. Finally, it identifies\npotential future research directions aimed at enhancing the effectiveness,\nreliability, and ethical integration of human-centered HAC systems in diverse\ndomains.",
      "pdf_url": "http://arxiv.org/pdf/2505.22477v1",
      "published": "2025-05-28T15:27:52+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.22477v1",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ]
    },
    {
      "title": "Topological Structure Learning Should Be A Research Priority for LLM-Based Multi-Agent Systems",
      "authors": [
        "Jiaxi Yang",
        "Mengqi Zhang",
        "Yiqiao Jin",
        "Hao Chen",
        "Qingsong Wen",
        "Lu Lin",
        "Yi He",
        "Weijie Xu",
        "James Evans",
        "Jindong Wang"
      ],
      "abstract": "Large Language Model-based Multi-Agent Systems (MASs) have emerged as a\npowerful paradigm for tackling complex tasks through collaborative\nintelligence. Nevertheless, the question of how agents should be structurally\norganized for optimal cooperation remains largely unexplored. In this position\npaper, we aim to gently redirect the focus of the MAS research community toward\nthis critical dimension: develop topology-aware MASs for specific tasks.\nSpecifically, the system consists of three core components - agents,\ncommunication links, and communication patterns - that collectively shape its\ncoordination performance and efficiency. To this end, we introduce a\nsystematic, three-stage framework: agent selection, structure profiling, and\ntopology synthesis. Each stage would trigger new research opportunities in\nareas such as language models, reinforcement learning, graph learning, and\ngenerative modeling; together, they could unleash the full potential of MASs in\ncomplicated real-world applications. Then, we discuss the potential challenges\nand opportunities in the evaluation of multiple systems. We hope our\nperspective and framework can offer critical new insights in the era of agentic\nAI.",
      "pdf_url": "http://arxiv.org/pdf/2505.22467v2",
      "published": "2025-05-28T15:20:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.22467v2",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Fostering Video Reasoning via Next-Event Prediction",
      "authors": [
        "Haonan Wang",
        "Hongfu Liu",
        "Xiangyan Liu",
        "Chao Du",
        "Kenji Kawaguchi",
        "Ye Wang",
        "Tianyu Pang"
      ],
      "abstract": "Next-token prediction serves as the foundational learning task enabling\nreasoning in LLMs. But what should the learning task be when aiming to equip\nMLLMs with temporal reasoning capabilities over video inputs? Existing tasks\nsuch as video question answering often rely on annotations from humans or much\nstronger MLLMs, while video captioning tends to entangle temporal reasoning\nwith spatial information. To address this gap, we propose next-event prediction\n(NEP), a learning task that harnesses future video segments as a rich,\nself-supervised signal to foster temporal reasoning. We segment each video into\npast and future frames: the MLLM takes the past frames as input and predicts a\nsummary of events derived from the future frames, thereby encouraging the model\nto reason temporally in order to complete the task. To support this task, we\ncurate V1-33K, a dataset comprising 33,000 automatically extracted video\nsegments spanning diverse real-world scenarios. We further explore a range of\nvideo instruction-tuning strategies to study their effects on temporal\nreasoning. To evaluate progress, we introduce FutureBench to assess coherence\nin predicting unseen future events. Experiments validate that NEP offers a\nscalable and effective training paradigm for fostering temporal reasoning in\nMLLMs.",
      "pdf_url": "http://arxiv.org/pdf/2505.22457v1",
      "published": "2025-05-28T15:13:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.22457v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Unsupervised Post-Training for Multi-Modal LLM Reasoning via GRPO",
      "authors": [
        "Lai Wei",
        "Yuting Li",
        "Chen Wang",
        "Yue Wang",
        "Linghe Kong",
        "Weiran Huang",
        "Lichao Sun"
      ],
      "abstract": "Improving Multi-modal Large Language Models (MLLMs) in the post-training\nstage typically relies on supervised fine-tuning (SFT) or reinforcement\nlearning (RL). However, these supervised methods require expensive and manually\nannotated multi-modal data--an ultimately unsustainable resource. While recent\nefforts have explored unsupervised post-training, their methods are complex and\ndifficult to iterate. In this work, we are the first to investigate the use of\nGRPO, a stable and scalable online RL algorithm, for enabling continual\nself-improvement without any external supervision. We propose MM-UPT, a simple\nyet effective framework for unsupervised post-training of MLLMs. MM-UPT builds\nupon GRPO, replacing traditional reward signals with a self-rewarding mechanism\nbased on majority voting over multiple sampled responses. Our experiments\ndemonstrate that MM-UPT significantly improves the reasoning ability of\nQwen2.5-VL-7B (e.g., 66.3 %$\\rightarrow$72.9 % on MathVista, 62.9\n%$\\rightarrow$68.7 % on We-Math), using standard dataset without ground truth\nlabels. MM-UPT also outperforms prior unsupervised baselines and even\napproaches the results of supervised GRPO. Furthermore, we show that\nincorporating synthetic questions, generated solely by MLLM itself, can boost\nperformance as well, highlighting a promising approach for scalable\nself-improvement. Overall, MM-UPT offers a new paradigm for continual,\nautonomous enhancement of MLLMs in the absence of external supervision. Our\ncode is available at https://github.com/waltonfuture/MM-UPT.",
      "pdf_url": "http://arxiv.org/pdf/2505.22453v1",
      "published": "2025-05-28T15:11:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.22453v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ]
    },
    {
      "title": "AI Mathematician: Towards Fully Automated Frontier Mathematical Research",
      "authors": [
        "Yuanhang Liu",
        "Yanxing Huang",
        "Yanqiao Wang",
        "Peng Li",
        "Yang Liu"
      ],
      "abstract": "Large Reasoning Models (LRMs) have made significant progress in mathematical\ncapabilities in recent times. However, these successes have been primarily\nconfined to competition-level problems. In this work, we propose AI\nMathematician (AIM) framework, which harnesses the reasoning strength of LRMs\nto support frontier mathematical research. We have identified two critical\nchallenges of mathematical research compared to competition, {\\it the intrinsic\ncomplexity of research problems} and {\\it the requirement of procedural rigor}.\nTo address these challenges, AIM incorporates two core strategies: an\nexploration mechanism to foster longer solution paths, and the pessimistic\nreasonable verification method to ensure reliability.\n  This early version of AIM already exhibits strong capability in tackling\nresearch-level tasks. We conducted extensive experiments across several\nreal-world mathematical topics and obtained promising results. AIM is able to\nautonomously construct substantial portions of proofs and uncover non-trivial\ninsights within each research area. These findings highlight the potential of\nLRMs in mathematical discovery and suggest that LRM-based agent systems could\nsignificantly accelerate mathematical research in the future.",
      "pdf_url": "http://arxiv.org/pdf/2505.22451v1",
      "published": "2025-05-28T15:10:37+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.22451v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "NFR: Neural Feature-Guided Non-Rigid Shape Registration",
      "authors": [
        "Puhua Jiang",
        "Zhangquan Chen",
        "Mingze Sun",
        "Ruqi Huang"
      ],
      "abstract": "In this paper, we propose a novel learning-based framework for 3D shape\nregistration, which overcomes the challenges of significant non-rigid\ndeformation and partiality undergoing among input shapes, and, remarkably,\nrequires no correspondence annotation during training. Our key insight is to\nincorporate neural features learned by deep learning-based shape matching\nnetworks into an iterative, geometric shape registration pipeline. The\nadvantage of our approach is two-fold -- On one hand, neural features provide\nmore accurate and semantically meaningful correspondence estimation than\nspatial features (e.g., coordinates), which is critical in the presence of\nlarge non-rigid deformations; On the other hand, the correspondences are\ndynamically updated according to the intermediate registrations and filtered by\nconsistency prior, which prominently robustify the overall pipeline. Empirical\nresults show that, with as few as dozens of training shapes of limited\nvariability, our pipeline achieves state-of-the-art results on several\nbenchmarks of non-rigid point cloud matching and partial shape matching across\nvarying settings, but also delivers high-quality correspondences between unseen\nchallenging shape pairs that undergo both significant extrinsic and intrinsic\ndeformations, in which case neither traditional registration methods nor\nintrinsic methods work.",
      "pdf_url": "http://arxiv.org/pdf/2505.22445v1",
      "published": "2025-05-28T15:08:49+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.22445v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.4.m; I.2.6"
      ]
    },
    {
      "title": "SOReL and TOReL: Two Methods for Fully Offline Reinforcement Learning",
      "authors": [
        "Mattie Fellows",
        "Clarisse Wibault",
        "Uljad Berdica",
        "Johannes Forkel",
        "Jakob N. Foerster",
        "Michael A. Osborne"
      ],
      "abstract": "Sample efficiency remains a major obstacle for real world adoption of\nreinforcement learning (RL): success has been limited to settings where\nsimulators provide access to essentially unlimited environment interactions,\nwhich in reality are typically costly or dangerous to obtain. Offline RL in\nprinciple offers a solution by exploiting offline data to learn a near-optimal\npolicy before deployment. In practice, however, current offline RL methods rely\non extensive online interactions for hyperparameter tuning, and have no\nreliable bound on their initial online performance. To address these two\nissues, we introduce two algorithms. Firstly, SOReL: an algorithm for safe\noffline reinforcement learning. Using only offline data, our Bayesian approach\ninfers a posterior over environment dynamics to obtain a reliable estimate of\nthe online performance via the posterior predictive uncertainty. Crucially, all\nhyperparameters are also tuned fully offline. Secondly, we introduce TOReL: a\ntuning for offline reinforcement learning algorithm that extends our\ninformation rate based offline hyperparameter tuning methods to general offline\nRL approaches. Our empirical evaluation confirms SOReL's ability to accurately\nestimate regret in the Bayesian setting whilst TOReL's offline hyperparameter\ntuning achieves competitive performance with the best online hyperparameter\ntuning methods using only offline data. Thus, SOReL and TOReL make a\nsignificant step towards safe and reliable offline RL, unlocking the potential\nfor RL in the real world. Our implementations are publicly available:\nhttps://github.com/CWibault/sorel\\_torel.",
      "pdf_url": "http://arxiv.org/pdf/2505.22442v1",
      "published": "2025-05-28T15:07:24+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.22442v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Can NeRFs See without Cameras?",
      "authors": [
        "Chaitanya Amballa",
        "Sattwik Basu",
        "Yu-Lin Wei",
        "Zhijian Yang",
        "Mehmet Ergezer",
        "Romit Roy Choudhury"
      ],
      "abstract": "Neural Radiance Fields (NeRFs) have been remarkably successful at\nsynthesizing novel views of 3D scenes by optimizing a volumetric scene\nfunction. This scene function models how optical rays bring color information\nfrom a 3D object to the camera pixels. Radio frequency (RF) or audio signals\ncan also be viewed as a vehicle for delivering information about the\nenvironment to a sensor. However, unlike camera pixels, an RF/audio sensor\nreceives a mixture of signals that contain many environmental reflections (also\ncalled \"multipath\"). Is it still possible to infer the environment using such\nmultipath signals? We show that with redesign, NeRFs can be taught to learn\nfrom multipath signals, and thereby \"see\" the environment. As a grounding\napplication, we aim to infer the indoor floorplan of a home from sparse WiFi\nmeasurements made at multiple locations inside the home. Although a difficult\ninverse problem, our implicitly learnt floorplans look promising, and enables\nforward applications, such as indoor signal prediction and basic ray tracing.",
      "pdf_url": "http://arxiv.org/pdf/2505.22441v1",
      "published": "2025-05-28T15:04:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.22441v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Synonymous Variational Inference for Perceptual Image Compression",
      "authors": [
        "Zijian Liang",
        "Kai Niu",
        "Changshuo Wang",
        "Jin Xu",
        "Ping Zhang"
      ],
      "abstract": "Recent contributions of semantic information theory reveal the set-element\nrelationship between semantic and syntactic information, represented as\nsynonymous relationships. In this paper, we propose a synonymous variational\ninference (SVI) method based on this synonymity viewpoint to re-analyze the\nperceptual image compression problem. It takes perceptual similarity as a\ntypical synonymous criterion to build an ideal synonymous set (Synset), and\napproximate the posterior of its latent synonymous representation with a\nparametric density by minimizing a partial semantic KL divergence. This\nanalysis theoretically proves that the optimization direction of perception\nimage compression follows a triple tradeoff that can cover the existing\nrate-distortion-perception schemes. Additionally, we introduce synonymous image\ncompression (SIC), a new image compression scheme that corresponds to the\nanalytical process of SVI, and implement a progressive SIC codec to fully\nleverage the model's capabilities. Experimental results demonstrate comparable\nrate-distortion-perception performance using a single progressive SIC codec,\nthus verifying the effectiveness of our proposed analysis method.",
      "pdf_url": "http://arxiv.org/pdf/2505.22438v1",
      "published": "2025-05-28T15:03:27+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.22438v1",
      "categories": [
        "cs.IT",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "eess.IV",
        "math.IT"
      ]
    },
    {
      "title": "Scaling Reasoning without Attention",
      "authors": [
        "Xueliang Zhao",
        "Wei Wu",
        "Lingpeng Kong"
      ],
      "abstract": "Large language models (LLMs) have made significant advances in complex\nreasoning tasks, yet they remain bottlenecked by two core challenges:\narchitectural inefficiency due to reliance on Transformers, and a lack of\nstructured fine-tuning for high-difficulty domains. We introduce \\ourmodel, an\nattention-free language model that addresses both issues through architectural\nand data-centric innovations. Built on the state space dual (SSD) layers of\nMamba-2, our model eliminates the need for self-attention and key-value\ncaching, enabling fixed-memory, constant-time inference. To train it for\ncomplex reasoning, we propose a two-phase curriculum fine-tuning strategy based\non the \\textsc{PromptCoT} synthesis paradigm, which generates pedagogically\nstructured problems via abstract concept selection and rationale-guided\ngeneration. On benchmark evaluations, \\ourmodel-7B outperforms strong\nTransformer and hybrid models of comparable scale, and even surpasses the much\nlarger Gemma3-27B by 2.6\\% on AIME 24, 0.6\\% on AIME 25, and 3.0\\% on\nLivecodebench. These results highlight the potential of state space models as\nefficient and scalable alternatives to attention-based architectures for\nhigh-capacity reasoning.",
      "pdf_url": "http://arxiv.org/pdf/2505.22425v1",
      "published": "2025-05-28T14:52:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.22425v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Mitigating Overthinking in Large Reasoning Models via Manifold Steering",
      "authors": [
        "Yao Huang",
        "Huanran Chen",
        "Shouwei Ruan",
        "Yichi Zhang",
        "Xingxing Wei",
        "Yinpeng Dong"
      ],
      "abstract": "Recent advances in Large Reasoning Models (LRMs) have demonstrated remarkable\ncapabilities in solving complex tasks such as mathematics and coding. However,\nthese models frequently exhibit a phenomenon known as overthinking during\ninference, characterized by excessive validation loops and redundant\ndeliberation, leading to substantial computational overheads. In this paper, we\naim to mitigate overthinking by investigating the underlying mechanisms from\nthe perspective of mechanistic interpretability. We first showcase that the\ntendency of overthinking can be effectively captured by a single direction in\nthe model's activation space and the issue can be eased by intervening the\nactivations along this direction. However, this efficacy soon reaches a plateau\nand even deteriorates as the intervention strength increases. We therefore\nsystematically explore the activation space and find that the overthinking\nphenomenon is actually tied to a low-dimensional manifold, which indicates that\nthe limited effect stems from the noises introduced by the high-dimensional\nsteering direction. Based on this insight, we propose Manifold Steering, a\nnovel approach that elegantly projects the steering direction onto the\nlow-dimensional activation manifold given the theoretical approximation of the\ninterference noise. Extensive experiments on DeepSeek-R1 distilled models\nvalidate that our method reduces output tokens by up to 71% while maintaining\nand even improving the accuracy on several mathematical benchmarks. Our method\nalso exhibits robust cross-domain transferability, delivering consistent token\nreduction performance in code generation and knowledge-based QA tasks. Code is\navailable at: https://github.com/Aries-iai/Manifold_Steering.",
      "pdf_url": "http://arxiv.org/pdf/2505.22411v1",
      "published": "2025-05-28T14:39:26+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.22411v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Physics-Informed Distillation of Diffusion Models for PDE-Constrained Generation",
      "authors": [
        "Yi Zhang",
        "Difan Zou"
      ],
      "abstract": "Modeling physical systems in a generative manner offers several advantages,\nincluding the ability to handle partial observations, generate diverse\nsolutions, and address both forward and inverse problems. Recently, diffusion\nmodels have gained increasing attention in the modeling of physical systems,\nparticularly those governed by partial differential equations (PDEs). However,\ndiffusion models only access noisy data $\\boldsymbol{x}_t$ at intermediate\nsteps, making it infeasible to directly enforce constraints on the clean sample\n$\\boldsymbol{x}_0$ at each noisy level. As a workaround, constraints are\ntypically applied to the expectation of clean samples\n$\\mathbb{E}[\\boldsymbol{x}_0|\\boldsymbol{x}_t]$, which is estimated using the\nlearned score network. However, imposing PDE constraints on the expectation\ndoes not strictly represent the one on the true clean data, known as Jensen's\nGap. This gap creates a trade-off: enforcing PDE constraints may come at the\ncost of reduced accuracy in generative modeling. To address this, we propose a\nsimple yet effective post-hoc distillation approach, where PDE constraints are\nnot injected directly into the diffusion process, but instead enforced during a\npost-hoc distillation stage. We term our method as Physics-Informed\nDistillation of Diffusion Models (PIDDM). This distillation not only\nfacilitates single-step generation with improved PDE satisfaction, but also\nsupport both forward and inverse problem solving and reconstruction from\nrandomly partial observation. Extensive experiments across various PDE\nbenchmarks demonstrate that PIDDM significantly improves PDE satisfaction over\nseveral recent and competitive baselines, such as PIDM, DiffusionPDE, and\nECI-sampling, with less computation overhead. Our approach can shed light on\nmore efficient and effective strategies for incorporating physical constraints\ninto diffusion models.",
      "pdf_url": "http://arxiv.org/pdf/2505.22391v1",
      "published": "2025-05-28T14:17:58+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.22391v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE",
        "cs.NA",
        "math.NA"
      ]
    },
    {
      "title": "Train with Perturbation, Infer after Merging: A Two-Stage Framework for Continual Learning",
      "authors": [
        "Haomiao Qiu",
        "Miao Zhang",
        "Ziyue Qiao",
        "Liqiang Nie"
      ],
      "abstract": "Continual Learning (CL) aims to enable models to continuously acquire new\nknowledge from a sequence of tasks with avoiding the forgetting of learned\ninformation. However, existing CL methods only rely on the parameters of the\nmost recent task for inference, which makes them susceptible to catastrophic\nforgetting. Inspired by the recent success of model merging techniques, we\npropose \\textbf{Perturb-and-Merge (P\\&M)}, a novel continual learning framework\nthat integrates model merging into the CL paradigm to mitigate forgetting.\nSpecifically, after training on each task, P\\&M constructs a new model by\nforming a convex combination of the previous model and the newly trained\ntask-specific model. Through theoretical analysis, we minimize the total loss\nincrease across all tasks and derive an analytical solution for the optimal\nmerging coefficient. To further improve the performance of the merged model, we\nobserve that the degradation introduced during merging can be alleviated by a\nregularization term composed of the task vector and the Hessian matrix of the\nloss function. Interestingly, we show that this term can be efficiently\napproximated using second-order symmetric finite differences, and a stochastic\nperturbation strategy along the task vector direction is accordingly devised\nwhich incurs no additional forward or backward passes while providing an\neffective approximation of the regularization term. Finally, we combine P\\&M\nwith LoRA, a parameter-efficient fine-tuning method, to reduce memory overhead.\nOur proposed approach achieves state-of-the-art performance on several\ncontinual learning benchmark datasets.",
      "pdf_url": "http://arxiv.org/pdf/2505.22389v2",
      "published": "2025-05-28T14:14:19+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.22389v2",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "DAM: Domain-Aware Module for Multi-Domain Dataset Condensation",
      "authors": [
        "Jaehyun Choi",
        "Gyojin Han",
        "Dong-Jae Lee",
        "Sunghyun Baek",
        "Junmo Kim"
      ],
      "abstract": "Dataset Condensation (DC) has emerged as a promising solution to mitigate the\ncomputational and storage burdens associated with training deep learning\nmodels. However, existing DC methods largely overlook the multi-domain nature\nof modern datasets, which are increasingly composed of heterogeneous images\nspanning multiple domains. In this paper, we extend DC and introduce\nMulti-Domain Dataset Condensation (MDDC), which aims to condense data that\ngeneralizes across both single-domain and multi-domain settings. To this end,\nwe propose the Domain-Aware Module (DAM), a training-time module that embeds\ndomain-related features into each synthetic image via learnable spatial masks.\nAs explicit domain labels are mostly unavailable in real-world datasets, we\nemploy frequency-based pseudo-domain labeling, which leverages low-frequency\namplitude statistics. DAM is only active during the condensation process, thus\npreserving the same images per class (IPC) with prior methods. Experiments show\nthat DAM consistently improves in-domain, out-of-domain, and cross-architecture\nperformance over baseline dataset condensation methods.",
      "pdf_url": "http://arxiv.org/pdf/2505.22387v1",
      "published": "2025-05-28T14:13:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.22387v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Exact Algorithms and Lower Bounds for Forming Coalitions of Constrained Maximum Size",
      "authors": [
        "Foivos Fioravantes",
        "Harmender Gahlawat",
        "Nikolaos Melissinos"
      ],
      "abstract": "Imagine we want to split a group of agents into teams in the most\n\\emph{efficient} way, considering that each agent has their own preferences\nabout their teammates. This scenario is modeled by the extensively studied\n\\textsc{Coalition Formation} problem. Here, we study a version of this problem\nwhere each team must additionally be of bounded size.\n  We conduct a systematic algorithmic study, providing several intractability\nresults as well as multiple exact algorithms that scale well as the input grows\n(FPT), which could prove useful in practice.\n  Our main contribution is an algorithm that deals efficiently with tree-like\nstructures (bounded \\emph{treewidth}) for ``small'' teams. We complement this\nresult by proving that our algorithm is asymptotically optimal. Particularly,\nthere can be no algorithm that vastly outperforms the one we present, under\nreasonable theoretical assumptions, even when considering star-like structures\n(bounded \\emph{vertex cover number}).",
      "pdf_url": "http://arxiv.org/pdf/2505.22384v1",
      "published": "2025-05-28T14:11:14+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.22384v1",
      "categories": [
        "cs.DS",
        "cs.AI"
      ]
    },
    {
      "title": "SplitLoRA: Balancing Stability and Plasticity in Continual Learning Through Gradient Space Splitting",
      "authors": [
        "Haomiao Qiu",
        "Miao Zhang",
        "Ziyue Qiao",
        "Weili Guan",
        "Min Zhang",
        "Liqiang Nie"
      ],
      "abstract": "Continual Learning requires a model to learn multiple tasks in sequence while\nmaintaining both stability:preserving knowledge from previously learned tasks,\nand plasticity:effectively learning new tasks. Gradient projection has emerged\nas an effective and popular paradigm in CL, where it partitions the gradient\nspace of previously learned tasks into two orthogonal subspaces: a primary\nsubspace and a minor subspace. New tasks are learned effectively within the\nminor subspace, thereby reducing interference with previously acquired\nknowledge. However, existing Gradient Projection methods struggle to achieve an\noptimal balance between plasticity and stability, as it is hard to\nappropriately partition the gradient space. In this work, we consider a\ncontinual learning paradigm based on Low-Rank Adaptation, which has gained\nconsiderable attention due to its efficiency and wide applicability, and\npropose a novel approach for continual learning, called SplitLoRA. We first\nprovide a theoretical analysis of how subspace partitioning affects model\nstability and plasticity. Informed by this analysis, we then introduce an\neffective method that derives the optimal partition of the gradient space for\npreviously learned tasks. This approach effectively balances stability and\nplasticity in continual learning. Experimental results on multiple datasets\ndemonstrate that the proposed method achieves state-of-the-art performance.",
      "pdf_url": "http://arxiv.org/pdf/2505.22370v2",
      "published": "2025-05-28T13:57:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.22370v2",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "AgentDNS: A Root Domain Naming System for LLM Agents",
      "authors": [
        "Enfang Cui",
        "Yujun Cheng",
        "Rui She",
        "Dan Liu",
        "Zhiyuan Liang",
        "Minxin Guo",
        "Tianzheng Li",
        "Qian Wei",
        "Wenjuan Xing",
        "Zhijie Zhong"
      ],
      "abstract": "The rapid evolution of Large Language Model (LLM) agents has highlighted\ncritical challenges in cross-vendor service discovery, interoperability, and\ncommunication. Existing protocols like model context protocol and\nagent-to-agent protocol have made significant strides in standardizing\ninteroperability between agents and tools, as well as communication among\nmulti-agents. However, there remains a lack of standardized protocols and\nsolutions for service discovery across different agent and tool vendors. In\nthis paper, we propose AgentDNS, a root domain naming and service discovery\nsystem designed to enable LLM agents to autonomously discover, resolve, and\nsecurely invoke third-party agent and tool services across organizational and\ntechnological boundaries. Inspired by the principles of the traditional DNS,\nAgentDNS introduces a structured mechanism for service registration, semantic\nservice discovery, secure invocation, and unified billing. We detail the\narchitecture, core functionalities, and use cases of AgentDNS, demonstrating\nits potential to streamline multi-agent collaboration in real-world scenarios.\nThe source code will be published on https://github.com/agentdns.",
      "pdf_url": "http://arxiv.org/pdf/2505.22368v1",
      "published": "2025-05-28T13:56:22+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.22368v1",
      "categories": [
        "cs.AI"
      ]
    }
  ]
}