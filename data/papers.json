{
  "last_updated": "2025-03-07T00:46:15.365944",
  "papers": [
    {
      "title": "The MASK Benchmark: Disentangling Honesty From Accuracy in AI Systems",
      "authors": [
        "Richard Ren",
        "Arunim Agarwal",
        "Mantas Mazeika",
        "Cristina Menghini",
        "Robert Vacareanu",
        "Brad Kenstler",
        "Mick Yang",
        "Isabelle Barrass",
        "Alice Gatti",
        "Xuwang Yin",
        "Eduardo Trevino",
        "Matias Geralnik",
        "Adam Khoja",
        "Dean Lee",
        "Summer Yue",
        "Dan Hendrycks"
      ],
      "abstract": "As large language models (LLMs) become more capable and agentic, the\nrequirement for trust in their outputs grows significantly, yet at the same\ntime concerns have been mounting that models may learn to lie in pursuit of\ntheir goals. To address these concerns, a body of work has emerged around the\nnotion of \"honesty\" in LLMs, along with interventions aimed at mitigating\ndeceptive behaviors. However, evaluations of honesty are currently highly\nlimited, with no benchmark combining large scale and applicability to all\nmodels. Moreover, many benchmarks claiming to measure honesty in fact simply\nmeasure accuracy--the correctness of a model's beliefs--in disguise. In this\nwork, we introduce a large-scale human-collected dataset for measuring honesty\ndirectly, allowing us to disentangle accuracy from honesty for the first time.\nAcross a diverse set of LLMs, we find that while larger models obtain higher\naccuracy on our benchmark, they do not become more honest. Surprisingly, while\nmost frontier LLMs obtain high scores on truthfulness benchmarks, we find a\nsubstantial propensity in frontier LLMs to lie when pressured to do so,\nresulting in low honesty scores on our benchmark. We find that simple methods,\nsuch as representation engineering interventions, can improve honesty. These\nresults underscore the growing need for robust evaluations and effective\ninterventions to ensure LLMs remain trustworthy.",
      "pdf_url": "http://arxiv.org/pdf/2503.03750v1",
      "published": "2025-03-05T18:59:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.03750v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ]
    },
    {
      "title": "Process-based Self-Rewarding Language Models",
      "authors": [
        "Shimao Zhang",
        "Xiao Liu",
        "Xin Zhang",
        "Junxiao Liu",
        "Zheheng Luo",
        "Shujian Huang",
        "Yeyun Gong"
      ],
      "abstract": "Large Language Models have demonstrated outstanding performance across\nvarious downstream tasks and have been widely applied in multiple scenarios.\nHuman-annotated preference data is used for training to further improve LLMs'\nperformance, which is constrained by the upper limit of human performance.\nTherefore, Self-Rewarding method has been proposed, where LLMs generate\ntraining data by rewarding their own outputs. However, the existing\nself-rewarding paradigm is not effective in mathematical reasoning scenarios\nand may even lead to a decline in performance. In this work, we propose the\nProcess-based Self-Rewarding pipeline for language models, which introduces\nlong-thought reasoning, step-wise LLM-as-a-Judge, and step-wise preference\noptimization within the self-rewarding paradigm. Our new paradigm successfully\nenhances the performance of LLMs on multiple mathematical reasoning benchmarks\nthrough iterative Process-based Self-Rewarding, demonstrating the immense\npotential of self-rewarding to achieve LLM reasoning that may surpass human\ncapabilities.",
      "pdf_url": "http://arxiv.org/pdf/2503.03746v1",
      "published": "2025-03-05T18:58:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.03746v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "CHOP: Mobile Operating Assistant with Constrained High-frequency Optimized Subtask Planning",
      "authors": [
        "Yuqi Zhou",
        "Shuai Wang",
        "Sunhao Dai",
        "Qinglin Jia",
        "Zhaocheng Du",
        "Zhenhua Dong",
        "Jun Xu"
      ],
      "abstract": "The advancement of visual language models (VLMs) has enhanced mobile device\noperations, allowing simulated human-like actions to address user requirements.\nCurrent VLM-based mobile operating assistants can be structured into three\nlevels: task, subtask, and action. The subtask level, linking high-level goals\nwith low-level executable actions, is crucial for task completion but faces two\nchallenges: ineffective subtasks that lower-level agent cannot execute and\ninefficient subtasks that fail to contribute to the completion of the\nhigher-level task. These challenges stem from VLM's lack of experience in\ndecomposing subtasks within GUI scenarios in multi-agent architecture. To\naddress these, we propose a new mobile assistant architecture with constrained\nhigh-frequency o}ptimized planning (CHOP). Our approach overcomes the VLM's\ndeficiency in GUI scenarios planning by using human-planned subtasks as the\nbasis vector. We evaluate our architecture in both English and Chinese contexts\nacross 20 Apps, demonstrating significant improvements in both effectiveness\nand efficiency. Our dataset and code is available at\nhttps://github.com/Yuqi-Zhou/CHOP",
      "pdf_url": "http://arxiv.org/pdf/2503.03743v1",
      "published": "2025-03-05T18:56:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.03743v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Rethinking Deep Clustering Paradigms: Self-Supervision Is All You Need",
      "authors": [
        "Amal Shaheena",
        "Nairouz Mrabahb",
        "Riadh Ksantinia",
        "Abdulla Alqaddoumia"
      ],
      "abstract": "The recent advances in deep clustering have been made possible by significant\nprogress in self-supervised and pseudo-supervised learning. However, the\ntrade-off between self-supervision and pseudo-supervision can give rise to\nthree primary issues. The joint training causes Feature Randomness and Feature\nDrift, whereas the independent training causes Feature Randomness and Feature\nTwist. In essence, using pseudo-labels generates random and unreliable\nfeatures. The combination of pseudo-supervision and self-supervision drifts the\nreliable clustering-oriented features. Moreover, moving from self-supervision\nto pseudo-supervision can twist the curved latent manifolds. This paper\naddresses the limitations of existing deep clustering paradigms concerning\nFeature Randomness, Feature Drift, and Feature Twist. We propose a new paradigm\nwith a new strategy that replaces pseudo-supervision with a second round of\nself-supervision training. The new strategy makes the transition between\ninstance-level self-supervision and neighborhood-level self-supervision\nsmoother and less abrupt. Moreover, it prevents the drifting effect that is\ncaused by the strong competition between instance-level self-supervision and\nclustering-level pseudo-supervision. Moreover, the absence of the\npseudo-supervision prevents the risk of generating random features. With this\nnovel approach, our paper introduces a Rethinking of the Deep Clustering\nParadigms, denoted by R-DC. Our model is specifically designed to address three\nprimary challenges encountered in Deep Clustering: Feature Randomness, Feature\nDrift, and Feature Twist. Experimental results conducted on six datasets have\nshown that the two-level self-supervision training yields substantial\nimprovements.",
      "pdf_url": "http://arxiv.org/pdf/2503.03733v1",
      "published": "2025-03-05T18:44:35+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.03733v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Deep Causal Behavioral Policy Learning: Applications to Healthcare",
      "authors": [
        "Jonas Knecht",
        "Anna Zink",
        "Jonathan Kolstad",
        "Maya Petersen"
      ],
      "abstract": "We present a deep learning-based approach to studying dynamic clinical\nbehavioral regimes in diverse non-randomized healthcare settings. Our proposed\nmethodology - deep causal behavioral policy learning (DC-BPL) - uses deep\nlearning algorithms to learn the distribution of high-dimensional clinical\naction paths, and identifies the causal link between these action paths and\npatient outcomes. Specifically, our approach: (1) identifies the causal effects\nof provider assignment on clinical outcomes; (2) learns the distribution of\nclinical actions a given provider would take given evolving patient\ninformation; (3) and combines these steps to identify the optimal provider for\na given patient type and emulate that provider's care decisions. Underlying\nthis strategy, we train a large clinical behavioral model (LCBM) on electronic\nhealth records data using a transformer architecture, and demonstrate its\nability to estimate clinical behavioral policies. We propose a novel\ninterpretation of a behavioral policy learned using the LCBM: that it is an\nefficient encoding of complex, often implicit, knowledge used to treat a\npatient. This allows us to learn a space of policies that are critical to a\nwide range of healthcare applications, in which the vast majority of clinical\nknowledge is acquired tacitly through years of practice and only a tiny\nfraction of information relevant to patient care is written down (e.g. in\ntextbooks, studies or standardized guidelines).",
      "pdf_url": "http://arxiv.org/pdf/2503.03724v1",
      "published": "2025-03-05T18:24:58+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.03724v1",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Machine Learning in Biomechanics: Key Applications and Limitations in Walking, Running, and Sports Movements",
      "authors": [
        "Carlo Dindorf",
        "Fabian Horst",
        "Djordje Slijepčević",
        "Bernhard Dumphart",
        "Jonas Dully",
        "Matthias Zeppelzauer",
        "Brian Horsak",
        "Michael Fröhlich"
      ],
      "abstract": "This chapter provides an overview of recent and promising Machine Learning\napplications, i.e. pose estimation, feature estimation, event detection, data\nexploration & clustering, and automated classification, in gait (walking and\nrunning) and sports biomechanics. It explores the potential of Machine Learning\nmethods to address challenges in biomechanical workflows, highlights central\nlimitations, i.e. data and annotation availability and explainability, that\nneed to be addressed, and emphasises the importance of interdisciplinary\napproaches for fully harnessing the potential of Machine Learning in gait and\nsports biomechanics.",
      "pdf_url": "http://arxiv.org/pdf/2503.03717v1",
      "published": "2025-03-05T18:10:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.03717v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Rethinking Video Tokenization: A Conditioned Diffusion-based Approach",
      "authors": [
        "Nianzu Yang",
        "Pandeng Li",
        "Liming Zhao",
        "Yang Li",
        "Chen-Wei Xie",
        "Yehui Tang",
        "Xudong Lu",
        "Zhihang Liu",
        "Yun Zheng",
        "Yu Liu",
        "Junchi Yan"
      ],
      "abstract": "Video tokenizers, which transform videos into compact latent representations,\nare key to video generation. Existing video tokenizers are based on the VAE\narchitecture and follow a paradigm where an encoder compresses videos into\ncompact latents, and a deterministic decoder reconstructs the original videos\nfrom these latents. In this paper, we propose a novel\n\\underline{\\textbf{C}}onditioned \\underline{\\textbf{D}}iffusion-based video\n\\underline{\\textbf{T}}okenizer entitled \\textbf{\\ourmethod}, which departs from\nprevious methods by replacing the deterministic decoder with a 3D causal\ndiffusion model. The reverse diffusion generative process of the decoder is\nconditioned on the latent representations derived via the encoder. With a\nfeature caching and sampling acceleration, the framework efficiently\nreconstructs high-fidelity videos of arbitrary lengths. Results show that\n{\\ourmethod} achieves state-of-the-art performance in video reconstruction\ntasks using just a single-step sampling. Even a smaller version of {\\ourmethod}\nstill achieves reconstruction results on par with the top two baselines.\nFurthermore, the latent video generation model trained using {\\ourmethod} also\nshows superior performance.",
      "pdf_url": "http://arxiv.org/pdf/2503.03708v1",
      "published": "2025-03-05T17:59:19+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.03708v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Curating Demonstrations using Online Experience",
      "authors": [
        "Annie S. Chen",
        "Alec M. Lessing",
        "Yuejiang Liu",
        "Chelsea Finn"
      ],
      "abstract": "Many robot demonstration datasets contain heterogeneous demonstrations of\nvarying quality. This heterogeneity may benefit policy pre-training, but can\nhinder robot performance when used with a final imitation learning objective.\nIn particular, some strategies in the data may be less reliable than others or\nmay be underrepresented in the data, leading to poor performance when such\nstrategies are sampled at test time. Moreover, such unreliable or\nunderrepresented strategies can be difficult even for people to discern, and\nsifting through demonstration datasets is time-consuming and costly. On the\nother hand, policy performance when trained on such demonstrations can reflect\nthe reliability of different strategies. We thus propose for robots to\nself-curate based on online robot experience (Demo-SCORE). More specifically,\nwe train and cross-validate a classifier to discern successful policy roll-outs\nfrom unsuccessful ones and use the classifier to filter heterogeneous\ndemonstration datasets. Our experiments in simulation and the real world show\nthat Demo-SCORE can effectively identify suboptimal demonstrations without\nmanual curation. Notably, Demo-SCORE achieves over 15-35% higher absolute\nsuccess rate in the resulting policy compared to the base policy trained with\nall original demonstrations.",
      "pdf_url": "http://arxiv.org/pdf/2503.03707v1",
      "published": "2025-03-05T17:58:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.03707v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "ILLC: Iterative Layer-by-Layer Compression for Enhancing Structural Faithfulness in SpArX",
      "authors": [
        "Ungsik Kim"
      ],
      "abstract": "In the field of Explainable Artificial Intelligence (XAI), argumentative XAI\napproaches have been proposed to represent the internal reasoning process of\ndeep neural networks in a more transparent way by interpreting hidden nodes as\narguements. However, as the number of layers increases, existing compression\nmethods simplify all layers at once, which lead to high accumulative\ninformation loss. To compensate for this, we propose an iterative\nlayer-by-layer compression technique in which each layer is compressed\nseparately and the reduction error in the next layer is immediately compensated\nfor, thereby improving the overall input-output and structural fidelity of the\nmodel. Experiments on the Breast Cancer Diagnosis dataset show that, compared\nto traditional compression, the method reduces input-output and structural\nunfaithfulness, and maintains a more consistent attack-support relationship in\nthe Argumentative Explanation scheme. This is significant because it provides a\nnew way to make complex MLP models more compact while still conveying their\ninternal inference logic without distortion.",
      "pdf_url": "http://arxiv.org/pdf/2503.03693v1",
      "published": "2025-03-05T17:43:49+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.03693v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Attentive Reasoning Queries: A Systematic Method for Optimizing Instruction-Following in Large Language Models",
      "authors": [
        "Bar Karov",
        "Dor Zohar",
        "Yam Marcovitz"
      ],
      "abstract": "We present Attentive Reasoning Queries (ARQs), a novel structured reasoning\napproach that significantly improves instruction-following in Large Language\nModels through domain-specialized reasoning blueprints. While LLMs demonstrate\nremarkable capabilities across diverse tasks, they often fail to maintain\nadherence to complex, use-case-specific instructions during multi-turn\nconversations, presenting challenges for business-critical applications. ARQs\naddress this limitation by guiding LLMs through systematic reasoning steps with\ntargeted queries that reinstate critical instructions and facilitate\nintermediate reasoning throughout the completion process. In extensive testing\nwithin Parlant, our framework for reliable customer-facing agents in which ARQs\nwere born out of necessity, they achieved a 90.2% success rate across 87 test\nscenarios, outperforming both Chain-of-Thought reasoning (86.1%) and direct\nresponse generation (81.5%). ARQs showed particular strength in addressing\npersistent failure modes like guideline re-application and hallucination\nprevention. Our analysis also revealed that ARQs can potentially be more\ncomputationally efficient than free-form reasoning when carefully designed.\nThese findings demonstrate that structured reasoning approaches provide\neffective mechanisms for controlling how LLMs process information and make\ndecisions in complex scenarios.",
      "pdf_url": "http://arxiv.org/pdf/2503.03669v1",
      "published": "2025-03-05T17:03:48+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.03669v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ]
    },
    {
      "title": "A Generative Approach to High Fidelity 3D Reconstruction from Text Data",
      "authors": [
        "Venkat Kumar R",
        "Deepak Saravanan"
      ],
      "abstract": "The convergence of generative artificial intelligence and advanced computer\nvision technologies introduces a groundbreaking approach to transforming\ntextual descriptions into three-dimensional representations. This research\nproposes a fully automated pipeline that seamlessly integrates text-to-image\ngeneration, various image processing techniques, and deep learning methods for\nreflection removal and 3D reconstruction. By leveraging state-of-the-art\ngenerative models like Stable Diffusion, the methodology translates natural\nlanguage inputs into detailed 3D models through a multi-stage workflow.\n  The reconstruction process begins with the generation of high-quality images\nfrom textual prompts, followed by enhancement by a reinforcement learning agent\nand reflection removal using the Stable Delight model. Advanced image upscaling\nand background removal techniques are then applied to further enhance visual\nfidelity. These refined two-dimensional representations are subsequently\ntransformed into volumetric 3D models using sophisticated machine learning\nalgorithms, capturing intricate spatial relationships and geometric\ncharacteristics. This process achieves a highly structured and detailed output,\nensuring that the final 3D models reflect both semantic accuracy and geometric\nprecision.\n  This approach addresses key challenges in generative reconstruction, such as\nmaintaining semantic coherence, managing geometric complexity, and preserving\ndetailed visual information. Comprehensive experimental evaluations will assess\nreconstruction quality, semantic accuracy, and geometric fidelity across\ndiverse domains and varying levels of complexity. By demonstrating the\npotential of AI-driven 3D reconstruction techniques, this research offers\nsignificant implications for fields such as augmented reality (AR), virtual\nreality (VR), and digital content creation.",
      "pdf_url": "http://arxiv.org/pdf/2503.03664v1",
      "published": "2025-03-05T16:54:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.03664v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Improving 6D Object Pose Estimation of metallic Household and Industry Objects",
      "authors": [
        "Thomas Pöllabauer",
        "Michael Gasser",
        "Tristan Wirth",
        "Sarah Berkei",
        "Volker Knauthe",
        "Arjan Kuijper"
      ],
      "abstract": "6D object pose estimation suffers from reduced accuracy when applied to\nmetallic objects. We set out to improve the state-of-the-art by addressing\nchallenges such as reflections and specular highlights in industrial\napplications. Our novel BOP-compatible dataset, featuring a diverse set of\nmetallic objects (cans, household, and industrial items) under various lighting\nand background conditions, provides additional geometric and visual cues. We\ndemonstrate that these cues can be effectively leveraged to enhance overall\nperformance. To illustrate the usefulness of the additional features, we\nimprove upon the GDRNPP algorithm by introducing an additional keypoint\nprediction and material estimator head in order to improve spatial scene\nunderstanding. Evaluations on the new dataset show improved accuracy for\nmetallic objects, supporting the hypothesis that additional geometric and\nvisual cues can improve learning.",
      "pdf_url": "http://arxiv.org/pdf/2503.03655v1",
      "published": "2025-03-05T16:35:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.03655v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Improving Neutral Point of View Text Generation through Parameter-Efficient Reinforcement Learning and a Small-Scale High-Quality Dataset",
      "authors": [
        "Jessica Hoffmann",
        "Christiane Ahlheim",
        "Zac Yu",
        "Aria Walfrand",
        "Jarvis Jin",
        "Marie Tano",
        "Ahmad Beirami",
        "Erin van Liemt",
        "Nithum Thain",
        "Hakim Sidahmed",
        "Lucas Dixon"
      ],
      "abstract": "This paper describes the construction of a dataset and the evaluation of\ntraining methods to improve generative large language models' (LLMs) ability to\nanswer queries on sensitive topics with a Neutral Point of View (NPOV), i.e.,\nto provide significantly more informative, diverse and impartial answers. The\ndataset, the SHQ-NPOV dataset, comprises 300 high-quality, human-written\nquadruplets: a query on a sensitive topic, an answer, an NPOV rating, and a set\nof links to source texts elaborating the various points of view. The first key\ncontribution of this paper is a new methodology to create such datasets through\niterative rounds of human peer-critique and annotator training, which we\nrelease alongside the dataset. The second key contribution is the\nidentification of a highly effective training regime for parameter-efficient\nreinforcement learning (PE-RL) to improve NPOV generation. We compare and\nextensively evaluate PE-RL and multiple baselines-including LoRA finetuning (a\nstrong baseline), SFT and RLHF.\n  PE-RL not only improves on overall NPOV quality compared to the strongest\nbaseline ($97.06\\%\\rightarrow 99.08\\%$), but also scores much higher on\nfeatures linguists identify as key to separating good answers from the best\nanswers ($60.25\\%\\rightarrow 85.21\\%$ for presence of supportive details,\n$68.74\\%\\rightarrow 91.43\\%$ for absence of oversimplification). A qualitative\nanalysis corroborates this. Finally, our evaluation finds no statistical\ndifferences between results on topics that appear in the training dataset and\nthose on separated evaluation topics, which provides strong evidence that our\napproach to training PE-RL exhibits very effective out of topic generalization.",
      "pdf_url": "http://arxiv.org/pdf/2503.03654v1",
      "published": "2025-03-05T16:32:47+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.03654v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Decoupled Recommender Systems: Exploring Alternative Recommender Ecosystem Designs",
      "authors": [
        "Anas Buhayh",
        "Elizabeth McKinnie",
        "Robin Burke"
      ],
      "abstract": "Recommender ecosystems are an emerging subject of research. Such research\nexamines how the characteristics of algorithms, recommendation consumers, and\nitem providers influence system dynamics and long-term outcomes. One\narchitectural possibility that has not yet been widely explored in this line of\nresearch is the consequences of a configuration in which recommendation\nalgorithms are decoupled from the platforms they serve. This is sometimes\ncalled \"the friendly neighborhood algorithm store\" or \"middleware\" model. We\nare particularly interested in how such architectures might offer a range of\ndifferent distributions of utility across consumers, providers, and\nrecommendation platforms. In this paper, we create a model of a recommendation\necosystem that incorporates algorithm choice and examine the outcomes of such a\ndesign.",
      "pdf_url": "http://arxiv.org/pdf/2503.03606v1",
      "published": "2025-03-05T15:42:37+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.03606v1",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.HC"
      ]
    },
    {
      "title": "Towards Understanding Text Hallucination of Diffusion Models via Local Generation Bias",
      "authors": [
        "Rui Lu",
        "Runzhe Wang",
        "Kaifeng Lyu",
        "Xitai Jiang",
        "Gao Huang",
        "Mengdi Wang"
      ],
      "abstract": "Score-based diffusion models have achieved incredible performance in\ngenerating realistic images, audio, and video data. While these models produce\nhigh-quality samples with impressive details, they often introduce unrealistic\nartifacts, such as distorted fingers or hallucinated texts with no meaning.\nThis paper focuses on textual hallucinations, where diffusion models correctly\ngenerate individual symbols but assemble them in a nonsensical manner. Through\nexperimental probing, we consistently observe that such phenomenon is\nattributed it to the network's local generation bias. Denoising networks tend\nto produce outputs that rely heavily on highly correlated local regions,\nparticularly when different dimensions of the data distribution are nearly\npairwise independent. This behavior leads to a generation process that\ndecomposes the global distribution into separate, independent distributions for\neach symbol, ultimately failing to capture the global structure, including\nunderlying grammar. Intriguingly, this bias persists across various denoising\nnetwork architectures including MLP and transformers which have the structure\nto model global dependency. These findings also provide insights into\nunderstanding other types of hallucinations, extending beyond text, as a result\nof implicit biases in the denoising models. Additionally, we theoretically\nanalyze the training dynamics for a specific case involving a two-layer MLP\nlearning parity points on a hypercube, offering an explanation of its\nunderlying mechanism.",
      "pdf_url": "http://arxiv.org/pdf/2503.03595v1",
      "published": "2025-03-05T15:28:50+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.03595v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Small but Mighty: Enhancing Time Series Forecasting with Lightweight LLMs",
      "authors": [
        "Haoran Fan",
        "Bin Li",
        "Yixuan Weng",
        "Shoujun Zhou"
      ],
      "abstract": "While LLMs have demonstrated remarkable potential in time series forecasting,\ntheir practical deployment remains constrained by excessive computational\ndemands and memory footprints. Existing LLM-based approaches typically suffer\nfrom three critical limitations: Inefficient parameter utilization in handling\nnumerical time series patterns; Modality misalignment between continuous\ntemporal signals and discrete text embeddings; and Inflexibility for real-time\nexpert knowledge integration. We present SMETimes, the first systematic\ninvestigation of sub-3B parameter SLMs for efficient and accurate time series\nforecasting. Our approach centers on three key innovations: A\nstatistically-enhanced prompting mechanism that bridges numerical time series\nwith textual semantics through descriptive statistical features; A adaptive\nfusion embedding architecture that aligns temporal patterns with language model\ntoken spaces through learnable parameters; And a dynamic mixture-of-experts\nframework enabled by SLMs' computational efficiency, adaptively combining base\npredictions with domain-specific models. Extensive evaluations across seven\nbenchmark datasets demonstrate that our 3B-parameter SLM achieves\nstate-of-the-art performance on five primary datasets while maintaining 3.8x\nfaster training and 5.2x lower memory consumption compared to 7B-parameter LLM\nbaselines. Notably, the proposed model exhibits better learning capabilities,\nachieving 12.3% lower MSE than conventional LLM. Ablation studies validate that\nour statistical prompting and cross-modal fusion modules respectively\ncontribute 15.7% and 18.2% error reduction in long-horizon forecasting tasks.\nBy redefining the efficiency-accuracy trade-off landscape, this work\nestablishes SLMs as viable alternatives to resource-intensive LLMs for\npractical time series forecasting. Code and models are available at\nhttps://github.com/xiyan1234567/SMETimes.",
      "pdf_url": "http://arxiv.org/pdf/2503.03594v1",
      "published": "2025-03-05T15:27:36+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.03594v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "English K_Quantization of LLMs Does Not Disproportionately Diminish Multilingual Performance",
      "authors": [
        "Karl Audun Borgersen"
      ],
      "abstract": "For consumer usage of locally deployed LLMs, the GGUF format and\nk_quantization are invaluable tools for maintaining the performance of the\noriginal model while reducing it to sizes deployable with consumer-grade\nhardware. The number of bits dedicated to each weight from the original model\nis reduced based on how important they are thought to be during model\ninference. This importance is arrived at through the application of an\n'importance matrix'-a relatively small text document meant to be representative\nof the LLM's standard use-cases. In the vast majority of quants available\nonline, this document is primarily written in English. It was therefore an open\nquestion whether performance on English language tasks was preserved through\nthe sacrifice of multilingual performance and whether it can be preserved with\nalternate importance matrices. This article investigates these hypotheses by\nquantizing Llama3.3 70B on importance matrices written in three languages\n(English, Norwegian, and Malayalam) and evaluating them on the MixEval dataset\nin both English and Norwegian. All experiments related to k_quantization\nyielded non-significant results (In all cases p > 0.237) indicating that\ncurrent quantization practices do not disproportionately harm multilingual\nperformance.",
      "pdf_url": "http://arxiv.org/pdf/2503.03592v1",
      "published": "2025-03-05T15:26:59+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.03592v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "A Conceptual Model for Attributions in Event-Centric Knowledge Graphs",
      "authors": [
        "Florian Plötzky",
        "Katarina Britz",
        "Wolf-Tilo Balke"
      ],
      "abstract": "The use of narratives as a means of fusing information from knowledge graphs\n(KGs) into a coherent line of argumentation has been the subject of recent\ninvestigation. Narratives are especially useful in event-centric knowledge\ngraphs in that they provide a means to connect different real-world events and\ncategorize them by well-known narrations. However, specifically for\ncontroversial events, a problem in information fusion arises, namely, multiple\nviewpoints regarding the validity of certain event aspects, e.g., regarding the\nrole a participant takes in an event, may exist. Expressing those viewpoints in\nKGs is challenging because disputed information provided by different\nviewpoints may introduce inconsistencies. Hence, most KGs only feature a single\nview on the contained information, hampering the effectiveness of narrative\ninformation access. This paper is an extension of our original work and\nintroduces attributions, i.e., parameterized predicates that allow for the\nrepresentation of facts that are only valid in a specific viewpoint. For this,\nwe develop a conceptual model that allows for the representation of\nviewpoint-dependent information. As an extension, we enhance the model by a\nconception of viewpoint-compatibility. Based on this, we deepen our original\ndeliberations on the model's effects on information fusion and provide\nadditional grounding in the literature.",
      "pdf_url": "http://arxiv.org/pdf/2503.03563v1",
      "published": "2025-03-05T14:51:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.03563v1",
      "categories": [
        "cs.DB",
        "cs.AI"
      ]
    },
    {
      "title": "Towards Visual Discrimination and Reasoning of Real-World Physical Dynamics: Physics-Grounded Anomaly Detection",
      "authors": [
        "Wenqiao Li",
        "Yao Gu",
        "Xintao Chen",
        "Xiaohao Xu",
        "Ming Hu",
        "Xiaonan Huang",
        "Yingna Wu"
      ],
      "abstract": "Humans detect real-world object anomalies by perceiving, interacting, and\nreasoning based on object-conditioned physical knowledge. The long-term goal of\nIndustrial Anomaly Detection (IAD) is to enable machines to autonomously\nreplicate this skill. However, current IAD algorithms are largely developed and\ntested on static, semantically simple datasets, which diverge from real-world\nscenarios where physical understanding and reasoning are essential.To bridge\nthis gap, we introduce the Physics Anomaly Detection (Phys-AD) dataset, the\nfirst large-scale, real-world, physics-grounded video dataset for industrial\nanomaly detection. Collected using a real robot arm and motor, Phys-AD provides\na diverse set of dynamic, semantically rich scenarios. The dataset includes\nmore than 6400 videos across 22 real-world object categories, interacting with\nrobot arms and motors, and exhibits 47 types of anomalies. Anomaly detection in\nPhys-AD requires visual reasoning, combining both physical knowledge and video\ncontent to determine object abnormality.We benchmark state-of-the-art anomaly\ndetection methods under three settings: unsupervised AD, weakly-supervised AD,\nand video-understanding AD, highlighting their limitations in handling\nphysics-grounded anomalies. Additionally, we introduce the Physics Anomaly\nExplanation (PAEval) metric, designed to assess the ability of visual-language\nfoundation models to not only detect anomalies but also provide accurate\nexplanations for their underlying physical causes. Our dataset and benchmark\nwill be publicly available.",
      "pdf_url": "http://arxiv.org/pdf/2503.03562v1",
      "published": "2025-03-05T14:49:08+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.03562v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "AI-Enabled Conversational Journaling for Advancing Parkinson's Disease Symptom Tracking",
      "authors": [
        "Mashrur Rashik",
        "Shilpa Sweth",
        "Nishtha Agrawal",
        "Saiyyam Kochar",
        "Kara M Smith",
        "Fateme Rajabiyazdi",
        "Vidya Setlur",
        "Narges Mahyar",
        "Ali Sarvghad"
      ],
      "abstract": "Journaling plays a crucial role in managing chronic conditions by allowing\npatients to document symptoms and medication intake, providing essential data\nfor long-term care. While valuable, traditional journaling methods often rely\non static, self-directed entries, lacking interactive feedback and real-time\nguidance. This gap can result in incomplete or imprecise information, limiting\nits usefulness for effective treatment. To address this gap, we introduce\nPATRIKA, an AI-enabled prototype designed specifically for people with\nParkinson's disease (PwPD). The system incorporates cooperative conversation\nprinciples, clinical interview simulations, and personalization to create a\nmore effective and user-friendly journaling experience. Through two user\nstudies with PwPD and iterative refinement of PATRIKA, we demonstrate\nconversational journaling's significant potential in patient engagement and\ncollecting clinically valuable information. Our results showed that generating\nprobing questions PATRIKA turned journaling into a bi-directional interaction.\nAdditionally, we offer insights for designing journaling systems for healthcare\nand future directions for promoting sustained journaling.",
      "pdf_url": "http://arxiv.org/pdf/2503.03532v1",
      "published": "2025-03-05T14:14:25+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.03532v1",
      "categories": [
        "cs.HC",
        "cs.AI"
      ]
    },
    {
      "title": "AdaSin: Enhancing Hard Sample Metrics with Dual Adaptive Penalty for Face Recognition",
      "authors": [
        "Qiqi Guo",
        "Zhuowen Zheng",
        "Guanghua Yang",
        "Zhiquan Liu",
        "Xiaofan Li",
        "Jianqing Li",
        "Jinyu Tian",
        "Xueyuan Gong"
      ],
      "abstract": "In recent years, the emergence of deep convolutional neural networks has\npositioned face recognition as a prominent research focus in computer vision.\nTraditional loss functions, such as margin-based, hard-sample mining-based, and\nhybrid approaches, have achieved notable performance improvements, with some\nleveraging curriculum learning to optimize training. However, these methods\noften fall short in effectively quantifying the difficulty of hard samples. To\naddress this, we propose Adaptive Sine (AdaSin) loss function, which introduces\nthe sine of the angle between a sample's embedding feature and its ground-truth\nclass center as a novel difficulty metric. This metric enables precise and\neffective penalization of hard samples. By incorporating curriculum learning,\nthe model dynamically adjusts classification boundaries across different\ntraining stages. Unlike previous adaptive-margin loss functions, AdaSin\nintroduce a dual adaptive penalty, applied to both the positive and negative\ncosine similarities of hard samples. This design imposes stronger constraints,\nenhancing intra-class compactness and inter-class separability. The combination\nof the dual adaptive penalty and curriculum learning is guided by a\nwell-designed difficulty metric. It enables the model to focus more effectively\non hard samples in later training stages, and lead to the extraction of highly\ndiscriminative face features. Extensive experiments across eight benchmarks\ndemonstrate that AdaSin achieves superior accuracy compared to other\nstate-of-the-art methods.",
      "pdf_url": "http://arxiv.org/pdf/2503.03528v1",
      "published": "2025-03-05T14:11:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.03528v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "NeuGrasp: Generalizable Neural Surface Reconstruction with Background Priors for Material-Agnostic Object Grasp Detection",
      "authors": [
        "Qingyu Fan",
        "Yinghao Cai",
        "Chao Li",
        "Wenzhe He",
        "Xudong Zheng",
        "Tao Lu",
        "Bin Liang",
        "Shuo Wang"
      ],
      "abstract": "Robotic grasping in scenes with transparent and specular objects presents\ngreat challenges for methods relying on accurate depth information. In this\npaper, we introduce NeuGrasp, a neural surface reconstruction method that\nleverages background priors for material-agnostic grasp detection. NeuGrasp\nintegrates transformers and global prior volumes to aggregate multi-view\nfeatures with spatial encoding, enabling robust surface reconstruction in\nnarrow and sparse viewing conditions. By focusing on foreground objects through\nresidual feature enhancement and refining spatial perception with an\noccupancy-prior volume, NeuGrasp excels in handling objects with transparent\nand specular surfaces. Extensive experiments in both simulated and real-world\nscenarios show that NeuGrasp outperforms state-of-the-art methods in grasping\nwhile maintaining comparable reconstruction quality. More details are available\nat https://neugrasp.github.io/.",
      "pdf_url": "http://arxiv.org/pdf/2503.03511v1",
      "published": "2025-03-05T13:57:37+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.03511v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "I.2.9; I.2.10"
      ]
    },
    {
      "title": "Rethinking Synthetic Data definitions: A privacy driven approach",
      "authors": [
        "Vibeke Binz Vallevik",
        "Serena Elizabeth Marshall",
        "Aleksandar Babic",
        "Jan Franz Nygaard"
      ],
      "abstract": "Synthetic data is gaining traction as a cost-effective solution for the\nincreasing data demands of AI development and can be generated either from\nexisting knowledge or derived data captured from real-world events. The source\nof the synthetic data generation and the technique used significantly impacts\nits residual privacy risk and therefore its opportunity for sharing.\nTraditional classification of synthetic data types no longer fit the newer\ngeneration techniques and there is a need to better align the classification\nwith practical needs. We suggest a new way of grouping synthetic data types\nthat better supports privacy evaluations to aid regulatory policymaking. Our\nnovel classification provides flexibility to new advancements like deep\ngenerative methods and offers a more practical framework for future\napplications.",
      "pdf_url": "http://arxiv.org/pdf/2503.03506v1",
      "published": "2025-03-05T13:54:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.03506v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Parallelized Planning-Acting for Efficient LLM-based Multi-Agent Systems",
      "authors": [
        "Yaoru Li",
        "Shunyu Liu",
        "Tongya Zheng",
        "Mingli Song"
      ],
      "abstract": "Recent advancements in Large Language Model(LLM)-based Multi-Agent\nSystems(MAS) have demonstrated remarkable potential for tackling complex\ndecision-making tasks. However, existing frameworks inevitably rely on\nserialized execution paradigms, where agents must complete sequential LLM\nplanning before taking action. This fundamental constraint severely limits\nreal-time responsiveness and adaptation, which is crucial in dynamic\nenvironments with ever-changing scenarios. In this paper, we propose a novel\nparallelized planning-acting framework for LLM-based MAS, featuring a\ndual-thread architecture with interruptible execution to enable concurrent\nplanning and acting. Specifically, our framework comprises two core threads:(1)\na planning thread driven by a centralized memory system, maintaining\nsynchronization of environmental states and agent communication to support\ndynamic decision-making; and (2) an acting thread equipped with a comprehensive\nskill library, enabling automated task execution through recursive\ndecomposition. Extensive experiments on challenging Minecraft demonstrate the\neffectiveness of the proposed framework.",
      "pdf_url": "http://arxiv.org/pdf/2503.03505v1",
      "published": "2025-03-05T13:53:10+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.03505v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Collaborative Expert LLMs Guided Multi-Objective Molecular Optimization",
      "authors": [
        "Jiajun Yu",
        "Yizhen Zheng",
        "Huan Yee Koh",
        "Shirui Pan",
        "Tianyue Wang",
        "Haishuai Wang"
      ],
      "abstract": "Molecular optimization is a crucial yet complex and time-intensive process\nthat often acts as a bottleneck for drug development. Traditional methods rely\nheavily on trial and error, making multi-objective optimization both\ntime-consuming and resource-intensive. Current AI-based methods have shown\nlimited success in handling multi-objective optimization tasks, hampering their\npractical utilization. To address this challenge, we present MultiMol, a\ncollaborative large language model (LLM) system designed to guide\nmulti-objective molecular optimization. MultiMol comprises two agents,\nincluding a data-driven worker agent and a literature-guided research agent.\nThe data-driven worker agent is a large language model being fine-tuned to\nlearn how to generate optimized molecules considering multiple objectives,\nwhile the literature-guided research agent is responsible for searching\ntask-related literature to find useful prior knowledge that facilitates\nidentifying the most promising optimized candidates. In evaluations across six\nmulti-objective optimization tasks, MultiMol significantly outperforms existing\nmethods, achieving a 82.30% success rate, in sharp contrast to the 27.50%\nsuccess rate of current strongest methods. To further validate its practical\nimpact, we tested MultiMol on two real-world challenges. First, we enhanced the\nselectivity of Xanthine Amine Congener (XAC), a promiscuous ligand that binds\nboth A1R and A2AR, successfully biasing it towards A1R. Second, we improved the\nbioavailability of Saquinavir, an HIV-1 protease inhibitor with known\nbioavailability limitations. Overall, these results indicate that MultiMol\nrepresents a highly promising approach for multi-objective molecular\noptimization, holding great potential to accelerate the drug development\nprocess and contribute to the advancement of pharmaceutical research.",
      "pdf_url": "http://arxiv.org/pdf/2503.03503v1",
      "published": "2025-03-05T13:47:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.03503v1",
      "categories": [
        "q-bio.BM",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "CURVALID: Geometrically-guided Adversarial Prompt Detection",
      "authors": [
        "Canaan Yung",
        "Hanxun Huang",
        "Sarah Monazam Erfani",
        "Christopher Leckie"
      ],
      "abstract": "Adversarial prompts capable of jailbreaking large language models (LLMs) and\ninducing undesirable behaviours pose a significant obstacle to their safe\ndeployment. Current mitigation strategies rely on activating built-in defence\nmechanisms or fine-tuning the LLMs, but the fundamental distinctions between\nadversarial and benign prompts are yet to be understood. In this work, we\nintroduce CurvaLID, a novel defense framework that efficiently detects\nadversarial prompts by leveraging their geometric properties. It is agnostic to\nthe type of LLM, offering a unified detection framework across diverse\nadversarial prompts and LLM architectures. CurvaLID builds on the geometric\nanalysis of text prompts to uncover their underlying differences. We\ntheoretically extend the concept of curvature via the Whewell equation into an\n$n$-dimensional word embedding space, enabling us to quantify local geometric\nproperties, including semantic shifts and curvature in the underlying\nmanifolds. Additionally, we employ Local Intrinsic Dimensionality (LID) to\ncapture geometric features of text prompts within adversarial subspaces. Our\nfindings reveal that adversarial prompts differ fundamentally from benign\nprompts in terms of their geometric characteristics. Our results demonstrate\nthat CurvaLID delivers superior detection and rejection of adversarial queries,\npaving the way for safer LLM deployment. The source code can be found at\nhttps://github.com/Cancanxxx/CurvaLID",
      "pdf_url": "http://arxiv.org/pdf/2503.03502v1",
      "published": "2025-03-05T13:47:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.03502v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "SafeVLA: Towards Safety Alignment of Vision-Language-Action Model via Safe Reinforcement Learning",
      "authors": [
        "Borong Zhang",
        "Yuhao Zhang",
        "Jiaming Ji",
        "Yingshan Lei",
        "Josef Dai",
        "Yuanpei Chen",
        "Yaodong Yang"
      ],
      "abstract": "Vision-language-action models (VLAs) have shown great potential as generalist\nrobot policies. However, these models pose urgent safety challenges during\ndeployment, including the risk of physical harm to the environment, the robot\nitself, and humans. How can safety be explicitly incorporated into VLAs? In\nthis work, we propose SafeVLA, a novel algorithm designed to integrate safety\ninto VLAs, ensuring the protection of the environment, robot hardware and\nhumans in real-world settings. SafeVLA effectively balances safety and task\nperformance by employing large-scale constrained learning within simulated\nenvironments. We demonstrate that SafeVLA outperforms the current\nstate-of-the-art method in both safety and task performance, achieving average\nimprovements of 83.58% and 3.85%, respectively, in simulation. By prioritizing\nsafety, our approach eliminates high-risk behaviors and reduces the upper bound\nof unsafe behaviors to 1/35 of that in the current state-of-the-art, thereby\nsignificantly mitigating long-tail risks. Furthermore, the learned safety\nconstraints generalize to diverse, unseen scenarios, including multiple\nout-of-distribution perturbations and tasks. Our data, models and newly\nproposed benchmark environment are available at\nhttps://sites.google.com/view/pku-safevla.",
      "pdf_url": "http://arxiv.org/pdf/2503.03480v1",
      "published": "2025-03-05T13:16:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.03480v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "Open-Source Large Language Models as Multilingual Crowdworkers: Synthesizing Open-Domain Dialogues in Several Languages With No Examples in Targets and No Machine Translation",
      "authors": [
        "Ahmed Njifenjou",
        "Virgile Sucal",
        "Bassam Jabaian",
        "Fabrice Lefèvre"
      ],
      "abstract": "The prevailing paradigm in the domain of Open-Domain Dialogue agents\npredominantly focuses on the English language, encompassing both models and\ndatasets. Furthermore, the financial and temporal investments required for\ncrowdsourcing such datasets for finetuning are substantial, particularly when\nmultiple languages are involved. Fortunately, advancements in Large Language\nModels (LLMs) have unveiled a plethora of possibilities across diverse tasks.\nSpecifically, instruction-tuning has enabled LLMs to execute tasks based on\nnatural language instructions, occasionally surpassing the performance of human\ncrowdworkers. Additionally, these models possess the capability to function in\nvarious languages within a single thread. Consequently, to generate new samples\nin different languages, we propose leveraging these capabilities to replicate\nthe data collection process. We introduce a pipeline for generating Open-Domain\nDialogue data in multiple Target Languages using LLMs, with demonstrations\nprovided in a unique Source Language. By eschewing explicit Machine Translation\nin this approach, we enhance the adherence to language-specific nuances. We\napply this methodology to the PersonaChat dataset. To enhance the openness of\ngenerated dialogues and mimic real life scenarii, we added the notion of speech\nevents corresponding to the type of conversation the speakers are involved in\nand also that of common ground which represents the premises of a conversation.",
      "pdf_url": "http://arxiv.org/pdf/2503.03462v1",
      "published": "2025-03-05T12:52:14+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.03462v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ]
    },
    {
      "title": "Unified Mind Model: Reimagining Autonomous Agents in the LLM Era",
      "authors": [
        "Pengbo Hu",
        "Xiang Ying"
      ],
      "abstract": "Large language models (LLMs) have recently demonstrated remarkable\ncapabilities across domains, tasks, and languages (e.g., ChatGPT and GPT-4),\nreviving the research of general autonomous agents with human-like cognitive\nabilities.Such human-level agents require semantic comprehension and\ninstruction-following capabilities, which exactly fall into the strengths of\nLLMs.Although there have been several initial attempts to build human-level\nagents based on LLMs, the theoretical foundation remains a challenging open\nproblem. In this paper, we propose a novel theoretical cognitive architecture,\nthe Unified Mind Model (UMM), which offers guidance to facilitate the rapid\ncreation of autonomous agents with human-level cognitive abilities.\nSpecifically, our UMM starts with the global workspace theory and further\nleverage LLMs to enable the agent with various cognitive abilities, such as\nmulti-modal perception, planning, reasoning, tool use, learning, memory,\nreflection and motivation. Building upon UMM, we then develop an agent-building\nengine, MindOS, which allows users to quickly create domain-/task-specific\nautonomous agents without any programming effort.",
      "pdf_url": "http://arxiv.org/pdf/2503.03459v1",
      "published": "2025-03-05T12:49:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.03459v1",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Taxation Perspectives from Large Language Models: A Case Study on Additional Tax Penalties",
      "authors": [
        "Eunkyung Choi",
        "Young Jin Suh",
        "Hun Park",
        "Wonseok Hwang"
      ],
      "abstract": "How capable are large language models (LLMs) in the domain of taxation?\nAlthough numerous studies have explored the legal domain in general, research\ndedicated to taxation remain scarce. Moreover, the datasets used in these\nstudies are either simplified, failing to reflect the real-world complexities,\nor unavailable as open source. To address this gap, we introduce PLAT, a new\nbenchmark designed to assess the ability of LLMs to predict the legitimacy of\nadditional tax penalties. PLAT is constructed to evaluate LLMs' understanding\nof tax law, particularly in cases where resolving the issue requires more than\njust applying related statutes. Our experiments with six LLMs reveal that their\nbaseline capabilities are limited, especially when dealing with conflicting\nissues that demand a comprehensive understanding. However, we found that\nenabling retrieval, self-reasoning, and discussion among multiple agents with\nspecific role assignments, this limitation can be mitigated.",
      "pdf_url": "http://arxiv.org/pdf/2503.03444v1",
      "published": "2025-03-05T12:24:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.03444v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Conceptualizing Uncertainty",
      "authors": [
        "Isaac Roberts",
        "Alexander Schulz",
        "Sarah Schroeder",
        "Fabian Hinder",
        "Barbara Hammer"
      ],
      "abstract": "Uncertainty in machine learning refers to the degree of confidence or lack\nthereof in a model's predictions. While uncertainty quantification methods\nexist, explanations of uncertainty, especially in high-dimensional settings,\nremain an open challenge. Existing work focuses on feature attribution\napproaches which are restricted to local explanations. Understanding\nuncertainty, its origins, and characteristics on a global scale is crucial for\nenhancing interpretability and trust in a model's predictions. In this work, we\npropose to explain the uncertainty in high-dimensional data classification\nsettings by means of concept activation vectors which give rise to local and\nglobal explanations of uncertainty. We demonstrate the utility of the generated\nexplanations by leveraging them to refine and improve our model.",
      "pdf_url": "http://arxiv.org/pdf/2503.03443v1",
      "published": "2025-03-05T12:24:12+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.03443v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "RASD: Retrieval-Augmented Speculative Decoding",
      "authors": [
        "Guofeng Quan",
        "Wenfeng Feng",
        "Chuzhan Hao",
        "Guochao Jiang",
        "Yuewei Zhang",
        "Hao Wang"
      ],
      "abstract": "Speculative decoding accelerates inference in large language models (LLMs) by\ngenerating draft tokens for target model verification. Current approaches for\nobtaining draft tokens rely on lightweight draft models or additional model\nstructures to generate draft tokens and retrieve context from databases. Due to\nthe draft model's small size and limited training data, model-based speculative\ndecoding frequently becomes less effective in out-of-domain scenarios.\nAdditionally, the time cost of the drafting phase results in a low upper limit\non acceptance length during the verification step, limiting overall efficiency.\nThis paper proposes RASD (Retrieval-Augmented Speculative Decoding), which\nadopts retrieval methods to enhance model-based speculative decoding. We\nintroduce tree pruning and tree fusion to achieve this. Specifically, we\ndevelop a pruning method based on the draft model's probability distribution to\nconstruct the optimal retrieval tree. Second, we employ the longest prefix\nmatching algorithm to merge the tree generated by the draft model with the\nretrieval tree, resulting in a unified tree for verification. Experimental\nresults demonstrate that RASD achieves state-of-the-art inference acceleration\nacross tasks such as DocQA, Summary, Code, and In-Domain QA. Moreover, RASD\nexhibits strong scalability, seamlessly integrating with various speculative\ndecoding approaches, including both generation-based and retrieval-based\nmethods.",
      "pdf_url": "http://arxiv.org/pdf/2503.03434v1",
      "published": "2025-03-05T12:10:14+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.03434v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Privacy is All You Need: Revolutionizing Wearable Health Data with Advanced PETs",
      "authors": [
        "Karthik Barma",
        "Seshu Babu Barma"
      ],
      "abstract": "In a world where data is the new currency, wearable health devices offer\nunprecedented insights into daily life, continuously monitoring vital signs and\nmetrics. However, this convenience raises privacy concerns, as these devices\ncollect sensitive data that can be misused or breached. Traditional measures\noften fail due to real-time data processing needs and limited device power.\nUsers also lack awareness and control over data sharing and usage. We propose a\nPrivacy-Enhancing Technology (PET) framework for wearable devices, integrating\nfederated learning, lightweight cryptographic methods, and selectively deployed\nblockchain technology. The blockchain acts as a secure ledger triggered only\nupon data transfer requests, granting users real-time notifications and\ncontrol. By dismantling data monopolies, this approach returns data sovereignty\nto individuals. Through real-world applications like secure medical data\nsharing, privacy-preserving fitness tracking, and continuous health monitoring,\nour framework reduces privacy risks by up to 70 percent while preserving data\nutility and performance. This innovation sets a new benchmark for wearable\nprivacy and can scale to broader IoT ecosystems, including smart homes and\nindustry. As data continues to shape our digital landscape, our research\nunderscores the critical need to maintain privacy and user control at the\nforefront of technological progress.",
      "pdf_url": "http://arxiv.org/pdf/2503.03428v1",
      "published": "2025-03-05T12:01:22+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.03428v1",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.ET",
        "cs.HC"
      ]
    },
    {
      "title": "Simplicial SMOTE: Oversampling Solution to the Imbalanced Learning Problem",
      "authors": [
        "Oleg Kachan",
        "Andrey Savchenko",
        "Gleb Gusev"
      ],
      "abstract": "SMOTE (Synthetic Minority Oversampling Technique) is the established\ngeometric approach to random oversampling to balance classes in the imbalanced\nlearning problem, followed by many extensions. Its idea is to introduce\nsynthetic data points of the minor class, with each new point being the convex\ncombination of an existing data point and one of its k-nearest neighbors. In\nthis paper, by viewing SMOTE as sampling from the edges of a geometric\nneighborhood graph and borrowing tools from the topological data analysis, we\npropose a novel technique, Simplicial SMOTE, that samples from the simplices of\na geometric neighborhood simplicial complex. A new synthetic point is defined\nby the barycentric coordinates w.r.t. a simplex spanned by an arbitrary number\nof data points being sufficiently close rather than a pair. Such a replacement\nof the geometric data model results in better coverage of the underlying data\ndistribution compared to existing geometric sampling methods and allows the\ngeneration of synthetic points of the minority class closer to the majority\nclass on the decision boundary. We experimentally demonstrate that our\nSimplicial SMOTE outperforms several popular geometric sampling methods,\nincluding the original SMOTE. Moreover, we show that simplicial sampling can be\neasily integrated into existing SMOTE extensions. We generalize and evaluate\nsimplicial extensions of the classic Borderline SMOTE, Safe-level SMOTE, and\nADASYN algorithms, all of which outperform their graph-based counterparts.",
      "pdf_url": "http://arxiv.org/pdf/2503.03418v1",
      "published": "2025-03-05T11:47:41+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.03418v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "When Claims Evolve: Evaluating and Enhancing the Robustness of Embedding Models Against Misinformation Edits",
      "authors": [
        "Jabez Magomere",
        "Emanuele La Malfa",
        "Manuel Tonneau",
        "Ashkan Kazemi",
        "Scott Hale"
      ],
      "abstract": "Online misinformation remains a critical challenge, and fact-checkers\nincreasingly rely on embedding-based methods to retrieve relevant fact-checks.\nYet, when debunked claims reappear in edited forms, the performance of these\nmethods is unclear. In this work, we introduce a taxonomy of six common\nreal-world misinformation edits and propose a perturbation framework that\ngenerates valid, natural claim variations. Our multi-stage retrieval evaluation\nreveals that standard embedding models struggle with user-introduced edits,\nwhile LLM-distilled embeddings offer improved robustness at a higher\ncomputational cost. Although a strong reranker helps mitigate some issues, it\ncannot fully compensate for first-stage retrieval gaps. Addressing these\nretrieval gaps, our train- and inference-time mitigation approaches enhance\nin-domain robustness by up to 17 percentage points and boost out-of-domain\ngeneralization by 10 percentage points over baseline models. Overall, our\nfindings provide practical improvements to claim-matching systems, enabling\nmore reliable fact-checking of evolving misinformation.",
      "pdf_url": "http://arxiv.org/pdf/2503.03417v1",
      "published": "2025-03-05T11:47:32+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.03417v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Augmentation-Based Deep Learning for Identification of Circulating Tumor Cells",
      "authors": [
        "Martina Russo",
        "Giulia Bertolini",
        "Vera Cappelletti",
        "Cinzia De Marco",
        "Serena Di Cosimo",
        "Petra Paiè",
        "Nadia Brancati"
      ],
      "abstract": "Circulating tumor cells (CTCs) are crucial biomarkers in liquid biopsy,\noffering a noninvasive tool for cancer patient management. However, their\nidentification remains particularly challenging due to their limited number and\nheterogeneity. Labeling samples for contrast limits the generalization of\nfluorescence-based methods across different hospital datasets. Analyzing\nsingle-cell images enables detailed assessment of cell morphology, subcellular\nstructures, and phenotypic variations, often hidden in clustered images.\nDeveloping a method based on bright-field single-cell analysis could overcome\nthese limitations. CTCs can be isolated using an unbiased workflow combining\nParsortix technology, which selects cells based on size and deformability, with\nDEPArray technology, enabling precise visualization and selection of single\ncells. Traditionally, DEPArray-acquired digital images are manually analyzed,\nmaking the process time-consuming and prone to variability. In this study, we\npresent a Deep Learning-based classification pipeline designed to distinguish\nCTCs from leukocytes in blood samples, aimed to enhance diagnostic accuracy and\noptimize clinical workflows. Our approach employs images from the bright-field\nchannel acquired through DEPArray technology leveraging a ResNet-based CNN. To\nimprove model generalization, we applied three types of data augmentation\ntechniques and incorporated fluorescence (DAPI) channel images into the\ntraining phase, allowing the network to learn additional CTC-specific features.\nNotably, only bright-field images have been used for testing, ensuring the\nmodel's ability to identify CTCs without relying on fluorescence markers. The\nproposed model achieved an F1-score of 0.798, demonstrating its capability to\ndistinguish CTCs from leukocytes. These findings highlight the potential of DL\nin refining CTC analysis and advancing liquid biopsy applications.",
      "pdf_url": "http://arxiv.org/pdf/2503.03410v1",
      "published": "2025-03-05T11:39:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.03410v1",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "68T07, 68T10",
        "I.2; I.4; J.3"
      ]
    },
    {
      "title": "AI-Driven Multi-Stage Computer Vision System for Defect Detection in Laser-Engraved Industrial Nameplates",
      "authors": [
        "Adhish Anitha Vilasan",
        "Stephan Jäger",
        "Noah Klarmann"
      ],
      "abstract": "Automated defect detection in industrial manufacturing is essential for\nmaintaining product quality and minimizing production errors. In air disc brake\nmanufacturing, ensuring the precision of laser-engraved nameplates is crucial\nfor accurate product identification and quality control. Engraving errors, such\nas misprints or missing characters, can compromise both aesthetics and\nfunctionality, leading to material waste and production delays. This paper\npresents a proof of concept for an AI-driven computer vision system that\ninspects and verifies laser-engraved nameplates, detecting defects in logos and\nalphanumeric strings. The system integrates object detection using YOLOv7,\noptical character recognition (OCR) with Tesseract, and anomaly detection\nthrough a residual variational autoencoder (ResVAE) along with other computer\nvision methods to enable comprehensive inspections at multiple stages.\nExperimental results demonstrate the system's effectiveness, achieving 91.33%\naccuracy and 100% recall, ensuring that defective nameplates are consistently\ndetected and addressed. This solution highlights the potential of AI-driven\nvisual inspection to enhance quality control, reduce manual inspection efforts,\nand improve overall manufacturing efficiency.",
      "pdf_url": "http://arxiv.org/pdf/2503.03395v1",
      "published": "2025-03-05T11:19:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.03395v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Multi-Agent DRL for Queue-Aware Task Offloading in Hierarchical MEC-Enabled Air-Ground Networks",
      "authors": [
        "Muhammet Hevesli",
        "Abegaz Mohammed Seid",
        "Aiman Erbad",
        "Mohamed Abdallah"
      ],
      "abstract": "Mobile edge computing (MEC)-enabled air-ground networks are a key component\nof 6G, employing aerial base stations (ABSs) such as unmanned aerial vehicles\n(UAVs) and high-altitude platform stations (HAPS) to provide dynamic services\nto ground IoT devices (IoTDs). These IoTDs support real-time applications\n(e.g., multimedia and Metaverse services) that demand high computational\nresources and strict quality of service (QoS) guarantees in terms of latency\nand task queue management. Given their limited energy and processing\ncapabilities, IoTDs rely on UAVs and HAPS to offload tasks for distributed\nprocessing, forming a multi-tier MEC system. This paper tackles the overall\nenergy minimization problem in MEC-enabled air-ground integrated networks\n(MAGIN) by jointly optimizing UAV trajectories, computing resource allocation,\nand queue-aware task offloading decisions. The optimization is challenging due\nto the nonconvex, nonlinear nature of this hierarchical system, which renders\ntraditional methods ineffective. We reformulate the problem as a multi-agent\nMarkov decision process (MDP) with continuous action spaces and heterogeneous\nagents, and propose a novel variant of multi-agent proximal policy optimization\nwith a Beta distribution (MAPPO-BD) to solve it. Extensive simulations show\nthat MAPPO-BD outperforms baseline schemes, achieving superior energy savings\nand efficient resource management in MAGIN while meeting queue delay and edge\ncomputing constraints.",
      "pdf_url": "http://arxiv.org/pdf/2503.03391v1",
      "published": "2025-03-05T11:12:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.03391v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "From Infants to AI: Incorporating Infant-like Learning in Models Boosts Efficiency and Generalization in Learning Social Prediction Tasks",
      "authors": [
        "Shify Treger",
        "Shimon Ullman"
      ],
      "abstract": "Early in development, infants learn a range of useful concepts, which can be\nchallenging from a computational standpoint. This early learning comes together\nwith an initial understanding of aspects of the meaning of concepts, e.g.,\ntheir implications, causality, and using them to predict likely future events.\nAll this is accomplished in many cases with little or no supervision, and from\nrelatively few examples, compared with current network models. In learning\nabout objects and human-object interactions, early acquired and possibly innate\nconcepts are often used in the process of learning additional, more complex\nconcepts. In the current work, we model how early-acquired concepts are used in\nthe learning of subsequent concepts, and compare the results with standard deep\nnetwork modeling. We focused in particular on the use of the concepts of\nanimacy and goal attribution in learning to predict future events. We show that\nthe use of early concepts in the learning of new concepts leads to better\nlearning (higher accuracy) and more efficient learning (requiring less data).\nWe further show that this integration of early and new concepts shapes the\nrepresentation of the concepts acquired by the model. The results show that\nwhen the concepts were learned in a human-like manner, the emerging\nrepresentation was more useful, as measured in terms of generalization to novel\ndata and tasks. On a more general level, the results suggest that there are\nlikely to be basic differences in the conceptual structures acquired by current\nnetwork models compared to human learning.",
      "pdf_url": "http://arxiv.org/pdf/2503.03361v1",
      "published": "2025-03-05T10:40:19+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.03361v1",
      "categories": [
        "cs.AI",
        "cs.NE"
      ]
    },
    {
      "title": "Transformers for molecular property prediction: Domain adaptation efficiently improves performance",
      "authors": [
        "Afnan Sultan",
        "Max Rausch-Dupont",
        "Shahrukh Khan",
        "Olga Kalinina",
        "Andrea Volkamer",
        "Dietrich Klakow"
      ],
      "abstract": "Most of the current transformer-based chemical language models are\npre-trained on millions to billions of molecules. However, the improvement from\nsuch scaling in dataset size is not confidently linked to improved molecular\nproperty prediction. The aim of this study is to investigate and overcome some\nof the limitations of transformer models in predicting molecular properties.\nSpecifically, we examine the impact of pre-training dataset size and diversity\non the performance of transformer models and investigate the use of domain\nadaptation as a technique for improving model performance. First, our findings\nindicate that increasing pretraining dataset size beyond 400K molecules from\nthe GuacaMol dataset does not result in a significant improvement on four ADME\nendpoints, namely, solubility, permeability, microsomal stability, and plasma\nprotein binding. Second, our results demonstrate that using domain adaptation\nby further training the transformer model on a small set of domain-relevant\nmolecules, i.e., a few hundred to a few thousand, using multi-task regression\nof physicochemical properties was sufficient to significantly improve\nperformance for three out of the four investigated ADME endpoints (P-value <\n0.001). Finally, we observe that a model pre-trained on 400K molecules and\ndomain adopted on a few hundred/thousand molecules performs similarly (P-value\n> 0.05) to more complicated transformer models like MolBERT(pre-trained on 1.3M\nmolecules) and MolFormer (pre-trained on 100M molecules). A comparison to a\nrandom forest model trained on basic physicochemical properties showed similar\nperformance to the examined transformer models. We believe that current\ntransformer models can be improved through further systematic analysis of\npre-training and downstream data, pre-training objectives, and scaling laws,\nultimately leading to better and more helpful models.",
      "pdf_url": "http://arxiv.org/pdf/2503.03360v1",
      "published": "2025-03-05T10:40:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.03360v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Leveraging Large Language Models to Develop Heuristics for Emerging Optimization Problems",
      "authors": [
        "Thomas Bömer",
        "Nico Koltermann",
        "Max Disselnmeyer",
        "Laura Dörr",
        "Anne Meyer"
      ],
      "abstract": "Combinatorial optimization problems often rely on heuristic algorithms to\ngenerate efficient solutions. However, the manual design of heuristics is\nresource-intensive and constrained by the designer's expertise. Recent advances\nin artificial intelligence, particularly large language models (LLMs), have\ndemonstrated the potential to automate heuristic generation through\nevolutionary frameworks. Recent works focus only on well-known combinatorial\noptimization problems like the traveling salesman problem and online bin\npacking problem when designing constructive heuristics. This study investigates\nwhether LLMs can effectively generate heuristics for niche, not yet broadly\nresearched optimization problems, using the unit-load pre-marshalling problem\nas an example case. We propose the Contextual Evolution of Heuristics (CEoH)\nframework, an extension of the Evolution of Heuristics (EoH) framework, which\nincorporates problem-specific descriptions to enhance in-context learning\nduring heuristic generation. Through computational experiments, we evaluate\nCEoH and EoH and compare the results. Results indicate that CEoH enables\nsmaller LLMs to generate high-quality heuristics more consistently and even\noutperform larger models. Larger models demonstrate robust performance with or\nwithout contextualized prompts. The generated heuristics exhibit scalability to\ndiverse instance configurations.",
      "pdf_url": "http://arxiv.org/pdf/2503.03350v1",
      "published": "2025-03-05T10:22:49+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.03350v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Navigating Intelligence: A Survey of Google OR-Tools and Machine Learning for Global Path Planning in Autonomous Vehicles",
      "authors": [
        "Alexandre Benoit",
        "Pedram Asef"
      ],
      "abstract": "We offer a new in-depth investigation of global path planning (GPP) for\nunmanned ground vehicles, an autonomous mining sampling robot named ROMIE. GPP\nis essential for ROMIE's optimal performance, which is translated into solving\nthe traveling salesman problem, a complex graph theory challenge that is\ncrucial for determining the most effective route to cover all sampling\nlocations in a mining field. This problem is central to enhancing ROMIE's\noperational efficiency and competitiveness against human labor by optimizing\ncost and time. The primary aim of this research is to advance GPP by\ndeveloping, evaluating, and improving a cost-efficient software and web\napplication. We delve into an extensive comparison and analysis of Google\noperations research (OR)-Tools optimization algorithms. Our study is driven by\nthe goal of applying and testing the limits of OR-Tools capabilities by\nintegrating Reinforcement Learning techniques for the first time. This enables\nus to compare these methods with OR-Tools, assessing their computational\neffectiveness and real-world application efficiency. Our analysis seeks to\nprovide insights into the effectiveness and practical application of each\ntechnique. Our findings indicate that Q-Learning stands out as the optimal\nstrategy, demonstrating superior efficiency by deviating only 1.2% on average\nfrom the optimal solutions across our datasets.",
      "pdf_url": "http://arxiv.org/pdf/2503.03338v1",
      "published": "2025-03-05T10:12:22+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.03338v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CE",
        "eess.SP"
      ]
    },
    {
      "title": "See What You Are Told: Visual Attention Sink in Large Multimodal Models",
      "authors": [
        "Seil Kang",
        "Jinyeong Kim",
        "Junhyeok Kim",
        "Seong Jae Hwang"
      ],
      "abstract": "Large multimodal models (LMMs) \"see\" images by leveraging the attention\nmechanism between text and visual tokens in the transformer decoder. Ideally,\nthese models should focus on key visual information relevant to the text token.\nHowever, recent findings indicate that LMMs have an extraordinary tendency to\nconsistently allocate high attention weights to specific visual tokens, even\nwhen these tokens are irrelevant to the corresponding text. In this study, we\ninvestigate the property behind the appearance of these irrelevant visual\ntokens and examine their characteristics. Our findings show that this behavior\narises due to the massive activation of certain hidden state dimensions, which\nresembles the attention sink found in language models. Hence, we refer to this\nphenomenon as the visual attention sink. In particular, our analysis reveals\nthat removing the irrelevant visual sink tokens does not impact model\nperformance, despite receiving high attention weights. Consequently, we recycle\nthe attention to these tokens as surplus resources, redistributing the\nattention budget to enhance focus on the image. To achieve this, we introduce\nVisual Attention Redistribution (VAR), a method that redistributes attention in\nimage-centric heads, which we identify as innately focusing on visual\ninformation. VAR can be seamlessly applied across different LMMs to improve\nperformance on a wide range of tasks, including general vision-language tasks,\nvisual hallucination tasks, and vision-centric tasks, all without the need for\nadditional training, models, or inference steps. Experimental results\ndemonstrate that VAR enables LMMs to process visual information more\neffectively by adjusting their internal attention mechanisms, offering a new\ndirection to enhancing the multimodal capabilities of LMMs.",
      "pdf_url": "http://arxiv.org/pdf/2503.03321v1",
      "published": "2025-03-05T09:55:07+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.03321v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Exploring specialization and sensitivity of convolutional neural networks in the context of simultaneous image augmentations",
      "authors": [
        "Pavel Kharyuk",
        "Sergey Matveev",
        "Ivan Oseledets"
      ],
      "abstract": "Drawing parallels with the way biological networks are studied, we adapt the\ntreatment--control paradigm to explainable artificial intelligence research and\nenrich it through multi-parametric input alterations. In this study, we propose\na framework for investigating the internal inference impacted by input data\naugmentations. The internal changes in network operation are reflected in\nactivation changes measured by variance, which can be decomposed into\ncomponents related to each augmentation, employing Sobol indices and Shapley\nvalues. These quantities enable one to visualize sensitivity to different\nvariables and use them for guided masking of activations. In addition, we\nintroduce a way of single-class sensitivity analysis where the candidates are\nfiltered according to their matching to prediction bias generated by targeted\ndamaging of the activations. Relying on the observed parallels, we assume that\nthe developed framework can potentially be transferred to studying biological\nneural networks in complex environments.",
      "pdf_url": "http://arxiv.org/pdf/2503.03283v1",
      "published": "2025-03-05T09:09:01+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.03283v1",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "cs.NA",
        "math.NA",
        "68T07",
        "I.2.6; G.3; I.2.10"
      ]
    },
    {
      "title": "Benchmarking Dynamic SLO Compliance in Distributed Computing Continuum Systems",
      "authors": [
        "Alfreds Lapkovskis",
        "Boris Sedlak",
        "Sindri Magnússon",
        "Schahram Dustdar",
        "Praveen Kumar Donta"
      ],
      "abstract": "Ensuring Service Level Objectives (SLOs) in large-scale architectures, such\nas Distributed Computing Continuum Systems (DCCS), is challenging due to their\nheterogeneous nature and varying service requirements across different devices\nand applications. Additionally, unpredictable workloads and resource\nlimitations lead to fluctuating performance and violated SLOs. To improve SLO\ncompliance in DCCS, one possibility is to apply machine learning; however, the\ndesign choices are often left to the developer. To that extent, we provide a\nbenchmark of Active Inference -- an emerging method from neuroscience --\nagainst three established reinforcement learning algorithms (Deep Q-Network,\nAdvantage Actor-Critic, and Proximal Policy Optimization). We consider a\nrealistic DCCS use case: an edge device running a video conferencing\napplication alongside a WebSocket server streaming videos. Using one of the\nrespective algorithms, we continuously monitor key performance metrics, such as\nlatency and bandwidth usage, to dynamically adjust parameters -- including the\nnumber of streams, frame rate, and resolution -- to optimize service quality\nand user experience. To test algorithms' adaptability to constant system\nchanges, we simulate dynamically changing SLOs and both instant and gradual\ndata-shift scenarios, such as network bandwidth limitations and fluctuating\ndevice thermal states. Although the evaluated algorithms all showed advantages\nand limitations, our findings demonstrate that Active Inference is a promising\napproach for ensuring SLO compliance in DCCS, offering lower memory usage,\nstable CPU utilization, and fast convergence.",
      "pdf_url": "http://arxiv.org/pdf/2503.03274v1",
      "published": "2025-03-05T08:56:26+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.03274v1",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG",
        "cs.NI",
        "cs.PF"
      ]
    },
    {
      "title": "Conformal Transformations for Symmetric Power Transformers",
      "authors": [
        "Saurabh Kumar",
        "Jacob Buckman",
        "Carles Gelada",
        "Sean Zhang"
      ],
      "abstract": "Transformers with linear attention offer significant computational advantages\nover softmax-based transformers but often suffer from degraded performance. The\nsymmetric power (sympow) transformer, a particular type of linear transformer,\naddresses some of this performance gap by leveraging symmetric tensor\nembeddings, achieving comparable performance to softmax transformers. However,\nthe finite capacity of the recurrent state in sympow transformers limits their\nability to retain information, leading to performance degradation when scaling\nthe training or evaluation context length. To address this issue, we propose\nthe conformal-sympow transformer, which dynamically frees up capacity using\ndata-dependent multiplicative gating and adaptively stores information using\ndata-dependent rotary embeddings. Preliminary experiments on the LongCrawl64\ndataset demonstrate that conformal-sympow overcomes the limitations of sympow\ntransformers, achieving robust performance across scaled training and\nevaluation contexts.",
      "pdf_url": "http://arxiv.org/pdf/2503.03269v1",
      "published": "2025-03-05T08:50:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.03269v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Trajectory Prediction for Autonomous Driving: Progress, Limitations, and Future Directions",
      "authors": [
        "Nadya Abdel Madjid",
        "Abdulrahman Ahmad",
        "Murad Mebrahtu",
        "Yousef Babaa",
        "Abdelmoamen Nasser",
        "Sumbal Malik",
        "Bilal Hassan",
        "Naoufel Werghi",
        "Jorge Dias",
        "Majid Khonji"
      ],
      "abstract": "As the potential for autonomous vehicles to be integrated on a large scale\ninto modern traffic systems continues to grow, ensuring safe navigation in\ndynamic environments is crucial for smooth integration. To guarantee safety and\nprevent collisions, autonomous vehicles must be capable of accurately\npredicting the trajectories of surrounding traffic agents. Over the past\ndecade, significant efforts from both academia and industry have been dedicated\nto designing solutions for precise trajectory forecasting. These efforts have\nproduced a diverse range of approaches, raising questions about the differences\nbetween these methods and whether trajectory prediction challenges have been\nfully addressed. This paper reviews a substantial portion of recent trajectory\nprediction methods and devises a taxonomy to classify existing solutions. A\ngeneral overview of the prediction pipeline is also provided, covering input\nand output modalities, modeling features, and prediction paradigms discussed in\nthe literature. In addition, the paper discusses active research areas within\ntrajectory prediction, addresses the posed research questions, and highlights\nthe remaining research gaps and challenges.",
      "pdf_url": "http://arxiv.org/pdf/2503.03262v1",
      "published": "2025-03-05T08:38:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.03262v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ]
    },
    {
      "title": "Exploring the Potential of Large Language Models as Predictors in Dynamic Text-Attributed Graphs",
      "authors": [
        "Runlin Lei",
        "Jiarui Ji",
        "Haipeng Ding",
        "Lu Yi",
        "Zhewei Wei",
        "Yongchao Liu",
        "Chuntao Hong"
      ],
      "abstract": "With the rise of large language models (LLMs), there has been growing\ninterest in Graph Foundation Models (GFMs) for graph-based tasks. By leveraging\nLLMs as predictors, GFMs have demonstrated impressive generalizability across\nvarious tasks and datasets. However, existing research on LLMs as predictors\nhas predominantly focused on static graphs, leaving their potential in dynamic\ngraph prediction unexplored. In this work, we pioneer using LLMs for predictive\ntasks on dynamic graphs. We identify two key challenges: the constraints\nimposed by context length when processing large-scale historical data and the\nsignificant variability in domain characteristics, both of which complicate the\ndevelopment of a unified predictor. To address these challenges, we propose the\nGraphAgent-Dynamic (GAD) Framework, a multi-agent system that leverages\ncollaborative LLMs. In contrast to using a single LLM as the predictor, GAD\nincorporates global and local summary agents to generate domain-specific\nknowledge, enhancing its transferability across domains. Additionally,\nknowledge reflection agents enable adaptive updates to GAD's knowledge,\nmaintaining a unified and self-consistent architecture. In experiments, GAD\ndemonstrates performance comparable to or even exceeds that of full-supervised\ngraph neural networks without dataset-specific training. Finally, to enhance\nthe task-specific performance of LLM-based predictors, we discuss potential\nimprovements, such as dataset-specific fine-tuning to LLMs. By developing\ntailored strategies for different tasks, we provide new insights for the future\ndesign of LLM-based predictors.",
      "pdf_url": "http://arxiv.org/pdf/2503.03258v1",
      "published": "2025-03-05T08:28:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.03258v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Less is more? Rewards in RL for Cyber Defence",
      "authors": [
        "Elizabeth Bates",
        "Chris Hicks",
        "Vasilios Mavroudis"
      ],
      "abstract": "The last few years has seen an explosion of interest in autonomous cyber\ndefence agents based on deep reinforcement learning. Such agents are typically\ntrained in a cyber gym environment, also known as a cyber simulator, at least\n32 of which have already been built. Most, if not all cyber gyms provide dense\n\"scaffolded\" reward functions which combine many penalties or incentives for a\nrange of (un)desirable states and costly actions. Whilst dense rewards help\nalleviate the challenge of exploring complex environments, yielding seemingly\neffective strategies from relatively few environment steps; they are also known\nto bias the solutions an agent can find, potentially towards suboptimal\nsolutions. Sparse rewards could offer preferable or more effective solutions\nand have been overlooked by cyber gyms to date. In this work we set out to\nevaluate whether sparse reward functions might enable training more effective\ncyber defence agents. Towards this goal we first break down several evaluation\nlimitations in existing work by proposing a ground truth evaluation score that\ngoes beyond the standard RL paradigm used to train and evaluate agents. By\nadapting a well-established cyber gym to accommodate our methodology and ground\ntruth score, we propose and evaluate two sparse reward mechanisms and compare\nthem with a typical dense reward. Our evaluation considers a range of network\nsizes, from 2 to 50 nodes, and both reactive and proactive defensive actions.\nOur results show that sparse rewards, particularly positive reinforcement for\nan uncompromised network state, enable the training of more effective cyber\ndefence agents. Furthermore, we show that sparse rewards provide more stable\ntraining than dense rewards, and that both effectiveness and training stability\nare robust to a variety of cyber environment considerations.",
      "pdf_url": "http://arxiv.org/pdf/2503.03245v1",
      "published": "2025-03-05T07:53:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.03245v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ]
    },
    {
      "title": "FANS -- Formal Answer Selection for Natural Language Math Reasoning Using Lean4",
      "authors": [
        "Jiarui Yao",
        "Ruida Wang",
        "Tong Zhang"
      ],
      "abstract": "Large Language Models (LLMs) have displayed astonishing abilities in various\ntasks, especially in text generation, classification, question answering, etc.\nHowever, the reasoning ability of LLMs still faces many debates. The inherent\nambiguity of Natural Language (NL) limits LLMs' ability to perform verifiable\nreasoning, making its answers lack coherence and trustworthy support. To tackle\nthe above problems, we propose a novel framework named FANS: Formal ANswer\nSelection for Natural Language Math Reasoning Using Lean4. To the best of our\nknowledge, it is the first framework that utilizes Lean4 to enhance LLMs' NL\nmath reasoning ability. In particular, given an NL math question and\nLLM-generated answers, FANS first translates it into Lean4 theorem statements.\nThen it tries to prove it using a Lean4 prover and verify it by Lean4. Finally,\nit uses the FL result to assist in answer selection. It enhances LLMs' NL math\nability in providing a computer-verifiable solution for its correct answer and\nproposes an alternative method for answer selection beyond the reward model.\nExtensive experiments indicate the effectiveness of our framework. It can\nimprove the accuracy rate of reward model enhanced LLMs in the MATH-500 dataset\nby at most 1.91% and AMC-23 by at most 8.33% on strong reward-model baselines.\nIn some particular fields like number theory that Lean4 experts in, we can even\nselect all correct solutions. The qualitative analysis also shows our framework\ncan make NL results formally backed by Lean4 proofs. As a pioneering work in\nthe corresponding field, we will open-source all our models and datasets to\nfurther boost the development of the field.",
      "pdf_url": "http://arxiv.org/pdf/2503.03238v1",
      "published": "2025-03-05T07:34:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2503.03238v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    }
  ]
}