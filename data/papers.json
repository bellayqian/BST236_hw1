{
  "last_updated": "2025-10-29T00:53:20.142487",
  "papers": [
    {
      "title": "Variational Masked Diffusion Models",
      "authors": [
        "Yichi Zhang",
        "Alex Schwing",
        "Zhizhen Zhao"
      ],
      "abstract": "Masked diffusion models have recently emerged as a flexible framework for\ndiscrete generative modeling. However, a key limitation of standard masked\ndiffusion is its inability to effectively capture dependencies among tokens\nthat are predicted concurrently, leading to degraded generation quality when\ndependencies among tokens are important. To explicitly model dependencies among\ntokens, we propose Variational Masked Diffusion (VMD), a framework that\nintroduces latent variables into the masked diffusion process. Through\ncontrolled experiments on synthetic datasets, we demonstrate that VMD\nsuccessfully learns dependencies that conventional masked diffusion fails to\ncapture. We further validate the effectiveness of our approach on Sudoku\npuzzles and text datasets, where learning of dependencies among tokens improves\nglobal consistency. Across these domains, VMD enhances both generation quality\nand dependency awareness, highlighting the value of integrating variational\ninference into masked diffusion. Our code is available at:\nhttps://riccizz.github.io/VMD.",
      "pdf_url": "http://arxiv.org/pdf/2510.23606v1",
      "published": "2025-10-27T17:59:57+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.23606v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Track, Inpaint, Resplat: Subject-driven 3D and 4D Generation with Progressive Texture Infilling",
      "authors": [
        "Shuhong Zheng",
        "Ashkan Mirzaei",
        "Igor Gilitschenski"
      ],
      "abstract": "Current 3D/4D generation methods are usually optimized for photorealism,\nefficiency, and aesthetics. However, they often fail to preserve the semantic\nidentity of the subject across different viewpoints. Adapting generation\nmethods with one or few images of a specific subject (also known as\nPersonalization or Subject-driven generation) allows generating visual content\nthat align with the identity of the subject. However, personalized 3D/4D\ngeneration is still largely underexplored. In this work, we introduce TIRE\n(Track, Inpaint, REsplat), a novel method for subject-driven 3D/4D generation.\nIt takes an initial 3D asset produced by an existing 3D generative model as\ninput and uses video tracking to identify the regions that need to be modified.\nThen, we adopt a subject-driven 2D inpainting model for progressively infilling\nthe identified regions. Finally, we resplat the modified 2D multi-view\nobservations back to 3D while still maintaining consistency. Extensive\nexperiments demonstrate that our approach significantly improves identity\npreservation in 3D/4D generation compared to state-of-the-art methods. Our\nproject website is available at\nhttps://zsh2000.github.io/track-inpaint-resplat.github.io/.",
      "pdf_url": "http://arxiv.org/pdf/2510.23605v1",
      "published": "2025-10-27T17:59:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.23605v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG",
        "cs.RO"
      ]
    },
    {
      "title": "Alita-G: Self-Evolving Generative Agent for Agent Generation",
      "authors": [
        "Jiahao Qiu",
        "Xuan Qi",
        "Hongru Wang",
        "Xinzhe Juan",
        "Yimin Wang",
        "Zelin Zhao",
        "Jiayi Geng",
        "Jiacheng Guo",
        "Peihang Li",
        "Jingzhe Shi",
        "Shilong Liu",
        "Mengdi Wang"
      ],
      "abstract": "Large language models (LLMs) have been shown to perform better when\nscaffolded into agents with memory, tools, and feedback. Beyond this,\nself-evolving agents have emerged, but current work largely limits adaptation\nto prompt rewriting or failure retries. Therefore, we present ALITA-G, a\nself-evolution framework that transforms a general-purpose agent into a domain\nexpert by systematically generating, abstracting, and curating Model Context\nProtocol (MCP) tools. In this framework, a generalist agent executes a curated\nsuite of target-domain tasks and synthesizes candidate MCPs from successful\ntrajectories. These are then abstracted to parameterized primitives and\nconsolidated into an MCP Box. At inference time, ALITA-G performs\nretrieval-augmented MCP selection with the help of each tool's descriptions and\nuse cases, before executing an agent equipped with the MCP Executor. Across\nseveral benchmarks GAIA, PathVQA, and Humanity's Last Exam, ALITA-G attains\nstrong gains while reducing computation costs. On GAIA validation, it achieves\n83.03% pass@1 and 89.09% pass@3, establishing a new state-of-the-art result\nwhile reducing mean tokens per example by approximately 15% relative to a\nstrong baseline agent. ALITA-G thus provides a principled pathway from\ngeneralist capability to reusable, domain-specific competence, improving both\naccuracy and efficiency on complex reasoning tasks.",
      "pdf_url": "http://arxiv.org/pdf/2510.23601v1",
      "published": "2025-10-27T17:59:14+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.23601v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Multi-Agent Evolve: LLM Self-Improve through Co-evolution",
      "authors": [
        "Yixing Chen",
        "Yiding Wang",
        "Siqi Zhu",
        "Haofei Yu",
        "Tao Feng",
        "Muhan Zhang",
        "Mostofa Patwary",
        "Jiaxuan You"
      ],
      "abstract": "Reinforcement Learning (RL) has demonstrated significant potential in\nenhancing the reasoning capabilities of large language models (LLMs). However,\nthe success of RL for LLMs heavily relies on human-curated datasets and\nverifiable rewards, which limit their scalability and generality. Recent\nSelf-Play RL methods, inspired by the success of the paradigm in games and Go,\naim to enhance LLM reasoning capabilities without human-annotated data.\nHowever, their methods primarily depend on a grounded environment for feedback\n(e.g., a Python interpreter or a game engine); extending them to general\ndomains remains challenging. To address these challenges, we propose\nMulti-Agent Evolve (MAE), a framework that enables LLMs to self-evolve in\nsolving diverse tasks, including mathematics, reasoning, and general knowledge\nQ&A. The core design of MAE is based on a triplet of interacting agents\n(Proposer, Solver, Judge) that are instantiated from a single LLM, and applies\nreinforcement learning to optimize their behaviors. The Proposer generates\nquestions, the Solver attempts solutions, and the Judge evaluates both while\nco-evolving. Experiments on Qwen2.5-3B-Instruct demonstrate that MAE achieves\nan average improvement of 4.54% on multiple benchmarks. These results highlight\nMAE as a scalable, data-efficient method for enhancing the general reasoning\nabilities of LLMs with minimal reliance on human-curated supervision.",
      "pdf_url": "http://arxiv.org/pdf/2510.23595v2",
      "published": "2025-10-27T17:58:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.23595v2",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "A Survey of Data Agents: Emerging Paradigm or Overstated Hype?",
      "authors": [
        "Yizhang Zhu",
        "Liangwei Wang",
        "Chenyu Yang",
        "Xiaotian Lin",
        "Boyan Li",
        "Wei Zhou",
        "Xinyu Liu",
        "Zhangyang Peng",
        "Tianqi Luo",
        "Yu Li",
        "Chengliang Chai",
        "Chong Chen",
        "Shimin Di",
        "Ju Fan",
        "Ji Sun",
        "Nan Tang",
        "Fugee Tsung",
        "Jiannan Wang",
        "Chenglin Wu",
        "Yanwei Xu",
        "Shaolei Zhang",
        "Yong Zhang",
        "Xuanhe Zhou",
        "Guoliang Li",
        "Yuyu Luo"
      ],
      "abstract": "The rapid advancement of large language models (LLMs) has spurred the\nemergence of data agents--autonomous systems designed to orchestrate Data + AI\necosystems for tackling complex data-related tasks. However, the term \"data\nagent\" currently suffers from terminological ambiguity and inconsistent\nadoption, conflating simple query responders with sophisticated autonomous\narchitectures. This terminological ambiguity fosters mismatched user\nexpectations, accountability challenges, and barriers to industry growth.\nInspired by the SAE J3016 standard for driving automation, this survey\nintroduces the first systematic hierarchical taxonomy for data agents,\ncomprising six levels that delineate and trace progressive shifts in autonomy,\nfrom manual operations (L0) to a vision of generative, fully autonomous data\nagents (L5), thereby clarifying capability boundaries and responsibility\nallocation. Through this lens, we offer a structured review of existing\nresearch arranged by increasing autonomy, encompassing specialized data agents\nfor data management, preparation, and analysis, alongside emerging efforts\ntoward versatile, comprehensive systems with enhanced autonomy. We further\nanalyze critical evolutionary leaps and technical gaps for advancing data\nagents, especially the ongoing L2-to-L3 transition, where data agents evolve\nfrom procedural execution to autonomous orchestration. Finally, we conclude\nwith a forward-looking roadmap, envisioning the advent of proactive, generative\ndata agents.",
      "pdf_url": "http://arxiv.org/pdf/2510.23587v1",
      "published": "2025-10-27T17:54:07+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.23587v1",
      "categories": [
        "cs.DB",
        "cs.AI"
      ]
    },
    {
      "title": "Hope Speech Detection in Social Media English Corpora: Performance of Traditional and Transformer Models",
      "authors": [
        "Luis Ramos",
        "Hiram Calvo",
        "Olga Kolesnikova"
      ],
      "abstract": "The identification of hope speech has become a promised NLP task, considering\nthe need to detect motivational expressions of agency and goal-directed\nbehaviour on social media platforms. This proposal evaluates traditional\nmachine learning models and fine-tuned transformers for a previously split hope\nspeech dataset as train, development and test set. On development test, a\nlinear-kernel SVM and logistic regression both reached a macro-F1 of 0.78; SVM\nwith RBF kernel reached 0.77, and Na\\\"ive Bayes hit 0.75. Transformer models\ndelivered better results, the best model achieved weighted precision of 0.82,\nweighted recall of 0.80, weighted F1 of 0.79, macro F1 of 0.79, and 0.80\naccuracy. These results suggest that while optimally configured traditional\nmachine learning models remain agile, transformer architectures detect some\nsubtle semantics of hope to achieve higher precision and recall in hope speech\ndetection, suggesting that larges transformers and LLMs could perform better in\nsmall datasets.",
      "pdf_url": "http://arxiv.org/pdf/2510.23585v1",
      "published": "2025-10-27T17:53:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.23585v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Reduced AI Acceptance After the Generative AI Boom: Evidence From a Two-Wave Survey Study",
      "authors": [
        "Joachim Baumann",
        "Aleksandra Urman",
        "Ulrich Leicht-Deobald",
        "Zachary J. Roman",
        "Anikó Hannák",
        "Markus Christen"
      ],
      "abstract": "The rapid adoption of generative artificial intelligence (GenAI) technologies\nhas led many organizations to integrate AI into their products and services,\noften without considering user preferences. Yet, public attitudes toward AI\nuse, especially in impactful decision-making scenarios, are underexplored.\nUsing a large-scale two-wave survey study (n_wave1=1514, n_wave2=1488)\nrepresentative of the Swiss population, we examine shifts in public attitudes\ntoward AI before and after the launch of ChatGPT. We find that the GenAI boom\nis significantly associated with reduced public acceptance of AI (see Figure 1)\nand increased demand for human oversight in various decision-making contexts.\nThe proportion of respondents finding AI \"not acceptable at all\" increased from\n23% to 30%, while support for human-only decision-making rose from 18% to 26%.\nThese shifts have amplified existing social inequalities in terms of widened\neducational, linguistic, and gender gaps post-boom. Our findings challenge\nindustry assumptions about public readiness for AI deployment and highlight the\ncritical importance of aligning technological development with evolving public\npreferences.",
      "pdf_url": "http://arxiv.org/pdf/2510.23578v1",
      "published": "2025-10-27T17:47:58+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.23578v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "UrbanVLA: A Vision-Language-Action Model for Urban Micromobility",
      "authors": [
        "Anqi Li",
        "Zhiyong Wang",
        "Jiazhao Zhang",
        "Minghan Li",
        "Yunpeng Qi",
        "Zhibo Chen",
        "Zhizheng Zhang",
        "He Wang"
      ],
      "abstract": "Urban micromobility applications, such as delivery robots, demand reliable\nnavigation across large-scale urban environments while following long-horizon\nroute instructions. This task is particularly challenging due to the dynamic\nand unstructured nature of real-world city areas, yet most existing navigation\nmethods remain tailored to short-scale and controllable scenarios. Effective\nurban micromobility requires two complementary levels of navigation skills:\nlow-level capabilities such as point-goal reaching and obstacle avoidance, and\nhigh-level capabilities, such as route-visual alignment. To this end, we\npropose UrbanVLA, a route-conditioned Vision-Language-Action (VLA) framework\ndesigned for scalable urban navigation. Our method explicitly aligns noisy\nroute waypoints with visual observations during execution, and subsequently\nplans trajectories to drive the robot. To enable UrbanVLA to master both levels\nof navigation, we employ a two-stage training pipeline. The process begins with\nSupervised Fine-Tuning (SFT) using simulated environments and trajectories\nparsed from web videos. This is followed by Reinforcement Fine-Tuning (RFT) on\na mixture of simulation and real-world data, which enhances the model's safety\nand adaptability in real-world settings. Experiments demonstrate that UrbanVLA\nsurpasses strong baselines by more than 55% in the SocialNav task on MetaUrban.\nFurthermore, UrbanVLA achieves reliable real-world navigation, showcasing both\nscalability to large-scale urban environments and robustness against real-world\nuncertainties.",
      "pdf_url": "http://arxiv.org/pdf/2510.23576v1",
      "published": "2025-10-27T17:46:43+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.23576v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "RobotArena $\\infty$: Scalable Robot Benchmarking via Real-to-Sim Translation",
      "authors": [
        "Yash Jangir",
        "Yidi Zhang",
        "Kashu Yamazaki",
        "Chenyu Zhang",
        "Kuan-Hsun Tu",
        "Tsung-Wei Ke",
        "Lei Ke",
        "Yonatan Bisk",
        "Katerina Fragkiadaki"
      ],
      "abstract": "The pursuit of robot generalists - instructable agents capable of performing\ndiverse tasks across diverse environments - demands rigorous and scalable\nevaluation. Yet real-world testing of robot policies remains fundamentally\nconstrained: it is labor-intensive, slow, unsafe at scale, and difficult to\nreproduce. Existing simulation benchmarks are similarly limited, as they train\nand test policies within the same synthetic domains and cannot assess models\ntrained from real-world demonstrations or alternative simulation environments.\nAs policies expand in scope and complexity, these barriers only intensify,\nsince defining \"success\" in robotics often hinges on nuanced human judgments of\nexecution quality. In this paper, we introduce a new benchmarking framework\nthat overcomes these challenges by shifting VLA evaluation into large-scale\nsimulated environments augmented with online human feedback. Leveraging\nadvances in vision-language models, 2D-to-3D generative modeling, and\ndifferentiable rendering, our approach automatically converts video\ndemonstrations from widely used robot datasets into simulated counterparts.\nWithin these digital twins, we assess VLA policies using both automated\nVLM-guided scoring and scalable human preference judgments collected from\ncrowdworkers, transforming human involvement from tedious scene setup,\nresetting, and safety supervision into lightweight preference comparisons. To\nmeasure robustness, we systematically perturb simulated environments along\nmultiple axes, such as textures and object placements, stress-testing policy\ngeneralization under controlled variation. The result is a continuously\nevolving, reproducible, and scalable benchmark for real-world trained robot\nmanipulation policies, addressing a critical missing capability in today's\nrobotics landscape.",
      "pdf_url": "http://arxiv.org/pdf/2510.23571v1",
      "published": "2025-10-27T17:41:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.23571v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ]
    },
    {
      "title": "ReCode: Unify Plan and Action for Universal Granularity Control",
      "authors": [
        "Zhaoyang Yu",
        "Jiayi Zhang",
        "Huixue Su",
        "Yufan Zhao",
        "Yifan Wu",
        "Mingyi Deng",
        "Jinyu Xiang",
        "Yizhang Lin",
        "Lingxiao Tang",
        "Yingchao Li",
        "Yuyu Luo",
        "Bang Liu",
        "Chenglin Wu"
      ],
      "abstract": "Real-world tasks require decisions at varying granularities, and humans excel\nat this by leveraging a unified cognitive representation where planning is\nfundamentally understood as a high-level form of action. However, current Large\nLanguage Model (LLM)-based agents lack this crucial capability to operate\nfluidly across decision granularities. This limitation stems from existing\nparadigms that enforce a rigid separation between high-level planning and\nlow-level action, which impairs dynamic adaptability and limits generalization.\nWe propose ReCode (Recursive Code Generation), a novel paradigm that addresses\nthis limitation by unifying planning and action within a single code\nrepresentation. In this representation, ReCode treats high-level plans as\nabstract placeholder functions, which the agent then recursively decomposes\ninto finer-grained sub-functions until reaching primitive actions. This\nrecursive approach dissolves the rigid boundary between plan and action,\nenabling the agent to dynamically control its decision granularity.\nFurthermore, the recursive structure inherently generates rich,\nmulti-granularity training data, enabling models to learn hierarchical\ndecision-making processes. Extensive experiments show ReCode significantly\nsurpasses advanced baselines in inference performance and demonstrates\nexceptional data efficiency in training, validating our core insight that\nunifying planning and action through recursive code generation is a powerful\nand effective approach to achieving universal granularity control. The code is\navailable at https://github.com/FoundationAgents/ReCode.",
      "pdf_url": "http://arxiv.org/pdf/2510.23564v2",
      "published": "2025-10-27T17:35:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.23564v2",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    },
    {
      "title": "OntoPret: An Ontology for the Interpretation of Human Behavior",
      "authors": [
        "Alexis Ellis",
        "Stacie Severyn",
        "Fjollë Novakazi",
        "Hadi Banaee",
        "Cogan Shimizu"
      ],
      "abstract": "As human machine teaming becomes central to paradigms like Industry 5.0, a\ncritical need arises for machines to safely and effectively interpret complex\nhuman behaviors. A research gap currently exists between techno centric robotic\nframeworks, which often lack nuanced models of human behavior, and descriptive\nbehavioral ontologies, which are not designed for real time, collaborative\ninterpretation. This paper addresses this gap by presenting OntoPret, an\nontology for the interpretation of human behavior. Grounded in cognitive\nscience and a modular engineering methodology, OntoPret provides a formal,\nmachine processable framework for classifying behaviors, including task\ndeviations and deceptive actions. We demonstrate its adaptability across two\ndistinct use cases manufacturing and gameplay and establish the semantic\nfoundations necessary for advanced reasoning about human intentions.",
      "pdf_url": "http://arxiv.org/pdf/2510.23553v1",
      "published": "2025-10-27T17:28:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.23553v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "JanusCoder: Towards a Foundational Visual-Programmatic Interface for Code Intelligence",
      "authors": [
        "Qiushi Sun",
        "Jingyang Gong",
        "Yang Liu",
        "Qiaosheng Chen",
        "Lei Li",
        "Kai Chen",
        "Qipeng Guo",
        "Ben Kao",
        "Fei Yuan"
      ],
      "abstract": "The scope of neural code intelligence is rapidly expanding beyond text-based\nsource code to encompass the rich visual outputs that programs generate. This\nvisual dimension is critical for advanced applications like flexible content\ngeneration and precise, program-driven editing of visualizations. However,\nprogress has been impeded by the scarcity of high-quality multimodal code data,\na bottleneck stemming from challenges in synthesis and quality assessment. To\naddress these challenges, we make contributions from both a data and modeling\nperspective. We first introduce a complete synthesis toolkit that leverages\nreciprocal synergies between data modalities to efficiently produce a\nlarge-scale, high-quality corpus spanning from standard charts to complex\ninteractive web UIs and code-driven animations. Leveraging this toolkit, we\nconstruct JanusCode-800K, the largest multimodal code corpus to date. This\npowers the training of our models, JanusCoder and JanusCoderV, which establish\na visual-programmatic interface for generating code from textual instructions,\nvisual inputs, or a combination of both. Our unified model is a departure from\nexisting approaches that build specialized models for isolated tasks. Extensive\nexperiments on both text-centric and vision-centric coding tasks demonstrate\nthe superior performance of the JanusCoder series, with our 7B to 14B scale\nmodels approaching or even exceeding the performance of commercial models.\nFurthermore, extensive analysis provides key insights into harmonizing\nprogrammatic logic with its visual expression. Our code and checkpoints will\nare available at https://github.com/InternLM/JanusCoder.",
      "pdf_url": "http://arxiv.org/pdf/2510.23538v1",
      "published": "2025-10-27T17:13:49+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.23538v1",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.SE"
      ]
    },
    {
      "title": "When No Paths Lead to Rome: Benchmarking Systematic Neural Relational Reasoning",
      "authors": [
        "Anirban Das",
        "Irtaza Khalid",
        "Rafael Peñaloza",
        "Steven Schockaert"
      ],
      "abstract": "Designing models that can learn to reason in a systematic way is an important\nand long-standing challenge. In recent years, a wide range of solutions have\nbeen proposed for the specific case of systematic relational reasoning,\nincluding Neuro-Symbolic approaches, variants of the Transformer architecture,\nand specialised Graph Neural Networks. However, existing benchmarks for\nsystematic relational reasoning focus on an overly simplified setting, based on\nthe assumption that reasoning can be reduced to composing relational paths. In\nfact, this assumption is hard-baked into the architecture of several recent\nmodels, leading to approaches that can perform well on existing benchmarks but\nare difficult to generalise to other settings. To support further progress in\nthe field of systematic relational reasoning with neural networks, we introduce\nNoRA, a new benchmark which adds several levels of difficulty and requires\nmodels to go beyond path-based reasoning.",
      "pdf_url": "http://arxiv.org/pdf/2510.23532v1",
      "published": "2025-10-27T17:09:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.23532v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Learning Linearity in Audio Consistency Autoencoders via Implicit Regularization",
      "authors": [
        "Bernardo Torres",
        "Manuel Moussallam",
        "Gabriel Meseguer-Brocal"
      ],
      "abstract": "Audio autoencoders learn useful, compressed audio representations, but their\nnon-linear latent spaces prevent intuitive algebraic manipulation such as\nmixing or scaling. We introduce a simple training methodology to induce\nlinearity in a high-compression Consistency Autoencoder (CAE) by using data\naugmentation, thereby inducing homogeneity (equivariance to scalar gain) and\nadditivity (the decoder preserves addition) without altering the model's\narchitecture or loss function. When trained with our method, the CAE exhibits\nlinear behavior in both the encoder and decoder while preserving reconstruction\nfidelity. We test the practical utility of our learned space on music source\ncomposition and separation via simple latent arithmetic. This work presents a\nstraightforward technique for constructing structured latent spaces, enabling\nmore intuitive and efficient audio processing.",
      "pdf_url": "http://arxiv.org/pdf/2510.23530v1",
      "published": "2025-10-27T17:08:27+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.23530v1",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ]
    },
    {
      "title": "Toward Carbon-Neutral Human AI: Rethinking Data, Computation, and Learning Paradigms for Sustainable Intelligence",
      "authors": [
        "KC Santosh",
        "Rodrigue Rizk",
        "Longwei Wang"
      ],
      "abstract": "The rapid advancement of Artificial Intelligence (AI) has led to\nunprecedented computational demands, raising significant environmental and\nethical concerns. This paper critiques the prevailing reliance on large-scale,\nstatic datasets and monolithic training paradigms, advocating for a shift\ntoward human-inspired, sustainable AI solutions. We introduce a novel\nframework, Human AI (HAI), which emphasizes incremental learning, carbon-aware\noptimization, and human-in-the-loop collaboration to enhance adaptability,\nefficiency, and accountability. By drawing parallels with biological cognition\nand leveraging dynamic architectures, HAI seeks to balance performance with\necological responsibility. We detail the theoretical foundations, system\ndesign, and operational principles that enable AI to learn continuously and\ncontextually while minimizing carbon footprints and human annotation costs. Our\napproach addresses pressing challenges in active learning, continual\nadaptation, and energy-efficient model deployment, offering a pathway toward\nresponsible, human-centered artificial intelligence.",
      "pdf_url": "http://arxiv.org/pdf/2510.23524v1",
      "published": "2025-10-27T17:02:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.23524v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "A Deep Latent Factor Graph Clustering with Fairness-Utility Trade-off Perspective",
      "authors": [
        "Siamak Ghodsi",
        "Amjad Seyedi",
        "Tai Le Quy",
        "Fariba Karimi",
        "Eirini Ntoutsi"
      ],
      "abstract": "Fair graph clustering seeks partitions that respect network structure while\nmaintaining proportional representation across sensitive groups, with\napplications spanning community detection, team formation, resource allocation,\nand social network analysis. Many existing approaches enforce rigid constraints\nor rely on multi-stage pipelines (e.g., spectral embedding followed by\n$k$-means), limiting trade-off control, interpretability, and scalability. We\nintroduce \\emph{DFNMF}, an end-to-end deep nonnegative tri-factorization\ntailored to graphs that directly optimizes cluster assignments with a soft\nstatistical-parity regularizer. A single parameter $\\lambda$ tunes the\nfairness--utility balance, while nonnegativity yields parts-based factors and\ntransparent soft memberships. The optimization uses sparse-friendly alternating\nupdates and scales near-linearly with the number of edges. Across synthetic and\nreal networks, DFNMF achieves substantially higher group balance at comparable\nmodularity, often dominating state-of-the-art baselines on the Pareto front.\nThe code is available at https://github.com/SiamakGhodsi/DFNMF.git.",
      "pdf_url": "http://arxiv.org/pdf/2510.23507v1",
      "published": "2025-10-27T16:40:52+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.23507v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT",
        "math.IT"
      ]
    },
    {
      "title": "Emotion-Coherent Reasoning for Multimodal LLMs via Emotional Rationale Verifier",
      "authors": [
        "Hyeongseop Rha",
        "Jeong Hun Yeo",
        "Yeonju Kim",
        "Yong Man Ro"
      ],
      "abstract": "The recent advancement of Multimodal Large Language Models (MLLMs) is\ntransforming human-computer interaction (HCI) from surface-level exchanges into\nmore nuanced and emotionally intelligent communication. To realize this shift,\nemotion understanding becomes essential allowing systems to capture subtle cues\nunderlying user intent. Furthermore, providing faithful explanations for\npredicted emotions is crucial to ensure interpretability and build user trust.\nHowever, current MLLM-based methods often generate emotion explanations that\ndiverge from the target labels and sometimes even contradict their own\npredicted emotions. This inconsistency poses a critical risk for\nmisunderstanding and erodes reliability in interactive settings. To address\nthis, we propose a novel approach: the Emotional Rationale Verifier (ERV) and\nan Explanation Reward. Our method guides the model to produce reasoning that is\nexplicitly consistent with the target emotion during multimodal emotion\nrecognition without modifying the model architecture or requiring additional\npaired video-description annotations. Our method significantly improves\nfaithful explanation-prediction consistency and explanation emotion accuracy on\nthe MAFW and DFEW datasets. Through extensive experiments and human\nevaluations, we show that our approach not only enhances alignment between\nexplanation and prediction but also empowers MLLMs to deliver emotionally\ncoherent, trustworthy interactions, marking a key step toward truly human-like\nHCI systems.",
      "pdf_url": "http://arxiv.org/pdf/2510.23506v1",
      "published": "2025-10-27T16:40:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.23506v1",
      "categories": [
        "cs.AI",
        "cs.HC"
      ]
    },
    {
      "title": "Mixed Precision Training of Neural ODEs",
      "authors": [
        "Elena Celledoni",
        "Brynjulf Owren",
        "Lars Ruthotto",
        "Tianjiao Nicole Yang"
      ],
      "abstract": "Exploiting low-precision computations has become a standard strategy in deep\nlearning to address the growing computational costs imposed by ever larger\nmodels and datasets. However, naively performing all computations in low\nprecision can lead to roundoff errors and instabilities. Therefore, mixed\nprecision training schemes usually store the weights in high precision and use\nlow-precision computations only for whitelisted operations. Despite their\nsuccess, these principles are currently not reliable for training\ncontinuous-time architectures such as neural ordinary differential equations\n(Neural ODEs). This paper presents a mixed precision training framework for\nneural ODEs, combining explicit ODE solvers with a custom backpropagation\nscheme, and demonstrates its effectiveness across a range of learning tasks.\nOur scheme uses low-precision computations for evaluating the velocity,\nparameterized by the neural network, and for storing intermediate states, while\nstability is provided by a custom dynamic adjoint scaling and by accumulating\nthe solution and gradients in higher precision. These contributions address two\nkey challenges in training neural ODE: the computational cost of repeated\nnetwork evaluations and the growth of memory requirements with the number of\ntime steps or layers. Along with the paper, we publish our extendable,\nopen-source PyTorch package rampde, whose syntax resembles that of leading\npackages to provide a drop-in replacement in existing codes. We demonstrate the\nreliability and effectiveness of our scheme using challenging test cases and on\nneural ODE applications in image classification and generative models,\nachieving approximately 50% memory reduction and up to 2x speedup while\nmaintaining accuracy comparable to single-precision training.",
      "pdf_url": "http://arxiv.org/pdf/2510.23498v1",
      "published": "2025-10-27T16:32:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.23498v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NA",
        "math.NA",
        "68T07, 65L06, 65G50",
        "I.2; G.1"
      ]
    },
    {
      "title": "Are Agents Just Automata? On the Formal Equivalence Between Agentic AI and the Chomsky Hierarchy",
      "authors": [
        "Roham Koohestani",
        "Ziyou Li",
        "Anton Podkopaev",
        "Maliheh Izadi"
      ],
      "abstract": "This paper establishes a formal equivalence between the architectural classes\nof modern agentic AI systems and the abstract machines of the Chomsky\nhierarchy. We posit that the memory architecture of an AI agent is the\ndefinitive feature determining its computational power and that it directly\nmaps it to a corresponding class of automaton. Specifically, we demonstrate\nthat simple reflex agents are equivalent to Finite Automata, hierarchical\ntask-decomposition agents are equivalent to Pushdown Automata, and agents\nemploying readable/writable memory for reflection are equivalent to TMs. This\nAutomata-Agent Framework provides a principled methodology for right-sizing\nagent architectures to optimize computational efficiency and cost. More\ncritically, it creates a direct pathway to formal verification, enables the\napplication of mature techniques from automata theory to guarantee agent safety\nand predictability. By classifying agents, we can formally delineate the\nboundary between verifiable systems and those whose behavior is fundamentally\nundecidable. We address the inherent probabilistic nature of LLM-based agents\nby extending the framework to probabilistic automata that allow quantitative\nrisk analysis. The paper concludes by outlining an agenda for developing static\nanalysis tools and grammars for agentic frameworks.",
      "pdf_url": "http://arxiv.org/pdf/2510.23487v1",
      "published": "2025-10-27T16:22:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.23487v1",
      "categories": [
        "cs.AI",
        "cs.FL"
      ]
    },
    {
      "title": "On the Faithfulness of Visual Thinking: Measurement and Enhancement",
      "authors": [
        "Zujing Liu",
        "Junwen Pan",
        "Qi She",
        "Yuan Gao",
        "Guisong Xia"
      ],
      "abstract": "Recent large vision-language models (LVLMs) can generate vision-text\nmultimodal chain-of-thought (MCoT) traces after reinforcement fine-tuning\n(RFT). However, we observe that the visual information incorporated in MCoT is\noften inaccurate, though still yield correct answers, indicating a lack of\nfaithfulness in the MCoT reasoning process. We attribute this unfaithfulness to\nthe RL reward in RFT, which solely incentivizes the format of interleaved\nvision-text cues, ie, it encourages the model to incorporate visual information\ninto its text reasoning steps without considering the correctness of the visual\ninformation. In this paper, we first probe the faithfulness of MCoT by\nmeasuring how much the prediction changes when its visual and textual thoughts\nare intervened. Surprisingly, the model's predictions remain nearly unchanged\nunder visual intervention but change significantly under textual intervention,\nindicating that the visual evidence is largely ignored. To further analyze\nvisual information, we introduce an automated LVLM-based evaluation metric that\nquantifies the faithfulness of visual cues from two perspectives: reliability\nand sufficiency. Our evaluation reveals that the visual information in current\nMCoT traces is simultaneously unreliable and insufficient. To address this\nissue, we propose a novel MCoT learning strategy termed Sufficient-Component\nCause Model (SCCM) learning. This approach encourages the MCoT to generate\nsufficient yet minimal visual components that are independently capable of\nleading to correct answers. We note that the proposed SCCM is annotation-free\nand compatible with various RFT for MCoT in a plug-and-play manner. Empirical\nresults demonstrate that SCCM consistently improves the visual faithfulness\nacross a suite of fine-grained perception and reasoning benchmarks. Code is\navailable at https://github.com/EugeneLiu01/Faithful_Thinking_with_Image.",
      "pdf_url": "http://arxiv.org/pdf/2510.23482v1",
      "published": "2025-10-27T16:15:54+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.23482v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Human-AI Collaborative Uncertainty Quantification",
      "authors": [
        "Sima Noorani",
        "Shayan Kiyani",
        "George Pappas",
        "Hamed Hassani"
      ],
      "abstract": "AI predictive systems are increasingly embedded in decision making pipelines,\nshaping high stakes choices once made solely by humans. Yet robust decisions\nunder uncertainty still rely on capabilities that current AI lacks: domain\nknowledge not captured by data, long horizon context, and reasoning grounded in\nthe physical world. This gap has motivated growing efforts to design\ncollaborative frameworks that combine the complementary strengths of humans and\nAI. This work advances this vision by identifying the fundamental principles of\nHuman AI collaboration within uncertainty quantification, a key component of\nreliable decision making. We introduce Human AI Collaborative Uncertainty\nQuantification, a framework that formalizes how an AI model can refine a human\nexpert's proposed prediction set with two goals: avoiding counterfactual harm,\nensuring the AI does not degrade correct human judgments, and complementarity,\nenabling recovery of correct outcomes the human missed. At the population\nlevel, we show that the optimal collaborative prediction set follows an\nintuitive two threshold structure over a single score function, extending a\nclassical result in conformal prediction. Building on this insight, we develop\npractical offline and online calibration algorithms with provable distribution\nfree finite sample guarantees. The online method adapts to distribution shifts,\nincluding human behavior evolving through interaction with AI, a phenomenon we\ncall Human to AI Adaptation. Experiments across image classification,\nregression, and text based medical decision making show that collaborative\nprediction sets consistently outperform either agent alone, achieving higher\ncoverage and smaller set sizes across various conditions.",
      "pdf_url": "http://arxiv.org/pdf/2510.23476v1",
      "published": "2025-10-27T16:11:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.23476v1",
      "categories": [
        "cs.AI",
        "cs.HC",
        "stat.ML"
      ]
    },
    {
      "title": "Policy-Aware Generative AI for Safe, Auditable Data Access Governance",
      "authors": [
        "Shames Al Mandalawi",
        "Muzakkiruddin Ahmed Mohammed",
        "Hendrika Maclean",
        "Mert Can Cakmak",
        "John R. Talburt"
      ],
      "abstract": "Enterprises need access decisions that satisfy least privilege, comply with\nregulations, and remain auditable. We present a policy aware controller that\nuses a large language model (LLM) to interpret natural language requests\nagainst written policies and metadata, not raw data. The system, implemented\nwith Google Gemini~2.0 Flash, executes a six-stage reasoning framework (context\ninterpretation, user validation, data classification, business purpose test,\ncompliance mapping, and risk synthesis) with early hard policy gates and deny\nby default. It returns APPROVE, DENY, CONDITIONAL together with cited controls\nand a machine readable rationale. We evaluate on fourteen canonical cases\nacross seven scenario families using a privacy preserving benchmark. Results\nshow Exact Decision Match improving from 10/14 to 13/14 (92.9\\%) after applying\npolicy gates, DENY recall rising to 1.00, False Approval Rate on must-deny\nfamilies dropping to 0, and Functional Appropriateness and Compliance Adherence\nat 14/14. Expert ratings of rationale quality are high, and median latency is\nunder one minute. These findings indicate that policy constrained LLM\nreasoning, combined with explicit gates and audit trails, can translate human\nreadable policies into safe, compliant, and traceable machine decisions.",
      "pdf_url": "http://arxiv.org/pdf/2510.23474v1",
      "published": "2025-10-27T16:10:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.23474v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "BBOPlace-Bench: Benchmarking Black-Box Optimization for Chip Placement",
      "authors": [
        "Ke Xue",
        "Ruo-Tong Chen",
        "Rong-Xi Tan",
        "Xi Lin",
        "Yunqi Shi",
        "Siyuan Xu",
        "Mingxuan Yuan",
        "Chao Qian"
      ],
      "abstract": "Chip placement is a vital stage in modern chip design as it has a substantial\nimpact on the subsequent processes and the overall quality of the final chip.\nThe use of black-box optimization (BBO) for chip placement has a history of\nseveral decades. However, early efforts were limited by immature problem\nformulations and inefficient algorithm designs. Recent progress has shown the\neffectiveness and efficiency of BBO for chip placement, proving its potential\nto achieve state-of-the-art results. Despite these advancements, the field\nlacks a unified, BBO-specific benchmark for thoroughly assessing various\nproblem formulations and BBO algorithms. To fill this gap, we propose\nBBOPlace-Bench, the first benchmark designed specifically for evaluating and\ndeveloping BBO algorithms for chip placement tasks. It integrates three problem\nformulations of BBO for chip placement, and offers a modular, decoupled, and\nflexible framework that enables users to seamlessly implement, test, and\ncompare their own algorithms. BBOPlace-Bench integrates a wide variety of\nexisting BBO algorithms, including simulated annealing (SA), evolutionary\nalgorithms (EAs), and Bayesian optimization (BO). Experimental results show\nthat the problem formulations of mask-guided optimization and hyperparameter\noptimization exhibit superior performance than the sequence pair problem\nformulation, while EAs demonstrate better overall performance than SA and BO,\nespecially in high-dimensional search spaces, and also achieve state-of-the-art\nperformance compared to the mainstream chip placement methods. BBOPlace-Bench\nnot only facilitates the development of efficient BBO-driven solutions for chip\nplacement but also broadens the practical application scenarios (which are\nurgently needed) for the BBO community. The code of BBOPlace-Bench is available\nat https://github.com/lamda-bbo/BBOPlace-Bench.",
      "pdf_url": "http://arxiv.org/pdf/2510.23472v1",
      "published": "2025-10-27T16:10:32+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.23472v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.AR",
        "cs.NE"
      ]
    },
    {
      "title": "Robust Decision Making with Partially Calibrated Forecasts",
      "authors": [
        "Shayan Kiyani",
        "Hamed Hassani",
        "George Pappas",
        "Aaron Roth"
      ],
      "abstract": "Calibration has emerged as a foundational goal in ``trustworthy machine\nlearning'', in part because of its strong decision theoretic semantics.\nIndependent of the underlying distribution, and independent of the decision\nmaker's utility function, calibration promises that amongst all policies\nmapping predictions to actions, the uniformly best policy is the one that\n``trusts the predictions'' and acts as if they were correct. But this is true\nonly of \\emph{fully calibrated} forecasts, which are tractable to guarantee\nonly for very low dimensional prediction problems. For higher dimensional\nprediction problems (e.g. when outcomes are multiclass), weaker forms of\ncalibration have been studied that lack these decision theoretic properties. In\nthis paper we study how a conservative decision maker should map predictions\nendowed with these weaker (``partial'') calibration guarantees to actions, in a\nway that is robust in a minimax sense: i.e. to maximize their expected utility\nin the worst case over distributions consistent with the calibration\nguarantees. We characterize their minimax optimal decision rule via a duality\nargument, and show that surprisingly, ``trusting the predictions and acting\naccordingly'' is recovered in this minimax sense by \\emph{decision calibration}\n(and any strictly stronger notion of calibration), a substantially weaker and\nmore tractable condition than full calibration. For calibration guarantees that\nfall short of decision calibration, the minimax optimal decision rule is still\nefficiently computable, and we provide an empirical evaluation of a natural one\nthat applies to any regression model solved to optimize squared error.",
      "pdf_url": "http://arxiv.org/pdf/2510.23471v1",
      "published": "2025-10-27T16:09:07+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.23471v1",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Evaluating Large Language Models for Stance Detection on Financial Targets from SEC Filing Reports and Earnings Call Transcripts",
      "authors": [
        "Nikesh Gyawali",
        "Doina Caragea",
        "Alex Vasenkov",
        "Cornelia Caragea"
      ],
      "abstract": "Financial narratives from U.S. Securities and Exchange Commission (SEC)\nfiling reports and quarterly earnings call transcripts (ECTs) are very\nimportant for investors, auditors, and regulators. However, their length,\nfinancial jargon, and nuanced language make fine-grained analysis difficult.\nPrior sentiment analysis in the financial domain required a large, expensive\nlabeled dataset, making the sentence-level stance towards specific financial\ntargets challenging. In this work, we introduce a sentence-level corpus for\nstance detection focused on three core financial metrics: debt, earnings per\nshare (EPS), and sales. The sentences were extracted from Form 10-K annual\nreports and ECTs, and labeled for stance (positive, negative, neutral) using\nthe advanced ChatGPT-o3-pro model under rigorous human validation. Using this\ncorpus, we conduct a systematic evaluation of modern large language models\n(LLMs) using zero-shot, few-shot, and Chain-of-Thought (CoT) prompting\nstrategies. Our results show that few-shot with CoT prompting performs best\ncompared to supervised baselines, and LLMs' performance varies across the SEC\nand ECT datasets. Our findings highlight the practical viability of leveraging\nLLMs for target-specific stance in the financial domain without requiring\nextensive labeled data.",
      "pdf_url": "http://arxiv.org/pdf/2510.23464v1",
      "published": "2025-10-27T16:03:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.23464v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "BrowseConf: Confidence-Guided Test-Time Scaling for Web Agents",
      "authors": [
        "Litu Ou",
        "Kuan Li",
        "Huifeng Yin",
        "Liwen Zhang",
        "Zhongwang Zhang",
        "Xixi Wu",
        "Rui Ye",
        "Zile Qiao",
        "Yong Jiang",
        "Pengjun Xie",
        "Fei Huang",
        "Jingren Zhou"
      ],
      "abstract": "Confidence in LLMs is a useful indicator of model uncertainty and answer\nreliability. Existing work mainly focused on single-turn scenarios, while\nresearch on confidence in complex multi-turn interactions is limited. In this\npaper, we investigate whether LLM-based search agents have the ability to\ncommunicate their own confidence through verbalized confidence scores after\nlong sequences of actions, a significantly more challenging task compared to\noutputting confidence in a single interaction. Experimenting on open-source\nagentic models, we first find that models exhibit much higher task accuracy at\nhigh confidence while having near-zero accuracy when confidence is low. Based\non this observation, we propose Test-Time Scaling (TTS) methods that use\nconfidence scores to determine answer quality, encourage the model to try again\nuntil reaching a satisfactory confidence level. Results show that our proposed\nmethods significantly reduce token consumption while demonstrating competitive\nperformance compared to baseline fixed budget TTS methods.",
      "pdf_url": "http://arxiv.org/pdf/2510.23458v1",
      "published": "2025-10-27T15:58:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.23458v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "What are the odds? Risk and uncertainty about AI existential risk",
      "authors": [
        "Marco Grossi"
      ],
      "abstract": "This work is a commentary of the article\n\\href{https://doi.org/10.18716/ojs/phai/2025.2801}{AI Survival Stories: a\nTaxonomic Analysis of AI Existential Risk} by Cappelen, Goldstein, and\nHawthorne. It is not just a commentary though, but a useful reminder of the\nphilosophical limitations of \\say{linear} models of risk. The article will\nfocus on the model employed by the authors: first, I discuss some differences\nbetween standard Swiss Cheese models and this one. I then argue that in a\nsituation of epistemic indifference the probability of P(D) is higher than what\none might first suggest, given the structural relationships between layers. I\nthen distinguish between risk and uncertainty, and argue that any estimation of\nP(D) is structurally affected by two kinds of uncertainty: option uncertainty\nand state-space uncertainty. Incorporating these dimensions of uncertainty into\nour qualitative discussion on AI existential risk can provide a better\nunderstanding of the likeliness of P(D).",
      "pdf_url": "http://arxiv.org/pdf/2510.23453v1",
      "published": "2025-10-27T15:53:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.23453v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Omni-Reward: Towards Generalist Omni-Modal Reward Modeling with Free-Form Preferences",
      "authors": [
        "Zhuoran Jin",
        "Hongbang Yuan",
        "Kejian Zhu",
        "Jiachun Li",
        "Pengfei Cao",
        "Yubo Chen",
        "Kang Liu",
        "Jun Zhao"
      ],
      "abstract": "Reward models (RMs) play a critical role in aligning AI behaviors with human\npreferences, yet they face two fundamental challenges: (1) Modality Imbalance,\nwhere most RMs are mainly focused on text and image modalities, offering\nlimited support for video, audio, and other modalities; and (2) Preference\nRigidity, where training on fixed binary preference pairs fails to capture the\ncomplexity and diversity of personalized preferences. To address the above\nchallenges, we propose Omni-Reward, a step toward generalist omni-modal reward\nmodeling with support for free-form preferences, consisting of: (1) Evaluation:\nWe introduce Omni-RewardBench, the first omni-modal RM benchmark with free-form\npreferences, covering nine tasks across five modalities including text, image,\nvideo, audio, and 3D; (2) Data: We construct Omni-RewardData, a multimodal\npreference dataset comprising 248K general preference pairs and 69K\ninstruction-tuning pairs for training generalist omni-modal RMs; (3) Model: We\npropose Omni-RewardModel, which includes both discriminative and generative\nRMs, and achieves strong performance on Omni-RewardBench as well as other\nwidely used reward modeling benchmarks.",
      "pdf_url": "http://arxiv.org/pdf/2510.23451v1",
      "published": "2025-10-27T15:53:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.23451v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "FRBNet: Revisiting Low-Light Vision through Frequency-Domain Radial Basis Network",
      "authors": [
        "Fangtong Sun",
        "Congyu Li",
        "Ke Yang",
        "Yuchen Pan",
        "Hanwen Yu",
        "Xichuan Zhang",
        "Yiying Li"
      ],
      "abstract": "Low-light vision remains a fundamental challenge in computer vision due to\nsevere illumination degradation, which significantly affects the performance of\ndownstream tasks such as detection and segmentation. While recent\nstate-of-the-art methods have improved performance through invariant feature\nlearning modules, they still fall short due to incomplete modeling of low-light\nconditions. Therefore, we revisit low-light image formation and extend the\nclassical Lambertian model to better characterize low-light conditions. By\nshifting our analysis to the frequency domain, we theoretically prove that the\nfrequency-domain channel ratio can be leveraged to extract\nillumination-invariant features via a structured filtering process. We then\npropose a novel and end-to-end trainable module named \\textbf{F}requency-domain\n\\textbf{R}adial \\textbf{B}asis \\textbf{Net}work (\\textbf{FRBNet}), which\nintegrates the frequency-domain channel ratio operation with a learnable\nfrequency domain filter for the overall illumination-invariant feature\nenhancement. As a plug-and-play module, FRBNet can be integrated into existing\nnetworks for low-light downstream tasks without modifying loss functions.\nExtensive experiments across various downstream tasks demonstrate that FRBNet\nachieves superior performance, including +2.2 mAP for dark object detection and\n+2.9 mIoU for nighttime segmentation. Code is available at:\nhttps://github.com/Sing-Forevet/FRBNet.",
      "pdf_url": "http://arxiv.org/pdf/2510.23444v2",
      "published": "2025-10-27T15:46:07+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.23444v2",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "A Neuro-Symbolic Multi-Agent Approach to Legal-Cybersecurity Knowledge Integration",
      "authors": [
        "Chiara Bonfanti",
        "Alessandro Druetto",
        "Cataldo Basile",
        "Tharindu Ranasinghe",
        "Marcos Zampieri"
      ],
      "abstract": "The growing intersection of cybersecurity and law creates a complex\ninformation space where traditional legal research tools struggle to deal with\nnuanced connections between cases, statutes, and technical vulnerabilities.\nThis knowledge divide hinders collaboration between legal experts and\ncybersecurity professionals. To address this important gap, this work provides\na first step towards intelligent systems capable of navigating the increasingly\nintricate cyber-legal domain. We demonstrate promising initial results on\nmultilingual tasks.",
      "pdf_url": "http://arxiv.org/pdf/2510.23443v1",
      "published": "2025-10-27T15:46:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.23443v1",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CR",
        "cs.MA"
      ]
    },
    {
      "title": "Causal Deep Q Network",
      "authors": [
        "Elouanes Khelifi",
        "Amir Saki",
        "Usef Faghihi"
      ],
      "abstract": "Deep Q Networks (DQN) have shown remarkable success in various reinforcement\nlearning tasks. However, their reliance on associative learning often leads to\nthe acquisition of spurious correlations, hindering their problem-solving\ncapabilities. In this paper, we introduce a novel approach to integrate causal\nprinciples into DQNs, leveraging the PEACE (Probabilistic Easy vAriational\nCausal Effect) formula for estimating causal effects. By incorporating causal\nreasoning during training, our proposed framework enhances the DQN's\nunderstanding of the underlying causal structure of the environment, thereby\nmitigating the influence of confounding factors and spurious correlations. We\ndemonstrate that integrating DQNs with causal capabilities significantly\nenhances their problem-solving capabilities without compromising performance.\nExperimental results on standard benchmark environments showcase that our\napproach outperforms conventional DQNs, highlighting the effectiveness of\ncausal reasoning in reinforcement learning. Overall, our work presents a\npromising avenue for advancing the capabilities of deep reinforcement learning\nagents through principled causal inference.",
      "pdf_url": "http://arxiv.org/pdf/2510.23424v1",
      "published": "2025-10-27T15:28:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.23424v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Exploring Vulnerability in AI Industry",
      "authors": [
        "Claudio Pirrone",
        "Stefano Fricano",
        "Gioacchino Fazio"
      ],
      "abstract": "The rapid ascent of Foundation Models (FMs), enabled by the Transformer\narchitecture, drives the current AI ecosystem. Characterized by large-scale\ntraining and downstream adaptability, FMs (as GPT family) have achieved massive\npublic adoption, fueling a turbulent market shaped by platform economics and\nintense investment. Assessing the vulnerability of this fast-evolving industry\nis critical yet challenging due to data limitations. This paper proposes a\nsynthetic AI Vulnerability Index (AIVI) focusing on the upstream value chain\nfor FM production, prioritizing publicly available data. We model FM output as\na function of five inputs: Compute, Data, Talent, Capital, and Energy,\nhypothesizing that supply vulnerability in any input threatens the industry.\nKey vulnerabilities include compute concentration, data scarcity and legal\nrisks, talent bottlenecks, capital intensity and strategic dependencies, as\nwell as escalating energy demands. Acknowledging imperfect input\nsubstitutability, we propose a weighted geometrical average of aggregate\nsubindexes, normalized using theoretical or empirical benchmarks. Despite\nlimitations and room for improvement, this preliminary index aims to quantify\nsystemic risks in AI's core production engine, and implicitly shed a light on\nthe risks for downstream value chain.",
      "pdf_url": "http://arxiv.org/pdf/2510.23421v1",
      "published": "2025-10-27T15:26:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.23421v1",
      "categories": [
        "econ.GN",
        "cs.AI",
        "q-fin.EC"
      ]
    },
    {
      "title": "Bid2X: Revealing Dynamics of Bidding Environment in Online Advertising from A Foundation Model Lens",
      "authors": [
        "Jiahao Ji",
        "Tianyu Wang",
        "Yeshu Li",
        "Yushen Huo",
        "Zhilin Zhang",
        "Chuan Yu",
        "Jian Xu",
        "Bo Zheng"
      ],
      "abstract": "Auto-bidding is crucial in facilitating online advertising by automatically\nproviding bids for advertisers. While previous work has made great efforts to\nmodel bidding environments for better ad performance, it has limitations in\ngeneralizability across environments since these models are typically tailored\nfor specific bidding scenarios. To this end, we approach the\nscenario-independent principles through a unified function that estimates the\nachieved effect under specific bids, such as budget consumption, gross\nmerchandise volume (GMV), page views, etc. Then, we propose a bidding\nfoundation model Bid2X to learn this fundamental function from data in various\nscenarios. Our Bid2X is built over uniform series embeddings that encode\nheterogeneous data through tailored embedding methods. To capture complex\ninter-variable and dynamic temporal dependencies in bidding data, we propose\ntwo attention mechanisms separately treating embeddings of different variables\nand embeddings at different times as attention tokens for representation\nlearning. On top of the learned variable and temporal representations, a\nvariable-aware fusion module is used to perform adaptive bidding outcome\nprediction. To model the unique bidding data distribution, we devise a\nzero-inflated projection module to incorporate the estimated non-zero\nprobability into its value prediction, which makes up a joint optimization\nobjective containing classification and regression. The objective is proven to\nconverge to the zero-inflated distribution. Our model has been deployed on the\nad platform in Taobao, one of the world's largest e-commerce platforms. Offline\nevaluation on eight datasets exhibits Bid2X's superiority compared to various\nbaselines and its generality across different scenarios. Bid2X increased GMV by\n4.65% and ROI by 2.44% in online A/B tests, paving the way for bidding\nfoundation model in computational advertising.",
      "pdf_url": "http://arxiv.org/pdf/2510.23410v1",
      "published": "2025-10-27T15:15:01+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.23410v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Eigen-Value: Efficient Domain-Robust Data Valuation via Eigenvalue-Based Approach",
      "authors": [
        "Youngjun Choi",
        "Joonseong Kang",
        "Sungjun Lim",
        "Kyungwoo Song"
      ],
      "abstract": "Data valuation has become central in the era of data-centric AI. It drives\nefficient training pipelines and enables objective pricing in data markets by\nassigning a numeric value to each data point. Most existing data valuation\nmethods estimate the effect of removing individual data points by evaluating\nchanges in model validation performance under in-distribution (ID) settings, as\nopposed to out-of-distribution (OOD) scenarios where data follow different\npatterns. Since ID and OOD data behave differently, data valuation methods\nbased on ID loss often fail to generalize to OOD settings, particularly when\nthe validation set contains no OOD data. Furthermore, although OOD-aware\nmethods exist, they involve heavy computational costs, which hinder practical\ndeployment. To address these challenges, we introduce \\emph{Eigen-Value} (EV),\na plug-and-play data valuation framework for OOD robustness that uses only an\nID data subset, including during validation. EV provides a new spectral\napproximation of domain discrepancy, which is the gap of loss between ID and\nOOD using ratios of eigenvalues of ID data's covariance matrix. EV then\nestimates the marginal contribution of each data point to this discrepancy via\nperturbation theory, alleviating the computational burden. Subsequently, EV\nplugs into ID loss-based methods by adding an EV term without any additional\ntraining loop. We demonstrate that EV achieves improved OOD robustness and\nstable value rankings across real-world datasets, while remaining\ncomputationally lightweight. These results indicate that EV is practical for\nlarge-scale settings with domain shift, offering an efficient path to\nOOD-robust data valuation.",
      "pdf_url": "http://arxiv.org/pdf/2510.23409v2",
      "published": "2025-10-27T15:12:49+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.23409v2",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "AutoStreamPipe: LLM Assisted Automatic Generation of Data Stream Processing Pipelines",
      "authors": [
        "Abolfazl Younesi",
        "Zahra Najafabadi Samani",
        "Thomas Fahringer"
      ],
      "abstract": "Data pipelines are essential in stream processing as they enable the\nefficient collection, processing, and delivery of real-time data, supporting\nrapid data analysis. In this paper, we present AutoStreamPipe, a novel\nframework that employs Large Language Models (LLMs) to automate the design,\ngeneration, and deployment of stream processing pipelines. AutoStreamPipe\nbridges the semantic gap between high-level user intent and platform-specific\nimplementations across distributed stream processing systems for structured\nmulti-agent reasoning by integrating a Hypergraph of Thoughts (HGoT) as an\nextended version of GoT. AutoStreamPipe combines resilient execution\nstrategies, advanced query analysis, and HGoT to deliver pipelines with good\naccuracy. Experimental evaluations on diverse pipelines demonstrate that\nAutoStreamPipe significantly reduces development time (x6.3) and error rates\n(x5.19), as measured by a novel Error-Free Score (EFS), compared to LLM\ncode-generation methods.",
      "pdf_url": "http://arxiv.org/pdf/2510.23408v1",
      "published": "2025-10-27T15:11:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.23408v1",
      "categories": [
        "cs.AI",
        "cs.DC",
        "cs.ET",
        "cs.LG",
        "cs.MA"
      ]
    },
    {
      "title": "EMTSF:Extraordinary Mixture of SOTA Models for Time Series Forecasting",
      "authors": [
        "Musleh Alharthi",
        "Kaleel Mahmood",
        "Sarosh Patel",
        "Ausif Mahmood"
      ],
      "abstract": "The immense success of the Transformer architecture\n  in Natural Language Processing has led to its adoption in Time Se ries\nForecasting (TSF), where superior performance has been shown.\n  However, a recent important paper questioned their effectiveness by\n  demonstrating that a simple single layer linear model outperforms\n  Transformer-based models. This was soon shown to be not as valid,\n  by a better transformer-based model termed PatchTST. More re cently, TimeLLM\ndemonstrated even better results by repurposing a\n  Large Language Model (LLM) for the TSF domain. Again, a follow\n  up paper challenged this by demonstrating that removing the LLM\n  component or replacing it with a basic attention layer in fact yields\n  better performance. One of the challenges in forecasting is the fact\n  that TSF data favors the more recent past, and is sometimes subject\n  to unpredictable events. Based upon these recent insights in TSF, we\n  propose a strong Mixture of Experts (MoE) framework. Our method\n  combines the state-of-the-art (SOTA) models including xLSTM, en hanced\nLinear, PatchTST, and minGRU, among others. This set of\n  complimentary and diverse models for TSF are integrated in a Trans former\nbased MoE gating network. Our proposed model outperforms\n  all existing TSF models on standard benchmarks, surpassing even the\n  latest approaches based on MoE frameworks.",
      "pdf_url": "http://arxiv.org/pdf/2510.23396v1",
      "published": "2025-10-27T14:55:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.23396v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Detecting Religious Language in Climate Discourse",
      "authors": [
        "Evy Beijen",
        "Pien Pieterse",
        "Yusuf Çelik",
        "Willem Th. van Peursen",
        "Sandjai Bhulai",
        "Meike Morren"
      ],
      "abstract": "Religious language continues to permeate contemporary discourse, even in\nostensibly secular domains such as environmental activism and climate change\ndebates. This paper investigates how explicit and implicit forms of religious\nlanguage appear in climate-related texts produced by secular and religious\nnongovernmental organizations (NGOs). We introduce a dual methodological\napproach: a rule-based model using a hierarchical tree of religious terms\nderived from ecotheology literature, and large language models (LLMs) operating\nin a zero-shot setting. Using a dataset of more than 880,000 sentences, we\ncompare how these methods detect religious language and analyze points of\nagreement and divergence. The results show that the rule-based method\nconsistently labels more sentences as religious than LLMs. These findings\nhighlight not only the methodological challenges of computationally detecting\nreligious language but also the broader tension over whether religious language\nshould be defined by vocabulary alone or by contextual meaning. This study\ncontributes to digital methods in religious studies by demonstrating both the\npotential and the limitations of approaches for analyzing how the sacred\npersists in climate discourse.",
      "pdf_url": "http://arxiv.org/pdf/2510.23395v1",
      "published": "2025-10-27T14:54:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.23395v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Opinion Mining Based Entity Ranking using Fuzzy Logic Algorithmic Approach",
      "authors": [
        "Pratik N. Kalamkar",
        "A. G. Phakatkar"
      ],
      "abstract": "Opinions are central to almost all human activities and are key influencers\nof our behaviors. In current times due to growth of social networking website\nand increase in number of e-commerce site huge amount of opinions are now\navailable on web. Given a set of evaluative statements that contain opinions\n(or sentiments) about an Entity, opinion mining aims to extract attributes and\ncomponents of the object that have been commented on in each statement and to\ndetermine whether the comments are positive, negative or neutral. While lot of\nresearch recently has been done in field of opinion mining and some of it\ndealing with ranking of entities based on review or opinion set, classifying\nopinions into finer granularity level and then ranking entities has never been\ndone before. In this paper method for opinion mining from statements at a\ndeeper level of granularity is proposed. This is done by using fuzzy logic\nreasoning, after which entities are ranked as per this information.",
      "pdf_url": "http://arxiv.org/pdf/2510.23384v1",
      "published": "2025-10-27T14:35:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.23384v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Symbolic Neural Generation with Applications to Lead Discovery in Drug Design",
      "authors": [
        "Ashwin Srinivasan",
        "A Baskar",
        "Tirtharaj Dash",
        "Michael Bain",
        "Sanjay Kumar Dey",
        "Mainak Banerjee"
      ],
      "abstract": "We investigate a relatively underexplored class of hybrid neurosymbolic\nmodels integrating symbolic learning with neural reasoning to construct data\ngenerators meeting formal correctness criteria. In \\textit{Symbolic Neural\nGenerators} (SNGs), symbolic learners examine logical specifications of\nfeasible data from a small set of instances -- sometimes just one. Each\nspecification in turn constrains the conditional information supplied to a\nneural-based generator, which rejects any instance violating the symbolic\nspecification. Like other neurosymbolic approaches, SNG exploits the\ncomplementary strengths of symbolic and neural methods. The outcome of an SNG\nis a triple $(H, X, W)$, where $H$ is a symbolic description of feasible\ninstances constructed from data, $X$ a set of generated new instances that\nsatisfy the description, and $W$ an associated weight. We introduce a semantics\nfor such systems, based on the construction of appropriate \\textit{base} and\n\\textit{fibre} partially-ordered sets combined into an overall partial order,\nand outline a probabilistic extension relevant to practical applications. In\nthis extension, SNGs result from searching over a weighted partial ordering. We\nimplement an SNG combining a restricted form of Inductive Logic Programming\n(ILP) with a large language model (LLM) and evaluate it on early-stage drug\ndesign. Our main interest is the description and the set of potential inhibitor\nmolecules generated by the SNG. On benchmark problems -- where drug targets are\nwell understood -- SNG performance is statistically comparable to\nstate-of-the-art methods. On exploratory problems with poorly understood\ntargets, generated molecules exhibit binding affinities on par with leading\nclinical candidates. Experts further find the symbolic specifications useful as\npreliminary filters, with several generated molecules identified as viable for\nsynthesis and wet-lab testing.",
      "pdf_url": "http://arxiv.org/pdf/2510.23379v1",
      "published": "2025-10-27T14:29:22+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.23379v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE",
        "q-bio.BM",
        "I.2.6; I.2.1; J.3"
      ]
    },
    {
      "title": "ZeroFlood: A Geospatial Foundation Model for Data-Efficient Flood Susceptibility Mapping",
      "authors": [
        "Hyeongkyun Kim",
        "Orestis Oikonomou"
      ],
      "abstract": "Flood susceptibility mapping (FSM) is vital for disaster prevention but\nremains challenging in data-scarce regions where hydrodynamic models require\ndense geophysical inputs. This work introduces ZeroFlood, a geospatial\nfoundation model framework for data-efficient FSM. The approach fine-tunes\nGeospatial Foundation Models (GFMs) with Thinking-in-Modality (TiM) reasoning,\nenabling flood prediction from basic Earth observation data such as Sentinel-1\nor Sentinel-2 imagery. Using paired EO and simulated flood maps from data-rich\nregions, ZeroFlood bridges data availability gaps through cross-modal\nrepresentation learning. Experiments with TerraMind and Prithvi GFMs show that\nTiM enhances model robustness, with the TerraMind-Large configuration achieving\nan F1 score of 67.21. The results demonstrate the feasibility of\nfoundation-model-based FSM as a scalable and data-efficient solution for flood\nrisk management.",
      "pdf_url": "http://arxiv.org/pdf/2510.23364v1",
      "published": "2025-10-27T14:14:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.23364v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Planning Ahead with RSA: Efficient Signalling in Dynamic Environments by Projecting User Awareness across Future Timesteps",
      "authors": [
        "Anwesha Das",
        "John Duff",
        "Jörg Hoffmann",
        "Vera Demberg"
      ],
      "abstract": "Adaptive agent design offers a way to improve human-AI collaboration on\ntime-sensitive tasks in rapidly changing environments. In such cases, to ensure\nthe human maintains an accurate understanding of critical task elements, an\nassistive agent must not only identify the highest priority information but\nalso estimate how and when this information can be communicated most\neffectively, given that human attention represents a zero-sum cognitive\nresource where focus on one message diminishes awareness of other or upcoming\ninformation. We introduce a theoretical framework for adaptive signalling which\nmeets these challenges by using principles of rational communication,\nformalised as Bayesian reference resolution using the Rational Speech Act (RSA)\nmodelling framework, to plan a sequence of messages which optimise timely\nalignment between user belief and a dynamic environment. The agent adapts\nmessage specificity and timing to the particulars of a user and scenario based\non projections of how prior-guided interpretation of messages will influence\nattention to the interface and subsequent belief update, across several\ntimesteps out to a fixed horizon. In a comparison to baseline methods, we show\nthat this effectiveness depends crucially on combining multi-step planning with\na realistic model of user awareness. As the first application of RSA for\ncommunication in a dynamic environment, and for human-AI interaction in\ngeneral, we establish theoretical foundations for pragmatic communication in\nhuman-agent teams, highlighting how insights from cognitive science can be\ncapitalised to inform the design of assistive agents.",
      "pdf_url": "http://arxiv.org/pdf/2510.23340v1",
      "published": "2025-10-27T13:54:54+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.23340v1",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ]
    },
    {
      "title": "Multitask Multimodal Self-Supervised Learning for Medical Images",
      "authors": [
        "Cristian Simionescu"
      ],
      "abstract": "This thesis works to address a pivotal challenge in medical image analysis:\nthe reliance on extensive labeled datasets, which are often limited due to the\nneed for expert annotation and constrained by privacy and legal issues. By\nfocusing on the development of self-supervised learning techniques and domain\nadaptation methods, this research aims to circumvent these limitations,\npresenting a novel approach to enhance the utility and efficacy of deep\nlearning in medical imaging.\n  Central to this thesis is the development of the Medformer, an innovative\nneural network architecture designed for multitask learning and deep domain\nadaptation. This model is adept at pre-training on diverse medical image\ndatasets, handling varying sizes and modalities, and is equipped with a dynamic\ninput-output adaptation mechanism. This enables efficient processing and\nintegration of a wide range of medical image types, from 2D X-rays to complex\n3D MRIs, thus mitigating the dependency on large labeled datasets.\n  Further, the thesis explores the current state of self-supervised learning in\nmedical imaging. It introduces novel pretext tasks that are capable of\nextracting meaningful information from unlabeled data, significantly advancing\nthe model's interpretative abilities. This approach is validated through\nrigorous experimentation, including the use of the MedMNIST dataset,\ndemonstrating the model's proficiency in learning generalized features\napplicable to various downstream tasks.\n  In summary, this thesis contributes to the advancement of medical image\nanalysis by offering a scalable, adaptable framework that reduces reliance on\nlabeled data. It paves the way for more accurate, efficient diagnostic tools in\nhealthcare, signifying a major step forward in the application of deep learning\nin medical imaging.",
      "pdf_url": "http://arxiv.org/pdf/2510.23325v1",
      "published": "2025-10-27T13:42:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.23325v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Arabic Little STT: Arabic Children Speech Recognition Dataset",
      "authors": [
        "Mouhand Alkadri",
        "Dania Desouki",
        "Khloud Al Jallad"
      ],
      "abstract": "The performance of Artificial Intelligence (AI) systems fundamentally depends\non high-quality training data. However, low-resource languages like Arabic\nsuffer from severe data scarcity. Moreover, the absence of child-specific\nspeech corpora is an essential gap that poses significant challenges. To\naddress this gap, we present our created dataset, Arabic Little STT, a dataset\nof Levantine Arabic child speech recorded in classrooms, containing 355\nutterances from 288 children (ages 6 - 13). We further conduct a systematic\nassessment of Whisper, a state-of-the-art automatic speech recognition (ASR)\nmodel, on this dataset and compare its performance with adult Arabic\nbenchmarks. Our evaluation across eight Whisper variants reveals that even the\nbest-performing model (Large_v3) struggles significantly, achieving a 0.66 word\nerror rate (WER) on child speech, starkly contrasting with its sub 0.20 WER on\nadult datasets. These results align with other research on English speech.\nResults highlight the critical need for dedicated child speech benchmarks and\ninclusive training data in ASR development. Emphasizing that such data must be\ngoverned by strict ethical and privacy frameworks to protect sensitive child\ninformation. We hope that this study provides an initial step for future work\non equitable speech technologies for Arabic-speaking children. We hope that our\npublicly available dataset enrich the children's demographic representation in\nASR datasets.",
      "pdf_url": "http://arxiv.org/pdf/2510.23319v1",
      "published": "2025-10-27T13:30:54+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.23319v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.LG",
        "cs.SD"
      ]
    },
    {
      "title": "ReconViaGen: Towards Accurate Multi-view 3D Object Reconstruction via Generation",
      "authors": [
        "Jiahao Chang",
        "Chongjie Ye",
        "Yushuang Wu",
        "Yuantao Chen",
        "Yidan Zhang",
        "Zhongjin Luo",
        "Chenghong Li",
        "Yihao Zhi",
        "Xiaoguang Han"
      ],
      "abstract": "Existing multi-view 3D object reconstruction methods heavily rely on\nsufficient overlap between input views, where occlusions and sparse coverage in\npractice frequently yield severe reconstruction incompleteness. Recent\nadvancements in diffusion-based 3D generative techniques offer the potential to\naddress these limitations by leveraging learned generative priors to\nhallucinate invisible parts of objects, thereby generating plausible 3D\nstructures. However, the stochastic nature of the inference process limits the\naccuracy and reliability of generation results, preventing existing\nreconstruction frameworks from integrating such 3D generative priors. In this\nwork, we comprehensively analyze the reasons why diffusion-based 3D generative\nmethods fail to achieve high consistency, including (a) the insufficiency in\nconstructing and leveraging cross-view connections when extracting multi-view\nimage features as conditions, and (b) the poor controllability of iterative\ndenoising during local detail generation, which easily leads to plausible but\ninconsistent fine geometric and texture details with inputs. Accordingly, we\npropose ReconViaGen to innovatively integrate reconstruction priors into the\ngenerative framework and devise several strategies that effectively address\nthese issues. Extensive experiments demonstrate that our ReconViaGen can\nreconstruct complete and accurate 3D models consistent with input views in both\nglobal structure and local details.Project page:\nhttps://jiahao620.github.io/reconviagen.",
      "pdf_url": "http://arxiv.org/pdf/2510.23306v1",
      "published": "2025-10-27T13:15:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.23306v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "CNOT Minimal Circuit Synthesis: A Reinforcement Learning Approach",
      "authors": [
        "Riccardo Romanello",
        "Daniele Lizzio Bosco",
        "Jacopo Cossio",
        "Dusan Sutulovic",
        "Giuseppe Serra",
        "Carla Piazza",
        "Paolo Burelli"
      ],
      "abstract": "CNOT gates are fundamental to quantum computing, as they facilitate\nentanglement, a crucial resource for quantum algorithms. Certain classes of\nquantum circuits are constructed exclusively from CNOT gates. Given their\nwidespread use, it is imperative to minimise the number of CNOT gates employed.\nThis problem, known as CNOT minimisation, remains an open challenge, with its\ncomputational complexity yet to be fully characterised. In this work, we\nintroduce a novel reinforcement learning approach to address this task. Instead\nof training multiple reinforcement learning agents for different circuit sizes,\nwe use a single agent up to a fixed size $m$. Matrices of sizes different from\nm are preprocessed using either embedding or Gaussian striping. To assess the\nefficacy of our approach, we trained an agent with m = 8, and evaluated it on\nmatrices of size n that range from 3 to 15. The results we obtained show that\nour method overperforms the state-of-the-art algorithm as the value of n\nincreases.",
      "pdf_url": "http://arxiv.org/pdf/2510.23304v1",
      "published": "2025-10-27T13:13:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.23304v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "A Novel Framework for Multi-Modal Protein Representation Learning",
      "authors": [
        "Runjie Zheng",
        "Zhen Wang",
        "Anjie Qiao",
        "Jiancong Xie",
        "Jiahua Rao",
        "Yuedong Yang"
      ],
      "abstract": "Accurate protein function prediction requires integrating heterogeneous\nintrinsic signals (e.g., sequence and structure) with noisy extrinsic contexts\n(e.g., protein-protein interactions and GO term annotations). However, two key\nchallenges hinder effective fusion: (i) cross-modal distributional mismatch\namong embeddings produced by pre-trained intrinsic encoders, and (ii) noisy\nrelational graphs of extrinsic data that degrade GNN-based information\naggregation. We propose Diffused and Aligned Multi-modal Protein Embedding\n(DAMPE), a unified framework that addresses these through two core mechanisms.\nFirst, we propose Optimal Transport (OT)-based representation alignment that\nestablishes correspondence between intrinsic embedding spaces of different\nmodalities, effectively mitigating cross-modal heterogeneity. Second, we\ndevelop a Conditional Graph Generation (CGG)-based information fusion method,\nwhere a condition encoder fuses the aligned intrinsic embeddings to provide\ninformative cues for graph reconstruction. Meanwhile, our theoretical analysis\nimplies that the CGG objective drives this condition encoder to absorb\ngraph-aware knowledge into its produced protein representations. Empirically,\nDAMPE outperforms or matches state-of-the-art methods such as DPFunc on\nstandard GO benchmarks, achieving AUPR gains of 0.002-0.013 pp and Fmax gains\n0.004-0.007 pp. Ablation studies further show that OT-based alignment\ncontributes 0.043-0.064 pp AUPR, while CGG-based fusion adds 0.005-0.111 pp\nFmax. Overall, DAMPE offers a scalable and theoretically grounded approach for\nrobust multi-modal protein representation learning, substantially enhancing\nprotein function prediction.",
      "pdf_url": "http://arxiv.org/pdf/2510.23273v1",
      "published": "2025-10-27T12:33:01+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.23273v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ]
    },
    {
      "title": "PAHQ: Accelerating Automated Circuit Discovery through Mixed-Precision Inference Optimization",
      "authors": [
        "Xinhai Wang",
        "Shu Yang",
        "Liangyu Wang",
        "Lin Zhang",
        "Huanyi Xie",
        "Lijie Hu",
        "Di Wang"
      ],
      "abstract": "Circuit discovery, which involves identifying sparse and task-relevant\nsubnetworks in pre-trained language models, is a cornerstone of mechanistic\ninterpretability. Automated Circuit Discovery (ACDC) has emerged as a pivotal\nmethodology in circuit discovery, but its application to large language models\nis severely limited by computational inefficiency and prohibitively high memory\nrequirements. Although several accelerated approaches have been proposed, they\nprimarily rely on linear approximations to ACDC, which significantly\ncompromises analytical faithfulness. Our proposed method for accelerating\nautomated circuit discovery, Per Attention Head Quantization (PAHQ), takes a\nfundamentally different approach by optimizing the efficiency of each\nindividual patching operation. PAHQ leverages a fundamental alignment between\nactivation patching and mixed-precision quantization (MPQ): interpretability\nanalysis through patching essentially performs targeted ablation studies.\nTherefore, we can maintain high precision exclusively for investigated\ncomponents while safely reducing precision elsewhere in the network.\nPAHQ-accelerated ACDC reduces runtime by up to 80\\% and memory consumption by\nup to 30\\% compared to unaccelerated ACDC while maintaining faithfulness.\nImportantly, our method readily integrates with existing edge-based circuit\ndiscovery techniques by modifying the attention computation mechanism. This\ntraining-free approach provides a practical and novel pathway for accelerating\nmechanistic interpretability methods. Our code is available at\nhttps://github.com/626619403/PAHQ.",
      "pdf_url": "http://arxiv.org/pdf/2510.23264v1",
      "published": "2025-10-27T12:24:14+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.23264v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Deep Active Inference with Diffusion Policy and Multiple Timescale World Model for Real-World Exploration and Navigation",
      "authors": [
        "Riko Yokozawa",
        "Kentaro Fujii",
        "Yuta Nomura",
        "Shingo Murata"
      ],
      "abstract": "Autonomous robotic navigation in real-world environments requires exploration\nto acquire environmental information as well as goal-directed navigation in\norder to reach specified targets. Active inference (AIF) based on the\nfree-energy principle provides a unified framework for these behaviors by\nminimizing the expected free energy (EFE), thereby combining epistemic and\nextrinsic values. To realize this practically, we propose a deep AIF framework\nthat integrates a diffusion policy as the policy model and a multiple timescale\nrecurrent state-space model (MTRSSM) as the world model. The diffusion policy\ngenerates diverse candidate actions while the MTRSSM predicts their\nlong-horizon consequences through latent imagination, enabling action selection\nthat minimizes EFE. Real-world navigation experiments demonstrated that our\nframework achieved higher success rates and fewer collisions compared with the\nbaselines, particularly in exploration-demanding scenarios. These results\nhighlight how AIF based on EFE minimization can unify exploration and\ngoal-directed navigation in real-world robotic settings.",
      "pdf_url": "http://arxiv.org/pdf/2510.23258v1",
      "published": "2025-10-27T12:21:33+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.23258v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Progressive Growing of Patch Size: Curriculum Learning for Accelerated and Improved Medical Image Segmentation",
      "authors": [
        "Stefan M. Fischer",
        "Johannes Kiechle",
        "Laura Daza",
        "Lina Felsner",
        "Richard Osuala",
        "Daniel M. Lang",
        "Karim Lekadir",
        "Jan C. Peeken",
        "Julia A. Schnabel"
      ],
      "abstract": "In this work, we introduce Progressive Growing of Patch Size, an automatic\ncurriculum learning approach for 3D medical image segmentation. Our approach\nprogressively increases the patch size during model training, resulting in an\nimproved class balance for smaller patch sizes and accelerated convergence of\nthe training process. We evaluate our curriculum approach in two settings: a\nresource-efficient mode and a performance mode, both regarding Dice score\nperformance and computational costs across 15 diverse and popular 3D medical\nimage segmentation tasks. The resource-efficient mode matches the Dice score\nperformance of the conventional constant patch size sampling baseline with a\nnotable reduction in training time to only 44%. The performance mode improves\nupon constant patch size segmentation results, achieving a statistically\nsignificant relative mean performance gain of 1.28% in Dice Score. Remarkably,\nacross all 15 tasks, our proposed performance mode manages to surpass the\nconstant patch size baseline in Dice Score performance, while simultaneously\nreducing training time to only 89%. The benefits are particularly pronounced\nfor highly imbalanced tasks such as lesion segmentation tasks. Rigorous\nexperiments demonstrate that our performance mode not only improves mean\nsegmentation performance but also reduces performance variance, yielding more\ntrustworthy model comparison. Furthermore, our findings reveal that the\nproposed curriculum sampling is not tied to a specific architecture but\nrepresents a broadly applicable strategy that consistently boosts performance\nacross diverse segmentation models, including UNet, UNETR, and SwinUNETR. In\nsummary, we show that this simple yet elegant transformation on input data\nsubstantially improves both Dice Score performance and training runtime, while\nbeing compatible across diverse segmentation backbones.",
      "pdf_url": "http://arxiv.org/pdf/2510.23241v1",
      "published": "2025-10-27T11:55:12+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.23241v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Accelerating IC Thermal Simulation Data Generation via Block Krylov and Operator Action",
      "authors": [
        "Hong Wang",
        "Wenkai Yang",
        "Jie Wang",
        "Huanshuo Dong",
        "Zijie Geng",
        "Zhen Huang",
        "Depeng Xie",
        "Zhezheng Hao",
        "Hande Dong"
      ],
      "abstract": "Recent advances in data-driven approaches, such as neural operators (NOs),\nhave shown substantial efficacy in reducing the solution time for integrated\ncircuit (IC) thermal simulations. However, a limitation of these approaches is\nrequiring a large amount of high-fidelity training data, such as chip\nparameters and temperature distributions, thereby incurring significant\ncomputational costs. To address this challenge, we propose a novel algorithm\nfor the generation of IC thermal simulation data, named block Krylov and\noperator action (BlocKOA), which simultaneously accelerates the data generation\nprocess and enhances the precision of generated data. BlocKOA is specifically\ndesigned for IC applications. Initially, we use the block Krylov algorithm\nbased on the structure of the heat equation to quickly obtain a few basic\nsolutions. Then we combine them to get numerous temperature distributions that\nsatisfy the physical constraints. Finally, we apply heat operators on these\nfunctions to determine the heat source distributions, efficiently generating\nprecise data points. Theoretical analysis shows that the time complexity of\nBlocKOA is one order lower than the existing method. Experimental results\nfurther validate its efficiency, showing that BlocKOA achieves a 420-fold\nspeedup in generating thermal simulation data for 5000 chips with varying\nphysical parameters and IC structures. Even with just 4% of the generation\ntime, data-driven approaches trained on the data generated by BlocKOA exhibits\ncomparable performance to that using the existing method.",
      "pdf_url": "http://arxiv.org/pdf/2510.23221v1",
      "published": "2025-10-27T11:16:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.23221v1",
      "categories": [
        "cs.AI",
        "physics.comp-ph"
      ]
    }
  ]
}