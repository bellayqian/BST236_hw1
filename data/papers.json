{
  "last_updated": "2025-02-16T00:48:35.586528",
  "papers": [
    {
      "title": "Theoretical Benefit and Limitation of Diffusion Language Model",
      "authors": [
        "Guhao Feng",
        "Yihan Geng",
        "Jian Guan",
        "Wei Wu",
        "Liwei Wang",
        "Di He"
      ],
      "abstract": "Diffusion language models have emerged as a promising approach for text\ngeneration. One would naturally expect this method to be an efficient\nreplacement for autoregressive models since multiple tokens can be sampled in\nparallel during each diffusion step. However, its efficiency-accuracy trade-off\nis not yet well understood. In this paper, we present a rigorous theoretical\nanalysis of a widely used type of diffusion language model, the Masked\nDiffusion Model (MDM), and find that its effectiveness heavily depends on the\ntarget evaluation metric. Under mild conditions, we prove that when using\nperplexity as the metric, MDMs can achieve near-optimal perplexity in sampling\nsteps regardless of sequence length, demonstrating that efficiency can be\nachieved without sacrificing performance. However, when using the sequence\nerror rate--which is important for understanding the \"correctness\" of a\nsequence, such as a reasoning chain--we show that the required sampling steps\nmust scale linearly with sequence length to obtain \"correct\" sequences, thereby\neliminating MDM's efficiency advantage over autoregressive models. Our analysis\nestablishes the first theoretical foundation for understanding the benefits and\nlimitations of MDMs. All theoretical findings are supported by empirical\nstudies.",
      "pdf_url": "http://arxiv.org/pdf/2502.09622v1",
      "published": "2025-02-13T18:59:47+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.09622v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ]
    },
    {
      "title": "MME-CoT: Benchmarking Chain-of-Thought in Large Multimodal Models for Reasoning Quality, Robustness, and Efficiency",
      "authors": [
        "Dongzhi Jiang",
        "Renrui Zhang",
        "Ziyu Guo",
        "Yanwei Li",
        "Yu Qi",
        "Xinyan Chen",
        "Liuhui Wang",
        "Jianhan Jin",
        "Claire Guo",
        "Shen Yan",
        "Bo Zhang",
        "Chaoyou Fu",
        "Peng Gao",
        "Hongsheng Li"
      ],
      "abstract": "Answering questions with Chain-of-Thought (CoT) has significantly enhanced\nthe reasoning capabilities of Large Language Models (LLMs), yet its impact on\nLarge Multimodal Models (LMMs) still lacks a systematic assessment and in-depth\ninvestigation. In this paper, we introduce MME-CoT, a specialized benchmark\nevaluating the CoT reasoning performance of LMMs, spanning six domains: math,\nscience, OCR, logic, space-time, and general scenes. As the first comprehensive\nstudy in this area, we propose a thorough evaluation suite incorporating three\nnovel metrics that assess the reasoning quality, robustness, and efficiency at\na fine-grained level. Leveraging curated high-quality data and a unique\nevaluation strategy, we conduct an in-depth analysis of state-of-the-art LMMs,\nuncovering several key insights: 1) Models with reflection mechanism\ndemonstrate a superior CoT quality, with Kimi k1.5 outperforming GPT-4o and\ndemonstrating the highest quality results; 2) CoT prompting often degrades LMM\nperformance on perception-heavy tasks, suggesting a potentially harmful\noverthinking behavior; and 3) Although the CoT quality is high, LMMs with\nreflection exhibit significant inefficiency in both normal response and\nself-correction phases. We hope MME-CoT serves as a foundation for advancing\nmultimodal reasoning in LMMs. Project Page: https://mmecot.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2502.09621v1",
      "published": "2025-02-13T18:59:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.09621v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Exploring the Potential of Encoder-free Architectures in 3D LMMs",
      "authors": [
        "Yiwen Tang",
        "Zoey Guo",
        "Zhuhao Wang",
        "Ray Zhang",
        "Qizhi Chen",
        "Junli Liu",
        "Delin Qu",
        "Zhigang Wang",
        "Dong Wang",
        "Xuelong Li",
        "Bin Zhao"
      ],
      "abstract": "Encoder-free architectures have been preliminarily explored in the 2D visual\ndomain, yet it remains an open question whether they can be effectively applied\nto 3D understanding scenarios. In this paper, we present the first\ncomprehensive investigation into the potential of encoder-free architectures to\novercome the challenges of encoder-based 3D Large Multimodal Models (LMMs).\nThese challenges include the failure to adapt to varying point cloud\nresolutions and the point features from the encoder not meeting the semantic\nneeds of Large Language Models (LLMs). We identify key aspects for 3D LMMs to\nremove the encoder and enable the LLM to assume the role of the 3D encoder: 1)\nWe propose the LLM-embedded Semantic Encoding strategy in the pre-training\nstage, exploring the effects of various point cloud self-supervised losses. And\nwe present the Hybrid Semantic Loss to extract high-level semantics. 2) We\nintroduce the Hierarchical Geometry Aggregation strategy in the instruction\ntuning stage. This incorporates inductive bias into the LLM early layers to\nfocus on the local details of the point clouds. To the end, we present the\nfirst Encoder-free 3D LMM, ENEL. Our 7B model rivals the current\nstate-of-the-art model, ShapeLLM-13B, achieving 55.0%, 50.92%, and 42.7% on the\nclassification, captioning, and VQA tasks, respectively. Our results\ndemonstrate that the encoder-free architecture is highly promising for\nreplacing encoder-based architectures in the field of 3D understanding. The\ncode is released at https://github.com/Ivan-Tang-3D/ENEL",
      "pdf_url": "http://arxiv.org/pdf/2502.09620v1",
      "published": "2025-02-13T18:59:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.09620v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "DexTrack: Towards Generalizable Neural Tracking Control for Dexterous Manipulation from Human References",
      "authors": [
        "Xueyi Liu",
        "Jianibieke Adalibieke",
        "Qianwei Han",
        "Yuzhe Qin",
        "Li Yi"
      ],
      "abstract": "We address the challenge of developing a generalizable neural tracking\ncontroller for dexterous manipulation from human references. This controller\naims to manage a dexterous robot hand to manipulate diverse objects for various\npurposes defined by kinematic human-object interactions. Developing such a\ncontroller is complicated by the intricate contact dynamics of dexterous\nmanipulation and the need for adaptivity, generalizability, and robustness.\nCurrent reinforcement learning and trajectory optimization methods often fall\nshort due to their dependence on task-specific rewards or precise system\nmodels. We introduce an approach that curates large-scale successful robot\ntracking demonstrations, comprising pairs of human references and robot\nactions, to train a neural controller. Utilizing a data flywheel, we\niteratively enhance the controller's performance, as well as the number and\nquality of successful tracking demonstrations. We exploit available tracking\ndemonstrations and carefully integrate reinforcement learning and imitation\nlearning to boost the controller's performance in dynamic environments. At the\nsame time, to obtain high-quality tracking demonstrations, we individually\noptimize per-trajectory tracking by leveraging the learned tracking controller\nin a homotopy optimization method. The homotopy optimization, mimicking\nchain-of-thought, aids in solving challenging trajectory tracking problems to\nincrease demonstration diversity. We showcase our success by training a\ngeneralizable neural controller and evaluating it in both simulation and real\nworld. Our method achieves over a 10% improvement in success rates compared to\nleading baselines. The project website with animated results is available at\nhttps://meowuu7.github.io/DexTrack/.",
      "pdf_url": "http://arxiv.org/pdf/2502.09614v1",
      "published": "2025-02-13T18:59:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.09614v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ]
    },
    {
      "title": "Score-of-Mixture Training: Training One-Step Generative Models Made Simple",
      "authors": [
        "Tejas Jayashankar",
        "J. Jon Ryu",
        "Gregory Wornell"
      ],
      "abstract": "We propose Score-of-Mixture Training (SMT), a novel framework for training\none-step generative models by minimizing a class of divergences called the\n$\\alpha$-skew Jensen-Shannon divergence. At its core, SMT estimates the score\nof mixture distributions between real and fake samples across multiple noise\nlevels. Similar to consistency models, our approach supports both training from\nscratch (SMT) and distillation using a pretrained diffusion model, which we\ncall Score-of-Mixture Distillation (SMD). It is simple to implement, requires\nminimal hyperparameter tuning, and ensures stable training. Experiments on\nCIFAR-10 and ImageNet 64x64 show that SMT/SMD are competitive with and can even\noutperform existing methods.",
      "pdf_url": "http://arxiv.org/pdf/2502.09609v1",
      "published": "2025-02-13T18:57:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.09609v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Human-LLM Coevolution: Evidence from Academic Writing",
      "authors": [
        "Mingmeng Geng",
        "Roberto Trotta"
      ],
      "abstract": "With a statistical analysis of arXiv paper abstracts, we report a marked drop\nin the frequency of several words previously identified as overused by ChatGPT,\nsuch as \"delve\", starting soon after they were pointed out in early 2024. The\nfrequency of certain other words favored by ChatGPT, such as \"significant\", has\ninstead kept increasing. These phenomena suggest that some authors of academic\npapers have adapted their use of large language models (LLMs), for example, by\nselecting outputs or applying modifications to the LLM-generated content. Such\ncoevolution and cooperation of humans and LLMs thus introduce additional\nchallenges to the detection of machine-generated text in real-world scenarios.\nEstimating the impact of LLMs on academic writing by examining word frequency\nremains feasible, and more attention should be paid to words that were already\nfrequently employed, including those that have decreased in frequency.",
      "pdf_url": "http://arxiv.org/pdf/2502.09606v1",
      "published": "2025-02-13T18:55:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.09606v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.DL",
        "cs.LG"
      ]
    },
    {
      "title": "SelfCite: Self-Supervised Alignment for Context Attribution in Large Language Models",
      "authors": [
        "Yung-Sung Chuang",
        "Benjamin Cohen-Wang",
        "Shannon Zejiang Shen",
        "Zhaofeng Wu",
        "Hu Xu",
        "Xi Victoria Lin",
        "James Glass",
        "Shang-Wen Li",
        "Wen-tau Yih"
      ],
      "abstract": "We introduce SelfCite, a novel self-supervised approach that aligns LLMs to\ngenerate high-quality, fine-grained, sentence-level citations for the\nstatements in their generated responses. Instead of only relying on costly and\nlabor-intensive annotations, SelfCite leverages a reward signal provided by the\nLLM itself through context ablation: If a citation is necessary, removing the\ncited text from the context should prevent the same response; if sufficient,\nretaining the cited text alone should preserve the same response. This reward\ncan guide the inference-time best-of-N sampling strategy to improve citation\nquality significantly, as well as be used in preference optimization to\ndirectly fine-tune the models for generating better citations. The\neffectiveness of SelfCite is demonstrated by increasing citation F1 up to 5.3\npoints on the LongBench-Cite benchmark across five long-form question answering\ntasks.",
      "pdf_url": "http://arxiv.org/pdf/2502.09604v1",
      "published": "2025-02-13T18:55:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.09604v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "CoT-Valve: Length-Compressible Chain-of-Thought Tuning",
      "authors": [
        "Xinyin Ma",
        "Guangnian Wan",
        "Runpeng Yu",
        "Gongfan Fang",
        "Xinchao Wang"
      ],
      "abstract": "Chain-of-Thought significantly enhances a model's reasoning capability, but\nit also comes with a considerable increase in inference costs due to long\nchains. With the observation that the reasoning path can be easily compressed\nunder easy tasks but struggle on hard tasks, we explore the feasibility of\nelastically controlling the length of reasoning paths with only one model,\nthereby reducing the inference overhead of reasoning models dynamically based\non task difficulty. We introduce a new tuning and inference strategy named\nCoT-Valve, designed to allow models to generate reasoning chains of varying\nlengths. To achieve this, we propose to identify a direction in the parameter\nspace that, when manipulated, can effectively control the length of generated\nCoT. Moreover, we show that this property is valuable for compressing the\nreasoning chain. We construct datasets with chains from long to short for the\nsame questions and explore two enhanced strategies for CoT-Valve: (1) a precise\nlength-compressible CoT tuning method, and (2) a progressive chain length\ncompression approach. Our experiments show that CoT-Valve successfully enables\ncontrollability and compressibility of the chain and shows better performance\nthan the prompt-based control. We applied this method to QwQ-32B-Preview,\nreducing reasoning chains on GSM8K from 741 to 225 tokens with a minor\nperformance drop (95.07% to 94.92%) and on AIME from 6827 to 4629 tokens, with\nonly one additional incorrect answer.",
      "pdf_url": "http://arxiv.org/pdf/2502.09601v1",
      "published": "2025-02-13T18:52:36+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.09601v1",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "KIMAs: A Configurable Knowledge Integrated Multi-Agent System",
      "authors": [
        "Zitao Li",
        "Fei Wei",
        "Yuexiang Xie",
        "Dawei Gao",
        "Weirui Kuang",
        "Zhijian Ma",
        "Bingchen Qian",
        "Yaliang Li",
        "Bolin Ding"
      ],
      "abstract": "Knowledge-intensive conversations supported by large language models (LLMs)\nhave become one of the most popular and helpful applications that can assist\npeople in different aspects. Many current knowledge-intensive applications are\ncentered on retrieval-augmented generation (RAG) techniques. While many\nopen-source RAG frameworks facilitate the development of RAG-based\napplications, they often fall short in handling practical scenarios complicated\nby heterogeneous data in topics and formats, conversational context management,\nand the requirement of low-latency response times. This technical report\npresents a configurable knowledge integrated multi-agent system, KIMAs, to\naddress these challenges. KIMAs features a flexible and configurable system for\nintegrating diverse knowledge sources with 1) context management and query\nrewrite mechanisms to improve retrieval accuracy and multi-turn conversational\ncoherency, 2) efficient knowledge routing and retrieval, 3) simple but\neffective filter and reference generation mechanisms, and 4) optimized\nparallelizable multi-agent pipeline execution. Our work provides a scalable\nframework for advancing the deployment of LLMs in real-world settings. To show\nhow KIMAs can help developers build knowledge-intensive applications with\ndifferent scales and emphases, we demonstrate how we configure the system to\nthree applications already running in practice with reliable performance.",
      "pdf_url": "http://arxiv.org/pdf/2502.09596v1",
      "published": "2025-02-13T18:51:12+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.09596v1",
      "categories": [
        "cs.AI",
        "cs.MA"
      ]
    },
    {
      "title": "MorphNLI: A Stepwise Approach to Natural Language Inference Using Text Morphing",
      "authors": [
        "Vlad Andrei Negru",
        "Robert Vacareanu",
        "Camelia Lemnaru",
        "Mihai Surdeanu",
        "Rodica Potolea"
      ],
      "abstract": "We introduce MorphNLI, a modular step-by-step approach to natural language\ninference (NLI). When classifying the premise-hypothesis pairs into\n{entailment, contradiction, neutral}, we use a language model to generate the\nnecessary edits to incrementally transform (i.e., morph) the premise into the\nhypothesis. Then, using an off-the-shelf NLI model we track how the entailment\nprogresses with these atomic changes, aggregating these intermediate labels\ninto a final output. We demonstrate the advantages of our proposed method\nparticularly in realistic cross-domain settings, where our method always\noutperforms strong baselines with improvements up to 12.6% (relative). Further,\nour proposed approach is explainable as the atomic edits can be used to\nunderstand the overall NLI label.",
      "pdf_url": "http://arxiv.org/pdf/2502.09567v1",
      "published": "2025-02-13T18:22:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.09567v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "MDCrow: Automating Molecular Dynamics Workflows with Large Language Models",
      "authors": [
        "Quintina Campbell",
        "Sam Cox",
        "Jorge Medina",
        "Brittany Watterson",
        "Andrew D. White"
      ],
      "abstract": "Molecular dynamics (MD) simulations are essential for understanding\nbiomolecular systems but remain challenging to automate. Recent advances in\nlarge language models (LLM) have demonstrated success in automating complex\nscientific tasks using LLM-based agents. In this paper, we introduce MDCrow, an\nagentic LLM assistant capable of automating MD workflows. MDCrow uses\nchain-of-thought over 40 expert-designed tools for handling and processing\nfiles, setting up simulations, analyzing the simulation outputs, and retrieving\nrelevant information from literature and databases. We assess MDCrow's\nperformance across 25 tasks of varying required subtasks and difficulty, and we\nevaluate the agent's robustness to both difficulty and prompt style.\n\\texttt{gpt-4o} is able to complete complex tasks with low variance, followed\nclosely by \\texttt{llama3-405b}, a compelling open-source model. While prompt\nstyle does not influence the best models' performance, it has significant\neffects on smaller models.",
      "pdf_url": "http://arxiv.org/pdf/2502.09565v1",
      "published": "2025-02-13T18:19:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.09565v1",
      "categories": [
        "cs.AI",
        "physics.chem-ph"
      ]
    },
    {
      "title": "EmbodiedBench: Comprehensive Benchmarking Multi-modal Large Language Models for Vision-Driven Embodied Agents",
      "authors": [
        "Rui Yang",
        "Hanyang Chen",
        "Junyu Zhang",
        "Mark Zhao",
        "Cheng Qian",
        "Kangrui Wang",
        "Qineng Wang",
        "Teja Venkat Koripella",
        "Marziyeh Movahedi",
        "Manling Li",
        "Heng Ji",
        "Huan Zhang",
        "Tong Zhang"
      ],
      "abstract": "Leveraging Multi-modal Large Language Models (MLLMs) to create embodied\nagents offers a promising avenue for tackling real-world tasks. While\nlanguage-centric embodied agents have garnered substantial attention,\nMLLM-based embodied agents remain underexplored due to the lack of\ncomprehensive evaluation frameworks. To bridge this gap, we introduce\nEmbodiedBench, an extensive benchmark designed to evaluate vision-driven\nembodied agents. EmbodiedBench features: (1) a diverse set of 1,128 testing\ntasks across four environments, ranging from high-level semantic tasks (e.g.,\nhousehold) to low-level tasks involving atomic actions (e.g., navigation and\nmanipulation); and (2) six meticulously curated subsets evaluating essential\nagent capabilities like commonsense reasoning, complex instruction\nunderstanding, spatial awareness, visual perception, and long-term planning.\nThrough extensive experiments, we evaluated 13 leading proprietary and\nopen-source MLLMs within EmbodiedBench. Our findings reveal that: MLLMs excel\nat high-level tasks but struggle with low-level manipulation, with the best\nmodel, GPT-4o, scoring only 28.9% on average. EmbodiedBench provides a\nmultifaceted standardized evaluation platform that not only highlights existing\nchallenges but also offers valuable insights to advance MLLM-based embodied\nagents. Our code is available at https://embodiedbench.github.io.",
      "pdf_url": "http://arxiv.org/pdf/2502.09560v1",
      "published": "2025-02-13T18:11:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.09560v1",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ]
    },
    {
      "title": "Mind the Gap! Choice Independence in Using Multilingual LLMs for Persuasive Co-Writing Tasks in Different Languages",
      "authors": [
        "Shreyan Biswas",
        "Alexander Erlei",
        "Ujwal Gadiraju"
      ],
      "abstract": "Recent advances in generative AI have precipitated a proliferation of novel\nwriting assistants. These systems typically rely on multilingual large language\nmodels (LLMs), providing globalized workers the ability to revise or create\ndiverse forms of content in different languages. However, there is substantial\nevidence indicating that the performance of multilingual LLMs varies between\nlanguages. Users who employ writing assistance for multiple languages are\ntherefore susceptible to disparate output quality. Importantly, recent research\nhas shown that people tend to generalize algorithmic errors across independent\ntasks, violating the behavioral axiom of choice independence. In this paper, we\nanalyze whether user utilization of novel writing assistants in a charity\nadvertisement writing task is affected by the AI's performance in a second\nlanguage. Furthermore, we quantify the extent to which these patterns translate\ninto the persuasiveness of generated charity advertisements, as well as the\nrole of peoples' beliefs about LLM utilization in their donation choices. Our\nresults provide evidence that writers who engage with an LLM-based writing\nassistant violate choice independence, as prior exposure to a Spanish LLM\nreduces subsequent utilization of an English LLM. While these patterns do not\naffect the aggregate persuasiveness of the generated advertisements, people's\nbeliefs about the source of an advertisement (human versus AI) do. In\nparticular, Spanish-speaking female participants who believed that they read an\nAI-generated advertisement strongly adjusted their donation behavior downwards.\nFurthermore, people are generally not able to adequately differentiate between\nhuman-generated and LLM-generated ads. Our work has important implications for\nthe design, development, integration, and adoption of multilingual LLMs as\nassistive agents -- particularly in writing tasks.",
      "pdf_url": "http://arxiv.org/pdf/2502.09532v1",
      "published": "2025-02-13T17:49:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.09532v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ]
    },
    {
      "title": "Diffusion Models for Molecules: A Survey of Methods and Tasks",
      "authors": [
        "Liang Wang",
        "Chao Song",
        "Zhiyuan Liu",
        "Yu Rong",
        "Qiang Liu",
        "Shu Wu",
        "Liang Wang"
      ],
      "abstract": "Generative tasks about molecules, including but not limited to molecule\ngeneration, are crucial for drug discovery and material design, and have\nconsistently attracted significant attention. In recent years, diffusion models\nhave emerged as an impressive class of deep generative models, sparking\nextensive research and leading to numerous studies on their application to\nmolecular generative tasks. Despite the proliferation of related work, there\nremains a notable lack of up-to-date and systematic surveys in this area.\nParticularly, due to the diversity of diffusion model formulations, molecular\ndata modalities, and generative task types, the research landscape is\nchallenging to navigate, hindering understanding and limiting the area's\ngrowth. To address this, this paper conducts a comprehensive survey of\ndiffusion model-based molecular generative methods. We systematically review\nthe research from the perspectives of methodological formulations, data\nmodalities, and task types, offering a novel taxonomy. This survey aims to\nfacilitate understanding and further flourishing development in this area. The\nrelevant papers are summarized at:\nhttps://github.com/AzureLeon1/awesome-molecular-diffusion-models.",
      "pdf_url": "http://arxiv.org/pdf/2502.09511v1",
      "published": "2025-02-13T17:22:50+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.09511v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE"
      ]
    },
    {
      "title": "AttentionSmithy: A Modular Framework for Rapid Transformer Development and Customization",
      "authors": [
        "Caleb Cranney",
        "Jesse G. Meyer"
      ],
      "abstract": "Transformer architectures have transformed AI applications but remain complex\nto customize for domain experts lacking low-level implementation expertise. We\nintroduce AttentionSmithy, a modular software package that simplifies\ntransformer innovation by breaking down key components into reusable building\nblocks: attention modules, feed-forward networks, normalization layers, and\npositional encodings. Users can rapidly prototype and evaluate transformer\nvariants without extensive coding. Our framework supports four positional\nencoding strategies and integrates with neural architecture search for\nautomated design. We validate AttentionSmithy by replicating the original\ntransformer under resource constraints and optimizing translation performance\nby combining positional encodings. Additionally, we demonstrate its\nadaptability in gene-specific modeling, achieving over 95% accuracy in cell\ntype classification. These case studies highlight AttentionSmithy's potential\nto accelerate research across diverse fields by removing framework\nimplementation barriers.",
      "pdf_url": "http://arxiv.org/pdf/2502.09503v1",
      "published": "2025-02-13T17:15:26+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.09503v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Improve LLM-based Automatic Essay Scoring with Linguistic Features",
      "authors": [
        "Zhaoyi Joey Hou",
        "Alejandro Ciuba",
        "Xiang Lorraine Li"
      ],
      "abstract": "Automatic Essay Scoring (AES) assigns scores to student essays, reducing the\ngrading workload for instructors. Developing a scoring system capable of\nhandling essays across diverse prompts is challenging due to the flexibility\nand diverse nature of the writing task. Existing methods typically fall into\ntwo categories: supervised feature-based approaches and large language model\n(LLM)-based methods. Supervised feature-based approaches often achieve higher\nperformance but require resource-intensive training. In contrast, LLM-based\nmethods are computationally efficient during inference but tend to suffer from\nlower performance. This paper combines these approaches by incorporating\nlinguistic features into LLM-based scoring. Experimental results show that this\nhybrid method outperforms baseline models for both in-domain and out-of-domain\nwriting prompts.",
      "pdf_url": "http://arxiv.org/pdf/2502.09497v1",
      "published": "2025-02-13T17:09:52+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.09497v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Cracking the Code: Enhancing Development finance understanding with artificial intelligence",
      "authors": [
        "Pierre Beaucoral"
      ],
      "abstract": "Analyzing development projects is crucial for understanding donors aid\nstrategies, recipients priorities, and to assess development finance capacity\nto adress development issues by on-the-ground actions. In this area, the\nOrganisation for Economic Co-operation and Developments (OECD) Creditor\nReporting System (CRS) dataset is a reference data source. This dataset\nprovides a vast collection of project narratives from various sectors\n(approximately 5 million projects). While the OECD CRS provides a rich source\nof information on development strategies, it falls short in informing project\npurposes due to its reporting process based on donors self-declared main\nobjectives and pre-defined industrial sectors. This research employs a novel\napproach that combines Machine Learning (ML) techniques, specifically Natural\nLanguage Processing (NLP), an innovative Python topic modeling technique called\nBERTopic, to categorise (cluster) and label development projects based on their\nnarrative descriptions. By revealing existing yet hidden topics of development\nfinance, this application of artificial intelligence enables a better\nunderstanding of donor priorities and overall development funding and provides\nmethods to analyse public and private projects narratives.",
      "pdf_url": "http://arxiv.org/pdf/2502.09495v1",
      "published": "2025-02-13T17:01:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.09495v1",
      "categories": [
        "econ.GN",
        "cs.AI",
        "cs.LG",
        "q-fin.EC"
      ]
    },
    {
      "title": "Objective quantification of mood states using large language models",
      "authors": [
        "Jakub Onysk",
        "Quentin Huys"
      ],
      "abstract": "Emotional states influence human behaviour and cognition, leading to diverse\nthought trajectories. Similarly, Large Language Models (LLMs) showcase an\nexcellent level of response consistency across wide-ranging contexts (prompts).\nWe leverage these parallels to establish a framework for quantifying mental\nstates. Our approach utilises self-report questionnaires that reliably assess\nthese states due to their inherent sensitivity to patterns of co-occurring\nresponses. Specifically, we recruited a large sample of participants (N=422) to\ninvestigate how well an LLM (Mistral-7B-OpenOrca) quantifies a heterogenous set\nof depressive mood states measured with participants' open-ended responses to a\ndepression questionnaire. We show LLM responses to held-out multiple-choice\nquestions, given participants' open-ended answers, correlate strongly (r:\n0.52-0.84) with true questionnaire scores, demonstrating LLM's generalisation\nfrom mood representations. We explore a link between these representations and\nfactor analysis. Using ridge regression, we find depression-related subspaces\nwithin LLM hidden states. We show these subspaces to be predictive of\nparticipants' \"Depression\" and \"Somatic & Emotional Distress\" factor scores, as\nwell as suicidality severity. Overall, LLMs can provide quantitative measures\nof mental states. The reliability of these hinges upon how informative the\nquestions we ask participants are. Used correctly, this approach could\nsupplement mental state assessment in a variety of settings.",
      "pdf_url": "http://arxiv.org/pdf/2502.09487v1",
      "published": "2025-02-13T16:52:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.09487v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "PenTest++: Elevating Ethical Hacking with AI and Automation",
      "authors": [
        "Haitham S. Al-Sinani",
        "Chris J. Mitchell"
      ],
      "abstract": "Traditional ethical hacking relies on skilled professionals and\ntime-intensive command management, which limits its scalability and efficiency.\nTo address these challenges, we introduce PenTest++, an AI-augmented system\nthat integrates automation with generative AI (GenAI) to optimise ethical\nhacking workflows. Developed in a controlled virtual environment, PenTest++\nstreamlines critical penetration testing tasks, including reconnaissance,\nscanning, enumeration, exploitation, and documentation, while maintaining a\nmodular and adaptable design. The system balances automation with human\noversight, ensuring informed decision-making at key stages, and offers\nsignificant benefits such as enhanced efficiency, scalability, and\nadaptability. However, it also raises ethical considerations, including privacy\nconcerns and the risks of AI-generated inaccuracies (hallucinations). This\nresearch underscores the potential of AI-driven systems like PenTest++ to\ncomplement human expertise in cybersecurity by automating routine tasks,\nenabling professionals to focus on strategic decision-making. By incorporating\nrobust ethical safeguards and promoting ongoing refinement, PenTest++\ndemonstrates how AI can be responsibly harnessed to address operational and\nethical challenges in the evolving cybersecurity landscape.",
      "pdf_url": "http://arxiv.org/pdf/2502.09484v1",
      "published": "2025-02-13T16:46:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.09484v1",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "title": "Wholly-WOOD: Wholly Leveraging Diversified-quality Labels for Weakly-supervised Oriented Object Detection",
      "authors": [
        "Yi Yu",
        "Xue Yang",
        "Yansheng Li",
        "Zhenjun Han",
        "Feipeng Da",
        "Junchi Yan"
      ],
      "abstract": "Accurately estimating the orientation of visual objects with compact rotated\nbounding boxes (RBoxes) has become a prominent demand, which challenges\nexisting object detection paradigms that only use horizontal bounding boxes\n(HBoxes). To equip the detectors with orientation awareness, supervised\nregression/classification modules have been introduced at the high cost of\nrotation annotation. Meanwhile, some existing datasets with oriented objects\nare already annotated with horizontal boxes or even single points. It becomes\nattractive yet remains open for effectively utilizing weaker single point and\nhorizontal annotations to train an oriented object detector (OOD). We develop\nWholly-WOOD, a weakly-supervised OOD framework, capable of wholly leveraging\nvarious labeling forms (Points, HBoxes, RBoxes, and their combination) in a\nunified fashion. By only using HBox for training, our Wholly-WOOD achieves\nperformance very close to that of the RBox-trained counterpart on remote\nsensing and other areas, significantly reducing the tedious efforts on\nlabor-intensive annotation for oriented objects. The source codes are available\nat https://github.com/VisionXLab/whollywood (PyTorch-based) and\nhttps://github.com/VisionXLab/whollywood-jittor (Jittor-based).",
      "pdf_url": "http://arxiv.org/pdf/2502.09471v1",
      "published": "2025-02-13T16:34:59+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.09471v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Metamorphic Testing for Pose Estimation Systems",
      "authors": [
        "Matias Duran",
        "Thomas Laurent",
        "Ellen Rushe",
        "Anthony Ventresque"
      ],
      "abstract": "Pose estimation systems are used in a variety of fields, from sports\nanalytics to livestock care. Given their potential impact, it is paramount to\nsystematically test their behaviour and potential for failure. This is a\ncomplex task due to the oracle problem and the high cost of manual labelling\nnecessary to build ground truth keypoints. This problem is exacerbated by the\nfact that different applications require systems to focus on different subjects\n(e.g., human versus animal) or landmarks (e.g., only extremities versus whole\nbody and face), which makes labelled test data rarely reusable. To combat these\nproblems we propose MET-POSE, a metamorphic testing framework for pose\nestimation systems that bypasses the need for manual annotation while assessing\nthe performance of these systems under different circumstances. MET-POSE thus\nallows users of pose estimation systems to assess the systems in conditions\nthat more closely relate to their application without having to label an ad-hoc\ntest dataset or rely only on available datasets, which may not be adapted to\ntheir application domain. While we define MET-POSE in general terms, we also\npresent a non-exhaustive list of metamorphic rules that represent common\nchallenges in computer vision applications, as well as a specific way to\nevaluate these rules. We then experimentally show the effectiveness of MET-POSE\nby applying it to Mediapipe Holistic, a state of the art human pose estimation\nsystem, with the FLIC and PHOENIX datasets. With these experiments, we outline\nnumerous ways in which the outputs of MET-POSE can uncover faults in pose\nestimation systems at a similar or higher rate than classic testing using hand\nlabelled data, and show that users can tailor the rule set they use to the\nfaults and level of accuracy relevant to their application.",
      "pdf_url": "http://arxiv.org/pdf/2502.09460v1",
      "published": "2025-02-13T16:27:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.09460v1",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Relational Conformal Prediction for Correlated Time Series",
      "authors": [
        "Andrea Cini",
        "Alexander Jenkins",
        "Danilo Mandic",
        "Cesare Alippi",
        "Filippo Maria Bianchi"
      ],
      "abstract": "We address the problem of uncertainty quantification in time series\nforecasting by exploiting observations at correlated sequences. Relational deep\nlearning methods leveraging graph representations are among the most effective\ntools for obtaining point estimates from spatiotemporal data and correlated\ntime series. However, the problem of exploiting relational structures to\nestimate the uncertainty of such predictions has been largely overlooked in the\nsame context. To this end, we propose a novel distribution-free approach based\non the conformal prediction framework and quantile regression. Despite the\nrecent applications of conformal prediction to sequential data, existing\nmethods operate independently on each target time series and do not account for\nrelationships among them when constructing the prediction interval. We fill\nthis void by introducing a novel conformal prediction method based on graph\ndeep learning operators. Our method, named Conformal Relational Prediction\n(CoRel), does not require the relational structure (graph) to be known as a\nprior and can be applied on top of any pre-trained time series predictor.\nAdditionally, CoRel includes an adaptive component to handle non-exchangeable\ndata and changes in the input time series. Our approach provides accurate\ncoverage and archives state-of-the-art uncertainty quantification in relevant\nbenchmarks.",
      "pdf_url": "http://arxiv.org/pdf/2502.09443v1",
      "published": "2025-02-13T16:12:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.09443v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Variable Stiffness for Robust Locomotion through Reinforcement Learning",
      "authors": [
        "Dario Spoljaric",
        "Yashuai Yan",
        "Dongheui Lee"
      ],
      "abstract": "Reinforcement-learned locomotion enables legged robots to perform highly\ndynamic motions but often accompanies time-consuming manual tuning of joint\nstiffness. This paper introduces a novel control paradigm that integrates\nvariable stiffness into the action space alongside joint positions, enabling\ngrouped stiffness control such as per-joint stiffness (PJS), per-leg stiffness\n(PLS) and hybrid joint-leg stiffness (HJLS). We show that variable stiffness\npolicies, with grouping in per-leg stiffness (PLS), outperform position-based\ncontrol in velocity tracking and push recovery. In contrast, HJLS excels in\nenergy efficiency. Furthermore, our method showcases robust walking behaviour\non diverse outdoor terrains by sim-to-real transfer, although the policy is\nsorely trained on a flat floor. Our approach simplifies design by eliminating\nper-joint stiffness tuning while keeping competitive results with various\nmetrics.",
      "pdf_url": "http://arxiv.org/pdf/2502.09436v1",
      "published": "2025-02-13T16:00:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.09436v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "Dual Formulation for Non-Rectangular Lp Robust Markov Decision Processes",
      "authors": [
        "Navdeep Kumar",
        "Adarsh Gupta",
        "Maxence Mohamed Elfatihi",
        "Giorgia Ramponi",
        "Kfir Yehuda Levy",
        "Shie Mannor"
      ],
      "abstract": "We study robust Markov decision processes (RMDPs) with non-rectangular\nuncertainty sets, which capture interdependencies across states unlike\ntraditional rectangular models. While non-rectangular robust policy evaluation\nis generally NP-hard, even in approximation, we identify a powerful class of\n$L_p$-bounded uncertainty sets that avoid these complexity barriers due to\ntheir structural simplicity. We further show that this class can be decomposed\ninto infinitely many \\texttt{sa}-rectangular $L_p$-bounded sets and leverage\nits structural properties to derive a novel dual formulation for $L_p$ RMDPs.\nThis formulation provides key insights into the adversary's strategy and\nenables the development of the first robust policy evaluation algorithms for\nnon-rectangular RMDPs. Empirical results demonstrate that our approach\nsignificantly outperforms brute-force methods, establishing a promising\nfoundation for future investigation into non-rectangular robust MDPs.",
      "pdf_url": "http://arxiv.org/pdf/2502.09432v1",
      "published": "2025-02-13T15:55:00+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.09432v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Transformer-Enhanced Variational Autoencoder for Crystal Structure Prediction",
      "authors": [
        "Ziyi Chen",
        "Yang Yuan",
        "Siming Zheng",
        "Jialong Guo",
        "Sihan Liang",
        "Yangang Wang",
        "Zongguo Wang"
      ],
      "abstract": "Crystal structure forms the foundation for understanding the physical and\nchemical properties of materials. Generative models have emerged as a new\nparadigm in crystal structure prediction(CSP), however, accurately capturing\nkey characteristics of crystal structures, such as periodicity and symmetry,\nremains a significant challenge. In this paper, we propose a\nTransformer-Enhanced Variational Autoencoder for Crystal Structure Prediction\n(TransVAE-CSP), who learns the characteristic distribution space of stable\nmaterials, enabling both the reconstruction and generation of crystal\nstructures. TransVAE-CSP integrates adaptive distance expansion with\nirreducible representation to effectively capture the periodicity and symmetry\nof crystal structures, and the encoder is a transformer network based on an\nequivariant dot product attention mechanism. Experimental results on the\ncarbon_24, perov_5, and mp_20 datasets demonstrate that TransVAE-CSP\noutperforms existing methods in structure reconstruction and generation tasks\nunder various modeling metrics, offering a powerful tool for crystal structure\ndesign and optimization.",
      "pdf_url": "http://arxiv.org/pdf/2502.09423v1",
      "published": "2025-02-13T15:45:36+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.09423v1",
      "categories": [
        "cond-mat.mtrl-sci",
        "cs.AI"
      ]
    },
    {
      "title": "A Survey of Reinforcement Learning for Optimization in Automation",
      "authors": [
        "Ahmad Farooq",
        "Kamran Iqbal"
      ],
      "abstract": "Reinforcement Learning (RL) has become a critical tool for optimization\nchallenges within automation, leading to significant advancements in several\nareas. This review article examines the current landscape of RL within\nautomation, with a particular focus on its roles in manufacturing, energy\nsystems, and robotics. It discusses state-of-the-art methods, major challenges,\nand upcoming avenues of research within each sector, highlighting RL's capacity\nto solve intricate optimization challenges. The paper reviews the advantages\nand constraints of RL-driven optimization methods in automation. It points out\nprevalent challenges encountered in RL optimization, including issues related\nto sample efficiency and scalability; safety and robustness; interpretability\nand trustworthiness; transfer learning and meta-learning; and real-world\ndeployment and integration. It further explores prospective strategies and\nfuture research pathways to navigate these challenges. Additionally, the survey\nincludes a comprehensive list of relevant research papers, making it an\nindispensable guide for scholars and practitioners keen on exploring this\ndomain.",
      "pdf_url": "http://arxiv.org/pdf/2502.09417v1",
      "published": "2025-02-13T15:40:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.09417v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE",
        "cs.RO",
        "cs.SY",
        "eess.SY",
        "68T05, 90C40, 49M37",
        "I.2.6; I.2.8; I.2.9; G.1.6; C.4; J.6"
      ]
    },
    {
      "title": "SQuARE: Sequential Question Answering Reasoning Engine for Enhanced Chain-of-Thought in Large Language Models",
      "authors": [
        "Daniel Fleischer",
        "Moshe Berchansky",
        "Gad Markovits",
        "Moshe Wasserblat"
      ],
      "abstract": "In the rapidly evolving field of Natural Language Processing, Large Language\nModels (LLMs) are tasked with increasingly complex reasoning challenges.\nTraditional methods like chain-of-thought prompting have shown promise but\noften fall short in fully leveraging a model's reasoning capabilities. This\npaper introduces SQuARE (Sequential Question Answering Reasoning Engine), a\nnovel prompting technique designed to improve reasoning through a\nself-interrogation paradigm. Building upon CoT frameworks, SQuARE prompts\nmodels to generate and resolve multiple auxiliary questions before tackling the\nmain query, promoting a more thorough exploration of various aspects of a\ntopic. Our expansive evaluations, conducted with Llama 3 and GPT-4o models\nacross multiple question-answering datasets, demonstrate that SQuARE\nsignificantly surpasses traditional CoT prompts and existing\nrephrase-and-respond methods. By systematically decomposing queries, SQuARE\nadvances LLM capabilities in reasoning tasks. The code is publicly available at\nhttps://github.com/IntelLabs/RAG-FiT/tree/square.",
      "pdf_url": "http://arxiv.org/pdf/2502.09390v1",
      "published": "2025-02-13T15:07:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.09390v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "S$^2$-Diffusion: Generalizing from Instance-level to Category-level Skills in Robot Manipulation",
      "authors": [
        "Quantao Yang",
        "Michael C. Welle",
        "Danica Kragic",
        "Olov Andersson"
      ],
      "abstract": "Recent advances in skill learning has propelled robot manipulation to new\nheights by enabling it to learn complex manipulation tasks from a practical\nnumber of demonstrations. However, these skills are often limited to the\nparticular action, object, and environment \\textit{instances} that are shown in\nthe training data, and have trouble transferring to other instances of the same\ncategory. In this work we present an open-vocabulary Spatial-Semantic Diffusion\npolicy (S$^2$-Diffusion) which enables generalization from instance-level\ntraining data to category-level, enabling skills to be transferable between\ninstances of the same category. We show that functional aspects of skills can\nbe captured via a promptable semantic module combined with a spatial\nrepresentation. We further propose leveraging depth estimation networks to\nallow the use of only a single RGB camera. Our approach is evaluated and\ncompared on a diverse number of robot manipulation tasks, both in simulation\nand in the real world. Our results show that S$^2$-Diffusion is invariant to\nchanges in category-irrelevant factors as well as enables satisfying\nperformance on other instances within the same category, even if it was not\ntrained on that specific instance. Full videos of all real-world experiments\nare available in the supplementary material.",
      "pdf_url": "http://arxiv.org/pdf/2502.09389v1",
      "published": "2025-02-13T15:06:42+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.09389v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "Truth Knows No Language: Evaluating Truthfulness Beyond English",
      "authors": [
        "Blanca Calvo Figueras",
        "Eneko Sagarzazu",
        "Julen Etxaniz",
        "Jeremy Barnes",
        "Pablo Gamallo",
        "Iria De Dios Flores",
        "Rodrigo Agerri"
      ],
      "abstract": "We introduce a professionally translated extension of the TruthfulQA\nbenchmark designed to evaluate truthfulness in Basque, Catalan, Galician, and\nSpanish. Truthfulness evaluations of large language models (LLMs) have\nprimarily been conducted in English. However, the ability of LLMs to maintain\ntruthfulness across languages remains under-explored. Our study evaluates 12\nstate-of-the-art open LLMs, comparing base and instruction-tuned models using\nhuman evaluation, multiple-choice metrics, and LLM-as-a-Judge scoring. Our\nfindings reveal that, while LLMs perform best in English and worst in Basque\n(the lowest-resourced language), overall truthfulness discrepancies across\nlanguages are smaller than anticipated. Furthermore, we show that\nLLM-as-a-Judge correlates more closely with human judgments than\nmultiple-choice metrics, and that informativeness plays a critical role in\ntruthfulness assessment. Our results also indicate that machine translation\nprovides a viable approach for extending truthfulness benchmarks to additional\nlanguages, offering a scalable alternative to professional translation.\nFinally, we observe that universal knowledge questions are better handled\nacross languages than context- and time-dependent ones, highlighting the need\nfor truthfulness evaluations that account for cultural and temporal\nvariability. Dataset and code are publicly available under open licenses.",
      "pdf_url": "http://arxiv.org/pdf/2502.09387v1",
      "published": "2025-02-13T15:04:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.09387v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ]
    },
    {
      "title": "TRIFFID: Autonomous Robotic Aid For Increasing First Responders Efficiency",
      "authors": [
        "Jorgen Cani",
        "Panagiotis Koletsis",
        "Konstantinos Foteinos",
        "Ioannis Kefaloukos",
        "Lampros Argyriou",
        "Manolis Falelakis",
        "Iván Del Pino",
        "Angel Santamaria-Navarro",
        "Martin Čech",
        "Ondřej Severa",
        "Alessandro Umbrico",
        "Francesca Fracasso",
        "AndreA Orlandini",
        "Dimitrios Drakoulis",
        "Evangelos Markakis",
        "Georgios Th. Papadopoulos"
      ],
      "abstract": "The increasing complexity of natural disaster incidents demands innovative\ntechnological solutions to support first responders in their efforts. This\npaper introduces the TRIFFID system, a comprehensive technical framework that\nintegrates unmanned ground and aerial vehicles with advanced artificial\nintelligence functionalities to enhance disaster response capabilities across\nwildfires, urban floods, and post-earthquake search and rescue missions. By\nleveraging state-of-the-art autonomous navigation, semantic perception, and\nhuman-robot interaction technologies, TRIFFID provides a sophisticated system\ncom- posed of the following key components: hybrid robotic platform,\ncentralized ground station, custom communication infrastructure, and smartphone\napplication. The defined research and development activities demonstrate how\ndeep neural networks, knowledge graphs, and multimodal information fusion can\nenable robots to autonomously navigate and analyze disaster environ- ments,\nreducing personnel risks and accelerating response times. The proposed system\nenhances emergency response teams by providing advanced mission planning,\nsafety monitoring, and adaptive task execution capabilities. Moreover, it\nensures real- time situational awareness and operational support in complex and\nrisky situations, facilitating rapid and precise information collection and\ncoordinated actions.",
      "pdf_url": "http://arxiv.org/pdf/2502.09379v1",
      "published": "2025-02-13T14:46:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.09379v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "A Deep Inverse-Mapping Model for a Flapping Robotic Wing",
      "authors": [
        "Hadar Sharvit",
        "Raz Karl",
        "Tsevi Beatus"
      ],
      "abstract": "In systems control, the dynamics of a system are governed by modulating its\ninputs to achieve a desired outcome. For example, to control the thrust of a\nquad-copter propeller the controller modulates its rotation rate, relying on a\nstraightforward mapping between the input rotation rate and the resulting\nthrust. This mapping can be inverted to determine the rotation rate needed to\ngenerate a desired thrust. However, in complex systems, such as flapping-wing\nrobots where intricate fluid motions are involved, mapping inputs (wing\nkinematics) to outcomes (aerodynamic forces) is nontrivial and inverting this\nmapping for real-time control is computationally impractical. Here, we report a\nmachine-learning solution for the inverse mapping of a flapping-wing system\nbased on data from an experimental system we have developed. Our model learns\nthe input wing motion required to generate a desired aerodynamic force outcome.\nWe used a sequence-to-sequence model tailored for time-series data and\naugmented it with a novel adaptive-spectrum layer that implements\nrepresentation learning in the frequency domain. To train our model, we\ndeveloped a flapping wing system that simultaneously measures the wing's\naerodynamic force and its 3D motion using high-speed cameras. We demonstrate\nthe performance of our system on an additional open-source dataset of a\nflapping wing in a different flow regime. Results show superior performance\ncompared with more complex state-of-the-art transformer-based models, with 11%\nimprovement on the test datasets median loss. Moreover, our model shows\nsuperior inference time, making it practical for onboard robotic control. Our\nopen-source data and framework may improve modeling and real-time control of\nsystems governed by complex dynamics, from biomimetic robots to biomedical\ndevices.",
      "pdf_url": "http://arxiv.org/pdf/2502.09378v1",
      "published": "2025-02-13T14:46:04+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.09378v1",
      "categories": [
        "cs.AI",
        "cs.RO"
      ]
    },
    {
      "title": "Language Agents as Digital Representatives in Collective Decision-Making",
      "authors": [
        "Daniel Jarrett",
        "Miruna Pîslar",
        "Michiel A. Bakker",
        "Michael Henry Tessler",
        "Raphael Köster",
        "Jan Balaguer",
        "Romuald Elie",
        "Christopher Summerfield",
        "Andrea Tacchetti"
      ],
      "abstract": "Consider the process of collective decision-making, in which a group of\nindividuals interactively select a preferred outcome from among a universe of\nalternatives. In this context, \"representation\" is the activity of making an\nindividual's preferences present in the process via participation by a proxy\nagent -- i.e. their \"representative\". To this end, learned models of human\nbehavior have the potential to fill this role, with practical implications for\nmulti-agent scenario studies and mechanism design. In this work, we investigate\nthe possibility of training \\textit{language agents} to behave in the capacity\nof representatives of human agents, appropriately expressing the preferences of\nthose individuals whom they stand for. First, we formalize the setting of\n\\textit{collective decision-making} -- as the episodic process of interaction\nbetween a group of agents and a decision mechanism. On this basis, we then\nformalize the problem of \\textit{digital representation} -- as the simulation\nof an agent's behavior to yield equivalent outcomes from the mechanism.\nFinally, we conduct an empirical case study in the setting of\n\\textit{consensus-finding} among diverse humans, and demonstrate the\nfeasibility of fine-tuning large language models to act as digital\nrepresentatives.",
      "pdf_url": "http://arxiv.org/pdf/2502.09369v1",
      "published": "2025-02-13T14:35:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.09369v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ]
    },
    {
      "title": "Simple Path Structural Encoding for Graph Transformers",
      "authors": [
        "Louis Airale",
        "Antonio Longa",
        "Mattia Rigon",
        "Andrea Passerini",
        "Roberto Passerone"
      ],
      "abstract": "Graph transformers extend global self-attention to graph-structured data,\nachieving notable success in graph learning. Recently, random walk structural\nencoding (RWSE) has been found to further enhance their predictive power by\nencoding both structural and positional information into the edge\nrepresentation. However, RWSE cannot always distinguish between edges that\nbelong to different local graph patterns, which reduces its ability to capture\nthe full structural complexity of graphs. This work introduces Simple Path\nStructural Encoding (SPSE), a novel method that utilizes simple path counts for\nedge encoding. We show theoretically and experimentally that SPSE overcomes the\nlimitations of RWSE, providing a richer representation of graph structures,\nparticularly for capturing local cyclic patterns. To make SPSE computationally\ntractable, we propose an efficient approximate algorithm for simple path\ncounting. SPSE demonstrates significant performance improvements over RWSE on\nvarious benchmarks, including molecular and long-range graph datasets,\nachieving statistically significant gains in discriminative tasks. These\nresults pose SPSE as a powerful edge encoding alternative for enhancing the\nexpressivity of graph transformers.",
      "pdf_url": "http://arxiv.org/pdf/2502.09365v1",
      "published": "2025-02-13T14:33:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.09365v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Neural Spatiotemporal Point Processes: Trends and Challenges",
      "authors": [
        "Sumantrak Mukherjee",
        "Mouad Elhamdi",
        "George Mohler",
        "David A. Selby",
        "Yao Xie",
        "Sebastian Vollmer",
        "Gerrit Grossmann"
      ],
      "abstract": "Spatiotemporal point processes (STPPs) are probabilistic models for events\noccurring in continuous space and time. Real-world event data often exhibit\nintricate dependencies and heterogeneous dynamics. By incorporating modern deep\nlearning techniques, STPPs can model these complexities more effectively than\ntraditional approaches. Consequently, the fusion of neural methods with STPPs\nhas become an active and rapidly evolving research area. In this review, we\ncategorize existing approaches, unify key design choices, and explain the\nchallenges of working with this data modality. We further highlight emerging\ntrends and diverse application domains. Finally, we identify open challenges\nand gaps in the literature.",
      "pdf_url": "http://arxiv.org/pdf/2502.09341v1",
      "published": "2025-02-13T14:01:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.09341v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Graph Diffusion Network for Drug-Gene Prediction",
      "authors": [
        "Jiayang Wu",
        "Wensheng Gan",
        "Philip S. Yu"
      ],
      "abstract": "Predicting drug-gene associations is crucial for drug development and disease\ntreatment. While graph neural networks (GNN) have shown effectiveness in this\ntask, they face challenges with data sparsity and efficient contrastive\nlearning implementation. We introduce a graph diffusion network for drug-gene\nprediction (GDNDGP), a framework that addresses these limitations through two\nkey innovations. First, it employs meta-path-based homogeneous graph learning\nto capture drug-drug and gene-gene relationships, ensuring similar entities\nshare embedding spaces. Second, it incorporates a parallel diffusion network\nthat generates hard negative samples during training, eliminating the need for\nexhaustive negative sample retrieval. Our model achieves superior performance\non the DGIdb 4.0 dataset and demonstrates strong generalization capability on\ntripartite drug-gene-disease networks. Results show significant improvements\nover existing methods in drug-gene prediction tasks, particularly in handling\ncomplex heterogeneous relationships. The source code is publicly available at\nhttps://github.com/csjywu1/GDNDGP.",
      "pdf_url": "http://arxiv.org/pdf/2502.09335v1",
      "published": "2025-02-13T13:54:58+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.09335v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "When the LM misunderstood the human chuckled: Analyzing garden path effects in humans and language models",
      "authors": [
        "Samuel Joseph Amouyal",
        "Aya Meltzer-Asscher",
        "Jonathan Berant"
      ],
      "abstract": "Modern Large Language Models (LLMs) have shown human-like abilities in many\nlanguage tasks, sparking interest in comparing LLMs' and humans' language\nprocessing. In this paper, we conduct a detailed comparison of the two on a\nsentence comprehension task using garden-path constructions, which are\nnotoriously challenging for humans. Based on psycholinguistic research, we\nformulate hypotheses on why garden-path sentences are hard, and test these\nhypotheses on human participants and a large suite of LLMs using comprehension\nquestions. Our findings reveal that both LLMs and humans struggle with specific\nsyntactic complexities, with some models showing high correlation with human\ncomprehension. To complement our findings, we test LLM comprehension of\ngarden-path constructions with paraphrasing and text-to-image generation tasks,\nand find that the results mirror the sentence comprehension question results,\nfurther validating our findings on LLM understanding of these constructions.",
      "pdf_url": "http://arxiv.org/pdf/2502.09307v1",
      "published": "2025-02-13T13:19:33+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.09307v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Predicting Drive Test Results in Mobile Networks Using Optimization Techniques",
      "authors": [
        "MohammadJava Taheri",
        "Abolfazl Diyanat",
        "MortezaAli Ahmadi",
        "Ali Nazari"
      ],
      "abstract": "Mobile network operators constantly optimize their networks to ensure\nsuperior service quality and coverage. This optimization is crucial for\nmaintaining an optimal user experience and requires extensive data collection\nand analysis. One of the primary methods for gathering this data is through\ndrive tests, where technical teams use specialized equipment to collect signal\ninformation across various regions. However, drive tests are both costly and\ntime-consuming, and they face challenges such as traffic conditions,\nenvironmental factors, and limited access to certain areas. These constraints\nmake it difficult to replicate drive tests under similar conditions. In this\nstudy, we propose a method that enables operators to predict received signal\nstrength at specific locations using data from other drive test points. By\nreducing the need for widespread drive tests, this approach allows operators to\nsave time and resources while still obtaining the necessary data to optimize\ntheir networks and mitigate the challenges associated with traditional drive\ntests.",
      "pdf_url": "http://arxiv.org/pdf/2502.09305v1",
      "published": "2025-02-13T13:17:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.09305v1",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.SE"
      ]
    },
    {
      "title": "Indeterminacy in Affective Computing: Considering Meaning and Context in Data Collection Practices",
      "authors": [
        "Bernd Dudzik",
        "Tiffany Matej Hrkalovic",
        "Chenxu Hao",
        "Chirag Raman",
        "Masha Tsfasman"
      ],
      "abstract": "Automatic Affect Prediction (AAP) uses computational analysis of input data\nsuch as text, speech, images, and physiological signals to predict various\naffective phenomena (e.g., emotions or moods). These models are typically\nconstructed using supervised machine-learning algorithms, which rely heavily on\nlabeled training datasets. In this position paper, we posit that all AAP\ntraining data are derived from human Affective Interpretation Processes,\nresulting in a form of Affective Meaning. Research on human affect indicates a\nform of complexity that is fundamental to such meaning: it can possess what we\nrefer to here broadly as Qualities of Indeterminacy (QIs) - encompassing\nSubjectivity (meaning depends on who is interpreting), Uncertainty (lack of\nconfidence regarding meanings' correctness), Ambiguity (meaning contains\nmutually exclusive concepts) and Vagueness (meaning is situated at different\nlevels in a nested hierarchy). Failing to appropriately consider QIs leads to\nresults incapable of meaningful and reliable predictions. Based on this\npremise, we argue that a crucial step in adequately addressing indeterminacy in\nAAP is the development of data collection practices for modeling corpora that\ninvolve the systematic consideration of 1) a relevant set of QIs and 2) context\nfor the associated interpretation processes. To this end, we are 1) outlining a\nconceptual model of AIPs and the QIs associated with the meaning these produce\nand a conceptual structure of relevant context, supporting understanding of its\nrole. Finally, we use our framework for 2) discussing examples of\ncontext-sensitivity-related challenges for addressing QIs in data collection\nsetups. We believe our efforts can stimulate a structured discussion of both\nthe role of aspects of indeterminacy and context in research on AAP, informing\nthe development of better practices for data collection and analysis.",
      "pdf_url": "http://arxiv.org/pdf/2502.09294v1",
      "published": "2025-02-13T13:08:42+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.09294v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "SparQLe: Speech Queries to Text Translation Through LLMs",
      "authors": [
        "Amirbek Djanibekov",
        "Hanan Aldarmaki"
      ],
      "abstract": "With the growing influence of Large Language Models (LLMs), there is\nincreasing interest in integrating speech representations with them to enable\nmore seamless multi-modal processing and speech understanding. This study\nintroduces a novel approach that leverages self-supervised speech\nrepresentations in combination with instruction-tuned LLMs for speech-to-text\ntranslation. The proposed approach leverages a modality adapter to align\nextracted speech features with instruction-tuned LLMs using English-language\ndata. Our experiments demonstrate that this method effectively preserves the\nsemantic content of the input speech and serves as an effective bridge between\nself-supervised speech models and instruction-tuned LLMs, offering a promising\nsolution for various speech understanding applications.",
      "pdf_url": "http://arxiv.org/pdf/2502.09284v1",
      "published": "2025-02-13T12:57:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.09284v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "LiSA: Leveraging Link Recommender to Attack Graph Neural Networks via Subgraph Injection",
      "authors": [
        "Wenlun Zhang",
        "Enyan Dai",
        "Kentaro Yoshioka"
      ],
      "abstract": "Graph Neural Networks (GNNs) have demonstrated remarkable proficiency in\nmodeling data with graph structures, yet recent research reveals their\nsusceptibility to adversarial attacks. Traditional attack methodologies, which\nrely on manipulating the original graph or adding links to artificially created\nnodes, often prove impractical in real-world settings. This paper introduces a\nnovel adversarial scenario involving the injection of an isolated subgraph to\ndeceive both the link recommender and the node classifier within a GNN system.\nSpecifically, the link recommender is mislead to propose links between targeted\nvictim nodes and the subgraph, encouraging users to unintentionally establish\nconnections and that would degrade the node classification accuracy, thereby\nfacilitating a successful attack. To address this, we present the LiSA\nframework, which employs a dual surrogate model and bi-level optimization to\nsimultaneously meet two adversarial objectives. Extensive experiments on\nreal-world datasets demonstrate the effectiveness of our method.",
      "pdf_url": "http://arxiv.org/pdf/2502.09271v1",
      "published": "2025-02-13T12:33:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.09271v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Bandit Multiclass List Classification",
      "authors": [
        "Liad Erez",
        "Tomer Koren"
      ],
      "abstract": "We study the problem of multiclass list classification with (semi-)bandit\nfeedback, where input examples are mapped into subsets of size $m$ of a\ncollection of $K$ possible labels, and the feedback consists of the predicted\nlabels which lie in the set of true labels of the given example. Our main\nresult is for the $(\\varepsilon,\\delta)$-PAC variant of the problem for which\nwe design an algorithm that returns an $\\varepsilon$-optimal hypothesis with\nhigh probability using a sample complexity of $O \\big( (\\mathrm{poly}(K/m) + sm\n/ \\varepsilon^2) \\log (|H|/\\delta) \\big)$ where $H$ is the underlying (finite)\nhypothesis class and $s$ is an upper bound on the number of true labels for a\ngiven example. This bound improves upon known bounds for combinatorial\nsemi-bandits whenever $s \\ll K$. Moreover, in the regime where $s = O(1)$ the\nleading terms in our bound match the corresponding full-information rates,\nimplying that bandit feedback essentially comes at no cost. Our PAC learning\nalgorithm is also computationally efficient given access to an ERM oracle for\n$H$. Additionally, we consider the regret minimization setting where data can\nbe generated adversarially, and establish a regret bound of $\\widetilde O(|H| +\n\\sqrt{smT \\log |H|})$. Our results generalize and extend those of Erez et al.\n(2024) who consider the simpler single-label setting corresponding to $s=m=1$,\nand in fact hold for the more general contextual combinatorial semi-bandit\nproblem with $s$-sparse rewards.",
      "pdf_url": "http://arxiv.org/pdf/2502.09257v1",
      "published": "2025-02-13T12:13:25+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.09257v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ]
    },
    {
      "title": "DynSegNet:Dynamic Architecture Adjustment for Adversarial Learning in Segmenting Hemorrhagic Lesions from Fundus Images",
      "authors": [
        "Zesheng Li",
        "Minwen Liao",
        "Haoran Chen",
        "Yan Su",
        "Chengchang Pan",
        "Honggang Qi"
      ],
      "abstract": "The hemorrhagic lesion segmentation plays a critical role in ophthalmic\ndiagnosis, directly influencing early disease detection, treatment planning,\nand therapeutic efficacy evaluation. However, the task faces significant\nchallenges due to lesion morphological variability, indistinct boundaries, and\nlow contrast with background tissues. To improve diagnostic accuracy and\ntreatment outcomes, developing advanced segmentation techniques remains\nimperative. This paper proposes an adversarial learning-based dynamic\narchitecture adjustment approach that integrates hierarchical U-shaped\nencoder-decoder, residual blocks, attention mechanisms, and ASPP modules. By\ndynamically optimizing feature fusion, our method enhances segmentation\nperformance. Experimental results demonstrate a Dice coefficient of 0.6802, IoU\nof 0.5602, Recall of 0.766, Precision of 0.6525, and Accuracy of 0.9955,\neffectively addressing the challenges in fundus image hemorrhage\nsegmentation.[* Corresponding author.]",
      "pdf_url": "http://arxiv.org/pdf/2502.09256v1",
      "published": "2025-02-13T12:11:58+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.09256v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "AnomalyGFM: Graph Foundation Model for Zero/Few-shot Anomaly Detection",
      "authors": [
        "Hezhe Qiao",
        "Chaoxi Niu",
        "Ling Chen",
        "Guansong Pang"
      ],
      "abstract": "Graph anomaly detection (GAD) aims to identify abnormal nodes that differ\nfrom the majority of the nodes in a graph, which has been attracting\nsignificant attention in recent years. Existing generalist graph models have\nachieved remarkable success in different graph tasks but struggle to generalize\nto the GAD task. This limitation arises from their difficulty in learning\ngeneralized knowledge for capturing the inherently infrequent, irregular and\nheterogeneous abnormality patterns in graphs from different domains. To address\nthis challenge, we propose AnomalyGFM, a GAD-oriented graph foundation model\nthat supports zero-shot inference and few-shot prompt tuning for GAD in diverse\ngraph datasets. One key insight is that graph-agnostic representations for\nnormal and abnormal classes are required to support effective zero/few-shot GAD\nacross different graphs. Motivated by this, AnomalyGFM is pre-trained to align\ndata-independent, learnable normal and abnormal class prototypes with node\nrepresentation residuals (i.e., representation deviation of a node from its\nneighbors). The residual features essentially project the node information into\na unified feature space where we can effectively measure the abnormality of\nnodes from different graphs in a consistent way. This provides a driving force\nfor the learning of graph-agnostic, discriminative prototypes for the normal\nand abnormal classes, which can be used to enable zero-shot GAD on new graphs,\nincluding very large-scale graphs. If there are few-shot labeled normal nodes\navailable in the new graphs, AnomalyGFM can further support prompt tuning to\nleverage these nodes for better adaptation. Comprehensive experiments on 11\nwidely-used GAD datasets with real anomalies, demonstrate that AnomalyGFM\nsignificantly outperforms state-of-the-art competing methods under both zero-\nand few-shot GAD settings.",
      "pdf_url": "http://arxiv.org/pdf/2502.09254v1",
      "published": "2025-02-13T12:10:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.09254v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "The Joint Entity-Relation Extraction Model Based on Span and Interactive Fusion Representation for Chinese Medical Texts with Complex Semantics",
      "authors": [
        "Danni Feng",
        "Runzhi Li",
        "Jing Wang",
        "Siyu Yan",
        "Lihong Ma",
        "Yunli Xing"
      ],
      "abstract": "Joint entity-relation extraction is a critical task in transforming\nunstructured or semi-structured text into triplets, facilitating the\nconstruction of large-scale knowledge graphs, and supporting various downstream\napplications. Despite its importance, research on Chinese text, particularly\nwith complex semantics in specialized domains like medicine, remains limited.\nTo address this gap, we introduce the CH-DDI, a Chinese drug-drug interactions\ndataset designed to capture the intricacies of medical text. Leveraging the\nstrengths of attention mechanisms in capturing long-range dependencies, we\npropose the SEA module, which enhances the extraction of complex contextual\nsemantic information, thereby improving entity recognition and relation\nextraction. Additionally, to address the inefficiencies of existing methods in\nfacilitating information exchange between entity recognition and relation\nextraction, we present an interactive fusion representation module. This module\nemploys Cross Attention for bidirectional information exchange between the\ntasks and further refines feature extraction through BiLSTM. Experimental\nresults on both our CH-DDI dataset and public CoNLL04 dataset demonstrate that\nour model exhibits strong generalization capabilities. On the CH-DDI dataset,\nour model achieves an F1-score of 96.73% for entity recognition and 78.43% for\nrelation extraction. On the CoNLL04 dataset, it attains an entity recognition\nprecision of 89.54% and a relation extraction accuracy of 71.64%.",
      "pdf_url": "http://arxiv.org/pdf/2502.09247v1",
      "published": "2025-02-13T12:03:36+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.09247v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "From large language models to multimodal AI: A scoping review on the potential of generative AI in medicine",
      "authors": [
        "Lukas Buess",
        "Matthias Keicher",
        "Nassir Navab",
        "Andreas Maier",
        "Soroosh Tayebi Arasteh"
      ],
      "abstract": "Generative artificial intelligence (AI) models, such as diffusion models and\nOpenAI's ChatGPT, are transforming medicine by enhancing diagnostic accuracy\nand automating clinical workflows. The field has advanced rapidly, evolving\nfrom text-only large language models for tasks such as clinical documentation\nand decision support to multimodal AI systems capable of integrating diverse\ndata modalities, including imaging, text, and structured data, within a single\nmodel. The diverse landscape of these technologies, along with rising interest,\nhighlights the need for a comprehensive review of their applications and\npotential. This scoping review explores the evolution of multimodal AI,\nhighlighting its methods, applications, datasets, and evaluation in clinical\nsettings. Adhering to PRISMA-ScR guidelines, we systematically queried PubMed,\nIEEE Xplore, and Web of Science, prioritizing recent studies published up to\nthe end of 2024. After rigorous screening, 144 papers were included, revealing\nkey trends and challenges in this dynamic field. Our findings underscore a\nshift from unimodal to multimodal approaches, driving innovations in diagnostic\nsupport, medical report generation, drug discovery, and conversational AI.\nHowever, critical challenges remain, including the integration of heterogeneous\ndata types, improving model interpretability, addressing ethical concerns, and\nvalidating AI systems in real-world clinical settings. This review summarizes\nthe current state of the art, identifies critical gaps, and provides insights\nto guide the development of scalable, trustworthy, and clinically impactful\nmultimodal AI solutions in healthcare.",
      "pdf_url": "http://arxiv.org/pdf/2502.09242v1",
      "published": "2025-02-13T11:57:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.09242v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Hybrid Answer Set Programming: Foundations and Applications",
      "authors": [
        "Nicolas Rühling"
      ],
      "abstract": "Answer Set Programming (ASP) is a powerful tool for solving real-world\nproblems. However, many problems involve numeric values and complex constraints\nbeyond the capabilities of standard ASP solvers. Hybrid solvers like CLINGCON\nand CLINGO[DL] address this by using specialized methods for specific\nconstraints. However, these solvers lack a strong theoretical foundation.\n  This issue has first been addressed by introducing the Logic of\nHere-and-There with constraints (HT_c) as an extension of the Logic of\nHere-and-There (HT) and its non-monotone extension Equilibrium Logic. Nowadays,\nHT serves as a logical foundation for ASP and has facilitated a broader\nunderstanding of this paradigm. The idea is that HTC (and other extensions)\nplay an analogous role for hybrid ASP.\n  There remain many open questions about these logics regarding their\nfundamental characteristics as well as their practical use in solvers, ie. how\nthey can guide the implementation.\n  Having a formal understanding of these hybrid logics is also needed to better\nunderstand the inherent structure of the (real-world) problems they are applied\nto and to improve their representations in ASP. As an example of an application\nof ASP we use product configuration.",
      "pdf_url": "http://arxiv.org/pdf/2502.09235v1",
      "published": "2025-02-13T11:53:57+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.09235v1",
      "categories": [
        "cs.AI",
        "cs.LO"
      ]
    },
    {
      "title": "Commonsense Reasoning-Aided Autonomous Vehicle Systems",
      "authors": [
        "Keegan Kimbrell"
      ],
      "abstract": "Autonomous Vehicle (AV) systems have been developed with a strong reliance on\nmachine learning techniques. While machine learning approaches, such as deep\nlearning, are extremely effective at tasks that involve observation and\nclassification, they struggle when it comes to performing higher level\nreasoning about situations on the road. This research involves incorporating\ncommonsense reasoning models that use image data to improve AV systems. This\nwill allow AV systems to perform more accurate reasoning while also making them\nmore adjustable, explainable, and ethical. This paper will discuss the findings\nso far and motivate its direction going forward.",
      "pdf_url": "http://arxiv.org/pdf/2502.09233v1",
      "published": "2025-02-13T11:53:25+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.09233v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Logical foundations of Smart Contracts",
      "authors": [
        "Kalonji Kalala"
      ],
      "abstract": "Nowadays, sophisticated domains are emerging which require appropriate\nformalisms to be specified accurately in order to reason about them. One such\ndomain is constituted of smart contracts that have emerged in cyber physical\nsystems as a way of enforcing formal agreements between components of these\nsystems. Smart contracts self-execute to run and share business processes\nthrough blockchain, in decentralized systems, with many different participants.\nLegal contracts are in many cases complex documents, with a number of\nexceptions, and many subcontracts. The implementation of smart contracts based\non legal contracts is a long and laborious task, that needs to include all\nactions, procedures, and the effects of actions related to the execution of the\ncontract. An ongoing open problem in this area is to formally account for smart\ncontracts using a uniform and somewhat universal formalism. This thesis\nproposes logical foundations to smart contracts using the Situation Calculus, a\nlogic for reasoning about actions. Situation Calculus is one of the prominent\nlogic-based artificial intelligence approaches that provides enough logical\nmechanism to specify and implement dynamic and complex systems such as\ncontracts. Situation Calculus is suitable to show how worlds dynamically\nchange. Smart contracts are going to be implement with Golog (written en\nProlog), a Situation Calculus-based programming language for modeling complex\nand dynamic behaviors.",
      "pdf_url": "http://arxiv.org/pdf/2502.09232v1",
      "published": "2025-02-13T11:53:10+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.09232v1",
      "categories": [
        "cs.LO",
        "cs.AI"
      ]
    },
    {
      "title": "Relating Answer Set Programming and Many-sorted Logics for Formal Verification",
      "authors": [
        "Zachary Hansen"
      ],
      "abstract": "Answer Set Programming (ASP) is an important logic programming paradigm\nwithin the field of Knowledge Representation and Reasoning. As a concise,\nhuman-readable, declarative language, ASP is an excellent tool for developing\ntrustworthy (especially, artificially intelligent) software systems. However,\nformally verifying ASP programs offers some unique challenges, such as\n  1. a lack of modularity (the meanings of rules are difficult to define in\nisolation from the enclosing program),\n  2. the ground-and-solve semantics (the meanings of rules are dependent on the\ninput data with which the program is grounded), and\n  3. limitations of existing tools.\n  My research agenda has been focused on addressing these three issues with the\nintention of making ASP verification an accessible, routine task that is\nregularly performed alongside program development. In this vein, I have\ninvestigated alternative semantics for ASP based on translations into the logic\nof here-and-there and many-sorted first-order logic. These semantics promote a\nmodular understanding of logic programs, bypass grounding, and enable us to use\nautomated theorem provers to automatically verify properties of programs.",
      "pdf_url": "http://arxiv.org/pdf/2502.09230v1",
      "published": "2025-02-13T11:52:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.09230v1",
      "categories": [
        "cs.LO",
        "cs.AI",
        "cs.PL"
      ]
    },
    {
      "title": "Computational methods for Dynamic Answer Set Programming",
      "authors": [
        "Susana Hahn"
      ],
      "abstract": "In our daily lives and industrial settings, we often encounter dynamic\nproblems that require reasoning over time and metric constraints. These include\ntasks such as scheduling, routing, and production sequencing. Dynamic logics\nhave traditionally addressed these needs but often lack the flexibility and\nintegration required for comprehensive problem modeling. This research aims to\nextend Answer Set Programming (ASP), a powerful declarative problem-solving\napproach, to handle dynamic domains effectively. By integrating concepts from\ndynamic, temporal, and metric logics into ASP, we seek to develop robust\nsystems capable of modeling complex dynamic problems and performing efficient\nreasoning tasks, thereby enhancing ASPs applicability in industrial contexts.",
      "pdf_url": "http://arxiv.org/pdf/2502.09228v1",
      "published": "2025-02-13T11:52:25+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.09228v1",
      "categories": [
        "cs.AI",
        "cs.FL",
        "cs.LO",
        "I.2.4; I.2.8"
      ]
    }
  ]
}