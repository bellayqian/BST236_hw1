{
  "last_updated": "2025-12-18T00:51:59.427213",
  "papers": [
    {
      "title": "TimeLens: Rethinking Video Temporal Grounding with Multimodal LLMs",
      "authors": [
        "Jun Zhang",
        "Teng Wang",
        "Yuying Ge",
        "Yixiao Ge",
        "Xinhao Li",
        "Ying Shan",
        "Limin Wang"
      ],
      "abstract": "This paper does not introduce a novel method but instead establishes a straightforward, incremental, yet essential baseline for video temporal grounding (VTG), a core capability in video understanding. While multimodal large language models (MLLMs) excel at various video understanding tasks, the recipes for optimizing them for VTG remain under-explored. In this paper, we present TimeLens, a systematic investigation into building MLLMs with strong VTG ability, along two primary dimensions: data quality and algorithmic design. We first expose critical quality issues in existing VTG benchmarks and introduce TimeLens-Bench, comprising meticulously re-annotated versions of three popular benchmarks with strict quality criteria. Our analysis reveals dramatic model re-rankings compared to legacy benchmarks, confirming the unreliability of prior evaluation standards. We also address noisy training data through an automated re-annotation pipeline, yielding TimeLens-100K, a large-scale, high-quality training dataset. Building on our data foundation, we conduct in-depth explorations of algorithmic design principles, yielding a series of meaningful insights and effective yet efficient practices. These include interleaved textual encoding for time representation, a thinking-free reinforcement learning with verifiable rewards (RLVR) approach as the training paradigm, and carefully designed recipes for RLVR training. These efforts culminate in TimeLens models, a family of MLLMs with state-of-the-art VTG performance among open-source models and even surpass proprietary models such as GPT-5 and Gemini-2.5-Flash. All codes, data, and models will be released to facilitate future research.",
      "pdf_url": "https://arxiv.org/pdf/2512.14698v1",
      "published": "2025-12-16T18:59:58+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.14698v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.MM"
      ]
    },
    {
      "title": "Spherical Leech Quantization for Visual Tokenization and Generation",
      "authors": [
        "Yue Zhao",
        "Hanwen Jiang",
        "Zhenlin Xu",
        "Chutong Yang",
        "Ehsan Adeli",
        "Philipp Krähenbühl"
      ],
      "abstract": "Non-parametric quantization has received much attention due to its efficiency on parameters and scalability to a large codebook. In this paper, we present a unified formulation of different non-parametric quantization methods through the lens of lattice coding. The geometry of lattice codes explains the necessity of auxiliary loss terms when training auto-encoders with certain existing lookup-free quantization variants such as BSQ. As a step forward, we explore a few possible candidates, including random lattices, generalized Fibonacci lattices, and densest sphere packing lattices. Among all, we find the Leech lattice-based quantization method, which is dubbed as Spherical Leech Quantization ($Λ_{24}$-SQ), leads to both a simplified training recipe and an improved reconstruction-compression tradeoff thanks to its high symmetry and even distribution on the hypersphere. In image tokenization and compression tasks, this quantization approach achieves better reconstruction quality across all metrics than BSQ, the best prior art, while consuming slightly fewer bits. The improvement also extends to state-of-the-art auto-regressive image generation frameworks.",
      "pdf_url": "https://arxiv.org/pdf/2512.14697v1",
      "published": "2025-12-16T18:59:57+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.14697v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "eess.SP"
      ]
    },
    {
      "title": "Universal Reasoning Model",
      "authors": [
        "Zitian Gao",
        "Lynx Chen",
        "Yihao Xiao",
        "He Xing",
        "Ran Tao",
        "Haoming Luo",
        "Joey Zhou",
        "Bryan Dai"
      ],
      "abstract": "Universal transformers (UTs) have been widely used for complex reasoning tasks such as ARC-AGI and Sudoku, yet the specific sources of their performance gains remain underexplored. In this work, we systematically analyze UTs variants and show that improvements on ARC-AGI primarily arise from the recurrent inductive bias and strong nonlinear components of Transformer, rather than from elaborate architectural designs. Motivated by this finding, we propose the Universal Reasoning Model (URM), which enhances the UT with short convolution and truncated backpropagation. Our approach substantially improves reasoning performance, achieving state-of-the-art 53.8% pass@1 on ARC-AGI 1 and 16.0% pass@1 on ARC-AGI 2. Our code is avaliable at https://github.com/zitian-gao/URM.",
      "pdf_url": "https://arxiv.org/pdf/2512.14693v1",
      "published": "2025-12-16T18:58:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.14693v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Native and Compact Structured Latents for 3D Generation",
      "authors": [
        "Jianfeng Xiang",
        "Xiaoxue Chen",
        "Sicheng Xu",
        "Ruicheng Wang",
        "Zelong Lv",
        "Yu Deng",
        "Hongyuan Zhu",
        "Yue Dong",
        "Hao Zhao",
        "Nicholas Jing Yuan",
        "Jiaolong Yang"
      ],
      "abstract": "Recent advancements in 3D generative modeling have significantly improved the generation realism, yet the field is still hampered by existing representations, which struggle to capture assets with complex topologies and detailed appearance. This paper present an approach for learning a structured latent representation from native 3D data to address this challenge. At its core is a new sparse voxel structure called O-Voxel, an omni-voxel representation that encodes both geometry and appearance. O-Voxel can robustly model arbitrary topology, including open, non-manifold, and fully-enclosed surfaces, while capturing comprehensive surface attributes beyond texture color, such as physically-based rendering parameters. Based on O-Voxel, we design a Sparse Compression VAE which provides a high spatial compression rate and a compact latent space. We train large-scale flow-matching models comprising 4B parameters for 3D generation using diverse public 3D asset datasets. Despite their scale, inference remains highly efficient. Meanwhile, the geometry and material quality of our generated assets far exceed those of existing models. We believe our approach offers a significant advancement in 3D generative modeling.",
      "pdf_url": "https://arxiv.org/pdf/2512.14692v1",
      "published": "2025-12-16T18:58:28+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.14692v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Spoken DialogSum: An Emotion-Rich Conversational Dataset for Spoken Dialogue Summarization",
      "authors": [
        "Yen-Ju Lu",
        "Kunxiao Gao",
        "Mingrui Liang",
        "Helin Wang",
        "Thomas Thebaud",
        "Laureano Moro-Velazquez",
        "Najim Dehak",
        "Jesus Villalba"
      ],
      "abstract": "Recent audio language models can follow long conversations. However, research on emotion-aware or spoken dialogue summarization is constrained by the lack of data that links speech, summaries, and paralinguistic cues. We introduce Spoken DialogSum, the first corpus aligning raw conversational audio with factual summaries, emotion-rich summaries, and utterance-level labels for speaker age, gender, and emotion. The dataset is built in two stages: first, an LLM rewrites DialogSum scripts with Switchboard-style fillers and back-channels, then tags each utterance with emotion, pitch, and speaking rate. Second, an expressive TTS engine synthesizes speech from the tagged scripts, aligned with paralinguistic labels. Spoken DialogSum comprises 13,460 emotion-diverse dialogues, each paired with both a factual and an emotion-focused summary. The dataset is available online at https://fatfat-emosum.github.io/EmoDialog-Sum-Audio-Samples/. Baselines show that an Audio-LLM raises emotional-summary ROUGE-L by 28% relative to a cascaded ASR-LLM system, confirming the value of end-to-end speech modeling.",
      "pdf_url": "https://arxiv.org/pdf/2512.14687v1",
      "published": "2025-12-16T18:54:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.14687v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ]
    },
    {
      "title": "Bias-Variance Trade-off for Clipped Stochastic First-Order Methods: From Bounded Variance to Infinite Mean",
      "authors": [
        "Chuan He"
      ],
      "abstract": "Stochastic optimization is fundamental to modern machine learning. Recent research has extended the study of stochastic first-order methods (SFOMs) from light-tailed to heavy-tailed noise, which frequently arises in practice, with clipping emerging as a key technique for controlling heavy-tailed gradients. Extensive theoretical advances have further shown that the oracle complexity of SFOMs depends on the tail index $α$ of the noise. Nonetheless, existing complexity results often cover only the case $α\\in (1,2]$, that is, the regime where the noise has a finite mean, while the complexity bounds tend to infinity as $α$ approaches $1$. This paper tackles the general case of noise with tail index $α\\in(0,2]$, covering regimes ranging from noise with bounded variance to noise with an infinite mean, where the latter case has been scarcely studied. Through a novel analysis of the bias-variance trade-off in gradient clipping, we show that when a symmetry measure of the noise tail is controlled, clipped SFOMs achieve improved complexity guarantees in the presence of heavy-tailed noise for any tail index $α\\in (0,2]$. Our analysis of the bias-variance trade-off not only yields new unified complexity guarantees for clipped SFOMs across this full range of tail indices, but is also straightforward to apply and can be combined with classical analyses under light-tailed noise to establish oracle complexity guarantees under heavy-tailed noise. Finally, numerical experiments validate our theoretical findings.",
      "pdf_url": "https://arxiv.org/pdf/2512.14686v1",
      "published": "2025-12-16T18:52:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.14686v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC",
        "stat.CO",
        "stat.ML"
      ]
    },
    {
      "title": "VASA-3D: Lifelike Audio-Driven Gaussian Head Avatars from a Single Image",
      "authors": [
        "Sicheng Xu",
        "Guojun Chen",
        "Jiaolong Yang",
        "Yizhong Zhang",
        "Yu Deng",
        "Steve Lin",
        "Baining Guo"
      ],
      "abstract": "We propose VASA-3D, an audio-driven, single-shot 3D head avatar generator. This research tackles two major challenges: capturing the subtle expression details present in real human faces, and reconstructing an intricate 3D head avatar from a single portrait image. To accurately model expression details, VASA-3D leverages the motion latent of VASA-1, a method that yields exceptional realism and vividness in 2D talking heads. A critical element of our work is translating this motion latent to 3D, which is accomplished by devising a 3D head model that is conditioned on the motion latent. Customization of this model to a single image is achieved through an optimization framework that employs numerous video frames of the reference head synthesized from the input image. The optimization takes various training losses robust to artifacts and limited pose coverage in the generated training data. Our experiment shows that VASA-3D produces realistic 3D talking heads that cannot be achieved by prior art, and it supports the online generation of 512x512 free-viewpoint videos at up to 75 FPS, facilitating more immersive engagements with lifelike 3D avatars.",
      "pdf_url": "https://arxiv.org/pdf/2512.14677v1",
      "published": "2025-12-16T18:44:00+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.14677v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "gridfm-datakit-v1: A Python Library for Scalable and Realistic Power Flow and Optimal Power Flow Data Generation",
      "authors": [
        "Alban Puech",
        "Matteo Mazzonelli",
        "Celia Cintas",
        "Tamara R. Govindasamy",
        "Mangaliso Mngomezulu",
        "Jonas Weiss",
        "Matteo Baù",
        "Anna Varbella",
        "François Mirallès",
        "Kibaek Kim",
        "Le Xie",
        "Hendrik F. Hamann",
        "Etienne Vos",
        "Thomas Brunschwiler"
      ],
      "abstract": "We introduce gridfm-datakit-v1, a Python library for generating realistic and diverse Power Flow (PF) and Optimal Power Flow (OPF) datasets for training Machine Learning (ML) solvers. Existing datasets and libraries face three main challenges: (1) lack of realistic stochastic load and topology perturbations, limiting scenario diversity; (2) PF datasets are restricted to OPF-feasible points, hindering generalization of ML solvers to cases that violate operating limits (e.g., branch overloads or voltage violations); and (3) OPF datasets use fixed generator cost functions, limiting generalization across varying costs. gridfm-datakit addresses these challenges by: (1) combining global load scaling from real-world profiles with localized noise and supporting arbitrary N-k topology perturbations to create diverse yet realistic datasets; (2) generating PF samples beyond operating limits; and (3) producing OPF data with varying generator costs. It also scales efficiently to large grids (up to 10,000 buses). Comparisons with OPFData, OPF-Learn, PGLearn, and PF$Δ$ are provided. Available on GitHub at https://github.com/gridfm/gridfm-datakit under Apache 2.0 and via `pip install gridfm-datakit`.",
      "pdf_url": "https://arxiv.org/pdf/2512.14658v1",
      "published": "2025-12-16T18:17:50+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.14658v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SY",
        "math.OC"
      ]
    },
    {
      "title": "A Multicenter Benchmark of Multiple Instance Learning Models for Lymphoma Subtyping from HE-stained Whole Slide Images",
      "authors": [
        "Rao Muhammad Umer",
        "Daniel Sens",
        "Jonathan Noll",
        "Christian Matek",
        "Lukas Wolfseher",
        "Rainer Spang",
        "Ralf Huss",
        "Johannes Raffler",
        "Sarah Reinke",
        "Wolfram Klapper",
        "Katja Steiger",
        "Kristina Schwamborn",
        "Carsten Marr"
      ],
      "abstract": "Timely and accurate lymphoma diagnosis is essential for guiding cancer treatment. Standard diagnostic practice combines hematoxylin and eosin (HE)-stained whole slide images with immunohistochemistry, flow cytometry, and molecular genetic tests to determine lymphoma subtypes, a process requiring costly equipment, skilled personnel, and causing treatment delays. Deep learning methods could assist pathologists by extracting diagnostic information from routinely available HE-stained slides, yet comprehensive benchmarks for lymphoma subtyping on multicenter data are lacking. In this work, we present the first multicenter lymphoma benchmarking dataset covering four common lymphoma subtypes and healthy control tissue. We systematically evaluate five publicly available pathology foundation models (H-optimus-1, H0-mini, Virchow2, UNI2, Titan) combined with attention-based (AB-MIL) and transformer-based (TransMIL) multiple instance learning aggregators across three magnifications (10x, 20x, 40x). On in-distribution test sets, models achieve multiclass balanced accuracies exceeding 80% across all magnifications, with all foundation models performing similarly and both aggregation methods showing comparable results. The magnification study reveals that 40x resolution is sufficient, with no performance gains from higher resolutions or cross-magnification aggregation. However, on out-of-distribution test sets, performance drops substantially to around 60%, highlighting significant generalization challenges. To advance the field, larger multicenter studies covering additional rare lymphoma subtypes are needed. We provide an automated benchmarking pipeline to facilitate such future research.",
      "pdf_url": "https://arxiv.org/pdf/2512.14640v1",
      "published": "2025-12-16T17:58:03+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.14640v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "MuseCPBench: an Empirical Study of Music Editing Methods through Music Context Preservation",
      "authors": [
        "Yash Vishe",
        "Eric Xue",
        "Xunyi Jiang",
        "Zachary Novack",
        "Junda Wu",
        "Julian McAuley",
        "Xin Xu"
      ],
      "abstract": "Music editing plays a vital role in modern music production, with applications in film, broadcasting, and game development. Recent advances in music generation models have enabled diverse editing tasks such as timbre transfer, instrument substitution, and genre transformation. However, many existing works overlook the evaluation of their ability to preserve musical facets that should remain unchanged during editing a property we define as Music Context Preservation (MCP). While some studies do consider MCP, they adopt inconsistent evaluation protocols and metrics, leading to unreliable and unfair comparisons. To address this gap, we introduce the first MCP evaluation benchmark, MuseCPBench, which covers four categories of musical facets and enables comprehensive comparisons across five representative music editing baselines. Through systematic analysis along musical facets, methods, and models, we identify consistent preservation gaps in current music editing methods and provide insightful explanations. We hope our findings offer practical guidance for developing more effective and reliable music editing strategies with strong MCP capability",
      "pdf_url": "https://arxiv.org/pdf/2512.14629v1",
      "published": "2025-12-16T17:44:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.14629v1",
      "categories": [
        "cs.SD",
        "cs.AI"
      ]
    },
    {
      "title": "JMMMU-Pro: Image-based Japanese Multi-discipline Multimodal Understanding Benchmark via Vibe Benchmark Construction",
      "authors": [
        "Atsuyuki Miyai",
        "Shota Onohara",
        "Jeonghun Baek",
        "Kiyoharu Aizawa"
      ],
      "abstract": "This paper introduces JMMMU-Pro, an image-based Japanese Multi-discipline Multimodal Understanding Benchmark, and Vibe Benchmark Construction, a scalable construction method. Following the evolution from MMMU to MMMU-Pro, JMMMU-Pro extends JMMMU by composing the question image and question text into a single image, thereby creating a benchmark that requires integrated visual-textual understanding through visual perception. To build JMMMU-Pro, we propose Vibe Benchmark Construction, a methodology in which an image generative model (e.g., Nano Banana Pro) produces candidate visual questions, and humans verify the outputs and, when necessary, regenerate with adjusted prompts to ensure quality. By leveraging Nano Banana Pro's highly realistic image generation capabilities and its ability to embed clean Japanese text, we construct a high-quality benchmark at low cost, covering a wide range of background and layout designs. Experimental results show that all open-source LMMs struggle substantially with JMMMU-Pro, underscoring JMMMU-Pro as an important benchmark for guiding future efforts in the open-source community. We believe that JMMMU-Pro provides a more rigorous evaluation tool for assessing the Japanese capabilities of LMMs and that our Vibe Benchmark Construction also offers an efficient guideline for future development of image-based VQA benchmarks.",
      "pdf_url": "https://arxiv.org/pdf/2512.14620v1",
      "published": "2025-12-16T17:33:00+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.14620v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Model-Based Reinforcement Learning in Discrete-Action Non-Markovian Reward Decision Processes",
      "authors": [
        "Alessandro Trapasso",
        "Luca Iocchi",
        "Fabio Patrizi"
      ],
      "abstract": "Many practical decision-making problems involve tasks whose success depends on the entire system history, rather than on achieving a state with desired properties. Markovian Reinforcement Learning (RL) approaches are not suitable for such tasks, while RL with non-Markovian reward decision processes (NMRDPs) enables agents to tackle temporal-dependency tasks. This approach has long been known to lack formal guarantees on both (near-)optimality and sample efficiency. We contribute to solving both issues with QR-MAX, a novel model-based algorithm for discrete NMRDPs that factorizes Markovian transition learning from non-Markovian reward handling via reward machines. To the best of our knowledge, this is the first model-based RL algorithm for discrete-action NMRDPs that exploits this factorization to obtain PAC convergence to $\\varepsilon$-optimal policies with polynomial sample complexity. We then extend QR-MAX to continuous state spaces with Bucket-QR-MAX, a SimHash-based discretiser that preserves the same factorized structure and achieves fast and stable learning without manual gridding or function approximation. We experimentally compare our method with modern state-of-the-art model-based RL approaches on environments of increasing complexity, showing a significant improvement in sample efficiency and increased robustness in finding optimal policies.",
      "pdf_url": "https://arxiv.org/pdf/2512.14617v1",
      "published": "2025-12-16T17:26:24+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.14617v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "FakeRadar: Probing Forgery Outliers to Detect Unknown Deepfake Videos",
      "authors": [
        "Zhaolun Li",
        "Jichang Li",
        "Yinqi Cai",
        "Junye Chen",
        "Xiaonan Luo",
        "Guanbin Li",
        "Rushi Lan"
      ],
      "abstract": "In this paper, we propose FakeRadar, a novel deepfake video detection framework designed to address the challenges of cross-domain generalization in real-world scenarios. Existing detection methods typically rely on manipulation-specific cues, performing well on known forgery types but exhibiting severe limitations against emerging manipulation techniques. This poor generalization stems from their inability to adapt effectively to unseen forgery patterns. To overcome this, we leverage large-scale pretrained models (e.g. CLIP) to proactively probe the feature space, explicitly highlighting distributional gaps between real videos, known forgeries, and unseen manipulations. Specifically, FakeRadar introduces Forgery Outlier Probing, which employs dynamic subcluster modeling and cluster-conditional outlier generation to synthesize outlier samples near boundaries of estimated subclusters, simulating novel forgery artifacts beyond known manipulation types. Additionally, we design Outlier-Guided Tri-Training, which optimizes the detector to distinguish real, fake, and outlier samples using proposed outlier-driven contrastive learning and outlier-conditioned cross-entropy losses. Experiments show that FakeRadar outperforms existing methods across various benchmark datasets for deepfake video detection, particularly in cross-domain evaluations, by handling the variety of emerging manipulation techniques.",
      "pdf_url": "https://arxiv.org/pdf/2512.14601v1",
      "published": "2025-12-16T17:11:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.14601v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Towards Nepali-language LLMs: Efficient GPT training with a Nepali BPE tokenizer",
      "authors": [
        "Adarsha Shrestha",
        "Basanta Pokharel",
        "Binit Shrestha",
        "Smriti Adhikari",
        "Dinesh Gothe"
      ],
      "abstract": "Nepali, a low-resource language spoken by over 32 million people, continues to face challenges in natural language processing (NLP) due to its complex grammar, agglutinative morphology, and limited availability of high-quality corpora. Most efforts to date have centered on basic encoder architectures; they remain insufficient for Nepali-specific text generation. This study presents a GPT-2-based Nepali language model trained using several training strategies inspired by GPT-3, including optimized learning rate schedules, batch scaling, and architectural refinements. A custom 16k Byte-Pair Encoding (BPE) tokenizer was trained exclusively on Nepali text to ensure more consistent segmentation and improved input representation. The model was pretrained on a combined dataset comprising a 10.75GB cleaned NepBERTa corpus and additional web-scraped Nepali news articles. FlashAttention was integrated to reduce memory usage and stabilize training. After two epochs, the model achieved a training loss of 3.168177, a validation loss of 3.081982, and a final perplexity of 21.80, demonstrating its capability to generate coherent Nepali news-style text.",
      "pdf_url": "https://arxiv.org/pdf/2512.14585v1",
      "published": "2025-12-16T16:53:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.14585v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Low-Resource, High-Impact: Building Corpora for Inclusive Language Technologies",
      "authors": [
        "Ekaterina Artemova",
        "Laurie Burchell",
        "Daryna Dementieva",
        "Shu Okabe",
        "Mariya Shmatova",
        "Pedro Ortiz Suarez"
      ],
      "abstract": "This tutorial (https://tum-nlp.github.io/low-resource-tutorial) is designed for NLP practitioners, researchers, and developers working with multilingual and low-resource languages who seek to create more equitable and socially impactful language technologies. Participants will walk away with a practical toolkit for building end-to-end NLP pipelines for underrepresented languages -- from data collection and web crawling to parallel sentence mining, machine translation, and downstream applications such as text classification and multimodal reasoning. The tutorial presents strategies for tackling the challenges of data scarcity and cultural variance, offering hands-on methods and modeling frameworks. We will focus on fair, reproducible, and community-informed development approaches, grounded in real-world scenarios. We will showcase a diverse set of use cases covering over 10 languages from different language families and geopolitical contexts, including both digitally resource-rich and severely underrepresented languages.",
      "pdf_url": "https://arxiv.org/pdf/2512.14576v1",
      "published": "2025-12-16T16:44:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.14576v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Residual GRU+MHSA: A Lightweight Hybrid Recurrent Attention Model for Cardiovascular Disease Detection",
      "authors": [
        "Tejaswani Dash",
        "Gautam Datla",
        "Anudeep Vurity",
        "Tazeem Ahmad",
        "Mohd Adnan",
        "Saima Rafi",
        "Saisha Patro",
        "Saina Patro"
      ],
      "abstract": "Cardiovascular disease (CVD) remains the leading cause of mortality worldwide, underscoring the need for reliable and efficient predictive tools that support early intervention. Traditional diagnostic approaches rely on handcrafted features and clinician expertise, while machine learning methods improve reproducibility but often struggle to generalize across noisy and heterogeneous clinical data. In this work, we propose Residual GRU with Multi-Head Self-Attention, a compact deep learning architecture designed for tabular clinical records. The model integrates residual bidirectional gated recurrent units for sequential modeling of feature columns, a channel reweighting block, and multi-head self-attention pooling with a learnable classification token to capture global context. We evaluate the model on the UCI Heart Disease dataset using 5-fold stratified cross-validation and compare it against classical methods such as Logistic Regression, Random Forest, and Support Vector Machines, as well as modern deep learning baselines including DeepMLP, convolutional networks, recurrent networks, and Transformers. The proposed model achieves an accuracy of 0.861, macro-F1 of 0.860, ROC-AUC of 0.908, and PR-AUC of 0.904, outperforming all baselines. Ablation studies confirm the individual contributions of residual recurrence, channel gating, and attention pooling. t-SNE visualizations further indicate that the learned embeddings exhibit clearer separation between disease and non-disease classes compared to raw features. These results demonstrate that lightweight hybrid recurrent and attention-based architectures provide a strong balance between accuracy and efficiency for clinical risk prediction, supporting deployment in resource-constrained healthcare settings.",
      "pdf_url": "https://arxiv.org/pdf/2512.14563v1",
      "published": "2025-12-16T16:33:59+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.14563v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Polypersona: Persona-Grounded LLM for Synthetic Survey Responses",
      "authors": [
        "Tejaswani Dash",
        "Dinesh Karri",
        "Anudeep Vurity",
        "Gautam Datla",
        "Tazeem Ahmad",
        "Saima Rafi",
        "Rohith Tangudu"
      ],
      "abstract": "This paper introduces PolyPersona, a generative framework for synthesizing persona-conditioned survey responses across multiple domains. The framework instruction-tunes compact chat models using parameter-efficient LoRA adapters with 4-bit quantization under a resource-adaptive training setup. A dialogue-based data pipeline explicitly preserves persona cues, ensuring consistent behavioral alignment across generated responses. Using this pipeline, we construct a dataset of 3,568 synthetic survey responses spanning ten domains and 433 distinct personas, enabling controlled instruction tuning and systematic multi-domain evaluation. We evaluate the generated responses using a multi-metric evaluation suite that combines standard text generation metrics, including BLEU, ROUGE, and BERTScore, with survey-specific metrics designed to assess structural coherence, stylistic consistency, and sentiment alignment.Experimental results show that compact models such as TinyLlama 1.1B and Phi-2 achieve performance comparable to larger 7B to 8B baselines, with a highest BLEU score of 0.090 and ROUGE-1 of 0.429. These findings demonstrate that persona-conditioned fine-tuning enables small language models to generate reliable and coherent synthetic survey data. The proposed framework provides an efficient and reproducible approach for survey data generation, supporting scalable evaluation while facilitating bias analysis through transparent and open protocols.",
      "pdf_url": "https://arxiv.org/pdf/2512.14562v1",
      "published": "2025-12-16T16:33:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.14562v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "CLNet: Cross-View Correspondence Makes a Stronger Geo-Localizationer",
      "authors": [
        "Xianwei Cao",
        "Dou Quan",
        "Shuang Wang",
        "Ning Huyan",
        "Wei Wang",
        "Yunan Li",
        "Licheng Jiao"
      ],
      "abstract": "Image retrieval-based cross-view geo-localization (IRCVGL) aims to match images captured from significantly different viewpoints, such as satellite and street-level images. Existing methods predominantly rely on learning robust global representations or implicit feature alignment, which often fail to model explicit spatial correspondences crucial for accurate localization. In this work, we propose a novel correspondence-aware feature refinement framework, termed CLNet, that explicitly bridges the semantic and geometric gaps between different views. CLNet decomposes the view alignment process into three learnable and complementary modules: a Neural Correspondence Map (NCM) that spatially aligns cross-view features via latent correspondence fields; a Nonlinear Embedding Converter (NEC) that remaps features across perspectives using an MLP-based transformation; and a Global Feature Recalibration (GFR) module that reweights informative feature channels guided by learned spatial cues. The proposed CLNet can jointly capture both high-level semantics and fine-grained alignments. Extensive experiments on four public benchmarks, CVUSA, CVACT, VIGOR, and University-1652, demonstrate that our proposed CLNet achieves state-of-the-art performance while offering better interpretability and generalizability.",
      "pdf_url": "https://arxiv.org/pdf/2512.14560v1",
      "published": "2025-12-16T16:31:41+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.14560v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "VLegal-Bench: Cognitively Grounded Benchmark for Vietnamese Legal Reasoning of Large Language Models",
      "authors": [
        "Nguyen Tien Dong",
        "Minh-Anh Nguyen",
        "Thanh Dat Hoang",
        "Nguyen Tuan Ngoc",
        "Dao Xuan Quang Minh",
        "Phan Phi Hai",
        "Nguyen Thi Ngoc Anh",
        "Dang Van Tu",
        "Binh Vu"
      ],
      "abstract": "The rapid advancement of large language models (LLMs) has enabled new possibilities for applying artificial intelligence within the legal domain. Nonetheless, the complexity, hierarchical organization, and frequent revisions of Vietnamese legislation pose considerable challenges for evaluating how well these models interpret and utilize legal knowledge. To address this gap, Vietnamese Legal Benchmark (VLegal-Bench) is introduced, the first comprehensive benchmark designed to systematically assess LLMs on Vietnamese legal tasks. Informed by Bloom's cognitive taxonomy, VLegal-Bench encompasses multiple levels of legal understanding through tasks designed to reflect practical usage scenarios. The benchmark comprises 10,450 samples generated through a rigorous annotation pipeline, where legal experts label and cross-validate each instance using our annotation system to ensure every sample is grounded in authoritative legal documents and mirrors real-world legal assistant workflows, including general legal questions and answers, retrieval-augmented generation, multi-step reasoning, and scenario-based problem solving tailored to Vietnamese law. By providing a standardized, transparent, and cognitively informed evaluation framework, VLegal-Bench establishes a solid foundation for assessing LLM performance in Vietnamese legal contexts and supports the development of more reliable, interpretable, and ethically aligned AI-assisted legal systems.",
      "pdf_url": "https://arxiv.org/pdf/2512.14554v1",
      "published": "2025-12-16T16:28:32+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.14554v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Dual Language Models: Balancing Training Efficiency and Overfitting Resilience",
      "authors": [
        "David Samuel",
        "Lucas Georges Gabriel Charpentier"
      ],
      "abstract": "This paper combines autoregressive and masked-diffusion training objectives without any architectural modifications, resulting in flexible language models that outperform single-objective models. Autoregressive modeling has been a popular approach, partly because of its training efficiency; however, that comes at the cost of sensitivity to overfitting. On the other hand, masked-diffusion models are less efficient to train while being more resilient to overfitting. In this work, we demonstrate that dual-objective training achieves the best of both worlds. To derive the optimal ratio between both objectives, we train and evaluate 50 language models under varying levels of data repetition. We show that it is optimal to combine both objectives under all evaluated settings and that the optimal ratio is similar whether targeting autoregressive or masked-diffusion downstream performance.",
      "pdf_url": "https://arxiv.org/pdf/2512.14549v1",
      "published": "2025-12-16T16:25:33+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.14549v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "CAPRMIL: Context-Aware Patch Representations for Multiple Instance Learning",
      "authors": [
        "Andreas Lolos",
        "Theofilos Christodoulou",
        "Aris L. Moustakas",
        "Stergios Christodoulidis",
        "Maria Vakalopoulou"
      ],
      "abstract": "In computational pathology, weak supervision has become the standard for deep learning due to the gigapixel scale of WSIs and the scarcity of pixel-level annotations, with Multiple Instance Learning (MIL) established as the principal framework for slide-level model training. In this paper, we introduce a novel setting for MIL methods, inspired by proceedings in Neural Partial Differential Equation (PDE) Solvers. Instead of relying on complex attention-based aggregation, we propose an efficient, aggregator-agnostic framework that removes the complexity of correlation learning from the MIL aggregator. CAPRMIL produces rich context-aware patch embeddings that promote effective correlation learning on downstream tasks. By projecting patch features -- extracted using a frozen patch encoder -- into a small set of global context/morphology-aware tokens and utilizing multi-head self-attention, CAPRMIL injects global context with linear computational complexity with respect to the bag size. Paired with a simple Mean MIL aggregator, CAPRMIL matches state-of-the-art slide-level performance across multiple public pathology benchmarks, while reducing the total number of trainable parameters by 48%-92.8% versus SOTA MILs, lowering FLOPs during inference by 52%-99%, and ranking among the best models on GPU memory efficiency and training time. Our results indicate that learning rich, context-aware instance representations before aggregation is an effective and scalable alternative to complex pooling for whole-slide analysis. Our code is available at https://github.com/mandlos/CAPRMIL",
      "pdf_url": "https://arxiv.org/pdf/2512.14540v1",
      "published": "2025-12-16T16:16:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.14540v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Dynamic Learning Rate Scheduling based on Loss Changes Leads to Faster Convergence",
      "authors": [
        "Shreyas Subramanian",
        "Bala Krishnamoorthy",
        "Pranav Murthy"
      ],
      "abstract": "Despite significant advances in optimizers for training, most research works use common scheduler choices like Cosine or exponential decay. In this paper, we study \\emph{GreedyLR}, a novel scheduler that adaptively adjusts the learning rate during training based on the current loss. To validate the effectiveness of our proposed scheduler, we conduct experiments on several NLP, CV, and LLM tasks with up to $7B$ parameters, including both fine-tuning and pre-training experiments. The results show that our approach outperforms several state-of-the-art schedulers in terms of accuracy, speed, and convergence. We also provide a theoretical analysis of the GreedyLR algorithm, including a proof of convergence and derivation of the optimal scaling factor $F$ that maximizes the convergence rate, along with experiments to show robustness of the algorithm to realistic noisy landscapes. Our scheduler is easy to implement, computationally efficient, and could be considered a good default scheduler for training.",
      "pdf_url": "https://arxiv.org/pdf/2512.14527v1",
      "published": "2025-12-16T16:03:52+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.14527v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Sparse Multi-Modal Transformer with Masking for Alzheimer's Disease Classification",
      "authors": [
        "Cheng-Han Lu",
        "Pei-Hsuan Tsai"
      ],
      "abstract": "Transformer-based multi-modal intelligent systems often suffer from high computational and energy costs due to dense self-attention, limiting their scalability under resource constraints. This paper presents SMMT, a sparse multi-modal transformer architecture designed to improve efficiency and robustness. Building upon a cascaded multi-modal transformer framework, SMMT introduces cluster-based sparse attention to achieve near linear computational complexity and modality-wise masking to enhance robustness against incomplete inputs. The architecture is evaluated using Alzheimer's Disease classification on the ADNI dataset as a representative multi-modal case study. Experimental results show that SMMT maintains competitive predictive performance while significantly reducing training time, memory usage, and energy consumption compared to dense attention baselines, demonstrating its suitability as a resource-aware architectural component for scalable intelligent systems.",
      "pdf_url": "https://arxiv.org/pdf/2512.14491v1",
      "published": "2025-12-16T15:24:57+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.14491v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "SASQ: Static Activation Scaling for Quantization-Aware Training in Large Language Models",
      "authors": [
        "Shizhuo Mao",
        "Song Chen",
        "Yi Kang"
      ],
      "abstract": "Large language models (LLMs) excel at natural language tasks but face deployment challenges due to their growing size outpacing GPU memory advancements. Model quantization mitigates this issue by lowering weight and activation precision, but existing solutions face fundamental trade-offs: dynamic quantization incurs high computational overhead and poses deployment challenges on edge devices, while static quantization sacrifices accuracy. Existing approaches of quantization-aware training (QAT) further suffer from weight training costs. We propose SASQ: a lightweight QAT framework specifically tailored for activation quantization factors. SASQ exclusively optimizes only the quantization factors (without changing pre-trained weights), enabling static inference with high accuracy while maintaining deployment efficiency. SASQ adaptively truncates some outliers, thereby reducing the difficulty of quantization while preserving the distributional characteristics of the activations. SASQ not only surpasses existing SOTA quantization schemes but also outperforms the corresponding FP16 models. On LLaMA2-7B, it achieves 5.2% lower perplexity than QuaRot and 4.7% lower perplexity than the FP16 model on WikiText2.",
      "pdf_url": "https://arxiv.org/pdf/2512.14481v1",
      "published": "2025-12-16T15:12:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.14481v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "TACK Tunnel Data (TTD): A Benchmark Dataset for Deep Learning-Based Defect Detection in Tunnels",
      "authors": [
        "Andreas Sjölander",
        "Valeria Belloni",
        "Robel Fekadu",
        "Andrea Nascetti"
      ],
      "abstract": "Tunnels are essential elements of transportation infrastructure, but are increasingly affected by ageing and deterioration mechanisms such as cracking. Regular inspections are required to ensure their safety, yet traditional manual procedures are time-consuming, subjective, and costly. Recent advances in mobile mapping systems and Deep Learning (DL) enable automated visual inspections. However, their effectiveness is limited by the scarcity of tunnel datasets. This paper introduces a new publicly available dataset containing annotated images of three different tunnel linings, capturing typical defects: cracks, leaching, and water infiltration. The dataset is designed to support supervised, semi-supervised, and unsupervised DL methods for defect detection and segmentation. Its diversity in texture and construction techniques also enables investigation of model generalization and transferability across tunnel types. By addressing the critical lack of domain-specific data, this dataset contributes to advancing automated tunnel inspection and promoting safer, more efficient infrastructure maintenance strategies.",
      "pdf_url": "https://arxiv.org/pdf/2512.14477v1",
      "published": "2025-12-16T15:10:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.14477v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Model-First Reasoning LLM Agents: Reducing Hallucinations through Explicit Problem Modeling",
      "authors": [
        "Annu Rana",
        "Gaurav Kumar"
      ],
      "abstract": "Large Language Models (LLMs) often struggle with complex multi-step planning tasks, showing high rates of constraint violations and inconsistent solutions. Existing strategies such as Chain-of-Thought and ReAct rely on implicit state tracking and lack an explicit problem representation. Inspired by classical AI planning, we propose Model-First Reasoning (MFR), a two-phase paradigm in which the LLM first constructs an explicit model of the problem, defining entities, state variables, actions, and constraints, before generating a solution plan. Across multiple planning domains, including medical scheduling, route planning, resource allocation, logic puzzles, and procedural synthesis, MFR reduces constraint violations and improves solution quality compared to Chain-of-Thought and ReAct. Ablation studies show that the explicit modeling phase is critical for these gains. Our results suggest that many LLM planning failures stem from representational deficiencies rather than reasoning limitations, highlighting explicit modeling as a key component for robust and interpretable AI agents. All prompts, evaluation procedures, and task datasets are documented to facilitate reproducibility.",
      "pdf_url": "https://arxiv.org/pdf/2512.14474v1",
      "published": "2025-12-16T15:07:36+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.14474v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Context-Picker: Dynamic context selection using multi-stage reinforcement learning",
      "authors": [
        "Siyuan Zhu",
        "Chengdong Xu",
        "Kaiqiang Ke",
        "Chao Yu"
      ],
      "abstract": "In long-context question answering (LCQA), determining the optimal amount of context for a given query is a significant challenge. Including too few passages may omit critical information, while including too many can introduce noise and reduce the quality of the answer. Traditional approaches, such as fixed Top-$K$ retrieval and single-stage reranking, face the dilemma of selecting the right number of passages. This problem is particularly pronounced for factoid questions, which often require only a few specific pieces of evidence. To address this issue, we introduce \\emph{Context-Picker}, a reasoning-aware framework that shifts the paradigm from similarity-based ranking to minimal sufficient subset selection. Context-Picker treats context selection as a decision-making process optimized via a human-inspired, two-stage reinforcement learning schedule: a \\emph{recall-oriented} stage that prioritizes the coverage of reasoning chains, followed by a \\emph{precision-oriented} stage that aggressively prunes redundancy to distill a compact evidence set. To resolve reward sparsity, we propose an offline evidence distillation pipeline that mines \"minimal sufficient sets\" via a Leave-One-Out (LOO) procedure, providing dense, task-aligned supervision. Experiments on five long-context and multi-hop QA benchmarks demonstrate that Context-Picker significantly outperforms strong RAG baselines, achieving superior answer accuracy with comparable or reduced context lengths. Ablation studies indicate that the coarse-to-fine optimization schedule, the redundancy-aware reward shaping, and the rationale-guided format all contribute substantially to these gains.",
      "pdf_url": "https://arxiv.org/pdf/2512.14465v1",
      "published": "2025-12-16T14:52:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.14465v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Reasoning-Style Poisoning of LLM Agents via Stealthy Style Transfer: Process-Level Attacks and Runtime Monitoring in RSV Space",
      "authors": [
        "Xingfu Zhou",
        "Pengfei Wang"
      ],
      "abstract": "Large Language Model (LLM) agents relying on external retrieval are increasingly deployed in high-stakes environments. While existing adversarial attacks primarily focus on content falsification or instruction injection, we identify a novel, process-oriented attack surface: the agent's reasoning style. We propose Reasoning-Style Poisoning (RSP), a paradigm that manipulates how agents process information rather than what they process. We introduce Generative Style Injection (GSI), an attack method that rewrites retrieved documents into pathological tones--specifically \"analysis paralysis\" or \"cognitive haste\"--without altering underlying facts or using explicit triggers. To quantify these shifts, we develop the Reasoning Style Vector (RSV), a metric tracking Verification depth, Self-confidence, and Attention focus. Experiments on HotpotQA and FEVER using ReAct, Reflection, and Tree of Thoughts (ToT) architectures reveal that GSI significantly degrades performance. It increases reasoning steps by up to 4.4 times or induces premature errors, successfully bypassing state-of-the-art content filters. Finally, we propose RSP-M, a lightweight runtime monitor that calculates RSV metrics in real-time and triggers alerts when values exceed safety thresholds. Our work demonstrates that reasoning style is a distinct, exploitable vulnerability, necessitating process-level defenses beyond static content analysis.",
      "pdf_url": "https://arxiv.org/pdf/2512.14448v1",
      "published": "2025-12-16T14:34:10+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.14448v1",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "title": "Seismology modeling agent: A smart assistant for geophysical researchers",
      "authors": [
        "Yukun Ren",
        "Siwei Yu",
        "Kai Chen",
        "Jianwei Ma"
      ],
      "abstract": "To address the steep learning curve and reliance on complex manual file editing and command-line operations in the traditional workflow of the mainstream open-source seismic wave simulation software SPECFEM, this paper proposes an intelligent, interactive workflow powered by Large Language Models (LLMs). We introduce the first Model Context Protocol (MCP) server suite for SPECFEM (supporting 2D, 3D Cartesian, and 3D Globe versions), which decomposes the entire simulation process into discrete, agent-executable tools spanning from parameter generation and mesh partitioning to solver execution and visualization. This approach enables a paradigm shift from file-driven to intent-driven conversational interactions. The framework supports both fully automated execution and human-in-the-loop collaboration, allowing researchers to guide simulation strategies in real time and retain scientific decision-making authority while significantly reducing tedious low-level operations. Validated through multiple case studies, the workflow operates seamlessly in both autonomous and interactive modes, yielding high-fidelity results consistent with standard baselines. As the first application of MCP technology to computational seismology, this study significantly lowers the entry barrier, enhances reproducibility, and offers a promising avenue for advancing computational geophysics toward AI-assisted and automated scientific research. The complete source code is available at https://github.com/RenYukun1563/specfem-mcp.",
      "pdf_url": "https://arxiv.org/pdf/2512.14429v1",
      "published": "2025-12-16T14:18:26+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.14429v1",
      "categories": [
        "cs.AI",
        "cs.SE"
      ]
    },
    {
      "title": "Effect of Document Packing on the Latent Multi-Hop Reasoning Capabilities of Large Language Models",
      "authors": [
        "Gabriele Prato",
        "Shagun Sodhani",
        "Alessandro Sordoni",
        "Sarath Chandar"
      ],
      "abstract": "The standard practice for training large language models involves packing multiple documents together to optimize computational efficiency. However, the impact of this process on the models' capabilities remains largely unexplored. To address this gap, we investigate how different document-packing strategies influence the latent multi-hop reasoning abilities of LLMs. Our findings indicate that packing can improve model performance compared to training on individual documents, at the expense of more compute. To further understand the underlying mechanisms, we conduct an ablation study, identifying key factors that explain the advantages of packing. Ultimately, our research deepens the understanding of LLM training dynamics and provides practical insights for optimizing model development.",
      "pdf_url": "https://arxiv.org/pdf/2512.14427v1",
      "published": "2025-12-16T14:16:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.14427v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "DISCODE: Distribution-Aware Score Decoder for Robust Automatic Evaluation of Image Captioning",
      "authors": [
        "Nakamasa Inoue",
        "Kanoko Goto",
        "Masanari Oi",
        "Martyna Gruszka",
        "Mahiro Ukai",
        "Takumi Hirose",
        "Yusuke Sekikawa"
      ],
      "abstract": "Large vision-language models (LVLMs) have shown impressive performance across a broad range of multimodal tasks. However, robust image caption evaluation using LVLMs remains challenging, particularly under domain-shift scenarios. To address this issue, we introduce the Distribution-Aware Score Decoder (DISCODE), a novel finetuning-free method that generates robust evaluation scores better aligned with human judgments across diverse domains. The core idea behind DISCODE lies in its test-time adaptive evaluation approach, which introduces the Adaptive Test-Time (ATT) loss, leveraging a Gaussian prior distribution to improve robustness in evaluation score estimation. This loss is efficiently minimized at test time using an analytical solution that we derive. Furthermore, we introduce the Multi-domain Caption Evaluation (MCEval) benchmark, a new image captioning evaluation benchmark covering six distinct domains, designed to assess the robustness of evaluation metrics. In our experiments, we demonstrate that DISCODE achieves state-of-the-art performance as a reference-free evaluation metric across MCEval and four representative existing benchmarks.",
      "pdf_url": "https://arxiv.org/pdf/2512.14420v1",
      "published": "2025-12-16T14:06:35+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.14420v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "PortAgent: LLM-driven Vehicle Dispatching Agent for Port Terminals",
      "authors": [
        "Jia Hu",
        "Junqi Li",
        "Weimeng Lin",
        "Peng Jia",
        "Yuxiong Ji",
        "Jintao Lai"
      ],
      "abstract": "Vehicle Dispatching Systems (VDSs) are critical to the operational efficiency of Automated Container Terminals (ACTs). However, their widespread commercialization is hindered due to their low transferability across diverse terminals. This transferability challenge stems from three limitations: high reliance on port operational specialists, a high demand for terminal-specific data, and time-consuming manual deployment processes. Leveraging the emergence of Large Language Models (LLMs), this paper proposes PortAgent, an LLM-driven vehicle dispatching agent that fully automates the VDS transferring workflow. It bears three features: (1) no need for port operations specialists; (2) low need of data; and (3) fast deployment. Specifically, specialist dependency is eliminated by the Virtual Expert Team (VET). The VET collaborates with four virtual experts, including a Knowledge Retriever, Modeler, Coder, and Debugger, to emulate a human expert team for the VDS transferring workflow. These experts specialize in the domain of terminal VDS via a few-shot example learning approach. Through this approach, the experts are able to learn VDS-domain knowledge from a few VDS examples. These examples are retrieved via a Retrieval-Augmented Generation (RAG) mechanism, mitigating the high demand for terminal-specific data. Furthermore, an automatic VDS design workflow is established among these experts to avoid extra manual interventions. In this workflow, a self-correction loop inspired by the LLM Reflexion framework is created",
      "pdf_url": "https://arxiv.org/pdf/2512.14417v1",
      "published": "2025-12-16T14:04:50+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.14417v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Massive Editing for Large Language Models Based on Dynamic Weight Generation",
      "authors": [
        "Wentao Wan",
        "Qiqing Lao",
        "Zhiwei Xie",
        "Hefeng Wu",
        "Runnan Lin",
        "Liang Lin",
        "Keze Wang"
      ],
      "abstract": "Knowledge Editing (KE) is a field that studies how to modify some knowledge in Large Language Models (LLMs) at a low cost (compared to pre-training). Currently, performing large-scale edits on LLMs while ensuring the Reliability, Generality, and Locality metrics of the edits remain a challenge. This paper proposes a Massive editing approach for LLMs based on dynamic weight Generation (MeG). Our MeG involves attaching a dynamic weight neuron to specific layers of the LLMs and using a diffusion model to conditionally generate the weights of this neuron based on the input query required for the knowledge. This allows the use of adding a single dynamic weight neuron to achieve the goal of large-scale knowledge editing. Experiments show that our MeG can significantly improve the performance of large-scale KE in terms of Reliability, Generality, and Locality metrics compared to existing knowledge editing methods, particularly with a high percentage point increase in the absolute value index for the Locality metric, demonstrating the advantages of our proposed method.",
      "pdf_url": "https://arxiv.org/pdf/2512.14395v1",
      "published": "2025-12-16T13:32:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.14395v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "RePo: Language Models with Context Re-Positioning",
      "authors": [
        "Huayang Li",
        "Tianyu Zhao",
        "Richard Sproat"
      ],
      "abstract": "In-context learning is fundamental to modern Large Language Models (LLMs); however, prevailing architectures impose a rigid and fixed contextual structure by assigning linear or constant positional indices. Drawing on Cognitive Load Theory (CLT), we argue that this uninformative structure increases extraneous cognitive load, consuming finite working memory capacity that should be allocated to deep reasoning and attention allocation. To address this, we propose RePo, a novel mechanism that reduces extraneous load via context re-positioning. Unlike standard approaches, RePo utilizes a differentiable module, $f_φ$, to assign token positions that capture contextual dependencies, rather than replying on pre-defined integer range. By continually pre-training on the OLMo-2 1B backbone, we demonstrate that RePo significantly enhances performance on tasks involving noisy contexts, structured data, and longer context length, while maintaining competitive performance on general short-context tasks. Detailed analysis reveals that RePo successfully allocate higher attention to distant but relevant information, assign positions in dense and non-linear space, and capture the intrinsic structure of the input context. Our code is available at https://github.com/SakanaAI/repo.",
      "pdf_url": "https://arxiv.org/pdf/2512.14391v1",
      "published": "2025-12-16T13:30:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.14391v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Causal Structure Learning for Dynamical Systems with Theoretical Score Analysis",
      "authors": [
        "Nicholas Tagliapietra",
        "Katharina Ensinger",
        "Christoph Zimmer",
        "Osman Mian"
      ],
      "abstract": "Real world systems evolve in continuous-time according to their underlying causal relationships, yet their dynamics are often unknown. Existing approaches to learning such dynamics typically either discretize time -- leading to poor performance on irregularly sampled data -- or ignore the underlying causality. We propose CaDyT, a novel method for causal discovery on dynamical systems addressing both these challenges. In contrast to state-of-the-art causal discovery methods that model the problem using discrete-time Dynamic Bayesian networks, our formulation is grounded in Difference-based causal models, which allow milder assumptions for modeling the continuous nature of the system. CaDyT leverages exact Gaussian Process inference for modeling the continuous-time dynamics which is more aligned with the underlying dynamical process. We propose a practical instantiation that identifies the causal structure via a greedy search guided by the Algorithmic Markov Condition and Minimum Description Length principle. Our experiments show that CaDyT outperforms state-of-the-art methods on both regularly and irregularly-sampled data, discovering causal networks closer to the true underlying dynamics.",
      "pdf_url": "https://arxiv.org/pdf/2512.14361v1",
      "published": "2025-12-16T12:41:22+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.14361v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.DS"
      ]
    },
    {
      "title": "TiCard: Deployable EXPLAIN-only Residual Learning for Cardinality Estimation",
      "authors": [
        "Qizhi Wang"
      ],
      "abstract": "Cardinality estimation is a key bottleneck for cost-based query optimization, yet deployable improvements remain difficult: classical estimators miss correlations, while learned estimators often require workload-specific training pipelines and invasive integration into the optimizer. This paper presents TiCard, a low intrusion, correction-based framework that augments (rather than replaces) a database's native estimator. TiCard learns multiplicative residual corrections using EXPLAIN-only features, and uses EXPLAIN ANALYZE only for offline labels. We study two practical instantiations: (i) a Gradient Boosting Regressor for sub-millisecond inference, and (ii) TabPFN, an in-context tabular foundation model that adapts by refreshing a small reference set without gradient retraining. On TiDB with TPCH and the Join Order Benchmark, in a low-trace setting (263 executions total; 157 used for learning), TiCard improves operator-level tail accuracy substantially: P90 Q-error drops from 312.85 (native) to 13.69 (TiCard-GBR), and P99 drops from 37,974.37 to 3,416.50 (TiCard-TabPFN), while a join-only policy preserves near-perfect median behavior. We position TiCard as an AI4DB building block focused on deployability: explicit scope, conservative integration policies, and an integration roadmap from offline correction to in-optimizer use.",
      "pdf_url": "https://arxiv.org/pdf/2512.14358v1",
      "published": "2025-12-16T12:35:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.14358v1",
      "categories": [
        "cs.AI",
        "cs.DB"
      ]
    },
    {
      "title": "Enhancing Interpretability for Vision Models via Shapley Value Optimization",
      "authors": [
        "Kanglong Fan",
        "Yunqiao Yang",
        "Chen Ma"
      ],
      "abstract": "Deep neural networks have demonstrated remarkable performance across various domains, yet their decision-making processes remain opaque. Although many explanation methods are dedicated to bringing the obscurity of DNNs to light, they exhibit significant limitations: post-hoc explanation methods often struggle to faithfully reflect model behaviors, while self-explaining neural networks sacrifice performance and compatibility due to their specialized architectural designs. To address these challenges, we propose a novel self-explaining framework that integrates Shapley value estimation as an auxiliary task during training, which achieves two key advancements: 1) a fair allocation of the model prediction scores to image patches, ensuring explanations inherently align with the model's decision logic, and 2) enhanced interpretability with minor structural modifications, preserving model performance and compatibility. Extensive experiments on multiple benchmarks demonstrate that our method achieves state-of-the-art interpretability.",
      "pdf_url": "https://arxiv.org/pdf/2512.14354v1",
      "published": "2025-12-16T12:33:04+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.14354v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Towards Transferable Defense Against Malicious Image Edits",
      "authors": [
        "Jie Zhang",
        "Shuai Dong",
        "Shiguang Shan",
        "Xilin Chen"
      ],
      "abstract": "Recent approaches employing imperceptible perturbations in input images have demonstrated promising potential to counter malicious manipulations in diffusion-based image editing systems. However, existing methods suffer from limited transferability in cross-model evaluations. To address this, we propose Transferable Defense Against Malicious Image Edits (TDAE), a novel bimodal framework that enhances image immunity against malicious edits through coordinated image-text optimization. Specifically, at the visual defense level, we introduce FlatGrad Defense Mechanism (FDM), which incorporates gradient regularization into the adversarial objective. By explicitly steering the perturbations toward flat minima, FDM amplifies immune robustness against unseen editing models. For textual enhancement protection, we propose an adversarial optimization paradigm named Dynamic Prompt Defense (DPD), which periodically refines text embeddings to align the editing outcomes of immunized images with those of the original images, then updates the images under optimized embeddings. Through iterative adversarial updates to diverse embeddings, DPD enforces the generation of immunized images that seek a broader set of immunity-enhancing features, thereby achieving cross-model transferability. Extensive experimental results demonstrate that our TDAE achieves state-of-the-art performance in mitigating malicious edits under both intra- and cross-model evaluations.",
      "pdf_url": "https://arxiv.org/pdf/2512.14341v1",
      "published": "2025-12-16T12:10:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.14341v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ]
    },
    {
      "title": "Dual Attention Guided Defense Against Malicious Edits",
      "authors": [
        "Jie Zhang",
        "Shuai Dong",
        "Shiguang Shan",
        "Xilin Chen"
      ],
      "abstract": "Recent progress in text-to-image diffusion models has transformed image editing via text prompts, yet this also introduces significant ethical challenges from potential misuse in creating deceptive or harmful content. While current defenses seek to mitigate this risk by embedding imperceptible perturbations, their effectiveness is limited against malicious tampering. To address this issue, we propose a Dual Attention-Guided Noise Perturbation (DANP) immunization method that adds imperceptible perturbations to disrupt the model's semantic understanding and generation process. DANP functions over multiple timesteps to manipulate both cross-attention maps and the noise prediction process, using a dynamic threshold to generate masks that identify text-relevant and irrelevant regions. It then reduces attention in relevant areas while increasing it in irrelevant ones, thereby misguides the edit towards incorrect regions and preserves the intended targets. Additionally, our method maximizes the discrepancy between the injected noise and the model's predicted noise to further interfere with the generation. By targeting both attention and noise prediction mechanisms, DANP exhibits impressive immunity against malicious edits, and extensive experiments confirm that our method achieves state-of-the-art performance.",
      "pdf_url": "https://arxiv.org/pdf/2512.14333v1",
      "published": "2025-12-16T12:01:28+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.14333v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ]
    },
    {
      "title": "Step-Tagging: Toward controlling the generation of Language Reasoning Models through step monitoring",
      "authors": [
        "Yannis Belkhiter",
        "Seshu Tirupathi",
        "Giulio Zizzo",
        "John D. Kelleher"
      ],
      "abstract": "The field of Language Reasoning Models (LRMs) has been very active over the past few years with advances in training and inference techniques enabling LRMs to reason longer, and more accurately. However, a growing body of studies show that LRMs are still inefficient, over-generating verification and reflection steps. To address this challenge, we introduce the Step-Tagging framework, a lightweight sentence-classifier enabling real-time annotation of the type of reasoning steps that an LRM is generating. To monitor reasoning behaviors, we introduced ReasonType: a novel taxonomy of reasoning steps. Building on this framework, we demonstrated that online monitoring of the count of specific steps can produce effective interpretable early stopping criteria of LRM inferences. We evaluate the Step-tagging framework on three open-source reasoning models across standard benchmark datasets: MATH500, GSM8K, AIME and non-mathematical tasks (GPQA and MMLU-Pro). We achieve 20 to 50\\% token reduction while maintaining comparable accuracy to standard generation, with largest gains observed on more computation-heavy tasks. This work offers a novel way to increase control over the generation of LRMs, and a new tool to study behaviors of LRMs.",
      "pdf_url": "https://arxiv.org/pdf/2512.14332v1",
      "published": "2025-12-16T12:01:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.14332v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Criminal Liability in AI-Enabled Autonomous Vehicles: A Comparative Study",
      "authors": [
        "Sahibpreet Singh",
        "Manjit Singh"
      ],
      "abstract": "AI revolutionizes transportation through autonomous vehicles (AVs) but introduces complex criminal liability issues regarding infractions. This study employs a comparative legal analysis of primary statutes, real-world liability claims, and academic literature across the US, Germany, UK, China, and India; jurisdictions selected for their technological advancement and contrasting regulatory approaches. The research examines the attribution of human error, AI moral agency, and the identification of primary offenders in AV incidents. Findings reveal fragmented regulatory landscapes: India and the US rely on loose networks of state laws, whereas the UK enacted the pioneering Automated and Electric Vehicles Act 2018. Germany enforces strict safety standards, distinguishing liability based on the vehicle's operating mode, while China similarly aims for a stringent liability regime. The study concludes that globally harmonized legal standards are essential to foster technological innovation while ensuring minimum risk and clear liability attribution.",
      "pdf_url": "https://arxiv.org/pdf/2512.14330v1",
      "published": "2025-12-16T11:56:35+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.14330v1",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CR"
      ]
    },
    {
      "title": "A data-physics hybrid generative model for patient-specific post-stroke motor rehabilitation using wearable sensor data",
      "authors": [
        "Yanning Dai",
        "Chenyu Tang",
        "Ruizhi Zhang",
        "Wenyu Yang",
        "Yilan Zhang",
        "Yuhui Wang",
        "Junliang Chen",
        "Xuhang Chen",
        "Ruimou Xie",
        "Yangyue Cao",
        "Qiaoying Li",
        "Jin Cao",
        "Tao Li",
        "Hubin Zhao",
        "Yu Pan",
        "Arokia Nathan",
        "Xin Gao",
        "Peter Smielewski",
        "Shuo Gao"
      ],
      "abstract": "Dynamic prediction of locomotor capacity after stroke is crucial for tailoring rehabilitation, yet current assessments provide only static impairment scores and do not indicate whether patients can safely perform specific tasks such as slope walking or stair climbing. Here, we develop a data-physics hybrid generative framework that reconstructs an individual stroke survivor's neuromuscular control from a single 20 m level-ground walking trial and predicts task-conditioned locomotion across rehabilitation scenarios. The system combines wearable-sensor kinematics, a proportional-derivative physics controller, a population Healthy Motion Atlas, and goal-conditioned deep reinforcement learning with behaviour cloning and generative adversarial imitation learning to generate physically plausible, patient-specific gait simulations for slopes and stairs. In 11 stroke survivors, the personalized controllers preserved idiosyncratic gait patterns while improving joint-angle and endpoint fidelity by 4.73% and 12.10%, respectively, and reducing training time to 25.56% relative to a physics-only baseline. In a multicentre pilot involving 21 inpatients, clinicians who used our locomotion predictions to guide task selection and difficulty obtained larger gains in Fugl-Meyer lower-extremity scores over 28 days of standard rehabilitation than control clinicians (mean change 6.0 versus 3.7 points). These findings indicate that our generative, task-predictive framework can augment clinical decision-making in post-stroke gait rehabilitation and provide a template for dynamically personalized motor recovery strategies.",
      "pdf_url": "https://arxiv.org/pdf/2512.14329v1",
      "published": "2025-12-16T11:55:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.14329v1",
      "categories": [
        "cs.CE",
        "cs.AI"
      ]
    },
    {
      "title": "Semantic Mismatch and Perceptual Degradation: A New Perspective on Image Editing Immunity",
      "authors": [
        "Shuai Dong",
        "Jie Zhang",
        "Guoying Zhao",
        "Shiguang Shan",
        "Xilin Chen"
      ],
      "abstract": "Text-guided image editing via diffusion models, while powerful, raises significant concerns about misuse, motivating efforts to immunize images against unauthorized edits using imperceptible perturbations. Prevailing metrics for evaluating immunization success typically rely on measuring the visual dissimilarity between the output generated from a protected image and a reference output generated from the unprotected original. This approach fundamentally overlooks the core requirement of image immunization, which is to disrupt semantic alignment with attacker intent, regardless of deviation from any specific output. We argue that immunization success should instead be defined by the edited output either semantically mismatching the prompt or suffering substantial perceptual degradations, both of which thwart malicious intent. To operationalize this principle, we propose Synergistic Intermediate Feature Manipulation (SIFM), a method that strategically perturbs intermediate diffusion features through dual synergistic objectives: (1) maximizing feature divergence from the original edit trajectory to disrupt semantic alignment with the expected edit, and (2) minimizing feature norms to induce perceptual degradations. Furthermore, we introduce the Immunization Success Rate (ISR), a novel metric designed to rigorously quantify true immunization efficacy for the first time. ISR quantifies the proportion of edits where immunization induces either semantic failure relative to the prompt or significant perceptual degradations, assessed via Multimodal Large Language Models (MLLMs). Extensive experiments show our SIFM achieves the state-of-the-art performance for safeguarding visual content against malicious diffusion-based manipulation.",
      "pdf_url": "https://arxiv.org/pdf/2512.14320v1",
      "published": "2025-12-16T11:34:48+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.14320v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ]
    },
    {
      "title": "From YOLO to VLMs: Advancing Zero-Shot and Few-Shot Detection of Wastewater Treatment Plants Using Satellite Imagery in MENA Region",
      "authors": [
        "Akila Premarathna",
        "Kanishka Hewageegana",
        "Garcia Andarcia Mariangel"
      ],
      "abstract": "In regions of the Middle East and North Africa (MENA), there is a high demand for wastewater treatment plants (WWTPs), crucial for sustainable water management. Precise identification of WWTPs from satellite images enables environmental monitoring. Traditional methods like YOLOv8 segmentation require extensive manual labeling. But studies indicate that vision-language models (VLMs) are an efficient alternative to achieving equivalent or superior results through inherent reasoning and annotation. This study presents a structured methodology for VLM comparison, divided into zero-shot and few-shot streams specifically to identify WWTPs. The YOLOv8 was trained on a governmental dataset of 83,566 high-resolution satellite images from Egypt, Saudi Arabia, and UAE: ~85% WWTPs (positives), 15% non-WWTPs (negatives). Evaluated VLMs include LLaMA 3.2 Vision, Qwen 2.5 VL, DeepSeek-VL2, Gemma 3, Gemini, and Pixtral 12B (Mistral), used to identify WWTP components such as circular/rectangular tanks, aeration basins and distinguish confounders via expert prompts producing JSON outputs with confidence and descriptions. The dataset comprises 1,207 validated WWTP locations (198 UAE, 354 KSA, 655 Egypt) and equal non-WWTP sites from field/AI data, as 600mx600m Geo-TIFF images (Zoom 18, EPSG:4326). Zero-shot evaluations on WWTP images showed several VLMs out-performing YOLOv8's true positive rate, with Gemma-3 highest. Results confirm that VLMs, particularly with zero-shot, can replace YOLOv8 for efficient, annotation-free WWTP classification, enabling scalable remote sensing.",
      "pdf_url": "https://arxiv.org/pdf/2512.14312v1",
      "published": "2025-12-16T11:28:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.14312v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "A Threshold-Triggered Deep Q-Network-Based Framework for Self-Healing in Autonomic Software-Defined IIoT-Edge Networks",
      "authors": [
        "Agrippina Mwangi",
        "León Navarro-Hilfiker",
        "Lukasz Brewka",
        "Mikkel Gryning",
        "Elena Fumagalli",
        "Madeleine Gibescu"
      ],
      "abstract": "Stochastic disruptions such as flash events arising from benign traffic bursts and switch thermal fluctuations are major contributors to intermittent service degradation in software-defined industrial networks. These events violate IEC~61850-derived quality-of-service requirements and user-defined service-level agreements, hindering the reliable and timely delivery of control, monitoring, and best-effort traffic in IEC~61400-25-compliant wind power plants. Failure to maintain these requirements often results in delayed or lost control signals, reduced operational efficiency, and increased risk of wind turbine generator downtime.\n  To address these challenges, this study proposes a threshold-triggered Deep Q-Network self-healing agent that autonomically detects, analyzes, and mitigates network disruptions while adapting routing behavior and resource allocation in real time. The proposed agent was trained, validated, and tested on an emulated tri-clustered switch network deployed in a cloud-based proof-of-concept testbed.\n  Simulation results show that the proposed agent improves disruption recovery performance by 53.84% compared to a baseline shortest-path and load-balanced routing approach and outperforms state-of-the-art methods, including the Adaptive Network-based Fuzzy Inference System by 13.1% and the Deep Q-Network and traffic prediction-based routing optimization method by 21.5%, in a super-spine leaf data-plane architecture.\n  Additionally, the agent maintains switch thermal stability by proactively initiating external rack cooling when required. These findings highlight the potential of deep reinforcement learning in building resilience in software-defined industrial networks deployed in mission-critical, time-sensitive application scenarios.",
      "pdf_url": "https://arxiv.org/pdf/2512.14297v1",
      "published": "2025-12-16T11:11:37+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.14297v1",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.ET",
        "cs.PF",
        "hep-ex"
      ]
    },
    {
      "title": "Leveraging LLMs for Collaborative Ontology Engineering in Parkinson Disease Monitoring and Alerting",
      "authors": [
        "Georgios Bouchouras",
        "Dimitrios Doumanas",
        "Andreas Soularidis",
        "Konstantinos Kotis",
        "George A. Vouros"
      ],
      "abstract": "This paper explores the integration of Large Language Models (LLMs) in the engineering of a Parkinson's Disease (PD) monitoring and alerting ontology through four key methodologies: One Shot (OS) prompt techniques, Chain of Thought (CoT) prompts, X-HCOME, and SimX-HCOME+. The primary objective is to determine whether LLMs alone can create comprehensive ontologies and, if not, whether human-LLM collaboration can achieve this goal. Consequently, the paper assesses the effectiveness of LLMs in automated ontology development and the enhancement achieved through human-LLM collaboration.\n  Initial ontology generation was performed using One Shot (OS) and Chain of Thought (CoT) prompts, demonstrating the capability of LLMs to autonomously construct ontologies for PD monitoring and alerting. However, these outputs were not comprehensive and required substantial human refinement to enhance their completeness and accuracy.\n  X-HCOME, a hybrid ontology engineering approach that combines human expertise with LLM capabilities, showed significant improvements in ontology comprehensiveness. This methodology resulted in ontologies that are very similar to those constructed by experts.\n  Further experimentation with SimX-HCOME+, another hybrid methodology emphasizing continuous human supervision and iterative refinement, highlighted the importance of ongoing human involvement. This approach led to the creation of more comprehensive and accurate ontologies.\n  Overall, the paper underscores the potential of human-LLM collaboration in advancing ontology engineering, particularly in complex domains like PD. The results suggest promising directions for future research, including the development of specialized GPT models for ontology construction.",
      "pdf_url": "https://arxiv.org/pdf/2512.14288v1",
      "published": "2025-12-16T10:58:26+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.14288v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "The Trust in AI-Generated Health Advice (TAIGHA) Scale and Short Version (TAIGHA-S): Development and Validation Study",
      "authors": [
        "Marvin Kopka",
        "Azeem Majeed",
        "Gabriella Spinelli",
        "Austen El-Osta",
        "Markus Feufel"
      ],
      "abstract": "Artificial Intelligence tools such as large language models are increasingly used by the public to obtain health information and guidance. In health-related contexts, following or rejecting AI-generated advice can have direct clinical implications. Existing instruments like the Trust in Automated Systems Survey assess trustworthiness of generic technology, and no validated instrument measures users' trust in AI-generated health advice specifically. This study developed and validated the Trust in AI-Generated Health Advice (TAIGHA) scale and its four-item short form (TAIGHA-S) as theory-based instruments measuring trust and distrust, each with cognitive and affective components. The items were developed using a generative AI approach, followed by content validation with 10 domain experts, face validation with 30 lay participants, and psychometric validation with 385 UK participants who received AI-generated advice in a symptom-assessment scenario. After automated item reduction, 28 items were retained and reduced to 10 based on expert ratings. TAIGHA showed excellent content validity (S-CVI/Ave=0.99) and CFA confirmed a two-factor model with excellent fit (CFI=0.98, TLI=0.98, RMSEA=0.07, SRMR=0.03). Internal consistency was high (α=0.95). Convergent validity was supported by correlations with the Trust in Automated Systems Survey (r=0.67/-0.66) and users' reliance on the AI's advice (r=0.37 for trust), while divergent validity was supported by low correlations with reading flow and mental load (all |r|<0.25). TAIGHA-S correlated highly with the full scale (r=0.96) and showed good reliability (α=0.88). TAIGHA and TAIGHA-S are validated instruments for assessing user trust and distrust in AI-generated health advice. Reporting trust and distrust separately permits a more complete evaluation of AI interventions, and the short scale is well-suited for time-constrained settings.",
      "pdf_url": "https://arxiv.org/pdf/2512.14278v1",
      "published": "2025-12-16T10:40:07+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.14278v1",
      "categories": [
        "cs.HC",
        "cs.AI"
      ]
    },
    {
      "title": "SPARQL-LLM: Real-Time SPARQL Query Generation from Natural Language Questions",
      "authors": [
        "Panayiotis Smeros",
        "Vincent Emonet",
        "Ruijie Wang",
        "Ana-Claudia Sima",
        "Tarcisio Mendes de Farias"
      ],
      "abstract": "The advent of large language models is contributing to the emergence of novel approaches that promise to better tackle the challenge of generating structured queries, such as SPARQL queries, from natural language. However, these new approaches mostly focus on response accuracy over a single source while ignoring other evaluation criteria, such as federated query capability over distributed data stores, as well as runtime and cost to generate SPARQL queries. Consequently, they are often not production-ready or easy to deploy over (potentially federated) knowledge graphs with good accuracy. To mitigate these issues, in this paper, we extend our previous work and describe and systematically evaluate SPARQL-LLM, an open-source and triplestore-agnostic approach, powered by lightweight metadata, that generates SPARQL queries from natural language text. First, we describe its architecture, which consists of dedicated components for metadata indexing, prompt building, and query generation and execution. Then, we evaluate it based on a state-of-the-art challenge with multilingual questions, and a collection of questions from three of the most prevalent knowledge graphs within the field of bioinformatics. Our results demonstrate a substantial increase of 24% in the F1 Score on the state-of-the-art challenge, adaptability to high-resource languages such as English and Spanish, as well as ability to form complex and federated bioinformatics queries. Furthermore, we show that SPARQL-LLM is up to 36x faster than other systems participating in the challenge, while costing a maximum of $0.01 per question, making it suitable for real-time, low-cost text-to-SPARQL applications. One such application deployed over real-world decentralized knowledge graphs can be found at https://www.expasy.org/chat.",
      "pdf_url": "https://arxiv.org/pdf/2512.14277v1",
      "published": "2025-12-16T10:39:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.14277v1",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Explainable Preference Learning: a Decision Tree-based Surrogate Model for Preferential Bayesian Optimization",
      "authors": [
        "Nick Leenders",
        "Thomas Quadt",
        "Boris Cule",
        "Roy Lindelauf",
        "Herman Monsuur",
        "Joost van Oijen",
        "Mark Voskuijl"
      ],
      "abstract": "Current Preferential Bayesian Optimization methods rely on Gaussian Processes (GPs) as surrogate models. These models are hard to interpret, struggle with handling categorical data, and are computationally complex, limiting their real-world usability. In this paper, we introduce an inherently interpretable decision tree-based surrogate model capable of handling both categorical and continuous data, and scalable to large datasets. Extensive numerical experiments on eight increasingly spiky optimization functions show that our model outperforms GP-based alternatives on spiky functions and has only marginally lower performance for non-spiky functions. Moreover, we apply our model to the real-world Sushi dataset and show its ability to learn an individual's sushi preferences. Finally, we show some initial work on using historical preference data to speed up the optimization process for new unseen users.",
      "pdf_url": "https://arxiv.org/pdf/2512.14263v1",
      "published": "2025-12-16T10:17:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.14263v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ]
    },
    {
      "title": "Gödel's Poetry",
      "authors": [
        "Kelly J. Davis"
      ],
      "abstract": "Formal, automated theorem proving has long been viewed as a challenge to artificial intelligence. We introduce here a new approach to computer theorem proving, one that employs specialized language models for Lean4 proof generation combined with recursive decomposition of difficult theorems into simpler entailing propositions. These models are coordinated through a multi-agent architecture that orchestrates autoformalization (if required), proof generation, decomposition of difficult theorems into simpler entailing propositions, and recursive proof (and/or decomposition) of these propositions. Without decomposition, we achieve a 90.4% pass rate on miniF2F. With decomposition, this is significantly improved. A key technical contribution lies in our extension of the Kimina Lean Server with abstract syntax tree (AST) parsing capabilities to facilitate automated, recursive proof decomposition. The system is made available on PyPI as goedels-poetry (at https://pypi.org/project/goedels-poetry ), and the open-source implementation KellyJDavis/goedels-poetry (at https://github.com/KellyJDavis/goedels-poetry ) facilitates both adaptation to alternative language models and extension with custom functionality.",
      "pdf_url": "https://arxiv.org/pdf/2512.14252v1",
      "published": "2025-12-16T10:00:01+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.14252v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    }
  ]
}