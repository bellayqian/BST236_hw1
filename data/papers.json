{
  "last_updated": "2026-01-06T00:56:48.644231",
  "papers": [
    {
      "title": "Geometry of Reason: Spectral Signatures of Valid Mathematical Reasoning",
      "authors": [
        "Valentin Noël"
      ],
      "abstract": "We present a training-free method for detecting valid mathematical reasoning in large language models through spectral analysis of attention patterns. By treating attention matrices as adjacency matrices of dynamic graphs over tokens, we extract four interpretable spectral diagnostics, the Fiedler value (algebraic connectivity), high-frequency energy ratio (HFER), graph signal smoothness, and spectral entropy, that exhibit statistically significant differences between valid and invalid mathematical proofs. Experiments across seven transformer models from four independent architectural families (Meta Llama, Alibaba Qwen, Microsoft Phi, and Mistral AI) demonstrate that this spectral signature produces effect sizes up to Cohen's $d = 3.30$ ($p < 10^{-116}$), enabling 85.0--95.6\\% classification accuracy under rigorous evaluation, with calibrated thresholds reaching 93--95\\% on the full dataset. The method requires no training data, fine-tuning, or learned classifiers: a single threshold on a spectral metric suffices for high accuracy. Through systematic label correction, we discover that the spectral method detects logical coherence rather than compiler acceptance, identifying mathematically valid proofs that formal verifiers reject due to technical failures. We further identify an architectural dependency: Mistral-7B's Sliding Window Attention shifts the discriminative signal from HFER to late-layer Smoothness ($d = 2.09$, $p_{\\text{MW}} = 1.16 \\times 10^{-48}$), revealing that attention mechanism design affects which spectral features capture reasoning validity. These findings establish spectral graph analysis as a principled framework for reasoning verification with immediate applications to hallucination detection and AI safety monitoring.",
      "pdf_url": "https://arxiv.org/pdf/2601.00791v1",
      "published": "2026-01-02T18:49:37+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.00791v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.LO"
      ]
    },
    {
      "title": "FedHypeVAE: Federated Learning with Hypernetwork Generated Conditional VAEs for Differentially Private Embedding Sharing",
      "authors": [
        "Sunny Gupta",
        "Amit Sethi"
      ],
      "abstract": "Federated data sharing promises utility without centralizing raw data, yet existing embedding-level generators struggle under non-IID client heterogeneity and provide limited formal protection against gradient leakage. We propose FedHypeVAE, a differentially private, hypernetwork-driven framework for synthesizing embedding-level data across decentralized clients. Building on a conditional VAE backbone, we replace the single global decoder and fixed latent prior with client-aware decoders and class-conditional priors generated by a shared hypernetwork from private, trainable client codes. This bi-level design personalizes the generative layerrather than the downstream modelwhile decoupling local data from communicated parameters. The shared hypernetwork is optimized under differential privacy, ensuring that only noise-perturbed, clipped gradients are aggregated across clients. A local MMD alignment between real and synthetic embeddings and a Lipschitz regularizer on hypernetwork outputs further enhance stability and distributional coherence under non-IID conditions. After training, a neutral meta-code enables domain agnostic synthesis, while mixtures of meta-codes provide controllable multi-domain coverage. FedHypeVAE unifies personalization, privacy, and distribution alignment at the generator level, establishing a principled foundation for privacy-preserving data synthesis in federated settings. Code: github.com/sunnyinAI/FedHypeVAE",
      "pdf_url": "https://arxiv.org/pdf/2601.00785v1",
      "published": "2026-01-02T18:40:41+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.00785v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "LLM Agents for Combinatorial Efficient Frontiers: Investment Portfolio Optimization",
      "authors": [
        "Simon Paquette-Greenbaum",
        "Jiangbo Yu"
      ],
      "abstract": "Investment portfolio optimization is a task conducted in all major financial institutions. The Cardinality Constrained Mean-Variance Portfolio Optimization (CCPO) problem formulation is ubiquitous for portfolio optimization. The challenge of this type of portfolio optimization, a mixed-integer quadratic programming (MIQP) problem, arises from the intractability of solutions from exact solvers, where heuristic algorithms are used to find approximate portfolio solutions. CCPO entails many laborious and complex workflows and also requires extensive effort pertaining to heuristic algorithm development, where the combination of pooled heuristic solutions results in improved efficient frontiers. Hence, common approaches are to develop many heuristic algorithms. Agentic frameworks emerge as a promising candidate for many problems within combinatorial optimization, as they have been shown to be equally efficient with regard to automating large workflows and have been shown to be excellent in terms of algorithm development, sometimes surpassing human-level performance. This study implements a novel agentic framework for the CCPO and explores several concrete architectures. In benchmark problems, the implemented agentic framework matches state-of-the-art algorithms. Furthermore, complex workflows and algorithm development efforts are alleviated, while in the worst case, lower but acceptable error is reported.",
      "pdf_url": "https://arxiv.org/pdf/2601.00770v1",
      "published": "2026-01-02T18:02:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.00770v1",
      "categories": [
        "cs.CE",
        "cs.AI",
        "econ.GN"
      ]
    },
    {
      "title": "An Agentic Framework for Neuro-Symbolic Programming",
      "authors": [
        "Aliakbar Nafar",
        "Chetan Chigurupati",
        "Danial Kamali",
        "Hamid Karimian",
        "Parisa Kordjamshidi"
      ],
      "abstract": "Integrating symbolic constraints into deep learning models could make them more robust, interpretable, and data-efficient. Still, it remains a time-consuming and challenging task. Existing frameworks like DomiKnowS help this integration by providing a high-level declarative programming interface, but they still assume the user is proficient with the library's specific syntax. We propose AgenticDomiKnowS (ADS) to eliminate this dependency. ADS translates free-form task descriptions into a complete DomiKnowS program using an agentic workflow that creates and tests each DomiKnowS component separately. The workflow supports optional human-in-the-loop intervention, enabling users familiar with DomiKnowS to refine intermediate outputs. We show how ADS enables experienced DomiKnowS users and non-users to rapidly construct neuro-symbolic programs, reducing development time from hours to 10-15 minutes.",
      "pdf_url": "https://arxiv.org/pdf/2601.00743v1",
      "published": "2026-01-02T16:59:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.00743v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Stochastic Actor-Critic: Mitigating Overestimation via Temporal Aleatoric Uncertainty",
      "authors": [
        "Uğurcan Özalp"
      ],
      "abstract": "Off-policy actor-critic methods in reinforcement learning train a critic with temporal-difference updates and use it as a learning signal for the policy (actor). This design typically achieves higher sample efficiency than purely on-policy methods. However, critic networks tend to overestimate value estimates systematically. This is often addressed by introducing a pessimistic bias based on uncertainty estimates. Current methods employ ensembling to quantify the critic's epistemic uncertainty-uncertainty due to limited data and model ambiguity-to scale pessimistic updates. In this work, we propose a new algorithm called Stochastic Actor-Critic (STAC) that incorporates temporal (one-step) aleatoric uncertainty-uncertainty arising from stochastic transitions, rewards, and policy-induced variability in Bellman targets-to scale pessimistic bias in temporal-difference updates, rather than relying on epistemic uncertainty. STAC uses a single distributional critic network to model the temporal return uncertainty, and applies dropout to both the critic and actor networks for regularization. Our results show that pessimism based on a distributional critic alone suffices to mitigate overestimation, and naturally leads to risk-averse behavior in stochastic environments. Introducing dropout further improves training stability and performance by means of regularization. With this design, STAC achieves improved computational efficiency using a single distributional critic network.",
      "pdf_url": "https://arxiv.org/pdf/2601.00737v1",
      "published": "2026-01-02T16:33:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.00737v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SY"
      ]
    },
    {
      "title": "Exploring the Performance of Large Language Models on Subjective Span Identification Tasks",
      "authors": [
        "Alphaeus Dmonte",
        "Roland Oruche",
        "Tharindu Ranasinghe",
        "Marcos Zampieri",
        "Prasad Calyam"
      ],
      "abstract": "Identifying relevant text spans is important for several downstream tasks in NLP, as it contributes to model explainability. While most span identification approaches rely on relatively smaller pre-trained language models like BERT, a few recent approaches have leveraged the latest generation of Large Language Models (LLMs) for the task. Current work has focused on explicit span identification like Named Entity Recognition (NER), while more subjective span identification with LLMs in tasks like Aspect-based Sentiment Analysis (ABSA) has been underexplored. In this paper, we fill this important gap by presenting an evaluation of the performance of various LLMs on text span identification in three popular tasks, namely sentiment analysis, offensive language identification, and claim verification. We explore several LLM strategies like instruction tuning, in-context learning, and chain of thought. Our results indicate underlying relationships within text aid LLMs in identifying precise text spans.",
      "pdf_url": "https://arxiv.org/pdf/2601.00736v1",
      "published": "2026-01-02T16:30:14+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.00736v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Detecting Performance Degradation under Data Shift in Pathology Vision-Language Model",
      "authors": [
        "Hao Guan",
        "Li Zhou"
      ],
      "abstract": "Vision-Language Models have demonstrated strong potential in medical image analysis and disease diagnosis. However, after deployment, their performance may deteriorate when the input data distribution shifts from that observed during development. Detecting such performance degradation is essential for clinical reliability, yet remains challenging for large pre-trained VLMs operating without labeled data. In this study, we investigate performance degradation detection under data shift in a state-of-the-art pathology VLM. We examine both input-level data shift and output-level prediction behavior to understand their respective roles in monitoring model reliability. To facilitate systematic analysis of input data shift, we develop DomainSAT, a lightweight toolbox with a graphical interface that integrates representative shift detection algorithms and enables intuitive exploration of data shift. Our analysis shows that while input data shift detection is effective at identifying distributional changes and providing early diagnostic signals, it does not always correspond to actual performance degradation. Motivated by this observation, we further study output-based monitoring and introduce a label-free, confidence-based degradation indicator that directly captures changes in model prediction confidence. We find that this indicator exhibits a close relationship with performance degradation and serves as an effective complement to input shift detection. Experiments on a large-scale pathology dataset for tumor classification demonstrate that combining input data shift detection and output confidence-based indicators enables more reliable detection and interpretation of performance degradation in VLMs under data shift. These findings provide a practical and complementary framework for monitoring the reliability of foundation models in digital pathology.",
      "pdf_url": "https://arxiv.org/pdf/2601.00716v1",
      "published": "2026-01-02T15:12:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.00716v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "A Vision-and-Knowledge Enhanced Large Language Model for Generalizable Pedestrian Crossing Behavior Inference",
      "authors": [
        "Qingwen Pu",
        "Kun Xie",
        "Hong Yang",
        "Guocong Zhai"
      ],
      "abstract": "Existing paradigms for inferring pedestrian crossing behavior, ranging from statistical models to supervised learning methods, demonstrate limited generalizability and perform inadequately on new sites. Recent advances in Large Language Models (LLMs) offer a shift from numerical pattern fitting to semantic, context-aware behavioral reasoning, yet existing LLM applications lack domain-specific adaptation and visual context. This study introduces Pedestrian Crossing LLM (PedX-LLM), a vision-and-knowledge enhanced framework designed to transform pedestrian crossing inference from site-specific pattern recognition to generalizable behavioral reasoning. By integrating LLaVA-extracted visual features with textual data and transportation domain knowledge, PedX-LLM fine-tunes a LLaMA-2-7B foundation model via Low-Rank Adaptation (LoRA) to infer crossing decisions. PedX-LLM achieves 82.0% balanced accuracy, outperforming the best statistical and supervised learning methods. Results demonstrate that the vision-augmented module contributes a 2.9% performance gain by capturing the built environment and integrating domain knowledge yields an additional 4.1% improvement. To evaluate generalizability across unseen environments, cross-site validation was conducted using site-based partitioning. The zero-shot PedX-LLM configuration achieves 66.9% balanced accuracy on five unseen test sites, outperforming the baseline data-driven methods by at least 18 percentage points. Incorporating just five validation examples via few-shot learning to PedX-LLM further elevates the balanced accuracy to 72.2%. PedX-LLM demonstrates strong generalizability to unseen scenarios, confirming that vision-and-knowledge-enhanced reasoning enables the model to mimic human-like decision logic and overcome the limitations of purely data-driven methods.",
      "pdf_url": "https://arxiv.org/pdf/2601.00694v1",
      "published": "2026-01-02T14:13:28+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.00694v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "QSLM: A Performance- and Memory-aware Quantization Framework with Tiered Search Strategy for Spike-driven Language Models",
      "authors": [
        "Rachmad Vidya Wicaksana Putra",
        "Pasindu Wickramasinghe",
        "Muhammad Shafique"
      ],
      "abstract": "Large Language Models (LLMs) have been emerging as prominent AI models for solving many natural language tasks due to their high performance (e.g., accuracy) and capabilities in generating high-quality responses to the given inputs. However, their large computational cost, huge memory footprints, and high processing power/energy make it challenging for their embedded deployments. Amid several tinyLLMs, recent works have proposed spike-driven language models (SLMs) for significantly reducing the processing power/energy of LLMs. However, their memory footprints still remain too large for low-cost and resource-constrained embedded devices. Manual quantization approach may effectively compress SLM memory footprints, but it requires a huge design time and compute power to find the quantization setting for each network, hence making this approach not-scalable for handling different networks, performance requirements, and memory budgets. To bridge this gap, we propose QSLM, a novel framework that performs automated quantization for compressing pre-trained SLMs, while meeting the performance and memory constraints. To achieve this, QSLM first identifies the hierarchy of the given network architecture and the sensitivity of network layers under quantization, then employs a tiered quantization strategy (e.g., global-, block-, and module-level quantization) while leveraging a multi-objective performance-and-memory trade-off function to select the final quantization setting. Experimental results indicate that our QSLM reduces memory footprint by up to 86.5%, reduces power consumption by up to 20%, maintains high performance across different tasks (i.e., by up to 84.4% accuracy of sentiment classification on the SST-2 dataset and perplexity score of 23.2 for text generation on the WikiText-2 dataset) close to the original non-quantized model while meeting the performance and memory constraints.",
      "pdf_url": "https://arxiv.org/pdf/2601.00679v1",
      "published": "2026-01-02T13:05:33+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.00679v1",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "IRPO: Scaling the Bradley-Terry Model via Reinforcement Learning",
      "authors": [
        "Haonan Song",
        "Qingchen Xie",
        "Huan Zhu",
        "Feng Xiao",
        "Luxi Xing",
        "Fuzhen Li",
        "Liu Kang",
        "Feng Jiang",
        "Zhiyong Zheng",
        "Fan Yang"
      ],
      "abstract": "Generative Reward Models (GRMs) have attracted considerable research interest in reward modeling due to their interpretability, inference-time scalability, and potential for refinement through reinforcement learning (RL). However, widely used pairwise GRMs create a computational bottleneck when integrated with RL algorithms such as Group Relative Policy Optimization (GRPO). This bottleneck arises from two factors: (i) the O(n^2) time complexity of pairwise comparisons required to obtain relative scores, and (ii) the computational overhead of repeated sampling or additional chain-of-thought (CoT) reasoning to improve performance. To address the first factor, we propose Intergroup Relative Preference Optimization (IRPO), a novel RL framework that incorporates the well-established Bradley-Terry model into GRPO. By generating a pointwise score for each response, IRPO enables efficient evaluation of arbitrarily many candidates during RL training while preserving interpretability and fine-grained reward signals. Experimental results demonstrate that IRPO achieves state-of-the-art (SOTA) performance among pointwise GRMs across multiple benchmarks, with performance comparable to that of current leading pairwise GRMs. Furthermore, we show that IRPO significantly outperforms pairwise GRMs in post-training evaluations.",
      "pdf_url": "https://arxiv.org/pdf/2601.00677v1",
      "published": "2026-01-02T12:57:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.00677v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Fast-weight Product Key Memory",
      "authors": [
        "Tianyu Zhao",
        "Llion Jones"
      ],
      "abstract": "Sequence modeling layers in modern language models typically face a trade-off between storage capacity and computational efficiency. While Softmax attention offers unbounded storage at prohibitive quadratic costs, linear variants provide efficiency but suffer from limited, fixed-size storage. We propose Fast-weight Product Key Memory (FwPKM), a novel architecture that resolves this tension by transforming the sparse Product Key Memory (PKM) from a static module into a dynamic, \"fast-weight\" episodic memory. Unlike PKM, FwPKM updates its parameters dynamically at both training and inference time via local chunk-level gradient descent, allowing the model to rapidly memorize and retrieve new key-value pairs from input sequences. Experiments reveal that FwPKM functions as an effective episodic memory that complements the semantic memory of standard modules, yielding significant perplexity reductions on long-context datasets. Notably, in Needle in a Haystack evaluations, FwPKM generalizes to 128K-token contexts despite being trained on only 4K-token sequences.",
      "pdf_url": "https://arxiv.org/pdf/2601.00671v1",
      "published": "2026-01-02T12:37:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.00671v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Avatar Forcing: Real-Time Interactive Head Avatar Generation for Natural Conversation",
      "authors": [
        "Taekyung Ki",
        "Sangwon Jang",
        "Jaehyeong Jo",
        "Jaehong Yoon",
        "Sung Ju Hwang"
      ],
      "abstract": "Talking head generation creates lifelike avatars from static portraits for virtual communication and content creation. However, current models do not yet convey the feeling of truly interactive communication, often generating one-way responses that lack emotional engagement. We identify two key challenges toward truly interactive avatars: generating motion in real-time under causal constraints and learning expressive, vibrant reactions without additional labeled data. To address these challenges, we propose Avatar Forcing, a new framework for interactive head avatar generation that models real-time user-avatar interactions through diffusion forcing. This design allows the avatar to process real-time multimodal inputs, including the user's audio and motion, with low latency for instant reactions to both verbal and non-verbal cues such as speech, nods, and laughter. Furthermore, we introduce a direct preference optimization method that leverages synthetic losing samples constructed by dropping user conditions, enabling label-free learning of expressive interaction. Experimental results demonstrate that our framework enables real-time interaction with low latency (approximately 500ms), achieving 6.8X speedup compared to the baseline, and produces reactive and expressive avatar motion, which is preferred over 80% against the baseline.",
      "pdf_url": "https://arxiv.org/pdf/2601.00664v1",
      "published": "2026-01-02T11:58:48+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.00664v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.HC",
        "cs.MM"
      ]
    },
    {
      "title": "Interpretability-Guided Bi-objective Optimization: Aligning Accuracy and Explainability",
      "authors": [
        "Kasra Fouladi",
        "Hamta Rahmani"
      ],
      "abstract": "This paper introduces Interpretability-Guided Bi-objective Optimization (IGBO), a framework that trains interpretable models by incorporating structured domain knowledge via a bi-objective formulation. IGBO encodes feature importance hierarchies as a Directed Acyclic Graph (DAG) and uses Temporal Integrated Gradients (TIG) to measure feature importance. To address the Out-of-Distribution (OOD) problem in TIG computation, we propose an Optimal Path Oracle that learns data-manifold-aware integration paths. Theoretical analysis proves convergence properties and robustness to mini-batch noise, while empirical results on time-series data demonstrate IGBO's effectiveness in enforcing DAG constraints with minimal accuracy loss, outperforming standard regularization baselines.",
      "pdf_url": "https://arxiv.org/pdf/2601.00655v1",
      "published": "2026-01-02T11:32:00+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.00655v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "DA-DPO: Cost-efficient Difficulty-aware Preference Optimization for Reducing MLLM Hallucinations",
      "authors": [
        "Longtian Qiu",
        "Shan Ning",
        "Chuyu Zhang",
        "Jiaxuan Sun",
        "Xuming He"
      ],
      "abstract": "Direct Preference Optimization (DPO) has shown strong potential for mitigating hallucinations in Multimodal Large Language Models (MLLMs). However, existing multimodal DPO approaches often suffer from overfitting due to the difficulty imbalance in preference data. Our analysis shows that MLLMs tend to overemphasize easily distinguishable preference pairs, which hinders fine-grained hallucination suppression and degrades overall performance. To address this issue, we propose Difficulty-Aware Direct Preference Optimization (DA-DPO), a cost-effective framework designed to balance the learning process. DA-DPO consists of two main components: (1) Difficulty Estimation leverages pre-trained vision--language models with complementary generative and contrastive objectives, whose outputs are integrated via a distribution-aware voting strategy to produce robust difficulty scores without additional training; and (2) Difficulty-Aware Training reweights preference pairs based on their estimated difficulty, down-weighting easy samples while emphasizing harder ones to alleviate overfitting. This framework enables more effective preference optimization by prioritizing challenging examples, without requiring new data or extra fine-tuning stages. Extensive experiments demonstrate that DA-DPO consistently improves multimodal preference optimization, yielding stronger robustness to hallucinations and better generalization across standard benchmarks, while remaining computationally efficient. The project page is available at https://artanic30.github.io/project_pages/DA-DPO/.",
      "pdf_url": "https://arxiv.org/pdf/2601.00623v1",
      "published": "2026-01-02T09:41:54+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.00623v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Noise-Robust Tiny Object Localization with Flows",
      "authors": [
        "Huixin Sun",
        "Linlin Yang",
        "Ronyu Chen",
        "Kerui Gu",
        "Baochang Zhang",
        "Angela Yao",
        "Xianbin Cao"
      ],
      "abstract": "Despite significant advances in generic object detection, a persistent performance gap remains for tiny objects compared to normal-scale objects. We demonstrate that tiny objects are highly sensitive to annotation noise, where optimizing strict localization objectives risks noise overfitting. To address this, we propose Tiny Object Localization with Flows (TOLF), a noise-robust localization framework leveraging normalizing flows for flexible error modeling and uncertainty-guided optimization. Our method captures complex, non-Gaussian prediction distributions through flow-based error modeling, enabling robust learning under noisy supervision. An uncertainty-aware gradient modulation mechanism further suppresses learning from high-uncertainty, noise-prone samples, mitigating overfitting while stabilizing training. Extensive experiments across three datasets validate our approach's effectiveness. Especially, TOLF boosts the DINO baseline by 1.2% AP on the AI-TOD dataset.",
      "pdf_url": "https://arxiv.org/pdf/2601.00617v1",
      "published": "2026-01-02T09:16:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.00617v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Stronger Approximation Guarantees for Non-Monotone γ-Weakly DR-Submodular Maximization",
      "authors": [
        "Hareshkumar Jadav",
        "Ranveer Singh",
        "Vaneet Aggarwal"
      ],
      "abstract": "Maximizing submodular objectives under constraints is a fundamental problem in machine learning and optimization. We study the maximization of a nonnegative, non-monotone $γ$-weakly DR-submodular function over a down-closed convex body. Our main result is an approximation algorithm whose guarantee depends smoothly on $γ$; in particular, when $γ=1$ (the DR-submodular case) our bound recovers the $0.401$ approximation factor, while for $γ<1$ the guarantee degrades gracefully and, it improves upon previously reported bounds for $γ$-weakly DR-submodular maximization under the same constraints. Our approach combines a Frank-Wolfe-guided continuous-greedy framework with a $γ$-aware double-greedy step, yielding a simple yet effective procedure for handling non-monotonicity. This results in state-of-the-art guarantees for non-monotone $γ$-weakly DR-submodular maximization over down-closed convex bodies.",
      "pdf_url": "https://arxiv.org/pdf/2601.00611v1",
      "published": "2026-01-02T08:44:10+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.00611v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CC",
        "math.OC"
      ]
    },
    {
      "title": "HFedMoE: Resource-aware Heterogeneous Federated Learning with Mixture-of-Experts",
      "authors": [
        "Zihan Fang",
        "Zheng Lin",
        "Senkang Hu",
        "Yanan Ma",
        "Yihang Tao",
        "Yiqin Deng",
        "Xianhao Chen",
        "Yuguang Fang"
      ],
      "abstract": "While federated learning (FL) enables fine-tuning of large language models (LLMs) without compromising data privacy, the substantial size of an LLM renders on-device training impractical for resource-constrained clients, such as mobile devices. Thus, Mixture-of-Experts (MoE) models have emerged as a computation-efficient solution, which activates only a sparse subset of experts during model training to reduce computing burden without sacrificing performance. Though integrating MoE into FL fine-tuning holds significant potential, it still encounters three key challenges: i) selecting appropriate experts for clients remains challenging due to the lack of a reliable metric to measure each expert's impact on local fine-tuning performance, ii) the heterogeneous computing resources across clients severely hinder MoE-based LLM fine-tuning, as dynamic expert activations across diverse input samples can overwhelm resource-constrained devices, and iii) client-specific expert subsets and routing preference undermine global aggregation, where misaligned expert updates and inconsistent gating networks in troduce destructive interference. To address these challenges, we propose HFedMoE, a heterogeneous MoE-based FL fine-tuning framework that customizes a subset of experts to each client for computation-efficient LLM fine-tuning. Specifically, HFedMoE identifies the expert importance based on its contributions to fine-tuning performance, and then adaptively selects a subset of experts from an information bottleneck perspective to align with each client' s computing budget. A sparsity-aware model aggregation strategy is also designed to aggregate the actively fine-tuned experts and gating parameters with importance weighted contributions. Extensive experiments demonstrate that HFedMoE outperforms state-of-the-art benchmarks in training accuracy and convergence speed.",
      "pdf_url": "https://arxiv.org/pdf/2601.00583v1",
      "published": "2026-01-02T05:56:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.00583v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NI"
      ]
    },
    {
      "title": "Priority-Aware Multi-Robot Coverage Path Planning",
      "authors": [
        "Kanghoon Lee",
        "Hyeonjun Kim",
        "Jiachen Li",
        "Jinkyoo Park"
      ],
      "abstract": "Multi-robot systems are widely used for coverage tasks that require efficient coordination across large environments. In Multi-Robot Coverage Path Planning (MCPP), the objective is typically to minimize the makespan by generating non-overlapping paths for full-area coverage. However, most existing methods assume uniform importance across regions, limiting their effectiveness in scenarios where some zones require faster attention. We introduce the Priority-Aware MCPP (PA-MCPP) problem, where a subset of the environment is designated as prioritized zones with associated weights. The goal is to minimize, in lexicographic order, the total priority-weighted latency of zone coverage and the overall makespan. To address this, we propose a scalable two-phase framework combining (1) greedy zone assignment with local search, spanning-tree-based path planning, and (2) Steiner-tree-guided residual coverage. Experiments across diverse scenarios demonstrate that our method significantly reduces priority-weighted latency compared to standard MCPP baselines, while maintaining competitive makespan. Sensitivity analyses further show that the method scales well with the number of robots and that zone coverage behavior can be effectively controlled by adjusting priority weights.",
      "pdf_url": "https://arxiv.org/pdf/2601.00580v1",
      "published": "2026-01-02T05:45:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.00580v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.MA"
      ]
    },
    {
      "title": "Learning to be Reproducible: Custom Loss Design for Robust Neural Networks",
      "authors": [
        "Waqas Ahmed",
        "Sheeba Samuel",
        "Kevin Coakley",
        "Birgitta Koenig-Ries",
        "Odd Erik Gundersen"
      ],
      "abstract": "To enhance the reproducibility and reliability of deep learning models, we address a critical gap in current training methodologies: the lack of mechanisms that ensure consistent and robust performance across runs. Our empirical analysis reveals that even under controlled initialization and training conditions, the accuracy of the model can exhibit significant variability. To address this issue, we propose a Custom Loss Function (CLF) that reduces the sensitivity of training outcomes to stochastic factors such as weight initialization and data shuffling. By fine-tuning its parameters, CLF explicitly balances predictive accuracy with training stability, leading to more consistent and reliable model performance. Extensive experiments across diverse architectures for both image classification and time series forecasting demonstrate that our approach significantly improves training robustness without sacrificing predictive performance. These results establish CLF as an effective and efficient strategy for developing more stable, reliable and trustworthy neural networks.",
      "pdf_url": "https://arxiv.org/pdf/2601.00578v1",
      "published": "2026-01-02T05:31:08+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.00578v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Improving Scientific Document Retrieval with Academic Concept Index",
      "authors": [
        "Jeyun Lee",
        "Junhyoung Lee",
        "Wonbin Kweon",
        "Bowen Jin",
        "Yu Zhang",
        "Susik Yoon",
        "Dongha Lee",
        "Hwanjo Yu",
        "Jiawei Han",
        "Seongku Kang"
      ],
      "abstract": "Adapting general-domain retrievers to scientific domains is challenging due to the scarcity of large-scale domain-specific relevance annotations and the substantial mismatch in vocabulary and information needs. Recent approaches address these issues through two independent directions that leverage large language models (LLMs): (1) generating synthetic queries for fine-tuning, and (2) generating auxiliary contexts to support relevance matching. However, both directions overlook the diverse academic concepts embedded within scientific documents, often producing redundant or conceptually narrow queries and contexts. To address this limitation, we introduce an academic concept index, which extracts key concepts from papers and organizes them guided by an academic taxonomy. This structured index serves as a foundation for improving both directions. First, we enhance the synthetic query generation with concept coverage-based generation (CCQGen), which adaptively conditions LLMs on uncovered concepts to generate complementary queries with broader concept coverage. Second, we strengthen the context augmentation with concept-focused auxiliary contexts (CCExpand), which leverages a set of document snippets that serve as concise responses to the concept-aware CCQGen queries. Extensive experiments show that incorporating the academic concept index into both query generation and context augmentation leads to higher-quality queries, better conceptual alignment, and improved retrieval performance.",
      "pdf_url": "https://arxiv.org/pdf/2601.00567v1",
      "published": "2026-01-02T04:47:49+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.00567v1",
      "categories": [
        "cs.IR",
        "cs.AI"
      ]
    },
    {
      "title": "Cracking IoT Security: Can LLMs Outsmart Static Analysis Tools?",
      "authors": [
        "Jason Quantrill",
        "Noura Khajehnouri",
        "Zihan Guo",
        "Manar H. Alalfi"
      ],
      "abstract": "Smart home IoT platforms such as openHAB rely on Trigger Action Condition (TAC) rules to automate device behavior, but the interplay among these rules can give rise to interaction threats, unintended or unsafe behaviors emerging from implicit dependencies, conflicting triggers, or overlapping conditions. Identifying these threats requires semantic understanding and structural reasoning that traditionally depend on symbolic, constraint-driven static analysis. This work presents the first comprehensive evaluation of Large Language Models (LLMs) across a multi-category interaction threat taxonomy, assessing their performance on both the original openHAB (oHC/IoTB) dataset and a structurally challenging Mutation dataset designed to test robustness under rule transformations. We benchmark Llama 3.1 8B, Llama 70B, GPT-4o, Gemini-2.5-Pro, and DeepSeek-R1 across zero-, one-, and two-shot settings, comparing their results against oHIT's manually validated ground truth. Our findings show that while LLMs exhibit promising semantic understanding, particularly on action- and condition-related threats, their accuracy degrades significantly for threats requiring cross-rule structural reasoning, especially under mutated rule forms. Model performance varies widely across threat categories and prompt settings, with no model providing consistent reliability. In contrast, the symbolic reasoning baseline maintains stable detection across both datasets, unaffected by rule rewrites or structural perturbations. These results underscore that LLMs alone are not yet dependable for safety critical interaction-threat detection in IoT environments. We discuss the implications for tool design and highlight the potential of hybrid architectures that combine symbolic analysis with LLM-based semantic interpretation to reduce false positives while maintaining structural rigor.",
      "pdf_url": "https://arxiv.org/pdf/2601.00559v1",
      "published": "2026-01-02T04:17:36+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.00559v1",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "title": "A Comprehensive Dataset for Human vs. AI Generated Image Detection",
      "authors": [
        "Rajarshi Roy",
        "Nasrin Imanpour",
        "Ashhar Aziz",
        "Shashwat Bajpai",
        "Gurpreet Singh",
        "Shwetangshu Biswas",
        "Kapil Wanaskar",
        "Parth Patwa",
        "Subhankar Ghosh",
        "Shreyas Dixit",
        "Nilesh Ranjan Pal",
        "Vipula Rawte",
        "Ritvik Garimella",
        "Gaytri Jena",
        "Vasu Sharma",
        "Vinija Jain",
        "Aman Chadha",
        "Aishwarya Naresh Reganti",
        "Amitava Das"
      ],
      "abstract": "Multimodal generative AI systems like Stable Diffusion, DALL-E, and MidJourney have fundamentally changed how synthetic images are created. These tools drive innovation but also enable the spread of misleading content, false information, and manipulated media. As generated images become harder to distinguish from photographs, detecting them has become an urgent priority. To combat this challenge, We release MS COCOAI, a novel dataset for AI generated image detection consisting of 96000 real and synthetic datapoints, built using the MS COCO dataset. To generate synthetic images, we use five generators: Stable Diffusion 3, Stable Diffusion 2.1, SDXL, DALL-E 3, and MidJourney v6. Based on the dataset, we propose two tasks: (1) classifying images as real or generated, and (2) identifying which model produced a given synthetic image. The dataset is available at https://huggingface.co/datasets/Rajarshi-Roy-research/Defactify_Image_Dataset.",
      "pdf_url": "https://arxiv.org/pdf/2601.00553v1",
      "published": "2026-01-02T03:58:18+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.00553v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "CoCo-Fed: A Unified Framework for Memory- and Communication-Efficient Federated Learning at the Wireless Edge",
      "authors": [
        "Zhiheng Guo",
        "Zhaoyang Liu",
        "Zihan Cen",
        "Chenyuan Feng",
        "Xinghua Sun",
        "Xiang Chen",
        "Tony Q. S. Quek",
        "Xijun Wang"
      ],
      "abstract": "The deployment of large-scale neural networks within the Open Radio Access Network (O-RAN) architecture is pivotal for enabling native edge intelligence. However, this paradigm faces two critical bottlenecks: the prohibitive memory footprint required for local training on resource-constrained gNBs, and the saturation of bandwidth-limited backhaul links during the global aggregation of high-dimensional model updates. To address these challenges, we propose CoCo-Fed, a novel Compression and Combination-based Federated learning framework that unifies local memory efficiency and global communication reduction. Locally, CoCo-Fed breaks the memory wall by performing a double-dimension down-projection of gradients, adapting the optimizer to operate on low-rank structures without introducing additional inference parameters/latency. Globally, we introduce a transmission protocol based on orthogonal subspace superposition, where layer-wise updates are projected and superimposed into a single consolidated matrix per gNB, drastically reducing the backhaul traffic. Beyond empirical designs, we establish a rigorous theoretical foundation, proving the convergence of CoCo-Fed even under unsupervised learning conditions suitable for wireless sensing tasks. Extensive simulations on an angle-of-arrival estimation task demonstrate that CoCo-Fed significantly outperforms state-of-the-art baselines in both memory and communication efficiency while maintaining robust convergence under non-IID settings.",
      "pdf_url": "https://arxiv.org/pdf/2601.00549v1",
      "published": "2026-01-02T03:39:50+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.00549v1",
      "categories": [
        "cs.IT",
        "cs.AI"
      ]
    },
    {
      "title": "ECR: Manifold-Guided Semantic Cues for Compact Language Models",
      "authors": [
        "Chung-Wei Victor Yuan"
      ],
      "abstract": "Compact models often lose the structure of their embedding space. The issue shows up when the capacity is tight or the data spans several languages. Such collapse makes it difficult for downstream tasks to build on the resulting representation. Existing compression methods focus on aligning model outputs at a superficial level but fail to preserve the underlying manifold structure. This mismatch often leads to semantic drift in the compact model, causing both task behavior and linguistic properties to deviate from the reference model.\n  To address those issues, we provide a new framework called Embedding Consistency Regulation (ECR). This framework first derives a set of semantic anchors from teacher embeddings (computed once offline). Then, the compact model learns to maintain consistent geometry around these anchors, without relying on matching logits or internal features. ECR adds only a small projection step at inference, without altering the decoding architecture or its runtime behavior.\n  In experiments on a 100K multilingual corpus, ECR consistently stabilizes training and preserves semantic structure across tasks and languages. It also produces a more compact and task-aligned representation space, enabling low-capacity models to learn cleaner manifolds than conventional baselines. ECR works without teacher outputs and is compatible with, but independent of, distillation. Taken together, our results show that ECR helps compact models better follow task requirements and makes them easier to deploy under strict efficiency or privacy limits.",
      "pdf_url": "https://arxiv.org/pdf/2601.00543v1",
      "published": "2026-01-02T03:16:24+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.00543v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Parametrized Sharing for Multi-Agent Hybrid DRL for Multiple Multi-Functional RISs-Aided Downlink NOMA Networks",
      "authors": [
        "Chi-Te Kuo",
        "Li-Hsiang Shen",
        "Jyun-Jhe Huang"
      ],
      "abstract": "Multi-functional reconfigurable intelligent surface (MF-RIS) is conceived to address the communication efficiency thanks to its extended signal coverage from its active RIS capability and self-sustainability from energy harvesting (EH). We investigate the architecture of multi-MF-RISs to assist non-orthogonal multiple access (NOMA) downlink networks. We formulate an energy efficiency (EE) maximization problem by optimizing power allocation, transmit beamforming and MF-RIS configurations of amplitudes, phase-shifts and EH ratios, as well as the position of MF-RISs, while satisfying constraints of available power, user rate requirements, and self-sustainability property. We design a parametrized sharing scheme for multi-agent hybrid deep reinforcement learning (PMHRL), where the multi-agent proximal policy optimization (PPO) and deep-Q network (DQN) handle continuous and discrete variables, respectively. The simulation results have demonstrated that proposed PMHRL has the highest EE compared to other benchmarks, including cases without parametrized sharing, pure PPO and DQN. Moreover, the proposed multi-MF-RISs-aided downlink NOMA achieves the highest EE compared to scenarios of no-EH/amplification, traditional RISs, and deployment without RISs/MF-RISs under different multiple access.",
      "pdf_url": "https://arxiv.org/pdf/2601.00538v1",
      "published": "2026-01-02T02:44:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.00538v1",
      "categories": [
        "eess.SP",
        "cs.AI"
      ]
    },
    {
      "title": "Optimizing LSTM Neural Networks for Resource-Constrained Retail Sales Forecasting: A Model Compression Study",
      "authors": [
        "Ravi Teja Pagidoju"
      ],
      "abstract": "Standard LSTM(Long Short-Term Memory) neural networks provide accurate predictions for sales data in the retail industry, but require a lot of computing power. It can be challenging especially for mid to small retail industries. This paper examines LSTM model compression by gradually reducing the number of hidden units from 128 to 16. We used the Kaggle Store Item Demand Forecasting dataset, which has 913,000 daily sales records from 10 stores and 50 items, to look at the trade-off between model size and how accurate the predictions are. Experiments show that lowering the number of hidden LSTM units to 64 maintains the same level of accuracy while also improving it. The mean absolute percentage error (MAPE) ranges from 23.6% for the full 128-unit model to 12.4% for the 64-unit model. The optimized model is 73% smaller (from 280KB to 76KB) and 47% more accurate. These results show that larger models do not always achieve better results.",
      "pdf_url": "https://arxiv.org/pdf/2601.00525v1",
      "published": "2026-01-02T01:35:49+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.00525v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Probability-Aware Parking Selection",
      "authors": [
        "Cameron Hickert",
        "Sirui Li",
        "Zhengbing He",
        "Cathy Wu"
      ],
      "abstract": "Current parking navigation systems often underestimate total travel time by failing to account for the time spent searching for a parking space, which significantly affects user experience, mode choice, congestion, and emissions. To address this issue, this paper introduces the probability-aware parking selection problem, which aims to direct drivers to the best parking location rather than straight to their destination. An adaptable dynamic programming framework is proposed for decision-making based on probabilistic information about parking availability at the parking lot level. Closed-form analysis determines when it is optimal to target a specific parking lot or explore alternatives, as well as the expected time cost. Sensitivity analysis and three illustrative cases are examined, demonstrating the model's ability to account for the dynamic nature of parking availability. Acknowledging the financial costs of permanent sensing infrastructure, the paper provides analytical and empirical assessments of errors incurred when leveraging stochastic observations to estimate parking availability. Experiments with real-world data from the US city of Seattle indicate this approach's viability, with mean absolute error decreasing from 7% to below 2% as observation frequency grows. In data-based simulations, probability-aware strategies demonstrate time savings up to 66% relative to probability-unaware baselines, yet still take up to 123% longer than direct-to-destination estimates.",
      "pdf_url": "https://arxiv.org/pdf/2601.00521v1",
      "published": "2026-01-02T01:13:47+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.00521v1",
      "categories": [
        "eess.SY",
        "cs.AI",
        "stat.AP"
      ]
    },
    {
      "title": "Trajectory Guard -- A Lightweight, Sequence-Aware Model for Real-Time Anomaly Detection in Agentic AI",
      "authors": [
        "Laksh Advani"
      ],
      "abstract": "Autonomous LLM agents generate multi-step action plans that can fail due to contextual misalignment or structural incoherence. Existing anomaly detection methods are ill-suited for this challenge: mean-pooling embeddings dilutes anomalous steps, while contrastive-only approaches ignore sequential structure. Standard unsupervised methods on pre-trained embeddings achieve F1-scores no higher than 0.69. We introduce Trajectory Guard, a Siamese Recurrent Autoencoder with a hybrid loss function that jointly learns task-trajectory alignment via contrastive learning and sequential validity via reconstruction. This dual objective enables unified detection of both \"wrong plan for this task\" and \"malformed plan structure.\" On benchmarks spanning synthetic perturbations and real-world failures from security audits (RAS-Eval) and multi-agent systems (Who\\&When), we achieve F1-scores of 0.88-0.94 on balanced sets and recall of 0.86-0.92 on imbalanced external benchmarks. At 32 ms inference latency, our approach runs 17-27$\\times$ faster than LLM Judge baselines, enabling real-time safety verification in production deployments.",
      "pdf_url": "https://arxiv.org/pdf/2601.00516v1",
      "published": "2026-01-02T00:27:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.00516v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "The Illusion of Insight in Reasoning Models",
      "authors": [
        "Liv G. d'Aliberti",
        "Manoel Horta Ribeiro"
      ],
      "abstract": "Do reasoning models have \"Aha!\" moments? Prior work suggests that models like DeepSeek-R1-Zero undergo sudden mid-trace realizations that lead to accurate outputs, implying an intrinsic capacity for self-correction. Yet, it remains unclear whether such intrinsic shifts in reasoning strategy actually improve performance. Here, we study mid-reasoning shifts and instrument training runs to detect them. Our analysis spans 1M+ reasoning traces, hundreds of training checkpoints, three reasoning domains, and multiple decoding temperatures and model architectures. We find that reasoning shifts are rare, do not become more frequent with training, and seldom improve accuracy, indicating that they do not correspond to prior perceptions of model insight. However, their effect varies with model uncertainty. Building on this finding, we show that artificially triggering extrinsic shifts under high entropy reliably improves accuracy. Our results show that mid-reasoning shifts are symptoms of unstable inference behavior rather than an intrinsic mechanism for self-correction.",
      "pdf_url": "https://arxiv.org/pdf/2601.00514v1",
      "published": "2026-01-02T00:12:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.00514v1",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "MotionPhysics: Learnable Motion Distillation for Text-Guided Simulation",
      "authors": [
        "Miaowei Wang",
        "Jakub Zadrożny",
        "Oisin Mac Aodha",
        "Amir Vaxman"
      ],
      "abstract": "Accurately simulating existing 3D objects and a wide variety of materials often demands expert knowledge and time-consuming physical parameter tuning to achieve the desired dynamic behavior. We introduce MotionPhysics, an end-to-end differentiable framework that infers plausible physical parameters from a user-provided natural language prompt for a chosen 3D scene of interest, removing the need for guidance from ground-truth trajectories or annotated videos. Our approach first utilizes a multimodal large language model to estimate material parameter values, which are constrained to lie within plausible ranges. We further propose a learnable motion distillation loss that extracts robust motion priors from pretrained video diffusion models while minimizing appearance and geometry inductive biases to guide the simulation. We evaluate MotionPhysics across more than thirty scenarios, including real-world, human-designed, and AI-generated 3D objects, spanning a wide range of materials such as elastic solids, metals, foams, sand, and both Newtonian and non-Newtonian fluids. We demonstrate that MotionPhysics produces visually realistic dynamic simulations guided by natural language, surpassing the state of the art while automatically determining physically plausible parameters. The code and project page are available at: https://wangmiaowei.github.io/MotionPhysics.github.io/.",
      "pdf_url": "https://arxiv.org/pdf/2601.00504v1",
      "published": "2026-01-01T22:56:37+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.00504v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ]
    },
    {
      "title": "Multi-Agent Coordinated Rename Refactoring",
      "authors": [
        "Abhiram Bellur",
        "Mohammed Raihan Ullah",
        "Fraol Batole",
        "Mohit Kansara",
        "Masaharu Morimoto",
        "Kai Ishikawa",
        "Haifeng Chen",
        "Yaroslav Zharov",
        "Timofey Bryksin",
        "Tien N. Nguyen",
        "Hridesh Rajan",
        "Danny Dig"
      ],
      "abstract": "The primary value of AI agents in software development lies in their ability to extend the developer's capacity for reasoning and action, not to supplant human involvement. To showcase how to use agents working in tandem with developers, we designed a novel approach for carrying out coordinated renaming. Coordinated renaming, where a single rename refactoring triggers refactorings in multiple, related identifiers, is a frequent yet challenging task. Developers must manually propagate these rename refactorings across numerous files and contexts, a process that is both tedious and highly error-prone. State-of-the-art heuristic-based approaches produce an overwhelming number of false positives, while vanilla Large Language Models (LLMs) provide incomplete suggestions due to their limited context and inability to interact with refactoring tools. This leaves developers with incomplete refactorings or burdens them with filtering too many false positives. Coordinated renaming is exactly the kind of repetitive task that agents can significantly reduce the developers' burden while keeping them in the driver's seat.\n  We designed, implemented, and evaluated the first multi-agent framework that automates coordinated renaming. It operates on a key insight: a developer's initial refactoring is a clue to infer the scope of related refactorings. Our Scope Inference Agent first transforms this clue into an explicit, natural-language Declared Scope. The Planned Execution Agent then uses this as a strict plan to identify program elements that should undergo refactoring and safely executes the changes by invoking the IDE's own trusted refactoring APIs. Finally, the Replication Agent uses it to guide the project-wide search. We first conducted a formative study on the practice of coordinated renaming in 609K commits in 100 open-source projects and surveyed 205 developers ...",
      "pdf_url": "https://arxiv.org/pdf/2601.00482v1",
      "published": "2026-01-01T21:29:43+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.00482v1",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "MAESTRO: Multi-Agent Evaluation Suite for Testing, Reliability, and Observability",
      "authors": [
        "Tie Ma",
        "Yixi Chen",
        "Vaastav Anand",
        "Alessandro Cornacchia",
        "Amândio R. Faustino",
        "Guanheng Liu",
        "Shan Zhang",
        "Hongbin Luo",
        "Suhaib A. Fahmy",
        "Zafar A. Qazi",
        "Marco Canini"
      ],
      "abstract": "We present MAESTRO, an evaluation suite for the testing, reliability, and observability of LLM-based MAS. MAESTRO standardizes MAS configuration and execution through a unified interface, supports integrating both native and third-party MAS via a repository of examples and lightweight adapters, and exports framework-agnostic execution traces together with system-level signals (e.g., latency, cost, and failures). We instantiate MAESTRO with 12 representative MAS spanning popular agentic frameworks and interaction patterns, and conduct controlled experiments across repeated runs, backend models, and tool configurations. Our case studies show that MAS executions can be structurally stable yet temporally variable, leading to substantial run-to-run variance in performance and reliability. We further find that MAS architecture is the dominant driver of resource profiles, reproducibility, and cost-latency-accuracy trade-off, often outweighing changes in backend models or tool settings. Overall, MAESTRO enables systematic evaluation and provides empirical guidance for designing and optimizing agentic systems.",
      "pdf_url": "https://arxiv.org/pdf/2601.00481v1",
      "published": "2026-01-01T21:25:52+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.00481v1",
      "categories": [
        "cs.NI",
        "cs.AI"
      ]
    },
    {
      "title": "Progressive Ideation using an Agentic AI Framework for Human-AI Co-Creation",
      "authors": [
        "Sankar B",
        "Srinidhi Ranjini Girish",
        "Aadya Bharti",
        "Dibakar Sen"
      ],
      "abstract": "The generation of truly novel and diverse ideas is important for contemporary engineering design, yet it remains a significant cognitive challenge for novice designers. Current 'single-spurt' AI systems exacerbate this challenge by producing a high volume of semantically clustered ideas. We propose MIDAS (Meta-cognitive Ideation through Distributed Agentic AI System), a novel framework that replaces the single-AI paradigm with a distributed 'team' of specialized AI agents designed to emulate the human meta-cognitive ideation workflow. This agentic system progressively refines ideas and assesses each one for both global novelty (against existing solutions) and local novelty (against previously generated ideas). MIDAS, therefore, demonstrates a viable and progressive paradigm for true human-AI co-creation, elevating the human designer from a passive filterer to a participatory, active, collaborative partner.",
      "pdf_url": "https://arxiv.org/pdf/2601.00475v1",
      "published": "2026-01-01T21:06:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.00475v1",
      "categories": [
        "cs.AI",
        "cs.HC"
      ]
    },
    {
      "title": "Neural Chains and Discrete Dynamical Systems",
      "authors": [
        "Sauro Succi",
        "Abhisek Ganguly",
        "Santosh Ansumali"
      ],
      "abstract": "We inspect the analogy between machine-learning (ML) applications based on the transformer architecture without self-attention, {\\it neural chains} hereafter, and discrete dynamical systems associated with discretised versions of neural integral and partial differential equations (NIE, PDE). A comparative analysis of the numerical solution of the (viscid and inviscid) Burgers and Eikonal equations via standard numerical discretization (also cast in terms of neural chains) and via PINN's learning is presented and commented on. It is found that standard numerical discretization and PINN learning provide two different paths to acquire essentially the same knowledge about the dynamics of the system. PINN learning proceeds through random matrices which bear no direct relation to the highly structured matrices associated with finite-difference (FD) procedures. Random matrices leading to acceptable solutions are far more numerous than the unique tridiagonal form in matrix space, which explains why the PINN search typically lands on the random ensemble. The price is a much larger number of parameters, causing lack of physical transparency (explainability) as well as large training costs with no counterpart in the FD procedure. However, our results refer to one-dimensional dynamic problems, hence they don't rule out the possibility that PINNs and ML in general, may offer better strategies for high-dimensional problems.",
      "pdf_url": "https://arxiv.org/pdf/2601.00473v1",
      "published": "2026-01-01T21:02:50+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.00473v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Geometric Regularization in Mixture-of-Experts: The Disconnect Between Weights and Activations",
      "authors": [
        "Hyunjun Kim"
      ],
      "abstract": "Mixture-of-Experts (MoE) models achieve efficiency through sparse activation, but the role of geometric regularization in expert specialization remains unclear. We apply orthogonality loss to enforce expert diversity and find it fails on multiple fronts: it does not reduce weight-space overlap (MSO actually increases by up to 114%), activation-space overlap remains high (~0.6) regardless of regularization, and effects on performance are inconsistent -- marginal improvement on WikiText-103 (-0.9%), slight degradation on TinyStories (+0.9%), and highly variable results on PTB (std > 1.0). Our analysis across 7 regularization strengths reveals no significant correlation (r = -0.293, p = 0.523) between weight and activation orthogonality. These findings demonstrate that weight-space regularization neither achieves its geometric goal nor reliably improves performance, making it unsuitable for MoE diversity.",
      "pdf_url": "https://arxiv.org/pdf/2601.00457v1",
      "published": "2026-01-01T19:53:01+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.00457v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Deep Networks Learn Deep Hierarchical Models",
      "authors": [
        "Amit Daniely"
      ],
      "abstract": "We consider supervised learning with $n$ labels and show that layerwise SGD on residual networks can efficiently learn a class of hierarchical models. This model class assumes the existence of an (unknown) label hierarchy $L_1 \\subseteq L_2 \\subseteq \\dots \\subseteq L_r = [n]$, where labels in $L_1$ are simple functions of the input, while for $i > 1$, labels in $L_i$ are simple functions of simpler labels.\n  Our class surpasses models that were previously shown to be learnable by deep learning algorithms, in the sense that it reaches the depth limit of efficient learnability. That is, there are models in this class that require polynomial depth to express, whereas previous models can be computed by log-depth circuits.\n  Furthermore, we suggest that learnability of such hierarchical models might eventually form a basis for understanding deep learning. Beyond their natural fit for domains where deep learning excels, we argue that the mere existence of human ``teachers\" supports the hypothesis that hierarchical structures are inherently available. By providing granular labels, teachers effectively reveal ``hints'' or ``snippets'' of the internal algorithms used by the brain. We formalize this intuition, showing that in a simplified model where a teacher is partially aware of their internal logic, a hierarchical structure emerges that facilitates efficient learnability.",
      "pdf_url": "https://arxiv.org/pdf/2601.00455v1",
      "published": "2026-01-01T19:44:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.00455v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Defensive M2S: Training Guardrail Models on Compressed Multi-turn Conversations",
      "authors": [
        "Hyunjun Kim"
      ],
      "abstract": "Guardrail models are essential for ensuring the safety of Large Language Model (LLM) deployments, but processing full multi-turn conversation histories incurs significant computational cost. We propose Defensive M2S, a training paradigm that fine-tunes guardrail models on Multi-turn to Single-turn (M2S) compressed conversations rather than complete dialogue histories. We provide a formal complexity analysis showing that M2S reduces training cost from $O(n^2)$ to $O(n)$ for $n$-turn conversations. Empirically, on our training dataset (779 samples, avg. 10.6 turns), M2S requires only 169K tokens compared to 15.7M tokens for the multi-turn baseline -- a 93$\\times$ reduction. We evaluate Defensive M2S across three guardrail model families (LlamaGuard, Nemotron, Qwen3Guard) and three compression templates (hyphenize, numberize, pythonize) on SafeDialBench, a comprehensive multi-turn jailbreak benchmark. Our best configuration, Qwen3Guard with hyphenize compression, achieves 93.8% attack detection recall while reducing inference tokens by 94.6% (from 3,231 to 173 tokens per conversation). This represents a 38.9 percentage point improvement over the baseline while dramatically reducing both training and inference costs. Our findings demonstrate that M2S compression can serve as an effective efficiency technique for guardrail deployment, enabling scalable safety screening of long multi-turn conversations.",
      "pdf_url": "https://arxiv.org/pdf/2601.00454v1",
      "published": "2026-01-01T19:42:08+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.00454v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Language as Mathematical Structure: Examining Semantic Field Theory Against Language Games",
      "authors": [
        "Dimitris Vartziotis"
      ],
      "abstract": "Large language models (LLMs) offer a new empirical setting in which long-standing theories of linguistic meaning can be examined. This paper contrasts two broad approaches: social constructivist accounts associated with language games, and a mathematically oriented framework we call Semantic Field Theory. Building on earlier work by the author, we formalize the notions of lexical fields (Lexfelder) and linguistic fields (Lingofelder) as interacting structures in a continuous semantic space. We then analyze how core properties of transformer architectures-such as distributed representations, attention mechanisms, and geometric regularities in embedding spaces-relate to these concepts. We argue that the success of LLMs in capturing semantic regularities supports the view that language exhibits an underlying mathematical structure, while their persistent limitations in pragmatic reasoning and context sensitivity are consistent with the importance of social grounding emphasized in philosophical accounts of language use. On this basis, we suggest that mathematical structure and language games can be understood as complementary rather than competing perspectives. The resulting framework clarifies the scope and limits of purely statistical models of language and motivates new directions for theoretically informed AI architectures.",
      "pdf_url": "https://arxiv.org/pdf/2601.00448v1",
      "published": "2026-01-01T19:15:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.00448v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "RMAAT: Astrocyte-Inspired Memory Compression and Replay for Efficient Long-Context Transformers",
      "authors": [
        "Md Zesun Ahmed Mia",
        "Malyaban Bal",
        "Abhronil Sengupta"
      ],
      "abstract": "The quadratic complexity of self-attention mechanism presents a significant impediment to applying Transformer models to long sequences. This work explores computational principles derived from astrocytes-glial cells critical for biological memory and synaptic modulation-as a complementary approach to conventional architectural modifications for efficient self-attention. We introduce the Recurrent Memory Augmented Astromorphic Transformer (RMAAT), an architecture integrating abstracted astrocyte functionalities. RMAAT employs a recurrent, segment-based processing strategy where persistent memory tokens propagate contextual information. An adaptive compression mechanism, governed by a novel retention factor derived from simulated astrocyte long-term plasticity (LTP), modulates these tokens. Attention within segments utilizes an efficient, linear-complexity mechanism inspired by astrocyte short-term plasticity (STP). Training is performed using Astrocytic Memory Replay Backpropagation (AMRB), a novel algorithm designed for memory efficiency in recurrent networks. Evaluations on the Long Range Arena (LRA) benchmark demonstrate RMAAT's competitive accuracy and substantial improvements in computational and memory efficiency, indicating the potential of incorporating astrocyte-inspired dynamics into scalable sequence models.",
      "pdf_url": "https://arxiv.org/pdf/2601.00426v1",
      "published": "2026-01-01T18:34:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.00426v1",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.ET",
        "cs.LG"
      ]
    },
    {
      "title": "E-GRPO: High Entropy Steps Drive Effective Reinforcement Learning for Flow Models",
      "authors": [
        "Shengjun Zhang",
        "Zhang Zhang",
        "Chensheng Dai",
        "Yueqi Duan"
      ],
      "abstract": "Recent reinforcement learning has enhanced the flow matching models on human preference alignment. While stochastic sampling enables the exploration of denoising directions, existing methods which optimize over multiple denoising steps suffer from sparse and ambiguous reward signals. We observe that the high entropy steps enable more efficient and effective exploration while the low entropy steps result in undistinguished roll-outs. To this end, we propose E-GRPO, an entropy aware Group Relative Policy Optimization to increase the entropy of SDE sampling steps. Since the integration of stochastic differential equations suffer from ambiguous reward signals due to stochasticity from multiple steps, we specifically merge consecutive low entropy steps to formulate one high entropy step for SDE sampling, while applying ODE sampling on other steps. Building upon this, we introduce multi-step group normalized advantage, which computes group-relative advantages within samples sharing the same consolidated SDE denoising step. Experimental results on different reward settings have demonstrated the effectiveness of our methods.",
      "pdf_url": "https://arxiv.org/pdf/2601.00423v1",
      "published": "2026-01-01T18:27:32+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.00423v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Can Semantic Methods Enhance Team Sports Tactics? A Methodology for Football with Broader Applications",
      "authors": [
        "Alessio Di Rubbo",
        "Mattia Neri",
        "Remo Pareschi",
        "Marco Pedroni",
        "Roberto Valtancoli",
        "Paolino Zica"
      ],
      "abstract": "This paper explores how semantic-space reasoning, traditionally used in computational linguistics, can be extended to tactical decision-making in team sports. Building on the analogy between texts and teams -- where players act as words and collective play conveys meaning -- the proposed methodology models tactical configurations as compositional semantic structures. Each player is represented as a multidimensional vector integrating technical, physical, and psychological attributes; team profiles are aggregated through contextual weighting into a higher-level semantic representation. Within this shared vector space, tactical templates such as high press, counterattack, or possession build-up are encoded analogously to linguistic concepts. Their alignment with team profiles is evaluated using vector-distance metrics, enabling the computation of tactical ``fit'' and opponent-exploitation potential. A Python-based prototype demonstrates how these methods can generate interpretable, dynamically adaptive strategy recommendations, accompanied by fine-grained diagnostic insights at the attribute level. Beyond football, the approach offers a generalizable framework for collective decision-making and performance optimization in team-based domains -- ranging from basketball and hockey to cooperative robotics and human-AI coordination systems. The paper concludes by outlining future directions toward real-world data integration, predictive simulation, and hybrid human-machine tactical intelligence.",
      "pdf_url": "https://arxiv.org/pdf/2601.00421v1",
      "published": "2026-01-01T18:23:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.00421v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Deep Delta Learning",
      "authors": [
        "Yifan Zhang",
        "Yifeng Liu",
        "Mengdi Wang",
        "Quanquan Gu"
      ],
      "abstract": "The efficacy of deep residual networks is fundamentally predicated on the identity shortcut connection. While this mechanism effectively mitigates the vanishing gradient problem, it imposes a strictly additive inductive bias on feature transformations, thereby limiting the network's capacity to model complex state transitions. In this paper, we introduce Deep Delta Learning (DDL), a novel architecture that generalizes the standard residual connection by modulating the identity shortcut with a learnable, data-dependent geometric transformation. This transformation, termed the Delta Operator, constitutes a rank-1 perturbation of the identity matrix, parameterized by a reflection direction vector $\\mathbf{k}(\\mathbf{X})$ and a gating scalar $β(\\mathbf{X})$. We provide a spectral analysis of this operator, demonstrating that the gate $β(\\mathbf{X})$ enables dynamic interpolation between identity mapping, orthogonal projection, and geometric reflection. Furthermore, we restructure the residual update as a synchronous rank-1 injection, where the gate acts as a dynamic step size governing both the erasure of old information and the writing of new features. This unification empowers the network to explicitly control the spectrum of its layer-wise transition operator, enabling the modeling of complex, non-monotonic dynamics while preserving the stable training characteristics of gated residual architectures.",
      "pdf_url": "https://arxiv.org/pdf/2601.00417v1",
      "published": "2026-01-01T18:11:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.00417v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ]
    },
    {
      "title": "Do LLMs Judge Distantly Supervised Named Entity Labels Well? Constructing the JudgeWEL Dataset",
      "authors": [
        "Alistair Plum",
        "Laura Bernardy",
        "Tharindu Ranasinghe"
      ],
      "abstract": "We present judgeWEL, a dataset for named entity recognition (NER) in Luxembourgish, automatically labelled and subsequently verified using large language models (LLM) in a novel pipeline. Building datasets for under-represented languages remains one of the major bottlenecks in natural language processing, where the scarcity of resources and linguistic particularities make large-scale annotation costly and potentially inconsistent. To address these challenges, we propose and evaluate a novel approach that leverages Wikipedia and Wikidata as structured sources of weak supervision. By exploiting internal links within Wikipedia articles, we infer entity types based on their corresponding Wikidata entries, thereby generating initial annotations with minimal human intervention. Because such links are not uniformly reliable, we mitigate noise by employing and comparing several LLMs to identify and retain only high-quality labelled sentences. The resulting corpus is approximately five times larger than the currently available Luxembourgish NER dataset and offers broader and more balanced coverage across entity categories, providing a substantial new resource for multilingual and low-resource NER research.",
      "pdf_url": "https://arxiv.org/pdf/2601.00411v1",
      "published": "2026-01-01T17:53:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.00411v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Adaptive Causal Coordination Detection for Social Media: A Memory-Guided Framework with Semi-Supervised Learning",
      "authors": [
        "Weng Ding",
        "Yi Han",
        "Mu-Jiang-Shan Wang"
      ],
      "abstract": "Detecting coordinated inauthentic behavior on social media remains a critical and persistent challenge, as most existing approaches rely on superficial correlation analysis, employ static parameter settings, and demand extensive and labor-intensive manual annotation. To address these limitations systematically, we propose the Adaptive Causal Coordination Detection (ACCD) framework. ACCD adopts a three-stage, progressive architecture that leverages a memory-guided adaptive mechanism to dynamically learn and retain optimal detection configurations for diverse coordination scenarios. Specifically, in the first stage, ACCD introduces an adaptive Convergent Cross Mapping (CCM) technique to deeply identify genuine causal relationships between accounts. The second stage integrates active learning with uncertainty sampling within a semi-supervised classification scheme, significantly reducing the burden of manual labeling. The third stage deploys an automated validation module driven by historical detection experience, enabling self-verification and optimization of the detection outcomes. We conduct a comprehensive evaluation using real-world datasets, including the Twitter IRA dataset, Reddit coordination traces, and several widely-adopted bot detection benchmarks. Experimental results demonstrate that ACCD achieves an F1-score of 87.3\\% in coordinated attack detection, representing a 15.2\\% improvement over the strongest existing baseline. Furthermore, the system reduces manual annotation requirements by 68\\% and achieves a 2.8x speedup in processing through hierarchical clustering optimization. In summary, ACCD provides a more accurate, efficient, and highly automated end-to-end solution for identifying coordinated behavior on social platforms, offering substantial practical value and promising potential for broad application.",
      "pdf_url": "https://arxiv.org/pdf/2601.00400v1",
      "published": "2026-01-01T17:27:52+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.00400v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Engineering Attack Vectors and Detecting Anomalies in Additive Manufacturing",
      "authors": [
        "Md Mahbub Hasan",
        "Marcus Sternhagen",
        "Krishna Chandra Roy"
      ],
      "abstract": "Additive manufacturing (AM) is rapidly integrating into critical sectors such as aerospace, automotive, and healthcare. However, this cyber-physical convergence introduces new attack surfaces, especially at the interface between computer-aided design (CAD) and machine execution layers. In this work, we investigate targeted cyberattacks on two widely used fused deposition modeling (FDM) systems, Creality's flagship model K1 Max, and Ender 3. Our threat model is a multi-layered Man-in-the-Middle (MitM) intrusion, where the adversary intercepts and manipulates G-code files during upload from the user interface to the printer firmware. The MitM intrusion chain enables several stealthy sabotage scenarios. These attacks remain undetectable by conventional slicer software or runtime interfaces, resulting in structurally defective yet externally plausible printed parts. To counter these stealthy threats, we propose an unsupervised Intrusion Detection System (IDS) that analyzes structured machine logs generated during live printing. Our defense mechanism uses a frozen Transformer-based encoder (a BERT variant) to extract semantic representations of system behavior, followed by a contrastively trained projection head that learns anomaly-sensitive embeddings. Later, a clustering-based approach and a self-attention autoencoder are used for classification. Experimental results demonstrate that our approach effectively distinguishes between benign and compromised executions.",
      "pdf_url": "https://arxiv.org/pdf/2601.00384v1",
      "published": "2026-01-01T16:27:52+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.00384v1",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Word Frequency Counting Based on Serverless MapReduce",
      "authors": [
        "Hanzhe Li",
        "Bingchen Lin",
        "Mengyuan Xu"
      ],
      "abstract": "With the increasing demand for high-performance and high-efficiency computing, cloud computing, especially serverless computing, has gradually become a research hotspot in recent years, attracting numerous research attention. Meanwhile, MapReduce, which is a popular big data processing model in the industry, has been widely applied in various fields. Inspired by the serverless framework of Function as a Service and the high concurrency and robustness of MapReduce programming model, this paper focus on combining them to reduce the time span and increase the efficiency when executing the word frequency counting task. In this case, the paper use a MapReduce programming model based on a serverless computing platform to figure out the most optimized number of Map functions and Reduce functions for a particular task. For the same amount of workload, extensive experiments show both execution time reduces and the overall efficiency of the program improves at different rates as the number of map functions and reduce functions increases. This paper suppose the discovery of the most optimized number of map and reduce functions can help cooperations and programmers figure out the most optimized solutions.",
      "pdf_url": "https://arxiv.org/pdf/2601.00380v1",
      "published": "2026-01-01T16:16:47+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.00380v1",
      "categories": [
        "cs.DC",
        "cs.AI"
      ]
    },
    {
      "title": "In Line with Context: Repository-Level Code Generation via Context Inlining",
      "authors": [
        "Chao Hu",
        "Wenhao Zeng",
        "Yuling Shi",
        "Beijun Shen",
        "Xiaodong Gu"
      ],
      "abstract": "Repository-level code generation has attracted growing attention in recent years. Unlike function-level code generation, it requires the model to understand the entire repository, reasoning over complex dependencies across functions, classes, and modules. However, existing approaches such as retrieval-augmented generation (RAG) or context-based function selection often fall short: they primarily rely on surface-level similarity and struggle to capture the rich dependencies that govern repository-level semantics. In this paper, we introduce InlineCoder, a novel framework for repository-level code generation. InlineCoder enhances the understanding of repository context by inlining the unfinished function into its call graph, thereby reframing the challenging repository understanding as an easier function-level coding task. Given a function signature, InlineCoder first generates a draft completion, termed an anchor, which approximates downstream dependencies and enables perplexity-based confidence estimation. This anchor drives a bidirectional inlining process: (i) Upstream Inlining, which embeds the anchor into its callers to capture diverse usage scenarios; and (ii) Downstream Retrieval, which integrates the anchor's callees into the prompt to provide precise dependency context. The enriched context, combining draft completion with upstream and downstream perspectives, equips the LLM with a comprehensive repository view.",
      "pdf_url": "https://arxiv.org/pdf/2601.00376v1",
      "published": "2026-01-01T15:56:24+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.00376v1",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "PatchBlock: A Lightweight Defense Against Adversarial Patches for Embedded EdgeAI Devices",
      "authors": [
        "Nandish Chattopadhyay",
        "Abdul Basit",
        "Amira Guesmi",
        "Muhammad Abdullah Hanif",
        "Bassem Ouni",
        "Muhammad Shafique"
      ],
      "abstract": "Adversarial attacks pose a significant challenge to the reliable deployment of machine learning models in EdgeAI applications, such as autonomous driving and surveillance, which rely on resource-constrained devices for real-time inference. Among these, patch-based adversarial attacks, where small malicious patches (e.g., stickers) are applied to objects, can deceive neural networks into making incorrect predictions with potentially severe consequences. In this paper, we present PatchBlock, a lightweight framework designed to detect and neutralize adversarial patches in images. Leveraging outlier detection and dimensionality reduction, PatchBlock identifies regions affected by adversarial noise and suppresses their impact. It operates as a pre-processing module at the sensor level, efficiently running on CPUs in parallel with GPU inference, thus preserving system throughput while avoiding additional GPU overhead. The framework follows a three-stage pipeline: splitting the input into chunks (Chunking), detecting anomalous regions via a redesigned isolation forest with targeted cuts for faster convergence (Separating), and applying dimensionality reduction on the identified outliers (Mitigating). PatchBlock is both model- and patch-agnostic, can be retrofitted to existing pipelines, and integrates seamlessly between sensor inputs and downstream models. Evaluations across multiple neural architectures, benchmark datasets, attack types, and diverse edge devices demonstrate that PatchBlock consistently improves robustness, recovering up to 77% of model accuracy under strong patch attacks such as the Google Adversarial Patch, while maintaining high portability and minimal clean accuracy loss. Additionally, PatchBlock outperforms the state-of-the-art defenses in efficiency, in terms of computation time and energy consumption per sample, making it suitable for EdgeAI applications.",
      "pdf_url": "https://arxiv.org/pdf/2601.00367v1",
      "published": "2026-01-01T15:04:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.00367v1",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "title": "BERT-JEPA: Reorganizing CLS Embeddings for Language-Invariant Semantics",
      "authors": [
        "Taj Gillin",
        "Adam Lalani",
        "Kenneth Zhang",
        "Marcel Mateos Salles"
      ],
      "abstract": "Joint Embedding Predictive Architectures (JEPA) are a novel self supervised training technique that have shown recent promise across domains. We introduce BERT-JEPA (BEPA), a training paradigm that adds a JEPA training objective to BERT-style models, working to combat a collapsed [CLS] embedding space and turning it into a language-agnostic space. This new structure leads to increased performance across multilingual benchmarks.",
      "pdf_url": "https://arxiv.org/pdf/2601.00366v1",
      "published": "2026-01-01T14:59:58+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.00366v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Mapping Human Anti-collusion Mechanisms to Multi-agent AI",
      "authors": [
        "Jamiu Adekunle Idowu",
        "Ahmed Almasoud",
        "Ayman Alfahid"
      ],
      "abstract": "As multi-agent AI systems become increasingly autonomous, evidence shows they can develop collusive strategies similar to those long observed in human markets and institutions. While human domains have accumulated centuries of anti-collusion mechanisms, it remains unclear how these can be adapted to AI settings. This paper addresses that gap by (i) developing a taxonomy of human anti-collusion mechanisms, including sanctions, leniency & whistleblowing, monitoring & auditing, market design, and governance and (ii) mapping them to potential interventions for multi-agent AI systems. For each mechanism, we propose implementation approaches. We also highlight open challenges, such as the attribution problem (difficulty attributing emergent coordination to specific agents) identity fluidity (agents being easily forked or modified) the boundary problem (distinguishing beneficial cooperation from harmful collusion) and adversarial adaptation (agents learning to evade detection).",
      "pdf_url": "https://arxiv.org/pdf/2601.00360v1",
      "published": "2026-01-01T14:30:37+00:00",
      "arxiv_url": "http://arxiv.org/abs/2601.00360v1",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.CY"
      ]
    }
  ]
}