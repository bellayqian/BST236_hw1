{
  "last_updated": "2025-05-10T00:48:43.466500",
  "papers": [
    {
      "title": "Flow-GRPO: Training Flow Matching Models via Online RL",
      "authors": [
        "Jie Liu",
        "Gongye Liu",
        "Jiajun Liang",
        "Yangguang Li",
        "Jiaheng Liu",
        "Xintao Wang",
        "Pengfei Wan",
        "Di Zhang",
        "Wanli Ouyang"
      ],
      "abstract": "We propose Flow-GRPO, the first method integrating online reinforcement\nlearning (RL) into flow matching models. Our approach uses two key strategies:\n(1) an ODE-to-SDE conversion that transforms a deterministic Ordinary\nDifferential Equation (ODE) into an equivalent Stochastic Differential Equation\n(SDE) that matches the original model's marginal distribution at all timesteps,\nenabling statistical sampling for RL exploration; and (2) a Denoising Reduction\nstrategy that reduces training denoising steps while retaining the original\ninference timestep number, significantly improving sampling efficiency without\nperformance degradation. Empirically, Flow-GRPO is effective across multiple\ntext-to-image tasks. For complex compositions, RL-tuned SD3.5 generates nearly\nperfect object counts, spatial relations, and fine-grained attributes, boosting\nGenEval accuracy from $63\\%$ to $95\\%$. In visual text rendering, its accuracy\nimproves from $59\\%$ to $92\\%$, significantly enhancing text generation.\nFlow-GRPO also achieves substantial gains in human preference alignment.\nNotably, little to no reward hacking occurred, meaning rewards did not increase\nat the cost of image quality or diversity, and both remained stable in our\nexperiments.",
      "pdf_url": "http://arxiv.org/pdf/2505.05470v1",
      "published": "2025-05-08T17:58:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.05470v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "StreamBridge: Turning Your Offline Video Large Language Model into a Proactive Streaming Assistant",
      "authors": [
        "Haibo Wang",
        "Bo Feng",
        "Zhengfeng Lai",
        "Mingze Xu",
        "Shiyu Li",
        "Weifeng Ge",
        "Afshin Dehghan",
        "Meng Cao",
        "Ping Huang"
      ],
      "abstract": "We present StreamBridge, a simple yet effective framework that seamlessly\ntransforms offline Video-LLMs into streaming-capable models. It addresses two\nfundamental challenges in adapting existing models into online scenarios: (1)\nlimited capability for multi-turn real-time understanding, and (2) lack of\nproactive response mechanisms. Specifically, StreamBridge incorporates (1) a\nmemory buffer combined with a round-decayed compression strategy, supporting\nlong-context multi-turn interactions, and (2) a decoupled, lightweight\nactivation model that can be effortlessly integrated into existing Video-LLMs,\nenabling continuous proactive responses. To further support StreamBridge, we\nconstruct Stream-IT, a large-scale dataset tailored for streaming video\nunderstanding, featuring interleaved video-text sequences and diverse\ninstruction formats. Extensive experiments show that StreamBridge significantly\nimproves the streaming understanding capabilities of offline Video-LLMs across\nvarious tasks, outperforming even proprietary models such as GPT-4o and Gemini\n1.5 Pro. Simultaneously, it achieves competitive or superior performance on\nstandard video understanding benchmarks.",
      "pdf_url": "http://arxiv.org/pdf/2505.05467v1",
      "published": "2025-05-08T17:57:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.05467v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "ComPO: Preference Alignment via Comparison Oracles",
      "authors": [
        "Peter Chen",
        "Xi Chen",
        "Wotao Yin",
        "Tianyi Lin"
      ],
      "abstract": "Direct alignment methods are increasingly used for aligning large language\nmodels (LLMs) with human preferences. However, these methods suffer from the\nissues of verbosity and likelihood displacement, which can be driven by the\nnoisy preference pairs that induce similar likelihood for preferred and\ndispreferred responses. The contributions of this paper are two-fold. First, we\npropose a new preference alignment method based on comparison oracles and\nprovide the convergence guarantee for its basic scheme. Second, we improve our\nmethod using some heuristics and conduct the experiments to demonstrate the\nflexibility and compatibility of practical scheme in improving the performance\nof LLMs using noisy preference pairs. Evaluations are conducted across multiple\nbase and instruction-tuned models (Mistral-7B, Llama-3-8B and Gemma-2-9B) with\nbenchmarks (AlpacaEval 2, MT-Bench and Arena-Hard). Experimental results show\nthe effectiveness of our method as an alternative to addressing the limitations\nof existing direct alignment methods. A highlight of our work is that we\nevidence the importance of designing specialized methods for preference pairs\nwith distinct likelihood margin, which complements the recent findings in\n\\citet{Razin-2025-Unintentional}.",
      "pdf_url": "http://arxiv.org/pdf/2505.05465v1",
      "published": "2025-05-08T17:56:57+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.05465v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Conversational Process Model Redesign",
      "authors": [
        "Nataliia Klievtsova",
        "Timotheus Kampik",
        "Juergen Mangler",
        "Stefanie Rinderle-Ma"
      ],
      "abstract": "With the recent success of large language models (LLMs), the idea of\nAI-augmented Business Process Management systems is becoming more feasible. One\nof their essential characteristics is the ability to be conversationally\nactionable, allowing humans to interact with the LLM effectively to perform\ncrucial process life cycle tasks such as process model design and redesign.\nHowever, most current research focuses on single-prompt execution and\nevaluation of results, rather than on continuous interaction between the user\nand the LLM. In this work, we aim to explore the feasibility of using LLMs to\nempower domain experts in the creation and redesign of process models in an\niterative and effective way. The proposed conversational process model redesign\n(CPD) approach receives as input a process model and a redesign request by the\nuser in natural language. Instead of just letting the LLM make changes, the LLM\nis employed to (a) identify process change patterns from literature, (b)\nre-phrase the change request to be aligned with an expected wording for the\nidentified pattern (i.e., the meaning), and then to (c) apply the meaning of\nthe change to the process model. This multi-step approach allows for\nexplainable and reproducible changes. In order to ensure the feasibility of the\nCPD approach, and to find out how well the patterns from literature can be\nhandled by the LLM, we performed an extensive evaluation. The results show that\nsome patterns are hard to understand by LLMs and by users. Within the scope of\nthe study, we demonstrated that users need support to describe the changes\nclearly. Overall the evaluation shows that the LLMs can handle most changes\nwell according to a set of completeness and correctness criteria.",
      "pdf_url": "http://arxiv.org/pdf/2505.05453v1",
      "published": "2025-05-08T17:44:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.05453v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "EcoAgent: An Efficient Edge-Cloud Collaborative Multi-Agent Framework for Mobile Automation",
      "authors": [
        "Biao Yi",
        "Xavier Hu",
        "Yurun Chen",
        "Shengyu Zhang",
        "Hongxia Yang",
        "Fan Wu",
        "Fei Wu"
      ],
      "abstract": "Cloud-based mobile agents powered by (multimodal) large language models\n((M)LLMs) offer strong reasoning abilities but suffer from high latency and\ncost. While fine-tuned (M)SLMs enable edge deployment, they often lose general\ncapabilities and struggle with complex tasks. To address this, we propose\nEcoAgent, an Edge-Cloud cOllaborative multi-agent framework for mobile\nautomation. EcoAgent features a closed-loop collaboration among a cloud-based\nPlanning Agent and two edge-based agents: the Execution Agent for action\nexecution and the Observation Agent for verifying outcomes. The Observation\nAgent uses a Pre-Understanding Module to compress screen images into concise\ntext, reducing token usage. In case of failure, the Planning Agent retrieves\nscreen history and replans via a Reflection Module. Experiments on AndroidWorld\nshow that EcoAgent maintains high task success rates while significantly\nreducing MLLM token consumption, enabling efficient and practical mobile\nautomation.",
      "pdf_url": "http://arxiv.org/pdf/2505.05440v1",
      "published": "2025-05-08T17:31:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.05440v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "TransProQA: an LLM-based literary Translation evaluation metric with Professional Question Answering",
      "authors": [
        "Ran Zhang",
        "Wei Zhao",
        "Lieve Macken",
        "Steffen Eger"
      ],
      "abstract": "The impact of Large Language Models (LLMs) has extended into literary\ndomains. However, existing evaluation metrics prioritize mechanical accuracy\nover artistic expression and tend to overrate machine translation (MT) as being\nsuperior to experienced professional human translation. In the long run, this\nbias could result in a permanent decline in translation quality and cultural\nauthenticity. In response to the urgent need for a specialized literary\nevaluation metric, we introduce TransProQA, a novel, reference-free, LLM-based\nquestion-answering (QA) framework designed specifically for literary\ntranslation evaluation. TransProQA uniquely integrates insights from\nprofessional literary translators and researchers, focusing on critical\nelements in literary quality assessment such as literary devices, cultural\nunderstanding, and authorial voice. Our extensive evaluation shows that while\nliterary-finetuned XCOMET-XL yields marginal gains, TransProQA substantially\noutperforms current metrics, achieving up to 0.07 gain in correlation (ACC-EQ\nand Kendall's tau) and surpassing the best state-of-the-art (SOTA) metrics by\nover 15 points in adequacy assessments. Incorporating professional translator\ninsights as weights further improves performance, highlighting the value of\ntranslator inputs. Notably, TransProQA approaches human-level evaluation\nperformance comparable to trained linguistic annotators. It demonstrates broad\napplicability to open-source models such as LLaMA3.3-70b and Qwen2.5-32b,\nindicating its potential as an accessible and training-free literary evaluation\nmetric and a valuable tool for evaluating texts that require local processing\ndue to copyright or ethical considerations.",
      "pdf_url": "http://arxiv.org/pdf/2505.05423v1",
      "published": "2025-05-08T17:12:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.05423v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "TokLIP: Marry Visual Tokens to CLIP for Multimodal Comprehension and Generation",
      "authors": [
        "Haokun Lin",
        "Teng Wang",
        "Yixiao Ge",
        "Yuying Ge",
        "Zhichao Lu",
        "Ying Wei",
        "Qingfu Zhang",
        "Zhenan Sun",
        "Ying Shan"
      ],
      "abstract": "Pioneering token-based works such as Chameleon and Emu3 have established a\nfoundation for multimodal unification but face challenges of high training\ncomputational overhead and limited comprehension performance due to a lack of\nhigh-level semantics. In this paper, we introduce TokLIP, a visual tokenizer\nthat enhances comprehension by semanticizing vector-quantized (VQ) tokens and\nincorporating CLIP-level semantics while enabling end-to-end multimodal\nautoregressive training with standard VQ tokens. TokLIP integrates a low-level\ndiscrete VQ tokenizer with a ViT-based token encoder to capture high-level\ncontinuous semantics. Unlike previous approaches (e.g., VILA-U) that discretize\nhigh-level features, TokLIP disentangles training objectives for comprehension\nand generation, allowing the direct application of advanced VQ tokenizers\nwithout the need for tailored quantization operations. Our empirical results\ndemonstrate that TokLIP achieves exceptional data efficiency, empowering visual\ntokens with high-level semantic understanding while enhancing low-level\ngenerative capacity, making it well-suited for autoregressive Transformers in\nboth comprehension and generation tasks. The code and models are available at\nhttps://github.com/TencentARC/TokLIP.",
      "pdf_url": "http://arxiv.org/pdf/2505.05422v1",
      "published": "2025-05-08T17:12:19+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.05422v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Reasoning Models Don't Always Say What They Think",
      "authors": [
        "Yanda Chen",
        "Joe Benton",
        "Ansh Radhakrishnan",
        "Jonathan Uesato",
        "Carson Denison",
        "John Schulman",
        "Arushi Somani",
        "Peter Hase",
        "Misha Wagner",
        "Fabien Roger",
        "Vlad Mikulik",
        "Samuel R. Bowman",
        "Jan Leike",
        "Jared Kaplan",
        "Ethan Perez"
      ],
      "abstract": "Chain-of-thought (CoT) offers a potential boon for AI safety as it allows\nmonitoring a model's CoT to try to understand its intentions and reasoning\nprocesses. However, the effectiveness of such monitoring hinges on CoTs\nfaithfully representing models' actual reasoning processes. We evaluate CoT\nfaithfulness of state-of-the-art reasoning models across 6 reasoning hints\npresented in the prompts and find: (1) for most settings and models tested,\nCoTs reveal their usage of hints in at least 1% of examples where they use the\nhint, but the reveal rate is often below 20%, (2) outcome-based reinforcement\nlearning initially improves faithfulness but plateaus without saturating, and\n(3) when reinforcement learning increases how frequently hints are used (reward\nhacking), the propensity to verbalize them does not increase, even without\ntraining against a CoT monitor. These results suggest that CoT monitoring is a\npromising way of noticing undesired behaviors during training and evaluations,\nbut that it is not sufficient to rule them out. They also suggest that in\nsettings like ours where CoT reasoning is not necessary, test-time monitoring\nof CoTs is unlikely to reliably catch rare and catastrophic unexpected\nbehaviors.",
      "pdf_url": "http://arxiv.org/pdf/2505.05410v1",
      "published": "2025-05-08T16:51:43+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.05410v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Crosslingual Reasoning through Test-Time Scaling",
      "authors": [
        "Zheng-Xin Yong",
        "M. Farid Adilazuarda",
        "Jonibek Mansurov",
        "Ruochen Zhang",
        "Niklas Muennighoff",
        "Carsten Eickhoff",
        "Genta Indra Winata",
        "Julia Kreutzer",
        "Stephen H. Bach",
        "Alham Fikri Aji"
      ],
      "abstract": "Reasoning capabilities of large language models are primarily studied for\nEnglish, even when pretrained models are multilingual. In this work, we\ninvestigate to what extent English reasoning finetuning with long\nchain-of-thoughts (CoTs) can generalize across languages. First, we find that\nscaling up inference compute for English-centric reasoning language models\n(RLMs) improves multilingual mathematical reasoning across many languages\nincluding low-resource languages, to an extent where they outperform models\ntwice their size. Second, we reveal that while English-centric RLM's CoTs are\nnaturally predominantly English, they consistently follow a quote-and-think\npattern to reason about quoted non-English inputs. Third, we discover an\neffective strategy to control the language of long CoT reasoning, and we\nobserve that models reason better and more efficiently in high-resource\nlanguages. Finally, we observe poor out-of-domain reasoning generalization, in\nparticular from STEM to cultural commonsense knowledge, even for English.\nOverall, we demonstrate the potentials, study the mechanisms and outline the\nlimitations of crosslingual generalization of English reasoning test-time\nscaling. We conclude that practitioners should let English-centric RLMs reason\nin high-resource languages, while further work is needed to improve reasoning\nin low-resource languages and out-of-domain contexts.",
      "pdf_url": "http://arxiv.org/pdf/2505.05408v1",
      "published": "2025-05-08T16:50:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.05408v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "CART-ELC: Oblique Decision Tree Induction via Exhaustive Search",
      "authors": [
        "Andrew D. Laack"
      ],
      "abstract": "Oblique decision trees have attracted attention due to their potential for\nimproved classification performance over traditional axis-aligned decision\ntrees. However, methods that rely on exhaustive search to find oblique splits\nface computational challenges. As a result, they have not been widely explored.\nWe introduce a novel algorithm, Classification and Regression Tree - Exhaustive\nLinear Combinations (CART-ELC), for inducing oblique decision trees that\nperforms an exhaustive search on a restricted set of hyperplanes. We then\ninvestigate the algorithm's computational complexity and its predictive\ncapabilities. Our results demonstrate that CART-ELC consistently achieves\ncompetitive performance on small datasets, often yielding statistically\nsignificant improvements in classification accuracy relative to existing\ndecision tree induction algorithms, while frequently producing shallower,\nsimpler, and thus more interpretable trees.",
      "pdf_url": "http://arxiv.org/pdf/2505.05402v1",
      "published": "2025-05-08T16:42:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.05402v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DS",
        "I.2.6; I.5.2; F.2.2; G.3; G.2.1"
      ]
    },
    {
      "title": "A Pain Assessment Framework based on multimodal data and Deep Machine Learning methods",
      "authors": [
        "Stefanos Gkikas"
      ],
      "abstract": "From the original abstract:\n  This thesis initially aims to study the pain assessment process from a\nclinical-theoretical perspective while exploring and examining existing\nautomatic approaches. Building on this foundation, the primary objective of\nthis Ph.D. project is to develop innovative computational methods for automatic\npain assessment that achieve high performance and are applicable in real\nclinical settings. A primary goal is to thoroughly investigate and assess\nsignificant factors, including demographic elements that impact pain\nperception, as recognized in pain research, through a computational standpoint.\nWithin the limits of the available data in this research area, our goal was to\ndesign, develop, propose, and offer automatic pain assessment pipelines for\nunimodal and multimodal configurations that are applicable to the specific\nrequirements of different scenarios. The studies published in this Ph.D. thesis\nshowcased the effectiveness of the proposed methods, achieving state-of-the-art\nresults. Additionally, they paved the way for exploring new approaches in\nartificial intelligence, foundation models, and generative artificial\nintelligence.",
      "pdf_url": "http://arxiv.org/pdf/2505.05396v1",
      "published": "2025-05-08T16:32:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.05396v1",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ]
    },
    {
      "title": "Threshold Modulation for Online Test-Time Adaptation of Spiking Neural Networks",
      "authors": [
        "Kejie Zhao",
        "Wenjia Hua",
        "Aiersi Tuerhong",
        "Luziwei Leng",
        "Yuxin Ma",
        "Qinghua Guo"
      ],
      "abstract": "Recently, spiking neural networks (SNNs), deployed on neuromorphic chips,\nprovide highly efficient solutions on edge devices in different scenarios.\nHowever, their ability to adapt to distribution shifts after deployment has\nbecome a crucial challenge. Online test-time adaptation (OTTA) offers a\npromising solution by enabling models to dynamically adjust to new data\ndistributions without requiring source data or labeled target samples.\nNevertheless, existing OTTA methods are largely designed for traditional\nartificial neural networks and are not well-suited for SNNs. To address this\ngap, we propose a low-power, neuromorphic chip-friendly online test-time\nadaptation framework, aiming to enhance model generalization under distribution\nshifts. The proposed approach is called Threshold Modulation (TM), which\ndynamically adjusts the firing threshold through neuronal dynamics-inspired\nnormalization, being more compatible with neuromorphic hardware. Experimental\nresults on benchmark datasets demonstrate the effectiveness of this method in\nimproving the robustness of SNNs against distribution shifts while maintaining\nlow computational cost. The proposed method offers a practical solution for\nonline test-time adaptation of SNNs, providing inspiration for the design of\nfuture neuromorphic chips. The demo code is available at\ngithub.com/NneurotransmitterR/TM-OTTA-SNN.",
      "pdf_url": "http://arxiv.org/pdf/2505.05375v1",
      "published": "2025-05-08T16:09:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.05375v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ]
    },
    {
      "title": "Time of the Flight of the Gaussians: Optimizing Depth Indirectly in Dynamic Radiance Fields",
      "authors": [
        "Runfeng Li",
        "Mikhail Okunev",
        "Zixuan Guo",
        "Anh Ha Duong",
        "Christian Richardt",
        "Matthew O'Toole",
        "James Tompkin"
      ],
      "abstract": "We present a method to reconstruct dynamic scenes from monocular\ncontinuous-wave time-of-flight (C-ToF) cameras using raw sensor samples that\nachieves similar or better accuracy than neural volumetric approaches and is\n100x faster. Quickly achieving high-fidelity dynamic 3D reconstruction from a\nsingle viewpoint is a significant challenge in computer vision. In C-ToF\nradiance field reconstruction, the property of interest-depth-is not directly\nmeasured, causing an additional challenge. This problem has a large and\nunderappreciated impact upon the optimization when using a fast primitive-based\nscene representation like 3D Gaussian splatting, which is commonly used with\nmulti-view data to produce satisfactory results and is brittle in its\noptimization otherwise. We incorporate two heuristics into the optimization to\nimprove the accuracy of scene geometry represented by Gaussians. Experimental\nresults show that our approach produces accurate reconstructions under\nconstrained C-ToF sensing conditions, including for fast motions like swinging\nbaseball bats. https://visual.cs.brown.edu/gftorf",
      "pdf_url": "http://arxiv.org/pdf/2505.05356v1",
      "published": "2025-05-08T15:45:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.05356v1",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "High-fidelity Grain Growth Modeling: Leveraging Deep Learning for Fast Computations",
      "authors": [
        "Pungponhavoan Tep",
        "Marc Bernacki"
      ],
      "abstract": "Grain growth simulation is crucial for predicting metallic material\nmicrostructure evolution during annealing and resulting final mechanical\nproperties, but traditional partial differential equation-based methods are\ncomputationally expensive, creating bottlenecks in materials design and\nmanufacturing. In this work, we introduce a machine learning framework that\ncombines a Convolutional Long Short-Term Memory networks with an Autoencoder to\nefficiently predict grain growth evolution. Our approach captures both spatial\nand temporal aspects of grain evolution while encoding high-dimensional grain\nstructure data into a compact latent space for pattern learning, enhanced by a\nnovel composite loss function combining Mean Squared Error, Structural\nSimilarity Index Measurement, and Boundary Preservation to maintain structural\nintegrity of grain boundary topology of the prediction. Results demonstrated\nthat our machine learning approach accelerates grain growth prediction by up to\n\\SI{89}{\\times} faster, reducing computation time from \\SI{10}{\\minute} to\napproximately \\SI{10}{\\second} while maintaining high-fidelity predictions. The\nbest model (S-30-30) achieving a structural similarity score of\n\\SI{86.71}{\\percent} and mean grain size error of just \\SI{0.07}{\\percent}. All\nmodels accurately captured grain boundary topology, morphology, and size\ndistributions. This approach enables rapid microstructural prediction for\napplications where conventional simulations are prohibitively time-consuming,\npotentially accelerating innovation in materials science and manufacturing.",
      "pdf_url": "http://arxiv.org/pdf/2505.05354v1",
      "published": "2025-05-08T15:43:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.05354v1",
      "categories": [
        "cond-mat.mtrl-sci",
        "cs.AI"
      ]
    },
    {
      "title": "Feature-Augmented Deep Networks for Multiscale Building Segmentation in High-Resolution UAV and Satellite Imagery",
      "authors": [
        "Chintan B. Maniyar",
        "Minakshi Kumar",
        "Gengchen Mai"
      ],
      "abstract": "Accurate building segmentation from high-resolution RGB imagery remains\nchallenging due to spectral similarity with non-building features, shadows, and\nirregular building geometries. In this study, we present a comprehensive deep\nlearning framework for multiscale building segmentation using RGB aerial and\nsatellite imagery with spatial resolutions ranging from 0.4m to 2.7m. We curate\na diverse, multi-sensor dataset and introduce feature-augmented inputs by\nderiving secondary representations including Principal Component Analysis\n(PCA), Visible Difference Vegetation Index (VDVI), Morphological Building Index\n(MBI), and Sobel edge filters from RGB channels. These features guide a\nRes-U-Net architecture in learning complex spatial patterns more effectively.\nWe also propose training policies incorporating layer freezing, cyclical\nlearning rates, and SuperConvergence to reduce training time and resource\nusage. Evaluated on a held-out WorldView-3 image, our model achieves an overall\naccuracy of 96.5%, an F1-score of 0.86, and an Intersection over Union (IoU) of\n0.80, outperforming existing RGB-based benchmarks. This study demonstrates the\neffectiveness of combining multi-resolution imagery, feature augmentation, and\noptimized training strategies for robust building segmentation in remote\nsensing applications.",
      "pdf_url": "http://arxiv.org/pdf/2505.05321v1",
      "published": "2025-05-08T15:08:36+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.05321v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.4.6; I.4.10; I.5.1; I.2.10"
      ]
    },
    {
      "title": "Mapping User Trust in Vision Language Models: Research Landscape, Challenges, and Prospects",
      "authors": [
        "Agnese Chiatti",
        "Sara Bernardini",
        "Lara Shibelski Godoy Piccolo",
        "Viola Schiaffonati",
        "Matteo Matteucci"
      ],
      "abstract": "The rapid adoption of Vision Language Models (VLMs), pre-trained on large\nimage-text and video-text datasets, calls for protecting and informing users\nabout when to trust these systems. This survey reviews studies on trust\ndynamics in user-VLM interactions, through a multi-disciplinary taxonomy\nencompassing different cognitive science capabilities, collaboration modes, and\nagent behaviours. Literature insights and findings from a workshop with\nprospective VLM users inform preliminary requirements for future VLM trust\nstudies.",
      "pdf_url": "http://arxiv.org/pdf/2505.05318v1",
      "published": "2025-05-08T15:02:49+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.05318v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CY",
        "cs.HC",
        "cs.RO"
      ]
    },
    {
      "title": "Scalable Chain of Thoughts via Elastic Reasoning",
      "authors": [
        "Yuhui Xu",
        "Hanze Dong",
        "Lei Wang",
        "Doyen Sahoo",
        "Junnan Li",
        "Caiming Xiong"
      ],
      "abstract": "Large reasoning models (LRMs) have achieved remarkable progress on complex\ntasks by generating extended chains of thought (CoT). However, their\nuncontrolled output lengths pose significant challenges for real-world\ndeployment, where inference-time budgets on tokens, latency, or compute are\nstrictly constrained. We propose Elastic Reasoning, a novel framework for\nscalable chain of thoughts that explicitly separates reasoning into two\nphases--thinking and solution--with independently allocated budgets. At test\ntime, Elastic Reasoning prioritize that completeness of solution segments,\nsignificantly improving reliability under tight resource constraints. To train\nmodels that are robust to truncated thinking, we introduce a lightweight\nbudget-constrained rollout strategy, integrated into GRPO, which teaches the\nmodel to reason adaptively when the thinking process is cut short and\ngeneralizes effectively to unseen budget constraints without additional\ntraining. Empirical results on mathematical (AIME, MATH500) and programming\n(LiveCodeBench, Codeforces) benchmarks demonstrate that Elastic Reasoning\nperforms robustly under strict budget constraints, while incurring\nsignificantly lower training cost than baseline methods. Remarkably, our\napproach also produces more concise and efficient reasoning even in\nunconstrained settings. Elastic Reasoning offers a principled and practical\nsolution to the pressing challenge of controllable reasoning at scale.",
      "pdf_url": "http://arxiv.org/pdf/2505.05315v1",
      "published": "2025-05-08T15:01:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.05315v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Benchmarking Ophthalmology Foundation Models for Clinically Significant Age Macular Degeneration Detection",
      "authors": [
        "Benjamin A. Cohen",
        "Jonathan Fhima",
        "Meishar Meisel",
        "Baskin Meital",
        "Luis Filipe Nakayama",
        "Eran Berkowitz",
        "Joachim A. Behar"
      ],
      "abstract": "Self-supervised learning (SSL) has enabled Vision Transformers (ViTs) to\nlearn robust representations from large-scale natural image datasets, enhancing\ntheir generalization across domains. In retinal imaging, foundation models\npretrained on either natural or ophthalmic data have shown promise, but the\nbenefits of in-domain pretraining remain uncertain. To investigate this, we\nbenchmark six SSL-pretrained ViTs on seven digital fundus image (DFI) datasets\ntotaling 70,000 expert-annotated images for the task of moderate-to-late\nage-related macular degeneration (AMD) identification. Our results show that\niBOT pretrained on natural images achieves the highest out-of-distribution\ngeneralization, with AUROCs of 0.80-0.97, outperforming domain-specific models,\nwhich achieved AUROCs of 0.78-0.96 and a baseline ViT-L with no pretraining,\nwhich achieved AUROCs of 0.68-0.91. These findings highlight the value of\nfoundation models in improving AMD identification and challenge the assumption\nthat in-domain pretraining is necessary. Furthermore, we release BRAMD, an\nopen-access dataset (n=587) of DFIs with AMD labels from Brazil.",
      "pdf_url": "http://arxiv.org/pdf/2505.05291v1",
      "published": "2025-05-08T14:31:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.05291v1",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "q-bio.TO"
      ]
    },
    {
      "title": "PlaceIt3D: Language-Guided Object Placement in Real 3D Scenes",
      "authors": [
        "Ahmed Abdelreheem",
        "Filippo Aleotti",
        "Jamie Watson",
        "Zawar Qureshi",
        "Abdelrahman Eldesokey",
        "Peter Wonka",
        "Gabriel Brostow",
        "Sara Vicente",
        "Guillermo Garcia-Hernando"
      ],
      "abstract": "We introduce the novel task of Language-Guided Object Placement in Real 3D\nScenes. Our model is given a 3D scene's point cloud, a 3D asset, and a textual\nprompt broadly describing where the 3D asset should be placed. The task here is\nto find a valid placement for the 3D asset that respects the prompt. Compared\nwith other language-guided localization tasks in 3D scenes such as grounding,\nthis task has specific challenges: it is ambiguous because it has multiple\nvalid solutions, and it requires reasoning about 3D geometric relationships and\nfree space. We inaugurate this task by proposing a new benchmark and evaluation\nprotocol. We also introduce a new dataset for training 3D LLMs on this task, as\nwell as the first method to serve as a non-trivial baseline. We believe that\nthis challenging task and our new benchmark could become part of the suite of\nbenchmarks used to evaluate and compare generalist 3D LLM models.",
      "pdf_url": "http://arxiv.org/pdf/2505.05288v1",
      "published": "2025-05-08T14:29:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.05288v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ]
    },
    {
      "title": "Software Development Life Cycle Perspective: A Survey of Benchmarks for CodeLLMs and Agents",
      "authors": [
        "Kaixin Wang",
        "Tianlin Li",
        "Xiaoyu Zhang",
        "Chong Wang",
        "Weisong Sun",
        "Yang Liu",
        "Bin Shi"
      ],
      "abstract": "Code large language models (CodeLLMs) and agents have shown great promise in\ntackling complex software engineering tasks.Compared to traditional software\nengineering methods, CodeLLMs and agents offer stronger abilities, and can\nflexibly process inputs and outputs in both natural and code. Benchmarking\nplays a crucial role in evaluating the capabilities of CodeLLMs and agents,\nguiding their development and deployment. However, despite their growing\nsignificance, there remains a lack of comprehensive reviews of benchmarks for\nCodeLLMs and agents. To bridge this gap, this paper provides a comprehensive\nreview of existing benchmarks for CodeLLMs and agents, studying and analyzing\n181 benchmarks from 461 relevant papers, covering the different phases of the\nsoftware development life cycle (SDLC). Our findings reveal a notable imbalance\nin the coverage of current benchmarks, with approximately 60% focused on the\nsoftware development phase in SDLC, while requirements engineering and software\ndesign phases receive minimal attention at only 5% and 3%, respectively.\nAdditionally, Python emerges as the dominant programming language across the\nreviewed benchmarks. Finally, this paper highlights the challenges of current\nresearch and proposes future directions, aiming to narrow the gap between the\ntheoretical capabilities of CodeLLMs and agents and their application in\nreal-world scenarios.",
      "pdf_url": "http://arxiv.org/pdf/2505.05283v1",
      "published": "2025-05-08T14:27:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.05283v1",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "T-T: Table Transformer for Tagging-based Aspect Sentiment Triplet Extraction",
      "authors": [
        "Kun Peng",
        "Chaodong Tong",
        "Cong Cao",
        "Hao Peng",
        "Qian Li",
        "Guanlin Wu",
        "Lei Jiang",
        "Yanbing Liu",
        "Philip S. Yu"
      ],
      "abstract": "Aspect sentiment triplet extraction (ASTE) aims to extract triplets composed\nof aspect terms, opinion terms, and sentiment polarities from given sentences.\nThe table tagging method is a popular approach to addressing this task, which\nencodes a sentence into a 2-dimensional table, allowing for the tagging of\nrelations between any two words. Previous efforts have focused on designing\nvarious downstream relation learning modules to better capture interactions\nbetween tokens in the table, revealing that a stronger capability to capture\nrelations can lead to greater improvements in the model. Motivated by this, we\nattempt to directly utilize transformer layers as downstream relation learning\nmodules. Due to the powerful semantic modeling capability of transformers, it\nis foreseeable that this will lead to excellent improvement. However, owing to\nthe quadratic relation between the length of the table and the length of the\ninput sentence sequence, using transformers directly faces two challenges:\noverly long table sequences and unfair local attention interaction. To address\nthese challenges, we propose a novel Table-Transformer (T-T) for the\ntagging-based ASTE method. Specifically, we introduce a stripe attention\nmechanism with a loop-shift strategy to tackle these challenges. The former\nmodifies the global attention mechanism to only attend to a 2-dimensional local\nattention window, while the latter facilitates interaction between different\nattention windows. Extensive and comprehensive experiments demonstrate that the\nT-T, as a downstream relation learning module, achieves state-of-the-art\nperformance with lower computational costs.",
      "pdf_url": "http://arxiv.org/pdf/2505.05271v1",
      "published": "2025-05-08T14:17:27+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.05271v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Enhancing Cooperative Multi-Agent Reinforcement Learning with State Modelling and Adversarial Exploration",
      "authors": [
        "Andreas Kontogiannis",
        "Konstantinos Papathanasiou",
        "Yi Shen",
        "Giorgos Stamou",
        "Michael M. Zavlanos",
        "George Vouros"
      ],
      "abstract": "Learning to cooperate in distributed partially observable environments with\nno communication abilities poses significant challenges for multi-agent deep\nreinforcement learning (MARL). This paper addresses key concerns in this\ndomain, focusing on inferring state representations from individual agent\nobservations and leveraging these representations to enhance agents'\nexploration and collaborative task execution policies. To this end, we propose\na novel state modelling framework for cooperative MARL, where agents infer\nmeaningful belief representations of the non-observable state, with respect to\noptimizing their own policies, while filtering redundant and less informative\njoint state information. Building upon this framework, we propose the MARL SMPE\nalgorithm. In SMPE, agents enhance their own policy's discriminative abilities\nunder partial observability, explicitly by incorporating their beliefs into the\npolicy network, and implicitly by adopting an adversarial type of exploration\npolicies which encourages agents to discover novel, high-value states while\nimproving the discriminative abilities of others. Experimentally, we show that\nSMPE outperforms state-of-the-art MARL algorithms in complex fully cooperative\ntasks from the MPE, LBF, and RWARE benchmarks.",
      "pdf_url": "http://arxiv.org/pdf/2505.05262v1",
      "published": "2025-05-08T14:07:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.05262v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ]
    },
    {
      "title": "Advancing Neural Network Verification through Hierarchical Safety Abstract Interpretation",
      "authors": [
        "Luca Marzari",
        "Isabella Mastroeni",
        "Alessandro Farinelli"
      ],
      "abstract": "Traditional methods for formal verification (FV) of deep neural networks\n(DNNs) are constrained by a binary encoding of safety properties, where a model\nis classified as either safe or unsafe (robust or not robust). This binary\nencoding fails to capture the nuanced safety levels within a model, often\nresulting in either overly restrictive or too permissive requirements. In this\npaper, we introduce a novel problem formulation called Abstract\nDNN-Verification, which verifies a hierarchical structure of unsafe outputs,\nproviding a more granular analysis of the safety aspect for a given DNN.\nCrucially, by leveraging abstract interpretation and reasoning about output\nreachable sets, our approach enables assessing multiple safety levels during\nthe FV process, requiring the same (in the worst case) or even potentially less\ncomputational effort than the traditional binary verification approach.\nSpecifically, we demonstrate how this formulation allows rank adversarial\ninputs according to their abstract safety level violation, offering a more\ndetailed evaluation of the model's safety and robustness. Our contributions\ninclude a theoretical exploration of the relationship between our novel\nabstract safety formulation and existing approaches that employ abstract\ninterpretation for robustness verification, complexity analysis of the novel\nproblem introduced, and an empirical evaluation considering both a complex deep\nreinforcement learning task (based on Habitat 3.0) and standard\nDNN-Verification benchmarks.",
      "pdf_url": "http://arxiv.org/pdf/2505.05235v1",
      "published": "2025-05-08T13:29:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.05235v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "ChemRxivQuest: A Curated Chemistry Question-Answer Database Extracted from ChemRxiv Preprints",
      "authors": [
        "Mahmoud Amiri",
        "Thomas Bocklitz"
      ],
      "abstract": "The rapid expansion of chemistry literature poses significant challenges for\nresearchers seeking to efficiently access domain-specific knowledge. To support\nadvancements in chemistry-focused natural language processing (NLP), we present\nChemRxivQuest, a curated dataset of 970 high-quality question-answer (QA) pairs\nderived from 155 ChemRxiv preprints across 17 subfields of chemistry. Each QA\npair is explicitly linked to its source text segment to ensure traceability and\ncontextual accuracy. ChemRxivQuest was constructed using an automated pipeline\nthat combines optical character recognition (OCR), GPT-4o-based QA generation,\nand a fuzzy matching technique for answer verification. The dataset emphasizes\nconceptual, mechanistic, applied, and experimental questions, enabling\napplications in retrieval-based QA systems, search engine development, and\nfine-tuning of domain-adapted large language models. We analyze the dataset's\nstructure, coverage, and limitations, and outline future directions for\nexpansion and expert validation. ChemRxivQuest provides a foundational resource\nfor chemistry NLP research, education, and tool development.",
      "pdf_url": "http://arxiv.org/pdf/2505.05232v1",
      "published": "2025-05-08T13:26:33+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.05232v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Put CASH on Bandits: A Max K-Armed Problem for Automated Machine Learning",
      "authors": [
        "Amir Rezaei Balef",
        "Claire Vernade",
        "Katharina Eggensperger"
      ],
      "abstract": "The Combined Algorithm Selection and Hyperparameter optimization (CASH) is a\nchallenging resource allocation problem in the field of AutoML. We propose\nMaxUCB, a max $k$-armed bandit method to trade off exploring different model\nclasses and conducting hyperparameter optimization. MaxUCB is specifically\ndesigned for the light-tailed and bounded reward distributions arising in this\nsetting and, thus, provides an efficient alternative compared to classic max\n$k$-armed bandit methods assuming heavy-tailed reward distributions. We\ntheoretically and empirically evaluate our method on four standard AutoML\nbenchmarks, demonstrating superior performance over prior approaches.",
      "pdf_url": "http://arxiv.org/pdf/2505.05226v1",
      "published": "2025-05-08T13:18:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.05226v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Incentive-Aware Machine Learning; Robustness, Fairness, Improvement & Causality",
      "authors": [
        "Chara Podimata"
      ],
      "abstract": "The article explores the emerging domain of incentive-aware machine learning\n(ML), which focuses on algorithmic decision-making in contexts where\nindividuals can strategically modify their inputs to influence outcomes. It\ncategorizes the research into three perspectives: robustness, aiming to design\nmodels resilient to \"gaming\"; fairness, analyzing the societal impacts of such\nsystems; and improvement/causality, recognizing situations where strategic\nactions lead to genuine personal or societal improvement. The paper introduces\na unified framework encapsulating models for these perspectives, including\noffline, online, and causal settings, and highlights key challenges such as\ndifferentiating between gaming and improvement and addressing heterogeneity\namong agents. By synthesizing findings from diverse works, we outline\ntheoretical advancements and practical solutions for robust, fair, and\ncausally-informed incentive-aware ML systems.",
      "pdf_url": "http://arxiv.org/pdf/2505.05211v1",
      "published": "2025-05-08T13:04:32+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.05211v1",
      "categories": [
        "cs.GT",
        "cs.AI"
      ]
    },
    {
      "title": "LAPSO: A Unified Optimization View for Learning-Augmented Power System Operations",
      "authors": [
        "Wangkun Xu",
        "Zhongda Chu",
        "Fei Teng"
      ],
      "abstract": "With the high penetration of renewables, traditional model-based power system\noperation is challenged to deliver economic, stable, and robust decisions.\nMachine learning has emerged as a powerful modeling tool for capturing complex\ndynamics to address these challenges. However, its separate design often lacks\nsystematic integration with existing methods. To fill the gap, this paper\nproposes a holistic framework of Learning-Augmented Power System Operations\n(LAPSO, pronounced as Lap-So). Adopting a native optimization perspective,\nLAPSO is centered on the operation stage and aims to break the boundary between\ntemporally siloed power system tasks, such as forecast, operation and control,\nwhile unifying the objectives of machine learning and model-based optimizations\nat both training and inference stages. Systematic analysis and simulations\ndemonstrate the effectiveness of applying LAPSO in designing new integrated\nalgorithms, such as stability-constrained optimization (SCO) and\nobjective-based forecasting (OBF), while enabling end-to-end tracing of\ndifferent sources of uncertainties. In addition, a dedicated Python\npackage-lapso is introduced to automatically augment existing power system\noptimization models with learnable components. All code and data are available\nat https://github.com/xuwkk/lapso_exp.",
      "pdf_url": "http://arxiv.org/pdf/2505.05203v1",
      "published": "2025-05-08T13:00:24+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.05203v1",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY"
      ]
    },
    {
      "title": "Societal and technological progress as sewing an ever-growing, ever-changing, patchy, and polychrome quilt",
      "authors": [
        "Joel Z. Leibo",
        "Alexander Sasha Vezhnevets",
        "William A. Cunningham",
        "SÃ©bastien Krier",
        "Manfred Diaz",
        "Simon Osindero"
      ],
      "abstract": "Artificial Intelligence (AI) systems are increasingly placed in positions\nwhere their decisions have real consequences, e.g., moderating online spaces,\nconducting research, and advising on policy. Ensuring they operate in a safe\nand ethically acceptable fashion is thus critical. However, most solutions have\nbeen a form of one-size-fits-all \"alignment\". We are worried that such systems,\nwhich overlook enduring moral diversity, will spark resistance, erode trust,\nand destabilize our institutions. This paper traces the underlying problem to\nan often-unstated Axiom of Rational Convergence: the idea that under ideal\nconditions, rational agents will converge in the limit of conversation on a\nsingle ethics. Treating that premise as both optional and doubtful, we propose\nwhat we call the appropriateness framework: an alternative approach grounded in\nconflict theory, cultural evolution, multi-agent systems, and institutional\neconomics. The appropriateness framework treats persistent disagreement as the\nnormal case and designs for it by applying four principles: (1) contextual\ngrounding, (2) community customization, (3) continual adaptation, and (4)\npolycentric governance. We argue here that adopting these design principles is\na good way to shift the main alignment metaphor from moral unification to a\nmore productive metaphor of conflict management, and that taking this step is\nboth desirable and urgent.",
      "pdf_url": "http://arxiv.org/pdf/2505.05197v1",
      "published": "2025-05-08T12:55:07+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.05197v1",
      "categories": [
        "cs.AI",
        "cs.CY"
      ]
    },
    {
      "title": "Concept-Based Unsupervised Domain Adaptation",
      "authors": [
        "Xinyue Xu",
        "Yueying Hu",
        "Hui Tang",
        "Yi Qin",
        "Lu Mi",
        "Hao Wang",
        "Xiaomeng Li"
      ],
      "abstract": "Concept Bottleneck Models (CBMs) enhance interpretability by explaining\npredictions through human-understandable concepts but typically assume that\ntraining and test data share the same distribution. This assumption often fails\nunder domain shifts, leading to degraded performance and poor generalization.\nTo address these limitations and improve the robustness of CBMs, we propose the\nConcept-based Unsupervised Domain Adaptation (CUDA) framework. CUDA is designed\nto: (1) align concept representations across domains using adversarial\ntraining, (2) introduce a relaxation threshold to allow minor domain-specific\ndifferences in concept distributions, thereby preventing performance drop due\nto over-constraints of these distributions, (3) infer concepts directly in the\ntarget domain without requiring labeled concept data, enabling CBMs to adapt to\ndiverse domains, and (4) integrate concept learning into conventional domain\nadaptation (DA) with theoretical guarantees, improving interpretability and\nestablishing new benchmarks for DA. Experiments demonstrate that our approach\nsignificantly outperforms the state-of-the-art CBM and DA methods on real-world\ndatasets.",
      "pdf_url": "http://arxiv.org/pdf/2505.05195v1",
      "published": "2025-05-08T12:52:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.05195v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Revealing Weaknesses in Text Watermarking Through Self-Information Rewrite Attacks",
      "authors": [
        "Yixin Cheng",
        "Hongcheng Guo",
        "Yangming Li",
        "Leonid Sigal"
      ],
      "abstract": "Text watermarking aims to subtly embed statistical signals into text by\ncontrolling the Large Language Model (LLM)'s sampling process, enabling\nwatermark detectors to verify that the output was generated by the specified\nmodel. The robustness of these watermarking algorithms has become a key factor\nin evaluating their effectiveness. Current text watermarking algorithms embed\nwatermarks in high-entropy tokens to ensure text quality. In this paper, we\nreveal that this seemingly benign design can be exploited by attackers, posing\na significant risk to the robustness of the watermark. We introduce a generic\nefficient paraphrasing attack, the Self-Information Rewrite Attack (SIRA),\nwhich leverages the vulnerability by calculating the self-information of each\ntoken to identify potential pattern tokens and perform targeted attack. Our\nwork exposes a widely prevalent vulnerability in current watermarking\nalgorithms. The experimental results show SIRA achieves nearly 100% attack\nsuccess rates on seven recent watermarking methods with only 0.88 USD per\nmillion tokens cost. Our approach does not require any access to the watermark\nalgorithms or the watermarked LLM and can seamlessly transfer to any LLM as the\nattack model, even mobile-level models. Our findings highlight the urgent need\nfor more robust watermarking.",
      "pdf_url": "http://arxiv.org/pdf/2505.05190v1",
      "published": "2025-05-08T12:39:00+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.05190v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CR"
      ]
    },
    {
      "title": "Biomed-DPT: Dual Modality Prompt Tuning for Biomedical Vision-Language Models",
      "authors": [
        "Wei Peng",
        "Kang Liu",
        "Jianchen Hu",
        "Meng Zhang"
      ],
      "abstract": "Prompt learning is one of the most effective paradigms for adapting\npre-trained vision-language models (VLMs) to the biomedical image\nclassification tasks in few shot scenarios. However, most of the current prompt\nlearning methods only used the text prompts and ignored the particular\nstructures (such as the complex anatomical structures and subtle pathological\nfeatures) in the biomedical images. In this work, we propose Biomed-DPT, a\nknowledge-enhanced dual modality prompt tuning technique. In designing the text\nprompt, Biomed-DPT constructs a dual prompt including the template-driven\nclinical prompts and the large language model (LLM)-driven domain-adapted\nprompts, then extracts the clinical knowledge from the domain-adapted prompts\nthrough the knowledge distillation technique. In designing the vision prompt,\nBiomed-DPT introduces the zero vector as a soft prompt to leverage attention\nre-weighting so that the focus on non-diagnostic regions and the recognition of\nnon-critical pathological features are avoided. Biomed-DPT achieves an average\nclassification accuracy of 66.14\\% across 11 biomedical image datasets covering\n9 modalities and 10 organs, with performance reaching 78.06\\% in base classes\nand 75.97\\% in novel classes, surpassing the Context Optimization (CoOp) method\nby 6.20\\%, 3.78\\%, and 8.04\\%, respectively. Our code are available at\n\\underline{https://github.com/Kanyooo/Biomed-DPT}.",
      "pdf_url": "http://arxiv.org/pdf/2505.05189v1",
      "published": "2025-05-08T12:37:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.05189v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Stochastic Variational Propagation: Local, Scalable and Efficient Alternative to Backpropagation",
      "authors": [
        "Bojian Yin",
        "Federico Corradi"
      ],
      "abstract": "Backpropagation (BP) is the cornerstone of deep learning, but its reliance on\nglobal gradient synchronization limits scalability and imposes significant\nmemory overhead. We propose Stochastic Variational Propagation (SVP), a\nscalable alternative that reframes training as hierarchical variational\ninference. SVP treats layer activations as latent variables and optimizes local\nEvidence Lower Bounds (ELBOs), enabling independent, local updates while\npreserving global coherence. However, directly applying KL divergence in\nlayer-wise ELBOs risks inter-layer's representation collapse due to excessive\ncompression. To prevent this, SVP projects activations into low-dimensional\nspaces via fixed random matrices, ensuring information preservation and\nrepresentational diversity. Combined with a feature alignment loss for\ninter-layer consistency, SVP achieves competitive accuracy with BP across\ndiverse architectures (MLPs, CNNs, Transformers) and datasets (MNIST to\nImageNet), reduces memory usage by up to 4x, and significantly improves\nscalability. More broadly, SVP introduces a probabilistic perspective to deep\nrepresentation learning, opening pathways toward more modular and interpretable\nneural network design.",
      "pdf_url": "http://arxiv.org/pdf/2505.05181v1",
      "published": "2025-05-08T12:32:29+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.05181v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "MARK: Memory Augmented Refinement of Knowledge",
      "authors": [
        "Anish Ganguli",
        "Prabal Deb",
        "Debleena Banerjee"
      ],
      "abstract": "Large Language Models (LLMs) assist in specialized tasks but struggle to\nalign with evolving domain knowledge without costly fine-tuning. Domain\nknowledge consists of: Knowledge: Immutable facts (e.g., 'A stone is solid')\nand generally accepted principles (e.g., ethical standards); Refined Memory:\nEvolving insights shaped by business needs and real-world changes. However, a\nsignificant gap often exists between a domain expert's deep, nuanced\nunderstanding and the system's domain knowledge, which can hinder accurate\ninformation retrieval and application. Our Memory-Augmented Refinement of\nKnowledge (MARK) framework enables LLMs to continuously learn without\nretraining by leveraging structured refined memory, inspired by the Society of\nMind. MARK operates through specialized agents, each serving a distinct role:\nResidual Refined Memory Agent: Stores and retrieves domain-specific insights to\nmaintain context over time; User Question Refined Memory Agent: Captures\nuser-provided facts, abbreviations, and terminology for better comprehension;\nLLM Response Refined Memory Agent: Extracts key elements from responses for\nrefinement and personalization. These agents analyse stored refined memory,\ndetect patterns, resolve contradictions, and improve response accuracy.\nTemporal factors like recency and frequency prioritize relevant information\nwhile discarding outdated insights. MARK enhances LLMs in multiple ways: Ground\nTruth Strategy: Reduces hallucinations by establishing a structured reference;\nDomain-Specific Adaptation: Essential for fields like healthcare, law, and\nmanufacturing, where proprietary insights are absent from public datasets;\nPersonalized AI Assistants: Improves virtual assistants by remembering user\npreferences, ensuring coherent responses over time.",
      "pdf_url": "http://arxiv.org/pdf/2505.05177v1",
      "published": "2025-05-08T12:28:00+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.05177v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Dukawalla: Voice Interfaces for Small Businesses in Africa",
      "authors": [
        "Elizabeth Ankrah",
        "Stephanie Nyairo",
        "Mercy Muchai",
        "Kagonya Awori",
        "Millicent Ochieng",
        "Mark Kariuki",
        "Jacki O'Neill"
      ],
      "abstract": "Small and medium sized businesses often struggle with data driven decision\nmaking do to a lack of advanced analytics tools, especially in African\ncountries where they make up a majority of the workforce. Though many tools\nexist they are not designed to fit into the ways of working of SMB workers who\nare mobile first, have limited time to learn new workflows, and for whom social\nand business are tightly coupled. To address this, the Dukawalla prototype was\ncreated. This intelligent assistant bridges the gap between raw business data,\nand actionable insights by leveraging voice interaction and the power of\ngenerative AI. Dukawalla provides an intuitive way for business owners to\ninteract with their data, aiding in informed decision making. This paper\nexamines Dukawalla's deployment across SMBs in Nairobi, focusing on their\nexperiences using this voice based assistant to streamline data collection and\nprovide business insights",
      "pdf_url": "http://arxiv.org/pdf/2505.05170v1",
      "published": "2025-05-08T12:13:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.05170v1",
      "categories": [
        "cs.HC",
        "cs.AI"
      ]
    },
    {
      "title": "Understanding In-context Learning of Addition via Activation Subspaces",
      "authors": [
        "Xinyan Hu",
        "Kayo Yin",
        "Michael I. Jordan",
        "Jacob Steinhardt",
        "Lijie Chen"
      ],
      "abstract": "To perform in-context learning, language models must extract signals from\nindividual few-shot examples, aggregate these into a learned prediction rule,\nand then apply this rule to new examples. How is this implemented in the\nforward pass of modern transformer models? To study this, we consider a\nstructured family of few-shot learning tasks for which the true prediction rule\nis to add an integer $k$ to the input. We find that Llama-3-8B attains high\naccuracy on this task for a range of $k$, and localize its few-shot ability to\njust three attention heads via a novel optimization approach. We further show\nthe extracted signals lie in a six-dimensional subspace, where four of the\ndimensions track the unit digit and the other two dimensions track overall\nmagnitude. We finally examine how these heads extract information from\nindividual few-shot examples, identifying a self-correction mechanism in which\nmistakes from earlier examples are suppressed by later examples. Our results\ndemonstrate how tracking low-dimensional subspaces across a forward pass can\nprovide insight into fine-grained computational structures.",
      "pdf_url": "http://arxiv.org/pdf/2505.05145v1",
      "published": "2025-05-08T11:32:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.05145v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Guiding Evolutionary AutoEncoder Training with Activation-Based Pruning Operators",
      "authors": [
        "Steven Jorgensen",
        "Erik Hemberg",
        "Jamal Toutouh",
        "Una-May O'Reilly"
      ],
      "abstract": "This study explores a novel approach to neural network pruning using\nevolutionary computation, focusing on simultaneously pruning the encoder and\ndecoder of an autoencoder. We introduce two new mutation operators that use\nlayer activations to guide weight pruning. Our findings reveal that one of\nthese activation-informed operators outperforms random pruning, resulting in\nmore efficient autoencoders with comparable performance to canonically trained\nmodels. Prior work has established that autoencoder training is effective and\nscalable with a spatial coevolutionary algorithm that cooperatively coevolves a\npopulation of encoders with a population of decoders, rather than one\nautoencoder. We evaluate how the same activity-guided mutation operators\ntransfer to this context. We find that random pruning is better than guided\npruning, in the coevolutionary setting. This suggests activation-based guidance\nproves more effective in low-dimensional pruning environments, where\nconstrained sample spaces can lead to deviations from true uniformity in\nrandomization. Conversely, population-driven strategies enhance robustness by\nexpanding the total pruning dimensionality, achieving statistically uniform\nrandomness that better preserves system dynamics. We experiment with pruning\naccording to different schedules and present best combinations of operator and\nschedule for the canonical and coevolving populations cases.",
      "pdf_url": "http://arxiv.org/pdf/2505.05138v1",
      "published": "2025-05-08T11:21:29+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.05138v1",
      "categories": [
        "cs.NE",
        "cs.AI"
      ]
    },
    {
      "title": "Is there a half-life for the success rates of AI agents?",
      "authors": [
        "Toby Ord"
      ],
      "abstract": "Building on the recent empirical work of Kwa et al. (2025), I show that\nwithin their suite of research-engineering tasks the performance of AI agents\non longer-duration tasks can be explained by an extremely simple mathematical\nmodel -- a constant rate of failing during each minute a human would take to do\nthe task. This implies an exponentially declining success rate with the length\nof the task and that each agent could be characterised by its own half-life.\nThis empirical regularity allows us to estimate the success rate for an agent\nat different task lengths. And the fact that this model is a good fit for the\ndata is suggestive of the underlying causes of failure on longer tasks -- that\nthey involve increasingly large sets of subtasks where failing any one fails\nthe task. Whether this model applies more generally on other suites of tasks is\nunknown and an important subject for further work.",
      "pdf_url": "http://arxiv.org/pdf/2505.05115v1",
      "published": "2025-05-08T10:31:03+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.05115v1",
      "categories": [
        "cs.AI",
        "68T42",
        "I.2.8"
      ]
    },
    {
      "title": "Multi-agent Embodied AI: Advances and Future Directions",
      "authors": [
        "Zhaohan Feng",
        "Ruiqi Xue",
        "Lei Yuan",
        "Yang Yu",
        "Ning Ding",
        "Meiqin Liu",
        "Bingzhao Gao",
        "Jian Sun",
        "Gang Wang"
      ],
      "abstract": "Embodied artificial intelligence (Embodied AI) plays a pivotal role in the\napplication of advanced technologies in the intelligent era, where AI systems\nare integrated with physical bodies that enable them to perceive, reason, and\ninteract with their environments. Through the use of sensors for input and\nactuators for action, these systems can learn and adapt based on real-world\nfeedback, allowing them to perform tasks effectively in dynamic and\nunpredictable environments. As techniques such as deep learning (DL),\nreinforcement learning (RL), and large language models (LLMs) mature, embodied\nAI has become a leading field in both academia and industry, with applications\nspanning robotics, healthcare, transportation, and manufacturing. However, most\nresearch has focused on single-agent systems that often assume static, closed\nenvironments, whereas real-world embodied AI must navigate far more complex\nscenarios. In such settings, agents must not only interact with their\nsurroundings but also collaborate with other agents, necessitating\nsophisticated mechanisms for adaptation, real-time learning, and collaborative\nproblem-solving. Despite increasing interest in multi-agent systems, existing\nresearch remains narrow in scope, often relying on simplified models that fail\nto capture the full complexity of dynamic, open environments for multi-agent\nembodied AI. Moreover, no comprehensive survey has systematically reviewed the\nadvancements in this area. As embodied AI rapidly evolves, it is crucial to\ndeepen our understanding of multi-agent embodied AI to address the challenges\npresented by real-world applications. To fill this gap and foster further\ndevelopment in the field, this paper reviews the current state of research,\nanalyzes key contributions, and identifies challenges and future directions,\nproviding insights to guide innovation and progress in this field.",
      "pdf_url": "http://arxiv.org/pdf/2505.05108v1",
      "published": "2025-05-08T10:13:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.05108v1",
      "categories": [
        "cs.AI",
        "cs.MA"
      ]
    },
    {
      "title": "A Neuro-Symbolic Framework for Sequence Classification with Relational and Temporal Knowledge",
      "authors": [
        "Luca Salvatore Lorello",
        "Marco Lippi",
        "Stefano Melacci"
      ],
      "abstract": "One of the goals of neuro-symbolic artificial intelligence is to exploit\nbackground knowledge to improve the performance of learning tasks. However,\nmost of the existing frameworks focus on the simplified scenario where\nknowledge does not change over time and does not cover the temporal dimension.\nIn this work we consider the much more challenging problem of knowledge-driven\nsequence classification where different portions of knowledge must be employed\nat different timesteps, and temporal relations are available. Our experimental\nevaluation compares multi-stage neuro-symbolic and neural-only architectures,\nand it is conducted on a newly-introduced benchmarking framework. Results\ndemonstrate the challenging nature of this novel setting, and also highlight\nunder-explored shortcomings of neuro-symbolic methods, representing a precious\nreference for future research.",
      "pdf_url": "http://arxiv.org/pdf/2505.05106v1",
      "published": "2025-05-08T10:10:00+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.05106v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Beyond Low-rank Decomposition: A Shortcut Approach for Efficient On-Device Learning",
      "authors": [
        "Le-Trung Nguyen",
        "Ael Quelennec",
        "Van-Tam Nguyen",
        "Enzo Tartaglione"
      ],
      "abstract": "On-device learning has emerged as a promising direction for AI development,\nparticularly because of its potential to reduce latency issues and mitigate\nprivacy risks associated with device-server communication, while improving\nenergy efficiency. Despite these advantages, significant memory and\ncomputational constraints still represent major challenges for its deployment.\nDrawing on previous studies on low-rank decomposition methods that address\nactivation memory bottlenecks in backpropagation, we propose a novel shortcut\napproach as an alternative. Our analysis and experiments demonstrate that our\nmethod can reduce activation memory usage, even up to $120.09\\times$ compared\nto vanilla training, while also reducing overall training FLOPs up to\n$1.86\\times$ when evaluated on traditional benchmarks.",
      "pdf_url": "http://arxiv.org/pdf/2505.05086v1",
      "published": "2025-05-08T09:34:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.05086v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "FG-CLIP: Fine-Grained Visual and Textual Alignment",
      "authors": [
        "Chunyu Xie",
        "Bin Wang",
        "Fanjing Kong",
        "Jincheng Li",
        "Dawei Liang",
        "Gengshen Zhang",
        "Dawei Leng",
        "Yuhui Yin"
      ],
      "abstract": "Contrastive Language-Image Pre-training (CLIP) excels in multimodal tasks\nsuch as image-text retrieval and zero-shot classification but struggles with\nfine-grained understanding due to its focus on coarse-grained short captions.\nTo address this, we propose Fine-Grained CLIP (FG-CLIP), which enhances\nfine-grained understanding through three key innovations. First, we leverage\nlarge multimodal models to generate 1.6 billion long caption-image pairs for\ncapturing global-level semantic details. Second, a high-quality dataset is\nconstructed with 12 million images and 40 million region-specific bounding\nboxes aligned with detailed captions to ensure precise, context-rich\nrepresentations. Third, 10 million hard fine-grained negative samples are\nincorporated to improve the model's ability to distinguish subtle semantic\ndifferences. Corresponding training methods are meticulously designed for these\ndata. Extensive experiments demonstrate that FG-CLIP outperforms the original\nCLIP and other state-of-the-art methods across various downstream tasks,\nincluding fine-grained understanding, open-vocabulary object detection,\nimage-text retrieval, and general multimodal benchmarks. These results\nhighlight FG-CLIP's effectiveness in capturing fine-grained image details and\nimproving overall model performance. The related data, code, and models are\navailable at https://github.com/360CVGroup/FG-CLIP.",
      "pdf_url": "http://arxiv.org/pdf/2505.05071v1",
      "published": "2025-05-08T09:06:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.05071v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Enhancing Reinforcement Learning for the Floorplanning of Analog ICs with Beam Search",
      "authors": [
        "Sandro Junior Della Rovere",
        "Davide Basso",
        "Luca Bortolussi",
        "Mirjana Videnovic-Misic",
        "Husni Habal"
      ],
      "abstract": "The layout of analog ICs requires making complex trade-offs, while addressing\ndevice physics and variability of the circuits. This makes full automation with\nlearning-based solutions hard to achieve. However, reinforcement learning (RL)\nhas recently reached significant results, particularly in solving the\nfloorplanning problem. This paper presents a hybrid method that combines RL\nwith a beam (BS) strategy. The BS algorithm enhances the agent's inference\nprocess, allowing for the generation of flexible floorplans by accomodating\nvarious objective weightings, and addressing congestion without without the\nneed for policy retraining or fine-tuning. Moreover, the RL agent's\ngeneralization ability stays intact, along with its efficient handling of\ncircuit features and constraints. Experimental results show approx. 5-85%\nimprovement in area, dead space and half-perimeter wire length compared to a\nstandard RL application, along with higher rewards for the agent. Moreover,\nperformance and efficiency align closely with those of existing\nstate-of-the-art techniques.",
      "pdf_url": "http://arxiv.org/pdf/2505.05059v1",
      "published": "2025-05-08T08:50:32+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.05059v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Teochew-Wild: The First In-the-wild Teochew Dataset with Orthographic Annotations",
      "authors": [
        "Linrong Pan",
        "Chenglong Jiang",
        "Gaoze Hou",
        "Ying Gao"
      ],
      "abstract": "This paper reports the construction of the Teochew-Wild, a speech corpus of\nthe Teochew dialect. The corpus includes 18.9 hours of in-the-wild Teochew\nspeech data from multiple speakers, covering both formal and colloquial\nexpressions, with precise orthographic and pinyin annotations. Additionally, we\nprovide supplementary text processing tools and resources to propel research\nand applications in speech tasks for this low-resource language, such as\nautomatic speech recognition (ASR) and text-to-speech (TTS). To the best of our\nknowledge, this is the first publicly available Teochew dataset with accurate\northographic annotations. We conduct experiments on the corpus, and the results\nvalidate its effectiveness in ASR and TTS tasks.",
      "pdf_url": "http://arxiv.org/pdf/2505.05056v1",
      "published": "2025-05-08T08:47:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.05056v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Direct Image Classification from Fourier Ptychographic Microscopy Measurements without Reconstruction",
      "authors": [
        "Navya Sonal Agarwal",
        "Jan Philipp Schneider",
        "Kanchana Vaishnavi Gandikota",
        "Syed Muhammad Kazim",
        "John Meshreki",
        "Ivo Ihrke",
        "Michael Moeller"
      ],
      "abstract": "The computational imaging technique of Fourier Ptychographic Microscopy (FPM)\nenables high-resolution imaging with a wide field of view and can serve as an\nextremely valuable tool, e.g. in the classification of cells in medical\napplications. However, reconstructing a high-resolution image from tens or even\nhundreds of measurements is computationally expensive, particularly for a wide\nfield of view. Therefore, in this paper, we investigate the idea of classifying\nthe image content in the FPM measurements directly without performing a\nreconstruction step first. We show that Convolutional Neural Networks (CNN) can\nextract meaningful information from measurement sequences, significantly\noutperforming the classification on a single band-limited image (up to 12 %)\nwhile being significantly more efficient than a reconstruction of a\nhigh-resolution image. Furthermore, we demonstrate that a learned multiplexing\nof several raw measurements allows maintaining the classification accuracy\nwhile reducing the amount of data (and consequently also the acquisition time)\nsignificantly.",
      "pdf_url": "http://arxiv.org/pdf/2505.05054v1",
      "published": "2025-05-08T08:46:28+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.05054v1",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Image-Text Relation Prediction for Multilingual Tweets",
      "authors": [
        "MatÄ«ss Rikters",
        "Edison Marrese-Taylor"
      ],
      "abstract": "Various social networks have been allowing media uploads for over a decade\nnow. Still, it has not always been clear what is their relation with the posted\ntext or even if there is any at all. In this work, we explore how multilingual\nvision-language models tackle the task of image-text relation prediction in\ndifferent languages, and construct a dedicated balanced benchmark data set from\nTwitter posts in Latvian along with their manual translations into English. We\ncompare our results to previous work and show that the more recently released\nvision-language model checkpoints are becoming increasingly capable at this\ntask, but there is still much room for further improvement.",
      "pdf_url": "http://arxiv.org/pdf/2505.05040v1",
      "published": "2025-05-08T08:23:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.05040v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "A Reputation System for Large Language Model-based Multi-agent Systems to Avoid the Tragedy of the Commons",
      "authors": [
        "Siyue Ren",
        "Wanli Fu",
        "Xinkun Zou",
        "Chen Shen",
        "Yi Cai",
        "Chen Chu",
        "Zhen Wang",
        "Shuyue Hu"
      ],
      "abstract": "The tragedy of the commons, where individual self-interest leads to\ncollectively disastrous outcomes, is a pervasive challenge in human society.\nRecent studies have demonstrated that similar phenomena can arise in generative\nmulti-agent systems (MASs). To address this challenge, this paper explores the\nuse of reputation systems as a remedy. We propose RepuNet, a dynamic,\ndual-level reputation framework that models both agent-level reputation\ndynamics and system-level network evolution. Specifically, driven by direct\ninteractions and indirect gossip, agents form reputations for both themselves\nand their peers, and decide whether to connect or disconnect other agents for\nfuture interactions. Through two distinct scenarios, we show that RepuNet\neffectively mitigates the 'tragedy of the commons', promoting and sustaining\ncooperation in generative MASs. Moreover, we find that reputation systems can\ngive rise to rich emergent behaviors in generative MASs, such as the formation\nof cooperative clusters, the social isolation of exploitative agents, and the\npreference for sharing positive gossip rather than negative ones.",
      "pdf_url": "http://arxiv.org/pdf/2505.05029v1",
      "published": "2025-05-08T08:02:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.05029v1",
      "categories": [
        "cs.AI",
        "cs.MA"
      ]
    },
    {
      "title": "Generating Reliable Synthetic Clinical Trial Data: The Role of Hyperparameter Optimization and Domain Constraints",
      "authors": [
        "Waldemar Hahn",
        "Jan-Niklas Eckardt",
        "Christoph RÃ¶llig",
        "Martin Sedlmayr",
        "Jan Moritz Middeke",
        "Markus Wolfien"
      ],
      "abstract": "The generation of synthetic clinical trial data offers a promising approach\nto mitigating privacy concerns and data accessibility limitations in medical\nresearch. However, ensuring that synthetic datasets maintain high fidelity,\nutility, and adherence to domain-specific constraints remains a key challenge.\nWhile hyperparameter optimization (HPO) has been shown to improve generative\nmodel performance, the effectiveness of different optimization strategies for\nsynthetic clinical data remains unclear. This study systematically evaluates\nfour HPO strategies across eight generative models, comparing single-metric\noptimization against compound metric optimization approaches. Our results\ndemonstrate that HPO consistently improves synthetic data quality, with TVAE,\nCTGAN, and CTAB-GAN+ achieving improvements of up to 60%, 39%, and 38%,\nrespectively. Compound metric optimization outperformed single-metric\nstrategies, producing more balanced and generalizable synthetic datasets.\nInterestingly, HPO alone is insufficient to ensure clinically valid synthetic\ndata, as all models exhibited violations of fundamental survival constraints.\nPreprocessing and postprocessing played a crucial role in reducing these\nviolations, as models lacking robust processing steps produced invalid data in\nup to 61% of cases. These findings underscore the necessity of integrating\nexplicit domain knowledge alongside HPO to create high quality synthetic\ndatasets. Our study provides actionable recommendations for improving synthetic\ndata generation, with future research needed to refine metric selection and\nvalidate these findings on larger datasets to enhance clinical applicability.",
      "pdf_url": "http://arxiv.org/pdf/2505.05019v1",
      "published": "2025-05-08T07:51:36+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.05019v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "An Agent-Based Modeling Approach to Free-Text Keyboard Dynamics for Continuous Authentication",
      "authors": [
        "Roberto Dillon",
        "Arushi"
      ],
      "abstract": "Continuous authentication systems leveraging free-text keyboard dynamics\noffer a promising additional layer of security in a multifactor authentication\nsetup that can be used in a transparent way with no impact on user experience.\nThis study investigates the efficacy of behavioral biometrics by employing an\nAgent-Based Model (ABM) to simulate diverse typing profiles across mechanical\nand membrane keyboards. Specifically, we generated synthetic keystroke data\nfrom five unique agents, capturing features related to dwell time, flight time,\nand error rates within sliding 5-second windows updated every second. Two\nmachine learning approaches, One-Class Support Vector Machine (OC-SVM) and\nRandom Forest (RF), were evaluated for user verification. Results revealed a\nstark contrast in performance: while One-Class SVM failed to differentiate\nindividual users within each group, Random Forest achieved robust\nintra-keyboard user recognition (Accuracy > 0.7) but struggled to generalize\nacross keyboards for the same user, highlighting the significant impact of\nkeyboard hardware on typing behavior. These findings suggest that: (1)\nkeyboard-specific user profiles may be necessary for reliable authentication,\nand (2) ensemble methods like RF outperform One-Class SVM in capturing\nfine-grained user-specific patterns.",
      "pdf_url": "http://arxiv.org/pdf/2505.05015v1",
      "published": "2025-05-08T07:42:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.05015v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "68T10, 62H30",
        "I.2.6; I.5.4; I.6.3"
      ]
    },
    {
      "title": "StabStitch++: Unsupervised Online Video Stitching with Spatiotemporal Bidirectional Warps",
      "authors": [
        "Lang Nie",
        "Chunyu Lin",
        "Kang Liao",
        "Yun Zhang",
        "Shuaicheng Liu",
        "Yao Zhao"
      ],
      "abstract": "We retarget video stitching to an emerging issue, named warping shake, which\nunveils the temporal content shakes induced by sequentially unsmooth warps when\nextending image stitching to video stitching. Even if the input videos are\nstable, the stitched video can inevitably cause undesired warping shakes and\naffect the visual experience. To address this issue, we propose StabStitch++, a\nnovel video stitching framework to realize spatial stitching and temporal\nstabilization with unsupervised learning simultaneously. First, different from\nexisting learning-based image stitching solutions that typically warp one image\nto align with another, we suppose a virtual midplane between original image\nplanes and project them onto it. Concretely, we design a differentiable\nbidirectional decomposition module to disentangle the homography transformation\nand incorporate it into our spatial warp, evenly spreading alignment burdens\nand projective distortions across two views. Then, inspired by camera paths in\nvideo stabilization, we derive the mathematical expression of stitching\ntrajectories in video stitching by elaborately integrating spatial and temporal\nwarps. Finally, a warp smoothing model is presented to produce stable stitched\nvideos with a hybrid loss to simultaneously encourage content alignment,\ntrajectory smoothness, and online collaboration. Compared with StabStitch that\nsacrifices alignment for stabilization, StabStitch++ makes no compromise and\noptimizes both of them simultaneously, especially in the online mode. To\nestablish an evaluation benchmark and train the learning framework, we build a\nvideo stitching dataset with a rich diversity in camera motions and scenes.\nExperiments exhibit that StabStitch++ surpasses current solutions in stitching\nperformance, robustness, and efficiency, offering compelling advancements in\nthis field by building a real-time online video stitching system.",
      "pdf_url": "http://arxiv.org/pdf/2505.05001v1",
      "published": "2025-05-08T07:12:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.05001v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Foam-Agent: Towards Automated Intelligent CFD Workflows",
      "authors": [
        "Ling Yue",
        "Nithin Somasekharan",
        "Yadi Cao",
        "Shaowu Pan"
      ],
      "abstract": "Computational Fluid Dynamics (CFD) is an essential simulation tool in various\nengineering disciplines, but it often requires substantial domain expertise and\nmanual configuration, creating barriers to entry. We present Foam-Agent, a\nmulti-agent framework that automates complex OpenFOAM-based CFD simulation\nworkflows from natural language inputs. Our innovation includes (1) a\nhierarchical multi-index retrieval system with specialized indices for\ndifferent simulation aspects, (2) a dependency-aware file generation system\nthat provides consistency management across configuration files, and (3) an\niterative error correction mechanism that diagnoses and resolves simulation\nfailures without human intervention. Through comprehensive evaluation on the\ndataset of 110 simulation tasks, Foam-Agent achieves an 83.6% success rate with\nClaude 3.5 Sonnet, significantly outperforming existing frameworks (55.5% for\nMetaOpenFOAM and 37.3% for OpenFOAM-GPT). Ablation studies demonstrate the\ncritical contribution of each system component, with the specialized error\ncorrection mechanism providing a 36.4% performance improvement. Foam-Agent\nsubstantially lowers the CFD expertise threshold while maintaining modeling\naccuracy, demonstrating the potential of specialized multi-agent systems to\ndemocratize access to complex scientific simulation tools. The code is public\nat https://github.com/csml-rpi/Foam-Agent",
      "pdf_url": "http://arxiv.org/pdf/2505.04997v1",
      "published": "2025-05-08T07:05:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.04997v1",
      "categories": [
        "cs.AI",
        "cs.MA"
      ]
    }
  ]
}