{
  "last_updated": "2025-12-16T00:55:58.959942",
  "papers": [
    {
      "title": "Particulate: Feed-Forward 3D Object Articulation",
      "authors": [
        "Ruining Li",
        "Yuxin Yao",
        "Chuanxia Zheng",
        "Christian Rupprecht",
        "Joan Lasenby",
        "Shangzhe Wu",
        "Andrea Vedaldi"
      ],
      "abstract": "We present Particulate, a feed-forward approach that, given a single static 3D mesh of an everyday object, directly infers all attributes of the underlying articulated structure, including its 3D parts, kinematic structure, and motion constraints. At its core is a transformer network, Part Articulation Transformer, which processes a point cloud of the input mesh using a flexible and scalable architecture to predict all the aforementioned attributes with native multi-joint support. We train the network end-to-end on a diverse collection of articulated 3D assets from public datasets. During inference, Particulate lifts the network's feed-forward prediction to the input mesh, yielding a fully articulated 3D model in seconds, much faster than prior approaches that require per-object optimization. Particulate can also accurately infer the articulated structure of AI-generated 3D assets, enabling full-fledged extraction of articulated 3D objects from a single (real or synthetic) image when combined with an off-the-shelf image-to-3D generator. We further introduce a new challenging benchmark for 3D articulation estimation curated from high-quality public 3D assets, and redesign the evaluation protocol to be more consistent with human preferences. Quantitative and qualitative results show that Particulate significantly outperforms state-of-the-art approaches.",
      "pdf_url": "https://arxiv.org/pdf/2512.11798v1",
      "published": "2025-12-12T18:59:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.11798v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ]
    },
    {
      "title": "Super Suffixes: Bypassing Text Generation Alignment and Guard Models Simultaneously",
      "authors": [
        "Andrew Adiletta",
        "Kathryn Adiletta",
        "Kemal Derya",
        "Berk Sunar"
      ],
      "abstract": "The rapid deployment of Large Language Models (LLMs) has created an urgent need for enhanced security and privacy measures in Machine Learning (ML). LLMs are increasingly being used to process untrusted text inputs and even generate executable code, often while having access to sensitive system controls. To address these security concerns, several companies have introduced guard models, which are smaller, specialized models designed to protect text generation models from adversarial or malicious inputs. In this work, we advance the study of adversarial inputs by introducing Super Suffixes, suffixes capable of overriding multiple alignment objectives across various models with different tokenization schemes. We demonstrate their effectiveness, along with our joint optimization technique, by successfully bypassing the protection mechanisms of Llama Prompt Guard 2 on five different text generation models for malicious text and code generation. To the best of our knowledge, this is the first work to reveal that Llama Prompt Guard 2 can be compromised through joint optimization.\n  Additionally, by analyzing the changing similarity of a model's internal state to specific concept directions during token sequence processing, we propose an effective and lightweight method to detect Super Suffix attacks. We show that the cosine similarity between the residual stream and certain concept directions serves as a distinctive fingerprint of model intent. Our proposed countermeasure, DeltaGuard, significantly improves the detection of malicious prompts generated through Super Suffixes. It increases the non-benign classification rate to nearly 100%, making DeltaGuard a valuable addition to the guard model stack and enhancing robustness against adversarial prompt attacks.",
      "pdf_url": "https://arxiv.org/pdf/2512.11783v1",
      "published": "2025-12-12T18:52:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.11783v1",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "title": "Agile Flight Emerges from Multi-Agent Competitive Racing",
      "authors": [
        "Vineet Pasumarti",
        "Lorenzo Bianchi",
        "Antonio Loquercio"
      ],
      "abstract": "Through multi-agent competition and the sparse high-level objective of winning a race, we find that both agile flight (e.g., high-speed motion pushing the platform to its physical limits) and strategy (e.g., overtaking or blocking) emerge from agents trained with reinforcement learning. We provide evidence in both simulation and the real world that this approach outperforms the common paradigm of training agents in isolation with rewards that prescribe behavior, e.g., progress on the raceline, in particular when the complexity of the environment increases, e.g., in the presence of obstacles. Moreover, we find that multi-agent competition yields policies that transfer more reliably to the real world than policies trained with a single-agent progress-based reward, despite the two methods using the same simulation environment, randomization strategy, and hardware. In addition to improved sim-to-real transfer, the multi-agent policies also exhibit some degree of generalization to opponents unseen at training time. Overall, our work, following in the tradition of multi-agent competitive game-play in digital domains, shows that sparse task-level rewards are sufficient for training agents capable of advanced low-level control in the physical world.\n  Code: https://github.com/Jirl-upenn/AgileFlight_MultiAgent",
      "pdf_url": "https://arxiv.org/pdf/2512.11781v1",
      "published": "2025-12-12T18:48:50+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.11781v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.MA"
      ]
    },
    {
      "title": "Conditional Coverage Diagnostics for Conformal Prediction",
      "authors": [
        "Sacha Braun",
        "David Holzmüller",
        "Michael I. Jordan",
        "Francis Bach"
      ],
      "abstract": "Evaluating conditional coverage remains one of the most persistent challenges in assessing the reliability of predictive systems. Although conformal methods can give guarantees on marginal coverage, no method can guarantee to produce sets with correct conditional coverage, leaving practitioners without a clear way to interpret local deviations. To overcome sample-inefficiency and overfitting issues of existing metrics, we cast conditional coverage estimation as a classification problem. Conditional coverage is violated if and only if any classifier can achieve lower risk than the target coverage. Through the choice of a (proper) loss function, the resulting risk difference gives a conservative estimate of natural miscoverage measures such as L1 and L2 distance, and can even separate the effects of over- and under-coverage, and non-constant target coverages. We call the resulting family of metrics excess risk of the target coverage (ERT). We show experimentally that the use of modern classifiers provides much higher statistical power than simple classifiers underlying established metrics like CovGap. Additionally, we use our metric to benchmark different conformal prediction methods. Finally, we release an open-source package for ERT as well as previous conditional coverage metrics. Together, these contributions provide a new lens for understanding, diagnosing, and improving the conditional reliability of predictive systems.",
      "pdf_url": "https://arxiv.org/pdf/2512.11779v1",
      "published": "2025-12-12T18:47:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.11779v1",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Smudged Fingerprints: A Systematic Evaluation of the Robustness of AI Image Fingerprints",
      "authors": [
        "Kai Yao",
        "Marc Juarez"
      ],
      "abstract": "Model fingerprint detection techniques have emerged as a promising approach for attributing AI-generated images to their source models, but their robustness under adversarial conditions remains largely unexplored. We present the first systematic security evaluation of these techniques, formalizing threat models that encompass both white- and black-box access and two attack goals: fingerprint removal, which erases identifying traces to evade attribution, and fingerprint forgery, which seeks to cause misattribution to a target model. We implement five attack strategies and evaluate 14 representative fingerprinting methods across RGB, frequency, and learned-feature domains on 12 state-of-the-art image generators. Our experiments reveal a pronounced gap between clean and adversarial performance. Removal attacks are highly effective, often achieving success rates above 80% in white-box settings and over 50% under constrained black-box access. While forgery is more challenging than removal, its success significantly varies across targeted models. We also identify a utility-robustness trade-off: methods with the highest attribution accuracy are often vulnerable to attacks. Although some techniques exhibit robustness in specific settings, none achieves high robustness and accuracy across all evaluated threat models. These findings highlight the need for techniques balancing robustness and accuracy, and identify the most promising approaches for advancing this goal.",
      "pdf_url": "https://arxiv.org/pdf/2512.11771v1",
      "published": "2025-12-12T18:33:14+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.11771v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Generative Parametric Design (GPD): A framework for real-time geometry generation and on-the-fly multiparametric approximation",
      "authors": [
        "Mohammed El Fallaki Idrissi",
        "Jad Mounayer",
        "Sebastian Rodriguez",
        "Fodil Meraghni",
        "Francisco Chinesta"
      ],
      "abstract": "This paper presents a novel paradigm in simulation-based engineering sciences by introducing a new framework called Generative Parametric Design (GPD). The GPD framework enables the generation of new designs along with their corresponding parametric solutions given as a reduced basis. To achieve this, two Rank Reduction Autoencoders (RRAEs) are employed, one for encoding and generating the design or geometry, and the other for encoding the sparse Proper Generalized Decomposition (sPGD) mode solutions. These models are linked in the latent space using regression techniques, allowing efficient transitions between design and their associated sPGD modes. By empowering design exploration and optimization, this framework also advances digital and hybrid twin development, enhancing predictive modeling and real-time decision-making in engineering applications. The developed framework is demonstrated on two-phase microstructures, in which the multiparametric solutions account for variations in two key material parameters.",
      "pdf_url": "https://arxiv.org/pdf/2512.11748v1",
      "published": "2025-12-12T17:44:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.11748v1",
      "categories": [
        "cs.CE",
        "cs.AI"
      ]
    },
    {
      "title": "CogniSNN: Enabling Neuron-Expandability, Pathway-Reusability, and Dynamic-Configurability with Random Graph Architectures in Spiking Neural Networks",
      "authors": [
        "Yongsheng Huang",
        "Peibo Duan",
        "Yujie Wu",
        "Kai Sun",
        "Zhipeng Liu",
        "Changsheng Zhang",
        "Bin Zhang",
        "Mingkun Xu"
      ],
      "abstract": "Spiking neural networks (SNNs), regarded as the third generation of artificial neural networks, are expected to bridge the gap between artificial intelligence and computational neuroscience. However, most mainstream SNN research directly adopts the rigid, chain-like hierarchical architecture of traditional artificial neural networks (ANNs), ignoring key structural characteristics of the brain. Biological neurons are stochastically interconnected, forming complex neural pathways that exhibit Neuron-Expandability, Pathway-Reusability, and Dynamic-Configurability. In this paper, we introduce a new SNN paradigm, named Cognition-aware SNN (CogniSNN), by incorporating Random Graph Architecture (RGA). Furthermore, we address the issues of network degradation and dimensional mismatch in deep pathways by introducing an improved pure spiking residual mechanism alongside an adaptive pooling strategy. Then, we design a Key Pathway-based Learning without Forgetting (KP-LwF) approach, which selectively reuses critical neural pathways while retaining historical knowledge, enabling efficient multi-task transfer. Finally, we propose a Dynamic Growth Learning (DGL) algorithm that allows neurons and synapses to grow dynamically along the internal temporal dimension. Extensive experiments demonstrate that CogniSNN achieves performance comparable to, or even surpassing, current state-of-the-art SNNs on neuromorphic datasets and Tiny-ImageNet. The Pathway-Reusability enhances the network's continuous learning capability across different scenarios, while the dynamic growth algorithm improves robustness against interference and mitigates the fixed-timestep constraints during neuromorphic chip deployment. This work demonstrates the potential of SNNs with random graph structures in advancing brain-inspired intelligence and lays the foundation for their practical application on neuromorphic hardware.",
      "pdf_url": "https://arxiv.org/pdf/2512.11743v1",
      "published": "2025-12-12T17:36:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.11743v1",
      "categories": [
        "cs.NE",
        "cs.AI"
      ]
    },
    {
      "title": "From Signal to Turn: Interactional Friction in Modular Speech-to-Speech Pipelines",
      "authors": [
        "Titaya Mairittha",
        "Tanakon Sawanglok",
        "Panuwit Raden",
        "Jirapast Buntub",
        "Thanapat Warunee",
        "Napat Asawachaisuvikrom",
        "Thanaphum Saiwongin"
      ],
      "abstract": "While voice-based AI systems have achieved remarkable generative capabilities, their interactions often feel conversationally broken. This paper examines the interactional friction that emerges in modular Speech-to-Speech Retrieval-Augmented Generation (S2S-RAG) pipelines. By analyzing a representative production system, we move beyond simple latency metrics to identify three recurring patterns of conversational breakdown: (1) Temporal Misalignment, where system delays violate user expectations of conversational rhythm; (2) Expressive Flattening, where the loss of paralinguistic cues leads to literal, inappropriate responses; and (3) Repair Rigidity, where architectural gating prevents users from correcting errors in real-time. Through system-level analysis, we demonstrate that these friction points should not be understood as defects or failures, but as structural consequences of a modular design that prioritizes control over fluidity. We conclude that building natural spoken AI is an infrastructure design challenge, requiring a shift from optimizing isolated components to carefully choreographing the seams between them.",
      "pdf_url": "https://arxiv.org/pdf/2512.11724v1",
      "published": "2025-12-12T17:05:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.11724v1",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.SE"
      ]
    },
    {
      "title": "MedAI: Evaluating TxAgent's Therapeutic Agentic Reasoning in the NeurIPS CURE-Bench Competition",
      "authors": [
        "Tim Cofala",
        "Christian Kalfar",
        "Jingge Xiao",
        "Johanna Schrader",
        "Michelle Tang",
        "Wolfgang Nejdl"
      ],
      "abstract": "Therapeutic decision-making in clinical medicine constitutes a high-stakes domain in which AI guidance interacts with complex interactions among patient characteristics, disease processes, and pharmacological agents. Tasks such as drug recommendation, treatment planning, and adverse-effect prediction demand robust, multi-step reasoning grounded in reliable biomedical knowledge. Agentic AI methods, exemplified by TxAgent, address these challenges through iterative retrieval-augmented generation (RAG). TxAgent employs a fine-tuned Llama-3.1-8B model that dynamically generates and executes function calls to a unified biomedical tool suite (ToolUniverse), integrating FDA Drug API, OpenTargets, and Monarch resources to ensure access to current therapeutic information. In contrast to general-purpose RAG systems, medical applications impose stringent safety constraints, rendering the accuracy of both the reasoning trace and the sequence of tool invocations critical. These considerations motivate evaluation protocols treating token-level reasoning and tool-usage behaviors as explicit supervision signals. This work presents insights derived from our participation in the CURE-Bench NeurIPS 2025 Challenge, which benchmarks therapeutic-reasoning systems using metrics that assess correctness, tool utilization, and reasoning quality. We analyze how retrieval quality for function (tool) calls influences overall model performance and demonstrate performance gains achieved through improved tool-retrieval strategies. Our work was awarded the Excellence Award in Open Science. Complete information can be found at https://curebench.ai/.",
      "pdf_url": "https://arxiv.org/pdf/2512.11682v1",
      "published": "2025-12-12T16:01:48+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.11682v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "From Verification Burden to Trusted Collaboration: Design Goals for LLM-Assisted Literature Reviews",
      "authors": [
        "Brenda Nogueira",
        "Werner Geyer",
        "Andrew Anderson",
        "Toby Jia-Jun Li",
        "Dongwhi Kim",
        "Nuno Moniz",
        "Nitesh V. Chawla"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly embedded in academic writing practices. Although numerous studies have explored how researchers employ these tools for scientific writing, their concrete implementation, limitations, and design challenges within the literature review process remain underexplored. In this paper, we report a user study with researchers across multiple disciplines to characterize current practices, benefits, and \\textit{pain points} in using LLMs to investigate related work. We identified three recurring gaps: (i) lack of trust in outputs, (ii) persistent verification burden, and (iii) requiring multiple tools. This motivates our proposal of six design goals and a high-level framework that operationalizes them through improved related papers visualization, verification at every step, and human-feedback alignment with generation-guided explanations. Overall, by grounding our work in the practical, day-to-day needs of researchers, we designed a framework that addresses these limitations and models real-world LLM-assisted writing, advancing trust through verifiable actions and fostering practical collaboration between researchers and AI systems.",
      "pdf_url": "https://arxiv.org/pdf/2512.11661v1",
      "published": "2025-12-12T15:38:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.11661v1",
      "categories": [
        "cs.HC",
        "cs.AI"
      ]
    },
    {
      "title": "Causal Inference in Energy Demand Prediction",
      "authors": [
        "Chutian Ma",
        "Grigorii Pomazkin",
        "Giacinto Paolo Saggese",
        "Paul Smith"
      ],
      "abstract": "Energy demand prediction is critical for grid operators, industrial energy\n  consumers, and service providers. Energy demand is influenced by multiple\n  factors, including weather conditions (e.g. temperature, humidity, wind\n  speed, solar radiation), and calendar information (e.g. hour of day and\n  month of year), which further affect daily work and life schedules. These\n  factors are causally interdependent, making the problem more complex than\n  simple correlation-based learning techniques satisfactorily allow for. We\n  propose a structural causal model that explains the causal relationship\n  between these variables. A full analysis is performed to validate our causal\n  beliefs, also revealing important insights consistent with prior studies.\n  For example, our causal model reveals that energy demand responds to\n  temperature fluctuations with season-dependent sensitivity. Additionally, we\n  find that energy demand exhibits lower variance in winter due to the\n  decoupling effect between temperature changes and daily activity patterns.\n  We then build a Bayesian model, which takes advantage of the causal insights\n  we learned as prior knowledge. The model is trained and tested on unseen\n  data and yields state-of-the-art performance in the form of a 3.84 percent MAPE on\n  the test set. The model also demonstrates strong robustness, as the\n  cross-validation across two years of data yields an average MAPE of 3.88 percent.",
      "pdf_url": "https://arxiv.org/pdf/2512.11653v1",
      "published": "2025-12-12T15:30:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.11653v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Automating Historical Insight Extraction from Large-Scale Newspaper Archives via Neural Topic Modeling",
      "authors": [
        "Keerthana Murugaraj",
        "Salima Lamsiyah",
        "Marten During",
        "Martin Theobald"
      ],
      "abstract": "Extracting coherent and human-understandable themes from large collections of unstructured historical newspaper archives presents significant challenges due to topic evolution, Optical Character Recognition (OCR) noise, and the sheer volume of text. Traditional topic-modeling methods, such as Latent Dirichlet Allocation (LDA), often fall short in capturing the complexity and dynamic nature of discourse in historical texts. To address these limitations, we employ BERTopic. This neural topic-modeling approach leverages transformerbased embeddings to extract and classify topics, which, despite its growing popularity, still remains underused in historical research. Our study focuses on articles published between 1955 and 2018, specifically examining discourse on nuclear power and nuclear safety. We analyze various topic distributions across the corpus and trace their temporal evolution to uncover long-term trends and shifts in public discourse. This enables us to more accurately explore patterns in public discourse, including the co-occurrence of themes related to nuclear power and nuclear weapons and their shifts in topic importance over time. Our study demonstrates the scalability and contextual sensitivity of BERTopic as an alternative to traditional approaches, offering richer insights into historical discourses extracted from newspaper archives. These findings contribute to historical, nuclear, and social-science research while reflecting on current limitations and proposing potential directions for future work.",
      "pdf_url": "https://arxiv.org/pdf/2512.11635v1",
      "published": "2025-12-12T15:15:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.11635v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ]
    },
    {
      "title": "Bounding Hallucinations: Information-Theoretic Guarantees for RAG Systems via Merlin-Arthur Protocols",
      "authors": [
        "Björn Deiseroth",
        "Max Henning Höth",
        "Kristian Kersting",
        "Letitia Parcalabescu"
      ],
      "abstract": "Retrieval-augmented generation (RAG) models rely on retrieved evidence to guide large language model (LLM) generators, yet current systems treat retrieval as a weak heuristic rather than verifiable evidence. As a result, LLMs answer without support, hallucinate under incomplete or misleading context, and rely on spurious evidence. We introduce a training framework that treats the entire RAG pipeline -- both the retriever and the generator -- as an interactive proof system via an adaptation of the Merlin-Arthur (M/A) protocol. Arthur (the generator LLM) trains on questions of unkown provenance: Merlin provides helpful evidence, while Morgana injects adversarial, misleading context. Both use a linear-time XAI method to identify and modify the evidence most influential to Arthur. Consequently, Arthur learns to (i) answer when the context support the answer, (ii) reject when evidence is insufficient, and (iii) rely on the specific context spans that truly ground the answer. We further introduce a rigorous evaluation framework to disentangle explanation fidelity from baseline predictive errors. This allows us to introduce and measure the Explained Information Fraction (EIF), which normalizes M/A certified mutual-information guarantees relative to model capacity and imperfect benchmarks. Across three RAG datasets and two model families of varying sizes, M/A-trained LLMs show improved groundedness, completeness, soundness, and reject behavior, as well as reduced hallucinations -- without needing manually annotated unanswerable questions. The retriever likewise improves recall and MRR through automatically generated M/A hard positives and negatives. Our results demonstrate that autonomous interactive-proof-style supervision provides a principled and practical path toward reliable RAG systems that treat retrieved documents not as suggestions, but as verifiable evidence.",
      "pdf_url": "https://arxiv.org/pdf/2512.11614v1",
      "published": "2025-12-12T14:50:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.11614v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "AI Benchmark Democratization and Carpentry",
      "authors": [
        "Gregor von Laszewski",
        "Wesley Brewer",
        "Jeyan Thiyagalingam",
        "Juri Papay",
        "Armstrong Foundjem",
        "Piotr Luszczek",
        "Murali Emani",
        "Shirley V. Moore",
        "Vijay Janapa Reddi",
        "Matthew D. Sinclair",
        "Sebastian Lobentanzer",
        "Sujata Goswami",
        "Benjamin Hawks",
        "Marco Colombo",
        "Nhan Tran",
        "Christine R. Kirkpatrick",
        "Abdulkareem Alsudais",
        "Gregg Barrett",
        "Tianhao Li",
        "Kirsten Morehouse",
        "Shivaram Venkataraman",
        "Rutwik Jain",
        "Kartik Mathur",
        "Victor Lu",
        "Tejinder Singh",
        "Khojasteh Z. Mirza",
        "Kongtao Chen",
        "Sasidhar Kunapuli",
        "Gavin Farrell",
        "Renato Umeton",
        "Geoffrey C. Fox"
      ],
      "abstract": "Benchmarks are a cornerstone of modern machine learning, enabling reproducibility, comparison, and scientific progress. However, AI benchmarks are increasingly complex, requiring dynamic, AI-focused workflows. Rapid evolution in model architectures, scale, datasets, and deployment contexts makes evaluation a moving target. Large language models often memorize static benchmarks, causing a gap between benchmark results and real-world performance.\n  Beyond traditional static benchmarks, continuous adaptive benchmarking frameworks are needed to align scientific assessment with deployment risks. This calls for skills and education in AI Benchmark Carpentry. From our experience with MLCommons, educational initiatives, and programs like the DOE's Trillion Parameter Consortium, key barriers include high resource demands, limited access to specialized hardware, lack of benchmark design expertise, and uncertainty in relating results to application domains. Current benchmarks often emphasize peak performance on top-tier hardware, offering limited guidance for diverse, real-world scenarios.\n  Benchmarking must become dynamic, incorporating evolving models, updated data, and heterogeneous platforms while maintaining transparency, reproducibility, and interpretability. Democratization requires both technical innovation and systematic education across levels, building sustained expertise in benchmark design and use. Benchmarks should support application-relevant comparisons, enabling informed, context-sensitive decisions. Dynamic, inclusive benchmarking will ensure evaluation keeps pace with AI evolution and supports responsible, reproducible, and accessible AI deployment. Community efforts can provide a foundation for AI Benchmark Carpentry.",
      "pdf_url": "https://arxiv.org/pdf/2512.11588v1",
      "published": "2025-12-12T14:20:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.11588v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Atomic Action Slicing: Planner-Aligned Options for Generalist VLA Agents",
      "authors": [
        "Stefan Tabakov",
        "Asen Popov",
        "Dimitar Dimitrov",
        "S. Ensiye Kiyamousavi",
        "Vladimir Hristov",
        "Boris Kraychev"
      ],
      "abstract": "Current vision-language-action (VLA) models generalize poorly, particularly when tasks require new compositions of skills or objects. We introduce Atomic Action Slicing (AAS), a planner-aligned approach that decomposes long-horizon demonstrations into short, typed atomic actions that are easier for planners to use and policies to learn. Using LIBERO demonstrations, AAS produces a validated dataset of 2,124 atomic segments labeled with action type, temporal span, and confidence. A stronger segmenter (Gemini 2.5 Pro) closely matches planner-defined plans and remains robust under keyframe jitter, while smaller models perform worse on multi-object tasks. Fine-tuning CLIP-RT+ on our atomic dataset improves task success from 94.2% to 95.3% on LIBERO-Goal and 83.8% to 88.8% on LIBERO-Long. We publicly release the GATE-VLAP dataset on HuggingFace(https://huggingface.co/datasets/gate-institute/GATE-VLAP-datasets)",
      "pdf_url": "https://arxiv.org/pdf/2512.11584v1",
      "published": "2025-12-12T14:14:27+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.11584v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ]
    },
    {
      "title": "Multi-temporal Calving Front Segmentation",
      "authors": [
        "Marcel Dreier",
        "Nora Gourmelon",
        "Dakota Pyles",
        "Fei Wu",
        "Matthias Braun",
        "Thorsten Seehaus",
        "Andreas Maier",
        "Vincent Christlein"
      ],
      "abstract": "The calving fronts of marine-terminating glaciers undergo constant changes. These changes significantly affect the glacier's mass and dynamics, demanding continuous monitoring. To address this need, deep learning models were developed that can automatically delineate the calving front in Synthetic Aperture Radar imagery. However, these models often struggle to correctly classify areas affected by seasonal conditions such as ice melange or snow-covered surfaces. To address this issue, we propose to process multiple frames from a satellite image time series of the same glacier in parallel and exchange temporal information between the corresponding feature maps to stabilize each prediction. We integrate our approach into the current state-of-the-art architecture Tyrion and accomplish a new state-of-the-art performance on the CaFFe benchmark dataset. In particular, we achieve a Mean Distance Error of 184.4 m and a mean Intersection over Union of 83.6.",
      "pdf_url": "https://arxiv.org/pdf/2512.11560v1",
      "published": "2025-12-12T13:45:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.11560v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "DentalGPT: Incentivizing Multimodal Complex Reasoning in Dentistry",
      "authors": [
        "Zhenyang Cai",
        "Jiaming Zhang",
        "Junjie Zhao",
        "Ziyi Zeng",
        "Yanchao Li",
        "Jingyi Liang",
        "Junying Chen",
        "Yunjin Yang",
        "Jiajun You",
        "Shuzhi Deng",
        "Tongfei Wang",
        "Wanting Chen",
        "Chunxiu Hao",
        "Ruiqi Xie",
        "Zhenwei Wen",
        "Xiangyi Feng",
        "Zou Ting",
        "Jin Zou Lin",
        "Jianquan Li",
        "Guangjun Yu",
        "Liangyi Chen",
        "Junwen Wang",
        "Shan Jiang",
        "Benyou Wang"
      ],
      "abstract": "Reliable interpretation of multimodal data in dentistry is essential for automated oral healthcare, yet current multimodal large language models (MLLMs) struggle to capture fine-grained dental visual details and lack sufficient reasoning ability for precise diagnosis. To address these limitations, we present DentalGPT, a specialized dental MLLM developed through high-quality domain knowledge injection and reinforcement learning. Specifically, the largest annotated multimodal dataset for dentistry to date was constructed by aggregating over 120k dental images paired with detailed descriptions that highlight diagnostically relevant visual features, making it the multimodal dataset with the most extensive collection of dental images to date. Training on this dataset significantly enhances the MLLM's visual understanding of dental conditions, while the subsequent reinforcement learning stage further strengthens its capability for multimodal complex reasoning. Comprehensive evaluations on intraoral and panoramic benchmarks, along with dental subsets of medical VQA benchmarks, show that DentalGPT achieves superior performance in disease classification and dental VQA tasks, outperforming many state-of-the-art MLLMs despite having only 7B parameters. These results demonstrate that high-quality dental data combined with staged adaptation provides an effective pathway for building capable and domain-specialized dental MLLMs.",
      "pdf_url": "https://arxiv.org/pdf/2512.11558v1",
      "published": "2025-12-12T13:42:57+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.11558v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Optimizing the Training Diet: Data Mixture Search for Robust Time Series Forecasting",
      "authors": [
        "Federico Pennino",
        "Maurizio Gabbrielli"
      ],
      "abstract": "The standard paradigm for training deep learning models on sensor data assumes that more data is always better. However, raw sensor streams are often imbalanced and contain significant redundancy, meaning that not all data points contribute equally to model generalization. In this paper, we show that, in some cases, \"less is more\" when considering datasets. We do this by reframing the data selection problem: rather than tuning model hyperparameters, we fix the model and optimize the composition of the training data itself. We introduce a framework for discovering the optimal \"training diet\" from a large, unlabeled time series corpus. Our framework first uses a large-scale encoder and k-means clustering to partition the dataset into distinct, behaviorally consistent clusters. These clusters represent the fundamental 'ingredients' available for training. We then employ the Optuna optimization framework to search the high-dimensional space of possible data mixtures. For each trial, Optuna proposes a specific sampling ratio for each cluster, and a new training set is constructed based on this recipe. A smaller target model is then trained and evaluated. Our experiments reveal that this data-centric search consistently discovers data mixtures that yield models with significantly higher performance compared to baselines trained on the entire dataset. Specifically - evaluated on PMSM dataset - our method improved performance from a baseline MSE of 1.70 to 1.37, a 19.41% improvement.",
      "pdf_url": "https://arxiv.org/pdf/2512.11546v1",
      "published": "2025-12-12T13:26:07+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.11546v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Graph Embedding with Mel-spectrograms for Underwater Acoustic Target Recognition",
      "authors": [
        "Sheng Feng",
        "Shuqing Ma",
        "Xiaoqian Zhu"
      ],
      "abstract": "Underwater acoustic target recognition (UATR) is extremely challenging due to the complexity of ship-radiated noise and the variability of ocean environments. Although deep learning (DL) approaches have achieved promising results, most existing models implicitly assume that underwater acoustic data lie in a Euclidean space. This assumption, however, is unsuitable for the inherently complex topology of underwater acoustic signals, which exhibit non-stationary, non-Gaussian, and nonlinear characteristics. To overcome this limitation, this paper proposes the UATR-GTransformer, a non-Euclidean DL model that integrates Transformer architectures with graph neural networks (GNNs). The model comprises three key components: a Mel patchify block, a GTransformer block, and a classification head. The Mel patchify block partitions the Mel-spectrogram into overlapping patches, while the GTransformer block employs a Transformer Encoder to capture mutual information between split patches to generate Mel-graph embeddings. Subsequently, a GNN enhances these embeddings by modeling local neighborhood relationships, and a feed-forward network (FFN) further performs feature transformation. Experiments results based on two widely used benchmark datasets demonstrate that the UATR-GTransformer achieves performance competitive with state-of-the-art methods. In addition, interpretability analysis reveals that the proposed model effectively extracts rich frequency-domain information, highlighting its potential for applications in ocean engineering.",
      "pdf_url": "https://arxiv.org/pdf/2512.11545v1",
      "published": "2025-12-12T13:25:54+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.11545v1",
      "categories": [
        "cs.SD",
        "cs.AI"
      ]
    },
    {
      "title": "AI-MASLD Metabolic Dysfunction and Information Steatosis of Large Language Models in Unstructured Clinical Narratives",
      "authors": [
        "Yuan Shen",
        "Xiaojun Wu",
        "Linghua Yu"
      ],
      "abstract": "This study aims to simulate real-world clinical scenarios to systematically evaluate the ability of Large Language Models (LLMs) to extract core medical information from patient chief complaints laden with noise and redundancy, and to verify whether they exhibit a functional decline analogous to Metabolic Dysfunction-Associated Steatotic Liver Disease (MASLD). We employed a cross-sectional analysis design based on standardized medical probes, selecting four mainstream LLMs as research subjects: GPT-4o, Gemini 2.5, DeepSeek 3.1, and Qwen3-Max. An evaluation system comprising twenty medical probes across five core dimensions was used to simulate a genuine clinical communication environment. All probes had gold-standard answers defined by clinical experts and were assessed via a double-blind, inverse rating scale by two independent clinicians. The results show that all tested models exhibited functional defects to varying degrees, with Qwen3-Max demonstrating the best overall performance and Gemini 2.5 the worst. Under conditions of extreme noise, most models experienced a functional collapse. Notably, GPT-4o made a severe misjudgment in the risk assessment for pulmonary embolism (PE) secondary to deep vein thrombosis (DVT). This research is the first to empirically confirm that LLMs exhibit features resembling metabolic dysfunction when processing clinical information, proposing the innovative concept of \"AI-Metabolic Dysfunction-Associated Steatotic Liver Disease (AI-MASLD)\". These findings offer a crucial safety warning for the application of Artificial Intelligence (AI) in healthcare, emphasizing that current LLMs must be used as auxiliary tools under human expert supervision, as there remains a significant gap between their theoretical knowledge and practical clinical application.",
      "pdf_url": "https://arxiv.org/pdf/2512.11544v1",
      "published": "2025-12-12T13:25:19+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.11544v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Parallax: Runtime Parallelization for Operator Fallbacks in Heterogeneous Edge Systems",
      "authors": [
        "Chong Tang",
        "Hao Dai",
        "Jagmohan Chauhan"
      ],
      "abstract": "The growing demand for real-time DNN applications on edge devices necessitates faster inference of increasingly complex models. Although many devices include specialized accelerators (e.g., mobile GPUs), dynamic control-flow operators and unsupported kernels often fall back to CPU execution. Existing frameworks handle these fallbacks poorly, leaving CPU cores idle and causing high latency and memory spikes. We introduce Parallax, a framework that accelerates mobile DNN inference without model refactoring or custom operator implementations. Parallax first partitions the computation DAG to expose parallelism, then employs branch-aware memory management with dedicated arenas and buffer reuse to reduce runtime footprint. An adaptive scheduler executes branches according to device memory constraints, meanwhile, fine-grained subgraph control enables heterogeneous inference of dynamic models. By evaluating on five representative DNNs across three different mobile devices, Parallax achieves up to 46% latency reduction, maintains controlled memory overhead (26.5% on average), and delivers up to 30% energy savings compared with state-of-the-art frameworks, offering improvements aligned with the responsiveness demands of real-time mobile inference.",
      "pdf_url": "https://arxiv.org/pdf/2512.11532v1",
      "published": "2025-12-12T13:07:00+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.11532v1",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Contrastive Time Series Forecasting with Anomalies",
      "authors": [
        "Joel Ekstrand",
        "Zahra Taghiyarrenani",
        "Slawomir Nowaczyk"
      ],
      "abstract": "Time series forecasting predicts future values from past data. In real-world settings, some anomalous events have lasting effects and influence the forecast, while others are short-lived and should be ignored. Standard forecasting models fail to make this distinction, often either overreacting to noise or missing persistent shifts. We propose Co-TSFA (Contrastive Time Series Forecasting with Anomalies), a regularization framework that learns when to ignore anomalies and when to respond. Co-TSFA generates input-only and input-output augmentations to model forecast-irrelevant and forecast-relevant anomalies, and introduces a latent-output alignment loss that ties representation changes to forecast changes. This encourages invariance to irrelevant perturbations while preserving sensitivity to meaningful distributional shifts. Experiments on the Traffic and Electricity benchmarks, as well as on a real-world cash-demand dataset, demonstrate that Co-TSFA improves performance under anomalous conditions while maintaining accuracy on normal data. An anonymized GitHub repository with the implementation of Co-TSFA is provided and will be made public upon acceptance.",
      "pdf_url": "https://arxiv.org/pdf/2512.11526v1",
      "published": "2025-12-12T12:54:24+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.11526v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ]
    },
    {
      "title": "NeuralOGCM: Differentiable Ocean Modeling with Learnable Physics",
      "authors": [
        "Hao Wu",
        "Yuan Gao",
        "Fan Xu",
        "Fan Zhang",
        "Guangliang Liu",
        "Yuxuan Liang",
        "Xiaomeng Huang"
      ],
      "abstract": "High-precision scientific simulation faces a long-standing trade-off between computational efficiency and physical fidelity. To address this challenge, we propose NeuralOGCM, an ocean modeling framework that fuses differentiable programming with deep learning. At the core of NeuralOGCM is a fully differentiable dynamical solver, which leverages physics knowledge as its core inductive bias. The learnable physics integration captures large-scale, deterministic physical evolution, and transforms key physical parameters (e.g., diffusion coefficients) into learnable parameters, enabling the model to autonomously optimize its physical core via end-to-end training. Concurrently, a deep neural network learns to correct for subgrid-scale processes and discretization errors not captured by the physics model. Both components work in synergy, with their outputs integrated by a unified ODE solver. Experiments demonstrate that NeuralOGCM maintains long-term stability and physical consistency, significantly outperforming traditional numerical models in speed and pure AI baselines in accuracy. Our work paves a new path for building fast, stable, and physically-plausible models for scientific computing.",
      "pdf_url": "https://arxiv.org/pdf/2512.11525v1",
      "published": "2025-12-12T12:53:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.11525v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Does Less Hallucination Mean Less Creativity? An Empirical Investigation in LLMs",
      "authors": [
        "Mohor Banerjee",
        "Nadya Yuki Wangsajaya",
        "Syed Ali Redha Alsagoff",
        "Min Sen Tan",
        "Zachary Choy Kit Chun",
        "Alvin Chan Guo Wei"
      ],
      "abstract": "Large Language Models (LLMs) exhibit remarkable capabilities in natural language understanding and reasoning, but suffer from hallucination: the generation of factually incorrect content. While numerous methods have been developed to reduce hallucinations, their impact on creative generations remains unexplored. This gap is particularly critical for AI-assisted scientific discovery, which requires both factual accuracy and creative hypothesis generation. We investigate how three hallucination-reduction techniques: Chain of Verification (CoVe), Decoding by Contrasting Layers (DoLa), and Retrieval-Augmented Generation (RAG), affect creativity in LLMs. Evaluating multiple model families (LLaMA, Qwen, Mistral) at varying scales (1B - 70B parameters) on two creativity benchmarks (NeoCoder and CS4), we find that these methods have opposing effects on divergent creativity. CoVe enhances divergent thinking, DoLa suppresses it, and RAG shows minimal impact. Our findings provide guidance for selecting appropriate hallucination-reduction methods in scientific applications, where the balance between factual accuracy and creative exploration is crucial.",
      "pdf_url": "https://arxiv.org/pdf/2512.11509v1",
      "published": "2025-12-12T12:14:29+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.11509v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "EmeraldMind: A Knowledge Graph-Augmented Framework for Greenwashing Detection",
      "authors": [
        "Georgios Kaoukis",
        "Ioannis Aris Koufopoulos",
        "Psaroudaki Eleni",
        "Danae Pla Karidi",
        "Evaggelia Pitoura",
        "George Papastefanatos",
        "Panayiotis Tsaparas"
      ],
      "abstract": "As AI and web agents become pervasive in decision-making, it is critical to design intelligent systems that not only support sustainability efforts but also guard against misinformation. Greenwashing, i.e., misleading corporate sustainability claims, poses a major challenge to environmental progress. To address this challenge, we introduce EmeraldMind, a fact-centric framework integrating a domain-specific knowledge graph with retrieval-augmented generation to automate greenwashing detection. EmeraldMind builds the EmeraldGraph from diverse corporate ESG (environmental, social, and governance) reports, surfacing verifiable evidence, often missing in generic knowledge bases, and supporting large language models in claim assessment. The framework delivers justification-centric classifications, presenting transparent, evidence-backed verdicts and abstaining responsibly when claims cannot be verified. Experiments on a new greenwashing claims dataset demonstrate that EmeraldMind achieves competitive accuracy, greater coverage, and superior explanation quality compared to generic LLMs, without the need for fine-tuning or retraining.",
      "pdf_url": "https://arxiv.org/pdf/2512.11506v1",
      "published": "2025-12-12T12:06:36+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.11506v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "BAID: A Benchmark for Bias Assessment of AI Detectors",
      "authors": [
        "Priyam Basu",
        "Yunfeng Zhang",
        "Vipul Raheja"
      ],
      "abstract": "AI-generated text detectors have recently gained adoption in educational and professional contexts. Prior research has uncovered isolated cases of bias, particularly against English Language Learners (ELLs) however, there is a lack of systematic evaluation of such systems across broader sociolinguistic factors. In this work, we propose BAID, a comprehensive evaluation framework for AI detectors across various types of biases. As a part of the framework, we introduce over 200k samples spanning 7 major categories: demographics, age, educational grade level, dialect, formality, political leaning, and topic. We also generated synthetic versions of each sample with carefully crafted prompts to preserve the original content while reflecting subgroup-specific writing styles. Using this, we evaluate four open-source state-of-the-art AI text detectors and find consistent disparities in detection performance, particularly low recall rates for texts from underrepresented groups. Our contributions provide a scalable, transparent approach for auditing AI detectors and emphasize the need for bias-aware evaluation before these tools are deployed for public use.",
      "pdf_url": "https://arxiv.org/pdf/2512.11505v1",
      "published": "2025-12-12T12:01:42+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.11505v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Towards Privacy-Preserving Code Generation: Differentially Private Code Language Models",
      "authors": [
        "Melih Catal",
        "Pooja Rani",
        "Harald C. Gall"
      ],
      "abstract": "Large language models specialized for code (CodeLLMs) have demonstrated remarkable capabilities in generating code snippets, documentation, and test cases. However, despite their promising capabilities, CodeLLMs can inadvertently memorize and reproduce snippets from their training data, which poses risks of privacy breaches and intellectual property violations. These risks restrict the deployment of CodeLLMs in sensitive domains and limit their training datasets to publicly available sources. To mitigate the memorization risk without compromising their task performance, we apply Differential Privacy (DP) to CodeLLMs. To the best of our knowledge, this is the first comprehensive study that systematically evaluates the effectiveness of DP in CodeLLMs. DP adds calibrated noise to the training process to protect individual data points while still allowing the model to learn useful patterns. To this end, we first identify and understand the driving reasons of the memorization behaviour of the CodeLLMs during their fine-tuning. Then, to address this issue, we empirically evaluate the effect of DP on mitigating memorization while preserving code generation capabilities. Our findings show that DP substantially reduces memorization in CodeLLMs across all the tested snippet types. The snippet types most prone to memorization are also the most effectively mitigated by DP. Furthermore, we observe that DP slightly increases perplexity but preserves, and can even enhance, the code generation capabilities of CodeLLMs, which makes it feasible to apply DP in practice without significantly compromising model utility. Finally, we analyze the impact of DP on training efficiency and energy consumption, finding that DP does not significantly affect training time or energy usage, making it a practical choice for privacy-preserving CodeLLMs training.",
      "pdf_url": "https://arxiv.org/pdf/2512.11482v1",
      "published": "2025-12-12T11:31:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.11482v1",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CR"
      ]
    },
    {
      "title": "General-purpose AI models can generate actionable knowledge on agroecological crop protection",
      "authors": [
        "Kris A. G. Wyckhuys"
      ],
      "abstract": "Generative artificial intelligence (AI) offers potential for democratizing scientific knowledge and converting this to clear, actionable information, yet its application in agri-food science remains unexplored. Here, we verify the scientific knowledge on agroecological crop protection that is generated by either web-grounded or non-grounded large language models (LLMs), i.e., DeepSeek versus the free-tier version of ChatGPT. For nine globally limiting pests, weeds, and plant diseases, we assessed the factual accuracy, data consistency, and breadth of knowledge or data completeness of each LLM. Overall, DeepSeek consistently screened a 4.8-49.7-fold larger literature corpus and reported 1.6-2.4-fold more biological control agents or management solutions than ChatGPT. As a result, DeepSeek reported 21.6% higher efficacy estimates, exhibited greater laboratory-to-field data consistency, and showed more realistic effects of pest identity and management tactics. However, both models hallucinated, i.e., fabricated fictitious agents or references, reported on implausible ecological interactions or outcomes, confused old and new scientific nomenclatures, and omitted data on key agents or solutions. Despite these shortcomings, both LLMs correctly reported low-resolution efficacy trends. Overall, when paired with rigorous human oversight, LLMs may pose a powerful tool to support farm-level decision-making and unleash scientific creativity.",
      "pdf_url": "https://arxiv.org/pdf/2512.11474v1",
      "published": "2025-12-12T11:17:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.11474v1",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.IR"
      ]
    },
    {
      "title": "Three methods, one problem: Classical and AI approaches to no-three-in-line",
      "authors": [
        "Pranav Ramanathan",
        "Thomas Prellberg",
        "Matthew Lewis",
        "Prathamesh Dinesh Joshi",
        "Raj Abhijit Dandekar",
        "Rajat Dandekar",
        "Sreedath Panat"
      ],
      "abstract": "The No-Three-In-Line problem asks for the maximum number of points that can be placed on an n by n grid with no three collinear, representing a famous problem in combinatorial geometry. While classical methods like Integer Linear Programming (ILP) guarantee optimal solutions, they face exponential scaling with grid size, and recent advances in machine learning offer promising alternatives for pattern-based approximation. This paper presents the first systematic comparison of classical optimization and AI approaches to this problem, evaluating their performance against traditional algorithms. We apply PatternBoost transformer learning and reinforcement learning (PPO) to this problem for the first time, comparing them against ILP. ILP achieves provably optimal solutions up to 19 by 19 grids, while PatternBoost matches optimal performance up to 14 by 14 grids with 96% test loss reduction. PPO achieves perfect solutions on 10 by 10 grids but fails at 11 by 11 grids, where constraint violations prevent valid configurations. These results demonstrate that classical optimization remains essential for exact solutions while AI methods offer competitive performance on smaller instances, with hybrid approaches presenting the most promising direction for scaling to larger problem sizes.",
      "pdf_url": "https://arxiv.org/pdf/2512.11469v1",
      "published": "2025-12-12T11:12:42+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.11469v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Exploring MLLM-Diffusion Information Transfer with MetaCanvas",
      "authors": [
        "Han Lin",
        "Xichen Pan",
        "Ziqi Huang",
        "Ji Hou",
        "Jialiang Wang",
        "Weifeng Chen",
        "Zecheng He",
        "Felix Juefei-Xu",
        "Junzhe Sun",
        "Zhipeng Fan",
        "Ali Thabet",
        "Mohit Bansal",
        "Chu Wang"
      ],
      "abstract": "Multimodal learning has rapidly advanced visual understanding, largely via multimodal large language models (MLLMs) that use powerful LLMs as cognitive cores. In visual generation, however, these powerful core models are typically reduced to global text encoders for diffusion models, leaving most of their reasoning and planning ability unused. This creates a gap: current multimodal LLMs can parse complex layouts, attributes, and knowledge-intensive scenes, yet struggle to generate images or videos with equally precise and structured control. We propose MetaCanvas, a lightweight framework that lets MLLMs reason and plan directly in spatial and spatiotemporal latent spaces and interface tightly with diffusion generators. We empirically implement MetaCanvas on three different diffusion backbones and evaluate it across six tasks, including text-to-image generation, text/image-to-video generation, image/video editing, and in-context video generation, each requiring precise layouts, robust attribute binding, and reasoning-intensive control. MetaCanvas consistently outperforms global-conditioning baselines, suggesting that treating MLLMs as latent-space planners is a promising direction for narrowing the gap between multimodal understanding and generation.",
      "pdf_url": "https://arxiv.org/pdf/2512.11464v1",
      "published": "2025-12-12T11:07:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.11464v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Boosting Skeleton-based Zero-Shot Action Recognition with Training-Free Test-Time Adaptation",
      "authors": [
        "Jingmin Zhu",
        "Anqi Zhu",
        "Hossein Rahmani",
        "Jun Liu",
        "Mohammed Bennamoun",
        "Qiuhong Ke"
      ],
      "abstract": "We introduce Skeleton-Cache, the first training-free test-time adaptation framework for skeleton-based zero-shot action recognition (SZAR), aimed at improving model generalization to unseen actions during inference. Skeleton-Cache reformulates inference as a lightweight retrieval process over a non-parametric cache that stores structured skeleton representations, combining both global and fine-grained local descriptors. To guide the fusion of descriptor-wise predictions, we leverage the semantic reasoning capabilities of large language models (LLMs) to assign class-specific importance weights. By integrating these structured descriptors with LLM-guided semantic priors, Skeleton-Cache dynamically adapts to unseen actions without any additional training or access to training data. Extensive experiments on NTU RGB+D 60/120 and PKU-MMD II demonstrate that Skeleton-Cache consistently boosts the performance of various SZAR backbones under both zero-shot and generalized zero-shot settings. The code is publicly available at https://github.com/Alchemist0754/Skeleton-Cache.",
      "pdf_url": "https://arxiv.org/pdf/2512.11458v1",
      "published": "2025-12-12T10:53:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.11458v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Flowception: Temporally Expansive Flow Matching for Video Generation",
      "authors": [
        "Tariq Berrada Ifriqi",
        "John Nguyen",
        "Karteek Alahari",
        "Jakob Verbeek",
        "Ricky T. Q. Chen"
      ],
      "abstract": "We present Flowception, a novel non-autoregressive and variable-length video generation framework. Flowception learns a probability path that interleaves discrete frame insertions with continuous frame denoising. Compared to autoregressive methods, Flowception alleviates error accumulation/drift as the frame insertion mechanism during sampling serves as an efficient compression mechanism to handle long-term context. Compared to full-sequence flows, our method reduces FLOPs for training three-fold, while also being more amenable to local attention variants, and allowing to learn the length of videos jointly with their content. Quantitative experimental results show improved FVD and VBench metrics over autoregressive and full-sequence baselines, which is further validated with qualitative results. Finally, by learning to insert and denoise frames in a sequence, Flowception seamlessly integrates different tasks such as image-to-video generation and video interpolation.",
      "pdf_url": "https://arxiv.org/pdf/2512.11438v1",
      "published": "2025-12-12T10:23:47+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.11438v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Back to the Baseline: Examining Baseline Effects on Explainability Metrics",
      "authors": [
        "Agustin Martin Picard",
        "Thibaut Boissin",
        "Varshini Subhash",
        "Rémi Cadène",
        "Thomas Fel"
      ],
      "abstract": "Attribution methods are among the most prevalent techniques in Explainable Artificial Intelligence (XAI) and are usually evaluated and compared using Fidelity metrics, with Insertion and Deletion being the most popular. These metrics rely on a baseline function to alter the pixels of the input image that the attribution map deems most important. In this work, we highlight a critical problem with these metrics: the choice of a given baseline will inevitably favour certain attribution methods over others. More concerningly, even a simple linear model with commonly used baselines contradicts itself by designating different optimal methods. A question then arises: which baseline should we use? We propose to study this problem through two desirable properties of a baseline: (i) that it removes information and (ii) that it does not produce overly out-of-distribution (OOD) images. We first show that none of the tested baselines satisfy both criteria, and there appears to be a trade-off among current baselines: either they remove information or they produce a sequence of OOD images. Finally, we introduce a novel baseline by leveraging recent work in feature visualisation to artificially produce a model-dependent baseline that removes information without being overly OOD, thus improving on the trade-off when compared to other existing baselines. Our code is available at https://github.com/deel-ai-papers/Back-to-the-Baseline",
      "pdf_url": "https://arxiv.org/pdf/2512.11433v1",
      "published": "2025-12-12T10:13:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.11433v1",
      "categories": [
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "AgentBalance: Backbone-then-Topology Design for Cost-Effective Multi-Agent Systems under Budget Constraints",
      "authors": [
        "Shuowei Cai",
        "Yansong Ning",
        "Hao Liu"
      ],
      "abstract": "Large Language Model (LLM)-based multi-agent systems (MAS) are becoming indispensable building blocks for web-scale applications such as web search, social network analytics, and online customer support, where cost-effectiveness is increasingly the primary constraint for large-scale deployment. While recent work improves MAS cost-effectiveness by shaping inter-agent communication topologies and selecting agent backbones, it rarely models and optimizes under explicit token-cost and latency budgets that reflect deployment constraints. This often leads to topology-first designs and suboptimal cost-effectiveness when budgets are binding. We present AgentBalance, a framework for constructing cost-effective MAS under explicit token-cost and latency budgets via a backbone-then-topology design. AgentBalance first performs backbone-oriented agent generation, constructing agents with heterogeneous backbones through LLM pool construction, pool selection, and role-backbone matching. It then performs adaptive MAS topology generation, guiding inter-agent communication via agent representation learning, gating, and latency-aware topology synthesis. Experiments on benchmarks with 14 candidate LLM backbones show that AgentBalance achieves up to 10% and 22% performance gains under matched token-cost and latency budgets, respectively, and yields strong AUC on performance-versus-budget curves across benchmarks. AgentBalance also functions as a plug-in for existing MAS, improving performance under the same token-cost and latency constraints, and it generalizes well to unseen LLMs for practical, budget-aware deployment. Code: https://github.com/usail-hkust/AgentBalance",
      "pdf_url": "https://arxiv.org/pdf/2512.11426v1",
      "published": "2025-12-12T10:08:03+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.11426v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Towards Trustworthy Multi-Turn LLM Agents via Behavioral Guidance",
      "authors": [
        "Gonca Gürsun"
      ],
      "abstract": "Large Language Models demonstrate strong reasoning and generation abilities, yet their behavior in multi-turn tasks often lacks reliability and verifiability. We present a task completion framework that enables LLM-based agents to act under explicit behavioral guidance in environments described by reinforcement learning formalisms with defined observation, action, and reward signals.\n  The framework integrates three components: a lightweight task profiler that selects reasoning and generation strategies, a reasoning module that learns verifiable observation - action mappings, and a generation module that enforces constraint-compliant outputs through validation or deterministic synthesis. We show that as the agent interacts with the environment, these components co-evolve, yielding trustworthy behavior.",
      "pdf_url": "https://arxiv.org/pdf/2512.11421v1",
      "published": "2025-12-12T10:03:24+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.11421v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Task-Specific Sparse Feature Masks for Molecular Toxicity Prediction with Chemical Language Models",
      "authors": [
        "Kwun Sy Lee",
        "Jiawei Chen",
        "Fuk Sheng Ford Chung",
        "Tianyu Zhao",
        "Zhenyuan Chen",
        "Debby D. Wang"
      ],
      "abstract": "Reliable in silico molecular toxicity prediction is a cornerstone of modern drug discovery, offering a scalable alternative to experimental screening. However, the black-box nature of state-of-the-art models remains a significant barrier to adoption, as high-stakes safety decisions demand verifiable structural insights alongside predictive performance. To address this, we propose a novel multi-task learning (MTL) framework designed to jointly enhance accuracy and interpretability. Our architecture integrates a shared chemical language model with task-specific attention modules. By imposing an L1 sparsity penalty on these modules, the framework is constrained to focus on a minimal set of salient molecular fragments for each distinct toxicity endpoint. The resulting framework is trained end-to-end and is readily adaptable to various transformer-based backbones. Evaluated on the ClinTox, SIDER, and Tox21 benchmark datasets, our approach consistently outperforms both single-task and standard MTL baselines. Crucially, the sparse attention weights provide chemically intuitive visualizations that reveal the specific fragments influencing predictions, thereby enhancing insight into the model's decision-making process.",
      "pdf_url": "https://arxiv.org/pdf/2512.11412v1",
      "published": "2025-12-12T09:41:04+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.11412v1",
      "categories": [
        "cs.CE",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "q-bio.BM"
      ]
    },
    {
      "title": "REMODEL-LLM: Transforming C code to Java using LLMs",
      "authors": [
        "Aryan Gupta",
        "Y. Raghu Reddy"
      ],
      "abstract": "The automated translation of C code to Java code is a notoriously difficult task, fraught with challenges stemming from fundamental paradigm shifts (procedural vs. Object Oriented), memory models (manual pointers vs. Garbage Collection), and incompatible data types. This paper investigates the efficacy of 19 small, quantized LLMs (under 20 billion parameters) for the C to Java translation task. We use a novel, hybrid pipeline that leverages Abstract Syntax Trees (ASTs) for semantic decomposition and employs a highly constrained, rule based prompting strategy. The results are stark: a clear multi tiered performance divide emerged. The vast majority of models (Tier 3, e.g., llama3.1, gemma3, starcoder2) failed 100\\% of the tests, proving incapable of generating even basic, runnable Java boilerplate. A small middle tier (Tier 2, e.g., mistral-nemo and mistral) produced runnable code but was plagued by dangerous semantic failures and wrong translations. Only three models (Tier 1: phi4, deepseek-coder-v2, codeqwen) proved viable, passing over 50\\% of the test suite. Even these top models failed on the most complex C concepts, such as function pointers, sizeof, and enum logic, revealing a hard ceiling for the reasoning capabilities of current quantized models.",
      "pdf_url": "https://arxiv.org/pdf/2512.11402v1",
      "published": "2025-12-12T09:25:10+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.11402v1",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "Surveillance Video-Based Traffic Accident Detection Using Transformer Architecture",
      "authors": [
        "Tanu Singh",
        "Pranamesh Chakraborty",
        "Long T. Truong"
      ],
      "abstract": "Road traffic accidents represent a leading cause of mortality globally, with incidence rates rising due to increasing population, urbanization, and motorization. Rising accident rates raise concerns about traffic surveillance effectiveness. Traditional computer vision methods for accident detection struggle with limited spatiotemporal understanding and poor cross-domain generalization. Recent advances in transformer architectures excel at modeling global spatial-temporal dependencies and parallel computation. However, applying these models to automated traffic accident detection is limited by small, non-diverse datasets, hindering the development of robust, generalizable systems. To address this gap, we curated a comprehensive and balanced dataset that captures a wide spectrum of traffic environments, accident types, and contextual variations. Utilizing the curated dataset, we propose an accident detection model based on a transformer architecture using pre-extracted spatial video features. The architecture employs convolutional layers to extract local correlations across diverse patterns within a frame, while leveraging transformers to capture sequential-temporal dependencies among the retrieved features. Moreover, most existing studies neglect the integration of motion cues, which are essential for understanding dynamic scenes, especially during accidents. These approaches typically rely on static features or coarse temporal information. In this study, multiple methods for incorporating motion cues were evaluated to identify the most effective strategy. Among the tested input approaches, concatenating RGB features with optical flow achieved the highest accuracy at 88.3%. The results were further compared with vision language models (VLM) such as GPT, Gemini, and LLaVA-NeXT-Video to assess the effectiveness of the proposed method.",
      "pdf_url": "https://arxiv.org/pdf/2512.11350v1",
      "published": "2025-12-12T07:57:36+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.11350v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "MLLM Machine Unlearning via Visual Knowledge Distillation",
      "authors": [
        "Yuhang Wang",
        "Zhenxing Niu",
        "Haoxuan Ji",
        "Guangyu He",
        "Haichang Gao",
        "Gang Hua"
      ],
      "abstract": "Recently, machine unlearning approaches have been proposed to remove sensitive information from well-trained large models. However, most existing methods are tailored for LLMs, while MLLM-oriented unlearning remains at its early stage. Inspired by recent studies exploring the internal mechanisms of MLLMs, we propose to disentangle the visual and textual knowledge embedded within MLLMs and introduce a dedicated approach to selectively erase target visual knowledge while preserving textual knowledge. Unlike previous unlearning methods that rely on output-level supervision, our approach introduces a Visual Knowledge Distillation (VKD) scheme, which leverages intermediate visual representations within the MLLM as supervision signals. This design substantially enhances both unlearning effectiveness and model utility. Moreover, since our method only fine-tunes the visual components of the MLLM, it offers significant efficiency advantages. Extensive experiments demonstrate that our approach outperforms state-of-the-art unlearning methods in terms of both effectiveness and efficiency. Moreover, we are the first to evaluate the robustness of MLLM unlearning against relearning attacks.",
      "pdf_url": "https://arxiv.org/pdf/2512.11325v1",
      "published": "2025-12-12T06:51:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.11325v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "CAPTURE: A Benchmark and Evaluation for LVLMs in CAPTCHA Resolving",
      "authors": [
        "Jianyi Zhang",
        "Ziyin Zhou",
        "Xu Ji",
        "Shizhao Liu",
        "Zhangchi Zhao"
      ],
      "abstract": "Benefiting from strong and efficient multi-modal alignment strategies, Large Visual Language Models (LVLMs) are able to simulate human visual and reasoning capabilities, such as solving CAPTCHAs. However, existing benchmarks based on visual CAPTCHAs still face limitations. Previous studies, when designing benchmarks and datasets, customized them according to their research objectives. Consequently, these benchmarks cannot comprehensively cover all CAPTCHA types. Notably, there is a dearth of dedicated benchmarks for LVLMs. To address this problem, we introduce a novel CAPTCHA benchmark for the first time, named CAPTURE CAPTCHA for Testing Under Real-world Experiments, specifically for LVLMs. Our benchmark encompasses 4 main CAPTCHA types and 25 sub-types from 31 vendors. The diversity enables a multi-dimensional and thorough evaluation of LVLM performance. CAPTURE features extensive class variety, large-scale data, and unique LVLM-tailored labels, filling the gaps in previous research in terms of data comprehensiveness and labeling pertinence. When evaluated by this benchmark, current LVLMs demonstrate poor performance in solving CAPTCHAs.",
      "pdf_url": "https://arxiv.org/pdf/2512.11323v1",
      "published": "2025-12-12T06:50:27+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.11323v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Condensation-Concatenation Framework for Dynamic Graph Continual Learning",
      "authors": [
        "Tingxu Yan",
        "Ye Yuan"
      ],
      "abstract": "Dynamic graphs are prevalent in real-world scenarios, where continuous structural changes induce catastrophic forgetting in graph neural networks (GNNs). While continual learning has been extended to dynamic graphs, existing methods overlook the effects of topological changes on existing nodes. To address it, we propose a novel framework for continual learning on dynamic graphs, named Condensation-Concatenation-based Continual Learning (CCC). Specifically, CCC first condenses historical graph snapshots into compact semantic representations while aiming to preserve the original label distribution and topological properties. Then it concatenates these historical embeddings with current graph representations selectively. Moreover, we refine the forgetting measure (FM) to better adapt to dynamic graph scenarios by quantifying the predictive performance degradation of existing nodes caused by structural updates. CCC demonstrates superior performance over state-of-the-art baselines across four real-world datasets in extensive experiments.",
      "pdf_url": "https://arxiv.org/pdf/2512.11317v1",
      "published": "2025-12-12T06:32:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.11317v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Few-Shot VLM-Based G-Code and HMI Verification in CNC Machining",
      "authors": [
        "Yasaman Hashem Pour",
        "Nazanin Mahjourian",
        "Vinh Nguyen"
      ],
      "abstract": "Manual generation of G-code is important for learning the operation of CNC machines. Prior work in G-code verification uses Large-Language Models (LLMs), which primarily examine errors in the written programming. However, CNC machining requires extensive use and knowledge of the Human-Machine Interface (HMI), which displays machine status and errors. LLMs currently lack the capability to leverage knowledge of HMIs due to their inability to access the vision modality. This paper proposes a few-shot VLM-based verification approach that simultaneously evaluates the G-code and the HMI display for errors and safety status. The input dataset includes paired G-code text and associated HMI screenshots from a 15-slant-PRO lathe, including both correct and error-prone cases. To enable few-shot learning, the VLM is provided with a structured JSON schema based on prior heuristic knowledge. After determining the prompts, instances of G-code and HMI that either contain errors or are error free are used as few-shot examples to guide the VLM. The model was then evaluated in comparison to a zero-shot VLM through multiple scenarios of incorrect G-code and HMI errors with respect to per-slot accuracy. The VLM showed that few-shot prompting led to overall enhancement of detecting HMI errors and discrepancies with the G-code for more comprehensive debugging. Therefore, the proposed framework was demonstrated to be suitable for verification of manually generated G-code that is typically developed in CNC training.",
      "pdf_url": "https://arxiv.org/pdf/2512.11296v1",
      "published": "2025-12-12T05:42:36+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.11296v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC"
      ]
    },
    {
      "title": "AI Autonomy or Human Dependency? Defining the Boundary in Responsible AI with the $α$-Coefficient",
      "authors": [
        "Nattaya Mairittha",
        "Gabriel Phorncharoenmusikul",
        "Sorawit Worapradidth"
      ],
      "abstract": "The integrity of contemporary AI systems is undermined by a critical design flaw: the misappropriation of Human-in-the-Loop (HITL) models to mask systems that are fundamentally reliant on human labor. We term this structural reliance Human-Instead-of-AI (HISOAI). HISOAI systems represent an ethical failure and an unsustainable economic dependency, where human workers function as hidden operational fallbacks rather than strategic collaborators. To rectify this, we propose the AI-First, Human-Empowered (AFHE) paradigm. AFHE mandates a technological design where the AI component must achieve a minimum, quantifiable level of functional independence prior to deployment. This standard is formalized through the AI Autonomy Coefficient (alpha), a metric that determines the proportion of tasks that the AI successfully processes without mandatory human substitution. We introduce the AFHE Deployment Algorithm, an algorithmic gate that requires the system to meet a specified alpha threshold across both offline and shadow testing. By enforcing this structural separation, the AFHE framework redefines the human's role to focus exclusively on high-value tasks, including ethical oversight, boundary pushing, and strategic model tuning, thereby ensuring true system transparency and operational independence. This work advocates for a critical shift toward metric-driven, structurally sound AI architecture, moving the industry beyond deceptive human dependency toward verifiable autonomy.",
      "pdf_url": "https://arxiv.org/pdf/2512.11295v1",
      "published": "2025-12-12T05:41:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.11295v1",
      "categories": [
        "cs.HC",
        "cs.AI"
      ]
    },
    {
      "title": "CIP: A Plug-and-Play Causal Prompting Framework for Mitigating Hallucinations under Long-Context Noise",
      "authors": [
        "Qingsen Ma",
        "Dianyun Wang",
        "Ran Jing",
        "Yujun Sun",
        "Zhenbo Xu"
      ],
      "abstract": "Large language models often hallucinate when processing long and noisy retrieval contexts because they rely on spurious correlations rather than genuine causal relationships. We propose CIP, a lightweight and plug-and-play causal prompting framework that mitigates hallucinations at the input stage. CIP constructs a causal relation sequence among entities, actions, and events and injects it into the prompt to guide reasoning toward causally relevant evidence. Through causal intervention and counterfactual reasoning, CIP suppresses non causal reasoning paths, improving factual grounding and interpretability. Experiments across seven mainstream language models, including GPT-4o, Gemini 2.0 Flash, and Llama 3.1, show that CIP consistently enhances reasoning quality and reliability, achieving 2.6 points improvement in Attributable Rate, 0.38 improvement in Causal Consistency Score, and a fourfold increase in effective information density. API level profiling further shows that CIP accelerates contextual understanding and reduces end to end response latency by up to 55.1 percent. These results suggest that causal reasoning may serve as a promising paradigm for improving the explainability, stability, and efficiency of large language models.",
      "pdf_url": "https://arxiv.org/pdf/2512.11282v1",
      "published": "2025-12-12T05:02:26+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.11282v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Words to Describe What I'm Feeling: Exploring the Potential of AI Agents for High Subjectivity Decisions in Advance Care Planning",
      "authors": [
        "Kellie Yu Hui Sim",
        "Pin Sym Foong",
        "Chenyu Zhao",
        "Melanie Yi Ning Quek",
        "Swarangi Subodh Mehta",
        "Kenny Tsu Wei Choo"
      ],
      "abstract": "Serious illness can deprive patients of the capacity to speak for themselves. As populations age and caregiver networks shrink, the need for reliable support in Advance Care Planning (ACP) grows. To probe this fraught design space of using proxy agents for high-risk, high-subjectivity decisions, we built an experience prototype (\\acpagent{}) and asked 15 participants in 4 workshops to train it to be their personal proxy in ACP decisions. We analysed their coping strategies and feature requests and mapped the results onto axes of agent autonomy and human control. Our findings argue for a potential new role of AI in ACP where agents act as personal advocates for individuals, building mutual intelligibility over time. We conclude with design recommendations to balance the risks and benefits of such an agent.",
      "pdf_url": "https://arxiv.org/pdf/2512.11276v1",
      "published": "2025-12-12T04:39:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.11276v1",
      "categories": [
        "cs.HC",
        "cs.AI"
      ]
    },
    {
      "title": "TriFlow: A Progressive Multi-Agent Framework for Intelligent Trip Planning",
      "authors": [
        "Yuxing Chen",
        "Basem Suleiman",
        "Qifan Chen"
      ],
      "abstract": "Real-world trip planning requires transforming open-ended user requests into executable itineraries under strict spatial, temporal, and budgetary constraints while aligning with user preferences. Existing LLM-based agents struggle with constraint satisfaction, tool coordination, and efficiency, often producing infeasible or costly plans. To address these limitations, we present TriFlow, a progressive multi-agent framework that unifies structured reasoning and language-based flexibility through a three-stage pipeline of retrieval, planning, and governance. By this design, TriFlow progressively narrows the search space, assembles constraint-consistent itineraries via rule-LLM collaboration, and performs bounded iterative refinement to ensure global feasibility and personalisation. Evaluations on TravelPlanner and TripTailor benchmarks demonstrated state-of-the-art results, achieving 91.1% and 97% final pass rates, respectively, with over 10x runtime efficiency improvement compared to current SOTA.",
      "pdf_url": "https://arxiv.org/pdf/2512.11271v1",
      "published": "2025-12-12T04:27:22+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.11271v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "A-LAMP: Agentic LLM-Based Framework for Automated MDP Modeling and Policy Generation",
      "authors": [
        "Hong Je-Gal",
        "Chan-Bin Yi",
        "Hyun-Suk Lee"
      ],
      "abstract": "Applying reinforcement learning (RL) to real-world tasks requires converting informal descriptions into a formal Markov decision process (MDP), implementing an executable environment, and training a policy agent. Automating this process is challenging due to modeling errors, fragile code, and misaligned objectives, which often impede policy training. We introduce an agentic large language model (LLM)-based framework for automated MDP modeling and policy generation (A-LAMP), that automatically translates free-form natural language task descriptions into an MDP formulation and trained policy. The framework decomposes modeling, coding, and training into verifiable stages, ensuring semantic alignment throughout the pipeline. Across both classic control and custom RL domains, A-LAMP consistently achieves higher policy generation capability than a single state-of-the-art LLM model. Notably, even its lightweight variant, which is built on smaller language models, approaches the performance of much larger models. Failure analysis reveals why these improvements occur. In addition, a case study also demonstrates that A-LAMP generates environments and policies that preserve the task's optimality, confirming its correctness and reliability.",
      "pdf_url": "https://arxiv.org/pdf/2512.11270v1",
      "published": "2025-12-12T04:21:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.11270v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "A Scalable Multi-GPU Framework for Encrypted Large-Model Inference",
      "authors": [
        "Siddharth Jayashankar",
        "Joshua Kim",
        "Michael B. Sullivan",
        "Wenting Zheng",
        "Dimitrios Skarlatos"
      ],
      "abstract": "Encrypted AI using fully homomorphic encryption (FHE) provides strong privacy guarantees; but its slow performance has limited practical deployment. Recent works proposed ASICs to accelerate FHE, but require expensive advanced manufacturing processes that constrain their accessibility. GPUs are a far more accessible platform, but achieving ASIC-level performance using GPUs has remained elusive. Furthermore, state-of-the-art approaches primarily focus on small models that fit comfortably within a single device. Supporting large models such as LLMs in FHE introduces a dramatic increase in computational complexity that requires optimized GPU kernels, along with managing terabyte-scale memory footprints that far exceed the capacity of a single GPU. This paper presents Cerium, a multi-GPU framework for FHE inference on large models. Cerium integrates a domain-specific language, an optimizing compiler, and a runtime system to automatically generate high-performance GPU kernels, manage terabyte-scale memory footprints, and parallelize computation across multiple GPUs. It introduces new IR constructs, compiler passes, sparse polynomial representations, memory-efficient data layouts, and communication-aware parallelization techniques that together enable encrypted inference for models ranging from small CNNs to Llama3-8B. We build Cerium on NVIDIA GPUs and demonstrate significant performance gains. For small models, Cerium outperforms expert-written hand-optimized GPU libraries by up to 2.25 times. Cerium achieves performance competitive with state-of-the-art FHE ASICs, outright matching prior FHE ASIC CraterLake. It is the first GPU system to execute bootstrapping in under 10 milliseconds, achieving 7.5 milliseconds, and is the first to demonstrate encrypted inference for BERT-Base and Llama3-8B in 8 seconds and 134 seconds, respectively.",
      "pdf_url": "https://arxiv.org/pdf/2512.11269v1",
      "published": "2025-12-12T04:15:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.11269v1",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "title": "Multi-Intent Spoken Language Understanding: Methods, Trends, and Challenges",
      "authors": [
        "Di Wu",
        "Ruiyu Fang",
        "Liting Jiang",
        "Shuangyong Song",
        "Xiaomeng Huang",
        "Shiquan Wang",
        "Zhongqiu Li",
        "Lingling Shi",
        "Mengjiao Bao",
        "Yongxiang Li",
        "Hao Huang"
      ],
      "abstract": "Multi-intent spoken language understanding (SLU) involves two tasks: multiple intent detection and slot filling, which jointly handle utterances containing more than one intent. Owing to this characteristic, which closely reflects real-world applications, the task has attracted increasing research attention, and substantial progress has been achieved. However, there remains a lack of a comprehensive and systematic review of existing studies on multi-intent SLU. To this end, this paper presents a survey of recent advances in multi-intent SLU. We provide an in-depth overview of previous research from two perspectives: decoding paradigms and modeling approaches. On this basis, we further compare the performance of representative models and analyze their strengths and limitations. Finally, we discuss the current challenges and outline promising directions for future research. We hope this survey will offer valuable insights and serve as a useful reference for advancing research in multi-intent SLU.",
      "pdf_url": "https://arxiv.org/pdf/2512.11258v1",
      "published": "2025-12-12T03:46:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.11258v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "A Simple Generalisation of the Implicit Dynamics of In-Context Learning",
      "authors": [
        "Francesco Innocenti",
        "El Mehdi Achour"
      ],
      "abstract": "In-context learning (ICL) refers to the ability of a model to learn new tasks from examples in its input without any parameter updates. In contrast to previous theories of ICL relying on toy models and data settings, recently it has been shown that an abstraction of a transformer block can be seen as implicitly updating the weights of its feedforward network according to the context (Dherin et al., 2025). Here, we provide a simple generalisation of this result for (i) all sequence positions beyond the last, (ii) any transformer block beyond the first, and (iii) more realistic residual blocks including layer normalisation. We empirically verify our theory on simple in-context linear regression tasks and investigate the relationship between the implicit updates related to different tokens within and between blocks. These results help to bring the theory of Dherin et al. (2025) even closer to practice, with potential for validation on large-scale models.",
      "pdf_url": "https://arxiv.org/pdf/2512.11255v1",
      "published": "2025-12-12T03:26:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.11255v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    }
  ]
}