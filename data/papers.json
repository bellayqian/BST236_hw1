{
  "last_updated": "2025-06-14T00:51:11.203690",
  "papers": [
    {
      "title": "Rethinking Losses for Diffusion Bridge Samplers",
      "authors": [
        "Sebastian Sanokowski",
        "Lukas Gruber",
        "Christoph Bartmann",
        "Sepp Hochreiter",
        "Sebastian Lehner"
      ],
      "abstract": "Diffusion bridges are a promising class of deep-learning methods for sampling\nfrom unnormalized distributions. Recent works show that the Log Variance (LV)\nloss consistently outperforms the reverse Kullback-Leibler (rKL) loss when\nusing the reparametrization trick to compute rKL-gradients. While the on-policy\nLV loss yields identical gradients to the rKL loss when combined with the\nlog-derivative trick for diffusion samplers with non-learnable forward\nprocesses, this equivalence does not hold for diffusion bridges or when\ndiffusion coefficients are learned. Based on this insight we argue that for\ndiffusion bridges the LV loss does not represent an optimization objective that\ncan be motivated like the rKL loss via the data processing inequality. Our\nanalysis shows that employing the rKL loss with the log-derivative trick\n(rKL-LD) does not only avoid these conceptual problems but also consistently\noutperforms the LV loss. Experimental results with different types of diffusion\nbridges on challenging benchmarks show that samplers trained with the rKL-LD\nloss achieve better performance. From a practical perspective we find that\nrKL-LD requires significantly less hyperparameter optimization and yields more\nstable training behavior.",
      "pdf_url": "http://arxiv.org/pdf/2506.10982v1",
      "published": "2025-06-12T17:59:58+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.10982v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ]
    },
    {
      "title": "Fine-Grained Perturbation Guidance via Attention Head Selection",
      "authors": [
        "Donghoon Ahn",
        "Jiwon Kang",
        "Sanghyun Lee",
        "Minjae Kim",
        "Jaewon Min",
        "Wooseok Jang",
        "Saungwu Lee",
        "Sayak Paul",
        "Susung Hong",
        "Seungryong Kim"
      ],
      "abstract": "Recent guidance methods in diffusion models steer reverse sampling by\nperturbing the model to construct an implicit weak model and guide generation\naway from it. Among these approaches, attention perturbation has demonstrated\nstrong empirical performance in unconditional scenarios where classifier-free\nguidance is not applicable. However, existing attention perturbation methods\nlack principled approaches for determining where perturbations should be\napplied, particularly in Diffusion Transformer (DiT) architectures where\nquality-relevant computations are distributed across layers. In this paper, we\ninvestigate the granularity of attention perturbations, ranging from the layer\nlevel down to individual attention heads, and discover that specific heads\ngovern distinct visual concepts such as structure, style, and texture quality.\nBuilding on this insight, we propose \"HeadHunter\", a systematic framework for\niteratively selecting attention heads that align with user-centric objectives,\nenabling fine-grained control over generation quality and visual attributes. In\naddition, we introduce SoftPAG, which linearly interpolates each selected\nhead's attention map toward an identity matrix, providing a continuous knob to\ntune perturbation strength and suppress artifacts. Our approach not only\nmitigates the oversmoothing issues of existing layer-level perturbation but\nalso enables targeted manipulation of specific visual styles through\ncompositional head selection. We validate our method on modern large-scale\nDiT-based text-to-image models including Stable Diffusion 3 and FLUX.1,\ndemonstrating superior performance in both general quality enhancement and\nstyle-specific guidance. Our work provides the first head-level analysis of\nattention perturbation in diffusion models, uncovering interpretable\nspecialization within attention layers and enabling practical design of\neffective perturbation strategies.",
      "pdf_url": "http://arxiv.org/pdf/2506.10978v1",
      "published": "2025-06-12T17:59:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.10978v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "AutoMind: Adaptive Knowledgeable Agent for Automated Data Science",
      "authors": [
        "Yixin Ou",
        "Yujie Luo",
        "Jingsheng Zheng",
        "Lanning Wei",
        "Shuofei Qiao",
        "Jintian Zhang",
        "Da Zheng",
        "Huajun Chen",
        "Ningyu Zhang"
      ],
      "abstract": "Large Language Model (LLM) agents have shown great potential in addressing\nreal-world data science problems. LLM-driven data science agents promise to\nautomate the entire machine learning pipeline, yet their real-world\neffectiveness remains limited. Existing frameworks depend on rigid, pre-defined\nworkflows and inflexible coding strategies; consequently, they excel only on\nrelatively simple, classical problems and fail to capture the empirical\nexpertise that human practitioners bring to complex, innovative tasks. In this\nwork, we introduce AutoMind, an adaptive, knowledgeable LLM-agent framework\nthat overcomes these deficiencies through three key advances: (1) a curated\nexpert knowledge base that grounds the agent in domain expert knowledge, (2) an\nagentic knowledgeable tree search algorithm that strategically explores\npossible solutions, and (3) a self-adaptive coding strategy that dynamically\ntailors code generation to task complexity. Evaluations on two automated data\nscience benchmarks demonstrate that AutoMind delivers superior performance\nversus state-of-the-art baselines. Additional analyses confirm favorable\neffectiveness, efficiency, and qualitative solution quality, highlighting\nAutoMind as an efficient and robust step toward fully automated data science.",
      "pdf_url": "http://arxiv.org/pdf/2506.10974v1",
      "published": "2025-06-12T17:59:32+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.10974v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.LG",
        "cs.MA"
      ]
    },
    {
      "title": "Principled Approaches for Extending Neural Architectures to Function Spaces for Operator Learning",
      "authors": [
        "Julius Berner",
        "Miguel Liu-Schiaffini",
        "Jean Kossaifi",
        "Valentin Duruisseaux",
        "Boris Bonev",
        "Kamyar Azizzadenesheli",
        "Anima Anandkumar"
      ],
      "abstract": "A wide range of scientific problems, such as those described by\ncontinuous-time dynamical systems and partial differential equations (PDEs),\nare naturally formulated on function spaces. While function spaces are\ntypically infinite-dimensional, deep learning has predominantly advanced\nthrough applications in computer vision and natural language processing that\nfocus on mappings between finite-dimensional spaces. Such fundamental\ndisparities in the nature of the data have limited neural networks from\nachieving a comparable level of success in scientific applications as seen in\nother fields. Neural operators are a principled way to generalize neural\nnetworks to mappings between function spaces, offering a pathway to replicate\ndeep learning's transformative impact on scientific problems. For instance,\nneural operators can learn solution operators for entire classes of PDEs, e.g.,\nphysical systems with different boundary conditions, coefficient functions, and\ngeometries. A key factor in deep learning's success has been the careful\nengineering of neural architectures through extensive empirical testing.\nTranslating these neural architectures into neural operators allows operator\nlearning to enjoy these same empirical optimizations. However, prior neural\noperator architectures have often been introduced as standalone models, not\ndirectly derived as extensions of existing neural network architectures. In\nthis paper, we identify and distill the key principles for constructing\npractical implementations of mappings between infinite-dimensional function\nspaces. Using these principles, we propose a recipe for converting several\npopular neural architectures into neural operators with minimal modifications.\nThis paper aims to guide practitioners through this process and details the\nsteps to make neural operators work in practice. Our code can be found at\nhttps://github.com/neuraloperator/NNs-to-NOs",
      "pdf_url": "http://arxiv.org/pdf/2506.10973v1",
      "published": "2025-06-12T17:59:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.10973v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NA",
        "math.FA",
        "math.NA"
      ]
    },
    {
      "title": "Farseer: A Refined Scaling Law in Large Language Models",
      "authors": [
        "Houyi Li",
        "Wenzhen Zheng",
        "Qiufeng Wang",
        "Zhenyu Ding",
        "Haoying Wang",
        "Zili Wang",
        "Shijie Xuyang",
        "Ning Ding",
        "Shuigeng Zhou",
        "Xiangyu Zhang",
        "Daxin Jiang"
      ],
      "abstract": "Training Large Language Models (LLMs) is prohibitively expensive, creating a\ncritical scaling gap where insights from small-scale experiments often fail to\ntransfer to resource-intensive production systems, thereby hindering efficient\ninnovation. To bridge this, we introduce Farseer, a novel and refined scaling\nlaw offering enhanced predictive accuracy across scales. By systematically\nconstructing a model loss surface $L(N,D)$, Farseer achieves a significantly\nbetter fit to empirical data than prior laws (e.g., Chinchilla's law). Our\nmethodology yields accurate, robust, and highly generalizable predictions,\ndemonstrating excellent extrapolation capabilities, improving upon Chinchilla's\nlaw by reducing extrapolation error by 433\\%. This allows for the reliable\nevaluation of competing training strategies across all $(N,D)$ settings,\nenabling conclusions from small-scale ablation studies to be confidently\nextrapolated to predict large-scale performance. Furthermore, Farseer provides\nnew insights into optimal compute allocation, better reflecting the nuanced\ndemands of modern LLM training. To validate our approach, we trained an\nextensive suite of approximately 1,000 LLMs across diverse scales and\nconfigurations, consuming roughly 3 million NVIDIA H100 GPU hours. We are\ncomprehensively open-sourcing all models, data, results, and logs at\nhttps://github.com/Farseer-Scaling-Law/Farseer to foster further research.",
      "pdf_url": "http://arxiv.org/pdf/2506.10972v1",
      "published": "2025-06-12T17:59:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.10972v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2"
      ]
    },
    {
      "title": "Beyond Attention or Similarity: Maximizing Conditional Diversity for Token Pruning in MLLMs",
      "authors": [
        "Qizhe Zhang",
        "Mengzhen Liu",
        "Lichen Li",
        "Ming Lu",
        "Yuan Zhang",
        "Junwen Pan",
        "Qi She",
        "Shanghang Zhang"
      ],
      "abstract": "In multimodal large language models (MLLMs), the length of input visual\ntokens is often significantly greater than that of their textual counterparts,\nleading to a high inference cost. Many works aim to address this issue by\nremoving redundant visual tokens. However, current approaches either rely on\nattention-based pruning, which retains numerous duplicate tokens, or use\nsimilarity-based pruning, overlooking the instruction relevance, consequently\ncausing suboptimal performance. In this paper, we go beyond attention or\nsimilarity by proposing a novel visual token pruning method named CDPruner,\nwhich maximizes the conditional diversity of retained tokens. We first define\nthe conditional similarity between visual tokens conditioned on the\ninstruction, and then reformulate the token pruning problem with determinantal\npoint process (DPP) to maximize the conditional diversity of the selected\nsubset. The proposed CDPruner is training-free and model-agnostic, allowing\neasy application to various MLLMs. Extensive experiments across diverse MLLMs\nshow that CDPruner establishes new state-of-the-art on various vision-language\nbenchmarks. By maximizing conditional diversity through DPP, the selected\nsubset better represents the input images while closely adhering to user\ninstructions, thereby preserving strong performance even with high reduction\nratios. When applied to LLaVA, CDPruner reduces FLOPs by 95\\% and CUDA latency\nby 78\\%, while maintaining 94\\% of the original accuracy. Our code is available\nat https://github.com/Theia-4869/CDPruner.",
      "pdf_url": "http://arxiv.org/pdf/2506.10967v1",
      "published": "2025-06-12T17:59:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.10967v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "SpectralAR: Spectral Autoregressive Visual Generation",
      "authors": [
        "Yuanhui Huang",
        "Weiliang Chen",
        "Wenzhao Zheng",
        "Yueqi Duan",
        "Jie Zhou",
        "Jiwen Lu"
      ],
      "abstract": "Autoregressive visual generation has garnered increasing attention due to its\nscalability and compatibility with other modalities compared with diffusion\nmodels. Most existing methods construct visual sequences as spatial patches for\nautoregressive generation. However, image patches are inherently parallel,\ncontradicting the causal nature of autoregressive modeling. To address this, we\npropose a Spectral AutoRegressive (SpectralAR) visual generation framework,\nwhich realizes causality for visual sequences from the spectral perspective.\nSpecifically, we first transform an image into ordered spectral tokens with\nNested Spectral Tokenization, representing lower to higher frequency\ncomponents. We then perform autoregressive generation in a coarse-to-fine\nmanner with the sequences of spectral tokens. By considering different levels\nof detail in images, our SpectralAR achieves both sequence causality and token\nefficiency without bells and whistles. We conduct extensive experiments on\nImageNet-1K for image reconstruction and autoregressive generation, and\nSpectralAR achieves 3.02 gFID with only 64 tokens and 310M parameters. Project\npage: https://huang-yh.github.io/spectralar/.",
      "pdf_url": "http://arxiv.org/pdf/2506.10962v1",
      "published": "2025-06-12T17:57:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.10962v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "ChineseHarm-Bench: A Chinese Harmful Content Detection Benchmark",
      "authors": [
        "Kangwei Liu",
        "Siyuan Cheng",
        "Bozhong Tian",
        "Xiaozhuan Liang",
        "Yuyang Yin",
        "Meng Han",
        "Ningyu Zhang",
        "Bryan Hooi",
        "Xi Chen",
        "Shumin Deng"
      ],
      "abstract": "Large language models (LLMs) have been increasingly applied to automated\nharmful content detection tasks, assisting moderators in identifying policy\nviolations and improving the overall efficiency and accuracy of content review.\nHowever, existing resources for harmful content detection are predominantly\nfocused on English, with Chinese datasets remaining scarce and often limited in\nscope. We present a comprehensive, professionally annotated benchmark for\nChinese content harm detection, which covers six representative categories and\nis constructed entirely from real-world data. Our annotation process further\nyields a knowledge rule base that provides explicit expert knowledge to assist\nLLMs in Chinese harmful content detection. In addition, we propose a\nknowledge-augmented baseline that integrates both human-annotated knowledge\nrules and implicit knowledge from large language models, enabling smaller\nmodels to achieve performance comparable to state-of-the-art LLMs. Code and\ndata are available at https://github.com/zjunlp/ChineseHarm-bench.",
      "pdf_url": "http://arxiv.org/pdf/2506.10960v1",
      "published": "2025-06-12T17:57:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.10960v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR",
        "cs.IR",
        "cs.LG"
      ]
    },
    {
      "title": "Understanding In-Context Learning on Structured Manifolds: Bridging Attention to Kernel Methods",
      "authors": [
        "Zhaiming Shen",
        "Alexander Hsu",
        "Rongjie Lai",
        "Wenjing Liao"
      ],
      "abstract": "While in-context learning (ICL) has achieved remarkable success in natural\nlanguage and vision domains, its theoretical understanding--particularly in the\ncontext of structured geometric data--remains unexplored. In this work, we\ninitiate a theoretical study of ICL for regression of H\\\"older functions on\nmanifolds. By establishing a novel connection between the attention mechanism\nand classical kernel methods, we derive generalization error bounds in terms of\nthe prompt length and the number of training tasks. When a sufficient number of\ntraining tasks are observed, transformers give rise to the minimax regression\nrate of H\\\"older functions on manifolds, which scales exponentially with the\nintrinsic dimension of the manifold, rather than the ambient space dimension.\nOur result also characterizes how the generalization error scales with the\nnumber of training tasks, shedding light on the complexity of transformers as\nin-context algorithm learners. Our findings provide foundational insights into\nthe role of geometry in ICL and novels tools to study ICL of nonlinear models.",
      "pdf_url": "http://arxiv.org/pdf/2506.10959v1",
      "published": "2025-06-12T17:56:26+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.10959v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.ST",
        "stat.TH"
      ]
    },
    {
      "title": "ReGuidance: A Simple Diffusion Wrapper for Boosting Sample Quality on Hard Inverse Problems",
      "authors": [
        "Aayush Karan",
        "Kulin Shah",
        "Sitan Chen"
      ],
      "abstract": "There has been a flurry of activity around using pretrained diffusion models\nas informed data priors for solving inverse problems, and more generally around\nsteering these models using reward models. Training-free methods like diffusion\nposterior sampling (DPS) and its many variants have offered flexible heuristic\nalgorithms for these tasks, but when the reward is not informative enough,\ne.g., in hard inverse problems with low signal-to-noise ratio, these techniques\nveer off the data manifold, failing to produce realistic outputs. In this work,\nwe devise a simple wrapper, ReGuidance, for boosting both the sample realism\nand reward achieved by these methods. Given a candidate solution $\\hat{x}$\nproduced by an algorithm of the user's choice, we propose inverting the\nsolution by running the unconditional probability flow ODE in reverse starting\nfrom $\\hat{x}$, and then using the resulting latent as an initialization for\nDPS. We evaluate our wrapper on hard inverse problems like large box\nin-painting and super-resolution with high upscaling. Whereas state-of-the-art\nbaselines visibly fail, we find that applying our wrapper on top of these\nbaselines significantly boosts sample quality and measurement consistency. We\ncomplement these findings with theory proving that on certain multimodal data\ndistributions, ReGuidance simultaneously boosts the reward and brings the\ncandidate solution closer to the data manifold. To our knowledge, this\nconstitutes the first rigorous algorithmic guarantee for DPS.",
      "pdf_url": "http://arxiv.org/pdf/2506.10955v1",
      "published": "2025-06-12T17:55:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.10955v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "SWE-Factory: Your Automated Factory for Issue Resolution Training Data and Evaluation Benchmarks",
      "authors": [
        "Lianghong Guo",
        "Yanlin Wang",
        "Caihua Li",
        "Pengyu Yang",
        "Jiachi Chen",
        "Wei Tao",
        "Yingtian Zou",
        "Duyu Tang",
        "Zibin Zheng"
      ],
      "abstract": "Constructing large-scale datasets for the GitHub issue resolution task is\ncrucial for both training and evaluating the software engineering capabilities\nof Large Language Models (LLMs). However, the traditional process for creating\nsuch benchmarks is notoriously challenging and labor-intensive, particularly in\nthe stages of setting up evaluation environments, grading test outcomes, and\nvalidating task instances. In this paper, we propose SWE-Factory, an automated\npipeline designed to address these challenges. To tackle these issues, our\npipeline integrates three core automated components. First, we introduce\nSWE-Builder, a multi-agent system that automates evaluation environment\nconstruction, which employs four specialized agents that work in a\ncollaborative, iterative loop and leverages an environment memory pool to\nenhance efficiency. Second, we introduce a standardized, exit-code-based\ngrading method that eliminates the need for manually writing custom parsers.\nFinally, we automate the fail2pass validation process using these reliable exit\ncode signals. Experiments on 671 issues across four programming languages show\nthat our pipeline can effectively construct valid task instances; for example,\nwith GPT-4.1-mini, our SWE-Builder constructs 269 valid instances at $0.045 per\ninstance, while with Gemini-2.5-flash, it achieves comparable performance at\nthe lowest cost of $0.024 per instance. We also demonstrate that our\nexit-code-based grading achieves 100% accuracy compared to manual inspection,\nand our automated fail2pass validation reaches a precision of 0.92 and a recall\nof 1.00. We hope our automated pipeline will accelerate the collection of\nlarge-scale, high-quality GitHub issue resolution datasets for both training\nand evaluation. Our code and datasets are released at\nhttps://github.com/DeepSoftwareAnalytics/swe-factory.",
      "pdf_url": "http://arxiv.org/pdf/2506.10954v1",
      "published": "2025-06-12T17:54:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.10954v1",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "Domain2Vec: Vectorizing Datasets to Find the Optimal Data Mixture without Training",
      "authors": [
        "Mozhi Zhang",
        "Howe Tissue",
        "Lu Wang",
        "Xipeng Qiu"
      ],
      "abstract": "We introduce~\\textsc{Domain2Vec}, a novel approach that decomposes any\ndataset into a linear combination of several \\emph{meta-domains}, a new concept\ndesigned to capture the key underlying features of datasets.\n\\textsc{Domain2Vec} maintains a vocabulary of meta-domains and uses a\nclassifier to decompose any given dataset into a domain vector that corresponds\nto a distribution over this vocabulary. These domain vectors enable the\nidentification of the optimal data mixture for language model (LM) pretraining\nin a training-free manner under the \\emph{\\textbf{D}istribution\n\\textbf{A}lignment \\textbf{A}ssumption} (DA$^{2}$), which suggests that when\nthe data distributions of the training set and the validation set are better\naligned, a lower validation loss is achieved. Moreover, \\textsc{Domain2vec} can\nbe seamlessly integrated into previous works to model the relationship between\ndomain vectors and LM performance, greatly enhancing the efficiency and\nscalability of previous methods. Extensive experiments demonstrate that\n\\textsc{Domain2Vec} helps find the data mixture that enhances downstream task\nperformance with minimal computational overhead. Specifically,\n\\textsc{Domain2Vec} achieves the same validation loss on Pile-CC using only\n$51.5\\%$ of the computation required when training on the original mixture of\nThe Pile dataset. Under equivalent compute budget, \\textsc{Domain2Vec} improves\ndownstream performance by an average of $2.83\\%$.",
      "pdf_url": "http://arxiv.org/pdf/2506.10952v1",
      "published": "2025-06-12T17:53:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.10952v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Monitoring Decomposition Attacks in LLMs with Lightweight Sequential Monitors",
      "authors": [
        "Chen Yueh-Han",
        "Nitish Joshi",
        "Yulin Chen",
        "Maksym Andriushchenko",
        "Rico Angell",
        "He He"
      ],
      "abstract": "Current LLM safety defenses fail under decomposition attacks, where a\nmalicious goal is decomposed into benign subtasks that circumvent refusals. The\nchallenge lies in the existing shallow safety alignment techniques: they only\ndetect harm in the immediate prompt and do not reason about long-range intent,\nleaving them blind to malicious intent that emerges over a sequence of\nseemingly benign instructions. We therefore propose adding an external monitor\nthat observes the conversation at a higher granularity. To facilitate our study\nof monitoring decomposition attacks, we curate the largest and most diverse\ndataset to date, including question-answering, text-to-image, and agentic\ntasks. We verify our datasets by testing them on frontier LLMs and show an 87%\nattack success rate on average on GPT-4o. This confirms that decomposition\nattack is broadly effective. Additionally, we find that random tasks can be\ninjected into the decomposed subtasks to further obfuscate malicious intents.\nTo defend in real time, we propose a lightweight sequential monitoring\nframework that cumulatively evaluates each subtask. We show that a carefully\nprompt engineered lightweight monitor achieves a 93% defense success rate,\nbeating reasoning models like o3 mini as a monitor. Moreover, it remains robust\nagainst random task injection and cuts cost by 90% and latency by 50%. Our\nfindings suggest that lightweight sequential monitors are highly effective in\nmitigating decomposition attacks and are viable in deployment.",
      "pdf_url": "http://arxiv.org/pdf/2506.10949v1",
      "published": "2025-06-12T17:50:58+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.10949v1",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "title": "Spurious Rewards: Rethinking Training Signals in RLVR",
      "authors": [
        "Rulin Shao",
        "Shuyue Stella Li",
        "Rui Xin",
        "Scott Geng",
        "Yiping Wang",
        "Sewoong Oh",
        "Simon Shaolei Du",
        "Nathan Lambert",
        "Sewon Min",
        "Ranjay Krishna",
        "Yulia Tsvetkov",
        "Hannaneh Hajishirzi",
        "Pang Wei Koh",
        "Luke Zettlemoyer"
      ],
      "abstract": "We show that reinforcement learning with verifiable rewards (RLVR) can elicit\nstrong mathematical reasoning in certain models even with spurious rewards that\nhave little, no, or even negative correlation with the correct answer. For\nexample, RLVR improves MATH-500 performance for Qwen2.5-Math-7B in absolute\npoints by 21.4% (random reward), 13.8% (format reward), 24.1% (incorrect\nlabel), 26.0% (1-shot RL), and 27.1% (majority voting) -- nearly matching the\n29.1% gained with ground truth rewards. However, the spurious rewards that work\nfor Qwen often fail to yield gains with other model families like Llama3 or\nOLMo2. In particular, we find code reasoning -- thinking in code without actual\ncode execution -- to be a distinctive Qwen2.5-Math behavior that becomes\nsignificantly more frequent after RLVR, from 65% to over 90%, even with\nspurious rewards. Overall, we hypothesize that, given the lack of useful reward\nsignal, RLVR must somehow be surfacing useful reasoning representations learned\nduring pretraining, although the exact mechanism remains a topic for future\nwork. We suggest that future RLVR research should possibly be validated on\ndiverse models rather than a single de facto choice, as we show that it is easy\nto get significant performance gains on Qwen models even with completely\nspurious reward signals.",
      "pdf_url": "http://arxiv.org/pdf/2506.10947v1",
      "published": "2025-06-12T17:49:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.10947v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "GUARD: Guided Unlearning and Retention via Data Attribution for Large Language Models",
      "authors": [
        "Evelyn Ma",
        "Duo Zhou",
        "Peizhi Niu",
        "Huiting Zhou",
        "Huan Zhang",
        "Olgica Milenkovic",
        "S. Rasoul Etesami"
      ],
      "abstract": "Unlearning in large language models (LLMs) is becoming increasingly important\ndue to regulatory compliance, copyright protection, and privacy concerns.\nHowever, a key challenge in LLM unlearning is unintended forgetting, where the\nremoval of specific data inadvertently impairs the utility of the model and its\nretention of valuable, desired information. While prior work has primarily\nfocused on architectural innovations, the influence of data-level factors on\nunlearning performance remains underexplored. As a result, existing methods\noften suffer from degraded retention when forgetting high-impact data. To\naddress this, we propose GUARD-a novel framework for Guided Unlearning And\nRetention via Data attribution. At its core, GUARD introduces a lightweight\nproxy data attribution metric tailored for LLM unlearning, which quantifies the\n\"alignment\" between the forget and retain sets while remaining computationally\nefficient. Building on this, we design a novel unlearning objective that\nassigns adaptive, nonuniform unlearning weights to samples, inversely\nproportional to their proxy attribution scores. Through such a reallocation of\nunlearning power, GUARD mitigates unintended losses in retention. We provide\nrigorous theoretical guarantees that GUARD significantly enhances retention\nwhile maintaining forgetting metrics comparable to prior methods. Extensive\nexperiments on the TOFU benchmark across multiple LLM architectures demonstrate\nthat GUARD substantially improves utility preservation while ensuring effective\nunlearning. Notably, GUARD reduces utility sacrifice on the Retain Set by up to\n194.92% in terms of Truth Ratio when forgetting 10% of the training data.",
      "pdf_url": "http://arxiv.org/pdf/2506.10946v1",
      "published": "2025-06-12T17:49:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.10946v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "VINCIE: Unlocking In-context Image Editing from Video",
      "authors": [
        "Leigang Qu",
        "Feng Cheng",
        "Ziyan Yang",
        "Qi Zhao",
        "Shanchuan Lin",
        "Yichun Shi",
        "Yicong Li",
        "Wenjie Wang",
        "Tat-Seng Chua",
        "Lu Jiang"
      ],
      "abstract": "In-context image editing aims to modify images based on a contextual sequence\ncomprising text and previously generated images. Existing methods typically\ndepend on task-specific pipelines and expert models (e.g., segmentation and\ninpainting) to curate training data. In this work, we explore whether an\nin-context image editing model can be learned directly from videos. We\nintroduce a scalable approach to annotate videos as interleaved multimodal\nsequences. To effectively learn from this data, we design a block-causal\ndiffusion transformer trained on three proxy tasks: next-image prediction,\ncurrent segmentation prediction, and next-segmentation prediction.\nAdditionally, we propose a novel multi-turn image editing benchmark to advance\nresearch in this area. Extensive experiments demonstrate that our model\nexhibits strong in-context image editing capabilities and achieves\nstate-of-the-art results on two multi-turn image editing benchmarks. Despite\nbeing trained exclusively on videos, our model also shows promising abilities\nin multi-concept composition, story generation, and chain-of-editing\napplications.",
      "pdf_url": "http://arxiv.org/pdf/2506.10941v1",
      "published": "2025-06-12T17:46:54+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.10941v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.MM"
      ]
    },
    {
      "title": "The Role of Generative AI in Facilitating Social Interactions: A Scoping Review",
      "authors": [
        "T. T. J. E. Arets",
        "G. Perugia",
        "M. Houben",
        "W. A. IJsselsteijn"
      ],
      "abstract": "Reduced social connectedness increasingly poses a threat to mental health,\nlife expectancy, and general well-being. Generative AI (GAI) technologies, such\nas large language models (LLMs) and image generation tools, are increasingly\nintegrated into applications aimed at enhancing human social experiences.\nDespite their growing presence, little is known about how these technologies\ninfluence social interactions. This scoping review investigates how GAI-based\napplications are currently designed to facilitate social interaction, what\nforms of social engagement they target, and which design and evaluation\nmethodologies designers use to create and evaluate them. Through an analysis of\n30 studies published since 2020, we identify key trends in application domains\nincluding storytelling, socio-emotional skills training, reminiscence,\ncollaborative learning, music making, and general conversation. We highlight\nthe role of participatory and co-design approaches in fostering both effective\ntechnology use and social engagement, while also examining socio-ethical\nconcerns such as cultural bias and accessibility. This review underscores the\npotential of GAI to support dynamic and personalized interactions, but calls\nfor greater attention to equitable design practices and inclusive evaluation\nstrategies.",
      "pdf_url": "http://arxiv.org/pdf/2506.10927v1",
      "published": "2025-06-12T17:37:19+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.10927v1",
      "categories": [
        "cs.HC",
        "cs.AI"
      ]
    },
    {
      "title": "Agentic Semantic Control for Autonomous Wireless Space Networks: Extending Space-O-RAN with MCP-Driven Distributed Intelligence",
      "authors": [
        "Eduardo Baena",
        "Paolo Testolina",
        "Michele Polese",
        "Sergi Aliaga",
        "Andrew Benincasa",
        "Dimitrios Koutsonikolas",
        "Josep Jornet",
        "Tommaso Melodia"
      ],
      "abstract": "Lunar surface operations impose stringent requirements on wireless\ncommunication systems, including autonomy, robustness to disruption, and the\nability to adapt to environmental and mission-driven context. While Space-O-RAN\nprovides a distributed orchestration model aligned with 3GPP standards, its\ndecision logic is limited to static policies and lacks semantic integration. We\npropose a novel extension incorporating a semantic agentic layer enabled by the\nModel Context Protocol (MCP) and Agent-to-Agent (A2A) communication protocols,\nallowing context-aware decision making across real-time, near-real-time, and\nnon-real-time control layers. Distributed cognitive agents deployed in rovers,\nlanders, and lunar base stations implement wireless-aware coordination\nstrategies, including delay-adaptive reasoning and bandwidth-aware semantic\ncompression, while interacting with multiple MCP servers to reason over\ntelemetry, locomotion planning, and mission constraints.",
      "pdf_url": "http://arxiv.org/pdf/2506.10925v1",
      "published": "2025-06-12T17:35:36+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.10925v1",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.HC",
        "cs.SY",
        "eess.SY"
      ]
    },
    {
      "title": "Robustly Improving LLM Fairness in Realistic Settings via Interpretability",
      "authors": [
        "Adam Karvonen",
        "Samuel Marks"
      ],
      "abstract": "Large language models (LLMs) are increasingly deployed in high-stakes hiring\napplications, making decisions that directly impact people's careers and\nlivelihoods. While prior studies suggest simple anti-bias prompts can eliminate\ndemographic biases in controlled evaluations, we find these mitigations fail\nwhen realistic contextual details are introduced. We address these failures\nthrough internal bias mitigation: by identifying and neutralizing sensitive\nattribute directions within model activations, we achieve robust bias reduction\nacross all tested scenarios. Across leading commercial (GPT-4o, Claude 4\nSonnet, Gemini 2.5 Flash) and open-source models (Gemma-2 27B, Gemma-3,\nMistral-24B), we find that adding realistic context such as company names,\nculture descriptions from public careers pages, and selective hiring\nconstraints (e.g.,``only accept candidates in the top 10\\%\") induces\nsignificant racial and gender biases (up to 12\\% differences in interview\nrates). When these biases emerge, they consistently favor Black over White\ncandidates and female over male candidates across all tested models and\nscenarios. Moreover, models can infer demographics and become biased from\nsubtle cues like college affiliations, with these biases remaining invisible\neven when inspecting the model's chain-of-thought reasoning. To address these\nlimitations, our internal bias mitigation identifies race and gender-correlated\ndirections and applies affine concept editing at inference time. Despite using\ndirections from a simple synthetic dataset, the intervention generalizes\nrobustly, consistently reducing bias to very low levels (typically under 1\\%,\nalways below 2.5\\%) while largely maintaining model performance. Our findings\nsuggest that practitioners deploying LLMs for hiring should adopt more\nrealistic evaluation methodologies and consider internal mitigation strategies\nfor equitable outcomes.",
      "pdf_url": "http://arxiv.org/pdf/2506.10922v1",
      "published": "2025-06-12T17:34:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.10922v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "M4V: Multi-Modal Mamba for Text-to-Video Generation",
      "authors": [
        "Jiancheng Huang",
        "Gengwei Zhang",
        "Zequn Jie",
        "Siyu Jiao",
        "Yinlong Qian",
        "Ling Chen",
        "Yunchao Wei",
        "Lin Ma"
      ],
      "abstract": "Text-to-video generation has significantly enriched content creation and\nholds the potential to evolve into powerful world simulators. However, modeling\nthe vast spatiotemporal space remains computationally demanding, particularly\nwhen employing Transformers, which incur quadratic complexity in sequence\nprocessing and thus limit practical applications. Recent advancements in\nlinear-time sequence modeling, particularly the Mamba architecture, offer a\nmore efficient alternative. Nevertheless, its plain design limits its direct\napplicability to multi-modal and spatiotemporal video generation tasks. To\naddress these challenges, we introduce M4V, a Multi-Modal Mamba framework for\ntext-to-video generation. Specifically, we propose a multi-modal diffusion\nMamba (MM-DiM) block that enables seamless integration of multi-modal\ninformation and spatiotemporal modeling through a multi-modal token\nre-composition design. As a result, the Mamba blocks in M4V reduce FLOPs by 45%\ncompared to the attention-based alternative when generating videos at\n768$\\times$1280 resolution. Additionally, to mitigate the visual quality\ndegradation in long-context autoregressive generation processes, we introduce a\nreward learning strategy that further enhances per-frame visual realism.\nExtensive experiments on text-to-video benchmarks demonstrate M4V's ability to\nproduce high-quality videos while significantly lowering computational costs.\nCode and models will be publicly available at\nhttps://huangjch526.github.io/M4V_project.",
      "pdf_url": "http://arxiv.org/pdf/2506.10915v1",
      "published": "2025-06-12T17:29:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.10915v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Breaking Bad Molecules: Are MLLMs Ready for Structure-Level Molecular Detoxification?",
      "authors": [
        "Fei Lin",
        "Ziyang Gong",
        "Cong Wang",
        "Yonglin Tian",
        "Tengchao Zhang",
        "Xue Yang",
        "Gen Luo",
        "Fei-Yue Wang"
      ],
      "abstract": "Toxicity remains a leading cause of early-stage drug development failure.\nDespite advances in molecular design and property prediction, the task of\nmolecular toxicity repair - generating structurally valid molecular\nalternatives with reduced toxicity - has not yet been systematically defined or\nbenchmarked. To fill this gap, we introduce ToxiMol, the first benchmark task\nfor general-purpose Multimodal Large Language Models (MLLMs) focused on\nmolecular toxicity repair. We construct a standardized dataset covering 11\nprimary tasks and 560 representative toxic molecules spanning diverse\nmechanisms and granularities. We design a prompt annotation pipeline with\nmechanism-aware and task-adaptive capabilities, informed by expert\ntoxicological knowledge. In parallel, we propose an automated evaluation\nframework, ToxiEval, which integrates toxicity endpoint prediction, synthetic\naccessibility, drug-likeness, and structural similarity into a high-throughput\nevaluation chain for repair success. We systematically assess nearly 30\nmainstream general-purpose MLLMs and design multiple ablation studies to\nanalyze key factors such as evaluation criteria, candidate diversity, and\nfailure attribution. Experimental results show that although current MLLMs\nstill face significant challenges on this task, they begin to demonstrate\npromising capabilities in toxicity understanding, semantic constraint\nadherence, and structure-aware molecule editing.",
      "pdf_url": "http://arxiv.org/pdf/2506.10912v1",
      "published": "2025-06-12T17:25:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.10912v1",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "GenPlanX. Generation of Plans and Execution",
      "authors": [
        "Daniel Borrajo",
        "Giuseppe Canonaco",
        "Tomás de la Rosa",
        "Alfredo Garrachón",
        "Sriram Gopalakrishnan",
        "Simerjot Kaur",
        "Marianela Morales",
        "Sunandita Patra",
        "Alberto Pozanco",
        "Keshav Ramani",
        "Charese Smiley",
        "Pietro Totis",
        "Manuela Veloso"
      ],
      "abstract": "Classical AI Planning techniques generate sequences of actions for complex\ntasks. However, they lack the ability to understand planning tasks when\nprovided using natural language. The advent of Large Language Models (LLMs) has\nintroduced novel capabilities in human-computer interaction. In the context of\nplanning tasks, LLMs have shown to be particularly good in interpreting human\nintents among other uses. This paper introduces GenPlanX that integrates LLMs\nfor natural language-based description of planning tasks, with a classical AI\nplanning engine, alongside an execution and monitoring framework. We\ndemonstrate the efficacy of GenPlanX in assisting users with office-related\ntasks, highlighting its potential to streamline workflows and enhance\nproductivity through seamless human-AI collaboration.",
      "pdf_url": "http://arxiv.org/pdf/2506.10897v1",
      "published": "2025-06-12T17:02:27+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.10897v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "BioClinical ModernBERT: A State-of-the-Art Long-Context Encoder for Biomedical and Clinical NLP",
      "authors": [
        "Thomas Sounack",
        "Joshua Davis",
        "Brigitte Durieux",
        "Antoine Chaffin",
        "Tom J. Pollard",
        "Eric Lehman",
        "Alistair E. W. Johnson",
        "Matthew McDermott",
        "Tristan Naumann",
        "Charlotta Lindvall"
      ],
      "abstract": "Encoder-based transformer models are central to biomedical and clinical\nNatural Language Processing (NLP), as their bidirectional self-attention makes\nthem well-suited for efficiently extracting structured information from\nunstructured text through discriminative tasks. However, encoders have seen\nslower development compared to decoder models, leading to limited domain\nadaptation in biomedical and clinical settings. We introduce BioClinical\nModernBERT, a domain-adapted encoder that builds on the recent ModernBERT\nrelease, incorporating long-context processing and substantial improvements in\nspeed and performance for biomedical and clinical NLP. BioClinical ModernBERT\nis developed through continued pretraining on the largest biomedical and\nclinical corpus to date, with over 53.5 billion tokens, and addresses a key\nlimitation of prior clinical encoders by leveraging 20 datasets from diverse\ninstitutions, domains, and geographic regions, rather than relying on data from\na single source. It outperforms existing biomedical and clinical encoders on\nfour downstream tasks spanning a broad range of use cases. We release both base\n(150M parameters) and large (396M parameters) versions of BioClinical\nModernBERT, along with training checkpoints to support further research.",
      "pdf_url": "http://arxiv.org/pdf/2506.10896v1",
      "published": "2025-06-12T17:01:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.10896v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "AIR: Zero-shot Generative Model Adaptation with Iterative Refinement",
      "authors": [
        "Guimeng Liu",
        "Milad Abdollahzadeh",
        "Ngai-Man Cheung"
      ],
      "abstract": "Zero-shot generative model adaptation (ZSGM) aims to adapt a pre-trained\ngenerator to a target domain using only text guidance and without any samples\nfrom the target domain. Central to recent ZSGM approaches are directional loss\nwhich use the text guidance in the form of aligning the image offset with text\noffset in the embedding space of a vision-language model like CLIP. This is\nsimilar to the analogical reasoning in NLP where the offset between one pair of\nwords is used to identify a missing element in another pair by aligning the\noffset between these two pairs. However, a major limitation of existing ZSGM\nmethods is that the learning objective assumes the complete alignment between\nimage offset and text offset in the CLIP embedding space, resulting in quality\ndegrade in generated images. Our work makes two main contributions. Inspired by\nthe offset misalignment studies in NLP, as our first contribution, we perform\nan empirical study to analyze the misalignment between text offset and image\noffset in CLIP embedding space for various large publicly available datasets.\nOur important finding is that offset misalignment in CLIP embedding space is\ncorrelated with concept distance, i.e., close concepts have a less offset\nmisalignment. To address the limitations of the current approaches, as our\nsecond contribution, we propose Adaptation with Iterative Refinement (AIR)\nwhich is the first ZSGM approach to focus on improving target domain image\nquality based on our new insight on offset misalignment.Qualitative,\nquantitative, and user study in 26 experiment setups consistently demonstrate\nthe proposed AIR approach achieves SOTA performance. Additional experiments are\nin Supp.",
      "pdf_url": "http://arxiv.org/pdf/2506.10895v1",
      "published": "2025-06-12T17:00:50+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.10895v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "The Diffusion Duality",
      "authors": [
        "Subham Sekhar Sahoo",
        "Justin Deschenaux",
        "Aaron Gokaslan",
        "Guanghan Wang",
        "Justin Chiu",
        "Volodymyr Kuleshov"
      ],
      "abstract": "Uniform-state discrete diffusion models hold the promise of fast text\ngeneration due to their inherent ability to self-correct. However, they are\ntypically outperformed by autoregressive models and masked diffusion models. In\nthis work, we narrow this performance gap by leveraging a key insight:\nUniform-state diffusion processes naturally emerge from an underlying Gaussian\ndiffusion. Our method, Duo, transfers powerful techniques from Gaussian\ndiffusion to improve both training and sampling. First, we introduce a\ncurriculum learning strategy guided by the Gaussian process, doubling training\nspeed by reducing variance. Models trained with curriculum learning surpass\nautoregressive models in zero-shot perplexity on 3 of 7 benchmarks. Second, we\npresent Discrete Consistency Distillation, which adapts consistency\ndistillation from the continuous to the discrete setting. This algorithm\nunlocks few-step generation in diffusion language models by accelerating\nsampling by two orders of magnitude. We provide the code and model checkpoints\non the project page: http://s-sahoo.github.io/duo",
      "pdf_url": "http://arxiv.org/pdf/2506.10892v1",
      "published": "2025-06-12T16:55:35+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.10892v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Slimming Down LLMs Without Losing Their Minds",
      "authors": [
        "Qingda",
        "Mai"
      ],
      "abstract": "This paper investigates and validates the impact of fine-tuning on large\nlanguage model performance, focusing on parameter-efficient methods (LoRA and\nQLoRA). We evaluate model capabilities across three key domains: (1)\ncommonsense reasoning (HellaSwag), (2) mathematical reasoning (GSM8K), and (3)\nmulti-domain knowledge (MMLU-CS).\n  Our findings demonstrate that: (1) LoRA-based methods effectively improve\ntask-specific performance while maintaining computational efficiency, and (2)\nperformance strongly depends on alignment between fine-tuning dataset and\nbenchmark tasks. The study provides both theoretical insights into\nparameter-efficient mechanisms and practical guidance for developers\nimplementing efficient LLM adaptation with limited resources.",
      "pdf_url": "http://arxiv.org/pdf/2506.10885v1",
      "published": "2025-06-12T16:49:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.10885v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Data-Driven Prediction of Dynamic Interactions Between Robot Appendage and Granular Material",
      "authors": [
        "Guanjin Wang",
        "Xiangxue Zhao",
        "Shapour Azarm",
        "Balakumar Balachandran"
      ],
      "abstract": "An alternative data-driven modeling approach has been proposed and employed\nto gain fundamental insights into robot motion interaction with granular\nterrain at certain length scales. The approach is based on an integration of\ndimension reduction (Sequentially Truncated Higher-Order Singular Value\nDecomposition), surrogate modeling (Gaussian Process), and data assimilation\ntechniques (Reduced Order Particle Filter). This approach can be used online\nand is based on offline data, obtained from the offline collection of\nhigh-fidelity simulation data and a set of sparse experimental data. The\nresults have shown that orders of magnitude reduction in computational time can\nbe obtained from the proposed data-driven modeling approach compared with\nphysics-based high-fidelity simulations. With only simulation data as input,\nthe data-driven prediction technique can generate predictions that have\ncomparable accuracy as simulations. With both simulation data and sparse\nphysical experimental measurement as input, the data-driven approach with its\nembedded data assimilation techniques has the potential in outperforming only\nhigh-fidelity simulations for the long-horizon predictions. In addition, it is\ndemonstrated that the data-driven modeling approach can also reproduce the\nscaling relationship recovered by physics-based simulations for maximum\nresistive forces, which may indicate its general predictability beyond a\ncase-by-case basis. The results are expected to help robot navigation and\nexploration in unknown and complex terrains during both online and offline\nphases.",
      "pdf_url": "http://arxiv.org/pdf/2506.10875v1",
      "published": "2025-06-12T16:43:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.10875v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "cs.NA",
        "math.NA"
      ]
    },
    {
      "title": "A multi-scale loss formulation for learning a probabilistic model with proper score optimisation",
      "authors": [
        "Simon Lang",
        "Martin Leutbecher",
        "Pedro Maciel"
      ],
      "abstract": "We assess the impact of a multi-scale loss formulation for training\nprobabilistic machine-learned weather forecasting models. The multi-scale loss\nis tested in AIFS-CRPS, a machine-learned weather forecasting model developed\nat the European Centre for Medium-Range Weather Forecasts (ECMWF). AIFS-CRPS is\ntrained by directly optimising the almost fair continuous ranked probability\nscore (afCRPS). The multi-scale loss better constrains small scale variability\nwithout negatively impacting forecast skill. This opens up promising directions\nfor future work in scale-aware model training.",
      "pdf_url": "http://arxiv.org/pdf/2506.10868v1",
      "published": "2025-06-12T16:30:18+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.10868v1",
      "categories": [
        "physics.ao-ph",
        "cs.AI"
      ]
    },
    {
      "title": "Precise Zero-Shot Pointwise Ranking with LLMs through Post-Aggregated Global Context Information",
      "authors": [
        "Kehan Long",
        "Shasha Li",
        "Chen Xu",
        "Jintao Tang",
        "Ting Wang"
      ],
      "abstract": "Recent advancements have successfully harnessed the power of Large Language\nModels (LLMs) for zero-shot document ranking, exploring a variety of prompting\nstrategies. Comparative approaches like pairwise and listwise achieve high\neffectiveness but are computationally intensive and thus less practical for\nlarger-scale applications. Scoring-based pointwise approaches exhibit superior\nefficiency by independently and simultaneously generating the relevance scores\nfor each candidate document. However, this independence ignores critical\ncomparative insights between documents, resulting in inconsistent scoring and\nsuboptimal performance. In this paper, we aim to improve the effectiveness of\npointwise methods while preserving their efficiency through two key\ninnovations: (1) We propose a novel Global-Consistent Comparative Pointwise\nRanking (GCCP) strategy that incorporates global reference comparisons between\neach candidate and an anchor document to generate contrastive relevance scores.\nWe strategically design the anchor document as a query-focused summary of\npseudo-relevant candidates, which serves as an effective reference point by\ncapturing the global context for document comparison. (2) These contrastive\nrelevance scores can be efficiently Post-Aggregated with existing pointwise\nmethods, seamlessly integrating essential Global Context information in a\ntraining-free manner (PAGC). Extensive experiments on the TREC DL and BEIR\nbenchmark demonstrate that our approach significantly outperforms previous\npointwise methods while maintaining comparable efficiency. Our method also\nachieves competitive performance against comparative methods that require\nsubstantially more computational resources. More analyses further validate the\nefficacy of our anchor construction strategy.",
      "pdf_url": "http://arxiv.org/pdf/2506.10859v1",
      "published": "2025-06-12T16:20:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.10859v1",
      "categories": [
        "cs.IR",
        "cs.AI"
      ]
    },
    {
      "title": "VRBench: A Benchmark for Multi-Step Reasoning in Long Narrative Videos",
      "authors": [
        "Jiashuo Yu",
        "Yue Wu",
        "Meng Chu",
        "Zhifei Ren",
        "Zizheng Huang",
        "Pei Chu",
        "Ruijie Zhang",
        "Yinan He",
        "Qirui Li",
        "Songze Li",
        "Zhenxiang Li",
        "Zhongying Tu",
        "Conghui He",
        "Yu Qiao",
        "Yali Wang",
        "Yi Wang",
        "Limin Wang"
      ],
      "abstract": "We present VRBench, the first long narrative video benchmark crafted for\nevaluating large models' multi-step reasoning capabilities, addressing\nlimitations in existing evaluations that overlook temporal reasoning and\nprocedural validity. It comprises 1,010 long videos (with an average duration\nof 1.6 hours), along with 9,468 human-labeled multi-step question-answering\npairs and 30,292 reasoning steps with timestamps. These videos are curated via\na multi-stage filtering process including expert inter-rater reviewing to\nprioritize plot coherence. We develop a human-AI collaborative framework that\ngenerates coherent reasoning chains, each requiring multiple temporally\ngrounded steps, spanning seven types (e.g., event attribution, implicit\ninference). VRBench designs a multi-phase evaluation pipeline that assesses\nmodels at both the outcome and process levels. Apart from the MCQs for the\nfinal results, we propose a progress-level LLM-guided scoring metric to\nevaluate the quality of the reasoning chain from multiple dimensions\ncomprehensively. Through extensive evaluations of 12 LLMs and 16 VLMs on\nVRBench, we undertake a thorough analysis and provide valuable insights that\nadvance the field of multi-step reasoning.",
      "pdf_url": "http://arxiv.org/pdf/2506.10857v1",
      "published": "2025-06-12T16:17:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.10857v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ]
    },
    {
      "title": "A Study on Individual Spatiotemporal Activity Generation Method Using MCP-Enhanced Chain-of-Thought Large Language Models",
      "authors": [
        "Yu Zhang",
        "Yang Hu",
        "De Wang"
      ],
      "abstract": "Human spatiotemporal behavior simulation is critical for urban planning\nresearch, yet traditional rule-based and statistical approaches suffer from\nhigh computational costs, limited generalizability, and poor scalability. While\nlarge language models (LLMs) show promise as \"world simulators,\" they face\nchallenges in spatiotemporal reasoning including limited spatial cognition,\nlack of physical constraint understanding, and group homogenization tendencies.\nThis paper introduces a framework integrating chain-of-thought (CoT) reasoning\nwith Model Context Protocol (MCP) to enhance LLMs' capability in simulating\nspatiotemporal behaviors that correspond with validation data patterns. The\nmethodology combines human-like progressive reasoning through a five-stage\ncognitive framework with comprehensive data processing via six specialized MCP\ntool categories: temporal management, spatial navigation, environmental\nperception, personal memory, social collaboration, and experience evaluation.\nExperiments in Shanghai's Lujiazui district validate the framework's\neffectiveness across 1,000 generated samples. Results demonstrate high\nsimilarity with real mobile signaling data, achieving generation quality scores\nof 7.86 to 8.36 across different base models. Parallel processing experiments\nshow efficiency improvements, with generation times decreasing from 1.30 to\n0.17 minutes per sample when scaling from 2 to 12 processes. This work\ncontributes to integrating CoT reasoning with MCP for urban behavior modeling,\nadvancing LLMs applications in urban computing and providing a practical\napproach for synthetic mobility data generation. The framework offers a\nfoundation for smart city planning, transportation forecasting, and\nparticipatory urban design applications.",
      "pdf_url": "http://arxiv.org/pdf/2506.10853v1",
      "published": "2025-06-12T16:14:32+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.10853v1",
      "categories": [
        "cs.AI",
        "cs.CY"
      ]
    },
    {
      "title": "Accelerating Diffusion Large Language Models with SlowFast: The Three Golden Principles",
      "authors": [
        "Qingyan Wei",
        "Yaojie Zhang",
        "Zhiyuan Liu",
        "Dongrui Liu",
        "Linfeng Zhang"
      ],
      "abstract": "Diffusion-based language models (dLLMs) have emerged as a promising\nalternative to traditional autoregressive LLMs by enabling parallel token\ngeneration and significantly reducing inference latency. However, existing\nsampling strategies for dLLMs, such as confidence-based or semi-autoregressive\ndecoding, often suffer from static behavior, leading to suboptimal efficiency\nand limited flexibility. In this paper, we propose SlowFast Sampling, a novel\ndynamic sampling strategy that adaptively alternates between exploratory and\naccelerated decoding stages. Our method is guided by three golden principles:\ncertainty principle, convergence principle, and positional principle, which\ngovern when and where tokens can be confidently and efficiently decoded. We\nfurther integrate our strategy with dLLM-Cache to reduce redundant computation.\nExtensive experiments across benchmarks and models show that SlowFast Sampling\nachieves up to 15.63$\\times$ speedup on LLaDA with minimal accuracy drop, and\nup to 34.22$\\times$ when combined with caching. Notably, our approach\noutperforms strong autoregressive baselines like LLaMA3 8B in throughput,\ndemonstrating that well-designed sampling can unlock the full potential of\ndLLMs for fast and high-quality generation.",
      "pdf_url": "http://arxiv.org/pdf/2506.10848v1",
      "published": "2025-06-12T16:08:28+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.10848v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Post-Training Quantization for Video Matting",
      "authors": [
        "Tianrui Zhu",
        "Houyuan Chen",
        "Ruihao Gong",
        "Michele Magno",
        "Haotong Qin",
        "Kai Zhang"
      ],
      "abstract": "Video matting is crucial for applications such as film production and virtual\nreality, yet deploying its computationally intensive models on\nresource-constrained devices presents challenges. Quantization is a key\ntechnique for model compression and acceleration. As an efficient approach,\nPost-Training Quantization (PTQ) is still in its nascent stages for video\nmatting, facing significant hurdles in maintaining accuracy and temporal\ncoherence. To address these challenges, this paper proposes a novel and general\nPTQ framework specifically designed for video matting models, marking, to the\nbest of our knowledge, the first systematic attempt in this domain. Our\ncontributions include: (1) A two-stage PTQ strategy that combines\nblock-reconstruction-based optimization for fast, stable initial quantization\nand local dependency capture, followed by a global calibration of quantization\nparameters to minimize accuracy loss. (2) A Statistically-Driven Global Affine\nCalibration (GAC) method that enables the network to compensate for cumulative\nstatistical distortions arising from factors such as neglected BN layer\neffects, even reducing the error of existing PTQ methods on video matting tasks\nup to 20%. (3) An Optical Flow Assistance (OFA) component that leverages\ntemporal and semantic priors from frames to guide the PTQ process, enhancing\nthe model's ability to distinguish moving foregrounds in complex scenes and\nultimately achieving near full-precision performance even under ultra-low-bit\nquantization. Comprehensive quantitative and visual results show that our\nPTQ4VM achieves the state-of-the-art accuracy performance across different\nbit-widths compared to the existing quantization methods. We highlight that the\n4-bit PTQ4VM even achieves performance close to the full-precision counterpart\nwhile enjoying 8x FLOP savings.",
      "pdf_url": "http://arxiv.org/pdf/2506.10840v1",
      "published": "2025-06-12T15:57:14+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.10840v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Efficiency Robustness of Dynamic Deep Learning Systems",
      "authors": [
        "Ravishka Rathnasuriya",
        "Tingxi Li",
        "Zexin Xu",
        "Zihe Song",
        "Mirazul Haque",
        "Simin Chen",
        "Wei Yang"
      ],
      "abstract": "Deep Learning Systems (DLSs) are increasingly deployed in real-time\napplications, including those in resourceconstrained environments such as\nmobile and IoT devices. To address efficiency challenges, Dynamic Deep Learning\nSystems (DDLSs) adapt inference computation based on input complexity, reducing\noverhead. While this dynamic behavior improves efficiency, such behavior\nintroduces new attack surfaces. In particular, efficiency adversarial attacks\nexploit these dynamic mechanisms to degrade system performance. This paper\nsystematically explores efficiency robustness of DDLSs, presenting the first\ncomprehensive taxonomy of efficiency attacks. We categorize these attacks based\non three dynamic behaviors: (i) attacks on dynamic computations per inference,\n(ii) attacks on dynamic inference iterations, and (iii) attacks on dynamic\noutput production for downstream tasks. Through an in-depth evaluation, we\nanalyze adversarial strategies that target DDLSs efficiency and identify key\nchallenges in securing these systems. In addition, we investigate existing\ndefense mechanisms, demonstrating their limitations against increasingly\npopular efficiency attacks and the necessity for novel mitigation strategies to\nsecure future adaptive DDLSs.",
      "pdf_url": "http://arxiv.org/pdf/2506.10831v1",
      "published": "2025-06-12T15:49:01+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.10831v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "LLM-Driven Personalized Answer Generation and Evaluation",
      "authors": [
        "Mohammadreza Molavi",
        "Mohammadreza Tavakoli",
        "Mohammad Moein",
        "Abdolali Faraji",
        "Gábor Kismihók"
      ],
      "abstract": "Online learning has experienced rapid growth due to its flexibility and\naccessibility. Personalization, adapted to the needs of individual learners, is\ncrucial for enhancing the learning experience, particularly in online settings.\nA key aspect of personalization is providing learners with answers customized\nto their specific questions. This paper therefore explores the potential of\nLarge Language Models (LLMs) to generate personalized answers to learners'\nquestions, thereby enhancing engagement and reducing the workload on educators.\nTo evaluate the effectiveness of LLMs in this context, we conducted a\ncomprehensive study using the StackExchange platform in two distinct areas:\nlanguage learning and programming. We developed a framework and a dataset for\nvalidating automatically generated personalized answers. Subsequently, we\ngenerated personalized answers using different strategies, including 0-shot,\n1-shot, and few-shot scenarios. The generated answers were evaluated using\nthree methods: 1. BERTScore, 2. LLM evaluation, and 3. human evaluation. Our\nfindings indicated that providing LLMs with examples of desired answers (from\nthe learner or similar learners) can significantly enhance the LLMs' ability to\ntailor responses to individual learners' needs.",
      "pdf_url": "http://arxiv.org/pdf/2506.10829v1",
      "published": "2025-06-12T15:46:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.10829v1",
      "categories": [
        "cs.CY",
        "cs.AI"
      ]
    },
    {
      "title": "Generalist Models in Medical Image Segmentation: A Survey and Performance Comparison with Task-Specific Approaches",
      "authors": [
        "Andrea Moglia",
        "Matteo Leccardi",
        "Matteo Cavicchioli",
        "Alice Maccarini",
        "Marco Marcon",
        "Luca Mainardi",
        "Pietro Cerveri"
      ],
      "abstract": "Following the successful paradigm shift of large language models, leveraging\npre-training on a massive corpus of data and fine-tuning on different\ndownstream tasks, generalist models have made their foray into computer vision.\nThe introduction of Segment Anything Model (SAM) set a milestone on\nsegmentation of natural images, inspiring the design of a multitude of\narchitectures for medical image segmentation. In this survey we offer a\ncomprehensive and in-depth investigation on generalist models for medical image\nsegmentation. We start with an introduction on the fundamentals concepts\nunderpinning their development. Then, we provide a taxonomy on the different\ndeclinations of SAM in terms of zero-shot, few-shot, fine-tuning, adapters, on\nthe recent SAM 2, on other innovative models trained on images alone, and\nothers trained on both text and images. We thoroughly analyze their\nperformances at the level of both primary research and best-in-literature,\nfollowed by a rigorous comparison with the state-of-the-art task-specific\nmodels. We emphasize the need to address challenges in terms of compliance with\nregulatory frameworks, privacy and security laws, budget, and trustworthy\nartificial intelligence (AI). Finally, we share our perspective on future\ndirections concerning synthetic data, early fusion, lessons learnt from\ngeneralist models in natural language processing, agentic AI and physical AI,\nand clinical translation.",
      "pdf_url": "http://arxiv.org/pdf/2506.10825v1",
      "published": "2025-06-12T15:44:49+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.10825v1",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "A.1; I.2.0; I.4.6"
      ]
    },
    {
      "title": "VideoDeepResearch: Long Video Understanding With Agentic Tool Using",
      "authors": [
        "Huaying Yuan",
        "Zheng Liu",
        "Junjie Zhou",
        "Ji-Rong Wen",
        "Zhicheng Dou"
      ],
      "abstract": "Long video understanding (LVU) presents a significant challenge for current\nmulti-modal large language models (MLLMs) due to the task's inherent complexity\nand context window constraint. It is widely assumed that addressing LVU tasks\nrequires foundation MLLMs with extended context windows, strong visual\nperception capabilities, and proficient domain expertise. In this work, we\nchallenge this common belief by introducing VideoDeepResearch, a novel agentic\nframework for long video understanding. Our approach relies solely on a\ntext-only large reasoning model (LRM) combined with a modular multi-modal\ntoolkit, including multimodal retrievers and visual perceivers, all of which\nare readily available in practice. For each LVU task, the system formulates a\nproblem-solving strategy through reasoning, while selectively accessing and\nutilizing essential video content via tool using. We conduct extensive\nexperiments on popular LVU benchmarks, including MLVU, Video-MME, and LVBench.\nOur results demonstrate that VideoDeepResearch achieves substantial\nimprovements over existing MLLM baselines, surpassing the previous\nstate-of-the-art by 9.6%, 6.6%, and 3.9% on MLVU (test), LVBench, and\nLongVideoBench, respectively. These findings highlight the promise of agentic\nsystems in overcoming key challenges in LVU problems.",
      "pdf_url": "http://arxiv.org/pdf/2506.10821v1",
      "published": "2025-06-12T15:39:10+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.10821v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "What Users Value and Critique: Large-Scale Analysis of User Feedback on AI-Powered Mobile Apps",
      "authors": [
        "Vinaik Chhetri",
        "Krishna Upadhyay",
        "A. B. Siddique",
        "Umar Farooq"
      ],
      "abstract": "Artificial Intelligence (AI)-powered features have rapidly proliferated\nacross mobile apps in various domains, including productivity, education,\nentertainment, and creativity. However, how users perceive, evaluate, and\ncritique these AI features remains largely unexplored, primarily due to the\noverwhelming volume of user feedback. In this work, we present the first\ncomprehensive, large-scale study of user feedback on AI-powered mobile apps,\nleveraging a curated dataset of 292 AI-driven apps across 14 categories with\n894K AI-specific reviews from Google Play. We develop and validate a\nmulti-stage analysis pipeline that begins with a human-labeled benchmark and\nsystematically evaluates large language models (LLMs) and prompting strategies.\nEach stage, including review classification, aspect-sentiment extraction, and\nclustering, is validated for accuracy and consistency. Our pipeline enables\nscalable, high-precision analysis of user feedback, extracting over one million\naspect-sentiment pairs clustered into 18 positive and 15 negative user topics.\nOur analysis reveals that users consistently focus on a narrow set of themes:\npositive comments emphasize productivity, reliability, and personalized\nassistance, while negative feedback highlights technical failures (e.g.,\nscanning and recognition), pricing concerns, and limitations in language\nsupport. Our pipeline surfaces both satisfaction with one feature and\nfrustration with another within the same review. These fine-grained,\nco-occurring sentiments are often missed by traditional approaches that treat\npositive and negative feedback in isolation or rely on coarse-grained analysis.\nTo this end, our approach provides a more faithful reflection of the real-world\nuser experiences with AI-powered apps. Category-aware analysis further uncovers\nboth universal drivers of satisfaction and domain-specific frustrations.",
      "pdf_url": "http://arxiv.org/pdf/2506.10785v1",
      "published": "2025-06-12T14:56:52+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.10785v1",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "Improving Named Entity Transcription with Contextual LLM-based Revision",
      "authors": [
        "Viet Anh Trinh",
        "Xinlu He",
        "Jacob Whitehill"
      ],
      "abstract": "With recent advances in modeling and the increasing amount of supervised\ntraining data, automatic speech recognition (ASR) systems have achieved\nremarkable performance on general speech. However, the word error rate (WER) of\nstate-of-the-art ASR remains high for named entities. Since named entities are\noften the most critical keywords, misrecognizing them can affect all downstream\napplications, especially when the ASR system functions as the front end of a\ncomplex system. In this paper, we introduce a large language model (LLM)\nrevision mechanism to revise incorrect named entities in ASR predictions by\nleveraging the LLM's reasoning ability as well as local context (e.g., lecture\nnotes) containing a set of correct named entities. Finally, we introduce the\nNER-MIT-OpenCourseWare dataset, containing 45 hours of data from MIT courses\nfor development and testing. On this dataset, our proposed technique achieves\nup to 30\\% relative WER reduction for named entities.",
      "pdf_url": "http://arxiv.org/pdf/2506.10779v1",
      "published": "2025-06-12T14:53:48+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.10779v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "SlotPi: Physics-informed Object-centric Reasoning Models",
      "authors": [
        "Jian Li",
        "Wan Han",
        "Ning Lin",
        "Yu-Liang Zhan",
        "Ruizhi Chengze",
        "Haining Wang",
        "Yi Zhang",
        "Hongsheng Liu",
        "Zidong Wang",
        "Fan Yu",
        "Hao Sun"
      ],
      "abstract": "Understanding and reasoning about dynamics governed by physical laws through\nvisual observation, akin to human capabilities in the real world, poses\nsignificant challenges. Currently, object-centric dynamic simulation methods,\nwhich emulate human behavior, have achieved notable progress but overlook two\ncritical aspects: 1) the integration of physical knowledge into models. Humans\ngain physical insights by observing the world and apply this knowledge to\naccurately reason about various dynamic scenarios; 2) the validation of model\nadaptability across diverse scenarios. Real-world dynamics, especially those\ninvolving fluids and objects, demand models that not only capture object\ninteractions but also simulate fluid flow characteristics. To address these\ngaps, we introduce SlotPi, a slot-based physics-informed object-centric\nreasoning model. SlotPi integrates a physical module based on Hamiltonian\nprinciples with a spatio-temporal prediction module for dynamic forecasting.\nOur experiments highlight the model's strengths in tasks such as prediction and\nVisual Question Answering (VQA) on benchmark and fluid datasets. Furthermore,\nwe have created a real-world dataset encompassing object interactions, fluid\ndynamics, and fluid-object interactions, on which we validated our model's\ncapabilities. The model's robust performance across all datasets underscores\nits strong adaptability, laying a foundation for developing more advanced world\nmodels.",
      "pdf_url": "http://arxiv.org/pdf/2506.10778v1",
      "published": "2025-06-12T14:53:36+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.10778v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "ME: Trigger Element Combination Backdoor Attack on Copyright Infringement",
      "authors": [
        "Feiyu Yang",
        "Siyuan Liang",
        "Aishan Liu",
        "Dacheng Tao"
      ],
      "abstract": "The capability of generative diffusion models (DMs) like Stable Diffusion\n(SD) in replicating training data could be taken advantage of by attackers to\nlaunch the Copyright Infringement Attack, with duplicated poisoned image-text\npairs. SilentBadDiffusion (SBD) is a method proposed recently, which shew\noutstanding performance in attacking SD in text-to-image tasks. However, the\nfeasible data resources in this area are still limited, some of them are even\nconstrained or prohibited due to the issues like copyright ownership or\ninappropriate contents; And not all of the images in current datasets are\nsuitable for the proposed attacking methods; Besides, the state-of-the-art\n(SoTA) performance of SBD is far from ideal when few generated poisoning\nsamples could be adopted for attacks. In this paper, we raised new datasets\naccessible for researching in attacks like SBD, and proposed Multi-Element (ME)\nattack method based on SBD by increasing the number of poisonous visual-text\nelements per poisoned sample to enhance the ability of attacking, while\nimporting Discrete Cosine Transform (DCT) for the poisoned samples to maintain\nthe stealthiness. The Copyright Infringement Rate (CIR) / First Attack Epoch\n(FAE) we got on the two new datasets were 16.78% / 39.50 and 51.20% / 23.60,\nrespectively close to or even outperformed benchmark Pokemon and Mijourney\ndatasets. In condition of low subsampling ratio (5%, 6 poisoned samples), MESI\nand DCT earned CIR / FAE of 0.23% / 84.00 and 12.73% / 65.50, both better than\noriginal SBD, which failed to attack at all.",
      "pdf_url": "http://arxiv.org/pdf/2506.10776v1",
      "published": "2025-06-12T14:51:27+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.10776v1",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "title": "Stroke-based Cyclic Amplifier: Image Super-Resolution at Arbitrary Ultra-Large Scales",
      "authors": [
        "Wenhao Guo",
        "Peng Lu",
        "Xujun Peng",
        "Zhaoran Zhao",
        "Sheng Li"
      ],
      "abstract": "Prior Arbitrary-Scale Image Super-Resolution (ASISR) methods often experience\na significant performance decline when the upsampling factor exceeds the range\ncovered by the training data, introducing substantial blurring. To address this\nissue, we propose a unified model, Stroke-based Cyclic Amplifier (SbCA), for\nultra-large upsampling tasks. The key of SbCA is the stroke vector amplifier,\nwhich decomposes the image into a series of strokes represented as vector\ngraphics for magnification. Then, the detail completion module also restores\nmissing details, ensuring high-fidelity image reconstruction. Our cyclic\nstrategy achieves ultra-large upsampling by iteratively refining details with\nthis unified SbCA model, trained only once for all, while keeping sub-scales\nwithin the training range. Our approach effectively addresses the distribution\ndrift issue and eliminates artifacts, noise and blurring, producing\nhigh-quality, high-resolution super-resolved images. Experimental validations\non both synthetic and real-world datasets demonstrate that our approach\nsignificantly outperforms existing methods in ultra-large upsampling tasks\n(e.g. $\\times100$), delivering visual quality far superior to state-of-the-art\ntechniques.",
      "pdf_url": "http://arxiv.org/pdf/2506.10774v1",
      "published": "2025-06-12T14:51:10+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.10774v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Learning Chaotic Dynamics with Neuromorphic Network Dynamics",
      "authors": [
        "Yinhao Xu",
        "Georg A. Gottwald",
        "Zdenka Kuncic"
      ],
      "abstract": "This study investigates how dynamical systems may be learned and modelled\nwith a neuromorphic network which is itself a dynamical system. The\nneuromorphic network used in this study is based on a complex electrical\ncircuit comprised of memristive elements that produce neuro-synaptic nonlinear\nresponses to input electrical signals. To determine how computation may be\nperformed using the physics of the underlying system, the neuromorphic network\nwas simulated and evaluated on autonomous prediction of a multivariate chaotic\ntime series, implemented with a reservoir computing framework. Through\nmanipulating only input electrodes and voltages, optimal nonlinear dynamical\nresponses were found when input voltages maximise the number of memristive\ncomponents whose internal dynamics explore the entire dynamical range of the\nmemristor model. Increasing the network coverage with the input electrodes was\nfound to suppress other nonlinear responses that are less conducive to\nlearning. These results provide valuable insights into how a practical\nneuromorphic network device can be optimised for learning complex dynamical\nsystems using only external control parameters.",
      "pdf_url": "http://arxiv.org/pdf/2506.10773v1",
      "published": "2025-06-12T14:50:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.10773v1",
      "categories": [
        "cond-mat.dis-nn",
        "cs.AI",
        "cs.ET"
      ]
    },
    {
      "title": "OPT-BENCH: Evaluating LLM Agent on Large-Scale Search Spaces Optimization Problems",
      "authors": [
        "Xiaozhe Li",
        "Jixuan Chen",
        "Xinyu Fang",
        "Shengyuan Ding",
        "Haodong Duan",
        "Qingwen Liu",
        "Kai Chen"
      ],
      "abstract": "Large Language Models (LLMs) have shown remarkable capabilities in solving\ndiverse tasks. However, their proficiency in iteratively optimizing complex\nsolutions through learning from previous feedback remains insufficiently\nexplored. To bridge this gap, we present OPT-BENCH, a comprehensive benchmark\ndesigned to evaluate LLM agents on large-scale search space optimization\nproblems. OPT-BENCH includes 20 real-world machine learning tasks sourced from\nKaggle and 10 classical NP problems, offering a diverse and challenging\nenvironment for assessing LLM agents on iterative reasoning and solution\nrefinement. To enable rigorous evaluation, we introduce OPT-Agent, an\nend-to-end optimization framework that emulates human reasoning when tackling\ncomplex problems by generating, validating, and iteratively improving solutions\nthrough leveraging historical feedback. Through extensive experiments on 9\nstate-of-the-art LLMs from 6 model families, we analyze the effects of\noptimization iterations, temperature settings, and model architectures on\nsolution quality and convergence. Our results demonstrate that incorporating\nhistorical context significantly enhances optimization performance across both\nML and NP tasks. All datasets, code, and evaluation tools are open-sourced to\npromote further research in advancing LLM-driven optimization and iterative\nreasoning. Project page:\n\\href{https://github.com/OliverLeeXZ/OPT-BENCH}{https://github.com/OliverLeeXZ/OPT-BENCH}.",
      "pdf_url": "http://arxiv.org/pdf/2506.10764v1",
      "published": "2025-06-12T14:46:41+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.10764v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Grounded Vision-Language Navigation for UAVs with Open-Vocabulary Goal Understanding",
      "authors": [
        "Yuhang Zhang",
        "Haosheng Yu",
        "Jiaping Xiao",
        "Mir Feroskhan"
      ],
      "abstract": "Vision-and-language navigation (VLN) is a long-standing challenge in\nautonomous robotics, aiming to empower agents with the ability to follow human\ninstructions while navigating complex environments. Two key bottlenecks remain\nin this field: generalization to out-of-distribution environments and reliance\non fixed discrete action spaces. To address these challenges, we propose\nVision-Language Fly (VLFly), a framework tailored for Unmanned Aerial Vehicles\n(UAVs) to execute language-guided flight. Without the requirement for\nlocalization or active ranging sensors, VLFly outputs continuous velocity\ncommands purely from egocentric observations captured by an onboard monocular\ncamera. The VLFly integrates three modules: an instruction encoder based on a\nlarge language model (LLM) that reformulates high-level language into\nstructured prompts, a goal retriever powered by a vision-language model (VLM)\nthat matches these prompts to goal images via vision-language similarity, and a\nwaypoint planner that generates executable trajectories for real-time UAV\ncontrol. VLFly is evaluated across diverse simulation environments without\nadditional fine-tuning and consistently outperforms all baselines. Moreover,\nreal-world VLN tasks in indoor and outdoor environments under direct and\nindirect instructions demonstrate that VLFly achieves robust open-vocabulary\ngoal understanding and generalized navigation capabilities, even in the\npresence of abstract language input.",
      "pdf_url": "http://arxiv.org/pdf/2506.10756v1",
      "published": "2025-06-12T14:40:50+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.10756v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "BNMusic: Blending Environmental Noises into Personalized Music",
      "authors": [
        "Chi Zuo",
        "Martin B. Møller",
        "Pablo Martínez-Nuevo",
        "Huayang Huang",
        "Yu Wu",
        "Ye Zhu"
      ],
      "abstract": "While being disturbed by environmental noises, the acoustic masking technique\nis a conventional way to reduce the annoyance in audio engineering that seeks\nto cover up the noises with other dominant yet less intrusive sounds. However,\nmisalignment between the dominant sound and the noise-such as mismatched\ndownbeats-often requires an excessive volume increase to achieve effective\nmasking. Motivated by recent advances in cross-modal generation, in this work,\nwe introduce an alternative method to acoustic masking, aiming to reduce the\nnoticeability of environmental noises by blending them into personalized music\ngenerated based on user-provided text prompts. Following the paradigm of music\ngeneration using mel-spectrogram representations, we propose a Blending Noises\ninto Personalized Music (BNMusic) framework with two key stages. The first\nstage synthesizes a complete piece of music in a mel-spectrogram representation\nthat encapsulates the musical essence of the noise. In the second stage, we\nadaptively amplify the generated music segment to further reduce noise\nperception and enhance the blending effectiveness, while preserving auditory\nquality. Our experiments with comprehensive evaluations on MusicBench,\nEPIC-SOUNDS, and ESC-50 demonstrate the effectiveness of our framework,\nhighlighting the ability to blend environmental noise with rhythmically\naligned, adaptively amplified, and enjoyable music segments, minimizing the\nnoticeability of the noise, thereby improving overall acoustic experiences.",
      "pdf_url": "http://arxiv.org/pdf/2506.10754v1",
      "published": "2025-06-12T14:39:08+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.10754v1",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ]
    },
    {
      "title": "Think before You Simulate: Symbolic Reasoning to Orchestrate Neural Computation for Counterfactual Question Answering",
      "authors": [
        "Adam Ishay",
        "Zhun Yang",
        "Joohyung Lee",
        "Ilgu Kang",
        "Dongjae Lim"
      ],
      "abstract": "Causal and temporal reasoning about video dynamics is a challenging problem.\nWhile neuro-symbolic models that combine symbolic reasoning with neural-based\nperception and prediction have shown promise, they exhibit limitations,\nespecially in answering counterfactual questions. This paper introduces a\nmethod to enhance a neuro-symbolic model for counterfactual reasoning,\nleveraging symbolic reasoning about causal relations among events. We define\nthe notion of a causal graph to represent such relations and use Answer Set\nProgramming (ASP), a declarative logic programming method, to find how to\ncoordinate perception and simulation modules. We validate the effectiveness of\nour approach on two benchmarks, CLEVRER and CRAFT. Our enhancement achieves\nstate-of-the-art performance on the CLEVRER challenge, significantly\noutperforming existing models. In the case of the CRAFT benchmark, we leverage\na large pre-trained language model, such as GPT-3.5 and GPT-4, as a proxy for a\ndynamics simulator. Our findings show that this method can further improve its\nperformance on counterfactual questions by providing alternative prompts\ninstructed by symbolic causal reasoning.",
      "pdf_url": "http://arxiv.org/pdf/2506.10753v1",
      "published": "2025-06-12T14:37:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.10753v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "TED-LaST: Towards Robust Backdoor Defense Against Adaptive Attacks",
      "authors": [
        "Xiaoxing Mo",
        "Yuxuan Cheng",
        "Nan Sun",
        "Leo Yu Zhang",
        "Wei Luo",
        "Shang Gao"
      ],
      "abstract": "Deep Neural Networks (DNNs) are vulnerable to backdoor attacks, where\nattackers implant hidden triggers during training to maliciously control model\nbehavior. Topological Evolution Dynamics (TED) has recently emerged as a\npowerful tool for detecting backdoor attacks in DNNs. However, TED can be\nvulnerable to backdoor attacks that adaptively distort topological\nrepresentation distributions across network layers. To address this limitation,\nwe propose TED-LaST (Topological Evolution Dynamics against Laundry, Slow\nrelease, and Target mapping attack strategies), a novel defense strategy that\nenhances TED's robustness against adaptive attacks. TED-LaST introduces two key\ninnovations: label-supervised dynamics tracking and adaptive layer emphasis.\nThese enhancements enable the identification of stealthy threats that evade\ntraditional TED-based defenses, even in cases of inseparability in topological\nspace and subtle topological perturbations. We review and classify data\npoisoning tricks in state-of-the-art adaptive attacks and propose enhanced\nadaptive attack with target mapping, which can dynamically shift malicious\ntasks and fully leverage the stealthiness that adaptive attacks possess. Our\ncomprehensive experiments on multiple datasets (CIFAR-10, GTSRB, and\nImageNet100) and model architectures (ResNet20, ResNet101) show that TED-LaST\neffectively counteracts sophisticated backdoors like Adap-Blend, Adapt-Patch,\nand the proposed enhanced adaptive attack. TED-LaST sets a new benchmark for\nrobust backdoor detection, substantially enhancing DNN security against\nevolving threats.",
      "pdf_url": "http://arxiv.org/pdf/2506.10722v1",
      "published": "2025-06-12T14:12:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.10722v1",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "title": "PREMISE: Scalable and Strategic Prompt Optimization for Efficient Mathematical Reasoning in Large Models",
      "authors": [
        "Ye Yu",
        "Yaoning Yu",
        "Haohan Wang"
      ],
      "abstract": "Large reasoning models (LRMs) such as Claude 3.7 Sonnet and OpenAI o1 achieve\nstrong performance on mathematical benchmarks using lengthy chain-of-thought\n(CoT) reasoning, but the resulting traces are often unnecessarily verbose. This\ninflates token usage and cost, limiting deployment in latency-sensitive or\nAPI-constrained settings. We introduce PREMISE (PRompt-based Efficient\nMathematical Inference with Strategic Evaluation), a prompt-only framework that\nreduces reasoning overhead without modifying model weights. PREMISE combines\ntrace-level diagnostics with gradient-inspired prompt optimization to minimize\nredundant computation while preserving answer accuracy. The approach jointly\noptimizes brevity and correctness through a multi-objective textual search that\nbalances token length and answer validity. Unlike prior work, PREMISE runs in a\nsingle-pass black-box interface, so it can be applied directly to commercial\nLLMs. On GSM8K, SVAMP, and Math500 we match or exceed baseline accuracy\n($96\\%\\rightarrow96\\%$ with Claude, $91\\%\\rightarrow92\\%$ with Gemini) while\nreducing reasoning tokens by up to $87.5\\%$ and cutting dollar cost by\n$69$--$82\\%$. These results show that prompt-level optimization is a practical\nand scalable path to efficient LRM inference without compromising reasoning\nquality.",
      "pdf_url": "http://arxiv.org/pdf/2506.10716v1",
      "published": "2025-06-12T14:05:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.10716v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Deep Learning-based Multi Project InP Wafer Simulation for Unsupervised Surface Defect Detection",
      "authors": [
        "Emílio Dolgener Cantú",
        "Rolf Klemens Wittmann",
        "Oliver Abdeen",
        "Patrick Wagner",
        "Wojciech Samek",
        "Moritz Baier",
        "Sebastian Lapuschkin"
      ],
      "abstract": "Quality management in semiconductor manufacturing often relies on template\nmatching with known golden standards. For Indium-Phosphide (InP) multi-project\nwafer manufacturing, low production scale and high design variability lead to\nsuch golden standards being typically unavailable. Defect detection, in turn,\nis manual and labor-intensive. This work addresses this challenge by proposing\na methodology to generate a synthetic golden standard using Deep Neural\nNetworks, trained to simulate photo-realistic InP wafer images from CAD data.\nWe evaluate various training objectives and assess the quality of the simulated\nimages on both synthetic data and InP wafer photographs. Our\ndeep-learning-based method outperforms a baseline decision-tree-based approach,\nenabling the use of a 'simulated golden die' from CAD plans in any user-defined\nregion of a wafer for more efficient defect detection. We apply our method to a\ntemplate matching procedure, to demonstrate its practical utility in surface\ndefect detection.",
      "pdf_url": "http://arxiv.org/pdf/2506.10713v1",
      "published": "2025-06-12T14:03:10+00:00",
      "arxiv_url": "http://arxiv.org/abs/2506.10713v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ]
    }
  ]
}