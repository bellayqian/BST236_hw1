{
  "last_updated": "2025-10-07T00:47:34.025059",
  "papers": [
    {
      "title": "Reward Models are Metrics in a Trench Coat",
      "authors": [
        "Sebastian Gehrmann"
      ],
      "abstract": "The emergence of reinforcement learning in post-training of large language\nmodels has sparked significant interest in reward models. Reward models assess\nthe quality of sampled model outputs to generate training signals. This task is\nalso performed by evaluation metrics that monitor the performance of an AI\nmodel. We find that the two research areas are mostly separate, leading to\nredundant terminology and repeated pitfalls. Common challenges include\nsusceptibility to spurious correlations, impact on downstream reward hacking,\nmethods to improve data quality, and approaches to meta-evaluation. Our\nposition paper argues that a closer collaboration between the fields can help\novercome these issues. To that end, we show how metrics outperform reward\nmodels on specific tasks and provide an extensive survey of the two areas.\nGrounded in this survey, we point to multiple research topics in which closer\nalignment can improve reward models and metrics in areas such as preference\nelicitation methods, avoidance of spurious correlations and reward hacking, and\ncalibration-aware meta-evaluation.",
      "pdf_url": "http://arxiv.org/pdf/2510.03231v1",
      "published": "2025-10-03T17:59:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.03231v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Improving GUI Grounding with Explicit Position-to-Coordinate Mapping",
      "authors": [
        "Suyuchen Wang",
        "Tianyu Zhang",
        "Ahmed Masry",
        "Christopher Pal",
        "Spandana Gella",
        "Bang Liu",
        "Perouz Taslakian"
      ],
      "abstract": "GUI grounding, the task of mapping natural-language instructions to pixel\ncoordinates, is crucial for autonomous agents, yet remains difficult for\ncurrent VLMs. The core bottleneck is reliable patch-to-pixel mapping, which\nbreaks when extrapolating to high-resolution displays unseen during training.\nCurrent approaches generate coordinates as text tokens directly from visual\nfeatures, forcing the model to infer complex position-to-pixel mappings\nimplicitly; as a result, accuracy degrades and failures proliferate on new\nresolutions. We address this with two complementary innovations. First, RULER\ntokens serve as explicit coordinate markers, letting the model reference\npositions similar to gridlines on a map and adjust rather than generate\ncoordinates from scratch. Second, Interleaved MRoPE (I-MRoPE) improves spatial\nencoding by ensuring that width and height dimensions are represented equally,\naddressing the asymmetry of standard positional schemes. Experiments on\nScreenSpot, ScreenSpot-V2, and ScreenSpot-Pro show consistent gains in\ngrounding accuracy, with the largest improvements on high-resolution\ninterfaces. By providing explicit spatial guidance rather than relying on\nimplicit learning, our approach enables more reliable GUI automation across\ndiverse resolutions and platforms.",
      "pdf_url": "http://arxiv.org/pdf/2510.03230v1",
      "published": "2025-10-03T17:59:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.03230v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Test-Time Defense Against Adversarial Attacks via Stochastic Resonance of Latent Ensembles",
      "authors": [
        "Dong Lao",
        "Yuxiang Zhang",
        "Haniyeh Ehsani Oskouie",
        "Yangchao Wu",
        "Alex Wong",
        "Stefano Soatto"
      ],
      "abstract": "We propose a test-time defense mechanism against adversarial attacks:\nimperceptible image perturbations that significantly alter the predictions of a\nmodel. Unlike existing methods that rely on feature filtering or smoothing,\nwhich can lead to information loss, we propose to \"combat noise with noise\" by\nleveraging stochastic resonance to enhance robustness while minimizing\ninformation loss. Our approach introduces small translational perturbations to\nthe input image, aligns the transformed feature embeddings, and aggregates them\nbefore mapping back to the original reference image. This can be expressed in a\nclosed-form formula, which can be deployed on diverse existing network\narchitectures without introducing additional network modules or fine-tuning for\nspecific attack types. The resulting method is entirely training-free,\narchitecture-agnostic, and attack-agnostic. Empirical results show\nstate-of-the-art robustness on image classification and, for the first time,\nestablish a generic test-time defense for dense prediction tasks, including\nstereo matching and optical flow, highlighting the method's versatility and\npracticality. Specifically, relative to clean (unperturbed) performance, our\nmethod recovers up to 68.1% of the accuracy loss on image classification, 71.9%\non stereo matching, and 29.2% on optical flow under various types of\nadversarial attacks.",
      "pdf_url": "http://arxiv.org/pdf/2510.03224v1",
      "published": "2025-10-03T17:57:25+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.03224v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Self-Anchor: Large Language Model Reasoning via Step-by-step Attention Alignment",
      "authors": [
        "Hongxiang Zhang",
        "Yuan Tian",
        "Tianyi Zhang"
      ],
      "abstract": "To solve complex reasoning tasks for Large Language Models (LLMs),\nprompting-based methods offer a lightweight alternative to fine-tuning and\nreinforcement learning. However, as reasoning chains extend, critical\nintermediate steps and the original prompt will be buried in the context,\nreceiving insufficient attention and leading to errors. In this paper, we\npropose Self-Anchor, a novel pipeline that leverages the inherent structure of\nreasoning to steer LLM attention. Self-Anchor decomposes reasoning trajectories\ninto structured plans and automatically aligns the model's attention to the\nmost relevant inference steps, allowing the model to maintain focus throughout\ngeneration. Our experiment shows that Self-Anchor outperforms SOTA prompting\nmethods across six benchmarks. Notably, Self-Anchor significantly reduces the\nperformance gap between ``non-reasoning'' models and specialized reasoning\nmodels, with the potential to enable most LLMs to tackle complex reasoning\ntasks without retraining.",
      "pdf_url": "http://arxiv.org/pdf/2510.03223v1",
      "published": "2025-10-03T17:56:33+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.03223v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Abstain and Validate: A Dual-LLM Policy for Reducing Noise in Agentic Program Repair",
      "authors": [
        "Jos√© Cambronero",
        "Michele Tufano",
        "Sherry Shi",
        "Renyao Wei",
        "Grant Uy",
        "Runxiang Cheng",
        "Chin-Jung Liu",
        "Shiying Pan",
        "Satish Chandra",
        "Pat Rondon"
      ],
      "abstract": "Agentic Automated Program Repair (APR) is increasingly tackling complex,\nrepository-level bugs in industry, but ultimately agent-generated patches still\nneed to be reviewed by a human before committing them to ensure they address\nthe bug. Showing unlikely patches to developers can lead to substantial noise,\nwasting valuable developer time and eroding trust in automated code changes. We\nintroduce two complementary LLM-based policies to reduce such noise: bug\nabstention and patch validation policies. Bug abstention excludes bugs that the\nagentic APR system is unlikely to fix. Patch validation rejects patches that\nare unlikely to be a good fix for the given bug. We evaluate both policies on\nthree sets of bugs from Google's codebase, and their candidate patches\ngenerated by an internal agentic APR system. On a set of 174 human-reported\nbugs, removing bugs and patch trajectories rejected by our policies can raise\nsuccess rates by up to 13 percentage points and 15 percentage points,\nrespectively, and by up to 39 percentage points in combination. On null pointer\nexceptions and sanitizer-reported bugs with machine-generated bug reports,\npatch validation also improves average single-sample success rates. This\ntwo-policy approach provides a practical path to the reliable, industrial-scale\ndeployment of agentic APR systems.",
      "pdf_url": "http://arxiv.org/pdf/2510.03217v1",
      "published": "2025-10-03T17:53:28+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.03217v1",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "Wave-GMS: Lightweight Multi-Scale Generative Model for Medical Image Segmentation",
      "authors": [
        "Talha Ahmed",
        "Nehal Ahmed Shaikh",
        "Hassan Mohy-ud-Din"
      ],
      "abstract": "For equitable deployment of AI tools in hospitals and healthcare facilities,\nwe need Deep Segmentation Networks that offer high performance and can be\ntrained on cost-effective GPUs with limited memory and large batch sizes. In\nthis work, we propose Wave-GMS, a lightweight and efficient multi-scale\ngenerative model for medical image segmentation. Wave-GMS has a substantially\nsmaller number of trainable parameters, does not require loading\nmemory-intensive pretrained vision foundation models, and supports training\nwith large batch sizes on GPUs with limited memory. We conducted extensive\nexperiments on four publicly available datasets (BUS, BUSI, Kvasir-Instrument,\nand HAM10000), demonstrating that Wave-GMS achieves state-of-the-art\nsegmentation performance with superior cross-domain generalizability, while\nrequiring only ~2.6M trainable parameters. Code is available at\nhttps://github.com/ATPLab-LUMS/Wave-GMS.",
      "pdf_url": "http://arxiv.org/pdf/2510.03216v1",
      "published": "2025-10-03T17:53:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.03216v1",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Coevolutionary Continuous Discrete Diffusion: Make Your Diffusion Language Model a Latent Reasoner",
      "authors": [
        "Cai Zhou",
        "Chenxiao Yang",
        "Yi Hu",
        "Chenyu Wang",
        "Chubin Zhang",
        "Muhan Zhang",
        "Lester Mackey",
        "Tommi Jaakkola",
        "Stephen Bates",
        "Dinghuai Zhang"
      ],
      "abstract": "Diffusion language models, especially masked discrete diffusion models, have\nachieved great success recently. While there are some theoretical and primary\nempirical results showing the advantages of latent reasoning with looped\ntransformers or continuous chain-of-thoughts, continuous diffusion models\ntypically underperform their discrete counterparts. In this paper, we argue\nthat diffusion language models do not necessarily need to be in the discrete\nspace. In particular, we prove that continuous diffusion models have stronger\nexpressivity than discrete diffusions and looped transformers. We attribute the\ncontradiction between the theoretical expressiveness and empirical performance\nto their practical trainability: while continuous diffusion provides\nintermediate supervision that looped transformers lack, they introduce\nadditional difficulty decoding tokens into the discrete token space from the\ncontinuous representation space. We therefore propose Coevolutionary Continuous\nDiscrete Diffusion (CCDD), which defines a joint multimodal diffusion process\non the union of a continuous representation space and a discrete token space,\nleveraging a single model to simultaneously denoise in the joint space. By\ncombining two modalities, CCDD is expressive with rich semantics in the latent\nspace, as well as good trainability and sample quality with the help of\nexplicit discrete tokens. We also propose effective architectures and advanced\ntraining/sampling techniques for CCDD, which reveals strong empirical\nperformance in extensive language modeling experiments on real-world tasks.",
      "pdf_url": "http://arxiv.org/pdf/2510.03206v1",
      "published": "2025-10-03T17:44:41+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.03206v1",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "CoDA: Agentic Systems for Collaborative Data Visualization",
      "authors": [
        "Zichen Chen",
        "Jiefeng Chen",
        "Sercan √ñ. Arik",
        "Misha Sra",
        "Tomas Pfister",
        "Jinsung Yoon"
      ],
      "abstract": "Deep research has revolutionized data analysis, yet data scientists still\ndevote substantial time to manually crafting visualizations, highlighting the\nneed for robust automation from natural language queries. However, current\nsystems struggle with complex datasets containing multiple files and iterative\nrefinement. Existing approaches, including simple single- or multi-agent\nsystems, often oversimplify the task, focusing on initial query parsing while\nfailing to robustly manage data complexity, code errors, or final visualization\nquality. In this paper, we reframe this challenge as a collaborative\nmulti-agent problem. We introduce CoDA, a multi-agent system that employs\nspecialized LLM agents for metadata analysis, task planning, code generation,\nand self-reflection. We formalize this pipeline, demonstrating how\nmetadata-focused analysis bypasses token limits and quality-driven refinement\nensures robustness. Extensive evaluations show CoDA achieves substantial gains\nin the overall score, outperforming competitive baselines by up to 41.5%. This\nwork demonstrates that the future of visualization automation lies not in\nisolated code generation but in integrated, collaborative agentic workflows.",
      "pdf_url": "http://arxiv.org/pdf/2510.03194v1",
      "published": "2025-10-03T17:30:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.03194v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Simulation to Rules: A Dual-VLM Framework for Formal Visual Planning",
      "authors": [
        "Yilun Hao",
        "Yongchao Chen",
        "Chuchu Fan",
        "Yang Zhang"
      ],
      "abstract": "Vision Language Models (VLMs) show strong potential for visual planning but\nstruggle with precise spatial and long-horizon reasoning. In contrast, Planning\nDomain Definition Language (PDDL) planners excel at long-horizon formal\nplanning, but cannot interpret visual inputs. Recent works combine these\ncomplementary advantages by enabling VLMs to turn visual planning problems into\nPDDL files for formal planning. However, while VLMs can generate PDDL problem\nfiles satisfactorily, they struggle to accurately generate the PDDL domain\nfiles, which describe all the planning rules. As a result, prior methods rely\non human experts to predefine domain files or on constant environment access\nfor refinement. We propose VLMFP, a Dual-VLM-guided framework that can\nautonomously generate both PDDL problem and domain files for formal visual\nplanning. VLMFP introduces two VLMs to ensure reliable PDDL file generation: A\nSimVLM that simulates action consequences based on input rule descriptions, and\na GenVLM that generates and iteratively refines PDDL files by comparing the\nPDDL and SimVLM execution results. VLMFP unleashes multiple levels of\ngeneralizability: The same generated PDDL domain file works for all the\ndifferent instances under the same problem, and VLMs generalize to different\nproblems with varied appearances and rules. We evaluate VLMFP with 6 grid-world\ndomains and test its generalization to unseen instances, appearance, and game\nrules. On average, SimVLM accurately describes 95.5%, 82.6% of scenarios,\nsimulates 85.5%, 87.8% of action sequence, and judges 82.4%, 85.6% goal\nreaching for seen and unseen appearances, respectively. With the guidance of\nSimVLM, VLMFP can generate PDDL files to reach 70.0%, 54.1% valid plans for\nunseen instances in seen and unseen appearances, respectively. Project page:\nhttps://sites.google.com/view/vlmfp.",
      "pdf_url": "http://arxiv.org/pdf/2510.03182v1",
      "published": "2025-10-03T16:57:01+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.03182v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CL",
        "cs.SC"
      ]
    },
    {
      "title": "Topic Modeling as Long-Form Generation: Can Long-Context LLMs revolutionize NTM via Zero-Shot Prompting?",
      "authors": [
        "Xuan Xu",
        "Haolun Li",
        "Zhongliang Yang",
        "Beilin Chu",
        "Jia Song",
        "Moxuan Xu",
        "Linna Zhou"
      ],
      "abstract": "Traditional topic models such as neural topic models rely on inference and\ngeneration networks to learn latent topic distributions. This paper explores a\nnew paradigm for topic modeling in the era of large language models, framing TM\nas a long-form generation task whose definition is updated in this paradigm. We\npropose a simple but practical approach to implement LLM-based topic model\ntasks out of the box (sample a data subset, generate topics and representative\ntext with our prompt, text assignment with keyword match). We then investigate\nwhether the long-form generation paradigm can beat NTMs via zero-shot\nprompting. We conduct a systematic comparison between NTMs and LLMs in terms of\ntopic quality and empirically examine the claim that \"a majority of NTMs are\noutdated.\"",
      "pdf_url": "http://arxiv.org/pdf/2510.03174v1",
      "published": "2025-10-03T16:48:32+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.03174v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "UniShield: An Adaptive Multi-Agent Framework for Unified Forgery Image Detection and Localization",
      "authors": [
        "Qing Huang",
        "Zhipei Xu",
        "Xuanyu Zhang",
        "Jian Zhang"
      ],
      "abstract": "With the rapid advancements in image generation, synthetic images have become\nincreasingly realistic, posing significant societal risks, such as\nmisinformation and fraud. Forgery Image Detection and Localization (FIDL) thus\nemerges as essential for maintaining information integrity and societal\nsecurity. Despite impressive performances by existing domain-specific detection\nmethods, their practical applicability remains limited, primarily due to their\nnarrow specialization, poor cross-domain generalization, and the absence of an\nintegrated adaptive framework. To address these issues, we propose UniShield,\nthe novel multi-agent-based unified system capable of detecting and localizing\nimage forgeries across diverse domains, including image manipulation, document\nmanipulation, DeepFake, and AI-generated images. UniShield innovatively\nintegrates a perception agent with a detection agent. The perception agent\nintelligently analyzes image features to dynamically select suitable detection\nmodels, while the detection agent consolidates various expert detectors into a\nunified framework and generates interpretable reports. Extensive experiments\nshow that UniShield achieves state-of-the-art results, surpassing both existing\nunified approaches and domain-specific detectors, highlighting its superior\npracticality, adaptiveness, and scalability.",
      "pdf_url": "http://arxiv.org/pdf/2510.03161v1",
      "published": "2025-10-03T16:33:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.03161v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "SpineBench: A Clinically Salient, Level-Aware Benchmark Powered by the SpineMed-450k Corpus",
      "authors": [
        "Ming Zhao",
        "Wenhui Dong",
        "Yang Zhang",
        "Xiang Zheng",
        "Zhonghao Zhang",
        "Zian Zhou",
        "Yunzhi Guan",
        "Liukun Xu",
        "Wei Peng",
        "Zhaoyang Gong",
        "Zhicheng Zhang",
        "Dachuan Li",
        "Xiaosheng Ma",
        "Yuli Ma",
        "Jianing Ni",
        "Changjiang Jiang",
        "Lixia Tian",
        "Qixin Chen",
        "Kaishun Xia",
        "Pingping Liu",
        "Tongshun Zhang",
        "Zhiqiang Liu",
        "Zhongan Bi",
        "Chenyang Si",
        "Tiansheng Sun",
        "Caifeng Shan"
      ],
      "abstract": "Spine disorders affect 619 million people globally and are a leading cause of\ndisability, yet AI-assisted diagnosis remains limited by the lack of\nlevel-aware, multimodal datasets. Clinical decision-making for spine disorders\nrequires sophisticated reasoning across X-ray, CT, and MRI at specific\nvertebral levels. However, progress has been constrained by the absence of\ntraceable, clinically-grounded instruction data and standardized,\nspine-specific benchmarks. To address this, we introduce SpineMed, an ecosystem\nco-designed with practicing spine surgeons. It features SpineMed-450k, the\nfirst large-scale dataset explicitly designed for vertebral-level reasoning\nacross imaging modalities with over 450,000 instruction instances, and\nSpineBench, a clinically-grounded evaluation framework. SpineMed-450k is\ncurated from diverse sources, including textbooks, guidelines, open datasets,\nand ~1,000 de-identified hospital cases, using a clinician-in-the-loop pipeline\nwith a two-stage LLM generation method (draft and revision) to ensure\nhigh-quality, traceable data for question-answering, multi-turn consultations,\nand report generation. SpineBench evaluates models on clinically salient axes,\nincluding level identification, pathology assessment, and surgical planning.\nOur comprehensive evaluation of several recently advanced large vision-language\nmodels (LVLMs) on SpineBench reveals systematic weaknesses in fine-grained,\nlevel-specific reasoning. In contrast, our model fine-tuned on SpineMed-450k\ndemonstrates consistent and significant improvements across all tasks.\nClinician assessments confirm the diagnostic clarity and practical utility of\nour model's outputs.",
      "pdf_url": "http://arxiv.org/pdf/2510.03160v1",
      "published": "2025-10-03T16:32:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.03160v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Stimulus-Voltage-Based Prediction of Action Potential Onset Timing: Classical vs. Quantum-Inspired Approaches",
      "authors": [
        "Stevens Johnson",
        "Varun Puram",
        "Johnson Thomas",
        "Acsah Konuparamban",
        "Ashwin Kannan"
      ],
      "abstract": "Accurate modeling of neuronal action potential (AP) onset timing is crucial\nfor understanding neural coding of danger signals. Traditional leaky\nintegrate-and-fire (LIF) models, while widely used, exhibit high relative error\nin predicting AP onset latency, especially under strong or rapidly changing\nstimuli. Inspired by recent experimental findings and quantum theory, we\npresent a quantum-inspired leaky integrate-and-fire (QI-LIF) model that treats\nAP onset as a probabilistic event, represented by a Gaussian wave packet in\ntime. This approach captures the biological variability and uncertainty\ninherent in neuronal firing. We systematically compare the relative error of AP\nonset predictions between the classical LIF and QI-LIF models using synthetic\ndata from hippocampal and sensory neurons subjected to varying stimulus\namplitudes. Our results demonstrate that the QI-LIF model significantly reduces\nprediction error, particularly for high-intensity stimuli, aligning closely\nwith observed biological responses. This work highlights the potential of\nquantum-inspired computational frameworks in advancing the accuracy of neural\nmodeling and has implications for quantum engineering approaches to\nbrain-inspired computing.",
      "pdf_url": "http://arxiv.org/pdf/2510.03155v1",
      "published": "2025-10-03T16:28:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.03155v1",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Improving Cooperation in Collaborative Embodied AI",
      "authors": [
        "Hima Jacob Leven Suprabha",
        "Laxmi Nag Laxminarayan Nagesh",
        "Ajith Nair",
        "Alvin Reuben Amal Selvaster",
        "Ayan Khan",
        "Raghuram Damarla",
        "Sanju Hannah Samuel",
        "Sreenithi Saravana Perumal",
        "Titouan Puech",
        "Venkataramireddy Marella",
        "Vishal Sonar",
        "Alessandro Suglia",
        "Oliver Lemon"
      ],
      "abstract": "The integration of Large Language Models (LLMs) into multiagent systems has\nopened new possibilities for collaborative reasoning and cooperation with AI\nagents. This paper explores different prompting methods and evaluates their\neffectiveness in enhancing agent collaborative behaviour and decision-making.\nWe enhance CoELA, a framework designed for building Collaborative Embodied\nAgents that leverage LLMs for multi-agent communication, reasoning, and task\ncoordination in shared virtual spaces. Through systematic experimentation, we\nexamine different LLMs and prompt engineering strategies to identify optimised\ncombinations that maximise collaboration performance. Furthermore, we extend\nour research by integrating speech capabilities, enabling seamless\ncollaborative voice-based interactions. Our findings highlight the\neffectiveness of prompt optimisation in enhancing collaborative agent\nperformance; for example, our best combination improved the efficiency of the\nsystem running with Gemma3 by 22% compared to the original CoELA system. In\naddition, the speech integration provides a more engaging user interface for\niterative system development and demonstrations.",
      "pdf_url": "http://arxiv.org/pdf/2510.03153v1",
      "published": "2025-10-03T16:25:48+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.03153v1",
      "categories": [
        "cs.AI",
        "cs.MA",
        "cs.RO"
      ]
    },
    {
      "title": "Signature-Informed Transformer for Asset Allocation",
      "authors": [
        "Yoontae Hwang",
        "Stefan Zohren"
      ],
      "abstract": "Robust asset allocation is a key challenge in quantitative finance, where\ndeep-learning forecasters often fail due to objective mismatch and error\namplification. We introduce the Signature-Informed Transformer (SIT), a novel\nframework that learns end-to-end allocation policies by directly optimizing a\nrisk-aware financial objective. SIT's core innovations include path signatures\nfor a rich geometric representation of asset dynamics and a signature-augmented\nattention mechanism embedding financial inductive biases, like lead-lag\neffects, into the model. Evaluated on daily S\\&P 100 equity data, SIT\ndecisively outperforms traditional and deep-learning baselines, especially when\ncompared to predict-then-optimize models. These results indicate that\nportfolio-aware objectives and geometry-aware inductive biases are essential\nfor risk-aware capital allocation in machine-learning systems. The code is\navailable at:\nhttps://github.com/Yoontae6719/Signature-Informed-Transformer-For-Asset-Allocation",
      "pdf_url": "http://arxiv.org/pdf/2510.03129v1",
      "published": "2025-10-03T15:58:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.03129v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-fin.PM"
      ]
    },
    {
      "title": "A Study of Rule Omission in Raven's Progressive Matrices",
      "authors": [
        "Binze Li"
      ],
      "abstract": "Analogical reasoning lies at the core of human cognition and remains a\nfundamental challenge for artificial intelligence. Raven's Progressive Matrices\n(RPM) serve as a widely used benchmark to assess abstract reasoning by\nrequiring the inference of underlying structural rules. While many vision-based\nand language-based models have achieved success on RPM tasks, it remains\nunclear whether their performance reflects genuine reasoning ability or\nreliance on statistical shortcuts. This study investigates the generalization\ncapacity of modern AI systems under conditions of incomplete training by\ndeliberately omitting several structural rules during training. Both\nsequence-to-sequence transformer models and vision-based architectures such as\nCoPINet and the Dual-Contrast Network are evaluated on the Impartial-RAVEN\n(I-RAVEN) dataset. Experiments reveal that although transformers demonstrate\nstrong performance on familiar rules, their accuracy declines sharply when\nfaced with novel or omitted rules. Moreover, the gap between token-level\naccuracy and complete answer accuracy highlights fundamental limitations in\ncurrent approaches. These findings provide new insights into the reasoning\nmechanisms underlying deep learning models and underscore the need for\narchitectures that move beyond pattern recognition toward robust abstract\nreasoning.",
      "pdf_url": "http://arxiv.org/pdf/2510.03127v1",
      "published": "2025-10-03T15:53:28+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.03127v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "HAVIR: HierArchical Vision to Image Reconstruction using CLIP-Guided Versatile Diffusion",
      "authors": [
        "Shiyi Zhang",
        "Dong Liang",
        "Hairong Zheng",
        "Yihang Zhou"
      ],
      "abstract": "The reconstruction of visual information from brain activity fosters\ninterdisciplinary integration between neuroscience and computer vision.\nHowever, existing methods still face challenges in accurately recovering highly\ncomplex visual stimuli. This difficulty stems from the characteristics of\nnatural scenes: low-level features exhibit heterogeneity, while high-level\nfeatures show semantic entanglement due to contextual overlaps. Inspired by the\nhierarchical representation theory of the visual cortex, we propose the HAVIR\nmodel, which separates the visual cortex into two hierarchical regions and\nextracts distinct features from each. Specifically, the Structural Generator\nextracts structural information from spatial processing voxels and converts it\ninto latent diffusion priors, while the Semantic Extractor converts semantic\nprocessing voxels into CLIP embeddings. These components are integrated via the\nVersatile Diffusion model to synthesize the final image. Experimental results\ndemonstrate that HAVIR enhances both the structural and semantic quality of\nreconstructions, even in complex scenes, and outperforms existing models.",
      "pdf_url": "http://arxiv.org/pdf/2510.03122v1",
      "published": "2025-10-03T15:50:52+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.03122v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Distilled Protein Backbone Generation",
      "authors": [
        "Liyang Xie",
        "Haoran Zhang",
        "Zhendong Wang",
        "Wesley Tansey",
        "Mingyuan Zhou"
      ],
      "abstract": "Diffusion- and flow-based generative models have recently demonstrated strong\nperformance in protein backbone generation tasks, offering unprecedented\ncapabilities for de novo protein design. However, while achieving notable\nperformance in generation quality, these models are limited by their generating\nspeed, often requiring hundreds of iterative steps in the reverse-diffusion\nprocess. This computational bottleneck limits their practical utility in\nlarge-scale protein discovery, where thousands to millions of candidate\nstructures are needed. To address this challenge, we explore the techniques of\nscore distillation, which has shown great success in reducing the number of\nsampling steps in the vision domain while maintaining high generation quality.\nHowever, a straightforward adaptation of these methods results in unacceptably\nlow designability. Through extensive study, we have identified how to\nappropriately adapt Score identity Distillation (SiD), a state-of-the-art score\ndistillation strategy, to train few-step protein backbone generators which\nsignificantly reduce sampling time, while maintaining comparable performance to\ntheir pretrained teacher model. In particular, multistep generation combined\nwith inference time noise modulation is key to the success. We demonstrate that\nour distilled few-step generators achieve more than a 20-fold improvement in\nsampling speed, while achieving similar levels of designability, diversity, and\nnovelty as the Proteina teacher model. This reduction in inference cost enables\nlarge-scale in silico protein design, thereby bringing diffusion-based models\ncloser to real-world protein engineering applications.",
      "pdf_url": "http://arxiv.org/pdf/2510.03095v1",
      "published": "2025-10-03T15:25:08+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.03095v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ]
    },
    {
      "title": "From Facts to Foils: Designing and Evaluating Counterfactual Explanations for Smart Environments",
      "authors": [
        "Anna Trapp",
        "Mersedeh Sadeghi",
        "Andreas Vogelsang"
      ],
      "abstract": "Explainability is increasingly seen as an essential feature of rule-based\nsmart environments. While counterfactual explanations, which describe what\ncould have been done differently to achieve a desired outcome, are a powerful\ntool in eXplainable AI (XAI), no established methods exist for generating them\nin these rule-based domains. In this paper, we present the first formalization\nand implementation of counterfactual explanations tailored to this domain. It\nis implemented as a plugin that extends an existing explanation engine for\nsmart environments. We conducted a user study (N=17) to evaluate our generated\ncounterfactuals against traditional causal explanations. The results show that\nuser preference is highly contextual: causal explanations are favored for their\nlinguistic simplicity and in time-pressured situations, while counterfactuals\nare preferred for their actionable content, particularly when a user wants to\nresolve a problem. Our work contributes a practical framework for a new type of\nexplanation in smart environments and provides empirical evidence to guide the\nchoice of when each explanation type is most effective.",
      "pdf_url": "http://arxiv.org/pdf/2510.03078v1",
      "published": "2025-10-03T15:06:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.03078v1",
      "categories": [
        "cs.AI",
        "cs.SE"
      ]
    },
    {
      "title": "What Drives Compositional Generalization in Visual Generative Models?",
      "authors": [
        "Karim Farid",
        "Rajat Sahay",
        "Yumna Ali Alnaggar",
        "Simon Schrodi",
        "Volker Fischer",
        "Cordelia Schmid",
        "Thomas Brox"
      ],
      "abstract": "Compositional generalization, the ability to generate novel combinations of\nknown concepts, is a key ingredient for visual generative models. Yet, not all\nmechanisms that enable or inhibit it are fully understood. In this work, we\nconduct a systematic study of how various design choices influence\ncompositional generalization in image and video generation in a positive or\nnegative way. Through controlled experiments, we identify two key factors: (i)\nwhether the training objective operates on a discrete or continuous\ndistribution, and (ii) to what extent conditioning provides information about\nthe constituent concepts during training. Building on these insights, we show\nthat relaxing the MaskGIT discrete loss with an auxiliary continuous JEPA-based\nobjective can improve compositional performance in discrete models like\nMaskGIT.",
      "pdf_url": "http://arxiv.org/pdf/2510.03075v1",
      "published": "2025-10-03T15:02:27+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.03075v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "A Study of Neural Polar Decoders for Communication",
      "authors": [
        "Rom Hirsch",
        "Ziv Aharoni",
        "Henry D. Pfister",
        "Haim H. Permuter"
      ],
      "abstract": "In this paper, we adapt and analyze Neural Polar Decoders (NPDs) for\nend-to-end communication systems. While prior work demonstrated the\neffectiveness of NPDs on synthetic channels, this study extends the NPD to\nreal-world communication systems. The NPD was adapted to complete OFDM and\nsingle-carrier communication systems. To satisfy practical system requirements,\nthe NPD is extended to support any code length via rate matching, higher-order\nmodulations, and robustness across diverse channel conditions. The NPD operates\ndirectly on channels with memory, exploiting their structure to achieve higher\ndata rates without requiring pilots and a cyclic prefix. Although NPD entails\nhigher computational complexity than the standard 5G polar decoder, its neural\nnetwork architecture enables an efficient representation of channel statistics,\nresulting in manageable complexity suitable for practical systems. Experimental\nresults over 5G channels demonstrate that the NPD consistently outperforms the\n5G polar decoder in terms of BER, BLER, and throughput. These improvements are\nparticularly significant for low-rate and short-block configurations, which are\nprevalent in 5G control channels. Furthermore, NPDs applied to single-carrier\nsystems offer performance comparable to OFDM with lower PAPR, enabling\neffective single-carrier transmission over 5G channels. These results position\nthe NPD as a high-performance, pilotless, and robust decoding solution.",
      "pdf_url": "http://arxiv.org/pdf/2510.03069v1",
      "published": "2025-10-03T14:55:18+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.03069v1",
      "categories": [
        "eess.SP",
        "cs.AI"
      ]
    },
    {
      "title": "A Unified Deep Reinforcement Learning Approach for Close Enough Traveling Salesman Problem",
      "authors": [
        "Mingfeng Fan",
        "Jiaqi Cheng",
        "Yaoxin Wu",
        "Yifeng Zhang",
        "Yibin Yang",
        "Guohua Wu",
        "Guillaume Sartoretti"
      ],
      "abstract": "In recent years, deep reinforcement learning (DRL) has gained traction for\nsolving the NP-hard traveling salesman problem (TSP). However, limited\nattention has been given to the close-enough TSP (CETSP), primarily due to the\nchallenge introduced by its neighborhood-based visitation criterion, wherein a\nnode is considered visited if the agent enters a compact neighborhood around\nit. In this work, we formulate a Markov decision process (MDP) for CETSP using\na discretization scheme and propose a novel unified dual-decoder DRL (UD3RL)\nframework that separates decision-making into node selection and waypoint\ndetermination. Specifically, an adapted encoder is employed for effective\nfeature extraction, followed by a node-decoder and a loc-decoder to handle the\ntwo sub-tasks, respectively. A k-nearest neighbors subgraph interaction\nstrategy is further introduced to enhance spatial reasoning during location\ndecoding. Furthermore, we customize the REINFORCE algorithm to train UD3RL as a\nunified model capable of generalizing across different problem sizes and\nvarying neighborhood radius types (i.e., constant and random radii).\nExperimental results show that UD3RL outperforms conventional methods in both\nsolution quality and runtime, while exhibiting strong generalization across\nproblem scales, spatial distributions, and radius ranges, as well as robustness\nto dynamic environments.",
      "pdf_url": "http://arxiv.org/pdf/2510.03065v1",
      "published": "2025-10-03T14:49:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.03065v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Comparative Analysis of Parameterized Action Actor-Critic Reinforcement Learning Algorithms for Web Search Match Plan Generation",
      "authors": [
        "Ubayd Bapoo",
        "Clement N Nyirenda"
      ],
      "abstract": "This study evaluates the performance of Soft Actor Critic (SAC), Greedy Actor\nCritic (GAC), and Truncated Quantile Critics (TQC) in high-dimensional\ndecision-making tasks using fully observable environments. The focus is on\nparametrized action (PA) spaces, eliminating the need for recurrent networks,\nwith benchmarks Platform-v0 and Goal-v0 testing discrete actions linked to\ncontinuous action-parameter spaces. Hyperparameter optimization was performed\nwith Microsoft NNI, ensuring reproducibility by modifying the codebase for GAC\nand TQC. Results show that Parameterized Action Greedy Actor-Critic (PAGAC)\noutperformed other algorithms, achieving the fastest training times and highest\nreturns across benchmarks, completing 5,000 episodes in 41:24 for the Platform\ngame and 24:04 for the Robot Soccer Goal game. Its speed and stability provide\nclear advantages in complex action spaces. Compared to PASAC and PATQC, PAGAC\ndemonstrated superior efficiency and reliability, making it ideal for tasks\nrequiring rapid convergence and robust performance. Future work could explore\nhybrid strategies combining entropy-regularization with truncation-based\nmethods to enhance stability and expand investigations into generalizability.",
      "pdf_url": "http://arxiv.org/pdf/2510.03064v1",
      "published": "2025-10-03T14:48:57+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.03064v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Semantic Differentiation in Speech Emotion Recognition: Insights from Descriptive and Expressive Speech Roles",
      "authors": [
        "Rongchen Guo",
        "Vincent Francoeur",
        "Isar Nejadgholi",
        "Sylvain Gagnon",
        "Miodrag Bolic"
      ],
      "abstract": "Speech Emotion Recognition (SER) is essential for improving human-computer\ninteraction, yet its accuracy remains constrained by the complexity of\nemotional nuances in speech. In this study, we distinguish between descriptive\nsemantics, which represents the contextual content of speech, and expressive\nsemantics, which reflects the speaker's emotional state. After watching\nemotionally charged movie segments, we recorded audio clips of participants\ndescribing their experiences, along with the intended emotion tags for each\nclip, participants' self-rated emotional responses, and their valence/arousal\nscores. Through experiments, we show that descriptive semantics align with\nintended emotions, while expressive semantics correlate with evoked emotions.\nOur findings inform SER applications in human-AI interaction and pave the way\nfor more context-aware AI systems.",
      "pdf_url": "http://arxiv.org/pdf/2510.03060v1",
      "published": "2025-10-03T14:42:35+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.03060v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "ZeroShotOpt: Towards Zero-Shot Pretrained Models for Efficient Black-Box Optimization",
      "authors": [
        "Jamison Meindl",
        "Yunsheng Tian",
        "Tony Cui",
        "Veronika Thost",
        "Zhang-Wei Hong",
        "Johannes D√ºrholt",
        "Jie Chen",
        "Wojciech Matusik",
        "Mina Konakoviƒá Lukoviƒá"
      ],
      "abstract": "Global optimization of expensive, derivative-free black-box functions\nrequires extreme sample efficiency. While Bayesian optimization (BO) is the\ncurrent state-of-the-art, its performance hinges on surrogate and acquisition\nfunction hyper-parameters that are often hand-tuned and fail to generalize\nacross problem landscapes. We present ZeroShotOpt, a general-purpose,\npretrained model for continuous black-box optimization tasks ranging from 2D to\n20D. Our approach leverages offline reinforcement learning on large-scale\noptimization trajectories collected from 12 BO variants. To scale pretraining,\nwe generate millions of synthetic Gaussian process-based functions with diverse\nlandscapes, enabling the model to learn transferable optimization policies. As\na result, ZeroShotOpt achieves robust zero-shot generalization on a wide array\nof unseen benchmarks, matching or surpassing the sample efficiency of leading\nglobal optimizers, including BO, while also offering a reusable foundation for\nfuture extensions and improvements. Our open-source code, dataset, and model\nare available at: https://github.com/jamisonmeindl/zeroshotopt",
      "pdf_url": "http://arxiv.org/pdf/2510.03051v1",
      "published": "2025-10-03T14:33:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.03051v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "When and Where do Events Switch in Multi-Event Video Generation?",
      "authors": [
        "Ruotong Liao",
        "Guowen Huang",
        "Qing Cheng",
        "Thomas Seidl",
        "Daniel Cremers",
        "Volker Tresp"
      ],
      "abstract": "Text-to-video (T2V) generation has surged in response to challenging\nquestions, especially when a long video must depict multiple sequential events\nwith temporal coherence and controllable content. Existing methods that extend\nto multi-event generation omit an inspection of the intrinsic factor in event\nshifting. The paper aims to answer the central question: When and where\nmulti-event prompts control event transition during T2V generation. This work\nintroduces MEve, a self-curated prompt suite for evaluating multi-event\ntext-to-video (T2V) generation, and conducts a systematic study of two\nrepresentative model families, i.e., OpenSora and CogVideoX. Extensive\nexperiments demonstrate the importance of early intervention in denoising steps\nand block-wise model layers, revealing the essential factor for multi-event\nvideo generation and highlighting the possibilities for multi-event\nconditioning in future models.",
      "pdf_url": "http://arxiv.org/pdf/2510.03049v1",
      "published": "2025-10-03T14:31:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.03049v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "CHORD: Customizing Hybrid-precision On-device Model for Sequential Recommendation with Device-cloud Collaboration",
      "authors": [
        "Tianqi Liu",
        "Kairui Fu",
        "Shengyu Zhang",
        "Wenyan Fan",
        "Zhaocheng Du",
        "Jieming Zhu",
        "Fan Wu",
        "Fei Wu"
      ],
      "abstract": "With the advancement of mobile device capabilities, deploying reranking\nmodels directly on devices has become feasible, enabling real-time contextual\nrecommendations. When migrating models from cloud to devices, resource\nheterogeneity inevitably necessitates model compression. Recent quantization\nmethods show promise for efficient deployment, yet they overlook\ndevice-specific user interests, resulting in compromised recommendation\naccuracy. While on-device finetuning captures personalized user preference, it\nimposes additional computational burden through local retraining. To address\nthese challenges, we propose a framework for \\underline{\\textbf{C}}ustomizing\n\\underline{\\textbf{H}}ybrid-precision \\underline{\\textbf{O}}n-device model for\nsequential \\underline{\\textbf{R}}ecommendation with\n\\underline{\\textbf{D}}evice-cloud collaboration (\\textbf{CHORD}), leveraging\nchannel-wise mixed-precision quantization to simultaneously achieve\npersonalization and resource-adaptive deployment. CHORD distributes randomly\ninitialized models across heterogeneous devices and identifies user-specific\ncritical parameters through auxiliary hypernetwork modules on the cloud. Our\nparameter sensitivity analysis operates across multiple granularities (layer,\nfilter, and element levels), enabling precise mapping from user profiles to\nquantization strategy. Through on-device mixed-precision quantization, CHORD\ndelivers dynamic model adaptation and accelerated inference without\nbackpropagation, eliminating costly retraining cycles. We minimize\ncommunication overhead by encoding quantization strategies using only 2 bits\nper channel instead of 32-bit weights. Experiments on three real-world datasets\nwith two popular backbones (SASRec and Caser) demonstrate the accuracy,\nefficiency, and adaptivity of CHORD.",
      "pdf_url": "http://arxiv.org/pdf/2510.03038v1",
      "published": "2025-10-03T14:20:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.03038v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR"
      ]
    },
    {
      "title": "Investigating The Smells of LLM Generated Code",
      "authors": [
        "Debalina Ghosh Paul",
        "Hong Zhu",
        "Ian Bayley"
      ],
      "abstract": "Context: Large Language Models (LLMs) are increasingly being used to generate\nprogram code. Much research has been reported on the functional correctness of\ngenerated code, but there is far less on code quality.\n  Objectives: In this study, we propose a scenario-based method of evaluating\nthe quality of LLM-generated code to identify the weakest scenarios in which\nthe quality of LLM generated code should be improved.\n  Methods: The method measures code smells, an important indicator of code\nquality, and compares them with a baseline formed from reference solutions of\nprofessionally written code. The test dataset is divided into various subsets\naccording to the topics of the code and complexity of the coding tasks to\nrepresent different scenarios of using LLMs for code generation. We will also\npresent an automated test system for this purpose and report experiments with\nthe Java programs generated in response to prompts given to four\nstate-of-the-art LLMs: Gemini Pro, ChatGPT, Codex, and Falcon.\n  Results: We find that LLM-generated code has a higher incidence of code\nsmells compared to reference solutions. Falcon performed the least badly, with\na smell increase of 42.28%, followed by Gemini Pro (62.07%), ChatGPT (65.05%)\nand finally Codex (84.97%). The average smell increase across all LLMs was\n63.34%, comprising 73.35% for implementation smells and 21.42% for design\nsmells. We also found that the increase in code smells is greater for more\ncomplex coding tasks and for more advanced topics, such as those involving\nobject-orientated concepts.\n  Conclusion: In terms of code smells, LLM's performances on various coding\ntask complexities and topics are highly correlated to the quality of human\nwritten code in the corresponding scenarios. However, the quality of LLM\ngenerated code is noticeably poorer than human written code.",
      "pdf_url": "http://arxiv.org/pdf/2510.03029v1",
      "published": "2025-10-03T14:09:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.03029v1",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "Learning Robust Diffusion Models from Imprecise Supervision",
      "authors": [
        "Dong-Dong Wu",
        "Jiacheng Cui",
        "Wei Wang",
        "Zhiqiang She",
        "Masashi Sugiyama"
      ],
      "abstract": "Conditional diffusion models have achieved remarkable success in various\ngenerative tasks recently, but their training typically relies on large-scale\ndatasets that inevitably contain imprecise information in conditional inputs.\nSuch supervision, often stemming from noisy, ambiguous, or incomplete labels,\nwill cause condition mismatch and degrade generation quality. To address this\nchallenge, we propose DMIS, a unified framework for training robust Diffusion\nModels from Imprecise Supervision, which is the first systematic study within\ndiffusion models. Our framework is derived from likelihood maximization and\ndecomposes the objective into generative and classification components: the\ngenerative component models imprecise-label distributions, while the\nclassification component leverages a diffusion classifier to infer\nclass-posterior probabilities, with its efficiency further improved by an\noptimized timestep sampling strategy. Extensive experiments on diverse forms of\nimprecise supervision, covering tasks of image generation, weakly supervised\nlearning, and noisy dataset condensation demonstrate that DMIS consistently\nproduces high-quality and class-discriminative samples.",
      "pdf_url": "http://arxiv.org/pdf/2510.03016v1",
      "published": "2025-10-03T14:00:32+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.03016v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "BrainIB++: Leveraging Graph Neural Networks and Information Bottleneck for Functional Brain Biomarkers in Schizophrenia",
      "authors": [
        "Tianzheng Hu",
        "Qiang Li",
        "Shu Liu",
        "Vince D. Calhoun",
        "Guido van Wingen",
        "Shujian Yu"
      ],
      "abstract": "The development of diagnostic models is gaining traction in the field of\npsychiatric disorders. Recently, machine learning classifiers based on\nresting-state functional magnetic resonance imaging (rs-fMRI) have been\ndeveloped to identify brain biomarkers that differentiate psychiatric disorders\nfrom healthy controls. However, conventional machine learning-based diagnostic\nmodels often depend on extensive feature engineering, which introduces bias\nthrough manual intervention. While deep learning models are expected to operate\nwithout manual involvement, their lack of interpretability poses significant\nchallenges in obtaining explainable and reliable brain biomarkers to support\ndiagnostic decisions, ultimately limiting their clinical applicability. In this\nstudy, we introduce an end-to-end innovative graph neural network framework\nnamed BrainIB++, which applies the information bottleneck (IB) principle to\nidentify the most informative data-driven brain regions as subgraphs during\nmodel training for interpretation. We evaluate the performance of our model\nagainst nine established brain network classification methods across three\nmulti-cohort schizophrenia datasets. It consistently demonstrates superior\ndiagnostic accuracy and exhibits generalizability to unseen data. Furthermore,\nthe subgraphs identified by our model also correspond with established clinical\nbiomarkers in schizophrenia, particularly emphasizing abnormalities in the\nvisual, sensorimotor, and higher cognition brain functional network. This\nalignment enhances the model's interpretability and underscores its relevance\nfor real-world diagnostic applications.",
      "pdf_url": "http://arxiv.org/pdf/2510.03004v1",
      "published": "2025-10-03T13:48:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.03004v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68T07 (Primary), 68U10, 94A17 (Secondary)"
      ]
    },
    {
      "title": "From high-frequency sensors to noon reports: Using transfer learning for shaft power prediction in maritime",
      "authors": [
        "Akriti Sharma",
        "Dogan Altan",
        "Dusica Marijan",
        "Arnbj√∏rn Maressa"
      ],
      "abstract": "With the growth of global maritime transportation, energy optimization has\nbecome crucial for reducing costs and ensuring operational efficiency. Shaft\npower is the mechanical power transmitted from the engine to the shaft and\ndirectly impacts fuel consumption, making its accurate prediction a paramount\nstep in optimizing vessel performance. Power consumption is highly correlated\nwith ship parameters such as speed and shaft rotation per minute, as well as\nweather and sea conditions. Frequent access to this operational data can\nimprove prediction accuracy. However, obtaining high-quality sensor data is\noften infeasible and costly, making alternative sources such as noon reports a\nviable option. In this paper, we propose a transfer learning-based approach for\npredicting vessels shaft power, where a model is initially trained on\nhigh-frequency data from a vessel and then fine-tuned with low-frequency daily\nnoon reports from other vessels. We tested our approach on sister vessels\n(identical dimensions and configurations), a similar vessel (slightly larger\nwith a different engine), and a different vessel (distinct dimensions and\nconfigurations). The experiments showed that the mean absolute percentage error\ndecreased by 10.6 percent for sister vessels, 3.6 percent for a similar vessel,\nand 5.3 percent for a different vessel, compared to the model trained solely on\nnoon report data.",
      "pdf_url": "http://arxiv.org/pdf/2510.03003v1",
      "published": "2025-10-03T13:47:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.03003v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Untargeted Jailbreak Attack",
      "authors": [
        "Xinzhe Huang",
        "Wenjing Hu",
        "Tianhang Zheng",
        "Kedong Xiu",
        "Xiaojun Jia",
        "Di Wang",
        "Zhan Qin",
        "Kui Ren"
      ],
      "abstract": "Existing gradient-based jailbreak attacks on Large Language Models (LLMs),\nsuch as Greedy Coordinate Gradient (GCG) and COLD-Attack, typically optimize\nadversarial suffixes to align the LLM output with a predefined target response.\nHowever, by restricting the optimization objective as inducing a predefined\ntarget, these methods inherently constrain the adversarial search space, which\nlimit their overall attack efficacy. Furthermore, existing methods typically\nrequire a large number of optimization iterations to fulfill the large gap\nbetween the fixed target and the original model response, resulting in low\nattack efficiency.\n  To overcome the limitations of targeted jailbreak attacks, we propose the\nfirst gradient-based untargeted jailbreak attack (UJA), aiming to elicit an\nunsafe response without enforcing any predefined patterns. Specifically, we\nformulate an untargeted attack objective to maximize the unsafety probability\nof the LLM response, which can be quantified using a judge model. Since the\nobjective is non-differentiable, we further decompose it into two\ndifferentiable sub-objectives for optimizing an optimal harmful response and\nthe corresponding adversarial prompt, with a theoretical analysis to validate\nthe decomposition. In contrast to targeted jailbreak attacks, UJA's\nunrestricted objective significantly expands the search space, enabling a more\nflexible and efficient exploration of LLM vulnerabilities.Extensive evaluations\ndemonstrate that \\textsc{UJA} can achieve over 80\\% attack success rates\nagainst recent safety-aligned LLMs with only 100 optimization iterations,\noutperforming the state-of-the-art gradient-based attacks such as I-GCG and\nCOLD-Attack by over 20\\%.",
      "pdf_url": "http://arxiv.org/pdf/2510.02999v1",
      "published": "2025-10-03T13:38:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.02999v1",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "title": "Onto-Epistemological Analysis of AI Explanations",
      "authors": [
        "Martina Mattioli",
        "Eike Petersen",
        "Aasa Feragen",
        "Marcello Pelillo",
        "Siavash A. Bigdeli"
      ],
      "abstract": "Artificial intelligence (AI) is being applied in almost every field. At the\nsame time, the currently dominant deep learning methods are fundamentally\nblack-box systems that lack explanations for their inferences, significantly\nlimiting their trustworthiness and adoption. Explainable AI (XAI) methods aim\nto overcome this challenge by providing explanations of the models' decision\nprocess. Such methods are often proposed and developed by engineers and\nscientists with a predominantly technical background and incorporate their\nassumptions about the existence, validity, and explanatory utility of different\nconceivable explanatory mechanisms. However, the basic concept of an\nexplanation -- what it is, whether we can know it, whether it is absolute or\nrelative -- is far from trivial and has been the subject of deep philosophical\ndebate for millennia. As we point out here, the assumptions incorporated into\ndifferent XAI methods are not harmless and have important consequences for the\nvalidity and interpretation of AI explanations in different domains. We\ninvestigate ontological and epistemological assumptions in explainability\nmethods when they are applied to AI systems, meaning the assumptions we make\nabout the existence of explanations and our ability to gain knowledge about\nthose explanations. Our analysis shows how seemingly small technical changes to\nan XAI method may correspond to important differences in the underlying\nassumptions about explanations. We furthermore highlight the risks of ignoring\nthe underlying onto-epistemological paradigm when choosing an XAI method for a\ngiven application, and we discuss how to select and adapt appropriate XAI\nmethods for different domains of application.",
      "pdf_url": "http://arxiv.org/pdf/2510.02996v1",
      "published": "2025-10-03T13:36:57+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.02996v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "AI Generated Child Sexual Abuse Material -- What's the Harm?",
      "authors": [
        "Caoilte √ì Ciardha",
        "John Buckley",
        "Rebecca S. Portnoff"
      ],
      "abstract": "The development of generative artificial intelligence (AI) tools capable of\nproducing wholly or partially synthetic child sexual abuse material (AI CSAM)\npresents profound challenges for child protection, law enforcement, and\nsocietal responses to child exploitation. While some argue that the harmfulness\nof AI CSAM differs fundamentally from other CSAM due to a perceived absence of\ndirect victimization, this perspective fails to account for the range of risks\nassociated with its production and consumption. AI has been implicated in the\ncreation of synthetic CSAM of children who have not previously been abused, the\nrevictimization of known survivors of abuse, the facilitation of grooming,\ncoercion and sexual extortion, and the normalization of child sexual\nexploitation. Additionally, AI CSAM may serve as a new or enhanced pathway into\noffending by lowering barriers to engagement, desensitizing users to\nprogressively extreme content, and undermining protective factors for\nindividuals with a sexual interest in children. This paper provides a primer on\nsome key technologies, critically examines the harms associated with AI CSAM,\nand cautions against claims that it may function as a harm reduction tool,\nemphasizing how some appeals to harmlessness obscure its real risks and may\ncontribute to inertia in ecosystem responses.",
      "pdf_url": "http://arxiv.org/pdf/2510.02978v1",
      "published": "2025-10-03T13:11:28+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.02978v1",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ]
    },
    {
      "title": "Corrosion Risk Estimation for Heritage Preservation: An Internet of Things and Machine Learning Approach Using Temperature and Humidity",
      "authors": [
        "Reginald Juan M. Mercado",
        "Muhammad Kabeer",
        "Haider Al-Obaidy",
        "Rosdiadee Nordin"
      ],
      "abstract": "Proactive preservation of steel structures at culturally significant heritage\nsites like the San Sebastian Basilica in the Philippines requires accurate\ncorrosion forecasting. This study developed an Internet of Things hardware\nsystem connected with LoRa wireless communications to monitor heritage\nbuildings with steel structures. From a three year dataset generated by the IoT\nsystem, we built a machine learning framework for predicting atmospheric\ncorrosion rates using only temperature and relative humidity data. Deployed via\na Streamlit dashboard with ngrok tunneling for public access, the framework\nprovides real-time corrosion monitoring and actionable preservation\nrecommendations. This minimal-data approach is scalable and cost effective for\nheritage sites with limited monitoring resources, showing that advanced\nregression can extract accurate corrosion predictions from basic meteorological\ndata enabling proactive preservation of culturally significant structures\nworldwide without requiring extensive sensor networks",
      "pdf_url": "http://arxiv.org/pdf/2510.02973v1",
      "published": "2025-10-03T13:07:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.02973v1",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.NI",
        "cs.SY",
        "eess.SY"
      ]
    },
    {
      "title": "Grounding Large Language Models in Clinical Evidence: A Retrieval-Augmented Generation System for Querying UK NICE Clinical Guidelines",
      "authors": [
        "Matthew Lewis",
        "Samuel Thio",
        "Richard JB Dobson",
        "Spiros Denaxas"
      ],
      "abstract": "This paper presents the development and evaluation of a Retrieval-Augmented\nGeneration (RAG) system for querying the United Kingdom's National Institute\nfor Health and Care Excellence (NICE) clinical guidelines using Large Language\nModels (LLMs). The extensive length and volume of these guidelines can impede\ntheir utilisation within a time-constrained healthcare system, a challenge this\nproject addresses through the creation of a system capable of providing users\nwith precisely matched information in response to natural language queries. The\nsystem's retrieval architecture, composed of a hybrid embedding mechanism, was\nevaluated against a database of 10,195 text chunks derived from three hundred\nguidelines. It demonstrates high performance, with a Mean Reciprocal Rank (MRR)\nof 0.814, a Recall of 81% at the first chunk and of 99.1% within the top ten\nretrieved chunks, when evaluated on 7901 queries.\n  The most significant impact of the RAG system was observed during the\ngeneration phase. When evaluated on a manually curated dataset of seventy\nquestion-answer pairs, RAG-enhanced models showed substantial gains in\nperformance. Faithfulness, the measure of whether an answer is supported by the\nsource text, was increased by 64.7 percentage points to 99.5% for the\nRAG-enhanced O4-Mini model and significantly outperformed the medical-focused\nMeditron3-8B LLM, which scored 43%. This, combined with a perfect Context\nPrecision score of 1 for all RAG-enhanced models, confirms the system's ability\nto prevent information fabrication by grounding its answers in relevant source\nmaterial. This study thus establishes RAG as an effective, reliable, and\nscalable approach for applying generative AI in healthcare, enabling\ncost-effective access to medical guidelines.",
      "pdf_url": "http://arxiv.org/pdf/2510.02967v1",
      "published": "2025-10-03T12:57:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.02967v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ]
    },
    {
      "title": "Ergodic Risk Measures: Towards a Risk-Aware Foundation for Continual Reinforcement Learning",
      "authors": [
        "Juan Sebastian Rojas",
        "Chi-Guhn Lee"
      ],
      "abstract": "Continual reinforcement learning (continual RL) seeks to formalize the\nnotions of lifelong learning and endless adaptation in RL. In particular, the\naim of continual RL is to develop RL agents that can maintain a careful balance\nbetween retaining useful information and adapting to new situations. To date,\ncontinual RL has been explored almost exclusively through the lens of\nrisk-neutral decision-making, in which the agent aims to optimize the expected\n(or mean) long-run performance. In this work, we present the first formal\ntheoretical treatment of continual RL through the lens of risk-aware\ndecision-making, in which the agent aims to optimize a reward-based measure of\nlong-run performance beyond the mean. In particular, we show that the classical\ntheory of risk measures, widely used as a theoretical foundation in\nnon-continual risk-aware RL, is, in its current form, incompatible with the\ncontinual setting. Then, building on this insight, we extend risk measure\ntheory into the continual setting by introducing a new class of ergodic risk\nmeasures that are compatible with continual learning. Finally, we provide a\ncase study of risk-aware continual learning, along with empirical results,\nwhich show the intuitive appeal and theoretical soundness of ergodic risk\nmeasures.",
      "pdf_url": "http://arxiv.org/pdf/2510.02945v1",
      "published": "2025-10-03T12:40:03+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.02945v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Multimodal Carotid Risk Stratification with Large Vision-Language Models: Benchmarking, Fine-Tuning, and Clinical Insights",
      "authors": [
        "Daphne Tsolissou",
        "Theofanis Ganitidis",
        "Konstantinos Mitsis",
        "Stergios CHristodoulidis",
        "Maria Vakalopoulou",
        "Konstantina Nikita"
      ],
      "abstract": "Reliable risk assessment for carotid atheromatous disease remains a major\nclinical challenge, as it requires integrating diverse clinical and imaging\ninformation in a manner that is transparent and interpretable to clinicians.\nThis study investigates the potential of state-of-the-art and recent large\nvision-language models (LVLMs) for multimodal carotid plaque assessment by\nintegrating ultrasound imaging (USI) with structured clinical, demographic,\nlaboratory, and protein biomarker data. A framework that simulates realistic\ndiagnostic scenarios through interview-style question sequences is proposed,\ncomparing a range of open-source LVLMs, including both general-purpose and\nmedically tuned models. Zero-shot experiments reveal that even if they are very\npowerful, not all LVLMs can accurately identify imaging modality and anatomy,\nwhile all of them perform poorly in accurate risk classification. To address\nthis limitation, LLaVa-NeXT-Vicuna is adapted to the ultrasound domain using\nlow-rank adaptation (LoRA), resulting in substantial improvements in stroke\nrisk stratification. The integration of multimodal tabular data in the form of\ntext further enhances specificity and balanced accuracy, yielding competitive\nperformance compared to prior convolutional neural network (CNN) baselines\ntrained on the same dataset. Our findings highlight both the promise and\nlimitations of LVLMs in ultrasound-based cardiovascular risk prediction,\nunderscoring the importance of multimodal integration, model calibration, and\ndomain adaptation for clinical translation.",
      "pdf_url": "http://arxiv.org/pdf/2510.02922v1",
      "published": "2025-10-03T11:48:12+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.02922v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "WavInWav: Time-domain Speech Hiding via Invertible Neural Network",
      "authors": [
        "Wei Fan",
        "Kejiang Chen",
        "Xiangkun Wang",
        "Weiming Zhang",
        "Nenghai Yu"
      ],
      "abstract": "Data hiding is essential for secure communication across digital media, and\nrecent advances in Deep Neural Networks (DNNs) provide enhanced methods for\nembedding secret information effectively. However, previous audio hiding\nmethods often result in unsatisfactory quality when recovering secret audio,\ndue to their inherent limitations in the modeling of time-frequency\nrelationships. In this paper, we explore these limitations and introduce a new\nDNN-based approach. We use a flow-based invertible neural network to establish\na direct link between stego audio, cover audio, and secret audio, enhancing the\nreversibility of embedding and extracting messages. To address common issues\nfrom time-frequency transformations that degrade secret audio quality during\nrecovery, we implement a time-frequency loss on the time-domain signal. This\napproach not only retains the benefits of time-frequency constraints but also\nenhances the reversibility of message recovery, which is vital for practical\napplications. We also add an encryption technique to protect the hidden data\nfrom unauthorized access. Experimental results on the VCTK and LibriSpeech\ndatasets demonstrate that our method outperforms previous approaches in terms\nof subjective and objective metrics and exhibits robustness to various types of\nnoise, suggesting its utility in targeted secure communication scenarios.",
      "pdf_url": "http://arxiv.org/pdf/2510.02915v1",
      "published": "2025-10-03T11:36:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.02915v1",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CR",
        "cs.LG",
        "eess.AS"
      ]
    },
    {
      "title": "FeDABoost: Fairness Aware Federated Learning with Adaptive Boosting",
      "authors": [
        "Tharuka Kasthuri Arachchige",
        "Veselka Boeva",
        "Shahrooz Abghari"
      ],
      "abstract": "This work focuses on improving the performance and fairness of Federated\nLearning (FL) in non IID settings by enhancing model aggregation and boosting\nthe training of underperforming clients. We propose FeDABoost, a novel FL\nframework that integrates a dynamic boosting mechanism and an adaptive gradient\naggregation strategy. Inspired by the weighting mechanism of the Multiclass\nAdaBoost (SAMME) algorithm, our aggregation method assigns higher weights to\nclients with lower local error rates, thereby promoting more reliable\ncontributions to the global model. In parallel, FeDABoost dynamically boosts\nunderperforming clients by adjusting the focal loss focusing parameter,\nemphasizing hard to classify examples during local training. We have evaluated\nFeDABoost on three benchmark datasets MNIST, FEMNIST, and CIFAR10, and compared\nits performance with those of FedAvg and Ditto. The results show that FeDABoost\nachieves improved fairness and competitive performance.",
      "pdf_url": "http://arxiv.org/pdf/2510.02914v1",
      "published": "2025-10-03T11:36:08+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.02914v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "FinReflectKG -- MultiHop: Financial QA Benchmark for Reasoning with Knowledge Graph Evidence",
      "authors": [
        "Abhinav Arun",
        "Reetu Raj Harsh",
        "Bhaskarjit Sarmah",
        "Stefano Pasquali"
      ],
      "abstract": "Multi-hop reasoning over financial disclosures is often a retrieval problem\nbefore it becomes a reasoning or generation problem: relevant facts are\ndispersed across sections, filings, companies, and years, and LLMs often expend\nexcessive tokens navigating noisy context. Without precise Knowledge Graph\n(KG)-guided selection of relevant context, even strong reasoning models either\nfail to answer or consume excessive tokens, whereas KG-linked evidence enables\nmodels to focus their reasoning on composing already retrieved facts. We\npresent FinReflectKG - MultiHop, a benchmark built on FinReflectKG, a\ntemporally indexed financial KG that links audited triples to source chunks\nfrom S&P 100 filings (2022-2024). Mining frequent 2-3 hop subgraph patterns\nacross sectors (via GICS taxonomy), we generate financial analyst style\nquestions with exact supporting evidence from the KG. A two-phase pipeline\nfirst creates QA pairs via pattern-specific prompts, followed by a\nmulti-criteria quality control evaluation to ensure QA validity. We then\nevaluate three controlled retrieval scenarios: (S1) precise KG-linked paths;\n(S2) text-only page windows centered on relevant text spans; and (S3) relevant\npage windows with randomizations and distractors. Across both reasoning and\nnon-reasoning models, KG-guided precise retrieval yields substantial gains on\nthe FinReflectKG - MultiHop QA benchmark dataset, boosting correctness scores\nby approximately 24 percent while reducing token utilization by approximately\n84.5 percent compared to the page window setting, which reflects the\ntraditional vector retrieval paradigm. Spanning intra-document, inter-year, and\ncross-company scopes, our work underscores the pivotal role of knowledge graphs\nin efficiently connecting evidence for multi-hop financial QA. We also release\na curated subset of the benchmark (555 QA Pairs) to catalyze further research.",
      "pdf_url": "http://arxiv.org/pdf/2510.02906v1",
      "published": "2025-10-03T11:19:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.02906v1",
      "categories": [
        "q-fin.CP",
        "cs.AI"
      ]
    },
    {
      "title": "DMark: Order-Agnostic Watermarking for Diffusion Large Language Models",
      "authors": [
        "Linyu Wu",
        "Linhao Zhong",
        "Wenjie Qu",
        "Yuexin Li",
        "Yue Liu",
        "Shengfang Zhai",
        "Chunhua Shen",
        "Jiaheng Zhang"
      ],
      "abstract": "Diffusion large language models (dLLMs) offer faster generation than\nautoregressive models while maintaining comparable quality, but existing\nwatermarking methods fail on them due to their non-sequential decoding. Unlike\nautoregressive models that generate tokens left-to-right, dLLMs can finalize\ntokens in arbitrary order, breaking the causal design underlying traditional\nwatermarks. We present DMark, the first watermarking framework designed\nspecifically for dLLMs. DMark introduces three complementary strategies to\nrestore watermark detectability: predictive watermarking uses model-predicted\ntokens when actual context is unavailable; bidirectional watermarking exploits\nboth forward and backward dependencies unique to diffusion decoding; and\npredictive-bidirectional watermarking combines both approaches to maximize\ndetection strength. Experiments across multiple dLLMs show that DMark achieves\n92.0-99.5% detection rates at 1% false positive rate while maintaining text\nquality, compared to only 49.6-71.2% for naive adaptations of existing methods.\nDMark also demonstrates robustness against text manipulations, establishing\nthat effective watermarking is feasible for non-autoregressive language models.",
      "pdf_url": "http://arxiv.org/pdf/2510.02902v1",
      "published": "2025-10-03T11:14:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.02902v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ]
    },
    {
      "title": "Global Convergence of Policy Gradient for Entropy Regularized Linear-Quadratic Control with multiplicative noise",
      "authors": [
        "Gabriel Diaz",
        "Lucky Li",
        "Wenhao Zhang"
      ],
      "abstract": "Reinforcement Learning (RL) has emerged as a powerful framework for\nsequential decision-making in dynamic environments, particularly when system\nparameters are unknown. This paper investigates RL-based control for\nentropy-regularized Linear Quadratic control (LQC) problems with multiplicative\nnoises over an infinite time horizon. First, we adapt the Regularized Policy\nGradient (RPG) algorithm to stochastic optimal control settings, proving that\ndespite the non-convexity of the problem, RPG converges globally under\nconditions of gradient domination and near-smoothness. Second, based on\nzero-order optimization approach, we introduce a novel model free RL algorithm:\nSample-Based Regularized Policy Gradient (SB-RPG). SB-RPG operates without\nknowledge of system parameters yet still retains strong theoretical guarantees\nof global convergence. Our model leverages entropy regularization to accelerate\nconvergence and address the exploration versus exploitation trade-off inherent\nin RL. Numerical simulations validate the theoretical results and demonstrate\nthe efficacy of SB-RPG in unknown-parameters environments.",
      "pdf_url": "http://arxiv.org/pdf/2510.02896v1",
      "published": "2025-10-03T11:03:12+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.02896v1",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY",
        "37N35, 49N10"
      ]
    },
    {
      "title": "Consolidating Reinforcement Learning for Multimodal Discrete Diffusion Models",
      "authors": [
        "Tianren Ma",
        "Mu Zhang",
        "Yibing Wang",
        "Qixiang Ye"
      ],
      "abstract": "Optimizing discrete diffusion model (DDM) with rewards remains a challenge:\nthe non-autoregressive paradigm makes importance sampling intractable and\nrollout complex, puzzling reinforcement learning methods such as Group Relative\nPolicy Optimization (GRPO). In this study, we introduce MaskGRPO, the first\nviable approach to enable scalable multimodal reinforcement learning in\ndiscrete diffusion with effective importance sampling and modality-specific\nadaptations. To this end, we first clarify the theoretical foundation for DDMs,\nwhich facilitates building an importance estimator that captures valuable token\nfluctuation for gradient updates. We then delicately tailored the rollout\nmethod for visual sequences, which yields diverse completions and reliable\noptimization gradients. Upon math reasoning, coding, and visual generation\nbenchmarks, MaskGRPO brings more stable and efficient updates, leading to\nstronger reasoning performance and better generation quality. This study\nestablishes MaskGRPO as a systematic policy optimization approach and the first\npractical way for discretized visual diffusion.",
      "pdf_url": "http://arxiv.org/pdf/2510.02880v1",
      "published": "2025-10-03T10:36:24+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.02880v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Representing Beauty: Towards a Participatory but Objective Latent Aesthetics",
      "authors": [
        "Alexander Michael Rusnak"
      ],
      "abstract": "What does it mean for a machine to recognize beauty? While beauty remains a\nculturally and experientially compelling but philosophically elusive concept,\ndeep learning systems increasingly appear capable of modeling aesthetic\njudgment. In this paper, we explore the capacity of neural networks to\nrepresent beauty despite the immense formal diversity of objects for which the\nterm applies. By drawing on recent work on cross-model representational\nconvergence, we show how aesthetic content produces more similar and aligned\nrepresentations between models which have been trained on distinct data and\nmodalities - while unaesthetic images do not produce more aligned\nrepresentations. This finding implies that the formal structure of beautiful\nimages has a realist basis - rather than only as a reflection of socially\nconstructed values. Furthermore, we propose that these realist representations\nexist because of a joint grounding of aesthetic form in physical and cultural\nsubstance. We argue that human perceptual and creative acts play a central role\nin shaping these the latent spaces of deep learning systems, but that a realist\nbasis for aesthetics shows that machines are not mere creative parrots but can\nproduce novel creative insights from the unique vantage point of scale. Our\nfindings suggest that human-machine co-creation is not merely possible, but\nfoundational - with beauty serving as a teleological attractor in both cultural\nproduction and machine perception.",
      "pdf_url": "http://arxiv.org/pdf/2510.02869v1",
      "published": "2025-10-03T10:09:37+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.02869v1",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Constraint Satisfaction Approaches to Wordle: Novel Heuristics and Cross-Lexicon Validation",
      "authors": [
        "Jahidul Arafat",
        "Fariha Tasmin",
        "Sanjaya Poudel",
        "Kamrujjaman",
        "Eftakhar Ahmed Arnob",
        "Ahsan Habib Tareq"
      ],
      "abstract": "Wordle presents an algorithmically rich testbed for constraint satisfaction\nproblem (CSP) solving. While existing solvers rely on information-theoretic\nentropy maximization or frequency-based heuristics without formal constraint\ntreatment, we present the first comprehensive CSP formulation of Wordle with\nnovel constraint-aware solving strategies. We introduce CSP-Aware Entropy,\ncomputing information gain after constraint propagation rather than on raw\ncandidate sets, and a Probabilistic CSP framework integrating Bayesian\nword-frequency priors with logical constraints. Through evaluation on 2,315\nEnglish words, CSP-Aware Entropy achieves 3.54 average guesses with 99.9%\nsuccess rate, a statistically significant 1.7% improvement over Forward\nChecking (t=-4.82, p<0.001, Cohen's d=0.07) with 46% faster runtime (12.9ms\nversus 23.7ms per guess). Under 10% noise, CSP-aware approaches maintain 5.3\npercentage point advantages (29.0% versus 23.7%, p=0.041), while Probabilistic\nCSP achieves 100% success across all noise levels (0-20%) through constraint\nrecovery mechanisms. Cross-lexicon validation on 500 Spanish words demonstrates\n88% success with zero language-specific tuning, validating that core CSP\nprinciples transfer across languages despite an 11.2 percentage point gap from\nlinguistic differences (p<0.001, Fisher's exact test). Our open-source\nimplementation with 34 unit tests achieving 91% code coverage provides\nreproducible infrastructure for CSP research. The combination of formal CSP\ntreatment, constraint-aware heuristics, probabilistic-logical integration,\nrobustness analysis, and cross-lexicon validation establishes new performance\nbenchmarks demonstrating that principled constraint satisfaction techniques\noutperform classical information-theoretic and learning-based approaches for\nstructured puzzle-solving domains.",
      "pdf_url": "http://arxiv.org/pdf/2510.02855v1",
      "published": "2025-10-03T09:44:14+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.02855v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "68T20, 90C27",
        "I.2.8; I.2.3; G.1.6"
      ]
    },
    {
      "title": "Reward Model Routing in Alignment",
      "authors": [
        "Xinle Wu",
        "Yao Lu"
      ],
      "abstract": "Reinforcement learning from human or AI feedback (RLHF / RLAIF) has become\nthe standard paradigm for aligning large language models (LLMs). However, most\npipelines rely on a single reward model (RM), limiting alignment quality and\nrisking overfitting. Recent work explores RM routing--dynamically selecting an\nRM from a candidate pool to exploit complementary strengths while maintaining\n$O(1)$ RM calls--but existing methods suffer from cold-start and insufficient\nexploration. We propose BayesianRouter, a hybrid routing framework that\ncombines offline RM strengths learning with online Bayesian selection. In the\noffline stage, a multi-task router is trained on preference data to estimate\nper-RM reliability. In the online stage, a Bayesian Thompson sampling router\nperforms per-query RM selection, initializing RM-specific weight vectors with\noffline embeddings as Gaussian priors and adaptively updating their posteriors\nwith online rewards to adapt to the evolving policy distribution. Extensive\nexperiments on instruction-following (AlpacaEval-2, Arena-Hard, MT-Bench) and\nreasoning (GSM8K, MMLU) benchmarks show that BayesianRouter consistently\noutperforms individual RMs, RM ensembling, and existing routing methods.",
      "pdf_url": "http://arxiv.org/pdf/2510.02850v1",
      "published": "2025-10-03T09:37:59+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.02850v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Flamed-TTS: Flow Matching Attention-Free Models for Efficient Generating and Dynamic Pacing Zero-shot Text-to-Speech",
      "authors": [
        "Hieu-Nghia Huynh-Nguyen",
        "Huynh Nguyen Dang",
        "Ngoc-Son Nguyen",
        "Van Nguyen"
      ],
      "abstract": "Zero-shot Text-to-Speech (TTS) has recently advanced significantly, enabling\nmodels to synthesize speech from text using short, limited-context prompts.\nThese prompts serve as voice exemplars, allowing the model to mimic speaker\nidentity, prosody, and other traits without extensive speaker-specific data.\nAlthough recent approaches incorporating language models, diffusion, and flow\nmatching have proven their effectiveness in zero-shot TTS, they still encounter\nchallenges such as unreliable synthesis caused by token repetition or\nunexpected content transfer, along with slow inference and substantial\ncomputational overhead. Moreover, temporal diversity-crucial for enhancing the\nnaturalness of synthesized speech-remains largely underexplored. To address\nthese challenges, we propose Flamed-TTS, a novel zero-shot TTS framework that\nemphasizes low computational cost, low latency, and high speech fidelity\nalongside rich temporal diversity. To achieve this, we reformulate the flow\nmatching training paradigm and incorporate both discrete and continuous\nrepresentations corresponding to different attributes of speech. Experimental\nresults demonstrate that Flamed-TTS surpasses state-of-the-art models in terms\nof intelligibility, naturalness, speaker similarity, acoustic characteristics\npreservation, and dynamic pace. Notably, Flamed-TTS achieves the best WER of 4%\ncompared to the leading zero-shot TTS baselines, while maintaining low latency\nin inference and high fidelity in generated speech. Code and audio samples are\navailable at our demo page https://flamed-tts.github.io.",
      "pdf_url": "http://arxiv.org/pdf/2510.02848v1",
      "published": "2025-10-03T09:36:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.02848v1",
      "categories": [
        "cs.SD",
        "cs.AI"
      ]
    },
    {
      "title": "Take Goodhart Seriously: Principled Limit on General-Purpose AI Optimization",
      "authors": [
        "Antoine Maier",
        "Aude Maier",
        "Tom David"
      ],
      "abstract": "A common but rarely examined assumption in machine learning is that training\nyields models that actually satisfy their specified objective function. We call\nthis the Objective Satisfaction Assumption (OSA). Although deviations from OSA\nare acknowledged, their implications are overlooked. We argue, in a\nlearning-paradigm-agnostic framework, that OSA fails in realistic conditions:\napproximation, estimation, and optimization errors guarantee systematic\ndeviations from the intended objective, regardless of the quality of its\nspecification. Beyond these technical limitations, perfectly capturing and\ntranslating the developer's intent, such as alignment with human preferences,\ninto a formal objective is practically impossible, making misspecification\ninevitable. Building on recent mathematical results, absent a mathematical\ncharacterization of these gaps, they are indistinguishable from those that\ncollapse into Goodhart's law failure modes under strong optimization pressure.\nBecause the Goodhart breaking point cannot be located ex ante, a principled\nlimit on the optimization of General-Purpose AI systems is necessary. Absent\nsuch a limit, continued optimization is liable to push systems into predictable\nand irreversible loss of control.",
      "pdf_url": "http://arxiv.org/pdf/2510.02840v1",
      "published": "2025-10-03T09:25:12+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.02840v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Knowledge-Aware Modeling with Frequency Adaptive Learning for Battery Health Prognostics",
      "authors": [
        "Vijay Babu Pamshetti",
        "Wei Zhang",
        "Sumei Sun",
        "Jie Zhang",
        "Yonggang Wen",
        "Qingyu Yan"
      ],
      "abstract": "Battery health prognostics are critical for ensuring safety, efficiency, and\nsustainability in modern energy systems. However, it has been challenging to\nachieve accurate and robust prognostics due to complex battery degradation\nbehaviors with nonlinearity, noise, capacity regeneration, etc. Existing\ndata-driven models capture temporal degradation features but often lack\nknowledge guidance, which leads to unreliable long-term health prognostics. To\novercome these limitations, we propose Karma, a knowledge-aware model with\nfrequency-adaptive learning for battery capacity estimation and remaining\nuseful life prediction. The model first performs signal decomposition to derive\nbattery signals in different frequency bands. A dual-stream deep learning\narchitecture is developed, where one stream captures long-term low-frequency\ndegradation trends and the other models high-frequency short-term dynamics.\nKarma regulates the prognostics with knowledge, where battery degradation is\nmodeled as a double exponential function based on empirical studies. Our\ndual-stream model is used to optimize the parameters of the knowledge with\nparticle filters to ensure physically consistent and reliable prognostics and\nuncertainty quantification. Experimental study demonstrates Karma's superior\nperformance, achieving average error reductions of 50.6% and 32.6% over\nstate-of-the-art algorithms for battery health prediction on two mainstream\ndatasets, respectively. These results highlight Karma's robustness,\ngeneralizability, and potential for safer and more reliable battery management\nacross diverse applications.",
      "pdf_url": "http://arxiv.org/pdf/2510.02839v1",
      "published": "2025-10-03T09:24:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2510.02839v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    }
  ]
}