{
  "last_updated": "2025-05-29T00:52:36.563264",
  "papers": [
    {
      "title": "How does Alignment Enhance LLMs' Multilingual Capabilities? A Language Neurons Perspective",
      "authors": [
        "Shimao Zhang",
        "Zhejian Lai",
        "Xiang Liu",
        "Shuaijie She",
        "Xiao Liu",
        "Yeyun Gong",
        "Shujian Huang",
        "Jiajun Chen"
      ],
      "abstract": "Multilingual Alignment is an effective and representative paradigm to enhance\nLLMs' multilingual capabilities, which transfers the capabilities from the\nhigh-resource languages to the low-resource languages. Meanwhile, some\nresearches on language-specific neurons reveal that there are language-specific\nneurons that are selectively activated in LLMs when processing different\nlanguages. This provides a new perspective to analyze and understand LLMs'\nmechanisms more specifically in multilingual scenarios. In this work, we\npropose a new finer-grained neuron identification algorithm, which detects\nlanguage neurons~(including language-specific neurons and language-related\nneurons) and language-agnostic neurons. Furthermore, based on the\ndistributional characteristics of different types of neurons, we divide the\nLLMs' internal process for multilingual inference into four parts: (1)\nmultilingual understanding, (2) shared semantic space reasoning, (3)\nmultilingual output space transformation, and (4) vocabulary space outputting.\nAdditionally, we systematically analyze the models before and after alignment\nwith a focus on different types of neurons. We also analyze the phenomenon of\n''Spontaneous Multilingual Alignment''. Overall, our work conducts a\ncomprehensive investigation based on different types of neurons, providing\nempirical results and valuable insights for better understanding multilingual\nalignment and multilingual capabilities of LLMs.",
      "pdf_url": "http://arxiv.org/pdf/2505.21505v1",
      "published": "2025-05-27T17:59:52+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.21505v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Silence is Not Consensus: Disrupting Agreement Bias in Multi-Agent LLMs via Catfish Agent for Clinical Decision Making",
      "authors": [
        "Yihan Wang",
        "Qiao Yan",
        "Zhenghao Xing",
        "Lihao Liu",
        "Junjun He",
        "Chi-Wing Fu",
        "Xiaowei Hu",
        "Pheng-Ann Heng"
      ],
      "abstract": "Large language models (LLMs) have demonstrated strong potential in clinical\nquestion answering, with recent multi-agent frameworks further improving\ndiagnostic accuracy via collaborative reasoning. However, we identify a\nrecurring issue of Silent Agreement, where agents prematurely converge on\ndiagnoses without sufficient critical analysis, particularly in complex or\nambiguous cases. We present a new concept called Catfish Agent, a\nrole-specialized LLM designed to inject structured dissent and counter silent\nagreement. Inspired by the ``catfish effect'' in organizational psychology, the\nCatfish Agent is designed to challenge emerging consensus to stimulate deeper\nreasoning. We formulate two mechanisms to encourage effective and context-aware\ninterventions: (i) a complexity-aware intervention that modulates agent\nengagement based on case difficulty, and (ii) a tone-calibrated intervention\narticulated to balance critique and collaboration. Evaluations on nine medical\nQ&A and three medical VQA benchmarks show that our approach consistently\noutperforms both single- and multi-agent LLMs frameworks, including leading\ncommercial models such as GPT-4o and DeepSeek-R1.",
      "pdf_url": "http://arxiv.org/pdf/2505.21503v1",
      "published": "2025-05-27T17:59:50+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.21503v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "q-bio.OT"
      ]
    },
    {
      "title": "ViewSpatial-Bench: Evaluating Multi-perspective Spatial Localization in Vision-Language Models",
      "authors": [
        "Dingming Li",
        "Hongxing Li",
        "Zixuan Wang",
        "Yuchen Yan",
        "Hang Zhang",
        "Siqi Chen",
        "Guiyang Hou",
        "Shengpei Jiang",
        "Wenqi Zhang",
        "Yongliang Shen",
        "Weiming Lu",
        "Yueting Zhuang"
      ],
      "abstract": "Vision-language models (VLMs) have demonstrated remarkable capabilities in\nunderstanding and reasoning about visual content, but significant challenges\npersist in tasks requiring cross-viewpoint understanding and spatial reasoning.\nWe identify a critical limitation: current VLMs excel primarily at egocentric\nspatial reasoning (from the camera's perspective) but fail to generalize to\nallocentric viewpoints when required to adopt another entity's spatial frame of\nreference. We introduce ViewSpatial-Bench, the first comprehensive benchmark\ndesigned specifically for multi-viewpoint spatial localization recognition\nevaluation across five distinct task types, supported by an automated 3D\nannotation pipeline that generates precise directional labels. Comprehensive\nevaluation of diverse VLMs on ViewSpatial-Bench reveals a significant\nperformance disparity: models demonstrate reasonable performance on\ncamera-perspective tasks but exhibit reduced accuracy when reasoning from a\nhuman viewpoint. By fine-tuning VLMs on our multi-perspective spatial dataset,\nwe achieve an overall performance improvement of 46.24% across tasks,\nhighlighting the efficacy of our approach. Our work establishes a crucial\nbenchmark for spatial intelligence in embodied AI systems and provides\nempirical evidence that modeling 3D spatial relationships enhances VLMs'\ncorresponding spatial comprehension capabilities.",
      "pdf_url": "http://arxiv.org/pdf/2505.21500v1",
      "published": "2025-05-27T17:59:26+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.21500v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "AdInject: Real-World Black-Box Attacks on Web Agents via Advertising Delivery",
      "authors": [
        "Haowei Wang",
        "Junjie Wang",
        "Xiaojun Jia",
        "Rupeng Zhang",
        "Mingyang Li",
        "Zhe Liu",
        "Yang Liu",
        "Qing Wang"
      ],
      "abstract": "Vision-Language Model (VLM) based Web Agents represent a significant step\ntowards automating complex tasks by simulating human-like interaction with\nwebsites. However, their deployment in uncontrolled web environments introduces\nsignificant security vulnerabilities. Existing research on adversarial\nenvironmental injection attacks often relies on unrealistic assumptions, such\nas direct HTML manipulation, knowledge of user intent, or access to agent model\nparameters, limiting their practical applicability. In this paper, we propose\nAdInject, a novel and real-world black-box attack method that leverages the\ninternet advertising delivery to inject malicious content into the Web Agent's\nenvironment. AdInject operates under a significantly more realistic threat\nmodel than prior work, assuming a black-box agent, static malicious content\nconstraints, and no specific knowledge of user intent. AdInject includes\nstrategies for designing malicious ad content aimed at misleading agents into\nclicking, and a VLM-based ad content optimization technique that infers\npotential user intents from the target website's context and integrates these\nintents into the ad content to make it appear more relevant or critical to the\nagent's task, thus enhancing attack effectiveness. Experimental evaluations\ndemonstrate the effectiveness of AdInject, attack success rates exceeding 60%\nin most scenarios and approaching 100% in certain cases. This strongly\ndemonstrates that prevalent advertising delivery constitutes a potent and\nreal-world vector for environment injection attacks against Web Agents. This\nwork highlights a critical vulnerability in Web Agent security arising from\nreal-world environment manipulation channels, underscoring the urgent need for\ndeveloping robust defense mechanisms against such threats. Our code is\navailable at https://github.com/NicerWang/AdInject.",
      "pdf_url": "http://arxiv.org/pdf/2505.21499v1",
      "published": "2025-05-27T17:59:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.21499v1",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "title": "Paper2Poster: Towards Multimodal Poster Automation from Scientific Papers",
      "authors": [
        "Wei Pang",
        "Kevin Qinghong Lin",
        "Xiangru Jian",
        "Xi He",
        "Philip Torr"
      ],
      "abstract": "Academic poster generation is a crucial yet challenging task in scientific\ncommunication, requiring the compression of long-context interleaved documents\ninto a single, visually coherent page. To address this challenge, we introduce\nthe first benchmark and metric suite for poster generation, which pairs recent\nconference papers with author-designed posters and evaluates outputs on\n(i)Visual Quality-semantic alignment with human posters, (ii)Textual\nCoherence-language fluency, (iii)Holistic Assessment-six fine-grained aesthetic\nand informational criteria scored by a VLM-as-judge, and notably\n(iv)PaperQuiz-the poster's ability to convey core paper content as measured by\nVLMs answering generated quizzes. Building on this benchmark, we propose\nPosterAgent, a top-down, visual-in-the-loop multi-agent pipeline: the (a)Parser\ndistills the paper into a structured asset library; the (b)Planner aligns\ntext-visual pairs into a binary-tree layout that preserves reading order and\nspatial balance; and the (c)Painter-Commenter loop refines each panel by\nexecuting rendering code and using VLM feedback to eliminate overflow and\nensure alignment. In our comprehensive evaluation, we find that GPT-4o\noutputs-though visually appealing at first glance-often exhibit noisy text and\npoor PaperQuiz scores, and we find that reader engagement is the primary\naesthetic bottleneck, as human-designed posters rely largely on visual\nsemantics to convey meaning. Our fully open-source variants (e.g. based on the\nQwen-2.5 series) outperform existing 4o-driven multi-agent systems across\nnearly all metrics, while using 87% fewer tokens. It transforms a 22-page paper\ninto a finalized yet editable .pptx poster - all for just $0.005. These\nfindings chart clear directions for the next generation of fully automated\nposter-generation models. The code and datasets are available at\nhttps://github.com/Paper2Poster/Paper2Poster.",
      "pdf_url": "http://arxiv.org/pdf/2505.21497v1",
      "published": "2025-05-27T17:58:49+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.21497v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.MA"
      ]
    },
    {
      "title": "Be Decisive: Noise-Induced Layouts for Multi-Subject Generation",
      "authors": [
        "Omer Dahary",
        "Yehonathan Cohen",
        "Or Patashnik",
        "Kfir Aberman",
        "Daniel Cohen-Or"
      ],
      "abstract": "Generating multiple distinct subjects remains a challenge for existing\ntext-to-image diffusion models. Complex prompts often lead to subject leakage,\ncausing inaccuracies in quantities, attributes, and visual features. Preventing\nleakage among subjects necessitates knowledge of each subject's spatial\nlocation. Recent methods provide these spatial locations via an external layout\ncontrol. However, enforcing such a prescribed layout often conflicts with the\ninnate layout dictated by the sampled initial noise, leading to misalignment\nwith the model's prior. In this work, we introduce a new approach that predicts\na spatial layout aligned with the prompt, derived from the initial noise, and\nrefines it throughout the denoising process. By relying on this noise-induced\nlayout, we avoid conflicts with externally imposed layouts and better preserve\nthe model's prior. Our method employs a small neural network to predict and\nrefine the evolving noise-induced layout at each denoising step, ensuring clear\nboundaries between subjects while maintaining consistency. Experimental results\nshow that this noise-aligned strategy achieves improved text-image alignment\nand more stable multi-subject generation compared to existing layout-guided\ntechniques, while preserving the rich diversity of the model's original\ndistribution.",
      "pdf_url": "http://arxiv.org/pdf/2505.21488v1",
      "published": "2025-05-27T17:54:24+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.21488v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG"
      ]
    },
    {
      "title": "Robust Hypothesis Generation: LLM-Automated Language Bias for Inductive Logic Programming",
      "authors": [
        "Yang Yang",
        "Jiemin Wu",
        "Yutao Yue"
      ],
      "abstract": "Automating robust hypothesis generation in open environments is pivotal for\nAI cognition. We introduce a novel framework integrating a multi-agent system,\npowered by Large Language Models (LLMs), with Inductive Logic Programming\n(ILP). Our system's LLM agents autonomously define a structured symbolic\nvocabulary (predicates) and relational templates , i.e., \\emph{language bias}\ndirectly from raw textual data. This automated symbolic grounding (the\nconstruction of the language bias), traditionally an expert-driven bottleneck\nfor ILP, then guides the transformation of text into facts for an ILP solver,\nwhich inductively learns interpretable rules. This approach overcomes\ntraditional ILP's reliance on predefined symbolic structures and the\nnoise-sensitivity of pure LLM methods. Extensive experiments in diverse,\nchallenging scenarios validate superior performance, paving a new path for\nautomated, explainable, and verifiable hypothesis generation.",
      "pdf_url": "http://arxiv.org/pdf/2505.21486v1",
      "published": "2025-05-27T17:53:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.21486v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Policy Optimized Text-to-Image Pipeline Design",
      "authors": [
        "Uri Gadot",
        "Rinon Gal",
        "Yftah Ziser",
        "Gal Chechik",
        "Shie Mannor"
      ],
      "abstract": "Text-to-image generation has evolved beyond single monolithic models to\ncomplex multi-component pipelines. These combine fine-tuned generators,\nadapters, upscaling blocks and even editing steps, leading to significant\nimprovements in image quality. However, their effective design requires\nsubstantial expertise. Recent approaches have shown promise in automating this\nprocess through large language models (LLMs), but they suffer from two critical\nlimitations: extensive computational requirements from generating images with\nhundreds of predefined pipelines, and poor generalization beyond memorized\ntraining examples. We introduce a novel reinforcement learning-based framework\nthat addresses these inefficiencies. Our approach first trains an ensemble of\nreward models capable of predicting image quality scores directly from\nprompt-workflow combinations, eliminating the need for costly image generation\nduring training. We then implement a two-phase training strategy: initial\nworkflow vocabulary training followed by GRPO-based optimization that guides\nthe model toward higher-performing regions of the workflow space. Additionally,\nwe incorporate a classifier-free guidance based enhancement technique that\nextrapolates along the path between the initial and GRPO-tuned models, further\nimproving output quality. We validate our approach through a set of\ncomparisons, showing that it can successfully create new flows with greater\ndiversity and lead to superior image quality compared to existing baselines.",
      "pdf_url": "http://arxiv.org/pdf/2505.21478v1",
      "published": "2025-05-27T17:50:47+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.21478v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "LazyVLM: Neuro-Symbolic Approach to Video Analytics",
      "authors": [
        "Xiangru Jian",
        "Wei Pang",
        "Zhengyuan Dong",
        "Chao Zhang",
        "M. Tamer Özsu"
      ],
      "abstract": "Current video analytics approaches face a fundamental trade-off between\nflexibility and efficiency. End-to-end Vision Language Models (VLMs) often\nstruggle with long-context processing and incur high computational costs, while\nneural-symbolic methods depend heavily on manual labeling and rigid rule\ndesign. In this paper, we introduce LazyVLM, a neuro-symbolic video analytics\nsystem that provides a user-friendly query interface similar to VLMs, while\naddressing their scalability limitation. LazyVLM enables users to effortlessly\ndrop in video data and specify complex multi-frame video queries using a\nsemi-structured text interface for video analytics. To address the scalability\nlimitations of VLMs, LazyVLM decomposes multi-frame video queries into\nfine-grained operations and offloads the bulk of the processing to efficient\nrelational query execution and vector similarity search. We demonstrate that\nLazyVLM provides a robust, efficient, and user-friendly solution for querying\nopen-domain video data at scale.",
      "pdf_url": "http://arxiv.org/pdf/2505.21459v1",
      "published": "2025-05-27T17:31:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.21459v1",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.CV",
        "cs.IR",
        "cs.MM"
      ]
    },
    {
      "title": "Active-O3: Empowering Multimodal Large Language Models with Active Perception via GRPO",
      "authors": [
        "Muzhi Zhu",
        "Hao Zhong",
        "Canyu Zhao",
        "Zongze Du",
        "Zheng Huang",
        "Mingyu Liu",
        "Hao Chen",
        "Cheng Zou",
        "Jingdong Chen",
        "Ming Yang",
        "Chunhua Shen"
      ],
      "abstract": "Active vision, also known as active perception, refers to the process of\nactively selecting where and how to look in order to gather task-relevant\ninformation. It is a critical component of efficient perception and\ndecision-making in humans and advanced embodied agents. Recently, the use of\nMultimodal Large Language Models (MLLMs) as central planning and\ndecision-making modules in robotic systems has gained extensive attention.\nHowever, despite the importance of active perception in embodied intelligence,\nthere is little to no exploration of how MLLMs can be equipped with or learn\nactive perception capabilities. In this paper, we first provide a systematic\ndefinition of MLLM-based active perception tasks. We point out that the\nrecently proposed GPT-o3 model's zoom-in search strategy can be regarded as a\nspecial case of active perception; however, it still suffers from low search\nefficiency and inaccurate region selection. To address these issues, we propose\nACTIVE-O3, a purely reinforcement learning based training framework built on\ntop of GRPO, designed to equip MLLMs with active perception capabilities. We\nfurther establish a comprehensive benchmark suite to evaluate ACTIVE-O3 across\nboth general open-world tasks, such as small-object and dense object grounding,\nand domain-specific scenarios, including small object detection in remote\nsensing and autonomous driving, as well as fine-grained interactive\nsegmentation. In addition, ACTIVE-O3 also demonstrates strong zero-shot\nreasoning abilities on the V* Benchmark, without relying on any explicit\nreasoning data. We hope that our work can provide a simple codebase and\nevaluation protocol to facilitate future research on active perception in\nMLLMs.",
      "pdf_url": "http://arxiv.org/pdf/2505.21457v1",
      "published": "2025-05-27T17:29:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.21457v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "VoxAging: Continuously Tracking Speaker Aging with a Large-Scale Longitudinal Dataset in English and Mandarin",
      "authors": [
        "Zhiqi Ai",
        "Meixuan Bao",
        "Zhiyong Chen",
        "Zhi Yang",
        "Xinnuo Li",
        "Shugong Xu"
      ],
      "abstract": "The performance of speaker verification systems is adversely affected by\nspeaker aging. However, due to challenges in data collection, particularly the\nlack of sustained and large-scale longitudinal data for individuals, research\non speaker aging remains difficult. In this paper, we present VoxAging, a\nlarge-scale longitudinal dataset collected from 293 speakers (226 English\nspeakers and 67 Mandarin speakers) over several years, with the longest time\nspan reaching 17 years (approximately 900 weeks). For each speaker, the data\nwere recorded at weekly intervals. We studied the phenomenon of speaker aging\nand its effects on advanced speaker verification systems, analyzed individual\nspeaker aging processes, and explored the impact of factors such as age group\nand gender on speaker aging research.",
      "pdf_url": "http://arxiv.org/pdf/2505.21445v1",
      "published": "2025-05-27T17:16:59+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.21445v1",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CV",
        "cs.MM"
      ]
    },
    {
      "title": "Autoencoding Random Forests",
      "authors": [
        "Binh Duc Vu",
        "Jan Kapar",
        "Marvin Wright",
        "David S. Watson"
      ],
      "abstract": "We propose a principled method for autoencoding with random forests. Our\nstrategy builds on foundational results from nonparametric statistics and\nspectral graph theory to learn a low-dimensional embedding of the model that\noptimally represents relationships in the data. We provide exact and\napproximate solutions to the decoding problem via constrained optimization,\nsplit relabeling, and nearest neighbors regression. These methods effectively\ninvert the compression pipeline, establishing a map from the embedding space\nback to the input space using splits learned by the ensemble's constituent\ntrees. The resulting decoders are universally consistent under common\nregularity assumptions. The procedure works with supervised or unsupervised\nmodels, providing a window into conditional or joint distributions. We\ndemonstrate various applications of this autoencoder, including powerful new\ntools for visualization, compression, clustering, and denoising. Experiments\nillustrate the ease and utility of our method in a wide range of settings,\nincluding tabular, image, and genomic data.",
      "pdf_url": "http://arxiv.org/pdf/2505.21441v1",
      "published": "2025-05-27T17:15:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.21441v1",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Hume: Introducing System-2 Thinking in Visual-Language-Action Model",
      "authors": [
        "Haoming Song",
        "Delin Qu",
        "Yuanqi Yao",
        "Qizhi Chen",
        "Qi Lv",
        "Yiwen Tang",
        "Modi Shi",
        "Guanghui Ren",
        "Maoqing Yao",
        "Bin Zhao",
        "Dong Wang",
        "Xuelong Li"
      ],
      "abstract": "Humans practice slow thinking before performing actual actions when handling\ncomplex tasks in the physical world. This thinking paradigm, recently, has\nachieved remarkable advancement in boosting Large Language Models (LLMs) to\nsolve complex tasks in digital domains. However, the potential of slow thinking\nremains largely unexplored for robotic foundation models interacting with the\nphysical world. In this work, we propose Hume: a dual-system\nVision-Language-Action (VLA) model with value-guided System-2 thinking and\ncascaded action denoising, exploring human-like thinking capabilities of\nVision-Language-Action models for dexterous robot control. System 2 of Hume\nimplements value-Guided thinking by extending a Vision-Language-Action Model\nbackbone with a novel value-query head to estimate the state-action value of\npredicted actions. The value-guided thinking is conducted by repeat sampling\nmultiple action candidates and selecting one according to state-action value.\nSystem 1 of Hume is a lightweight reactive visuomotor policy that takes System\n2 selected action and performs cascaded action denoising for dexterous robot\ncontrol. At deployment time, System 2 performs value-guided thinking at a low\nfrequency while System 1 asynchronously receives the System 2 selected action\ncandidate and predicts fluid actions in real time. We show that Hume\noutperforms the existing state-of-the-art Vision-Language-Action models across\nmultiple simulation benchmark and real-robot deployments.",
      "pdf_url": "http://arxiv.org/pdf/2505.21432v1",
      "published": "2025-05-27T17:04:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.21432v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "Policy Induction: Predicting Startup Success via Explainable Memory-Augmented In-Context Learning",
      "authors": [
        "Xianling Mu",
        "Joseph Ternasky",
        "Fuat Alican",
        "Yigit Ihlamur"
      ],
      "abstract": "Early-stage startup investment is a high-risk endeavor characterized by\nscarce data and uncertain outcomes. Traditional machine learning approaches\noften require large, labeled datasets and extensive fine-tuning, yet remain\nopaque and difficult for domain experts to interpret or improve. In this paper,\nwe propose a transparent and data-efficient investment decision framework\npowered by memory-augmented large language models (LLMs) using in-context\nlearning (ICL). Central to our method is a natural language policy embedded\ndirectly into the LLM prompt, enabling the model to apply explicit reasoning\npatterns and allowing human experts to easily interpret, audit, and iteratively\nrefine the logic. We introduce a lightweight training process that combines\nfew-shot learning with an in-context learning loop, enabling the LLM to update\nits decision policy iteratively based on structured feedback. With only minimal\nsupervision and no gradient-based optimization, our system predicts startup\nsuccess far more accurately than existing benchmarks. It is over 20x more\nprecise than random chance, which succeeds 1.9% of the time. It is also 7.1x\nmore precise than the typical 5.6% success rate of top-tier venture capital\n(VC) firms.",
      "pdf_url": "http://arxiv.org/pdf/2505.21427v1",
      "published": "2025-05-27T16:57:07+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.21427v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Learning Individual Behavior in Agent-Based Models with Graph Diffusion Networks",
      "authors": [
        "Francesco Cozzi",
        "Marco Pangallo",
        "Alan Perotti",
        "André Panisson",
        "Corrado Monti"
      ],
      "abstract": "Agent-Based Models (ABMs) are powerful tools for studying emergent properties\nin complex systems. In ABMs, agent behaviors are governed by local interactions\nand stochastic rules. However, these rules are, in general, non-differentiable,\nlimiting the use of gradient-based methods for optimization, and thus\nintegration with real-world data. We propose a novel framework to learn a\ndifferentiable surrogate of any ABM by observing its generated data. Our method\ncombines diffusion models to capture behavioral stochasticity and graph neural\nnetworks to model agent interactions. Distinct from prior surrogate approaches,\nour method introduces a fundamental shift: rather than approximating\nsystem-level outputs, it models individual agent behavior directly, preserving\nthe decentralized, bottom-up dynamics that define ABMs. We validate our\napproach on two ABMs (Schelling's segregation model and a Predator-Prey\necosystem) showing that it replicates individual-level patterns and accurately\nforecasts emergent dynamics beyond training. Our results demonstrate the\npotential of combining diffusion models and graph learning for data-driven ABM\nsimulation.",
      "pdf_url": "http://arxiv.org/pdf/2505.21426v1",
      "published": "2025-05-27T16:55:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.21426v1",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.MA",
        "econ.EM",
        "physics.soc-ph"
      ]
    },
    {
      "title": "Mentor3AD: Feature Reconstruction-based 3D Anomaly Detection via Multi-modality Mentor Learning",
      "authors": [
        "Jinbao Wang",
        "Hanzhe Liang",
        "Can Gao",
        "Chenxi Hu",
        "Jie Zhou",
        "Yunkang Cao",
        "Linlin Shen",
        "Weiming Shen"
      ],
      "abstract": "Multimodal feature reconstruction is a promising approach for 3D anomaly\ndetection, leveraging the complementary information from dual modalities. We\nfurther advance this paradigm by utilizing multi-modal mentor learning, which\nfuses intermediate features to further distinguish normal from feature\ndifferences. To address these challenges, we propose a novel method called\nMentor3AD, which utilizes multi-modal mentor learning. By leveraging the shared\nfeatures of different modalities, Mentor3AD can extract more effective features\nand guide feature reconstruction, ultimately improving detection performance.\nSpecifically, Mentor3AD includes a Mentor of Fusion Module (MFM) that merges\nfeatures extracted from RGB and 3D modalities to create a mentor feature.\nAdditionally, we have designed a Mentor of Guidance Module (MGM) to facilitate\ncross-modal reconstruction, supported by the mentor feature. Lastly, we\nintroduce a Voting Module (VM) to more accurately generate the final anomaly\nscore. Extensive comparative and ablation studies on MVTec 3D-AD and Eyecandies\nhave verified the effectiveness of the proposed method.",
      "pdf_url": "http://arxiv.org/pdf/2505.21420v1",
      "published": "2025-05-27T16:46:28+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.21420v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Diagnosing and Resolving Cloud Platform Instability with Multi-modal RAG LLMs",
      "authors": [
        "Yifan Wang",
        "Kenneth P. Birman"
      ],
      "abstract": "Today's cloud-hosted applications and services are complex systems, and a\nperformance or functional instability can have dozens or hundreds of potential\nroot causes. Our hypothesis is that by combining the pattern matching\ncapabilities of modern AI tools with a natural multi-modal RAG LLM interface,\nproblem identification and resolution can be simplified. ARCA is a new\nmulti-modal RAG LLM system that targets this domain. Step-wise evaluations show\nthat ARCA outperforms state-of-the-art alternatives.",
      "pdf_url": "http://arxiv.org/pdf/2505.21419v2",
      "published": "2025-05-27T16:43:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.21419v2",
      "categories": [
        "cs.AI",
        "cs.OS"
      ]
    },
    {
      "title": "A Framework for Adversarial Analysis of Decision Support Systems Prior to Deployment",
      "authors": [
        "Brett Bissey",
        "Kyle Gatesman",
        "Walker Dimon",
        "Mohammad Alam",
        "Luis Robaina",
        "Joseph Weissman"
      ],
      "abstract": "This paper introduces a comprehensive framework designed to analyze and\nsecure decision-support systems trained with Deep Reinforcement Learning (DRL),\nprior to deployment, by providing insights into learned behavior patterns and\nvulnerabilities discovered through simulation. The introduced framework aids in\nthe development of precisely timed and targeted observation perturbations,\nenabling researchers to assess adversarial attack outcomes within a strategic\ndecision-making context. We validate our framework, visualize agent behavior,\nand evaluate adversarial outcomes within the context of a custom-built\nstrategic game, CyberStrike. Utilizing the proposed framework, we introduce a\nmethod for systematically discovering and ranking the impact of attacks on\nvarious observation indices and time-steps, and we conduct experiments to\nevaluate the transferability of adversarial attacks across agent architectures\nand DRL training algorithms. The findings underscore the critical need for\nrobust adversarial defense mechanisms to protect decision-making policies in\nhigh-stakes environments.",
      "pdf_url": "http://arxiv.org/pdf/2505.21414v1",
      "published": "2025-05-27T16:41:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.21414v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.GT"
      ]
    },
    {
      "title": "RefTool: Enhancing Model Reasoning with Reference-Guided Tool Creation",
      "authors": [
        "Xiao Liu",
        "Da Yin",
        "Zirui Wu",
        "Yansong Feng"
      ],
      "abstract": "Tools enhance the reasoning capabilities of large language models (LLMs) in\ncomplex problem-solving tasks, but not all tasks have available tools. In the\nabsence of predefined tools, prior works have explored instructing LLMs to\ngenerate tools on their own. However, such approaches rely heavily on the\nmodels' internal knowledge and would fail in domains beyond the LLMs' knowledge\nscope. To address this limitation, we propose RefTool, a reference-guided\nframework for automatic tool creation that leverages structured external\nmaterials such as textbooks. RefTool consists of two modules: (1) tool\ncreation, where LLMs generate executable tools from reference content, validate\nthem using illustrative examples, and organize them hierarchically into a\ntoolbox; and (2) tool utilization, where LLMs navigate the toolbox structure to\nselect and apply the appropriate tools to solve problems. Experiments on\ncausality, physics, and chemistry benchmarks demonstrate that RefTool\noutperforms existing tool-creation and domain-specific reasoning methods by\n11.3% on average accuracy, while being cost-efficient and broadly\ngeneralizable. Analyses reveal that grounding tool creation in references\nproduces accurate and faithful tools, and that the hierarchical structure\nfacilitates effective tool selection. RefTool enables LLMs to overcome\nknowledge limitations, demonstrating the value of grounding tool creation in\nexternal references for enhanced and generalizable reasoning.",
      "pdf_url": "http://arxiv.org/pdf/2505.21413v1",
      "published": "2025-05-27T16:41:19+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.21413v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "MRSD: Multi-Resolution Skill Discovery for HRL Agents",
      "authors": [
        "Shashank Sharma",
        "Janina Hoffmann",
        "Vinay Namboodiri"
      ],
      "abstract": "Hierarchical reinforcement learning (HRL) relies on abstract skills to solve\nlong-horizon tasks efficiently. While existing skill discovery methods learns\nthese skills automatically, they are limited to a single skill per task. In\ncontrast, humans learn and use both fine-grained and coarse motor skills\nsimultaneously. Inspired by human motor control, we propose Multi-Resolution\nSkill Discovery (MRSD), an HRL framework that learns multiple skill encoders at\ndifferent temporal resolutions in parallel. A high-level manager dynamically\nselects among these skills, enabling adaptive control strategies over time. We\nevaluate MRSD on tasks from the DeepMind Control Suite and show that it\noutperforms prior state-of-the-art skill discovery and HRL methods, achieving\nfaster convergence and higher final performance. Our findings highlight the\nbenefits of integrating multi-resolution skills in HRL, paving the way for more\nversatile and efficient agents.",
      "pdf_url": "http://arxiv.org/pdf/2505.21410v1",
      "published": "2025-05-27T16:38:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.21410v1",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ]
    },
    {
      "title": "RelationalFactQA: A Benchmark for Evaluating Tabular Fact Retrieval from Large Language Models",
      "authors": [
        "Dario Satriani",
        "Enzo Veltri",
        "Donatello Santoro",
        "Paolo Papotti"
      ],
      "abstract": "Factuality in Large Language Models (LLMs) is a persistent challenge. Current\nbenchmarks often assess short factual answers, overlooking the critical ability\nto generate structured, multi-record tabular outputs from parametric knowledge.\nWe demonstrate that this relational fact retrieval is substantially more\ndifficult than isolated point-wise queries, even when individual facts are\nknown to the model, exposing distinct failure modes sensitive to output\ndimensionality (e.g., number of attributes or records). To systematically\nevaluate this under-explored capability, we introduce RelationalFactQA, a new\nbenchmark featuring diverse natural language questions (paired with SQL) and\ngold-standard tabular answers, specifically designed to assess knowledge\nretrieval in a structured format. RelationalFactQA enables analysis across\nvarying query complexities, output sizes, and data characteristics. Our\nexperiments reveal that even state-of-the-art LLMs struggle significantly, not\nexceeding 25% factual accuracy in generating relational outputs, with\nperformance notably degrading as output dimensionality increases. These\nfindings underscore critical limitations in current LLMs' ability to synthesize\nstructured factual knowledge and establish RelationalFactQA as a crucial\nresource for measuring future progress in LLM factuality.",
      "pdf_url": "http://arxiv.org/pdf/2505.21409v1",
      "published": "2025-05-27T16:33:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.21409v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DB"
      ]
    },
    {
      "title": "Factual Self-Awareness in Language Models: Representation, Robustness, and Scaling",
      "authors": [
        "Hovhannes Tamoyan",
        "Subhabrata Dutta",
        "Iryna Gurevych"
      ],
      "abstract": "Factual incorrectness in generated content is one of the primary concerns in\nubiquitous deployment of large language models (LLMs). Prior findings suggest\nLLMs can (sometimes) detect factual incorrectness in their generated content\n(i.e., fact-checking post-generation). In this work, we provide evidence\nsupporting the presence of LLMs' internal compass that dictate the correctness\nof factual recall at the time of generation. We demonstrate that for a given\nsubject entity and a relation, LLMs internally encode linear features in the\nTransformer's residual stream that dictate whether it will be able to recall\nthe correct attribute (that forms a valid entity-relation-attribute triplet).\nThis self-awareness signal is robust to minor formatting variations. We\ninvestigate the effects of context perturbation via different example selection\nstrategies. Scaling experiments across model sizes and training dynamics\nhighlight that self-awareness emerges rapidly during training and peaks in\nintermediate layers. These findings uncover intrinsic self-monitoring\ncapabilities within LLMs, contributing to their interpretability and\nreliability.",
      "pdf_url": "http://arxiv.org/pdf/2505.21399v1",
      "published": "2025-05-27T16:24:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.21399v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "A Structured Unplugged Approach for Foundational AI Literacy in Primary Education",
      "authors": [
        "Maria Cristina Carrisi",
        "Mirko Marras",
        "Sara Vergallo"
      ],
      "abstract": "Younger generations are growing up in a world increasingly shaped by\nintelligent technologies, making early AI literacy crucial for developing the\nskills to critically understand and navigate them. However, education in this\nfield often emphasizes tool-based learning, prioritizing usage over\nunderstanding the underlying concepts. This lack of knowledge leaves\nnon-experts, especially children, prone to misconceptions, unrealistic\nexpectations, and difficulties in recognizing biases and stereotypes. In this\npaper, we propose a structured and replicable teaching approach that fosters\nfoundational AI literacy in primary students, by building upon core\nmathematical elements closely connected to and of interest in primary\ncurricula, to strengthen conceptualization, data representation, classification\nreasoning, and evaluation of AI. To assess the effectiveness of our approach,\nwe conducted an empirical study with thirty-one fifth-grade students across two\nclasses, evaluating their progress through a post-test and a satisfaction\nsurvey. Our results indicate improvements in terminology understanding and\nusage, features description, logical reasoning, and evaluative skills, with\nstudents showing a deeper comprehension of decision-making processes and their\nlimitations. Moreover, the approach proved engaging, with students particularly\nenjoying activities that linked AI concepts to real-world reasoning. Materials:\nhttps://github.com/tail-unica/ai-literacy-primary-ed.",
      "pdf_url": "http://arxiv.org/pdf/2505.21398v1",
      "published": "2025-05-27T16:23:57+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.21398v1",
      "categories": [
        "cs.AI",
        "cs.ET"
      ]
    },
    {
      "title": "Improving Research Idea Generation Through Data: An Empirical Investigation in Social Science",
      "authors": [
        "Xiao Liu",
        "Xinyi Dong",
        "Xinyang Gao",
        "Yansong Feng",
        "Xun Pang"
      ],
      "abstract": "Recent advancements in large language models (LLMs) have shown promise in\ngenerating novel research ideas. However, these ideas often face challenges\nrelated to feasibility and expected effectiveness. This paper explores how\naugmenting LLMs with relevant data during the idea generation process can\nenhance the quality of generated ideas. We introduce two ways of incorporating\ndata: (1) providing metadata during the idea generation stage to guide LLMs\ntoward feasible directions, and (2) adding automatic validation during the idea\nselection stage to assess the empirical plausibility of hypotheses within\nideas. We conduct experiments in the social science domain, specifically with\nclimate negotiation topics, and find that metadata improves the feasibility of\ngenerated ideas by 20%, while automatic validation improves the overall quality\nof selected ideas by 7%. A human study shows that LLM-generated ideas, along\nwith their related data and validation processes, inspire researchers to\npropose research ideas with higher quality. Our work highlights the potential\nof data-driven research idea generation, and underscores the practical utility\nof LLM-assisted ideation in real-world academic settings.",
      "pdf_url": "http://arxiv.org/pdf/2505.21396v1",
      "published": "2025-05-27T16:23:42+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.21396v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.HC"
      ]
    },
    {
      "title": "Leveraging the Power of Conversations: Optimal Key Term Selection in Conversational Contextual Bandits",
      "authors": [
        "Maoli Liu",
        "Zhuohua Li",
        "Xiangxiang Dai",
        "John C. S. Lui"
      ],
      "abstract": "Conversational recommender systems proactively query users with relevant \"key\nterms\" and leverage the feedback to elicit users' preferences for personalized\nrecommendations. Conversational contextual bandits, a prevalent approach in\nthis domain, aim to optimize preference learning by balancing exploitation and\nexploration. However, several limitations hinder their effectiveness in\nreal-world scenarios. First, existing algorithms employ key term selection\nstrategies with insufficient exploration, often failing to thoroughly probe\nusers' preferences and resulting in suboptimal preference estimation. Second,\ncurrent algorithms typically rely on deterministic rules to initiate\nconversations, causing unnecessary interactions when preferences are\nwell-understood and missed opportunities when preferences are uncertain. To\naddress these limitations, we propose three novel algorithms: CLiSK, CLiME, and\nCLiSK-ME. CLiSK introduces smoothed key term contexts to enhance exploration in\npreference learning, CLiME adaptively initiates conversations based on\npreference uncertainty, and CLiSK-ME integrates both techniques. We\ntheoretically prove that all three algorithms achieve a tighter regret upper\nbound of $O(\\sqrt{dT\\log{T}})$ with respect to the time horizon $T$, improving\nupon existing methods. Additionally, we provide a matching lower bound\n$\\Omega(\\sqrt{dT})$ for conversational bandits, demonstrating that our\nalgorithms are nearly minimax optimal. Extensive evaluations on both synthetic\nand real-world datasets show that our approaches achieve at least a 14.6%\nimprovement in cumulative regret.",
      "pdf_url": "http://arxiv.org/pdf/2505.21393v1",
      "published": "2025-05-27T16:22:32+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.21393v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Finite Sample Analysis of Linear Temporal Difference Learning with Arbitrary Features",
      "authors": [
        "Zixuan Xie",
        "Xinyu Liu",
        "Rohan Chandra",
        "Shangtong Zhang"
      ],
      "abstract": "Linear TD($\\lambda$) is one of the most fundamental reinforcement learning\nalgorithms for policy evaluation. Previously, convergence rates are typically\nestablished under the assumption of linearly independent features, which does\nnot hold in many practical scenarios. This paper instead establishes the first\n$L^2$ convergence rates for linear TD($\\lambda$) operating under arbitrary\nfeatures, without making any algorithmic modification or additional\nassumptions. Our results apply to both the discounted and average-reward\nsettings. To address the potential non-uniqueness of solutions resulting from\narbitrary features, we develop a novel stochastic approximation result\nfeaturing convergence rates to the solution set instead of a single point.",
      "pdf_url": "http://arxiv.org/pdf/2505.21391v1",
      "published": "2025-05-27T16:17:49+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.21391v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ]
    },
    {
      "title": "DeSocial: Blockchain-based Decentralized Social Networks",
      "authors": [
        "Jingyuan Huang",
        "Xi Zhu",
        "Minghao Guo",
        "Yongfeng Zhang"
      ],
      "abstract": "Web 2.0 social platforms are inherently centralized, with user data and\nalgorithmic decisions controlled by the platform. However, users can only\npassively receive social predictions without being able to choose the\nunderlying algorithm, which limits personalization. Fortunately, with the\nemergence of blockchain, users are allowed to choose algorithms that are\ntailored to their local situation, improving prediction results in a\npersonalized way. In a blockchain environment, each user possesses its own\nmodel to perform the social prediction, capturing different perspectives on\nsocial interactions. In our work, we propose DeSocial, a decentralized social\nnetwork learning framework deployed on an Ethereum (ETH) local development\nchain that integrates distributed data storage, node-level consensus, and\nuser-driven model selection through Ganache. In the first stage, each user\nleverages DeSocial to evaluate multiple backbone models on their local\nsubgraph. DeSocial coordinates the execution and returns model-wise prediction\nresults, enabling the user to select the most suitable backbone for\npersonalized social prediction. Then, DeSocial uniformly selects several\nvalidation nodes that possess the algorithm specified by each user, and\naggregates the prediction results by majority voting, to prevent errors caused\nby any single model's misjudgment. Extensive experiments show that DeSocial has\nan evident improvement compared to the five classical centralized social\nnetwork learning models, promoting user empowerment in blockchain-based\ndecentralized social networks, showing the importance of multi-node validation\nand personalized algorithm selection based on blockchain. Our implementation is\navailable at: https://github.com/agiresearch/DeSocial.",
      "pdf_url": "http://arxiv.org/pdf/2505.21388v1",
      "published": "2025-05-27T16:17:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.21388v1",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Improving LLM-based Global Optimization with Search Space Partitioning",
      "authors": [
        "Andrej Schwanke",
        "Lyubomir Ivanov",
        "David Salinas",
        "Fabio Ferreira",
        "Aaron Klein",
        "Frank Hutter",
        "Arber Zela"
      ],
      "abstract": "Large Language Models (LLMs) have recently emerged as effective surrogate\nmodels and candidate generators within global optimization frameworks for\nexpensive blackbox functions. Despite promising results, LLM-based methods\noften struggle in high-dimensional search spaces or when lacking\ndomain-specific priors, leading to sparse or uninformative suggestions. To\novercome these limitations, we propose HOLLM, a novel global optimization\nalgorithm that enhances LLM-driven sampling by partitioning the search space\ninto promising subregions. Each subregion acts as a ``meta-arm'' selected via a\nbandit-inspired scoring mechanism that effectively balances exploration and\nexploitation. Within each selected subregion, an LLM then proposes high-quality\ncandidate points, without any explicit domain knowledge. Empirical evaluation\non standard optimization benchmarks shows that HOLLM consistently matches or\nsurpasses leading Bayesian optimization and trust-region methods, while\nsubstantially outperforming global LLM-based sampling strategies.",
      "pdf_url": "http://arxiv.org/pdf/2505.21372v1",
      "published": "2025-05-27T16:01:49+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.21372v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Towards Interpretability Without Sacrifice: Faithful Dense Layer Decomposition with Mixture of Decoders",
      "authors": [
        "James Oldfield",
        "Shawn Im",
        "Yixuan Li",
        "Mihalis A. Nicolaou",
        "Ioannis Patras",
        "Grigorios G Chrysos"
      ],
      "abstract": "Multilayer perceptrons (MLPs) are an integral part of large language models,\nyet their dense representations render them difficult to understand, edit, and\nsteer. Recent methods learn interpretable approximations via neuron-level\nsparsity, yet fail to faithfully reconstruct the original\nmapping--significantly increasing model's next-token cross-entropy loss. In\nthis paper, we advocate for moving to layer-level sparsity to overcome the\naccuracy trade-off in sparse layer approximation. Under this paradigm, we\nintroduce Mixture of Decoders (MxDs). MxDs generalize MLPs and Gated Linear\nUnits, expanding pre-trained dense layers into tens of thousands of specialized\nsublayers. Through a flexible form of tensor factorization, each sparsely\nactivating MxD sublayer implements a linear transformation with full-rank\nweights--preserving the original decoders' expressive capacity even under heavy\nsparsity. Experimentally, we show that MxDs significantly outperform\nstate-of-the-art methods (e.g., Transcoders) on the sparsity-accuracy frontier\nin language models with up to 3B parameters. Further evaluations on sparse\nprobing and feature steering demonstrate that MxDs learn similarly specialized\nfeatures of natural language--opening up a promising new avenue for designing\ninterpretable yet faithful decompositions. Our code is included at:\nhttps://github.com/james-oldfield/MxD/.",
      "pdf_url": "http://arxiv.org/pdf/2505.21364v1",
      "published": "2025-05-27T15:55:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.21364v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Subgroups Matter for Robust Bias Mitigation",
      "authors": [
        "Anissa Alloula",
        "Charles Jones",
        "Ben Glocker",
        "Bartłomiej W. Papież"
      ],
      "abstract": "Despite the constant development of new bias mitigation methods for machine\nlearning, no method consistently succeeds, and a fundamental question remains\nunanswered: when and why do bias mitigation techniques fail? In this paper, we\nhypothesise that a key factor may be the often-overlooked but crucial step\nshared by many bias mitigation methods: the definition of subgroups. To\ninvestigate this, we conduct a comprehensive evaluation of state-of-the-art\nbias mitigation methods across multiple vision and language classification\ntasks, systematically varying subgroup definitions, including coarse,\nfine-grained, intersectional, and noisy subgroups. Our results reveal that\nsubgroup choice significantly impacts performance, with certain groupings\nparadoxically leading to worse outcomes than no mitigation at all. Our findings\nsuggest that observing a disparity between a set of subgroups is not a\nsufficient reason to use those subgroups for mitigation. Through theoretical\nanalysis, we explain these phenomena and uncover a counter-intuitive insight\nthat, in some cases, improving fairness with respect to a particular set of\nsubgroups is best achieved by using a different set of subgroups for\nmitigation. Our work highlights the importance of careful subgroup definition\nin bias mitigation and suggest it as a alternative lever for improving the\nrobustness and fairness of machine learning models.",
      "pdf_url": "http://arxiv.org/pdf/2505.21363v1",
      "published": "2025-05-27T15:52:58+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.21363v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Evaluating LLM Adaptation to Sociodemographic Factors: User Profile vs. Dialogue History",
      "authors": [
        "Qishuai Zhong",
        "Zongmin Li",
        "Siqi Fan",
        "Aixin Sun"
      ],
      "abstract": "Effective engagement by large language models (LLMs) requires adapting\nresponses to users' sociodemographic characteristics, such as age, occupation,\nand education level. While many real-world applications leverage dialogue\nhistory for contextualization, existing evaluations of LLMs' behavioral\nadaptation often focus on single-turn prompts. In this paper, we propose a\nframework to evaluate LLM adaptation when attributes are introduced either (1)\nexplicitly via user profiles in the prompt or (2) implicitly through multi-turn\ndialogue history. We assess the consistency of model behavior across these\nmodalities. Using a multi-agent pipeline, we construct a synthetic dataset\npairing dialogue histories with distinct user profiles and employ questions\nfrom the Value Survey Module (VSM 2013) (Hofstede and Hofstede, 2016) to probe\nvalue expression. Our findings indicate that most models adjust their expressed\nvalues in response to demographic changes, particularly in age and education\nlevel, but consistency varies. Models with stronger reasoning capabilities\ndemonstrate greater alignment, indicating the importance of reasoning in robust\nsociodemographic adaptation.",
      "pdf_url": "http://arxiv.org/pdf/2505.21362v1",
      "published": "2025-05-27T15:52:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.21362v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ]
    },
    {
      "title": "Prostate Cancer Screening with Artificial Intelligence-Enhanced Micro-Ultrasound: A Comparative Study with Traditional Methods",
      "authors": [
        "Muhammad Imran",
        "Wayne G. Brisbane",
        "Li-Ming Su",
        "Jason P. Joseph",
        "Wei Shao"
      ],
      "abstract": "Background and objective: Micro-ultrasound (micro-US) is a novel imaging\nmodality with diagnostic accuracy comparable to MRI for detecting clinically\nsignificant prostate cancer (csPCa). We investigated whether artificial\nintelligence (AI) interpretation of micro-US can outperform clinical screening\nmethods using PSA and digital rectal examination (DRE). Methods: We\nretrospectively studied 145 men who underwent micro-US guided biopsy (79 with\ncsPCa, 66 without). A self-supervised convolutional autoencoder was used to\nextract deep image features from 2D micro-US slices. Random forest classifiers\nwere trained using five-fold cross-validation to predict csPCa at the slice\nlevel. Patients were classified as csPCa-positive if 88 or more consecutive\nslices were predicted positive. Model performance was compared with a\nclassifier using PSA, DRE, prostate volume, and age. Key findings and\nlimitations: The AI-based micro-US model and clinical screening model achieved\nAUROCs of 0.871 and 0.753, respectively. At a fixed threshold, the micro-US\nmodel achieved 92.5% sensitivity and 68.1% specificity, while the clinical\nmodel showed 96.2% sensitivity but only 27.3% specificity. Limitations include\na retrospective single-center design and lack of external validation.\nConclusions and clinical implications: AI-interpreted micro-US improves\nspecificity while maintaining high sensitivity for csPCa detection. This method\nmay reduce unnecessary biopsies and serve as a low-cost alternative to\nPSA-based screening. Patient summary: We developed an AI system to analyze\nprostate micro-ultrasound images. It outperformed PSA and DRE in detecting\naggressive cancer and may help avoid unnecessary biopsies.",
      "pdf_url": "http://arxiv.org/pdf/2505.21355v1",
      "published": "2025-05-27T15:47:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.21355v1",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "The Multilingual Divide and Its Impact on Global AI Safety",
      "authors": [
        "Aidan Peppin",
        "Julia Kreutzer",
        "Alice Schoenauer Sebag",
        "Kelly Marchisio",
        "Beyza Ermis",
        "John Dang",
        "Samuel Cahyawijaya",
        "Shivalika Singh",
        "Seraphina Goldfarb-Tarrant",
        "Viraat Aryabumi",
        "Aakanksha",
        "Wei-Yin Ko",
        "Ahmet Üstün",
        "Matthias Gallé",
        "Marzieh Fadaee",
        "Sara Hooker"
      ],
      "abstract": "Despite advances in large language model capabilities in recent years, a\nlarge gap remains in their capabilities and safety performance for many\nlanguages beyond a relatively small handful of globally dominant languages.\nThis paper provides researchers, policymakers and governance experts with an\noverview of key challenges to bridging the \"language gap\" in AI and minimizing\nsafety risks across languages. We provide an analysis of why the language gap\nin AI exists and grows, and how it creates disparities in global AI safety. We\nidentify barriers to address these challenges, and recommend how those working\nin policy and governance can help address safety concerns associated with the\nlanguage gap by supporting multilingual dataset creation, transparency, and\nresearch.",
      "pdf_url": "http://arxiv.org/pdf/2505.21344v1",
      "published": "2025-05-27T15:37:32+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.21344v1",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "An Uncertainty-Aware ED-LSTM for Probabilistic Suffix Prediction",
      "authors": [
        "Henryk Mustroph",
        "Michel Kunkler",
        "Stefanie Rinderle-Ma"
      ],
      "abstract": "Suffix prediction of business processes forecasts the remaining sequence of\nevents until process completion. Current approaches focus on predicting a\nsingle, most likely suffix. However, if the future course of a process is\nexposed to uncertainty or has high variability, the expressiveness of a single\nsuffix prediction can be limited. To address this limitation, we propose\nprobabilistic suffix prediction, a novel approach that approximates a\nprobability distribution of suffixes. The proposed approach is based on an\nUncertainty-Aware Encoder-Decoder LSTM (U-ED-LSTM) and a Monte Carlo (MC)\nsuffix sampling algorithm. We capture epistemic uncertainties via MC dropout\nand aleatoric uncertainties as learned loss attenuation. This technical report\nprovides a detailed evaluation of the U-ED-LSTM's predictive performance and\nassesses its calibration on four real-life event logs with three different\nhyperparameter settings. The results show that i) the U-ED-LSTM has reasonable\npredictive performance across various datasets, ii) aggregating probabilistic\nsuffix predictions into mean values can outperform most likely predictions,\nparticularly for rare prefixes or longer suffixes, and iii) the approach\neffectively captures uncertainties present in event logs.",
      "pdf_url": "http://arxiv.org/pdf/2505.21339v1",
      "published": "2025-05-27T15:33:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.21339v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Structure from Collision",
      "authors": [
        "Takuhiro Kaneko"
      ],
      "abstract": "Recent advancements in neural 3D representations, such as neural radiance\nfields (NeRF) and 3D Gaussian splatting (3DGS), have enabled the accurate\nestimation of 3D structures from multiview images. However, this capability is\nlimited to estimating the visible external structure, and identifying the\ninvisible internal structure hidden behind the surface is difficult. To\novercome this limitation, we address a new task called Structure from Collision\n(SfC), which aims to estimate the structure (including the invisible internal\nstructure) of an object from appearance changes during collision. To solve this\nproblem, we propose a novel model called SfC-NeRF that optimizes the invisible\ninternal structure of an object through a video sequence under physical,\nappearance (i.e., visible external structure)-preserving, and keyframe\nconstraints. In particular, to avoid falling into undesirable local optima\nowing to its ill-posed nature, we propose volume annealing; that is, searching\nfor global optima by repeatedly reducing and expanding the volume. Extensive\nexperiments on 115 objects involving diverse structures (i.e., various cavity\nshapes, locations, and sizes) and material properties revealed the properties\nof SfC and demonstrated the effectiveness of the proposed SfC-NeRF.",
      "pdf_url": "http://arxiv.org/pdf/2505.21335v1",
      "published": "2025-05-27T15:30:01+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.21335v1",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.RO"
      ]
    },
    {
      "title": "Something's Fishy In The Data Lake: A Critical Re-evaluation of Table Union Search Benchmarks",
      "authors": [
        "Allaa Boutaleb",
        "Bernd Amann",
        "Hubert Naacke",
        "Rafael Angarita"
      ],
      "abstract": "Recent table representation learning and data discovery methods tackle table\nunion search (TUS) within data lakes, which involves identifying tables that\ncan be unioned with a given query table to enrich its content. These methods\nare commonly evaluated using benchmarks that aim to assess semantic\nunderstanding in real-world TUS tasks. However, our analysis of prominent TUS\nbenchmarks reveals several limitations that allow simple baselines to perform\nsurprisingly well, often outperforming more sophisticated approaches. This\nsuggests that current benchmark scores are heavily influenced by\ndataset-specific characteristics and fail to effectively isolate the gains from\nsemantic understanding. To address this, we propose essential criteria for\nfuture benchmarks to enable a more realistic and reliable evaluation of\nprogress in semantic table union search.",
      "pdf_url": "http://arxiv.org/pdf/2505.21329v2",
      "published": "2025-05-27T15:23:52+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.21329v2",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.DB",
        "cs.LG"
      ]
    },
    {
      "title": "MME-Reasoning: A Comprehensive Benchmark for Logical Reasoning in MLLMs",
      "authors": [
        "Jiakang Yuan",
        "Tianshuo Peng",
        "Yilei Jiang",
        "Yiting Lu",
        "Renrui Zhang",
        "Kaituo Feng",
        "Chaoyou Fu",
        "Tao Chen",
        "Lei Bai",
        "Bo Zhang",
        "Xiangyu Yue"
      ],
      "abstract": "Logical reasoning is a fundamental aspect of human intelligence and an\nessential capability for multimodal large language models (MLLMs). Despite the\nsignificant advancement in multimodal reasoning, existing benchmarks fail to\ncomprehensively evaluate their reasoning abilities due to the lack of explicit\ncategorization for logical reasoning types and an unclear understanding of\nreasoning. To address these issues, we introduce MME-Reasoning, a comprehensive\nbenchmark designed to evaluate the reasoning ability of MLLMs, which covers all\nthree types of reasoning (i.e., inductive, deductive, and abductive) in its\nquestions. We carefully curate the data to ensure that each question\neffectively evaluates reasoning ability rather than perceptual skills or\nknowledge breadth, and extend the evaluation protocols to cover the evaluation\nof diverse questions. Our evaluation reveals substantial limitations of\nstate-of-the-art MLLMs when subjected to holistic assessments of logical\nreasoning capabilities. Even the most advanced MLLMs show limited performance\nin comprehensive logical reasoning, with notable performance imbalances across\nreasoning types. In addition, we conducted an in-depth analysis of approaches\nsuch as ``thinking mode'' and Rule-based RL, which are commonly believed to\nenhance reasoning abilities. These findings highlight the critical limitations\nand performance imbalances of current MLLMs in diverse logical reasoning\nscenarios, providing comprehensive and systematic insights into the\nunderstanding and evaluation of reasoning capabilities.",
      "pdf_url": "http://arxiv.org/pdf/2505.21327v1",
      "published": "2025-05-27T15:23:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.21327v1",
      "categories": [
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Assured Autonomy with Neuro-Symbolic Perception",
      "authors": [
        "R. Spencer Hallyburton",
        "Miroslav Pajic"
      ],
      "abstract": "Many state-of-the-art AI models deployed in cyber-physical systems (CPS),\nwhile highly accurate, are simply pattern-matchers.~With limited security\nguarantees, there are concerns for their reliability in safety-critical and\ncontested domains. To advance assured AI, we advocate for a paradigm shift that\nimbues data-driven perception models with symbolic structure, inspired by a\nhuman's ability to reason over low-level features and high-level context. We\npropose a neuro-symbolic paradigm for perception (NeuSPaPer) and illustrate how\njoint object detection and scene graph generation (SGG) yields deep scene\nunderstanding.~Powered by foundation models for offline knowledge extraction\nand specialized SGG algorithms for real-time deployment, we design a framework\nleveraging structured relational graphs that ensures the integrity of\nsituational awareness in autonomy. Using physics-based simulators and\nreal-world datasets, we demonstrate how SGG bridges the gap between low-level\nsensor perception and high-level reasoning, establishing a foundation for\nresilient, context-aware AI and advancing trusted autonomy in CPS.",
      "pdf_url": "http://arxiv.org/pdf/2505.21322v1",
      "published": "2025-05-27T15:21:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.21322v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Beyond Chemical QA: Evaluating LLM's Chemical Reasoning with Modular Chemical Operations",
      "authors": [
        "Hao Li",
        "He Cao",
        "Bin Feng",
        "Yanjun Shao",
        "Xiangru Tang",
        "Zhiyuan Yan",
        "Li Yuan",
        "Yonghong Tian",
        "Yu Li"
      ],
      "abstract": "While large language models (LLMs) with Chain-of-Thought (CoT) reasoning\nexcel in mathematics and coding, their potential for systematic reasoning in\nchemistry, a domain demanding rigorous structural analysis for real-world tasks\nlike drug design and reaction engineering, remains untapped. Current benchmarks\nfocus on simple knowledge retrieval, neglecting step-by-step reasoning required\nfor complex tasks such as molecular optimization and reaction prediction. To\naddress this, we introduce ChemCoTBench, a reasoning framework that bridges\nmolecular structure understanding with arithmetic-inspired operations,\nincluding addition, deletion, and substitution, to formalize chemical\nproblem-solving into transparent, step-by-step workflows. By treating molecular\ntransformations as modular \"chemical operations\", the framework enables\nslow-thinking reasoning, mirroring the logic of mathematical proofs while\ngrounding solutions in real-world chemical constraints. We evaluate models on\ntwo high-impact tasks: Molecular Property Optimization and Chemical Reaction\nPrediction. These tasks mirror real-world challenges while providing structured\nevaluability. By providing annotated datasets, a reasoning taxonomy, and\nbaseline evaluations, ChemCoTBench bridges the gap between abstract reasoning\nmethods and practical chemical discovery, establishing a foundation for\nadvancing LLMs as tools for AI-driven scientific innovation.",
      "pdf_url": "http://arxiv.org/pdf/2505.21318v1",
      "published": "2025-05-27T15:15:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.21318v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "A Cross Modal Knowledge Distillation & Data Augmentation Recipe for Improving Transcriptomics Representations through Morphological Features",
      "authors": [
        "Ihab Bendidi",
        "Yassir El Mesbahi",
        "Alisandra K. Denton",
        "Karush Suri",
        "Kian Kenyon-Dean",
        "Auguste Genovesio",
        "Emmanuel Noutahi"
      ],
      "abstract": "Understanding cellular responses to stimuli is crucial for biological\ndiscovery and drug development. Transcriptomics provides interpretable,\ngene-level insights, while microscopy imaging offers rich predictive features\nbut is harder to interpret. Weakly paired datasets, where samples share\nbiological states, enable multimodal learning but are scarce, limiting their\nutility for training and multimodal inference. We propose a framework to\nenhance transcriptomics by distilling knowledge from microscopy images. Using\nweakly paired data, our method aligns and binds modalities, enriching gene\nexpression representations with morphological information. To address data\nscarcity, we introduce (1) Semi-Clipped, an adaptation of CLIP for cross-modal\ndistillation using pretrained foundation models, achieving state-of-the-art\nresults, and (2) PEA (Perturbation Embedding Augmentation), a novel\naugmentation technique that enhances transcriptomics data while preserving\ninherent biological information. These strategies improve the predictive power\nand retain the interpretability of transcriptomics, enabling rich unimodal\nrepresentations for complex biological tasks.",
      "pdf_url": "http://arxiv.org/pdf/2505.21317v1",
      "published": "2025-05-27T15:15:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.21317v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "How Humans and LLMs Organize Conceptual Knowledge: Exploring Subordinate Categories in Italian",
      "authors": [
        "Andrea Pedrotti",
        "Giulia Rambelli",
        "Caterina Villani",
        "Marianna Bolognesi"
      ],
      "abstract": "People can categorize the same entity at multiple taxonomic levels, such as\nbasic (bear), superordinate (animal), and subordinate (grizzly bear). While\nprior research has focused on basic-level categories, this study is the first\nattempt to examine the organization of categories by analyzing exemplars\nproduced at the subordinate level. We present a new Italian psycholinguistic\ndataset of human-generated exemplars for 187 concrete words. We then use these\ndata to evaluate whether textual and vision LLMs produce meaningful exemplars\nthat align with human category organization across three key tasks: exemplar\ngeneration, category induction, and typicality judgment. Our findings show a\nlow alignment between humans and LLMs, consistent with previous studies.\nHowever, their performance varies notably across different semantic domains.\nUltimately, this study highlights both the promises and the constraints of\nusing AI-generated exemplars to support psychological and linguistic research.",
      "pdf_url": "http://arxiv.org/pdf/2505.21301v1",
      "published": "2025-05-27T15:04:52+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.21301v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Large Language Models Miss the Multi-Agent Mark",
      "authors": [
        "Emanuele La Malfa",
        "Gabriele La Malfa",
        "Samuele Marro",
        "Jie M. Zhang",
        "Elizabeth Black",
        "Micheal Luck",
        "Philip Torr",
        "Michael Wooldridge"
      ],
      "abstract": "Recent interest in Multi-Agent Systems of Large Language Models (MAS LLMs)\nhas led to an increase in frameworks leveraging multiple LLMs to tackle complex\ntasks. However, much of this literature appropriates the terminology of MAS\nwithout engaging with its foundational principles. In this position paper, we\nhighlight critical discrepancies between MAS theory and current MAS LLMs\nimplementations, focusing on four key areas: the social aspect of agency,\nenvironment design, coordination and communication protocols, and measuring\nemergent behaviours. Our position is that many MAS LLMs lack multi-agent\ncharacteristics such as autonomy, social interaction, and structured\nenvironments, and often rely on oversimplified, LLM-centric architectures. The\nfield may slow down and lose traction by revisiting problems the MAS literature\nhas already addressed. Therefore, we systematically analyse this issue and\noutline associated research opportunities; we advocate for better integrating\nestablished MAS concepts and more precise terminology to avoid\nmischaracterisation and missed opportunities.",
      "pdf_url": "http://arxiv.org/pdf/2505.21298v1",
      "published": "2025-05-27T15:01:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.21298v1",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Complex System Diagnostics Using a Knowledge Graph-Informed and Large Language Model-Enhanced Framework",
      "authors": [
        "Saman Marandi",
        "Yu-Shu Hu",
        "Mohammad Modarres"
      ],
      "abstract": "In this paper, we present a novel diagnostic framework that integrates\nKnowledge Graphs (KGs) and Large Language Models (LLMs) to support system\ndiagnostics in high-reliability systems such as nuclear power plants.\nTraditional diagnostic modeling struggles when systems become too complex,\nmaking functional modeling a more attractive approach. Our approach introduces\na diagnostic framework grounded in the functional modeling principles of the\nDynamic Master Logic (DML) model. It incorporates two coordinated LLM\ncomponents, including an LLM-based workflow for automated construction of DML\nlogic from system documentation and an LLM agent that facilitates interactive\ndiagnostics. The generated logic is encoded into a structured KG, referred to\nas KG-DML, which supports hierarchical fault reasoning. Expert knowledge or\noperational data can also be incorporated to refine the model's precision and\ndiagnostic depth. In the interaction phase, users submit natural language\nqueries, which are interpreted by the LLM agent. The agent selects appropriate\ntools for structured reasoning, including upward and downward propagation\nacross the KG-DML. Rather than embedding KG content into every prompt, the LLM\nagent distinguishes between diagnostic and interpretive tasks. For diagnostics,\nthe agent selects and executes external tools that perform structured KG\nreasoning. For general queries, a Graph-based Retrieval-Augmented Generation\n(Graph-RAG) approach is used, retrieving relevant KG segments and embedding\nthem into the prompt to generate natural explanations. A case study on an\nauxiliary feedwater system demonstrated the framework's effectiveness, with\nover 90% accuracy in key elements and consistent tool and argument extraction,\nsupporting its use in safety-critical diagnostics.",
      "pdf_url": "http://arxiv.org/pdf/2505.21291v1",
      "published": "2025-05-27T14:54:49+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.21291v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "GSAT: Graph Structure Attention Networks",
      "authors": [
        "Farshad Noravesh",
        "Reza Haffari",
        "Layki Soon",
        "Arghya Pal"
      ],
      "abstract": "Graph Neural Networks (GNNs) have emerged as a powerful tool for processing\ndata represented in graph structures, achieving remarkable success across a\nwide range of applications. However, to further improve the performance on\ngraph classification benchmarks, structural representation of each node that\nencodes rich local topological information in the neighbourhood of nodes is an\nimportant type of feature that is often overlooked in the modeling. The\nconsequence of neglecting the structural information has resulted high number\nof layers to connect messages from distant nodes which by itself produces other\nproblems such as oversmoothing. In the present paper, we leverage these\nstructural information that are modeled by anonymous random walks (ARWs) and\nintroduce graph structure attention network (GSAT) which is a generalization of\ngraph attention network(GAT) to integrate the original attribute and the\nstructural representation to enforce the model to automatically find patterns\nfor attending to different edges in the node neighbourhood to enrich graph\nrepresentation. Our experiments show GSAT slightly improves SOTA on some graph\nclassification benchmarks.",
      "pdf_url": "http://arxiv.org/pdf/2505.21288v1",
      "published": "2025-05-27T14:54:08+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.21288v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "RLJP: Legal Judgment Prediction via First-Order Logic Rule-enhanced with Large Language Models",
      "authors": [
        "Yue Zhang",
        "Zhiliang Tian",
        "Shicheng Zhou",
        "Haiyang Wang",
        "Wenqing Hou",
        "Yuying Liu",
        "Xuechen Zhao",
        "Minlie Huang",
        "Ye Wang",
        "Bin Zhou"
      ],
      "abstract": "Legal Judgment Prediction (LJP) is a pivotal task in legal AI. Existing\nsemantic-enhanced LJP models integrate judicial precedents and legal knowledge\nfor high performance. But they neglect legal reasoning logic, a critical\ncomponent of legal judgments requiring rigorous logical analysis. Although some\napproaches utilize legal reasoning logic for high-quality predictions, their\nlogic rigidity hinders adaptation to case-specific logical frameworks,\nparticularly in complex cases that are lengthy and detailed. This paper\nproposes a rule-enhanced legal judgment prediction framework based on\nfirst-order logic (FOL) formalism and comparative learning (CL) to develop an\nadaptive adjustment mechanism for legal judgment logic and further enhance\nperformance in LJP. Inspired by the process of human exam preparation, our\nmethod follows a three-stage approach: first, we initialize judgment rules\nusing the FOL formalism to capture complex reasoning logic accurately; next, we\npropose a Confusion-aware Contrastive Learning (CACL) to dynamically optimize\nthe judgment rules through a quiz consisting of confusable cases; finally, we\nutilize the optimized judgment rules to predict legal judgments. Experimental\nresults on two public datasets show superior performance across all metrics.\nThe code is publicly available{https://anonymous.4open.science/r/RLJP-FDF1}.",
      "pdf_url": "http://arxiv.org/pdf/2505.21281v1",
      "published": "2025-05-27T14:50:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.21281v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "XBOUND: Exploring the Capability Boundaries of Device-Control Agents through Trajectory Tree Exploration",
      "authors": [
        "Shaoqing Zhang",
        "Kehai Chen",
        "Zhuosheng Zhang",
        "Rumei Li",
        "Rongxiang Weng",
        "Yang Xiang",
        "Liqiang Nie",
        "Min Zhang"
      ],
      "abstract": "Recent advancements in vision-language models (VLMs) have spurred increased\ninterest in Device-Control Agents (DC agents), such as utilizing in-the-wild\ndevice control to manage graphical user interfaces. Conventional methods for\nassessing the capabilities of DC agents, such as computing step-wise action\naccuracy and overall task success rates, provide a macroscopic view of DC\nagents' performance; however, they fail to offer microscopic insights into\npotential errors that may occur in real-world applications. Conducting a\nfiner-grained performance evaluation of DC agents presents significant\nchallenges. This study introduces a new perspective on evaluation methods for\nDC agents by proposing the XBOUND evaluation method, which employs the\ncalculation of a novel Explore Metric to delineate the capability boundaries of\nDC agents. Compared to previous evaluation methods, XBOUND focuses on\nindividual states to assess the proficiency of DC agents in mastering these\nstates. Furthermore, we have developed a ``pseudo'' episode tree dataset\nderived from Android Control test data. Utilizing this dataset and XBOUND, we\ncomprehensively evaluate the OS-Atlas and UI-TARS series, examining both the\noverall and specific performance across five common tasks. Additionally, we\nselect representative cases to highlight the current deficiencies and\nlimitations inherent in both series. Code is available at\nhttps://github.com/sqzhang-lazy/XBOUND.",
      "pdf_url": "http://arxiv.org/pdf/2505.21279v1",
      "published": "2025-05-27T14:49:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.21279v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Breaking the Ceiling: Exploring the Potential of Jailbreak Attacks through Expanding Strategy Space",
      "authors": [
        "Yao Huang",
        "Yitong Sun",
        "Shouwei Ruan",
        "Yichi Zhang",
        "Yinpeng Dong",
        "Xingxing Wei"
      ],
      "abstract": "Large Language Models (LLMs), despite advanced general capabilities, still\nsuffer from numerous safety risks, especially jailbreak attacks that bypass\nsafety protocols. Understanding these vulnerabilities through black-box\njailbreak attacks, which better reflect real-world scenarios, offers critical\ninsights into model robustness. While existing methods have shown improvements\nthrough various prompt engineering techniques, their success remains limited\nagainst safety-aligned models, overlooking a more fundamental problem: the\neffectiveness is inherently bounded by the predefined strategy spaces. However,\nexpanding this space presents significant challenges in both systematically\ncapturing essential attack patterns and efficiently navigating the increased\ncomplexity. To better explore the potential of expanding the strategy space, we\naddress these challenges through a novel framework that decomposes jailbreak\nstrategies into essential components based on the Elaboration Likelihood Model\n(ELM) theory and develops genetic-based optimization with intention evaluation\nmechanisms. To be striking, our experiments reveal unprecedented jailbreak\ncapabilities by expanding the strategy space: we achieve over 90% success rate\non Claude-3.5 where prior methods completely fail, while demonstrating strong\ncross-model transferability and surpassing specialized safeguard models in\nevaluation accuracy. The code is open-sourced at:\nhttps://github.com/Aries-iai/CL-GSO.",
      "pdf_url": "http://arxiv.org/pdf/2505.21277v1",
      "published": "2025-05-27T14:48:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.21277v1",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Multilingual Pretraining for Pixel Language Models",
      "authors": [
        "Ilker Kesen",
        "Jonas F. Lotz",
        "Ingo Ziegler",
        "Phillip Rust",
        "Desmond Elliott"
      ],
      "abstract": "Pixel language models operate directly on images of rendered text,\neliminating the need for a fixed vocabulary. While these models have\ndemonstrated strong capabilities for downstream cross-lingual transfer,\nmultilingual pretraining remains underexplored. We introduce PIXEL-M4, a model\npretrained on four visually and linguistically diverse languages: English,\nHindi, Ukrainian, and Simplified Chinese. Multilingual evaluations on semantic\nand syntactic tasks show that PIXEL-M4 outperforms an English-only counterpart\non non-Latin scripts. Word-level probing analyses confirm that PIXEL-M4\ncaptures rich linguistic features, even in languages not seen during\npretraining. Furthermore, an analysis of its hidden representations shows that\nmultilingual pretraining yields a semantic embedding space closely aligned\nacross the languages used for pretraining. This work demonstrates that\nmultilingual pretraining substantially enhances the capability of pixel\nlanguage models to effectively support a diverse set of languages.",
      "pdf_url": "http://arxiv.org/pdf/2505.21265v1",
      "published": "2025-05-27T14:40:47+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.21265v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Breaking the Performance Ceiling in Complex Reinforcement Learning requires Inference Strategies",
      "authors": [
        "Felix Chalumeau",
        "Daniel Rajaonarivonivelomanantsoa",
        "Ruan de Kock",
        "Claude Formanek",
        "Sasha Abramowitz",
        "Oumayma Mahjoub",
        "Wiem Khlifi",
        "Simon Du Toit",
        "Louay Ben Nessir",
        "Refiloe Shabe",
        "Arnol Fokam",
        "Siddarth Singh",
        "Ulrich Mbou Sob",
        "Arnu Pretorius"
      ],
      "abstract": "Reinforcement learning (RL) systems have countless applications, from\nenergy-grid management to protein design. However, such real-world scenarios\nare often extremely difficult, combinatorial in nature, and require complex\ncoordination between multiple agents. This level of complexity can cause even\nstate-of-the-art RL systems, trained until convergence, to hit a performance\nceiling which they are unable to break out of with zero-shot inference.\nMeanwhile, many digital or simulation-based applications allow for an inference\nphase that utilises a specific time and compute budget to explore multiple\nattempts before outputting a final solution. In this work, we show that such an\ninference phase employed at execution time, and the choice of a corresponding\ninference strategy, are key to breaking the performance ceiling observed in\ncomplex multi-agent RL problems. Our main result is striking: we can obtain up\nto a 126% and, on average, a 45% improvement over the previous state-of-the-art\nacross 17 tasks, using only a couple seconds of extra wall-clock time during\nexecution. We also demonstrate promising compute scaling properties, supported\nby over 60k experiments, making it the largest study on inference strategies\nfor complex RL to date. Our experimental data and code are available at\nhttps://sites.google.com/view/inf-marl.",
      "pdf_url": "http://arxiv.org/pdf/2505.21236v1",
      "published": "2025-05-27T14:19:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.21236v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ]
    },
    {
      "title": "PSRB: A Comprehensive Benchmark for Evaluating Persian ASR Systems",
      "authors": [
        "Nima Sedghiyeh",
        "Sara Sadeghi",
        "Reza Khodadadi",
        "Farzin Kashani",
        "Omid Aghdaei",
        "Somayeh Rahimi",
        "Mohammad Sadegh Safari"
      ],
      "abstract": "Although Automatic Speech Recognition (ASR) systems have become an integral\npart of modern technology, their evaluation remains challenging, particularly\nfor low-resource languages such as Persian. This paper introduces Persian\nSpeech Recognition Benchmark(PSRB), a comprehensive benchmark designed to\naddress this gap by incorporating diverse linguistic and acoustic conditions.\nWe evaluate ten ASR systems, including state-of-the-art commercial and\nopen-source models, to examine performance variations and inherent biases.\nAdditionally, we conduct an in-depth analysis of Persian ASR transcriptions,\nidentifying key error types and proposing a novel metric that weights\nsubstitution errors. This metric enhances evaluation robustness by reducing the\nimpact of minor and partial errors, thereby improving the precision of\nperformance assessment. Our findings indicate that while ASR models generally\nperform well on standard Persian, they struggle with regional accents,\nchildren's speech, and specific linguistic challenges. These results highlight\nthe necessity of fine-tuning and incorporating diverse, representative training\ndatasets to mitigate biases and enhance overall ASR performance. PSRB provides\na valuable resource for advancing ASR research in Persian and serves as a\nframework for developing benchmarks in other low-resource languages. A subset\nof the PSRB dataset is publicly available at\nhttps://huggingface.co/datasets/PartAI/PSRB.",
      "pdf_url": "http://arxiv.org/pdf/2505.21230v1",
      "published": "2025-05-27T14:14:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.21230v1",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.SD"
      ]
    }
  ]
}