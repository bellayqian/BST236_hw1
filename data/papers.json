{
  "last_updated": "2025-07-29T01:02:39.594550",
  "papers": [
    {
      "title": "Advancing Event Forecasting through Massive Training of Large Language Models: Challenges, Solutions, and Broader Impacts",
      "authors": [
        "Sang-Woo Lee",
        "Sohee Yang",
        "Donghyun Kwak",
        "Noah Y. Siegel"
      ],
      "abstract": "Many recent papers have studied the development of superforecaster-level\nevent forecasting LLMs. While methodological problems with early studies cast\ndoubt on the use of LLMs for event forecasting, recent studies with improved\nevaluation methods have shown that state-of-the-art LLMs are gradually reaching\nsuperforecaster-level performance, and reinforcement learning has also been\nreported to improve future forecasting. Additionally, the unprecedented success\nof recent reasoning models and Deep Research-style models suggests that\ntechnology capable of greatly improving forecasting performance has been\ndeveloped. Therefore, based on these positive recent trends, we argue that the\ntime is ripe for research on large-scale training of superforecaster-level\nevent forecasting LLMs. We discuss two key research directions: training\nmethods and data acquisition. For training, we first introduce three\ndifficulties of LLM-based event forecasting training: noisiness-sparsity,\nknowledge cut-off, and simple reward structure problems. Then, we present\nrelated ideas to mitigate these problems: hypothetical event Bayesian networks,\nutilizing poorly-recalled and counterfactual events, and auxiliary reward\nsignals. For data, we propose aggressive use of market, public, and crawling\ndatasets to enable large-scale training and evaluation. Finally, we explain how\nthese technical advances could enable AI to provide predictive intelligence to\nsociety in broader areas. This position paper presents promising specific paths\nand considerations for getting closer to superforecaster-level AI technology,\naiming to call for researchers' interest in these directions.",
      "pdf_url": "http://arxiv.org/pdf/2507.19477v1",
      "published": "2025-07-25T17:59:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.19477v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential Recommendations with Content-Based Initialization",
      "authors": [
        "Anton Pembek",
        "Artem Fatkulin",
        "Anton Klenitskiy",
        "Alexey Vasilev"
      ],
      "abstract": "Many sequential recommender systems suffer from the cold start problem, where\nitems with few or no interactions cannot be effectively used by the model due\nto the absence of a trained embedding. Content-based approaches, which leverage\nitem metadata, are commonly used in such scenarios. One possible way is to use\nembeddings derived from content features such as textual descriptions as\ninitialization for the model embeddings. However, directly using frozen content\nembeddings often results in suboptimal performance, as they may not fully adapt\nto the recommendation task. On the other hand, fine-tuning these embeddings can\ndegrade performance for cold-start items, as item representations may drift far\nfrom their original structure after training. We propose a novel approach to\naddress this limitation. Instead of entirely freezing the content embeddings or\nfine-tuning them extensively, we introduce a small trainable delta to frozen\nembeddings that enables the model to adapt item representations without letting\nthem go too far from their original semantic structure. This approach\ndemonstrates consistent improvements across multiple datasets and modalities,\nincluding e-commerce datasets with textual descriptions and a music dataset\nwith audio-based representation.",
      "pdf_url": "http://arxiv.org/pdf/2507.19473v1",
      "published": "2025-07-25T17:57:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.19473v1",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Hierarchical Deep Reinforcement Learning Framework for Multi-Year Asset Management Under Budget Constraints",
      "authors": [
        "Amir Fard",
        "Arnold X. -X. Yuan"
      ],
      "abstract": "Budget planning and maintenance optimization are crucial for infrastructure\nasset management, ensuring cost-effectiveness and sustainability. However, the\ncomplexity arising from combinatorial action spaces, diverse asset\ndeterioration, stringent budget constraints, and environmental uncertainty\nsignificantly limits existing methods' scalability. This paper proposes a\nHierarchical Deep Reinforcement Learning methodology specifically tailored to\nmulti-year infrastructure planning. Our approach decomposes the problem into\ntwo hierarchical levels: a high-level Budget Planner allocating annual budgets\nwithin explicit feasibility bounds, and a low-level Maintenance Planner\nprioritizing assets within the allocated budget. By structurally separating\nmacro-budget decisions from asset-level prioritization and integrating linear\nprogramming projection within a hierarchical Soft Actor-Critic framework, the\nmethod efficiently addresses exponential growth in the action space and ensures\nrigorous budget compliance. A case study evaluating sewer networks of varying\nsizes (10, 15, and 20 sewersheds) illustrates the effectiveness of the proposed\napproach. Compared to conventional Deep Q-Learning and enhanced genetic\nalgorithms, our methodology converges more rapidly, scales effectively, and\nconsistently delivers near-optimal solutions even as network size grows.",
      "pdf_url": "http://arxiv.org/pdf/2507.19458v1",
      "published": "2025-07-25T17:42:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.19458v1",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "eess.SY",
        "math.OC"
      ]
    },
    {
      "title": "GEPA: Reflective Prompt Evolution Can Outperform Reinforcement Learning",
      "authors": [
        "Lakshya A Agrawal",
        "Shangyin Tan",
        "Dilara Soylu",
        "Noah Ziems",
        "Rishi Khare",
        "Krista Opsahl-Ong",
        "Arnav Singhvi",
        "Herumb Shandilya",
        "Michael J Ryan",
        "Meng Jiang",
        "Christopher Potts",
        "Koushik Sen",
        "Alexandros G. Dimakis",
        "Ion Stoica",
        "Dan Klein",
        "Matei Zaharia",
        "Omar Khattab"
      ],
      "abstract": "Large language models (LLMs) are increasingly adapted to downstream tasks via\nreinforcement learning (RL) methods like Group Relative Policy Optimization\n(GRPO), which often require thousands of rollouts to learn new tasks. We argue\nthat the interpretable nature of language can often provide a much richer\nlearning medium for LLMs, compared with policy gradients derived from sparse,\nscalar rewards. To test this, we introduce GEPA (Genetic-Pareto), a prompt\noptimizer that thoroughly incorporates natural language reflection to learn\nhigh-level rules from trial and error. Given any AI system containing one or\nmore LLM prompts, GEPA samples system-level trajectories (e.g., reasoning, tool\ncalls, and tool outputs) and reflects on them in natural language to diagnose\nproblems, propose and test prompt updates, and combine complementary lessons\nfrom the Pareto frontier of its own attempts. As a result of GEPA's design, it\ncan often turn even just a few rollouts into a large quality gain. Across four\ntasks, GEPA outperforms GRPO by 10% on average and by up to 20%, while using up\nto 35x fewer rollouts. GEPA also outperforms the leading prompt optimizer,\nMIPROv2, by over 10% across two LLMs, and demonstrates promising results as an\ninference-time search strategy for code optimization.",
      "pdf_url": "http://arxiv.org/pdf/2507.19457v1",
      "published": "2025-07-25T17:42:32+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.19457v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.SE",
        "I.2.7; I.2.6; I.2.4; I.2.8"
      ]
    },
    {
      "title": "Step-3 is Large yet Affordable: Model-system Co-design for Cost-effective Decoding",
      "authors": [
        "StepFun",
        ":",
        "Bin Wang",
        "Bojun Wang",
        "Changyi Wan",
        "Guanzhe Huang",
        "Hanpeng Hu",
        "Haonan Jia",
        "Hao Nie",
        "Mingliang Li",
        "Nuo Chen",
        "Siyu Chen",
        "Song Yuan",
        "Wuxun Xie",
        "Xiaoniu Song",
        "Xing Chen",
        "Xingping Yang",
        "Xuelin Zhang",
        "Yanbo Yu",
        "Yaoyu Wang",
        "Yibo Zhu",
        "Yimin Jiang",
        "Yu Zhou",
        "Yuanwei Lu",
        "Houyi Li",
        "Jingcheng Hu",
        "Ka Man Lo",
        "Ailin Huang",
        "Binxing Jiao",
        "Bo Li",
        "Boyu Chen",
        "Changxin Miao",
        "Chang Lou",
        "Chen Hu",
        "Chen Xu",
        "Chenfeng Yu",
        "Chengyuan Yao",
        "Daokuan Lv",
        "Dapeng Shi",
        "Deshan Sun",
        "Ding Huang",
        "Dingyuan Hu",
        "Dongqing Pang",
        "Enle Liu",
        "Fajie Zhang",
        "Fanqi Wan",
        "Gulin Yan",
        "Han Zhang",
        "Han Zhou",
        "Hanghao Wu",
        "Hangyu Guo",
        "Hanqi Chen",
        "Hanshan Zhang",
        "Hao Wu",
        "Haocheng Zhang",
        "Haolong Yan",
        "Haoran Lv",
        "Haoran Wei",
        "Hebin Zhou",
        "Heng Wang",
        "Heng Wang",
        "Hongxin Li",
        "Hongyu Zhou",
        "Hongyuan Wang",
        "Huiyong Guo",
        "Jia Wang",
        "Jiahao Gong",
        "Jialing Xie",
        "Jian Zhou",
        "Jianjian Sun",
        "Jiaoren Wu",
        "Jiaran Zhang",
        "Jiayu Liu",
        "Jie Cheng",
        "Jie Luo",
        "Jie Yan",
        "Jie Yang",
        "Jieyi Hou",
        "Jinguang Zhang",
        "Jinlan Cao",
        "Jisheng Yin",
        "Junfeng Liu",
        "Junhao Huang",
        "Junzhe Lin",
        "Kaijun Tan",
        "Kaixiang Li",
        "Kang An",
        "Kangheng Lin",
        "Kenkun Liu",
        "Lei Yang",
        "Liang Zhao",
        "Liangyu Chen",
        "Lieyu Shi",
        "Liguo Tan",
        "Lin Lin",
        "Lin Zhang",
        "Lina Chen",
        "Liwen Huang",
        "Liying Shi",
        "Longlong Gu",
        "Mei Chen",
        "Mengqiang Ren",
        "Ming Li",
        "Mingzhe Chen",
        "Na Wang",
        "Nan Wu",
        "Qi Han",
        "Qian Zhao",
        "Qiang Zhang",
        "Qianni Liu",
        "Qiaohui Chen",
        "Qiling Wu",
        "Qinglin He",
        "Qinyuan Tan",
        "Qiufeng Wang",
        "Qiuping Wu",
        "Qiuyan Liang",
        "Quan Sun",
        "Rui Li",
        "Ruihang Miao",
        "Ruosi Wan",
        "Ruyan Guo",
        "Shangwu Zhong",
        "Shaoliang Pang",
        "Shengjie Fan",
        "Shijie Shang",
        "Shilei Jiang",
        "Shiliang Yang",
        "Shiming Hao",
        "Shuli Gao",
        "Siming Huang",
        "Siqi Liu",
        "Tiancheng Cao",
        "Tianhao Cheng",
        "Tianhao Peng",
        "Wang You",
        "Wei Ji",
        "Wen Sun",
        "Wenjin Deng",
        "Wenqing He",
        "Wenzhen Zheng",
        "Xi Chen",
        "Xiangwen Kong",
        "Xianzhen Luo",
        "Xiaobo Yang",
        "Xiaojia Liu",
        "Xiaoxiao Ren",
        "Xin Han",
        "Xin Li",
        "Xin Wu",
        "Xu Zhao",
        "Yanan Wei",
        "Yang Li",
        "Yangguang Li",
        "Yangshijie Xu",
        "Yanming Xu",
        "Yaqiang Shi",
        "Yeqing Shen",
        "Yi Yang",
        "Yifei Yang",
        "Yifeng Gong",
        "Yihan Chen",
        "Yijing Yang",
        "Yinmin Zhang",
        "Yizhuang Zhou",
        "Yuanhao Ding",
        "Yuantao Fan",
        "Yuanzhen Yang",
        "Yuchu Luo",
        "Yue Peng",
        "Yufan Lu",
        "Yuhang Deng",
        "Yuhe Yin",
        "Yujie Liu",
        "Yukun Chen",
        "Yuling Zhao",
        "Yun Mou",
        "Yunlong Li",
        "Yunzhou Ju",
        "Yusheng Li",
        "Yuxiang Yang",
        "Yuxiang Zhang",
        "Yuyang Chen",
        "Zejia Weng",
        "Zhe Xie",
        "Zheng Ge",
        "Zheng Gong",
        "Zhenyi Lu",
        "Zhewei Huang",
        "Zhichao Chang",
        "Zhiguo Huang",
        "Zhirui Wang",
        "Zidong Yang",
        "Zili Wang",
        "Ziqi Wang",
        "Zixin Zhang",
        "Binxing Jiao",
        "Daxin Jiang",
        "Heung-Yeung Shum",
        "Xiangyu Zhang"
      ],
      "abstract": "Large language models (LLMs) face low hardware efficiency during decoding,\nespecially for long-context reasoning tasks. This paper introduces Step-3, a\n321B-parameter VLM with hardware-aware model-system co-design optimized for\nminimizing decoding costs. Step-3 innovates in two key dimensions: (1) A novel\nMulti-Matrix Factorization Attention (MFA) mechanism that significantly reduces\nboth KV cache size and computation while maintaining high attention\nexpressiveness, and (2) Attention-FFN Disaggregation (AFD), a distributed\ninference system that decouples attention and Feed-Forward Network (FFN) layers\ninto specialized subsystems. This co-design achieves unprecedented cost\nefficiency: Step-3 significantly reduces theoretical decoding costs compared\nwith models like DeepSeek-V3 and Qwen3 MoE 235B, with the gains widening at\nlonger context. Step-3 achieves low cost while activating 38B parameters per\ntoken (more than DeepSeek-V3 and Qwen3 MoE 235B), demonstrating that\nhardware-aligned attention arithmetic intensity, MoE sparsity, and AFD are\ncritical to cost-effectiveness. We perform a head-to-head comparison with\nDeepSeek-V3 in its favorable scenarios. Our implementation on Hopper GPUs\nachieves a decoding throughput of up to 4,039 tokens per second per GPU under\n50ms TPOT SLA (4K context, FP8, no MTP). It is higher than DeepSeek-V3's 2,324\nin the same setup and sets a new Pareto frontier for LLM decoding.",
      "pdf_url": "http://arxiv.org/pdf/2507.19427v1",
      "published": "2025-07-25T16:53:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.19427v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "On Arbitrary Predictions from Equally Valid Models",
      "authors": [
        "Sarah Lockfisch",
        "Kristian Schwethelm",
        "Martin Menten",
        "Rickmer Braren",
        "Daniel Rueckert",
        "Alexander Ziller",
        "Georgios Kaissis"
      ],
      "abstract": "Model multiplicity refers to the existence of multiple machine learning\nmodels that describe the data equally well but may produce different\npredictions on individual samples. In medicine, these models can admit\nconflicting predictions for the same patient -- a risk that is poorly\nunderstood and insufficiently addressed.\n  In this study, we empirically analyze the extent, drivers, and ramifications\nof predictive multiplicity across diverse medical tasks and model\narchitectures, and show that even small ensembles can mitigate/eliminate\npredictive multiplicity in practice. Our analysis reveals that (1) standard\nvalidation metrics fail to identify a uniquely optimal model and (2) a\nsubstantial amount of predictions hinges on arbitrary choices made during model\ndevelopment. Using multiple models instead of a single model reveals instances\nwhere predictions differ across equally plausible models -- highlighting\npatients that would receive arbitrary diagnoses if any single model were used.\nIn contrast, (3) a small ensemble paired with an abstention strategy can\neffectively mitigate measurable predictive multiplicity in practice;\npredictions with high inter-model consensus may thus be amenable to automated\nclassification. While accuracy is not a principled antidote to predictive\nmultiplicity, we find that (4) higher accuracy achieved through increased model\ncapacity reduces predictive multiplicity.\n  Our findings underscore the clinical importance of accounting for model\nmultiplicity and advocate for ensemble-based strategies to improve diagnostic\nreliability. In cases where models fail to reach sufficient consensus, we\nrecommend deferring decisions to expert review.",
      "pdf_url": "http://arxiv.org/pdf/2507.19408v1",
      "published": "2025-07-25T16:15:59+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.19408v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "SDVDiag: A Modular Platform for the Diagnosis of Connected Vehicle Functions",
      "authors": [
        "Matthias Weiß",
        "Falk Dettinger",
        "Michael Weyrich"
      ],
      "abstract": "Connected and software-defined vehicles promise to offer a broad range of\nservices and advanced functions to customers, aiming to increase passenger\ncomfort and support autonomous driving capabilities. Due to the high\nreliability and availability requirements of connected vehicles, it is crucial\nto resolve any occurring failures quickly. To achieve this however, a complex\ncloud/edge architecture with a mesh of dependencies must be navigated to\ndiagnose the responsible root cause. As such, manual analyses become unfeasible\nsince they would significantly delay the troubleshooting.\n  To address this challenge, this paper presents SDVDiag, an extensible\nplatform for the automated diagnosis of connected vehicle functions. The\nplatform enables the creation of pipelines that cover all steps from initial\ndata collection to the tracing of potential root causes. In addition, SDVDiag\nsupports self-adaptive behavior by the ability to exchange modules at runtime.\nDependencies between functions are detected and continuously updated, resulting\nin a dynamic graph view of the system. In addition, vital system metrics are\nmonitored for anomalies. Whenever an incident is investigated, a snapshot of\nthe graph is taken and augmented by relevant anomalies. Finally, the analysis\nis performed by traversing the graph and creating a ranking of the most likely\ncauses.\n  To evaluate the platform, it is deployed inside an 5G test fleet environment\nfor connected vehicle functions. The results show that injected faults can be\ndetected reliably. As such, the platform offers the potential to gain new\ninsights and reduce downtime by identifying problems and their causes at an\nearly stage.",
      "pdf_url": "http://arxiv.org/pdf/2507.19403v1",
      "published": "2025-07-25T16:09:27+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.19403v1",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.DC",
        "B.8.2; C.2.4"
      ]
    },
    {
      "title": "Running in CIRCLE? A Simple Benchmark for LLM Code Interpreter Security",
      "authors": [
        "Gabriel Chua"
      ],
      "abstract": "As large language models (LLMs) increasingly integrate native code\ninterpreters, they enable powerful real-time execution capabilities,\nsubstantially expanding their utility. However, such integrations introduce\npotential system-level cybersecurity threats, fundamentally different from\nprompt-based vulnerabilities. To systematically evaluate these\ninterpreter-specific risks, we propose CIRCLE (Code-Interpreter Resilience\nCheck for LLM Exploits), a simple benchmark comprising 1,260 prompts targeting\nCPU, memory, and disk resource exhaustion. Each risk category includes\nexplicitly malicious (\"direct\") and plausibly benign (\"indirect\") prompt\nvariants. Our automated evaluation framework assesses not only whether LLMs\nrefuse or generates risky code, but also executes the generated code within the\ninterpreter environment to evaluate code correctness, simplifications made by\nthe LLM to make the code safe, or execution timeouts. Evaluating 7 commercially\navailable models from OpenAI and Google, we uncover significant and\ninconsistent vulnerabilities. For instance, evaluations show substantial\ndisparities even within providers - OpenAI's o4-mini correctly refuses risky\nrequests at 7.1%, notably higher rates compared to GPT-4.1 at 0.5%. Results\nparticularly underscore that indirect, socially-engineered prompts\nsubstantially weaken model defenses. This highlights an urgent need for\ninterpreter-specific cybersecurity benchmarks, dedicated mitigation tools\n(e.g., guardrails), and clear industry standards to guide safe and responsible\ndeployment of LLM interpreter integrations. The benchmark dataset and\nevaluation code are publicly released to foster further research.",
      "pdf_url": "http://arxiv.org/pdf/2507.19399v1",
      "published": "2025-07-25T16:06:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.19399v1",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "title": "CXR-CML: Improved zero-shot classification of long-tailed multi-label diseases in Chest X-Rays",
      "authors": [
        "Rajesh Madhipati",
        "Sheethal Bhat",
        "Lukas Buess",
        "Andreas Maier"
      ],
      "abstract": "Chest radiography (CXR) plays a crucial role in the diagnosis of various\ndiseases. However, the inherent class imbalance in the distribution of clinical\nfindings presents a significant challenge for current self-supervised deep\nlearning models. These models often fail to accurately classify long-tailed\nclasses. Current Vision-Language models such as Contrastive Language Image\nPre-training (CLIP) models effectively model the manifold distribution of the\nlatent space, enabling high zero-shot classification accuracies. Although CLIP\nperforms well on most of the primary classes in the dataset, our work reveals\nthat its effectiveness decreases significantly for classes with a long-tailed\ndistribution. Our approach employs a class-weighting mechanism that directly\naligns with the distribution of classes within the latent space. This method\nensures a substantial improvement in overall classification performance, with\nparticular emphasis on enhancing the recognition and accuracy of rarely\nobserved classes. We accomplish this by applying Gaussian Mixture Model (GMM)\nclustering to the latent space. The subsequent clusters are further refined by\nStudent t-distribution, followed by a metric loss that utilizes the altered\nembeddings. Our approach facilitates stable and adaptive clustering of the\nfeatures. This results in a notable average improvement of 7\\% points in\nzero-shot AUC scores across 40 classes in the MIMIC-CXR-JPG dataset from\nprevious SOTA models.",
      "pdf_url": "http://arxiv.org/pdf/2507.19398v1",
      "published": "2025-07-25T16:05:47+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.19398v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "ReCatcher: Towards LLMs Regression Testing for Code Generation",
      "authors": [
        "Altaf Allah Abbassi",
        "Leuson Da Silva",
        "Amin Nikanjam",
        "Foutse Khomh"
      ],
      "abstract": "Large Language Models (LLMs) for code generation evolve rapidly through\nfine-tuning, merging, or new model releases. However, such updates can\nintroduce regressions, not only in correctness but also in code quality and\nperformance. To address this, we present ReCatcher, a regression testing\nframework for Python code generation. ReCatcher systematically compares two\nLLMs, typically a current model and a candidate update, across three\ndimensions: logical correctness, static code quality, and execution\nperformance. We apply ReCatcher to assess regressions across three update\nscenarios, fine-tuning, merging, and model release, using CodeLlama,\nDeepSeek-Coder, and GPT-4o. Our evaluation shows that fine-tuning with\ncross-language datasets increases syntax errors by up to 12%. Merging with\ngeneral-purpose models like Llama2 leads to regressions in correctness by up to\n18%. GPT-4o introduces regressions of up to 50% in handling missing imports\ncompared to GPT-3.5-turbo, while GPT-4o-mini suffers up to 80% performance\ndegradation in execution time versus GPT-4o. Overall, logical correctness,\nperformance, and error handling (e.g., syntax errors and missing imports) are\nthe most regression-prone areas. Comparing ReCatcher with baseline solutions,\nit presents better and consistent accuracy across logical and performance\naspects. ReCatcher highlights the importance of systematic regression\nevaluation before adopting new models, while assisting researchers and\npractitioners in making more informed update decisions.",
      "pdf_url": "http://arxiv.org/pdf/2507.19390v1",
      "published": "2025-07-25T15:45:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.19390v1",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "Data Augmentation for Spoken Grammatical Error Correction",
      "authors": [
        "Penny Karanasou",
        "Mengjie Qian",
        "Stefano Bannò",
        "Mark J. F. Gales",
        "Kate M. Knill"
      ],
      "abstract": "While there exist strong benchmark datasets for grammatical error correction\n(GEC), high-quality annotated spoken datasets for Spoken GEC (SGEC) are still\nunder-resourced. In this paper, we propose a fully automated method to generate\naudio-text pairs with grammatical errors and disfluencies. Moreover, we propose\na series of objective metrics that can be used to evaluate the generated data\nand choose the more suitable dataset for SGEC. The goal is to generate an\naugmented dataset that maintains the textual and acoustic characteristics of\nthe original data while providing new types of errors. This augmented dataset\nshould augment and enrich the original corpus without altering the language\nassessment scores of the second language (L2) learners. We evaluate the use of\nthe augmented corpus both for written GEC (the text part) and for SGEC (the\naudio-text pairs). Our experiments are conducted on the S\\&I Corpus, the first\npublicly available speech dataset with grammar error annotations.",
      "pdf_url": "http://arxiv.org/pdf/2507.19374v1",
      "published": "2025-07-25T15:25:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.19374v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ]
    },
    {
      "title": "Learning neuro-symbolic convergent term rewriting systems",
      "authors": [
        "Flavio Petruzzellis",
        "Alberto Testolin",
        "Alessandro Sperduti"
      ],
      "abstract": "Building neural systems that can learn to execute symbolic algorithms is a\nchallenging open problem in artificial intelligence, especially when aiming for\nstrong generalization and out-of-distribution performance. In this work, we\nintroduce a general framework for learning convergent term rewriting systems\nusing a neuro-symbolic architecture inspired by the rewriting algorithm itself.\nWe present two modular implementations of such architecture: the Neural\nRewriting System (NRS) and the Fast Neural Rewriting System (FastNRS). As a\nresult of algorithmic-inspired design and key architectural elements, both\nmodels can generalize to out-of-distribution instances, with FastNRS offering\nsignificant improvements in terms of memory efficiency, training speed, and\ninference time. We evaluate both architectures on four tasks involving the\nsimplification of mathematical formulas and further demonstrate their\nversatility in a multi-domain learning scenario, where a single model is\ntrained to solve multiple types of problems simultaneously. The proposed system\nsignificantly outperforms two strong neural baselines: the Neural Data Router,\na recent transformer variant specifically designed to solve algorithmic\nproblems, and GPT-4o, one of the most powerful general-purpose large-language\nmodels. Moreover, our system matches or outperforms the latest o1-preview model\nfrom OpenAI that excels in reasoning benchmarks.",
      "pdf_url": "http://arxiv.org/pdf/2507.19372v1",
      "published": "2025-07-25T15:24:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.19372v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Counterfactual Explanations in Medical Imaging: Exploring SPN-Guided Latent Space Manipulation",
      "authors": [
        "Julia Siekiera",
        "Stefan Kramer"
      ],
      "abstract": "Artificial intelligence is increasingly leveraged across various domains to\nautomate decision-making processes that significantly impact human lives. In\nmedical image analysis, deep learning models have demonstrated remarkable\nperformance. However, their inherent complexity makes them black box systems,\nraising concerns about reliability and interpretability. Counterfactual\nexplanations provide comprehensible insights into decision processes by\npresenting hypothetical \"what-if\" scenarios that alter model classifications.\nBy examining input alterations, counterfactual explanations provide patterns\nthat influence the decision-making process. Despite their potential, generating\nplausible counterfactuals that adhere to similarity constraints providing\nhuman-interpretable explanations remains a challenge. In this paper, we\ninvestigate this challenge by a model-specific optimization approach. While\ndeep generative models such as variational autoencoders (VAEs) exhibit\nsignificant generative power, probabilistic models like sum-product networks\n(SPNs) efficiently represent complex joint probability distributions. By\nmodeling the likelihood of a semi-supervised VAE's latent space with an SPN, we\nleverage its dual role as both a latent space descriptor and a classifier for a\ngiven discrimination task. This formulation enables the optimization of latent\nspace counterfactuals that are both close to the original data distribution and\naligned with the target class distribution. We conduct experimental evaluation\non the cheXpert dataset. To evaluate the effectiveness of the integration of\nSPNs, our SPN-guided latent space manipulation is compared against a neural\nnetwork baseline. Additionally, the trade-off between latent variable\nregularization and counterfactual quality is analyzed.",
      "pdf_url": "http://arxiv.org/pdf/2507.19368v1",
      "published": "2025-07-25T15:19:32+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.19368v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Integrating LLM in Agent-Based Social Simulation: Opportunities and Challenges",
      "authors": [
        "Patrick Taillandier",
        "Jean Daniel Zucker",
        "Arnaud Grignard",
        "Benoit Gaudou",
        "Nghi Quang Huynh",
        "Alexis Drogoul"
      ],
      "abstract": "This position paper examines the use of Large Language Models (LLMs) in\nsocial simulation, analyzing both their potential and their limitations from a\ncomputational social science perspective. The first part reviews recent\nfindings on the ability of LLMs to replicate key aspects of human cognition,\nincluding Theory of Mind reasoning and social inference, while also\nhighlighting significant limitations such as cognitive biases, lack of true\nunderstanding, and inconsistencies in behavior. The second part surveys\nemerging applications of LLMs in multi-agent simulation frameworks, focusing on\nsystem architectures, scale, and validation strategies. Notable projects such\nas Generative Agents (Smallville) and AgentSociety are discussed in terms of\ntheir design choices, empirical grounding, and methodological innovations.\nParticular attention is given to the challenges of behavioral fidelity,\ncalibration, and reproducibility in large-scale LLM-driven simulations. The\nfinal section distinguishes between contexts where LLMs, like other black-box\nsystems, offer direct value-such as interactive simulations and serious\ngames-and those where their use is more problematic, notably in explanatory or\npredictive modeling. The paper concludes by advocating for hybrid approaches\nthat integrate LLMs into traditional agent-based modeling platforms (GAMA,\nNetlogo, etc), enabling modelers to combine the expressive flexibility of\nlanguage-based reasoning with the transparency and analytical rigor of\nclassical rule-based systems.",
      "pdf_url": "http://arxiv.org/pdf/2507.19364v1",
      "published": "2025-07-25T15:15:35+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.19364v1",
      "categories": [
        "cs.AI",
        "cs.MA"
      ]
    },
    {
      "title": "LOTUS: A Leaderboard for Detailed Image Captioning from Quality to Societal Bias and User Preferences",
      "authors": [
        "Yusuke Hirota",
        "Boyi Li",
        "Ryo Hachiuma",
        "Yueh-Hua Wu",
        "Boris Ivanovic",
        "Yuta Nakashima",
        "Marco Pavone",
        "Yejin Choi",
        "Yu-Chiang Frank Wang",
        "Chao-Han Huck Yang"
      ],
      "abstract": "Large Vision-Language Models (LVLMs) have transformed image captioning,\nshifting from concise captions to detailed descriptions. We introduce LOTUS, a\nleaderboard for evaluating detailed captions, addressing three main gaps in\nexisting evaluations: lack of standardized criteria, bias-aware assessments,\nand user preference considerations. LOTUS comprehensively evaluates various\naspects, including caption quality (e.g., alignment, descriptiveness), risks\n(\\eg, hallucination), and societal biases (e.g., gender bias) while enabling\npreference-oriented evaluations by tailoring criteria to diverse user\npreferences. Our analysis of recent LVLMs reveals no single model excels across\nall criteria, while correlations emerge between caption detail and bias risks.\nPreference-oriented evaluations demonstrate that optimal model selection\ndepends on user priorities.",
      "pdf_url": "http://arxiv.org/pdf/2507.19362v1",
      "published": "2025-07-25T15:12:42+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.19362v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.LG"
      ]
    },
    {
      "title": "SpeechIQ: Speech Intelligence Quotient Across Cognitive Levels in Voice Understanding Large Language Models",
      "authors": [
        "Zhen Wan",
        "Chao-Han Huck Yang",
        "Yahan Yu",
        "Jinchuan Tian",
        "Sheng Li",
        "Ke Hu",
        "Zhehuai Chen",
        "Shinji Watanabe",
        "Fei Cheng",
        "Chenhui Chu",
        "Sadao Kurohashi"
      ],
      "abstract": "We introduce Speech-based Intelligence Quotient (SIQ) as a new form of human\ncognition-inspired evaluation pipeline for voice understanding large language\nmodels, LLM Voice, designed to assess their voice understanding ability. Moving\nbeyond popular voice understanding metrics such as word error rate (WER), SIQ\nexamines LLM Voice across three cognitive levels motivated by Bloom's Taxonomy:\n(1) Remembering (i.e., WER for verbatim accuracy); (2) Understanding (i.e.,\nsimilarity of LLM's interpretations); and (3) Application (i.e., QA accuracy\nfor simulating downstream tasks). We demonstrate that SIQ not only quantifies\nvoice understanding abilities but also provides unified comparisons between\ncascaded methods (e.g., ASR LLM) and end-to-end models, identifies annotation\nerrors in existing benchmarks, and detects hallucinations in LLM Voice. Our\nframework represents a first-of-its-kind intelligence examination that bridges\ncognitive principles with voice-oriented benchmarks, while exposing overlooked\nchallenges in multi-modal training.",
      "pdf_url": "http://arxiv.org/pdf/2507.19361v1",
      "published": "2025-07-25T15:12:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.19361v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SC",
        "cs.SD",
        "eess.AS"
      ]
    },
    {
      "title": "Smooth Reading: Bridging the Gap of Recurrent LLM to Self-Attention LLM on Long-Context Tasks",
      "authors": [
        "Kai Liu",
        "Zhan Su",
        "Peijie Dong",
        "Fengran Mo",
        "Jianfei Gao",
        "ShaoTing Zhang",
        "Kai Chen"
      ],
      "abstract": "Recently, recurrent large language models (Recurrent LLMs) with linear\ncomputational complexity have re-emerged as efficient alternatives to\nself-attention-based LLMs (Self-Attention LLMs), which have quadratic\ncomplexity. However, Recurrent LLMs often underperform on long-context tasks\ndue to their limited fixed-size memory. Previous research has primarily focused\non enhancing the memory capacity of Recurrent LLMs through architectural\ninnovations, but these approaches have not yet enabled Recurrent LLMs to match\nthe performance of Self-Attention LLMs on long-context tasks. We argue that\nthis limitation arises because processing the entire context at once is not\nwell-suited for Recurrent LLMs. In this paper, we propose Smooth Reading, a\nchunk-wise inference method inspired by human reading strategies. Smooth\nReading processes context in chunks and iteratively summarizes the contextual\ninformation, thereby reducing memory demands and making the approach more\ncompatible with Recurrent LLMs. Our experimental results show that this method\nsubstantially narrows the performance gap between Recurrent and Self-Attention\nLLMs on long-context tasks, while preserving the efficiency advantages of\nRecurrent LLMs. Our Smooth Reading boosts SWA-3B-4k (a Recurrent LLM) from\n5.68% lower to 3.61% higher performance than Self-Attention LLMs on LongBench.\nBesides, our method maintains the high efficiency, training 3x faster and\ninferring 2x faster at 64k context compared to Self-Attention LLMs. To our\nknowledge, this is the first work to achieve comparable performance using\nRecurrent LLMs compared with Self-Attention LLMs on long-context tasks. We hope\nour method will inspire future research in this area. To facilitate further\nprogress, we will release code and dataset.",
      "pdf_url": "http://arxiv.org/pdf/2507.19353v1",
      "published": "2025-07-25T15:02:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.19353v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Doubling Your Data in Minutes: Ultra-fast Tabular Data Generation via LLM-Induced Dependency Graphs",
      "authors": [
        "Shuo Yang",
        "Zheyu Zhang",
        "Bardh Prenkaj",
        "Gjergji Kasneci"
      ],
      "abstract": "Tabular data is critical across diverse domains, yet high-quality datasets\nremain scarce due to privacy concerns and the cost of collection. Contemporary\napproaches adopt large language models (LLMs) for tabular augmentation, but\nexhibit two major limitations: (1) dense dependency modeling among tabular\nfeatures that can introduce bias, and (2) high computational overhead in\nsampling. To address these issues, we propose SPADA for SPArse\nDependency-driven Augmentation, a lightweight generative framework that\nexplicitly captures sparse dependencies via an LLM-induced graph. We treat each\nfeature as a node and synthesize values by traversing the graph, conditioning\neach feature solely on its parent nodes. We explore two synthesis strategies: a\nnon-parametric method using Gaussian kernel density estimation, and a\nconditional normalizing flow model that learns invertible mappings for\nconditional density estimation. Experiments on four datasets show that SPADA\nreduces constraint violations by 4% compared to diffusion-based methods and\naccelerates generation by nearly 9,500 times over LLM-based baselines.",
      "pdf_url": "http://arxiv.org/pdf/2507.19334v1",
      "published": "2025-07-25T14:43:50+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.19334v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "SIDE: Sparse Information Disentanglement for Explainable Artificial Intelligence",
      "authors": [
        "Viktar Dubovik",
        "Łukasz Struski",
        "Jacek Tabor",
        "Dawid Rymarczyk"
      ],
      "abstract": "Understanding the decisions made by deep neural networks is essential in\nhigh-stakes domains such as medical imaging and autonomous driving. Yet, these\nmodels often lack transparency, particularly in computer vision.\nPrototypical-parts-based neural networks have emerged as a promising solution\nby offering concept-level explanations. However, most are limited to\nfine-grained classification tasks, with few exceptions such as InfoDisent.\nInfoDisent extends prototypical models to large-scale datasets like ImageNet,\nbut produces complex explanations.\n  We introduce Sparse Information Disentanglement for Explainability (SIDE), a\nnovel method that improves the interpretability of prototypical parts through a\ndedicated training and pruning scheme that enforces sparsity. Combined with\nsigmoid activations in place of softmax, this approach allows SIDE to associate\neach class with only a small set of relevant prototypes. Extensive experiments\nshow that SIDE matches the accuracy of existing methods while reducing\nexplanation size by over $90\\%$, substantially enhancing the understandability\nof prototype-based explanations.",
      "pdf_url": "http://arxiv.org/pdf/2507.19321v1",
      "published": "2025-07-25T14:34:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.19321v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Multistream Network for LiDAR and Camera-based 3D Object Detection in Outdoor Scenes",
      "authors": [
        "Muhammad Ibrahim",
        "Naveed Akhtar",
        "Haitian Wang",
        "Saeed Anwar",
        "Ajmal Mian"
      ],
      "abstract": "Fusion of LiDAR and RGB data has the potential to enhance outdoor 3D object\ndetection accuracy. To address real-world challenges in outdoor 3D object\ndetection, fusion of LiDAR and RGB input has started gaining traction. However,\neffective integration of these modalities for precise object detection task\nstill remains a largely open problem. To address that, we propose a MultiStream\nDetection (MuStD) network, that meticulously extracts task-relevant information\nfrom both data modalities. The network follows a three-stream structure. Its\nLiDAR-PillarNet stream extracts sparse 2D pillar features from the LiDAR input\nwhile the LiDAR-Height Compression stream computes Bird's-Eye View features. An\nadditional 3D Multimodal stream combines RGB and LiDAR features using UV\nmapping and polar coordinate indexing. Eventually, the features containing\ncomprehensive spatial, textural and geometric information are carefully fused\nand fed to a detection head for 3D object detection. Our extensive evaluation\non the challenging KITTI Object Detection Benchmark using public testing server\nat\nhttps://www.cvlibs.net/datasets/kitti/eval_object_detail.php?&result=d162ec699d6992040e34314d19ab7f5c217075e0\nestablishes the efficacy of our method by achieving new state-of-the-art or\nhighly competitive results in different categories while remaining among the\nmost efficient methods. Our code will be released through MuStD GitHub\nrepository at https://github.com/IbrahimUWA/MuStD.git",
      "pdf_url": "http://arxiv.org/pdf/2507.19304v1",
      "published": "2025-07-25T14:20:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.19304v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Controlling Topological Defects in Polar Fluids via Reinforcement Learning",
      "authors": [
        "Abhinav Singh",
        "Petros Koumoutsakos"
      ],
      "abstract": "Topological defects in active polar fluids exhibit complex dynamics driven by\ninternally generated stresses, reflecting the deep interplay between topology,\nflow, and non-equilibrium hydrodynamics. Feedback control offers a powerful\nmeans to guide such systems, enabling transitions between dynamic states. We\ninvestigated closed-loop steering of integer-charged defects in a confined\nactive fluid by modulating the spatial profile of activity. Using a continuum\nhydrodynamic model, we show that localized control of active stress induces\nflow fields that can reposition and direct defects along prescribed\ntrajectories by exploiting non-linear couplings in the system. A reinforcement\nlearning framework is used to discover effective control strategies that\nproduce robust defect transport across both trained and novel trajectories. The\nresults highlight how AI agents can learn the underlying dynamics and spatially\nstructure activity to manipulate topological excitations, offering insights\ninto the controllability of active matter and the design of adaptive,\nself-organized materials.",
      "pdf_url": "http://arxiv.org/pdf/2507.19298v1",
      "published": "2025-07-25T14:12:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.19298v1",
      "categories": [
        "cond-mat.soft",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Towards LLM-Enhanced Group Recommender Systems",
      "authors": [
        "Sebastian Lubos",
        "Alexander Felfernig",
        "Thi Ngoc Trang Tran",
        "Viet-Man Le",
        "Damian Garber",
        "Manuel Henrich",
        "Reinhard Willfort",
        "Jeremias Fuchs"
      ],
      "abstract": "In contrast to single-user recommender systems, group recommender systems are\ndesigned to generate and explain recommendations for groups. This\ngroup-oriented setting introduces additional complexities, as several factors -\nabsent in individual contexts - must be addressed. These include understanding\ngroup dynamics (e.g., social dependencies within the group), defining effective\ndecision-making processes, ensuring that recommendations are suitable for all\ngroup members, and providing group-level explanations as well as explanations\nfor individual users. In this paper, we analyze in which way large language\nmodels (LLMs) can support these aspects and help to increase the overall\ndecision support quality and applicability of group recommender systems.",
      "pdf_url": "http://arxiv.org/pdf/2507.19283v1",
      "published": "2025-07-25T13:59:54+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.19283v1",
      "categories": [
        "cs.IR",
        "cs.AI"
      ]
    },
    {
      "title": "Fine-Tuning Multilingual Language Models for Code Review: An Empirical Study on Industrial C# Projects",
      "authors": [
        "Igli Begolli",
        "Meltem Aksoy",
        "Daniel Neider"
      ],
      "abstract": "Code review is essential for maintaining software quality but often\ntime-consuming and cognitively demanding, especially in industrial\nenvironments. Recent advancements in language models (LMs) have opened new\navenues for automating core review tasks. This study presents the empirical\nevaluation of monolingual fine-tuning on the performance of open-source LMs\nacross three key automated code review tasks: Code Change Quality Estimation,\nReview Comment Generation, and Code Refinement. We fine-tuned three distinct\nmodels, CodeReviewer, CodeLlama-7B, and DeepSeek-R1-Distill, on a C\\# specific\ndataset combining public benchmarks with industrial repositories. Our study\ninvestigates how different configurations of programming languages and natural\nlanguages in the training data affect LM performance, particularly in comment\ngeneration. Additionally, we benchmark the fine-tuned models against an\nautomated software analysis tool (ASAT) and human reviewers to evaluate their\npractical utility in real-world settings. Our results show that monolingual\nfine-tuning improves model accuracy and relevance compared to multilingual\nbaselines. While LMs can effectively support code review workflows, especially\nfor routine or repetitive tasks, human reviewers remain superior in handling\nsemantically complex or context-sensitive changes. Our findings highlight the\nimportance of language alignment and task-specific adaptation in optimizing LMs\nfor automated code review.",
      "pdf_url": "http://arxiv.org/pdf/2507.19271v1",
      "published": "2025-07-25T13:49:24+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.19271v1",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.PL"
      ]
    },
    {
      "title": "Modeling Uncertainty: Constraint-Based Belief States in Imperfect-Information Games",
      "authors": [
        "Achille Morenville",
        "Éric Piette"
      ],
      "abstract": "In imperfect-information games, agents must make decisions based on partial\nknowledge of the game state. The Belief Stochastic Game model addresses this\nchallenge by delegating state estimation to the game model itself. This allows\nagents to operate on externally provided belief states, thereby reducing the\nneed for game-specific inference logic. This paper investigates two approaches\nto represent beliefs in games with hidden piece identities: a constraint-based\nmodel using Constraint Satisfaction Problems and a probabilistic extension\nusing Belief Propagation to estimate marginal probabilities. We evaluated the\nimpact of both representations using general-purpose agents across two\ndifferent games. Our findings indicate that constraint-based beliefs yield\nresults comparable to those of probabilistic inference, with minimal\ndifferences in agent performance. This suggests that constraint-based belief\nstates alone may suffice for effective decision-making in many settings.",
      "pdf_url": "http://arxiv.org/pdf/2507.19263v1",
      "published": "2025-07-25T13:38:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.19263v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Knowledge Grafting: A Mechanism for Optimizing AI Model Deployment in Resource-Constrained Environments",
      "authors": [
        "Osama Almurshed",
        "Ashish Kaushal",
        "Asmail Muftah",
        "Nitin Auluck",
        "Omer Rana"
      ],
      "abstract": "The increasing adoption of Artificial Intelligence (AI) has led to larger,\nmore complex models with numerous parameters that require substantial computing\npower -- resources often unavailable in many real-world application scenarios.\nOur paper addresses this challenge by introducing knowledge grafting, a novel\nmechanism that optimizes AI models for resource-constrained environments by\ntransferring selected features (the scion) from a large donor model to a\nsmaller rootstock model. The approach achieves an 88.54% reduction in model\nsize (from 64.39 MB to 7.38 MB), while improving generalization capability of\nthe model. Our new rootstock model achieves 89.97% validation accuracy (vs.\ndonor's 87.47%), maintains lower validation loss (0.2976 vs. 0.5068), and\nperforms exceptionally well on unseen test data with 90.45% accuracy. It\naddresses the typical size vs performance trade-off, and enables deployment of\nAI frameworks on resource-constrained devices with enhanced performance. We\nhave tested our approach on an agricultural weed detection scenario, however,\nit can be extended across various edge computing scenarios, potentially\naccelerating AI adoption in areas with limited hardware/software support -- by\nmirroring in a similar manner the horticultural grafting enables productive\ncultivation in challenging agri-based environments.",
      "pdf_url": "http://arxiv.org/pdf/2507.19261v1",
      "published": "2025-07-25T13:37:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.19261v1",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.PF"
      ]
    },
    {
      "title": "A Markov Categorical Framework for Language Modeling",
      "authors": [
        "Yifan Zhang"
      ],
      "abstract": "Auto-regressive language models factorize sequence probabilities and are\ntrained by minimizing the negative log-likelihood (NLL) objective. While\nempirically powerful, a deep theoretical understanding of why this simple\nobjective yields such versatile representations remains elusive. This work\nintroduces a unifying analytical framework using Markov Categories (MCs) to\ndeconstruct the AR generation process and the NLL objective. We model the\nsingle-step generation map as a composition of Markov kernels in the category\nStoch. This compositional view, when enriched with statistical divergences,\nallows us to dissect information flow and learned geometry. Our framework makes\nthree main contributions. First, we provide a formal, information-theoretic\nrationale for the success of modern speculative decoding methods like EAGLE,\nquantifying the information surplus in hidden states that these methods\nexploit. Second, we formalize how NLL minimization forces the model to learn\nnot just the next token, but the data's intrinsic conditional stochasticity, a\nprocess we analyze using categorical entropy. Third, and most centrally, we\nprove that NLL training acts as an implicit form of spectral contrastive\nlearning. By analyzing the information geometry of the model's prediction head,\nwe show that NLL implicitly forces the learned representation space to align\nwith the eigenspectrum of a predictive similarity operator, thereby learning a\ngeometrically structured space without explicit contrastive pairs. This\ncompositional and information-geometric perspective reveals the deep structural\nprinciples underlying the effectiveness of modern LMs. Project Page:\nhttps://github.com/asiresearch/lm-theory",
      "pdf_url": "http://arxiv.org/pdf/2507.19247v1",
      "published": "2025-07-25T13:14:03+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.19247v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Transfinite Fixed Points in Alpay Algebra as Ordinal Game Equilibria in Dependent Type Theory",
      "authors": [
        "Faruk Alpay",
        "Bugra Kilictas",
        "Taylan Alpay"
      ],
      "abstract": "This paper contributes to the Alpay Algebra by demonstrating that the stable\noutcome of a self referential process, obtained by iterating a transformation\nthrough all ordinal stages, is identical to the unique equilibrium of an\nunbounded revision dialogue between a system and its environment. The analysis\ninitially elucidates how classical fixed point theorems guarantee such\nconvergence in finite settings and subsequently extends the argument to the\ntransfinite domain, relying upon well founded induction and principles of order\ntheoretic continuity.\n  Furthermore, the resulting transordinal fixed point operator is embedded into\ndependent type theory, a formalization which permits every step of the\ntransfinite iteration and its limit to be verified within a modern proof\nassistant. This procedure yields a machine checked proof that the iterative\ndialogue necessarily stabilizes and that its limit is unique. The result\nprovides a foundation for Alpay's philosophical claim of semantic convergence\nwithin the framework of constructive logic. By unifying concepts from fixed\npoint theory, game semantics, ordinal analysis, and type theory, this research\nestablishes a broadly accessible yet formally rigorous foundation for reasoning\nabout infinite self referential systems and offers practical tools for\ncertifying their convergence within computational environments.",
      "pdf_url": "http://arxiv.org/pdf/2507.19245v1",
      "published": "2025-07-25T13:12:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.19245v1",
      "categories": [
        "cs.LO",
        "cs.AI",
        "68T27, 03B70, 68Q55"
      ]
    },
    {
      "title": "Virne: A Comprehensive Benchmark for Deep RL-based Network Resource Allocation in NFV",
      "authors": [
        "Tianfu Wang",
        "Liwei Deng",
        "Xi Chen",
        "Junyang Wang",
        "Huiguo He",
        "Leilei Ding",
        "Wei Wu",
        "Qilin Fan",
        "Hui Xiong"
      ],
      "abstract": "Resource allocation (RA) is critical to efficient service deployment in\nNetwork Function Virtualization (NFV), a transformative networking paradigm.\nRecently, deep Reinforcement Learning (RL)-based methods have been showing\npromising potential to address this complexity. However, the lack of a\nsystematic benchmarking framework and thorough analysis hinders the exploration\nof emerging networks and the development of more robust algorithms while\ncausing inconsistent evaluation. In this paper, we introduce Virne, a\ncomprehensive benchmarking framework for the NFV-RA problem, with a focus on\nsupporting deep RL-based methods. Virne provides customizable simulations for\ndiverse network scenarios, including cloud, edge, and 5G environments. It also\nfeatures a modular and extensible implementation pipeline that supports over 30\nmethods of various types, and includes practical evaluation perspectives beyond\neffectiveness, such as scalability, generalization, and scalability.\nFurthermore, we conduct in-depth analysis through extensive experiments to\nprovide valuable insights into performance trade-offs for efficient\nimplementation and offer actionable guidance for future research directions.\nOverall, with its diverse simulations, rich implementations, and extensive\nevaluation capabilities, Virne could serve as a comprehensive benchmark for\nadvancing NFV-RA methods and deep RL applications. The code is publicly\navailable at https://github.com/GeminiLight/virne.",
      "pdf_url": "http://arxiv.org/pdf/2507.19234v1",
      "published": "2025-07-25T12:58:32+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.19234v1",
      "categories": [
        "cs.NI",
        "cs.AI"
      ]
    },
    {
      "title": "Joint Holistic and Lesion Controllable Mammogram Synthesis via Gated Conditional Diffusion Model",
      "authors": [
        "Xin Li",
        "Kaixiang Yang",
        "Qiang Li",
        "Zhiwei Wang"
      ],
      "abstract": "Mammography is the most commonly used imaging modality for breast cancer\nscreening, driving an increasing demand for deep-learning techniques to support\nlarge-scale analysis. However, the development of accurate and robust methods\nis often limited by insufficient data availability and a lack of diversity in\nlesion characteristics. While generative models offer a promising solution for\ndata synthesis, current approaches often fail to adequately emphasize\nlesion-specific features and their relationships with surrounding tissues. In\nthis paper, we propose Gated Conditional Diffusion Model (GCDM), a novel\nframework designed to jointly synthesize holistic mammogram images and\nlocalized lesions. GCDM is built upon a latent denoising diffusion framework,\nwhere the noised latent image is concatenated with a soft mask embedding that\nrepresents breast, lesion, and their transitional regions, ensuring anatomical\ncoherence between them during the denoising process. To further emphasize\nlesion-specific features, GCDM incorporates a gated conditioning branch that\nguides the denoising process by dynamically selecting and fusing the most\nrelevant radiomic and geometric properties of lesions, effectively capturing\ntheir interplay. Experimental results demonstrate that GCDM achieves precise\ncontrol over small lesion areas while enhancing the realism and diversity of\nsynthesized mammograms. These advancements position GCDM as a promising tool\nfor clinical applications in mammogram synthesis. Our code is available at\nhttps://github.com/lixinHUST/Gated-Conditional-Diffusion-Model/",
      "pdf_url": "http://arxiv.org/pdf/2507.19201v1",
      "published": "2025-07-25T12:10:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.19201v1",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Enhancing Diabetic Retinopathy Classification Accuracy through Dual Attention Mechanism in Deep Learning",
      "authors": [
        "Abdul Hannan",
        "Zahid Mahmood",
        "Rizwan Qureshi",
        "Hazrat Ali"
      ],
      "abstract": "Automatic classification of Diabetic Retinopathy (DR) can assist\nophthalmologists in devising personalized treatment plans, making it a critical\ncomponent of clinical practice. However, imbalanced data distribution in the\ndataset becomes a bottleneck in the generalization of deep learning models\ntrained for DR classification. In this work, we combine global attention block\n(GAB) and category attention block (CAB) into the deep learning model, thus\neffectively overcoming the imbalanced data distribution problem in DR\nclassification. Our proposed approach is based on an attention mechanism-based\ndeep learning model that employs three pre-trained networks, namely,\nMobileNetV3-small, Efficientnet-b0, and DenseNet-169 as the backbone\narchitecture. We evaluate the proposed method on two publicly available\ndatasets of retinal fundoscopy images for DR. Experimental results show that on\nthe APTOS dataset, the DenseNet-169 yielded 83.20% mean accuracy, followed by\nthe MobileNetV3-small and EfficientNet-b0, which yielded 82% and 80%\naccuracies, respectively. On the EYEPACS dataset, the EfficientNet-b0 yielded a\nmean accuracy of 80%, while the DenseNet-169 and MobileNetV3-small yielded\n75.43% and 76.68% accuracies, respectively. In addition, we also compute the\nF1-score of 82.0%, precision of 82.1%, sensitivity of 83.0%, specificity of\n95.5%, and a kappa score of 88.2% for the experiments. Moreover, in our work,\nthe MobileNetV3-small has 1.6 million parameters on the APTOS dataset and 0.90\nmillion parameters on the EYEPACS dataset, which is comparatively less than\nother methods. The proposed approach achieves competitive performance that is\nat par with recently reported works on DR classification.",
      "pdf_url": "http://arxiv.org/pdf/2507.19199v1",
      "published": "2025-07-25T12:09:27+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.19199v1",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "WACA-UNet: Weakness-Aware Channel Attention for Static IR Drop Prediction in Integrated Circuit Design",
      "authors": [
        "Youngmin Seo",
        "Yunhyeong Kwon",
        "Younghun Park",
        "HwiRyong Kim",
        "Seungho Eum",
        "Jinha Kim",
        "Taigon Song",
        "Juho Kim",
        "Unsang Park"
      ],
      "abstract": "Accurate spatial prediction of power integrity issues, such as IR drop, is\ncritical for reliable VLSI design. However, traditional simulation-based\nsolvers are computationally expensive and difficult to scale. We address this\nchallenge by reformulating IR drop estimation as a pixel-wise regression task\non heterogeneous multi-channel physical maps derived from circuit layouts.\nPrior learning-based methods treat all input layers (e.g., metal, via, and\ncurrent maps) equally, ignoring their varying importance to prediction\naccuracy. To tackle this, we propose a novel Weakness-Aware Channel Attention\n(WACA) mechanism, which recursively enhances weak feature channels while\nsuppressing over-dominant ones through a two-stage gating strategy. Integrated\ninto a ConvNeXtV2-based attention U-Net, our approach enables adaptive and\nbalanced feature representation. On the public ICCAD-2023 benchmark, our method\noutperforms the ICCAD-2023 contest winner by reducing mean absolute error by\n61.1% and improving F1-score by 71.0%. These results demonstrate that\nchannel-wise heterogeneity is a key inductive bias in physical layout analysis\nfor VLSI.",
      "pdf_url": "http://arxiv.org/pdf/2507.19197v1",
      "published": "2025-07-25T12:07:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.19197v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "B.7.2; I.5.1; I.2.10; I.5.4"
      ]
    },
    {
      "title": "Can Small-Scale Data Poisoning Exacerbate Dialect-Linked Biases in Large Language Models?",
      "authors": [
        "Chaymaa Abbas",
        "Mariette Awad",
        "Razane Tajeddine"
      ],
      "abstract": "Despite the ongoing improvements in the design of large language models\n(LLMs) to foster inclusion and balanced responses, these systems remain\nsusceptible to encoding and amplifying social biases. This study examines how\ndialectal variation, specifically African American Vernacular English (AAVE)\nversus Standard American English (SAE), interacts with data poisoning to\ninfluence toxicity in outputs. Using both small- and medium-scale LLaMA models,\nwe show that even minimal exposure to poisoned data significantly increases\ntoxicity for AAVE inputs, while it remains comparatively unaffected for SAE.\nLarger models exhibit a more significant amplification effect which suggests\nheightened susceptibility with scale. To further assess these disparities, we\nemployed GPT-4o as a fairness auditor, which identified harmful stereotypical\npatterns disproportionately tied to AAVE inputs, including portrayals of\naggression, criminality, and intellectual inferiority. These findings\nunderscore the compounding impact of data poisoning and dialectal bias and\nemphasize the need for dialect-aware evaluation, targeted debiasing\ninterventions, and socially responsible training protocols during development.",
      "pdf_url": "http://arxiv.org/pdf/2507.19195v1",
      "published": "2025-07-25T12:05:47+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.19195v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "PrompTrend: Continuous Community-Driven Vulnerability Discovery and Assessment for Large Language Models",
      "authors": [
        "Tarek Gasmi",
        "Ramzi Guesmi",
        "Mootez Aloui",
        "Jihene Bennaceur"
      ],
      "abstract": "Static benchmarks fail to capture LLM vulnerabilities emerging through\ncommunity experimentation in online forums. We present PrompTrend, a system\nthat collects vulnerability data across platforms and evaluates them using\nmultidimensional scoring, with an architecture designed for scalable\nmonitoring. Cross-sectional analysis of 198 vulnerabilities collected from\nonline communities over a five-month period (January-May 2025) and tested on\nnine commercial models reveals that advanced capabilities correlate with\nincreased vulnerability in some architectures, psychological attacks\nsignificantly outperform technical exploits, and platform dynamics shape attack\neffectiveness with measurable model-specific patterns. The PrompTrend\nVulnerability Assessment Framework achieves 78% classification accuracy while\nrevealing limited cross-model transferability, demonstrating that effective LLM\nsecurity requires comprehensive socio-technical monitoring beyond traditional\nperiodic assessment. Our findings challenge the assumption that capability\nadvancement improves security and establish community-driven psychological\nmanipulation as the dominant threat vector for current language models.",
      "pdf_url": "http://arxiv.org/pdf/2507.19185v1",
      "published": "2025-07-25T11:52:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.19185v1",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "title": "Faster Lifting for Ordered Domains with Predecessor Relations",
      "authors": [
        "Kuncheng Zou",
        "Jiahao Mai",
        "Yonggang Zhang",
        "Yuyi Wang",
        "Ondřej Kuželka",
        "Yuanhong Wang",
        "Yi Chang"
      ],
      "abstract": "We investigate lifted inference on ordered domains with predecessor\nrelations, where the elements of the domain respect a total (cyclic) order, and\nevery element has a distinct (clockwise) predecessor. Previous work has\nexplored this problem through weighted first-order model counting (WFOMC),\nwhich computes the weighted sum of models for a given first-order logic\nsentence over a finite domain. In WFOMC, the order constraint is typically\nencoded by the linear order axiom introducing a binary predicate in the\nsentence to impose a linear ordering on the domain elements. The immediate and\nsecond predecessor relations are then encoded by the linear order predicate.\nAlthough WFOMC with the linear order axiom is theoretically tractable, existing\nalgorithms struggle with practical applications, particularly when the\npredecessor relations are involved. In this paper, we treat predecessor\nrelations as a native part of the axiom and devise a novel algorithm that\ninherently supports these relations. The proposed algorithm not only provides\nan exponential speedup for the immediate and second predecessor relations,\nwhich are known to be tractable, but also handles the general k-th predecessor\nrelations. The extensive experiments on lifted inference tasks and\ncombinatorics math problems demonstrate the efficiency of our algorithm,\nachieving speedups of a full order of magnitude.",
      "pdf_url": "http://arxiv.org/pdf/2507.19182v1",
      "published": "2025-07-25T11:43:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.19182v1",
      "categories": [
        "cs.AI",
        "cs.LO"
      ]
    },
    {
      "title": "PhysDrive: A Multimodal Remote Physiological Measurement Dataset for In-vehicle Driver Monitoring",
      "authors": [
        "Jiyao Wang",
        "Xiao Yang",
        "Qingyong Hu",
        "Jiankai Tang",
        "Can Liu",
        "Dengbo He",
        "Yuntao Wang",
        "Yingcong Chen",
        "Kaishun Wu"
      ],
      "abstract": "Robust and unobtrusive in-vehicle physiological monitoring is crucial for\nensuring driving safety and user experience. While remote physiological\nmeasurement (RPM) offers a promising non-invasive solution, its translation to\nreal-world driving scenarios is critically constrained by the scarcity of\ncomprehensive datasets. Existing resources are often limited in scale, modality\ndiversity, the breadth of biometric annotations, and the range of captured\nconditions, thereby omitting inherent real-world challenges in driving. Here,\nwe present PhysDrive, the first large-scale multimodal dataset for contactless\nin-vehicle physiological sensing with dedicated consideration on various\nmodality settings and driving factors. PhysDrive collects data from 48 drivers,\nincluding synchronized RGB, near-infrared camera, and raw mmWave radar data,\naccompanied with six synchronized ground truths (ECG, BVP, Respiration, HR, RR,\nand SpO2). It covers a wide spectrum of naturalistic driving conditions,\nincluding driver motions, dynamic natural light, vehicle types, and road\nconditions. We extensively evaluate both signal-processing and deep-learning\nmethods on PhysDrive, establishing a comprehensive benchmark across all\nmodalities, and release full open-source code with compatibility for mainstream\npublic toolboxes. We envision PhysDrive will serve as a foundational resource\nand accelerate research on multimodal driver monitoring and smart-cockpit\nsystems.",
      "pdf_url": "http://arxiv.org/pdf/2507.19172v1",
      "published": "2025-07-25T11:23:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.19172v1",
      "categories": [
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "An Empirical Investigation of Gender Stereotype Representation in Large Language Models: The Italian Case",
      "authors": [
        "Gioele Giachino",
        "Marco Rondina",
        "Antonio Vetrò",
        "Riccardo Coppola",
        "Juan Carlos De Martin"
      ],
      "abstract": "The increasing use of Large Language Models (LLMs) in a large variety of\ndomains has sparked worries about how easily they can perpetuate stereotypes\nand contribute to the generation of biased content. With a focus on gender and\nprofessional bias, this work examines in which manner LLMs shape responses to\nungendered prompts, contributing to biased outputs. This analysis uses a\nstructured experimental method, giving different prompts involving three\ndifferent professional job combinations, which are also characterized by a\nhierarchical relationship. This study uses Italian, a language with extensive\ngrammatical gender differences, to highlight potential limitations in current\nLLMs' ability to generate objective text in non-English languages. Two popular\nLLM-based chatbots are examined, namely OpenAI ChatGPT (gpt-4o-mini) and Google\nGemini (gemini-1.5-flash). Through APIs, we collected a range of 3600\nresponses. The results highlight how content generated by LLMs can perpetuate\nstereotypes. For example, Gemini associated 100% (ChatGPT 97%) of 'she'\npronouns to the 'assistant' rather than the 'manager'. The presence of bias in\nAI-generated text can have significant implications in many fields, such as in\nthe workplaces or in job selections, raising ethical concerns about its use.\nUnderstanding these risks is pivotal to developing mitigation strategies and\nassuring that AI-based systems do not increase social inequalities, but rather\ncontribute to more equitable outcomes. Future research directions include\nexpanding the study to additional chatbots or languages, refining prompt\nengineering methods or further exploiting a larger experimental base.",
      "pdf_url": "http://arxiv.org/pdf/2507.19156v1",
      "published": "2025-07-25T10:57:29+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.19156v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.HC"
      ]
    },
    {
      "title": "ReCoDe: Reinforcement Learning-based Dynamic Constraint Design for Multi-Agent Coordination",
      "authors": [
        "Michael Amir",
        "Guang Yang",
        "Zhan Gao",
        "Keisuke Okumura",
        "Heedo Woo",
        "Amanda Prorok"
      ],
      "abstract": "Constraint-based optimization is a cornerstone of robotics, enabling the\ndesign of controllers that reliably encode task and safety requirements such as\ncollision avoidance or formation adherence. However, handcrafted constraints\ncan fail in multi-agent settings that demand complex coordination. We introduce\nReCoDe--Reinforcement-based Constraint Design--a decentralized, hybrid\nframework that merges the reliability of optimization-based controllers with\nthe adaptability of multi-agent reinforcement learning. Rather than discarding\nexpert controllers, ReCoDe improves them by learning additional, dynamic\nconstraints that capture subtler behaviors, for example, by constraining agent\nmovements to prevent congestion in cluttered scenarios. Through local\ncommunication, agents collectively constrain their allowed actions to\ncoordinate more effectively under changing conditions. In this work, we focus\non applications of ReCoDe to multi-agent navigation tasks requiring intricate,\ncontext-based movements and consensus, where we show that it outperforms purely\nhandcrafted controllers, other hybrid approaches, and standard MARL baselines.\nWe give empirical (real robot) and theoretical evidence that retaining a\nuser-defined controller, even when it is imperfect, is more efficient than\nlearning from scratch, especially because ReCoDe can dynamically change the\ndegree to which it relies on this controller.",
      "pdf_url": "http://arxiv.org/pdf/2507.19151v1",
      "published": "2025-07-25T10:47:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.19151v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "cs.MA",
        "I.2.9"
      ]
    },
    {
      "title": "Solar Photovoltaic Assessment with Large Language Model",
      "authors": [
        "Muhao Guo",
        "Yang Weng"
      ],
      "abstract": "Accurate detection and localization of solar photovoltaic (PV) panels in\nsatellite imagery is essential for optimizing microgrids and active\ndistribution networks (ADNs), which are critical components of renewable energy\nsystems. Existing methods lack transparency regarding their underlying\nalgorithms or training datasets, rely on large, high-quality PV training data,\nand struggle to generalize to new geographic regions or varied environmental\nconditions without extensive re-training. These limitations lead to\ninconsistent detection outcomes, hindering large-scale deployment and\ndata-driven grid optimization. In this paper, we investigate how large language\nmodels (LLMs) can be leveraged to overcome these challenges. Despite their\npromise, LLMs face several challenges in solar panel detection, including\ndifficulties with multi-step logical processes, inconsistent output formatting,\nfrequent misclassification of visually similar objects (e.g., shadows, parking\nlots), and low accuracy in complex tasks such as spatial localization and\nquantification. To overcome these issues, we propose the PV Assessment with\nLLMs (PVAL) framework, which incorporates task decomposition for more efficient\nworkflows, output standardization for consistent and scalable formatting,\nfew-shot prompting to enhance classification accuracy, and fine-tuning using\ncurated PV datasets with detailed annotations. PVAL ensures transparency,\nscalability, and adaptability across heterogeneous datasets while minimizing\ncomputational overhead. By combining open-source accessibility with robust\nmethodologies, PVAL establishes an automated and reproducible pipeline for\nsolar panel detection, paving the way for large-scale renewable energy\nintegration and optimized grid management.",
      "pdf_url": "http://arxiv.org/pdf/2507.19144v1",
      "published": "2025-07-25T10:26:29+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.19144v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Assessment of Personality Dimensions Across Situations Using Conversational Speech",
      "authors": [
        "Alice Zhang",
        "Skanda Muralidhar",
        "Daniel Gatica-Perez",
        "Mathew Magimai-Doss"
      ],
      "abstract": "Prior research indicates that users prefer assistive technologies whose\npersonalities align with their own. This has sparked interest in automatic\npersonality perception (APP), which aims to predict an individual's perceived\npersonality traits. Previous studies in APP have treated personalities as\nstatic traits, independent of context. However, perceived personalities can\nvary by context and situation as shown in psychological research. In this\nstudy, we investigate the relationship between conversational speech and\nperceived personality for participants engaged in two work situations (a\nneutral interview and a stressful client interaction). Our key findings are: 1)\nperceived personalities differ significantly across interactions, 2) loudness,\nsound level, and spectral flux features are indicative of perceived\nextraversion, agreeableness, conscientiousness, and openness in neutral\ninteractions, while neuroticism correlates with these features in stressful\ncontexts, 3) handcrafted acoustic features and non-verbal features outperform\nspeaker embeddings in inference of perceived personality, and 4) stressful\ninteractions are more predictive of neuroticism, aligning with existing\npsychological research.",
      "pdf_url": "http://arxiv.org/pdf/2507.19137v1",
      "published": "2025-07-25T10:18:28+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.19137v1",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.SD"
      ]
    },
    {
      "title": "OS-MAP: How Far Can Computer-Using Agents Go in Breadth and Depth?",
      "authors": [
        "Xuetian Chen",
        "Yinghao Chen",
        "Xinfeng Yuan",
        "Zhuo Peng",
        "Lu Chen",
        "Yuekeng Li",
        "Zhoujia Zhang",
        "Yingqian Huang",
        "Leyan Huang",
        "Jiaqing Liang",
        "Tianbao Xie",
        "Zhiyong Wu",
        "Qiushi Sun",
        "Biqing Qi",
        "Bowen Zhou"
      ],
      "abstract": "Computer-using agents have shown strong potential to boost human productivity\nand enable new application forms across platforms. While recent advances have\nled to usable applications, existing benchmarks fail to account for the\ninternal task heterogeneity and the corresponding agent capabilities, as well\nas their alignment with actual user demands-hindering both targeted capability\ndevelopment and the reliable transition of research progress into practical\ndeployment. To bridge the gap, we present OS-MAP, a benchmark for daily\ncomputer-using automation that organizes its 416 realistic tasks across 15\napplications along two key dimensions: a five-level taxonomy of automation and\na generalization scope derived from a real-world user demand hierarchy. To\nenable fine-grained analysis of required capabilities and alignment with\nreal-world scenarios, OS-MAP evaluates agents along two dimensions: automation\nlevel across a five-level taxonomy, and generalization scope across a demand\nhierarchy. This design captures varying levels of required agent autonomy and\ngeneralization, forming a performance-generalization evaluation matrix for\nstructured and comprehensive assessment. Experiments show that even\nState-of-the-Art agents with VLM backbones struggle with higher-level tasks\ninvolving perception, reasoning, and coordination-highlighting the need for a\ndeeper understanding of current strengths and limitations to drive the future\nprogress in computer-using agents research and deployment. All code,\nenvironments, baselines, and data are publicly available at\nhttps://github.com/OS-Copilot/OS-Map.",
      "pdf_url": "http://arxiv.org/pdf/2507.19132v1",
      "published": "2025-07-25T10:14:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.19132v1",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.HC"
      ]
    },
    {
      "title": "PatchTraj: Dynamic Patch Representation Learning for Time-Frequency Trajectory Prediction",
      "authors": [
        "Yanghong Liu",
        "Xingping Dong",
        "Ming Li",
        "Weixing Zhang",
        "Yidong Lou"
      ],
      "abstract": "Pedestrian trajectory prediction is crucial for autonomous driving and\nrobotics. While existing point-based and grid-based methods expose two key\nlimitations: insufficiently modeling human motion dynamics, as they fail to\nbalance local motion details with long-range spatiotemporal dependencies, and\nthe time representation lacks interaction with the frequency domain in modeling\ntrajectory sequences. To address these challenges, we propose PatchTraj, a\ndynamic patch-based trajectory prediction framework that unifies time-domain\nand frequency-domain representations. Specifically, we decompose the trajectory\ninto raw time sequences and frequency components, employing dynamic patch\npartitioning for multi-scale trajectory segmentation to capture hierarchical\nmotion patterns. Each patch is processed by an adaptive embedding layer with\nscale-aware feature extraction, followed by hierarchical feature aggregation to\nmodel both fine-grained and long-range dependencies. The outputs of two\nbranches interact via cross-modal attention, enabling complementary fusion of\ntemporal and spectral cues. Finally, a Transformer encoder-decoder integrates\nboth modalities to autoregressively predict future trajectories. Extensive\nexperiments on ETH-UCY, SDD, NBA, and JRDB datasets demonstrate that our method\nachieves state-of-the-art performance with high efficiency.",
      "pdf_url": "http://arxiv.org/pdf/2507.19119v2",
      "published": "2025-07-25T09:55:33+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.19119v2",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Graph Structure Learning with Privacy Guarantees for Open Graph Data",
      "authors": [
        "Muhao Guo",
        "Jiaqi Wu",
        "Yang Weng",
        "Yizheng Liao",
        "Shengzhe Chen"
      ],
      "abstract": "Ensuring privacy in large-scale open datasets is increasingly challenging\nunder regulations such as the General Data Protection Regulation (GDPR). While\ndifferential privacy (DP) provides strong theoretical guarantees, it primarily\nfocuses on noise injection during model training, neglecting privacy\npreservation at the data publishing stage. Existing privacy-preserving data\npublishing (PPDP) approaches struggle to balance privacy and utility,\nparticularly when data publishers and users are distinct entities. To address\nthis gap, we focus on the graph recovery problem and propose a novel\nprivacy-preserving estimation framework for open graph data, leveraging\nGaussian DP (GDP) with a structured noise-injection mechanism. Unlike\ntraditional methods that perturb gradients or model updates, our approach\nensures unbiased graph structure recovery while enforcing DP at the data\npublishing stage. Moreover, we provide theoretical guarantees on estimation\naccuracy and extend our method to discrete-variable graphs, a setting often\noverlooked in DP research. Experimental results in graph learning demonstrate\nrobust performance, offering a viable solution for privacy-conscious graph\nanalysis.",
      "pdf_url": "http://arxiv.org/pdf/2507.19116v1",
      "published": "2025-07-25T09:51:12+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.19116v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Automated Code Review Using Large Language Models at Ericsson: An Experience Report",
      "authors": [
        "Shweta Ramesh",
        "Joy Bose",
        "Hamender Singh",
        "A K Raghavan",
        "Sujoy Roychowdhury",
        "Giriprasad Sridhara",
        "Nishrith Saini",
        "Ricardo Britto"
      ],
      "abstract": "Code review is one of the primary means of assuring the quality of released\nsoftware along with testing and static analysis. However, code review requires\nexperienced developers who may not always have the time to perform an in-depth\nreview of code. Thus, automating code review can help alleviate the cognitive\nburden on experienced software developers allowing them to focus on their\nprimary activities of writing code to add new features and fix bugs. In this\npaper, we describe our experience in using Large Language Models towards\nautomating the code review process in Ericsson. We describe the development of\na lightweight tool using LLMs and static program analysis. We then describe our\npreliminary experiments with experienced developers in evaluating our code\nreview tool and the encouraging results.",
      "pdf_url": "http://arxiv.org/pdf/2507.19115v1",
      "published": "2025-07-25T09:50:48+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.19115v1",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "Pareto-NRPA: A Novel Monte-Carlo Search Algorithm for Multi-Objective Optimization",
      "authors": [
        "Noé Lallouet",
        "Tristan Cazenave",
        "Cyrille Enderli"
      ],
      "abstract": "We introduce Pareto-NRPA, a new Monte-Carlo algorithm designed for\nmulti-objective optimization problems over discrete search spaces. Extending\nthe Nested Rollout Policy Adaptation (NRPA) algorithm originally formulated for\nsingle-objective problems, Pareto-NRPA generalizes the nested search and policy\nupdate mechanism to multi-objective optimization. The algorithm uses a set of\npolicies to concurrently explore different regions of the solution space and\nmaintains non-dominated fronts at each level of search. Policy adaptation is\nperformed with respect to the diversity and isolation of sequences within the\nPareto front. We benchmark Pareto-NRPA on two classes of problems: a novel\nbi-objective variant of the Traveling Salesman Problem with Time Windows\nproblem (MO-TSPTW), and a neural architecture search task on well-known\nbenchmarks. Results demonstrate that Pareto-NRPA achieves competitive\nperformance against state-of-the-art multi-objective algorithms, both in terms\nof convergence and diversity of solutions. Particularly, Pareto-NRPA strongly\noutperforms state-of-the-art evolutionary multi-objective algorithms on\nconstrained search spaces. To our knowledge, this work constitutes the first\nadaptation of NRPA to the multi-objective setting.",
      "pdf_url": "http://arxiv.org/pdf/2507.19109v1",
      "published": "2025-07-25T09:46:25+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.19109v1",
      "categories": [
        "cs.AI",
        "cs.NE"
      ]
    },
    {
      "title": "Distilling a Small Utility-Based Passage Selector to Enhance Retrieval-Augmented Generation",
      "authors": [
        "Hengran Zhang",
        "Keping Bi",
        "Jiafeng Guo",
        "Jiaming Zhang",
        "Shuaiqiang Wang",
        "Dawei Yin",
        "Xueqi Cheng"
      ],
      "abstract": "Retrieval-augmented generation (RAG) enhances large language models (LLMs) by\nincorporating retrieved information. Standard retrieval process prioritized\nrelevance, focusing on topical alignment between queries and passages. In\ncontrast, in RAG, the emphasis has shifted to utility, which considers the\nusefulness of passages for generating accurate answers. Despite empirical\nevidence showing the benefits of utility-based retrieval in RAG, the high\ncomputational cost of using LLMs for utility judgments limits the number of\npassages evaluated. This restriction is problematic for complex queries\nrequiring extensive information. To address this, we propose a method to\ndistill the utility judgment capabilities of LLMs into smaller, more efficient\nmodels. Our approach focuses on utility-based selection rather than ranking,\nenabling dynamic passage selection tailored to specific queries without the\nneed for fixed thresholds. We train student models to learn pseudo-answer\ngeneration and utility judgments from teacher LLMs, using a sliding window\nmethod that dynamically selects useful passages. Our experiments demonstrate\nthat utility-based selection provides a flexible and cost-effective solution\nfor RAG, significantly reducing computational costs while improving answer\nquality. We present the distillation results using Qwen3-32B as the teacher\nmodel for both relevance ranking and utility-based selection, distilled into\nRankQwen1.7B and UtilityQwen1.7B. Our findings indicate that for complex\nquestions, utility-based selection is more effective than relevance ranking in\nenhancing answer generation performance. We will release the relevance ranking\nand utility-based selection annotations for the MS MARCO dataset, supporting\nfurther research in this area.",
      "pdf_url": "http://arxiv.org/pdf/2507.19102v1",
      "published": "2025-07-25T09:32:29+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.19102v1",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    },
    {
      "title": "MedSymmFlow: Bridging Generative Modeling and Classification in Medical Imaging through Symmetrical Flow Matching",
      "authors": [
        "Francisco Caetano",
        "Lemar Abdi",
        "Christiaan Viviers",
        "Amaan Valiuddin",
        "Fons van der Sommen"
      ],
      "abstract": "Reliable medical image classification requires accurate predictions and\nwell-calibrated uncertainty estimates, especially in high-stakes clinical\nsettings. This work presents MedSymmFlow, a generative-discriminative hybrid\nmodel built on Symmetrical Flow Matching, designed to unify classification,\ngeneration, and uncertainty quantification in medical imaging. MedSymmFlow\nleverages a latent-space formulation that scales to high-resolution inputs and\nintroduces a semantic mask conditioning mechanism to enhance diagnostic\nrelevance. Unlike standard discriminative models, it naturally estimates\nuncertainty through its generative sampling process. The model is evaluated on\nfour MedMNIST datasets, covering a range of modalities and pathologies. The\nresults show that MedSymmFlow matches or exceeds the performance of established\nbaselines in classification accuracy and AUC, while also delivering reliable\nuncertainty estimates validated by performance improvements under selective\nprediction.",
      "pdf_url": "http://arxiv.org/pdf/2507.19098v1",
      "published": "2025-07-25T09:30:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.19098v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Fine-Grained Traffic Inference from Road to Lane via Spatio-Temporal Graph Node Generation",
      "authors": [
        "Shuhao Li",
        "Weidong Yang",
        "Yue Cui",
        "Xiaoxing Liu",
        "Lingkai Meng",
        "Lipeng Ma",
        "Fan Zhang"
      ],
      "abstract": "Fine-grained traffic management and prediction are fundamental to key\napplications such as autonomous driving, lane change guidance, and traffic\nsignal control. However, obtaining lane-level traffic data has become a\ncritical bottleneck for data-driven models due to limitations in the types and\nnumber of sensors and issues with the accuracy of tracking algorithms. To\naddress this, we propose the Fine-grained Road Traffic Inference (FRTI) task,\nwhich aims to generate more detailed lane-level traffic information using\nlimited road data, providing a more energy-efficient and cost-effective\nsolution for precise traffic management. This task is abstracted as the first\nscene of the spatio-temporal graph node generation problem. We designed a\ntwo-stage framework--RoadDiff--to solve the FRTI task. solve the FRTI task.\nThis framework leverages the Road-Lane Correlation Autoencoder-Decoder and the\nLane Diffusion Module to fully utilize the limited spatio-temporal dependencies\nand distribution relationships of road data to accurately infer fine-grained\nlane traffic states. Based on existing research, we designed several baseline\nmodels with the potential to solve the FRTI task and conducted extensive\nexperiments on six datasets representing different road conditions to validate\nthe effectiveness of the RoadDiff model in addressing the FRTI task. The\nrelevant datasets and code are available at\nhttps://github.com/ShuhaoLii/RoadDiff.",
      "pdf_url": "http://arxiv.org/pdf/2507.19089v1",
      "published": "2025-07-25T09:15:18+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.19089v1",
      "categories": [
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "PBiLoss: Popularity-Aware Regularization to Improve Fairness in Graph-Based Recommender Systems",
      "authors": [
        "Mohammad Naeimi",
        "Mostafa Haghir Chehreghani"
      ],
      "abstract": "Recommender systems, especially those based on graph neural networks (GNNs),\nhave achieved remarkable success in capturing user-item interaction patterns.\nHowever, they remain susceptible to popularity bias--the tendency to\nover-recommend popular items--resulting in reduced content diversity and\ncompromised fairness. In this paper, we propose PBiLoss, a novel\nregularization-based loss function designed to counteract popularity bias in\ngraph-based recommender models explicitly. PBiLoss augments traditional\ntraining objectives by penalizing the model's inclination toward popular items,\nthereby encouraging the recommendation of less popular but potentially more\npersonalized content. We introduce two sampling strategies: Popular Positive\n(PopPos) and Popular Negative (PopNeg), which respectively modulate the\ncontribution of the positive and negative popular items during training. We\nfurther explore two methods to distinguish popular items: one based on a fixed\npopularity threshold and another without any threshold, making the approach\nflexible and adaptive. Our proposed method is model-agnostic and can be\nseamlessly integrated into state-of-the-art graph-based frameworks such as\nLightGCN and its variants. Comprehensive experiments across multiple real-world\ndatasets demonstrate that PBiLoss significantly improves fairness, as\ndemonstrated by reductions in the Popularity-Rank Correlation for Users (PRU)\nand Popularity-Rank Correlation for Items (PRI), while maintaining or even\nenhancing standard recommendation accuracy and ranking metrics. These results\nhighlight the effectiveness of directly embedding fairness objectives into the\noptimization process, providing a practical and scalable solution for balancing\naccuracy and equitable content exposure in modern recommender systems.",
      "pdf_url": "http://arxiv.org/pdf/2507.19067v1",
      "published": "2025-07-25T08:29:32+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.19067v1",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.NE"
      ]
    },
    {
      "title": "Closing the Modality Gap for Mixed Modality Search",
      "authors": [
        "Binxu Li",
        "Yuhui Zhang",
        "Xiaohan Wang",
        "Weixin Liang",
        "Ludwig Schmidt",
        "Serena Yeung-Levy"
      ],
      "abstract": "Mixed modality search -- retrieving information across a heterogeneous corpus\ncomposed of images, texts, and multimodal documents -- is an important yet\nunderexplored real-world application. In this work, we investigate how\ncontrastive vision-language models, such as CLIP, perform on the mixed modality\nsearch task. Our analysis reveals a critical limitation: these models exhibit a\npronounced modality gap in the embedding space, where image and text embeddings\nform distinct clusters, leading to intra-modal ranking bias and inter-modal\nfusion failure. To address this issue, we propose GR-CLIP, a lightweight\npost-hoc calibration method that removes the modality gap in CLIP's embedding\nspace. Evaluated on MixBench -- the first benchmark specifically designed for\nmixed modality search -- GR-CLIP improves NDCG@10 by up to 26 percentage points\nover CLIP, surpasses recent vision-language generative embedding models by 4\npercentage points, while using 75x less compute.",
      "pdf_url": "http://arxiv.org/pdf/2507.19054v1",
      "published": "2025-07-25T08:15:28+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.19054v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.IR",
        "cs.LG"
      ]
    },
    {
      "title": "Dual Path Learning -- learning from noise and context for medical image denoising",
      "authors": [
        "Jitindra Fartiyal",
        "Pedro Freire",
        "Yasmeen Whayeb",
        "James S. Wolffsohn",
        "Sergei K. Turitsyn",
        "Sergei G. Sokolov"
      ],
      "abstract": "Medical imaging plays a critical role in modern healthcare, enabling\nclinicians to accurately diagnose diseases and develop effective treatment\nplans. However, noise, often introduced by imaging devices, can degrade image\nquality, leading to misinterpretation and compromised clinical outcomes.\nExisting denoising approaches typically rely either on noise characteristics or\non contextual information from the image. Moreover, they are commonly developed\nand evaluated for a single imaging modality and noise type. Motivated by Geng\net.al CNCL, which integrates both noise and context, this study introduces a\nDual-Pathway Learning (DPL) model architecture that effectively denoises\nmedical images by leveraging both sources of information and fusing them to\ngenerate the final output. DPL is evaluated across multiple imaging modalities\nand various types of noise, demonstrating its robustness and generalizability.\nDPL improves PSNR by 3.35% compared to the baseline UNet when evaluated on\nGaussian noise and trained across all modalities. The code is available at\n10.5281/zenodo.15836053.",
      "pdf_url": "http://arxiv.org/pdf/2507.19035v1",
      "published": "2025-07-25T07:43:50+00:00",
      "arxiv_url": "http://arxiv.org/abs/2507.19035v1",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ]
    }
  ]
}