{
  "last_updated": "2025-09-25T00:48:19.743093",
  "papers": [
    {
      "title": "Audio-Based Pedestrian Detection in the Presence of Vehicular Noise",
      "authors": [
        "Yonghyun Kim",
        "Chaeyeon Han",
        "Akash Sarode",
        "Noah Posner",
        "Subhrajit Guhathakurta",
        "Alexander Lerch"
      ],
      "abstract": "Audio-based pedestrian detection is a challenging task and has, thus far,\nonly been explored in noise-limited environments. We present a new dataset,\nresults, and a detailed analysis of the state-of-the-art in audio-based\npedestrian detection in the presence of vehicular noise. In our study, we\nconduct three analyses: (i) cross-dataset evaluation between noisy and\nnoise-limited environments, (ii) an assessment of the impact of noisy data on\nmodel performance, highlighting the influence of acoustic context, and (iii) an\nevaluation of the model's predictive robustness on out-of-domain sounds. The\nnew dataset is a comprehensive 1321-hour roadside dataset. It incorporates\ntraffic-rich soundscapes. Each recording includes 16kHz audio synchronized with\nframe-level pedestrian annotations and 1fps video thumbnails.",
      "pdf_url": "http://arxiv.org/pdf/2509.19295v1",
      "published": "2025-09-23T17:57:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.19295v1",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.LG",
        "cs.SD"
      ]
    },
    {
      "title": "SOE: Sample-Efficient Robot Policy Self-Improvement via On-Manifold Exploration",
      "authors": [
        "Yang Jin",
        "Jun Lv",
        "Han Xue",
        "Wendi Chen",
        "Chuan Wen",
        "Cewu Lu"
      ],
      "abstract": "Intelligent agents progress by continually refining their capabilities\nthrough actively exploring environments. Yet robot policies often lack\nsufficient exploration capability due to action mode collapse. Existing methods\nthat encourage exploration typically rely on random perturbations, which are\nunsafe and induce unstable, erratic behaviors, thereby limiting their\neffectiveness. We propose Self-Improvement via On-Manifold Exploration (SOE), a\nframework that enhances policy exploration and improvement in robotic\nmanipulation. SOE learns a compact latent representation of task-relevant\nfactors and constrains exploration to the manifold of valid actions, ensuring\nsafety, diversity, and effectiveness. It can be seamlessly integrated with\narbitrary policy models as a plug-in module, augmenting exploration without\ndegrading the base policy performance. Moreover, the structured latent space\nenables human-guided exploration, further improving efficiency and\ncontrollability. Extensive experiments in both simulation and real-world tasks\ndemonstrate that SOE consistently outperforms prior methods, achieving higher\ntask success rates, smoother and safer exploration, and superior sample\nefficiency. These results establish on-manifold exploration as a principled\napproach to sample-efficient policy self-improvement. Project website:\nhttps://ericjin2002.github.io/SOE",
      "pdf_url": "http://arxiv.org/pdf/2509.19292v1",
      "published": "2025-09-23T17:54:47+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.19292v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "MOIS-SAM2: Exemplar-based Segment Anything Model 2 for multilesion interactive segmentation of neurofibromas in whole-body MRI",
      "authors": [
        "Georgii Kolokolnikov",
        "Marie-Lena Schmalhofer",
        "Sophie Goetz",
        "Lennart Well",
        "Said Farschtschi",
        "Victor-Felix Mautner",
        "Inka Ristow",
        "Rene Werner"
      ],
      "abstract": "Background and Objectives: Neurofibromatosis type 1 is a genetic disorder\ncharacterized by the development of numerous neurofibromas (NFs) throughout the\nbody. Whole-body MRI (WB-MRI) is the clinical standard for detection and\nlongitudinal surveillance of NF tumor growth. Existing interactive segmentation\nmethods fail to combine high lesion-wise precision with scalability to hundreds\nof lesions. This study proposes a novel interactive segmentation model tailored\nto this challenge.\n  Methods: We introduce MOIS-SAM2, a multi-object interactive segmentation\nmodel that extends the state-of-the-art, transformer-based, promptable Segment\nAnything Model 2 (SAM2) with exemplar-based semantic propagation. MOIS-SAM2 was\ntrained and evaluated on 119 WB-MRI scans from 84 NF1 patients acquired using\nT2-weighted fat-suppressed sequences. The dataset was split at the patient\nlevel into a training set and four test sets (one in-domain and three\nreflecting different domain shift scenarios, e.g., MRI field strength\nvariation, low tumor burden, differences in clinical site and scanner vendor).\n  Results: On the in-domain test set, MOIS-SAM2 achieved a scan-wise DSC of\n0.60 against expert manual annotations, outperforming baseline 3D nnU-Net (DSC:\n0.54) and SAM2 (DSC: 0.35). Performance of the proposed model was maintained\nunder MRI field strength shift (DSC: 0.53) and scanner vendor variation (DSC:\n0.50), and improved in low tumor burden cases (DSC: 0.61). Lesion detection F1\nscores ranged from 0.62 to 0.78 across test sets. Preliminary inter-reader\nvariability analysis showed model-to-expert agreement (DSC: 0.62-0.68),\ncomparable to inter-expert agreement (DSC: 0.57-0.69).\n  Conclusions: The proposed MOIS-SAM2 enables efficient and scalable\ninteractive segmentation of NFs in WB-MRI with minimal user input and strong\ngeneralization, supporting integration into clinical workflows.",
      "pdf_url": "http://arxiv.org/pdf/2509.19277v2",
      "published": "2025-09-23T17:42:24+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.19277v2",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ]
    },
    {
      "title": "WolBanking77: Wolof Banking Speech Intent Classification Dataset",
      "authors": [
        "Abdou Karim Kandji",
        "Frédéric Precioso",
        "Cheikh Ba",
        "Samba Ndiaye",
        "Augustin Ndione"
      ],
      "abstract": "Intent classification models have made a lot of progress in recent years.\nHowever, previous studies primarily focus on high-resource languages datasets,\nwhich results in a gap for low-resource languages and for regions with a high\nrate of illiterate people where languages are more spoken than read or written.\nThis is the case in Senegal, for example, where Wolof is spoken by around 90\\%\nof the population, with an illiteracy rate of 42\\% for the country. Wolof is\nactually spoken by more than 10 million people in West African region. To\ntackle such limitations, we release a Wolof Intent Classification Dataset\n(WolBanking77), for academic research in intent classification. WolBanking77\ncurrently contains 9,791 text sentences in the banking domain and more than 4\nhours of spoken sentences. Experiments on various baselines are conducted in\nthis work, including text and voice state-of-the-art models. The results are\nvery promising on this current dataset. This paper also provides detailed\nanalyses of the contents of the data. We report baseline f1-score and word\nerror rate metrics respectively on NLP and ASR models trained on WolBanking77\ndataset and also comparisons between models. We plan to share and conduct\ndataset maintenance, updates and to release open-source code.",
      "pdf_url": "http://arxiv.org/pdf/2509.19271v1",
      "published": "2025-09-23T17:34:10+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.19271v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "SloPalSpeech: A 2,8000-Hour Slovak Speech Corpus from Parliamentary Data",
      "authors": [
        "Erik Božík",
        "Marek Šuppa"
      ],
      "abstract": "Automatic Speech Recognition (ASR) for low-resource languages like Slovak is\nhindered by the scarcity of training data. To address this, we introduce\nSloPalSpeech, a new, large-scale Slovak ASR dataset containing 2,806 hours of\nspeech from parliamentary proceedings. We developed a robust processing\npipeline to align and segment long-form recordings into clean, 30-second\naudio-transcript pairs suitable for model training. We use this dataset to\nfine-tune several OpenAI Whisper models (small, medium, large-v3, and\nlarge-v3-turbo), achieving significant Word Error Rate (WER) reductions on\nstandard Slovak benchmarks like Common Voice and FLEURS. For instance, the\nfine-tuned Whisper-small model's WER dropped by up to 70\\%, approaching the\nbaseline performance of the much larger Whisper-large-v3 model. To foster\nfuture research in low-resource speech recognition, we publicly release the\ncomplete SloPalSpeech dataset, the fully segmented transcripts (60 million\nwords), and all our fine-tuned models.",
      "pdf_url": "http://arxiv.org/pdf/2509.19270v1",
      "published": "2025-09-23T17:33:57+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.19270v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SD"
      ]
    },
    {
      "title": "Cross-Cultural Transfer of Commonsense Reasoning in LLMs: Evidence from the Arab World",
      "authors": [
        "Saeed Almheiri",
        "Rania Hossam",
        "Mena Attia",
        "Chenxi Wang",
        "Preslav Nakov",
        "Timothy Baldwin",
        "Fajri Koto"
      ],
      "abstract": "Large language models (LLMs) often reflect Western-centric biases, limiting\ntheir effectiveness in diverse cultural contexts. Although some work has\nexplored cultural alignment, the potential for cross-cultural transfer, using\nalignment in one culture to improve performance in others, remains\nunderexplored. This paper investigates cross-cultural transfer of commonsense\nreasoning in the Arab world, where linguistic and historical similarities\ncoexist with local cultural differences. Using a culturally grounded\ncommonsense reasoning dataset covering 13 Arab countries, we evaluate\nlightweight alignment methods such as in-context learning and\ndemonstration-based reinforcement (DITTO), alongside baselines like supervised\nfine-tuning and direct preference optimization. Our results show that merely 12\nculture-specific examples from one country can improve performance in others by\n10\\% on average, within multilingual models. In addition, we demonstrate that\nout-of-culture demonstrations from Indonesia and US contexts can match or\nsurpass in-culture alignment for MCQ reasoning, highlighting cultural\ncommonsense transferability beyond the Arab world. These findings demonstrate\nthat efficient cross-cultural alignment is possible and offer a promising\napproach to adapt LLMs to low-resource cultural settings.",
      "pdf_url": "http://arxiv.org/pdf/2509.19265v1",
      "published": "2025-09-23T17:24:14+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.19265v1",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Adversarially-Refined VQ-GAN with Dense Motion Tokenization for Spatio-Temporal Heatmaps",
      "authors": [
        "Gabriel Maldonado",
        "Narges Rashvand",
        "Armin Danesh Pazho",
        "Ghazal Alinezhad Noghre",
        "Vinit Katariya",
        "Hamed Tabkhi"
      ],
      "abstract": "Continuous human motion understanding remains a core challenge in computer\nvision due to its high dimensionality and inherent redundancy. Efficient\ncompression and representation are crucial for analyzing complex motion\ndynamics. In this work, we introduce an adversarially-refined VQ-GAN framework\nwith dense motion tokenization for compressing spatio-temporal heatmaps while\npreserving the fine-grained traces of human motion. Our approach combines dense\nmotion tokenization with adversarial refinement, which eliminates\nreconstruction artifacts like motion smearing and temporal misalignment\nobserved in non-adversarial baselines. Our experiments on the CMU Panoptic\ndataset provide conclusive evidence of our method's superiority, outperforming\nthe dVAE baseline by 9.31% SSIM and reducing temporal instability by 37.1%.\nFurthermore, our dense tokenization strategy enables a novel analysis of motion\ncomplexity, revealing that 2D motion can be optimally represented with a\ncompact 128-token vocabulary, while 3D motion's complexity demands a much\nlarger 1024-token codebook for faithful reconstruction. These results establish\npractical deployment feasibility across diverse motion analysis applications.\nThe code base for this work is available at\nhttps://github.com/TeCSAR-UNCC/Pose-Quantization.",
      "pdf_url": "http://arxiv.org/pdf/2509.19252v1",
      "published": "2025-09-23T17:12:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.19252v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Reinforcement Learning on Pre-Training Data",
      "authors": [
        "Siheng Li",
        "Kejiao Li",
        "Zenan Xu",
        "Guanhua Huang",
        "Evander Yang",
        "Kun Li",
        "Haoyuan Wu",
        "Jiajia Wu",
        "Zihao Zheng",
        "Chenchen Zhang",
        "Kun Shi",
        "Kyrierl Deng",
        "Qi Yi",
        "Ruibin Xiong",
        "Tingqiang Xu",
        "Yuhao Jiang",
        "Jianfeng Yan",
        "Yuyuan Zeng",
        "Guanghui Xu",
        "Jinbao Xue",
        "Zhijiang Xu",
        "Zheng Fang",
        "Shuai Li",
        "Qibin Liu",
        "Xiaoxue Li",
        "Zhuoyu Li",
        "Yangyu Tao",
        "Fei Gao",
        "Cheng Jiang",
        "Bo Chao Wang",
        "Kai Liu",
        "Jianchen Zhu",
        "Wai Lam",
        "Wayyt Wang",
        "Bo Zhou",
        "Di Wang"
      ],
      "abstract": "The growing disparity between the exponential scaling of computational\nresources and the finite growth of high-quality text data now constrains\nconventional scaling approaches for large language models (LLMs). To address\nthis challenge, we introduce Reinforcement Learning on Pre-Training data\n(RLPT), a new training-time scaling paradigm for optimizing LLMs. In contrast\nto prior approaches that scale training primarily through supervised learning,\nRLPT enables the policy to autonomously explore meaningful trajectories to\nlearn from pre-training data and improve its capability through reinforcement\nlearning (RL). While existing RL strategies such as reinforcement learning from\nhuman feedback (RLHF) and reinforcement learning with verifiable rewards (RLVR)\nrely on human annotation for reward construction, RLPT eliminates this\ndependency by deriving reward signals directly from pre-training data.\nSpecifically, it adopts a next-segment reasoning objective, rewarding the\npolicy for accurately predicting subsequent text segments conditioned on the\npreceding context. This formulation allows RL to be scaled on pre-training\ndata, encouraging the exploration of richer trajectories across broader\ncontexts and thereby fostering more generalizable reasoning skills. Extensive\nexperiments on both general-domain and mathematical reasoning benchmarks across\nmultiple models validate the effectiveness of RLPT. For example, when applied\nto Qwen3-4B-Base, RLPT yields absolute improvements of $3.0$, $5.1$, $8.1$,\n$6.0$, $6.6$, and $5.3$ on MMLU, MMLU-Pro, GPQA-Diamond, KOR-Bench, AIME24, and\nAIME25, respectively. The results further demonstrate favorable scaling\nbehavior, suggesting strong potential for continued gains with more compute. In\naddition, RLPT provides a solid foundation, extending the reasoning boundaries\nof LLMs and enhancing RLVR performance.",
      "pdf_url": "http://arxiv.org/pdf/2509.19249v1",
      "published": "2025-09-23T17:10:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.19249v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "AgentInit: Initializing LLM-based Multi-Agent Systems via Diversity and Expertise Orchestration for Effective and Efficient Collaboration",
      "authors": [
        "Chunhao Tian",
        "Yutong Wang",
        "Xuebo Liu",
        "Zhexuan Wang",
        "Liang Ding",
        "Miao Zhang",
        "Min Zhang"
      ],
      "abstract": "Proper initialization is crucial for any system, particularly in multi-agent\nsystems (MAS), where it plays a pivotal role in determining both the system's\nefficiency and effectiveness. However, existing MAS initialization methods do\nnot fully account for the collaborative needs of the generated agents in\nsubsequent stages. Inspired by the principles of effective team composition, we\npropose AgentInit, which aims to optimize the structure of agent teams.\nSpecifically, in addition to multi-round interactions and reflections between\nagents during agent generation, AgentInit incorporates a Natural Language to\nFormat mechanism to ensure consistency and standardization. Balanced team\nselection strategies using Pareto principles are subsequently applied to\njointly consider agent team diversity and task relevance to promote effective\nand efficient collaboration and enhance overall system performance. Experiments\nshow that AgentInit consistently outperforms state-of-the-art initialization\nmethods and pre-defined strategies across various frameworks and tasks,\nachieving an overall performance improvement of up to 1.2 and 1.6,\nrespectively, while also significantly reducing token consumption. Further\nanalysis confirms its strong transferability to similar tasks and verifies the\neffectiveness of its key components, demonstrating its capability and\nadaptability as a reliable MAS initialization method. Source code and models\nare available at https://github.com/1737423697/AgentInit.",
      "pdf_url": "http://arxiv.org/pdf/2509.19236v1",
      "published": "2025-09-23T16:58:54+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.19236v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Finding My Voice: Generative Reconstruction of Disordered Speech for Automated Clinical Evaluation",
      "authors": [
        "Karen Rosero",
        "Eunjung Yeo",
        "David R. Mortensen",
        "Cortney Van't Slot",
        "Rami R. Hallac",
        "Carlos Busso"
      ],
      "abstract": "We present ChiReSSD, a speech reconstruction framework that preserves\nchildren speaker's identity while suppressing mispronunciations. Unlike prior\napproaches trained on healthy adult speech, ChiReSSD adapts to the voices of\nchildren with speech sound disorders (SSD), with particular emphasis on pitch\nand prosody. We evaluate our method on the STAR dataset and report substantial\nimprovements in lexical accuracy and speaker identity preservation.\nFurthermore, we automatically predict the phonetic content in the original and\nreconstructed pairs, where the proportion of corrected consonants is comparable\nto the percentage of correct consonants (PCC), a clinical speech assessment\nmetric. Our experiments show Pearson correlation of 0.63 between automatic and\nhuman expert annotations, highlighting the potential to reduce the manual\ntranscription burden. In addition, experiments on the TORGO dataset demonstrate\neffective generalization for reconstructing adult dysarthric speech. Our\nresults indicate that disentangled, style-based TTS reconstruction can provide\nidentity-preserving speech across diverse clinical populations.",
      "pdf_url": "http://arxiv.org/pdf/2509.19231v1",
      "published": "2025-09-23T16:53:07+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.19231v1",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "MsFIN: Multi-scale Feature Interaction Network for Traffic Accident Anticipation",
      "authors": [
        "Tongshuai Wu",
        "Chao Lu",
        "Ze Song",
        "Yunlong Lin",
        "Sizhe Fan",
        "Xuemei Chen"
      ],
      "abstract": "With the widespread deployment of dashcams and advancements in computer\nvision, developing accident prediction models from the dashcam perspective has\nbecome critical for proactive safety interventions. However, two key challenges\npersist: modeling feature-level interactions among traffic participants (often\noccluded in dashcam views) and capturing complex, asynchronous multi-temporal\nbehavioral cues preceding accidents. To deal with these two challenges, a\nMulti-scale Feature Interaction Network (MsFIN) is proposed for early-stage\naccident anticipation from dashcam videos. MsFIN has three layers for\nmulti-scale feature aggregation, temporal feature processing and multi-scale\nfeature post fusion, respectively. For multi-scale feature aggregation, a\nMulti-scale Module is designed to extract scene representations at short-term,\nmid-term and long-term temporal scales. Meanwhile, the Transformer architecture\nis leveraged to facilitate comprehensive feature interactions. Temporal feature\nprocessing captures the sequential evolution of scene and object features under\ncausal constraints. In the multi-scale feature post fusion stage, the network\nfuses scene and object features across multiple temporal scales to generate a\ncomprehensive risk representation. Experiments on DAD and DADA datasets show\nthat MsFIN significantly outperforms state-of-the-art models with single-scale\nfeature extraction in both prediction correctness and earliness. Ablation\nstudies validate the effectiveness of each module in MsFIN, highlighting how\nthe network achieves superior performance through multi-scale feature fusion\nand contextual interaction modeling.",
      "pdf_url": "http://arxiv.org/pdf/2509.19227v1",
      "published": "2025-09-23T16:49:25+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.19227v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Systematic Comparative Analysis of Large Pretrained Language Models on Contextualized Medication Event Extraction",
      "authors": [
        "Tariq Abdul-Quddoos",
        "Xishuang Dong",
        "Lijun Qian"
      ],
      "abstract": "Attention-based models have become the leading approach in modeling medical\nlanguage for Natural Language Processing (NLP) in clinical notes. These models\noutperform traditional techniques by effectively capturing contextual rep-\nresentations of language. In this research a comparative analysis is done\namongst pre- trained attention based models namely Bert Base, BioBert, two\nvariations of Bio+Clinical Bert, RoBerta, and Clinical Long- former on task\nrelated to Electronic Health Record (EHR) information extraction. The tasks\nfrom Track 1 of Harvard Medical School's 2022 National Clinical NLP Challenges\n(n2c2) are considered for this comparison, with the Contextualized Medication\nEvent Dataset (CMED) given for these task. CMED is a dataset of unstructured\nEHRs and annotated notes that contain task relevant information about the EHRs.\nThe goal of the challenge is to develop effective solutions for extracting\ncontextual information related to patient medication events from EHRs using\ndata driven methods. Each pre-trained model is fine-tuned and applied on CMED\nto perform medication extraction, medical event detection, and\nmulti-dimensional medication event context classification. Pro- cessing methods\nare also detailed for breaking down EHRs for compatibility with the applied\nmodels. Performance analysis has been carried out using a script based on\nconstructing medical terms from the evaluation portion of CMED with metrics\nincluding recall, precision, and F1-Score. The results demonstrate that models\npre-trained on clinical data are more effective in detecting medication and\nmedication events, but Bert Base, pre- trained on general domain data showed to\nbe the most effective for classifying the context of events related to\nmedications.",
      "pdf_url": "http://arxiv.org/pdf/2509.19224v1",
      "published": "2025-09-23T16:48:28+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.19224v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "FedFusion: Federated Learning with Diversity- and Cluster-Aware Encoders for Robust Adaptation under Label Scarcity",
      "authors": [
        "Ferdinand Kahenga",
        "Antoine Bagula",
        "Patrick Sello",
        "Sajal K. Das"
      ],
      "abstract": "Federated learning in practice must contend with heterogeneous feature\nspaces, severe non-IID data, and scarce labels across clients. We present\nFedFusion, a federated transfer-learning framework that unifies domain\nadaptation and frugal labelling with diversity-/cluster-aware encoders (DivEn,\nDivEn-mix, DivEn-c). Labelled teacher clients guide learner clients via\nconfidence-filtered pseudo-labels and domain-adaptive transfer, while clients\nmaintain personalised encoders tailored to local data. To preserve global\ncoherence under heterogeneity, FedFusion employs similarity-weighted classifier\ncoupling (with optional cluster-wise averaging), mitigating dominance by\ndata-rich sites and improving minority-client performance. The frugal-labelling\npipeline combines self-/semi-supervised pretext training with selective\nfine-tuning, reducing annotation demands without sharing raw data. Across\ntabular and imaging benchmarks under IID, non-IID, and label-scarce regimes,\nFedFusion consistently outperforms state-of-the-art baselines in accuracy,\nrobustness, and fairness while maintaining comparable communication and\ncomputation budgets. These results show that harmonising personalisation,\ndomain adaptation, and label efficiency is an effective recipe for robust\nfederated learning under real-world constraints.",
      "pdf_url": "http://arxiv.org/pdf/2509.19220v1",
      "published": "2025-09-23T16:46:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.19220v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ]
    },
    {
      "title": "HyKid: An Open MRI Dataset with Expert-Annotated Multi-Structure and Choroid Plexus in Pediatric Hydrocephalus",
      "authors": [
        "Yunzhi Xu",
        "Yushuang Ding",
        "Hu Sun",
        "Hongxi Zhang",
        "Li Zhao"
      ],
      "abstract": "Evaluation of hydrocephalus in children is challenging, and the related\nresearch is limited by a lack of publicly available, expert-annotated datasets,\nparticularly those with segmentation of the choroid plexus. To address this, we\npresent HyKid, an open-source dataset from 48 pediatric patients with\nhydrocephalus. 3D MRIs were provided with 1mm isotropic resolution, which was\nreconstructed from routine low-resolution images using a slice-to-volume\nalgorithm. Manually corrected segmentations of brain tissues, including white\nmatter, grey matter, lateral ventricle, external CSF, and the choroid plexus,\nwere provided by an experienced neurologist. Additionally, structured data was\nextracted from clinical radiology reports using a Retrieval-Augmented\nGeneration framework. The strong correlation between choroid plexus volume and\ntotal CSF volume provided a potential biomarker for hydrocephalus evaluation,\nachieving excellent performance in a predictive model (AUC = 0.87). The\nproposed HyKid dataset provided a high-quality benchmark for neuroimaging\nalgorithms development, and it revealed the choroid plexus-related features in\nhydrocephalus assessments. Our datasets are publicly available at\nhttps://www.synapse.org/Synapse:syn68544889.",
      "pdf_url": "http://arxiv.org/pdf/2509.19218v1",
      "published": "2025-09-23T16:42:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.19218v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Steering Multimodal Large Language Models Decoding for Context-Aware Safety",
      "authors": [
        "Zheyuan Liu",
        "Zhangchen Xu",
        "Guangyao Dou",
        "Xiangchi Yuan",
        "Zhaoxuan Tan",
        "Radha Poovendran",
        "Meng Jiang"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) are increasingly deployed in\nreal-world applications, yet their ability to make context-aware safety\ndecisions remains limited. Existing methods often fail to balance\noversensitivity (unjustified refusals of benign queries) and undersensitivity\n(missed detection of visually grounded risks), leaving a persistent gap in\nsafety alignment. To address this issue, we introduce Safety-aware Contrastive\nDecoding (SafeCoDe), a lightweight and model-agnostic decoding framework that\ndynamically adjusts token generation based on multimodal context. SafeCoDe\noperates in two stages: (1) a contrastive decoding mechanism that highlights\ntokens sensitive to visual context by contrasting real and Gaussian-noised\nimages, and (2) a global-aware token modulation strategy that integrates\nscene-level reasoning with token-level adjustment to adapt refusals according\nto the predicted safety verdict. Extensive experiments across diverse MLLM\narchitectures and safety benchmarks, covering undersensitivity,\noversensitivity, and general safety evaluations, show that SafeCoDe\nconsistently improves context-sensitive refusal behaviors while preserving\nmodel helpfulness.",
      "pdf_url": "http://arxiv.org/pdf/2509.19212v1",
      "published": "2025-09-23T16:32:25+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.19212v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "YAC: Bridging Natural Language and Interactive Visual Exploration with Generative AI for Biomedical Data Discovery",
      "authors": [
        "Devin Lange",
        "Shanghua Gao",
        "Pengwei Sui",
        "Austen Money",
        "Priya Misner",
        "Marinka Zitnik",
        "Nils Gehlenborg"
      ],
      "abstract": "Incorporating natural language input has the potential to improve the\ncapabilities of biomedical data discovery interfaces. However, user interface\nelements and visualizations are still powerful tools for interacting with data,\neven in the new world of generative AI. In our prototype system, YAC, Yet\nAnother Chatbot, we bridge the gap between natural language and interactive\nvisualizations by generating structured declarative output with a multi-agent\nsystem and interpreting that output to render linked interactive visualizations\nand apply data filters. Furthermore, we include widgets, which allow users to\nadjust the values of that structured output through user interface elements. We\nreflect on the capabilities and design of this system with an analysis of its\ntechnical dimensions and illustrate the capabilities through four usage\nscenarios.",
      "pdf_url": "http://arxiv.org/pdf/2509.19182v1",
      "published": "2025-09-23T15:57:42+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.19182v1",
      "categories": [
        "cs.HC",
        "cs.AI"
      ]
    },
    {
      "title": "Soft Tokens, Hard Truths",
      "authors": [
        "Natasha Butt",
        "Ariel Kwiatkowski",
        "Ismail Labiad",
        "Julia Kempe",
        "Yann Ollivier"
      ],
      "abstract": "The use of continuous instead of discrete tokens during the Chain-of-Thought\n(CoT) phase of reasoning LLMs has garnered attention recently, based on the\nintuition that a continuous mixture of discrete tokens could simulate a\nsuperposition of several reasoning paths simultaneously. Theoretical results\nhave formally proven that continuous tokens have much greater expressivity and\ncan solve specific problems more efficiently. However, practical use of\ncontinuous tokens has been limited by strong training difficulties: previous\nworks either just use continuous tokens at inference time on a pre-trained\ndiscrete-token model, or must distill the continuous CoT from ground-truth\ndiscrete CoTs and face computational costs that limit the CoT to very few\ntokens.\n  This is the first work introducing a scalable method to learn continuous CoTs\nvia reinforcement learning (RL), without distilling from reference discrete\nCoTs. We use \"soft\" tokens: mixtures of tokens together with noise on the input\nembedding to provide RL exploration. Computational overhead is minimal,\nenabling us to learn continuous CoTs with hundreds of tokens. On math reasoning\nbenchmarks with Llama and Qwen models up to 8B, training with continuous CoTs\nmatch discrete-token CoTs for pass@1 and surpass them for pass@32, showing\ngreater CoT diversity. In systematic comparisons, the best-performing scenario\nis to train with continuous CoT tokens then use discrete tokens for inference,\nmeaning the \"soft\" models can be deployed in a standard way. Finally, we show\ncontinuous CoT RL training better preserves the predictions of the base model\non out-of-domain tasks, thus providing a softer touch to the base model.",
      "pdf_url": "http://arxiv.org/pdf/2509.19170v2",
      "published": "2025-09-23T15:43:47+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.19170v2",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "RoSe: Robust Self-supervised Stereo Matching under Adverse Weather Conditions",
      "authors": [
        "Yun Wang",
        "Junjie Hu",
        "Junhui Hou",
        "Chenghao Zhang",
        "Renwei Yang",
        "Dapeng Oliver Wu"
      ],
      "abstract": "Recent self-supervised stereo matching methods have made significant\nprogress, but their performance significantly degrades under adverse weather\nconditions such as night, rain, and fog. We identify two primary weaknesses\ncontributing to this performance degradation. First, adverse weather introduces\nnoise and reduces visibility, making CNN-based feature extractors struggle with\ndegraded regions like reflective and textureless areas. Second, these degraded\nregions can disrupt accurate pixel correspondences, leading to ineffective\nsupervision based on the photometric consistency assumption. To address these\nchallenges, we propose injecting robust priors derived from the visual\nfoundation model into the CNN-based feature extractor to improve feature\nrepresentation under adverse weather conditions. We then introduce scene\ncorrespondence priors to construct robust supervisory signals rather than\nrelying solely on the photometric consistency assumption. Specifically, we\ncreate synthetic stereo datasets with realistic weather degradations. These\ndatasets feature clear and adverse image pairs that maintain the same semantic\ncontext and disparity, preserving the scene correspondence property. With this\nknowledge, we propose a robust self-supervised training paradigm, consisting of\ntwo key steps: robust self-supervised scene correspondence learning and adverse\nweather distillation. Both steps aim to align underlying scene results from\nclean and adverse image pairs, thus improving model disparity estimation under\nadverse weather effects. Extensive experiments demonstrate the effectiveness\nand versatility of our proposed solution, which outperforms existing\nstate-of-the-art self-supervised methods. Codes are available at\n\\textcolor{blue}{https://github.com/cocowy1/RoSe-Robust-Self-supervised-Stereo-Matching-under-Adverse-Weather-Conditions}.",
      "pdf_url": "http://arxiv.org/pdf/2509.19165v1",
      "published": "2025-09-23T15:41:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.19165v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Generative Propaganda",
      "authors": [
        "Madeleine I. G. Daepp",
        "Alejandro Cuevas",
        "Robert Osazuwa Ness",
        "Vickie Yu-Ping Wang",
        "Bharat Kumar Nayak",
        "Dibyendu Mishra",
        "Ti-Chung Cheng",
        "Shaily Desai",
        "Joyojeet Pal"
      ],
      "abstract": "Generative propaganda is the use of generative artificial intelligence (AI)\nto shape public opinion. To characterize its use in real-world settings, we\nconducted interviews with defenders (e.g., factcheckers, journalists,\nofficials) in Taiwan and creators (e.g., influencers, political consultants,\nadvertisers) as well as defenders in India, centering two places characterized\nby high levels of online propaganda. The term \"deepfakes\", we find, exerts\noutsized discursive power in shaping defenders' expectations of misuse and, in\nturn, the interventions that are prioritized. To better characterize the space\nof generative propaganda, we develop a taxonomy that distinguishes between\nobvious versus hidden and promotional versus derogatory use. Deception was\nneither the main driver nor the main impact vector of AI's use; instead, Indian\ncreators sought to persuade rather than to deceive, often making AI's use\nobvious in order to reduce legal and reputational risks, while Taiwan's\ndefenders saw deception as a subset of broader efforts to distort the\nprevalence of strategic narratives online. AI was useful and used, however, in\nproducing efficiency gains in communicating across languages and modes, and in\nevading human and algorithmic detection. Security researchers should reconsider\nthreat models to clearly differentiate deepfakes from promotional and obvious\nuses, to complement and bolster the social factors that constrain misuse by\ninternal actors, and to counter efficiency gains globally.",
      "pdf_url": "http://arxiv.org/pdf/2509.19147v1",
      "published": "2025-09-23T15:27:00+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.19147v1",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.SI",
        "K.4.2"
      ]
    },
    {
      "title": "Anecdoctoring: Automated Red-Teaming Across Language and Place",
      "authors": [
        "Alejandro Cuevas",
        "Saloni Dash",
        "Bharat Kumar Nayak",
        "Dan Vann",
        "Madeleine I. G. Daepp"
      ],
      "abstract": "Disinformation is among the top risks of generative artificial intelligence\n(AI) misuse. Global adoption of generative AI necessitates red-teaming\nevaluations (i.e., systematic adversarial probing) that are robust across\ndiverse languages and cultures, but red-teaming datasets are commonly US- and\nEnglish-centric. To address this gap, we propose \"anecdoctoring\", a novel\nred-teaming approach that automatically generates adversarial prompts across\nlanguages and cultures. We collect misinformation claims from fact-checking\nwebsites in three languages (English, Spanish, and Hindi) and two geographies\n(US and India). We then cluster individual claims into broader narratives and\ncharacterize the resulting clusters with knowledge graphs, with which we\naugment an attacker LLM. Our method produces higher attack success rates and\noffers interpretability benefits relative to few-shot prompting. Results\nunderscore the need for disinformation mitigations that scale globally and are\ngrounded in real-world adversarial misuse.",
      "pdf_url": "http://arxiv.org/pdf/2509.19143v1",
      "published": "2025-09-23T15:26:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.19143v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ]
    },
    {
      "title": "On the Soundness and Consistency of LLM Agents for Executing Test Cases Written in Natural Language",
      "authors": [
        "Sébastien Salva",
        "Redha Taguelmimt"
      ],
      "abstract": "The use of natural language (NL) test cases for validating graphical user\ninterface (GUI) applications is emerging as a promising direction to manually\nwritten executable test scripts, which are costly to develop and difficult to\nmaintain. Recent advances in large language models (LLMs) have opened the\npossibility of the direct execution of NL test cases by LLM agents. This paper\ninvestigates this direction, focusing on the impact on NL test case unsoundness\nand on test case execution consistency. NL test cases are inherently unsound,\nas they may yield false failures due to ambiguous instructions or unpredictable\nagent behaviour. Furthermore, repeated executions of the same NL test case may\nlead to inconsistent outcomes, undermining test reliability. To address these\nchallenges, we propose an algorithm for executing NL test cases with guardrail\nmechanisms and specialised agents that dynamically verify the correct execution\nof each test step. We introduce measures to evaluate the capabilities of LLMs\nin test execution and one measure to quantify execution consistency. We propose\na definition of weak unsoundness to characterise contexts in which NL test case\nexecution remains acceptable, with respect to the industrial quality levels Six\nSigma. Our experimental evaluation with eight publicly available LLMs, ranging\nfrom 3B to 70B parameters, demonstrates both the potential and current\nlimitations of current LLM agents for GUI testing. Our experiments show that\nMeta Llama 3.1 70B demonstrates acceptable capabilities in NL test case\nexecution with high execution consistency (above the level 3-sigma). We provide\nprototype tools, test suites, and results.",
      "pdf_url": "http://arxiv.org/pdf/2509.19136v1",
      "published": "2025-09-23T15:20:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.19136v1",
      "categories": [
        "cs.SE",
        "cs.AI",
        "D.2.4; D.2.5; F.3.1"
      ]
    },
    {
      "title": "GSTM-HMU: Generative Spatio-Temporal Modeling for Human Mobility Understanding",
      "authors": [
        "Wenying Luo",
        "Zhiyuan Lin",
        "Wenhao Xu",
        "Minghao Liu",
        "Zhi Li"
      ],
      "abstract": "Human mobility traces, often recorded as sequences of check-ins, provide a\nunique window into both short-term visiting patterns and persistent lifestyle\nregularities. In this work we introduce GSTM-HMU, a generative spatio-temporal\nframework designed to advance mobility analysis by explicitly modeling the\nsemantic and temporal complexity of human movement. The framework consists of\nfour key innovations. First, a Spatio-Temporal Concept Encoder (STCE)\nintegrates geographic location, POI category semantics, and periodic temporal\nrhythms into unified vector representations. Second, a Cognitive Trajectory\nMemory (CTM) adaptively filters historical visits, emphasizing recent and\nbehaviorally salient events in order to capture user intent more effectively.\nThird, a Lifestyle Concept Bank (LCB) contributes structured human preference\ncues, such as activity types and lifestyle patterns, to enhance\ninterpretability and personalization. Finally, task-oriented generative heads\ntransform the learned representations into predictions for multiple downstream\ntasks. We conduct extensive experiments on four widely used real-world\ndatasets, including Gowalla, WeePlace, Brightkite, and FourSquare, and evaluate\nperformance on three benchmark tasks: next-location prediction, trajectory-user\nidentification, and time estimation. The results demonstrate consistent and\nsubstantial improvements over strong baselines, confirming the effectiveness of\nGSTM-HMU in extracting semantic regularities from complex mobility data. Beyond\nraw performance gains, our findings also suggest that generative modeling\nprovides a promising foundation for building more robust, interpretable, and\ngeneralizable systems for human mobility intelligence.",
      "pdf_url": "http://arxiv.org/pdf/2509.19135v1",
      "published": "2025-09-23T15:20:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.19135v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Analysis on distribution and clustering of weight",
      "authors": [
        "Chunming Ye",
        "Wenquan Tian",
        "Yalan Gao",
        "Songzhou Li"
      ],
      "abstract": "The study on architecture and parameter characteristics remains the hot topic\nin the research of large language models. In this paper we concern with the\ncharacteristics of weight which are used to analyze the correlations and\ndifferences between models. Two kinds of vectors-standard deviation vector and\nclustering vector-are proposed to describe features of models. In the first\ncase, the weights are assumed to follow normal distribution. The standard\ndeviation values of projection matrices are normalized to form\nStandard-Deviation Vector, representing the distribution characteristics of\nmodels. In the second case, the singular values from each weight projection\nmatrix are extracted and grouped by K-Means algorithm. The grouped data with\nthe same type matrix are combined as Clustering Vector to represent the\ncorrelation characteristics of models' weights. The study reveals that these\ntwo vectors can effectively distinguish between different models and clearly\nshow the similarities among models of the same family. Moreover, after\nconducting LoRA fine-tuning with different datasets and models, it is found\nthat the distribution of weights represented by standard deviation vector is\ndirectly influenced by the dataset, but the correlations between different\nweights represented by clustering vector remain unaffected and maintain a high\nconsistency with the pre-trained model.",
      "pdf_url": "http://arxiv.org/pdf/2509.19122v1",
      "published": "2025-09-23T15:08:25+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.19122v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68T50",
        "I.2.7"
      ]
    },
    {
      "title": "FedFiTS: Fitness-Selected, Slotted Client Scheduling for Trustworthy Federated Learning in Healthcare AI",
      "authors": [
        "Ferdinand Kahenga",
        "Antoine Bagula",
        "Sajal K. Das",
        "Patrick Sello"
      ],
      "abstract": "Federated Learning (FL) has emerged as a powerful paradigm for\nprivacy-preserving model training, yet deployments in sensitive domains such as\nhealthcare face persistent challenges from non-IID data, client unreliability,\nand adversarial manipulation. This paper introduces FedFiTS, a trust and\nfairness-aware selective FL framework that advances the FedFaSt line by\ncombining fitness-based client election with slotted aggregation. FedFiTS\nimplements a three-phase participation strategy-free-for-all training, natural\nselection, and slotted team participation-augmented with dynamic client\nscoring, adaptive thresholding, and cohort-based scheduling to balance\nconvergence efficiency with robustness. A theoretical convergence analysis\nestablishes bounds for both convex and non-convex objectives under standard\nassumptions, while a communication-complexity analysis shows reductions\nrelative to FedAvg and other baselines. Experiments on diverse datasets-medical\nimaging (X-ray pneumonia), vision benchmarks (MNIST, FMNIST), and tabular\nagricultural data (Crop Recommendation)-demonstrate that FedFiTS consistently\noutperforms FedAvg, FedRand, and FedPow in accuracy, time-to-target, and\nresilience to poisoning attacks. By integrating trust-aware aggregation with\nfairness-oriented client selection, FedFiTS advances scalable and secure FL,\nmaking it well suited for real-world healthcare and cross-domain deployments.",
      "pdf_url": "http://arxiv.org/pdf/2509.19120v1",
      "published": "2025-09-23T15:06:04+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.19120v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ]
    },
    {
      "title": "Towards Practical Multi-label Causal Discovery in High-Dimensional Event Sequences via One-Shot Graph Aggregation",
      "authors": [
        "Hugo Math",
        "Rainer Lienhart"
      ],
      "abstract": "Understanding causality in event sequences where outcome labels such as\ndiseases or system failures arise from preceding events like symptoms or error\ncodes is critical. Yet remains an unsolved challenge across domains like\nhealthcare or vehicle diagnostics. We introduce CARGO, a scalable multi-label\ncausal discovery method for sparse, high-dimensional event sequences comprising\nof thousands of unique event types. Using two pretrained causal Transformers as\ndomain-specific foundation models for event sequences. CARGO infers in\nparallel, per sequence one-shot causal graphs and aggregates them using an\nadaptive frequency fusion to reconstruct the global Markov boundaries of\nlabels. This two-stage approach enables efficient probabilistic reasoning at\nscale while bypassing the intractable cost of full-dataset conditional\nindependence testing. Our results on a challenging real-world automotive fault\nprediction dataset with over 29,100 unique event types and 474 imbalanced\nlabels demonstrate CARGO's ability to perform structured reasoning.",
      "pdf_url": "http://arxiv.org/pdf/2509.19112v1",
      "published": "2025-09-23T14:58:50+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.19112v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "FUNCanon: Learning Pose-Aware Action Primitives via Functional Object Canonicalization for Generalizable Robotic Manipulation",
      "authors": [
        "Hongli Xu",
        "Lei Zhang",
        "Xiaoyue Hu",
        "Boyang Zhong",
        "Kaixin Bai",
        "Zoltán-Csaba Márton",
        "Zhenshan Bing",
        "Zhaopeng Chen",
        "Alois Christian Knoll",
        "Jianwei Zhang"
      ],
      "abstract": "General-purpose robotic skills from end-to-end demonstrations often leads to\ntask-specific policies that fail to generalize beyond the training\ndistribution. Therefore, we introduce FunCanon, a framework that converts\nlong-horizon manipulation tasks into sequences of action chunks, each defined\nby an actor, verb, and object. These chunks focus policy learning on the\nactions themselves, rather than isolated tasks, enabling compositionality and\nreuse. To make policies pose-aware and category-general, we perform functional\nobject canonicalization for functional alignment and automatic manipulation\ntrajectory transfer, mapping objects into shared functional frames using\naffordance cues from large vision language models. An object centric and action\ncentric diffusion policy FuncDiffuser trained on this aligned data naturally\nrespects object affordances and poses, simplifying learning and improving\ngeneralization ability. Experiments on simulated and real-world benchmarks\ndemonstrate category-level generalization, cross-task behavior reuse, and\nrobust sim2real deployment, showing that functional canonicalization provides a\nstrong inductive bias for scalable imitation learning in complex manipulation\ndomains. Details of the demo and supplemental material are available on our\nproject website https://sites.google.com/view/funcanon.",
      "pdf_url": "http://arxiv.org/pdf/2509.19102v1",
      "published": "2025-09-23T14:49:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.19102v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Algorithms for Adversarially Robust Deep Learning",
      "authors": [
        "Alexander Robey"
      ],
      "abstract": "Given the widespread use of deep learning models in safety-critical\napplications, ensuring that the decisions of such models are robust against\nadversarial exploitation is of fundamental importance. In this thesis, we\ndiscuss recent progress toward designing algorithms that exhibit desirable\nrobustness properties. First, we discuss the problem of adversarial examples in\ncomputer vision, for which we introduce new technical results, training\nparadigms, and certification algorithms. Next, we consider the problem of\ndomain generalization, wherein the task is to train neural networks to\ngeneralize from a family of training distributions to unseen test\ndistributions. We present new algorithms that achieve state-of-the-art\ngeneralization in medical imaging, molecular identification, and image\nclassification. Finally, we study the setting of jailbreaking large language\nmodels (LLMs), wherein an adversarial user attempts to design prompts that\nelicit objectionable content from an LLM. We propose new attacks and defenses,\nwhich represent the frontier of progress toward designing robust language-based\nagents.",
      "pdf_url": "http://arxiv.org/pdf/2509.19100v1",
      "published": "2025-09-23T14:48:58+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.19100v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Pathways of Thoughts: Multi-Directional Thinking for Long-form Personalized Question Answering",
      "authors": [
        "Alireza Salemi",
        "Cheng Li",
        "Mingyang Zhang",
        "Qiaozhu Mei",
        "Zhuowan Li",
        "Spurthi Amba Hombaiah",
        "Weize Kong",
        "Tao Chen",
        "Hamed Zamani",
        "Michael Bendersky"
      ],
      "abstract": "Personalization is essential for adapting question answering (QA) systems to\nuser-specific information needs, thereby improving both accuracy and user\nsatisfaction. However, personalized QA remains relatively underexplored due to\nchallenges such as inferring preferences from long, noisy, and implicit\ncontexts, and generating responses that are simultaneously correct,\ncontextually appropriate, and aligned with user expectations and background\nknowledge. To address these challenges, we propose Pathways of Thoughts (PoT),\nan inference-stage method that applies to any large language model (LLM)\nwithout requiring task-specific fine-tuning. The approach models the reasoning\nof an LLM as an iterative decision process, where the model dynamically selects\namong cognitive operations such as reasoning, revision, personalization, and\nclarification. This enables exploration of multiple reasoning trajectories,\nproducing diverse candidate responses that capture different perspectives. PoT\nthen aggregates and reweights these candidates according to inferred user\npreferences, yielding a final personalized response that benefits from the\ncomplementary strengths of diverse reasoning paths. Experiments on the LaMP-QA\nbenchmark for personalized QA show that PoT consistently outperforms\ncompetitive baselines, achieving up to a 13.1% relative improvement. Human\nevaluation corroborates these results, with annotators preferring outputs from\nPoT in 66% of cases and reporting ties in only 15% of cases.",
      "pdf_url": "http://arxiv.org/pdf/2509.19094v1",
      "published": "2025-09-23T14:44:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.19094v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ]
    },
    {
      "title": "Training Flow Matching Models with Reliable Labels via Self-Purification",
      "authors": [
        "Hyeongju Kim",
        "Yechan Yu",
        "June Young Yi",
        "Juheon Lee"
      ],
      "abstract": "Training datasets are inherently imperfect, often containing mislabeled\nsamples due to human annotation errors, limitations of tagging models, and\nother sources of noise. Such label contamination can significantly degrade the\nperformance of a trained model. In this work, we introduce Self-Purifying Flow\nMatching (SPFM), a principled approach to filtering unreliable data within the\nflow-matching framework. SPFM identifies suspicious data using the model itself\nduring the training process, bypassing the need for pretrained models or\nadditional modules. Our experiments demonstrate that models trained with SPFM\ngenerate samples that accurately adhere to the specified conditioning, even\nwhen trained on noisy labels. Furthermore, we validate the robustness of SPFM\non the TITW dataset, which consists of in-the-wild speech data, achieving\nperformance that surpasses existing baselines.",
      "pdf_url": "http://arxiv.org/pdf/2509.19091v1",
      "published": "2025-09-23T14:43:27+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.19091v1",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.SD"
      ]
    },
    {
      "title": "Citrus-V: Advancing Medical Foundation Models with Unified Medical Image Grounding for Clinical Reasoning",
      "authors": [
        "Guoxin Wang",
        "Jun Zhao",
        "Xinyi Liu",
        "Yanbo Liu",
        "Xuyang Cao",
        "Chao Li",
        "Zhuoyun Liu",
        "Qintian Sun",
        "Fangru Zhou",
        "Haoqiang Xing",
        "Zhenhong Yang"
      ],
      "abstract": "Medical imaging provides critical evidence for clinical diagnosis, treatment\nplanning, and surgical decisions, yet most existing imaging models are narrowly\nfocused and require multiple specialized networks, limiting their\ngeneralization. Although large-scale language and multimodal models exhibit\nstrong reasoning and multi-task capabilities, real-world clinical applications\ndemand precise visual grounding, multimodal integration, and chain-of-thought\nreasoning. We introduce Citrus-V, a multimodal medical foundation model that\ncombines image analysis with textual reasoning. The model integrates detection,\nsegmentation, and multimodal chain-of-thought reasoning, enabling pixel-level\nlesion localization, structured report generation, and physician-like\ndiagnostic inference in a single framework. We propose a novel multimodal\ntraining approach and release a curated open-source data suite covering\nreasoning, detection, segmentation, and document understanding tasks.\nEvaluations demonstrate that Citrus-V outperforms existing open-source medical\nmodels and expert-level imaging systems across multiple benchmarks, delivering\na unified pipeline from visual grounding to clinical reasoning and supporting\nprecise lesion quantification, automated reporting, and reliable second\nopinions.",
      "pdf_url": "http://arxiv.org/pdf/2509.19090v2",
      "published": "2025-09-23T14:42:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.19090v2",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "A Mega-Study of Digital Twins Reveals Strengths, Weaknesses and Opportunities for Further Improvement",
      "authors": [
        "Tiany Peng",
        "George Gui",
        "Daniel J. Merlau",
        "Grace Jiarui Fan",
        "Malek Ben Sliman",
        "Melanie Brucks",
        "Eric J. Johnson",
        "Vicki Morwitz",
        "Abdullah Althenayyan",
        "Silvia Bellezza",
        "Dante Donati",
        "Hortense Fong",
        "Elizabeth Friedman",
        "Ariana Guevara",
        "Mohamed Hussein",
        "Kinshuk Jerath",
        "Bruce Kogut",
        "Kristen Lane",
        "Hannah Li",
        "Patryk Perkowski",
        "Oded Netzer",
        "Olivier Toubia"
      ],
      "abstract": "Do \"digital twins\" capture individual responses in surveys and experiments?\nWe run 19 pre-registered studies on a national U.S. panel and their LLM-powered\ndigital twins (constructed based on previously-collected extensive\nindividual-level data) and compare twin and human answers across 164 outcomes.\nThe correlation between twin and human answers is modest (approximately 0.2 on\naverage) and twin responses are less variable than human responses. While\nconstructing digital twins based on rich individual-level data improves our\nability to capture heterogeneity across participants and predict relative\ndifferences between them, it does not substantially improve our ability to\npredict the exact answers given by specific participants or enhance predictions\nof population means. Twin performance varies by domain and is higher among more\neducated, higher-income, and ideologically moderate participants. These results\nsuggest current digital twins can capture some degree of relative differences\nbut are unreliable for individual-level predictions and sample mean and\nvariance estimation, underscoring the need for careful validation before use.\nOur data and code are publicly available for researchers and practitioners\ninterested in optimizing digital twin pipelines.",
      "pdf_url": "http://arxiv.org/pdf/2509.19088v1",
      "published": "2025-09-23T14:42:14+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.19088v1",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC",
        "stat.AP"
      ]
    },
    {
      "title": "Graph Neural Networks with Similarity-Navigated Probabilistic Feature Copying",
      "authors": [
        "Asela Hevapathige"
      ],
      "abstract": "Graph Neural Networks (GNNs) have demonstrated remarkable success across\nvarious graph-based tasks. However, they face some fundamental limitations:\nfeature oversmoothing can cause node representations to become\nindistinguishable in deeper networks, they struggle to effectively manage\nheterogeneous relationships where connected nodes differ significantly, and\nthey process entire feature vectors as indivisible units, which limits\nflexibility. We seek to address these limitations. We propose AxelGNN, a novel\nGNN architecture inspired by Axelrod's cultural dissemination model that\naddresses these limitations through a unified framework. AxelGNN incorporates\nsimilarity-gated probabilistic interactions that adaptively promote convergence\nor divergence based on node similarity, implements trait-level copying\nmechanisms for fine-grained feature aggregation at the segment level, and\nmaintains global polarization to preserve node distinctiveness across multiple\nrepresentation clusters. The model's bistable convergence dynamics naturally\nhandle both homophilic and heterophilic graphs within a single architecture.\nExtensive experiments on node classification and influence estimation\nbenchmarks demonstrate that AxelGNN consistently outperforms or matches\nstate-of-the-art GNN methods across diverse graph structures with varying\nhomophily-heterophily characteristics.",
      "pdf_url": "http://arxiv.org/pdf/2509.19084v1",
      "published": "2025-09-23T14:39:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.19084v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "World4RL: Diffusion World Models for Policy Refinement with Reinforcement Learning for Robotic Manipulation",
      "authors": [
        "Zhennan Jiang",
        "Kai Liu",
        "Yuxin Qin",
        "Shuai Tian",
        "Yupeng Zheng",
        "Mingcai Zhou",
        "Chao Yu",
        "Haoran Li",
        "Dongbin Zhao"
      ],
      "abstract": "Robotic manipulation policies are commonly initialized through imitation\nlearning, but their performance is limited by the scarcity and narrow coverage\nof expert data. Reinforcement learning can refine polices to alleviate this\nlimitation, yet real-robot training is costly and unsafe, while training in\nsimulators suffers from the sim-to-real gap. Recent advances in generative\nmodels have demonstrated remarkable capabilities in real-world simulation, with\ndiffusion models in particular excelling at generation. This raises the\nquestion of how diffusion model-based world models can be combined to enhance\npre-trained policies in robotic manipulation. In this work, we propose\nWorld4RL, a framework that employs diffusion-based world models as\nhigh-fidelity simulators to refine pre-trained policies entirely in imagined\nenvironments for robotic manipulation. Unlike prior works that primarily employ\nworld models for planning, our framework enables direct end-to-end policy\noptimization. World4RL is designed around two principles: pre-training a\ndiffusion world model that captures diverse dynamics on multi-task datasets and\nrefining policies entirely within a frozen world model to avoid online\nreal-world interactions. We further design a two-hot action encoding scheme\ntailored for robotic manipulation and adopt diffusion backbones to improve\nmodeling fidelity. Extensive simulation and real-world experiments demonstrate\nthat World4RL provides high-fidelity environment modeling and enables\nconsistent policy refinement, yielding significantly higher success rates\ncompared to imitation learning and other baselines. More visualization results\nare available at https://world4rl.github.io/.",
      "pdf_url": "http://arxiv.org/pdf/2509.19080v1",
      "published": "2025-09-23T14:38:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.19080v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "Code Driven Planning with Domain-Adaptive Critic",
      "authors": [
        "Zikang Tian",
        "Shaohui Peng",
        "Du Huang",
        "Jiaming Guo",
        "Ruizhi Chen",
        "Rui Zhang",
        "Xishan Zhang",
        "Yuxuan Guo",
        "Zidong Du",
        "Qi Guo",
        "Ling Li",
        "Yewen Pu",
        "Xing Hu",
        "Yunji Chen"
      ],
      "abstract": "Large Language Models (LLMs) have been widely adopted as task planners for AI\nagents in sequential decision-making problems, leveraging their extensive world\nknowledge. However, the gap between their general knowledge and\nenvironment-specific requirements often leads to inaccurate plans. To address\nthis, existing approaches rely on frequent LLM queries to iteratively refine\nplans based on immediate environmental feedback, which incurs substantial query\ncosts. However, this refinement is typically guided by short-term environmental\nfeedback, limiting LLMs from developing plans aligned with long-term rewards.\nWe propose Code Driven Planning with Domain-Adaptive Critic (CoPiC). Instead of\nrelying on frequent queries, CoPiC employs LLMs to generate a diverse set of\nhigh-level planning programs, which iteratively produce and refine candidate\nplans. A trained domain-adaptive critic then evaluates these candidates and\nselects the one most aligned with long-term rewards for execution. Using\nhigh-level planning programs as planner and domain-adaptive critic as\nestimator, CoPiC improves planning while significantly reducing query costs.\nResults in ALFWorld, NetHack, and StarCraft II Unit Building show that CoPiC\noutperforms advanced LLM-based baselines, AdaPlanner and Reflexion, achieving\nan average (1) 23.33% improvement in success rate and (2) 91.27% reduction in\nquery costs.",
      "pdf_url": "http://arxiv.org/pdf/2509.19077v1",
      "published": "2025-09-23T14:36:12+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.19077v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Beyond Backpropagation: Exploring Innovative Algorithms for Energy-Efficient Deep Neural Network Training",
      "authors": [
        "Przemysław Spyra"
      ],
      "abstract": "The rising computational and energy demands of deep neural networks (DNNs),\ndriven largely by backpropagation (BP), challenge sustainable AI development.\nThis paper rigorously investigates three BP-free training methods: the\nForward-Forward (FF), Cascaded-Forward (CaFo), and Mono-Forward (MF)\nalgorithms, tracing their progression from foundational concepts to a\ndemonstrably superior solution.\n  A robust comparative framework was established: each algorithm was\nimplemented on its native architecture (MLPs for FF and MF, a CNN for CaFo) and\nbenchmarked against an equivalent BP-trained model. Hyperparameters were\noptimized with Optuna, and consistent early stopping criteria were applied\nbased on validation performance, ensuring all models were optimally tuned\nbefore comparison.\n  Results show that MF not only competes with but consistently surpasses BP in\nclassification accuracy on its native MLPs. Its superior generalization stems\nfrom converging to a more favorable minimum in the validation loss landscape,\nchallenging the assumption that global optimization is required for\nstate-of-the-art results. Measured at the hardware level using the NVIDIA\nManagement Library (NVML) API, MF reduces energy consumption by up to 41% and\nshortens training time by up to 34%, translating to a measurably smaller carbon\nfootprint as estimated by CodeCarbon.\n  Beyond this primary result, we present a hardware-level analysis that\nexplains the efficiency gains: exposing FF's architectural inefficiencies,\nvalidating MF's computationally lean design, and challenging the assumption\nthat all BP-free methods are inherently more memory-efficient. By documenting\nthe evolution from FF's conceptual groundwork to MF's synthesis of accuracy and\nsustainability, this work offers a clear, data-driven roadmap for future\nenergy-efficient deep learning.",
      "pdf_url": "http://arxiv.org/pdf/2509.19063v1",
      "published": "2025-09-23T14:27:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.19063v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68T07"
      ]
    },
    {
      "title": "Towards Causal Representation Learning with Observable Sources as Auxiliaries",
      "authors": [
        "Kwonho Kim",
        "Heejeong Nam",
        "Inwoo Hwang",
        "Sanghack Lee"
      ],
      "abstract": "Causal representation learning seeks to recover latent factors that generate\nobservational data through a mixing function. Needing assumptions on latent\nstructures or relationships to achieve identifiability in general, prior works\noften build upon conditional independence given known auxiliary variables.\nHowever, prior frameworks limit the scope of auxiliary variables to be external\nto the mixing function. Yet, in some cases, system-driving latent factors can\nbe easily observed or extracted from data, possibly facilitating\nidentification. In this paper, we introduce a framework of observable sources\nbeing auxiliaries, serving as effective conditioning variables. Our main\nresults show that one can identify entire latent variables up to subspace-wise\ntransformations and permutations using volume-preserving encoders. Moreover,\nwhen multiple known auxiliary variables are available, we offer a\nvariable-selection scheme to choose those that maximize recoverability of the\nlatent factors given knowledge of the latent causal graph. Finally, we\ndemonstrate the effectiveness of our framework through experiments on synthetic\ngraph and image data, thereby extending the boundaries of current approaches.",
      "pdf_url": "http://arxiv.org/pdf/2509.19058v1",
      "published": "2025-09-23T14:22:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.19058v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Landmarks, Monuments, and Beacons: Understanding Generative Calls to Action",
      "authors": [
        "Victoire Hervé",
        "Henrik Warpefelt",
        "Christoph Salge"
      ],
      "abstract": "Algorithmic evaluation of procedurally generated content struggles to find\nmetrics that align with human experience, particularly for composite artefacts.\nAutomatic decomposition as a possible solution requires concepts that meet a\nrange of properties. To this end, drawing on Games Studies and Game AI\nresearch, we introduce the nested concepts of \\textit{Landmarks},\n\\textit{Monuments}, and \\textit{Beacons}. These concepts are based on the\nartefact's perceivability, evocativeness, and Call to Action, all from a\nplayer-centric perspective. These terms are generic to games and usable across\ngenres. We argue that these entities can be found and evaluated with techniques\ncurrently used in both research and industry, opening a path towards a fully\nautomated decomposition of PCG, and evaluation of the salient sub-components.\nAlthough the work presented here emphasises mixed-initiative PCG and\ncompositional PCG, we believe it applies beyond those domains. With this\napproach, we intend to create a connection between humanities and technical\ngame research and allow for better computational PCG evaluation",
      "pdf_url": "http://arxiv.org/pdf/2509.19030v1",
      "published": "2025-09-23T14:03:54+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.19030v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Reduced-Order Model-Guided Reinforcement Learning for Demonstration-Free Humanoid Locomotion",
      "authors": [
        "Shuai Liu",
        "Meng Cheng Lau"
      ],
      "abstract": "We introduce Reduced-Order Model-Guided Reinforcement Learning (ROM-GRL), a\ntwo-stage reinforcement learning framework for humanoid walking that requires\nno motion capture data or elaborate reward shaping. In the first stage, a\ncompact 4-DOF (four-degree-of-freedom) reduced-order model (ROM) is trained via\nProximal Policy Optimization. This generates energy-efficient gait templates.\nIn the second stage, those dynamically consistent trajectories guide a\nfull-body policy trained with Soft Actor--Critic augmented by an adversarial\ndiscriminator, ensuring the student's five-dimensional gait feature\ndistribution matches the ROM's demonstrations. Experiments at 1\nmeter-per-second and 4 meter-per-second show that ROM-GRL produces stable,\nsymmetric gaits with substantially lower tracking error than a pure-reward\nbaseline. By distilling lightweight ROM guidance into high-dimensional\npolicies, ROM-GRL bridges the gap between reward-only and imitation-based\nlocomotion methods, enabling versatile, naturalistic humanoid behaviors without\nany human demonstrations.",
      "pdf_url": "http://arxiv.org/pdf/2509.19023v1",
      "published": "2025-09-23T13:58:36+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.19023v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "Fully Learnable Neural Reward Machines",
      "authors": [
        "Hazem Dewidar",
        "Elena Umili"
      ],
      "abstract": "Non-Markovian Reinforcement Learning (RL) tasks present significant\nchallenges, as agents must reason over entire trajectories of state-action\npairs to make optimal decisions. A common strategy to address this is through\nsymbolic formalisms, such as Linear Temporal Logic (LTL) or automata, which\nprovide a structured way to express temporally extended objectives. However,\nthese approaches often rely on restrictive assumptions -- such as the\navailability of a predefined Symbol Grounding (SG) function mapping raw\nobservations to high-level symbolic representations, or prior knowledge of the\ntemporal task. In this work, we propose a fully learnable version of Neural\nReward Machines (NRM), which can learn both the SG function and the automaton\nend-to-end, removing any reliance on prior knowledge. Our approach is therefore\nas easily applicable as classic deep RL (DRL) approaches, while being far more\nexplainable, because of the finite and compact nature of automata. Furthermore,\nwe show that by integrating Fully Learnable Reward Machines (FLNRM) with DRL,\nour method outperforms previous approaches based on Recurrent Neural Networks\n(RNNs).",
      "pdf_url": "http://arxiv.org/pdf/2509.19017v1",
      "published": "2025-09-23T13:57:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.19017v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Pure Vision Language Action (VLA) Models: A Comprehensive Survey",
      "authors": [
        "Dapeng Zhang",
        "Jin Sun",
        "Chenghui Hu",
        "Xiaoyan Wu",
        "Zhenlong Yuan",
        "Rui Zhou",
        "Fei Shen",
        "Qingguo Zhou"
      ],
      "abstract": "The emergence of Vision Language Action (VLA) models marks a paradigm shift\nfrom traditional policy-based control to generalized robotics, reframing Vision\nLanguage Models (VLMs) from passive sequence generators into active agents for\nmanipulation and decision-making in complex, dynamic environments. This survey\ndelves into advanced VLA methods, aiming to provide a clear taxonomy and a\nsystematic, comprehensive review of existing research. It presents a\ncomprehensive analysis of VLA applications across different scenarios and\nclassifies VLA approaches into several paradigms: autoregression-based,\ndiffusion-based, reinforcement-based, hybrid, and specialized methods; while\nexamining their motivations, core strategies, and implementations in detail. In\naddition, foundational datasets, benchmarks, and simulation platforms are\nintroduced. Building on the current VLA landscape, the review further proposes\nperspectives on key challenges and future directions to advance research in VLA\nmodels and generalizable robotics. By synthesizing insights from over three\nhundred recent studies, this survey maps the contours of this rapidly evolving\nfield and highlights the opportunities and challenges that will shape the\ndevelopment of scalable, general-purpose VLA methods.",
      "pdf_url": "http://arxiv.org/pdf/2509.19012v1",
      "published": "2025-09-23T13:53:52+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.19012v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "VIR-Bench: Evaluating Geospatial and Temporal Understanding of MLLMs via Travel Video Itinerary Reconstruction",
      "authors": [
        "Hao Wang",
        "Eiki Murata",
        "Lingfang Zhang",
        "Ayako Sato",
        "So Fukuda",
        "Ziqi Yin",
        "Wentao Hu",
        "Keisuke Nakao",
        "Yusuke Nakamura",
        "Sebastian Zwirner",
        "Yi-Chia Chen",
        "Hiroyuki Otomo",
        "Hiroki Ouchi",
        "Daisuke Kawahara"
      ],
      "abstract": "Recent advances in multimodal large language models (MLLMs) have\nsignificantly enhanced video understanding capabilities, opening new\npossibilities for practical applications. Yet current video benchmarks focus\nlargely on indoor scenes or short-range outdoor activities, leaving the\nchallenges associated with long-distance travel largely unexplored. Mastering\nextended geospatial-temporal trajectories is critical for next-generation\nMLLMs, underpinning real-world tasks such as embodied-AI planning and\nnavigation. To bridge this gap, we present VIR-Bench, a novel benchmark\nconsisting of 200 travel videos that frames itinerary reconstruction as a\nchallenging task designed to evaluate and push forward MLLMs'\ngeospatial-temporal intelligence. Experimental results reveal that\nstate-of-the-art MLLMs, including proprietary ones, struggle to achieve high\nscores, underscoring the difficulty of handling videos that span extended\nspatial and temporal scales. Moreover, we conduct an in-depth case study in\nwhich we develop a prototype travel-planning agent that leverages the insights\ngained from VIR-Bench. The agent's markedly improved itinerary recommendations\nverify that our evaluation protocol not only benchmarks models effectively but\nalso translates into concrete performance gains in user-facing applications.",
      "pdf_url": "http://arxiv.org/pdf/2509.19002v1",
      "published": "2025-09-23T13:46:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.19002v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    },
    {
      "title": "Remaining Time Prediction in Outbound Warehouse Processes: A Case Study (Short Paper)",
      "authors": [
        "Erik Penther",
        "Michael Grohs",
        "Jana-Rebecca Rehse"
      ],
      "abstract": "Predictive process monitoring is a sub-domain of process mining which aims to\nforecast the future of ongoing process executions. One common prediction target\nis the remaining time, meaning the time that will elapse until a process\nexecution is completed. In this paper, we compare four different remaining time\nprediction approaches in a real-life outbound warehouse process of a logistics\ncompany in the aviation business. For this process, the company provided us\nwith a novel and original event log with 169,523 traces, which we can make\npublicly available. Unsurprisingly, we find that deep learning models achieve\nthe highest accuracy, but shallow methods like conventional boosting techniques\nachieve competitive accuracy and require significantly fewer computational\nresources.",
      "pdf_url": "http://arxiv.org/pdf/2509.18986v1",
      "published": "2025-09-23T13:37:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.18986v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "From latent factors to language: a user study on LLM-generated explanations for an inherently interpretable matrix-based recommender system",
      "authors": [
        "Maxime Manderlier",
        "Fabian Lecron",
        "Olivier Vu Thanh",
        "Nicolas Gillis"
      ],
      "abstract": "We investigate whether large language models (LLMs) can generate effective,\nuser-facing explanations from a mathematically interpretable recommendation\nmodel. The model is based on constrained matrix factorization, where user types\nare explicitly represented and predicted item scores share the same scale as\nobserved ratings, making the model's internal representations and predicted\nscores directly interpretable. This structure is translated into natural\nlanguage explanations using carefully designed LLM prompts. Many works in\nexplainable AI rely on automatic evaluation metrics, which often fail to\ncapture users' actual needs and perceptions. In contrast, we adopt a\nuser-centered approach: we conduct a study with 326 participants who assessed\nthe quality of the explanations across five key dimensions-transparency,\neffectiveness, persuasion, trust, and satisfaction-as well as the\nrecommendations themselves.To evaluate how different explanation strategies are\nperceived, we generate multiple explanation types from the same underlying\nmodel, varying the input information provided to the LLM. Our analysis reveals\nthat all explanation types are generally well received, with moderate\nstatistical differences between strategies. User comments further underscore\nhow participants react to each type of explanation, offering complementary\ninsights beyond the quantitative results.",
      "pdf_url": "http://arxiv.org/pdf/2509.18980v1",
      "published": "2025-09-23T13:30:03+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.18980v1",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.IR",
        "H.3.3; H.5.2; I.2.7"
      ]
    },
    {
      "title": "LLM-based Agents Suffer from Hallucinations: A Survey of Taxonomy, Methods, and Directions",
      "authors": [
        "Xixun Lin",
        "Yucheng Ning",
        "Jingwen Zhang",
        "Yan Dong",
        "Yilong Liu",
        "Yongxuan Wu",
        "Xiaohua Qi",
        "Nan Sun",
        "Yanmin Shang",
        "Pengfei Cao",
        "Lixin Zou",
        "Xu Chen",
        "Chuan Zhou",
        "Jia Wu",
        "Shirui Pan",
        "Bin Wang",
        "Yanan Cao",
        "Kai Chen",
        "Songlin Hu",
        "Li Guo"
      ],
      "abstract": "Driven by the rapid advancements of Large Language Models (LLMs), LLM-based\nagents have emerged as powerful intelligent systems capable of human-like\ncognition, reasoning, and interaction. These agents are increasingly being\ndeployed across diverse real-world applications, including student education,\nscientific research, and financial analysis. However, despite their remarkable\npotential, LLM-based agents remain vulnerable to hallucination issues, which\ncan result in erroneous task execution and undermine the reliability of the\noverall system design. Addressing this critical challenge requires a deep\nunderstanding and a systematic consolidation of recent advances on LLM-based\nagents. To this end, we present the first comprehensive survey of\nhallucinations in LLM-based agents. By carefully analyzing the complete\nworkflow of agents, we propose a new taxonomy that identifies different types\nof agent hallucinations occurring at different stages. Furthermore, we conduct\nan in-depth examination of eighteen triggering causes underlying the emergence\nof agent hallucinations. Through a detailed review of a large number of\nexisting studies, we summarize approaches for hallucination mitigation and\ndetection, and highlight promising directions for future research. We hope this\nsurvey will inspire further efforts toward addressing hallucinations in\nLLM-based agents, ultimately contributing to the development of more robust and\nreliable agent systems.",
      "pdf_url": "http://arxiv.org/pdf/2509.18970v1",
      "published": "2025-09-23T13:24:48+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.18970v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Eva-VLA: Evaluating Vision-Language-Action Models' Robustness Under Real-World Physical Variations",
      "authors": [
        "Hanqing Liu",
        "Jiahuan Long",
        "Junqi Wu",
        "Jiacheng Hou",
        "Huili Tang",
        "Tingsong Jiang",
        "Weien Zhou",
        "Wen Yao"
      ],
      "abstract": "Vision-Language-Action (VLA) models have emerged as promising solutions for\nrobotic manipulation, yet their robustness to real-world physical variations\nremains critically underexplored. To bridge this gap, we propose Eva-VLA, the\nfirst unified framework that systematically evaluates the robustness of VLA\nmodels by transforming discrete physical variations into continuous\noptimization problems. However, comprehensively assessing VLA robustness\npresents two key challenges: (1) how to systematically characterize diverse\nphysical variations encountered in real-world deployments while maintaining\nevaluation reproducibility, and (2) how to discover worst-case scenarios\nwithout prohibitive real-world data collection costs efficiently. To address\nthe first challenge, we decompose real-world variations into three critical\ndomains: object 3D transformations that affect spatial reasoning, illumination\nvariations that challenge visual perception, and adversarial patches that\ndisrupt scene understanding. For the second challenge, we introduce a\ncontinuous black-box optimization framework that transforms discrete physical\nvariations into parameter optimization, enabling systematic exploration of\nworst-case scenarios. Extensive experiments on state-of-the-art OpenVLA models\nacross multiple benchmarks reveal alarming vulnerabilities: all variation types\ntrigger failure rates exceeding 60%, with object transformations causing up to\n97.8% failure in long-horizon tasks. Our findings expose critical gaps between\ncontrolled laboratory success and unpredictable deployment readiness, while the\nEva-VLA framework provides a practical pathway for hardening VLA-based robotic\nmanipulation models against real-world deployment challenges.",
      "pdf_url": "http://arxiv.org/pdf/2509.18953v1",
      "published": "2025-09-23T13:02:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.18953v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "Towards Privacy-Aware Bayesian Networks: A Credal Approach",
      "authors": [
        "Niccolò Rocchi",
        "Fabio Stella",
        "Cassio de Campos"
      ],
      "abstract": "Bayesian networks (BN) are probabilistic graphical models that enable\nefficient knowledge representation and inference. These have proven effective\nacross diverse domains, including healthcare, bioinformatics and economics. The\nstructure and parameters of a BN can be obtained by domain experts or directly\nlearned from available data. However, as privacy concerns escalate, it becomes\nincreasingly critical for publicly released models to safeguard sensitive\ninformation in training data. Typically, released models do not prioritize\nprivacy by design. In particular, tracing attacks from adversaries can combine\nthe released BN with auxiliary data to determine whether specific individuals\nbelong to the data from which the BN was learned. State-of-the-art protection\ntecniques involve introducing noise into the learned parameters. While this\noffers robust protection against tracing attacks, it significantly impacts the\nmodel's utility, in terms of both the significance and accuracy of the\nresulting inferences. Hence, high privacy may be attained at the cost of\nreleasing a possibly ineffective model. This paper introduces credal networks\n(CN) as a novel solution for balancing the model's privacy and utility. After\nadapting the notion of tracing attacks, we demonstrate that a CN enables the\nmasking of the learned BN, thereby reducing the probability of successful\nattacks. As CNs are obfuscated but not noisy versions of BNs, they can achieve\nmeaningful inferences while safeguarding privacy. Moreover, we identify key\nlearning information that must be concealed to prevent attackers from\nrecovering the underlying BN. Finally, we conduct a set of numerical\nexperiments to analyze how privacy gains can be modulated by tuning the CN\nhyperparameters. Our results confirm that CNs provide a principled, practical,\nand effective approach towards the development of privacy-aware probabilistic\ngraphical models.",
      "pdf_url": "http://arxiv.org/pdf/2509.18949v1",
      "published": "2025-09-23T12:58:32+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.18949v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Data Efficient Adaptation in Large Language Models via Continuous Low-Rank Fine-Tuning",
      "authors": [
        "Xiao Han",
        "Zimo Zhao",
        "Wanyu Wang",
        "Maolin Wang",
        "Zitao Liu",
        "Yi Chang",
        "Xiangyu Zhao"
      ],
      "abstract": "Recent advancements in Large Language Models (LLMs) have emphasized the\ncritical role of fine-tuning (FT) techniques in adapting LLMs to specific\ntasks, especially when retraining from scratch is computationally infeasible.\nFine-tuning enables LLMs to leverage task- or domain-specific data, producing\nmodels that more effectively meet the requirements of targeted applications.\nHowever, con- ventional FT approaches often suffer from catastrophic forgetting\nand suboptimal data efficiency, limiting their real-world applicability. To\naddress these challenges, this paper proposes DEAL, a novel framework that\nintegrates Low-Rank Adapta- tion (LoRA) with a continuous fine-tuning strategy.\nBy incorporating knowledge retention and adaptive parameter update modules, the\nframework mitigates the lim- itations of existing FT methods while maintaining\nefficiency in privacy-preserving settings. Experiments on 15 diverse datasets\nshow that DEAL consistently outper- forms baseline methods, yielding\nsubstantial gains in task accuracy and resource efficiency. These findings\ndemonstrate the potential of our approach to advance continual adaptation in\nLLMs by enhancing task performance while improving resource efficiency.",
      "pdf_url": "http://arxiv.org/pdf/2509.18942v1",
      "published": "2025-09-23T12:55:57+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.18942v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "No Labels Needed: Zero-Shot Image Classification with Collaborative Self-Learning",
      "authors": [
        "Matheus Vinícius Todescato",
        "Joel Luís Carbonera"
      ],
      "abstract": "While deep learning, including Convolutional Neural Networks (CNNs) and\nVision Transformers (ViTs), has significantly advanced classification\nperformance, its typical reliance on extensive annotated datasets presents a\nmajor obstacle in many practical scenarios where such data is scarce.\nVision-language models (VLMs) and transfer learning with pre-trained visual\nmodels appear as promising techniques to deal with this problem. This paper\nproposes a novel zero-shot image classification framework that combines a VLM\nand a pre-trained visual model within a self-learning cycle. Requiring only the\nset of class names and no labeled training data, our method utilizes a\nconfidence-based pseudo-labeling strategy to train a lightweight classifier\ndirectly on the test data, enabling dynamic adaptation. The VLM identifies\nhigh-confidence samples, and the pre-trained visual model enhances their visual\nrepresentations. These enhanced features then iteratively train the classifier,\nallowing the system to capture complementary semantic and visual cues without\nsupervision. Notably, our approach avoids VLM fine-tuning and the use of large\nlanguage models, relying on the visual-only model to reduce the dependence on\nsemantic representation. Experimental evaluations on ten diverse datasets\ndemonstrate that our approach outperforms the baseline zero-shot method.",
      "pdf_url": "http://arxiv.org/pdf/2509.18938v1",
      "published": "2025-09-23T12:54:52+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.18938v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Accurate and Efficient Prediction of Wi-Fi Link Quality Based on Machine Learning",
      "authors": [
        "Gabriele Formis",
        "Gianluca Cena",
        "Lukasz Wisniewski",
        "Stefano Scanzio"
      ],
      "abstract": "Wireless communications are characterized by their unpredictability, posing\nchallenges for maintaining consistent communication quality. This paper\npresents a comprehensive analysis of various prediction models, with a focus on\nachieving accurate and efficient Wi-Fi link quality forecasts using machine\nlearning techniques. Specifically, the paper evaluates the performance of\ndata-driven models based on the linear combination of exponential moving\naverages, which are designed for low-complexity implementations and are then\nsuitable for hardware platforms with limited processing resources. Accuracy of\nthe proposed approaches was assessed using experimental data from a real-world\nWi-Fi testbed, considering both channel-dependent and channel-independent\ntraining data. Remarkably, channel-independent models, which allow for\ngeneralized training by equipment manufacturers, demonstrated competitive\nperformance. Overall, this study provides insights into the practical\ndeployment of machine learning-based prediction models for enhancing Wi-Fi\ndependability in industrial environments.",
      "pdf_url": "http://arxiv.org/pdf/2509.18933v1",
      "published": "2025-09-23T12:52:01+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.18933v1",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Tackling GNARLy Problems: Graph Neural Algorithmic Reasoning Reimagined through Reinforcement Learning",
      "authors": [
        "Alex Schutz",
        "Victor-Alexandru Darvariu",
        "Efimia Panagiotaki",
        "Bruno Lacerda",
        "Nick Hawes"
      ],
      "abstract": "Neural Algorithmic Reasoning (NAR) is a paradigm that trains neural networks\nto execute classic algorithms by supervised learning. Despite its successes,\nimportant limitations remain: inability to construct valid solutions without\npost-processing and to reason about multiple correct ones, poor performance on\ncombinatorial NP-hard problems, and inapplicability to problems for which\nstrong algorithms are not yet known. To address these limitations, we reframe\nthe problem of learning algorithm trajectories as a Markov Decision Process,\nwhich imposes structure on the solution construction procedure and unlocks the\npowerful tools of imitation and reinforcement learning (RL). We propose the\nGNARL framework, encompassing the methodology to translate problem formulations\nfrom NAR to RL and a learning architecture suitable for a wide range of\ngraph-based problems. We achieve very high graph accuracy results on several\nCLRS-30 problems, performance matching or exceeding much narrower NAR\napproaches for NP-hard problems and, remarkably, applicability even when\nlacking an expert algorithm.",
      "pdf_url": "http://arxiv.org/pdf/2509.18930v1",
      "published": "2025-09-23T12:49:25+00:00",
      "arxiv_url": "http://arxiv.org/abs/2509.18930v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    }
  ]
}