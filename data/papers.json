{
  "last_updated": "2025-05-16T00:52:21.098700",
  "papers": [
    {
      "title": "Language Agents Mirror Human Causal Reasoning Biases. How Can We Help Them Think Like Scientists?",
      "authors": [
        "Anthony GX-Chen",
        "Dongyan Lin",
        "Mandana Samiei",
        "Doina Precup",
        "Blake A. Richards",
        "Rob Fergus",
        "Kenneth Marino"
      ],
      "abstract": "Language model (LM) agents are increasingly used as autonomous\ndecision-makers who need to actively gather information to guide their\ndecisions. A crucial cognitive skill for such agents is the efficient\nexploration and understanding of the causal structure of the world -- key to\nrobust, scientifically grounded reasoning. Yet, it remains unclear whether LMs\npossess this capability or exhibit systematic biases leading to erroneous\nconclusions. In this work, we examine LMs' ability to explore and infer causal\nrelationships, using the well-established \"Blicket Test\" paradigm from\ndevelopmental psychology. We find that LMs reliably infer the common, intuitive\ndisjunctive causal relationships but systematically struggle with the unusual,\nyet equally (or sometimes even more) evidenced conjunctive ones. This\n\"disjunctive bias\" persists across model families, sizes, and prompting\nstrategies, and performance further declines as task complexity increases.\nInterestingly, an analogous bias appears in human adults, suggesting that LMs\nmay have inherited deep-seated reasoning heuristics from their training data.\nTo this end, we quantify similarities between LMs and humans, finding that LMs\nexhibit adult-like inference profiles (but not children-like). Finally, we\npropose a test-time sampling method which explicitly samples and eliminates\nhypotheses about causal relationships from the LM. This scalable approach\nsignificantly reduces the disjunctive bias and moves LMs closer to the goal of\nscientific, causally rigorous reasoning.",
      "pdf_url": "http://arxiv.org/pdf/2505.09614v1",
      "published": "2025-05-14T17:59:35+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.09614v1",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Customizing a Large Language Model for VHDL Design of High-Performance Microprocessors",
      "authors": [
        "Nicolas Dupuis",
        "Ravi Nair",
        "Shyam Ramji",
        "Sean McClintock",
        "Nishant Chauhan",
        "Priyanka Nagpal",
        "Bart Blaner",
        "Ken Valk",
        "Leon Stok",
        "Ruchir Puri"
      ],
      "abstract": "The use of Large Language Models (LLMs) in hardware design has taken off in\nrecent years, principally through its incorporation in tools that increase chip\ndesigner productivity. There has been considerable discussion about the use of\nLLMs in RTL specifications of chip designs, for which the two most popular\nlanguages are Verilog and VHDL. LLMs and their use in Verilog design has\nreceived significant attention due to the higher popularity of the language,\nbut little attention so far has been given to VHDL despite its continued\npopularity in the industry. There has also been little discussion about the\nunique needs of organizations that engage in high-performance processor design,\nand techniques to deploy AI solutions in these settings. In this paper, we\ndescribe our journey in developing a Large Language Model (LLM) specifically\nfor the purpose of explaining VHDL code, a task that has particular importance\nin an organization with decades of experience and assets in high-performance\nprocessor design. We show how we developed test sets specific to our needs and\nused them for evaluating models as we performed extended pretraining (EPT) of a\nbase LLM. Expert evaluation of the code explanations produced by the EPT model\nincreased to 69% compared to a base model rating of 43%. We further show how we\ndeveloped an LLM-as-a-judge to gauge models similar to expert evaluators. This\nled us to deriving and evaluating a host of new models, including an\ninstruction-tuned version of the EPT model with an expected expert evaluator\nrating of 71%. Our experiments also indicate that with the potential use of\nnewer base models, this rating can be pushed to 85% and beyond. We conclude\nwith a discussion on further improving the quality of hardware design LLMs\nusing exciting new developments in the Generative AI world.",
      "pdf_url": "http://arxiv.org/pdf/2505.09610v1",
      "published": "2025-05-14T17:58:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.09610v1",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "How Hungry is AI? Benchmarking Energy, Water, and Carbon Footprint of LLM Inference",
      "authors": [
        "Nidhal Jegham",
        "Marwen Abdelatti",
        "Lassad Elmoubarki",
        "Abdeltawab Hendawi"
      ],
      "abstract": "As large language models (LLMs) spread across industries, understanding their\nenvironmental footprint at the inference level is no longer optional; it is\nessential. However, most existing studies exclude proprietary models, overlook\ninfrastructural variability and overhead, or focus solely on training, even as\ninference increasingly dominates AI's environmental impact. To bridge this gap,\nthis paper introduces a novel infrastructure-aware benchmarking framework for\nquantifying the environmental footprint of LLM inference across 30\nstate-of-the-art models as deployed in commercial data centers. Our framework\ncombines public API performance data with region-specific environmental\nmultipliers and statistical inference of hardware configurations. We\nadditionally utilize cross-efficiency Data Envelopment Analysis (DEA) to rank\nmodels by performance relative to environmental cost. Our results show that o3\nand DeepSeek-R1 emerge as the most energy-intensive models, consuming over 33\nWh per long prompt, more than 70 times the consumption of GPT-4.1 nano, and\nthat Claude-3.7 Sonnet ranks highest in eco-efficiency. While a single short\nGPT-4o query consumes 0.43 Wh, scaling this to 700 million queries/day results\nin substantial annual environmental impacts. These include electricity use\ncomparable to 35,000 U.S. homes, freshwater evaporation matching the annual\ndrinking needs of 1.2 million people, and carbon emissions requiring a\nChicago-sized forest to offset. These findings illustrate a growing paradox:\nalthough individual queries are efficient, their global scale drives\ndisproportionate resource consumption. Our study provides a standardized,\nempirically grounded methodology for benchmarking the sustainability of LLM\ndeployments, laying a foundation for future environmental accountability in AI\ndevelopment and sustainability standards.",
      "pdf_url": "http://arxiv.org/pdf/2505.09598v1",
      "published": "2025-05-14T17:47:00+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.09598v1",
      "categories": [
        "cs.CY",
        "cs.AI"
      ]
    },
    {
      "title": "WorldView-Bench: A Benchmark for Evaluating Global Cultural Perspectives in Large Language Models",
      "authors": [
        "Abdullah Mushtaq",
        "Imran Taj",
        "Rafay Naeem",
        "Ibrahim Ghaznavi",
        "Junaid Qadir"
      ],
      "abstract": "Large Language Models (LLMs) are predominantly trained and aligned in ways\nthat reinforce Western-centric epistemologies and socio-cultural norms, leading\nto cultural homogenization and limiting their ability to reflect global\ncivilizational plurality. Existing benchmarking frameworks fail to adequately\ncapture this bias, as they rely on rigid, closed-form assessments that overlook\nthe complexity of cultural inclusivity. To address this, we introduce\nWorldView-Bench, a benchmark designed to evaluate Global Cultural Inclusivity\n(GCI) in LLMs by analyzing their ability to accommodate diverse worldviews. Our\napproach is grounded in the Multiplex Worldview proposed by Senturk et al.,\nwhich distinguishes between Uniplex models, reinforcing cultural\nhomogenization, and Multiplex models, which integrate diverse perspectives.\nWorldView-Bench measures Cultural Polarization, the exclusion of alternative\nperspectives, through free-form generative evaluation rather than conventional\ncategorical benchmarks. We implement applied multiplexity through two\nintervention strategies: (1) Contextually-Implemented Multiplex LLMs, where\nsystem prompts embed multiplexity principles, and (2) Multi-Agent System\n(MAS)-Implemented Multiplex LLMs, where multiple LLM agents representing\ndistinct cultural perspectives collaboratively generate responses. Our results\ndemonstrate a significant increase in Perspectives Distribution Score (PDS)\nentropy from 13% at baseline to 94% with MAS-Implemented Multiplex LLMs,\nalongside a shift toward positive sentiment (67.7%) and enhanced cultural\nbalance. These findings highlight the potential of multiplex-aware AI\nevaluation in mitigating cultural bias in LLMs, paving the way for more\ninclusive and ethically aligned AI systems.",
      "pdf_url": "http://arxiv.org/pdf/2505.09595v1",
      "published": "2025-05-14T17:43:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.09595v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.MA"
      ]
    },
    {
      "title": "Variational Visual Question Answering",
      "authors": [
        "Tobias Jan Wieczorek",
        "Nathalie Daun",
        "Mohammad Emtiyaz Khan",
        "Marcus Rohrbach"
      ],
      "abstract": "Despite remarkable progress in multimodal models for Visual Question\nAnswering (VQA), there remain major reliability concerns because the models can\noften be overconfident and miscalibrated, especially in out-of-distribution\n(OOD) settings. Plenty has been done to address such issues for unimodal\nmodels, but little work exists for multimodal cases. Here, we address\nunreliability in multimodal models by proposing a Variational VQA approach.\nSpecifically, instead of fine-tuning vision-language models by using AdamW, we\nemploy a recently proposed variational algorithm called IVON, which yields a\nposterior distribution over model parameters. Through extensive experiments, we\nshow that our approach improves calibration and abstentions without sacrificing\nthe accuracy of AdamW. For instance, compared to AdamW fine-tuning, we reduce\nExpected Calibration Error by more than 50% compared to the AdamW baseline and\nraise Coverage by 4% vs. SOTA (for a fixed risk of 1%). In the presence of\ndistribution shifts, the performance gain is even higher, achieving 8% Coverage\n(@ 1% risk) improvement vs. SOTA when 50% of test cases are OOD. Overall, we\npresent variational learning as a viable option to enhance the reliability of\nmultimodal models.",
      "pdf_url": "http://arxiv.org/pdf/2505.09591v1",
      "published": "2025-05-14T17:40:22+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.09591v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Ethics and Persuasion in Reinforcement Learning from Human Feedback: A Procedural Rhetorical Approach",
      "authors": [
        "Shannon Lodoen",
        "Alexi Orchard"
      ],
      "abstract": "Since 2022, versions of generative AI chatbots such as ChatGPT and Claude\nhave been trained using a specialized technique called Reinforcement Learning\nfrom Human Feedback (RLHF) to fine-tune language model output using feedback\nfrom human annotators. As a result, the integration of RLHF has greatly\nenhanced the outputs of these large language models (LLMs) and made the\ninteractions and responses appear more \"human-like\" than those of previous\nversions using only supervised learning. The increasing convergence of human\nand machine-written text has potentially severe ethical, sociotechnical, and\npedagogical implications relating to transparency, trust, bias, and\ninterpersonal relations. To highlight these implications, this paper presents a\nrhetorical analysis of some of the central procedures and processes currently\nbeing reshaped by RLHF-enhanced generative AI chatbots: upholding language\nconventions, information seeking practices, and expectations for social\nrelationships. Rhetorical investigations of generative AI and LLMs have, to\nthis point, focused largely on the persuasiveness of the content generated.\nUsing Ian Bogost's concept of procedural rhetoric, this paper shifts the site\nof rhetorical investigation from content analysis to the underlying mechanisms\nof persuasion built into RLHF-enhanced LLMs. In doing so, this theoretical\ninvestigation opens a new direction for further inquiry in AI ethics that\nconsiders how procedures rerouted through AI-driven technologies might\nreinforce hegemonic language use, perpetuate biases, decontextualize learning,\nand encroach upon human relationships. It will therefore be of interest to\neducators, researchers, scholars, and the growing number of users of generative\nAI chatbots.",
      "pdf_url": "http://arxiv.org/pdf/2505.09576v1",
      "published": "2025-05-14T17:29:19+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.09576v1",
      "categories": [
        "cs.CY",
        "cs.AI"
      ]
    },
    {
      "title": "BLIP3-o: A Family of Fully Open Unified Multimodal Models-Architecture, Training and Dataset",
      "authors": [
        "Jiuhai Chen",
        "Zhiyang Xu",
        "Xichen Pan",
        "Yushi Hu",
        "Can Qin",
        "Tom Goldstein",
        "Lifu Huang",
        "Tianyi Zhou",
        "Saining Xie",
        "Silvio Savarese",
        "Le Xue",
        "Caiming Xiong",
        "Ran Xu"
      ],
      "abstract": "Unifying image understanding and generation has gained growing attention in\nrecent research on multimodal models. Although design choices for image\nunderstanding have been extensively studied, the optimal model architecture and\ntraining recipe for a unified framework with image generation remain\nunderexplored. Motivated by the strong potential of autoregressive and\ndiffusion models for high-quality generation and scalability, we conduct a\ncomprehensive study of their use in unified multimodal settings, with emphasis\non image representations, modeling objectives, and training strategies.\nGrounded in these investigations, we introduce a novel approach that employs a\ndiffusion transformer to generate semantically rich CLIP image features, in\ncontrast to conventional VAE-based representations. This design yields both\nhigher training efficiency and improved generative quality. Furthermore, we\ndemonstrate that a sequential pretraining strategy for unified models-first\ntraining on image understanding and subsequently on image generation-offers\npractical advantages by preserving image understanding capability while\ndeveloping strong image generation ability. Finally, we carefully curate a\nhigh-quality instruction-tuning dataset BLIP3o-60k for image generation by\nprompting GPT-4o with a diverse set of captions covering various scenes,\nobjects, human gestures, and more. Building on our innovative model design,\ntraining recipe, and datasets, we develop BLIP3-o, a suite of state-of-the-art\nunified multimodal models. BLIP3-o achieves superior performance across most of\nthe popular benchmarks spanning both image understanding and generation tasks.\nTo facilitate future research, we fully open-source our models, including code,\nmodel weights, training scripts, and pretraining and instruction tuning\ndatasets.",
      "pdf_url": "http://arxiv.org/pdf/2505.09568v1",
      "published": "2025-05-14T17:11:07+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.09568v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Meta-learning Slice-to-Volume Reconstruction in Fetal Brain MRI using Implicit Neural Representations",
      "authors": [
        "Maik Dannecker",
        "Thomas Sanchez",
        "Meritxell Bach Cuadra",
        "Özgün Turgut",
        "Anthony N. Price",
        "Lucilio Cordero-Grande",
        "Vanessa Kyriakopoulou",
        "Joseph V. Hajnal",
        "Daniel Rueckert"
      ],
      "abstract": "High-resolution slice-to-volume reconstruction (SVR) from multiple\nmotion-corrupted low-resolution 2D slices constitutes a critical step in\nimage-based diagnostics of moving subjects, such as fetal brain Magnetic\nResonance Imaging (MRI). Existing solutions struggle with image artifacts and\nsevere subject motion or require slice pre-alignment to achieve satisfying\nreconstruction performance. We propose a novel SVR method to enable fast and\naccurate MRI reconstruction even in cases of severe image and motion\ncorruption. Our approach performs motion correction, outlier handling, and\nsuper-resolution reconstruction with all operations being entirely based on\nimplicit neural representations. The model can be initialized with\ntask-specific priors through fully self-supervised meta-learning on either\nsimulated or real-world data. In extensive experiments including over 480\nreconstructions of simulated and clinical MRI brain data from different\ncenters, we prove the utility of our method in cases of severe subject motion\nand image artifacts. Our results demonstrate improvements in reconstruction\nquality, especially in the presence of severe motion, compared to\nstate-of-the-art methods, and up to 50% reduction in reconstruction time.",
      "pdf_url": "http://arxiv.org/pdf/2505.09565v1",
      "published": "2025-05-14T17:07:37+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.09565v1",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Learning Long-Context Diffusion Policies via Past-Token Prediction",
      "authors": [
        "Marcel Torne",
        "Andy Tang",
        "Yuejiang Liu",
        "Chelsea Finn"
      ],
      "abstract": "Reasoning over long sequences of observations and actions is essential for\nmany robotic tasks. Yet, learning effective long-context policies from\ndemonstrations remains challenging. As context length increases, training\nbecomes increasingly expensive due to rising memory demands, and policy\nperformance often degrades as a result of spurious correlations. Recent methods\ntypically sidestep these issues by truncating context length, discarding\nhistorical information that may be critical for subsequent decisions. In this\npaper, we propose an alternative approach that explicitly regularizes the\nretention of past information. We first revisit the copycat problem in\nimitation learning and identify an opposite challenge in recent diffusion\npolicies: rather than over-relying on prior actions, they often fail to capture\nessential dependencies between past and future actions. To address this, we\nintroduce Past-Token Prediction (PTP), an auxiliary task in which the policy\nlearns to predict past action tokens alongside future ones. This regularization\nsignificantly improves temporal modeling in the policy head, with minimal\nreliance on visual representations. Building on this observation, we further\nintroduce a multistage training strategy: pre-train the visual encoder with\nshort contexts, and fine-tune the policy head using cached long-context\nembeddings. This strategy preserves the benefits of PTP while greatly reducing\nmemory and computational overhead. Finally, we extend PTP into a\nself-verification mechanism at test time, enabling the policy to score and\nselect candidates consistent with past actions during inference. Experiments\nacross four real-world and six simulated tasks demonstrate that our proposed\nmethod improves the performance of long-context diffusion policies by 3x and\naccelerates policy training by more than 10x.",
      "pdf_url": "http://arxiv.org/pdf/2505.09561v1",
      "published": "2025-05-14T17:00:47+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.09561v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "WavReward: Spoken Dialogue Models With Generalist Reward Evaluators",
      "authors": [
        "Shengpeng Ji",
        "Tianle Liang",
        "Yangzhuo Li",
        "Jialong Zuo",
        "Minghui Fang",
        "Jinzheng He",
        "Yifu Chen",
        "Zhengqing Liu",
        "Ziyue Jiang",
        "Xize Cheng",
        "Siqi Zheng",
        "Jin Xu",
        "Junyang Lin",
        "Zhou Zhao"
      ],
      "abstract": "End-to-end spoken dialogue models such as GPT-4o-audio have recently garnered\nsignificant attention in the speech domain. However, the evaluation of spoken\ndialogue models' conversational performance has largely been overlooked. This\nis primarily due to the intelligent chatbots convey a wealth of non-textual\ninformation which cannot be easily measured using text-based language models\nlike ChatGPT. To address this gap, we propose WavReward, a reward feedback\nmodel based on audio language models that can evaluate both the IQ and EQ of\nspoken dialogue systems with speech input. Specifically, 1) based on audio\nlanguage models, WavReward incorporates the deep reasoning process and the\nnonlinear reward mechanism for post-training. By utilizing multi-sample\nfeedback via the reinforcement learning algorithm, we construct a specialized\nevaluator tailored to spoken dialogue models. 2) We introduce ChatReward-30K, a\npreference dataset used to train WavReward. ChatReward-30K includes both\ncomprehension and generation aspects of spoken dialogue models. These scenarios\nspan various tasks, such as text-based chats, nine acoustic attributes of\ninstruction chats, and implicit chats. WavReward outperforms previous\nstate-of-the-art evaluation models across multiple spoken dialogue scenarios,\nachieving a substantial improvement about Qwen2.5-Omni in objective accuracy\nfrom 55.1$\\%$ to 91.5$\\%$. In subjective A/B testing, WavReward also leads by a\nmargin of 83$\\%$. Comprehensive ablation studies confirm the necessity of each\ncomponent of WavReward. All data and code will be publicly at\nhttps://github.com/jishengpeng/WavReward after the paper is accepted.",
      "pdf_url": "http://arxiv.org/pdf/2505.09558v1",
      "published": "2025-05-14T16:54:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.09558v1",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.LG",
        "cs.MM",
        "cs.SD"
      ]
    },
    {
      "title": "\\textsc{rfPG}: Robust Finite-Memory Policy Gradients for Hidden-Model POMDPs",
      "authors": [
        "Maris F. L. Galesloot",
        "Roman Andriushchenko",
        "Milan Češka",
        "Sebastian Junges",
        "Nils Jansen"
      ],
      "abstract": "Partially observable Markov decision processes (POMDPs) model specific\nenvironments in sequential decision-making under uncertainty. Critically,\noptimal policies for POMDPs may not be robust against perturbations in the\nenvironment. Hidden-model POMDPs (HM-POMDPs) capture sets of different\nenvironment models, that is, POMDPs with a shared action and observation space.\nThe intuition is that the true model is hidden among a set of potential models,\nand it is unknown which model will be the environment at execution time. A\npolicy is robust for a given HM-POMDP if it achieves sufficient performance for\neach of its POMDPs. We compute such robust policies by combining two orthogonal\ntechniques: (1) a deductive formal verification technique that supports\ntractable robust policy evaluation by computing a worst-case POMDP within the\nHM-POMDP and (2) subgradient ascent to optimize the candidate policy for a\nworst-case POMDP. The empirical evaluation shows that, compared to various\nbaselines, our approach (1) produces policies that are more robust and\ngeneralize better to unseen POMDPs and (2) scales to HM-POMDPs that consist of\nover a hundred thousand environments.",
      "pdf_url": "http://arxiv.org/pdf/2505.09518v1",
      "published": "2025-05-14T16:15:58+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.09518v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Flash-VL 2B: Optimizing Vision-Language Model Performance for Ultra-Low Latency and High Throughput",
      "authors": [
        "Bo Zhang",
        "Shuo Li",
        "Runhe Tian",
        "Yang Yang",
        "Jixin Tang",
        "Jinhao Zhou",
        "Lin Ma"
      ],
      "abstract": "In this paper, we introduce Flash-VL 2B, a novel approach to optimizing\nVision-Language Models (VLMs) for real-time applications, targeting ultra-low\nlatency and high throughput without sacrificing accuracy. Leveraging advanced\narchitectural enhancements and efficient computational strategies, Flash-VL 2B\nis designed to maximize throughput by reducing processing time while\nmaintaining competitive performance across multiple vision-language benchmarks.\nOur approach includes tailored architectural choices, token compression\nmechanisms, data curation, training schemes, and a novel image processing\ntechnique called implicit semantic stitching that effectively balances\ncomputational load and model performance. Through extensive evaluations on 11\nstandard VLM benchmarks, we demonstrate that Flash-VL 2B achieves\nstate-of-the-art results in both speed and accuracy, making it a promising\nsolution for deployment in resource-constrained environments and large-scale\nreal-time applications.",
      "pdf_url": "http://arxiv.org/pdf/2505.09498v1",
      "published": "2025-05-14T15:45:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.09498v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Preserving Plasticity in Continual Learning with Adaptive Linearity Injection",
      "authors": [
        "Seyed Roozbeh Razavi Rohani",
        "Khashayar Khajavi",
        "Wesley Chung",
        "Mo Chen",
        "Sharan Vaswani"
      ],
      "abstract": "Loss of plasticity in deep neural networks is the gradual reduction in a\nmodel's capacity to incrementally learn and has been identified as a key\nobstacle to learning in non-stationary problem settings. Recent work has shown\nthat deep linear networks tend to be resilient towards loss of plasticity.\nMotivated by this observation, we propose Adaptive Linearization (AdaLin), a\ngeneral approach that dynamically adapts each neuron's activation function to\nmitigate plasticity loss. Unlike prior methods that rely on regularization or\nperiodic resets, AdaLin equips every neuron with a learnable parameter and a\ngating mechanism that injects linearity into the activation function based on\nits gradient flow. This adaptive modulation ensures sufficient gradient signal\nand sustains continual learning without introducing additional hyperparameters\nor requiring explicit task boundaries. When used with conventional activation\nfunctions like ReLU, Tanh, and GeLU, we demonstrate that AdaLin can\nsignificantly improve performance on standard benchmarks, including Random\nLabel and Permuted MNIST, Random Label and Shuffled CIFAR-10, and Class-Split\nCIFAR-100. Furthermore, its efficacy is shown in more complex scenarios, such\nas class-incremental learning on CIFAR-100 with a ResNet-18 backbone, and in\nmitigating plasticity loss in off-policy reinforcement learning agents. We\nperform a systematic set of ablations that show that neuron-level adaptation is\ncrucial for good performance and analyze a number of metrics in the network\nthat might be correlated to loss of plasticity.",
      "pdf_url": "http://arxiv.org/pdf/2505.09486v1",
      "published": "2025-05-14T15:36:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.09486v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Deploying Foundation Model-Enabled Air and Ground Robots in the Field: Challenges and Opportunities",
      "authors": [
        "Zachary Ravichandran",
        "Fernando Cladera",
        "Jason Hughes",
        "Varun Murali",
        "M. Ani Hsieh",
        "George J. Pappas",
        "Camillo J. Taylor",
        "Vijay Kumar"
      ],
      "abstract": "The integration of foundation models (FMs) into robotics has enabled robots\nto understand natural language and reason about the semantics in their\nenvironments. However, existing FM-enabled robots primary operate in\nclosed-world settings, where the robot is given a full prior map or has a full\nview of its workspace. This paper addresses the deployment of FM-enabled robots\nin the field, where missions often require a robot to operate in large-scale\nand unstructured environments. To effectively accomplish these missions, robots\nmust actively explore their environments, navigate obstacle-cluttered terrain,\nhandle unexpected sensor inputs, and operate with compute constraints. We\ndiscuss recent deployments of SPINE, our LLM-enabled autonomy framework, in\nfield robotic settings. To the best of our knowledge, we present the first\ndemonstration of large-scale LLM-enabled robot planning in unstructured\nenvironments with several kilometers of missions. SPINE is agnostic to a\nparticular LLM, which allows us to distill small language models capable of\nrunning onboard size, weight and power (SWaP) limited platforms. Via\npreliminary model distillation work, we then present the first language-driven\nUAV planner using on-device language models. We conclude our paper by proposing\nseveral promising directions for future research.",
      "pdf_url": "http://arxiv.org/pdf/2505.09477v1",
      "published": "2025-05-14T15:28:43+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.09477v1",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "A 2D Semantic-Aware Position Encoding for Vision Transformers",
      "authors": [
        "Xi Chen",
        "Shiyang Zhou",
        "Muqi Huang",
        "Jiaxu Feng",
        "Yun Xiong",
        "Kun Zhou",
        "Biao Yang",
        "Yuhui Zhang",
        "Huishuai Bao",
        "Sijia Peng",
        "Chuan Li",
        "Feng Shi"
      ],
      "abstract": "Vision transformers have demonstrated significant advantages in computer\nvision tasks due to their ability to capture long-range dependencies and\ncontextual relationships through self-attention. However, existing position\nencoding techniques, which are largely borrowed from natural language\nprocessing, fail to effectively capture semantic-aware positional relationships\nbetween image patches. Traditional approaches like absolute position encoding\nand relative position encoding primarily focus on 1D linear position\nrelationship, often neglecting the semantic similarity between distant yet\ncontextually related patches. These limitations hinder model generalization,\ntranslation equivariance, and the ability to effectively handle repetitive or\nstructured patterns in images. In this paper, we propose 2-Dimensional\nSemantic-Aware Position Encoding ($\\text{SaPE}^2$), a novel position encoding\nmethod with semantic awareness that dynamically adapts position representations\nby leveraging local content instead of fixed linear position relationship or\nspatial coordinates. Our method enhances the model's ability to generalize\nacross varying image resolutions and scales, improves translation equivariance,\nand better aggregates features for visually similar but spatially distant\npatches. By integrating $\\text{SaPE}^2$ into vision transformers, we bridge the\ngap between position encoding and perceptual similarity, thereby improving\nperformance on computer vision tasks.",
      "pdf_url": "http://arxiv.org/pdf/2505.09466v1",
      "published": "2025-05-14T15:17:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.09466v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Quantum state-agnostic work extraction (almost) without dissipation",
      "authors": [
        "Josep Lumbreras",
        "Ruo Cheng Huang",
        "Yanglin Hu",
        "Mile Gu",
        "Marco Tomamichel"
      ],
      "abstract": "We investigate work extraction protocols designed to transfer the maximum\npossible energy to a battery using sequential access to $N$ copies of an\nunknown pure qubit state. The core challenge is designing interactions to\noptimally balance two competing goals: charging of the battery optimally using\nthe qubit in hand, and acquiring more information by qubit to improve energy\nharvesting in subsequent rounds. Here, we leverage exploration-exploitation\ntrade-off in reinforcement learning to develop adaptive strategies achieving\nenergy dissipation that scales only poly-logarithmically in $N$. This\nrepresents an exponential improvement over current protocols based on full\nstate tomography.",
      "pdf_url": "http://arxiv.org/pdf/2505.09456v1",
      "published": "2025-05-14T15:07:58+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.09456v1",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Evaluating GPT- and Reasoning-based Large Language Models on Physics Olympiad Problems: Surpassing Human Performance and Implications for Educational Assessment",
      "authors": [
        "Paul Tschisgale",
        "Holger Maus",
        "Fabian Kieser",
        "Ben Kroehs",
        "Stefan Petersen",
        "Peter Wulff"
      ],
      "abstract": "Large language models (LLMs) are now widely accessible, reaching learners at\nall educational levels. This development has raised concerns that their use may\ncircumvent essential learning processes and compromise the integrity of\nestablished assessment formats. In physics education, where problem solving\nplays a central role in instruction and assessment, it is therefore essential\nto understand the physics-specific problem-solving capabilities of LLMs. Such\nunderstanding is key to informing responsible and pedagogically sound\napproaches to integrating LLMs into instruction and assessment. This study\ntherefore compares the problem-solving performance of a general-purpose LLM\n(GPT-4o, using varying prompting techniques) and a reasoning-optimized model\n(o1-preview) with that of participants of the German Physics Olympiad, based on\na set of well-defined Olympiad problems. In addition to evaluating the\ncorrectness of the generated solutions, the study analyzes characteristic\nstrengths and limitations of LLM-generated solutions. The findings of this\nstudy indicate that both tested LLMs (GPT-4o and o1-preview) demonstrate\nadvanced problem-solving capabilities on Olympiad-type physics problems, on\naverage outperforming the human participants. Prompting techniques had little\neffect on GPT-4o's performance, while o1-preview almost consistently\noutperformed both GPT-4o and the human benchmark. Based on these findings, the\nstudy discusses implications for the design of summative and formative\nassessment in physics education, including how to uphold assessment integrity\nand support students in critically engaging with LLMs.",
      "pdf_url": "http://arxiv.org/pdf/2505.09438v1",
      "published": "2025-05-14T14:46:32+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.09438v1",
      "categories": [
        "physics.ed-ph",
        "cs.AI"
      ]
    },
    {
      "title": "CXMArena: Unified Dataset to benchmark performance in realistic CXM Scenarios",
      "authors": [
        "Raghav Garg",
        "Kapil Sharma",
        "Karan Gupta"
      ],
      "abstract": "Large Language Models (LLMs) hold immense potential for revolutionizing\nCustomer Experience Management (CXM), particularly in contact center\noperations. However, evaluating their practical utility in complex operational\nenvironments is hindered by data scarcity (due to privacy concerns) and the\nlimitations of current benchmarks. Existing benchmarks often lack realism,\nfailing to incorporate deep knowledge base (KB) integration, real-world noise,\nor critical operational tasks beyond conversational fluency. To bridge this\ngap, we introduce CXMArena, a novel, large-scale synthetic benchmark dataset\nspecifically designed for evaluating AI in operational CXM contexts. Given the\ndiversity in possible contact center features, we have developed a scalable\nLLM-powered pipeline that simulates the brand's CXM entities that form the\nfoundation of our datasets-such as knowledge articles including product\nspecifications, issue taxonomies, and contact center conversations. The\nentities closely represent real-world distribution because of controlled noise\ninjection (informed by domain experts) and rigorous automated validation.\nBuilding on this, we release CXMArena, which provides dedicated benchmarks\ntargeting five important operational tasks: Knowledge Base Refinement, Intent\nPrediction, Agent Quality Adherence, Article Search, and Multi-turn RAG with\nIntegrated Tools. Our baseline experiments underscore the benchmark's\ndifficulty: even state of the art embedding and generation models achieve only\n68% accuracy on article search, while standard embedding methods yield a low F1\nscore of 0.3 for knowledge base refinement, highlighting significant challenges\nfor current models necessitating complex pipelines and solutions over\nconventional techniques.",
      "pdf_url": "http://arxiv.org/pdf/2505.09436v1",
      "published": "2025-05-14T14:44:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.09436v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ]
    },
    {
      "title": "Endo-CLIP: Progressive Self-Supervised Pre-training on Raw Colonoscopy Records",
      "authors": [
        "Yili He",
        "Yan Zhu",
        "Peiyao Fu",
        "Ruijie Yang",
        "Tianyi Chen",
        "Zhihua Wang",
        "Quanlin Li",
        "Pinghong Zhou",
        "Xian Yang",
        "Shuo Wang"
      ],
      "abstract": "Pre-training on image-text colonoscopy records offers substantial potential\nfor improving endoscopic image analysis, but faces challenges including\nnon-informative background images, complex medical terminology, and ambiguous\nmulti-lesion descriptions. We introduce Endo-CLIP, a novel self-supervised\nframework that enhances Contrastive Language-Image Pre-training (CLIP) for this\ndomain. Endo-CLIP's three-stage framework--cleansing, attunement, and\nunification--addresses these challenges by (1) removing background frames, (2)\nleveraging large language models to extract clinical attributes for\nfine-grained contrastive learning, and (3) employing patient-level\ncross-attention to resolve multi-polyp ambiguities. Extensive experiments\ndemonstrate that Endo-CLIP significantly outperforms state-of-the-art\npre-training methods in zero-shot and few-shot polyp detection and\nclassification, paving the way for more accurate and clinically relevant\nendoscopic analysis.",
      "pdf_url": "http://arxiv.org/pdf/2505.09435v1",
      "published": "2025-05-14T14:43:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.09435v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Counterfactual Strategies for Markov Decision Processes",
      "authors": [
        "Paul Kobialka",
        "Lina Gerlach",
        "Francesco Leofante",
        "Erika Ábrahám",
        "Silvia Lizeth Tapia Tarifa",
        "Einar Broch Johnsen"
      ],
      "abstract": "Counterfactuals are widely used in AI to explain how minimal changes to a\nmodel's input can lead to a different output. However, established methods for\ncomputing counterfactuals typically focus on one-step decision-making, and are\nnot directly applicable to sequential decision-making tasks. This paper fills\nthis gap by introducing counterfactual strategies for Markov Decision Processes\n(MDPs). During MDP execution, a strategy decides which of the enabled actions\n(with known probabilistic effects) to execute next. Given an initial strategy\nthat reaches an undesired outcome with a probability above some limit, we\nidentify minimal changes to the initial strategy to reduce that probability\nbelow the limit. We encode such counterfactual strategies as solutions to\nnon-linear optimization problems, and further extend our encoding to synthesize\ndiverse counterfactual strategies. We evaluate our approach on four real-world\ndatasets and demonstrate its practical viability in sophisticated sequential\ndecision-making tasks.",
      "pdf_url": "http://arxiv.org/pdf/2505.09412v1",
      "published": "2025-05-14T14:07:27+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.09412v1",
      "categories": [
        "cs.AI",
        "I.2.m"
      ]
    },
    {
      "title": "Multilingual Machine Translation with Quantum Encoder Decoder Attention-based Convolutional Variational Circuits",
      "authors": [
        "Subrit Dikshit",
        "Ritu Tiwari",
        "Priyank Jain"
      ],
      "abstract": "Cloud-based multilingual translation services like Google Translate and\nMicrosoft Translator achieve state-of-the-art translation capabilities. These\nservices inherently use large multilingual language models such as GRU, LSTM,\nBERT, GPT, T5, or similar encoder-decoder architectures with attention\nmechanisms as the backbone. Also, new age natural language systems, for\ninstance ChatGPT and DeepSeek, have established huge potential in multiple\ntasks in natural language processing. At the same time, they also possess\noutstanding multilingual translation capabilities. However, these models use\nthe classical computing realm as a backend. QEDACVC (Quantum Encoder Decoder\nAttention-based Convolutional Variational Circuits) is an alternate solution\nthat explores the quantum computing realm instead of the classical computing\nrealm to study and demonstrate multilingual machine translation. QEDACVC\nintroduces the quantum encoder-decoder architecture that simulates and runs on\nquantum computing hardware via quantum convolution, quantum pooling, quantum\nvariational circuit, and quantum attention as software alterations. QEDACVC\nachieves an Accuracy of 82% when trained on the OPUS dataset for English,\nFrench, German, and Hindi corpora for multilingual translations.",
      "pdf_url": "http://arxiv.org/pdf/2505.09407v1",
      "published": "2025-05-14T14:04:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.09407v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.ET"
      ]
    },
    {
      "title": "The Influence of Human-inspired Agentic Sophistication in LLM-driven Strategic Reasoners",
      "authors": [
        "Vince Trencsenyi",
        "Agnieszka Mensfelt",
        "Kostas Stathis"
      ],
      "abstract": "The rapid rise of large language models (LLMs) has shifted artificial\nintelligence (AI) research toward agentic systems, motivating the use of weaker\nand more flexible notions of agency. However, this shift raises key questions\nabout the extent to which LLM-based agents replicate human strategic reasoning,\nparticularly in game-theoretic settings. In this context, we examine the role\nof agentic sophistication in shaping artificial reasoners' performance by\nevaluating three agent designs: a simple game-theoretic model, an unstructured\nLLM-as-agent model, and an LLM integrated into a traditional agentic framework.\nUsing guessing games as a testbed, we benchmarked these agents against human\nparticipants across general reasoning patterns and individual role-based\nobjectives. Furthermore, we introduced obfuscated game scenarios to assess\nagents' ability to generalise beyond training distributions. Our analysis,\ncovering over 2000 reasoning samples across 25 agent configurations, shows that\nhuman-inspired cognitive structures can enhance LLM agents' alignment with\nhuman strategic behaviour. Still, the relationship between agentic design\ncomplexity and human-likeness is non-linear, highlighting a critical dependence\non underlying LLM capabilities and suggesting limits to simple architectural\naugmentation.",
      "pdf_url": "http://arxiv.org/pdf/2505.09396v1",
      "published": "2025-05-14T13:51:24+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.09396v1",
      "categories": [
        "cs.AI",
        "cs.MA"
      ]
    },
    {
      "title": "Quantum-Enhanced Parameter-Efficient Learning for Typhoon Trajectory Forecasting",
      "authors": [
        "Chen-Yu Liu",
        "Kuan-Cheng Chen",
        "Yi-Chien Chen",
        "Samuel Yen-Chi Chen",
        "Wei-Hao Huang",
        "Wei-Jia Huang",
        "Yen-Jui Chang"
      ],
      "abstract": "Typhoon trajectory forecasting is essential for disaster preparedness but\nremains computationally demanding due to the complexity of atmospheric dynamics\nand the resource requirements of deep learning models. Quantum-Train (QT), a\nhybrid quantum-classical framework that leverages quantum neural networks\n(QNNs) to generate trainable parameters exclusively during training,\neliminating the need for quantum hardware at inference time. Building on QT's\nsuccess across multiple domains, including image classification, reinforcement\nlearning, flood prediction, and large language model (LLM) fine-tuning, we\nintroduce Quantum Parameter Adaptation (QPA) for efficient typhoon forecasting\nmodel learning. Integrated with an Attention-based Multi-ConvGRU model, QPA\nenables parameter-efficient training while maintaining predictive accuracy.\nThis work represents the first application of quantum machine learning (QML) to\nlarge-scale typhoon trajectory prediction, offering a scalable and\nenergy-efficient approach to climate modeling. Our results demonstrate that QPA\nsignificantly reduces the number of trainable parameters while preserving\nperformance, making high-performance forecasting more accessible and\nsustainable through hybrid quantum-classical learning.",
      "pdf_url": "http://arxiv.org/pdf/2505.09395v1",
      "published": "2025-05-14T13:50:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.09395v1",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "UMotion: Uncertainty-driven Human Motion Estimation from Inertial and Ultra-wideband Units",
      "authors": [
        "Huakun Liu",
        "Hiroki Ota",
        "Xin Wei",
        "Yutaro Hirao",
        "Monica Perusquia-Hernandez",
        "Hideaki Uchiyama",
        "Kiyoshi Kiyokawa"
      ],
      "abstract": "Sparse wearable inertial measurement units (IMUs) have gained popularity for\nestimating 3D human motion. However, challenges such as pose ambiguity, data\ndrift, and limited adaptability to diverse bodies persist. To address these\nissues, we propose UMotion, an uncertainty-driven, online fusing-all state\nestimation framework for 3D human shape and pose estimation, supported by six\nintegrated, body-worn ultra-wideband (UWB) distance sensors with IMUs. UWB\nsensors measure inter-node distances to infer spatial relationships, aiding in\nresolving pose ambiguities and body shape variations when combined with\nanthropometric data. Unfortunately, IMUs are prone to drift, and UWB sensors\nare affected by body occlusions. Consequently, we develop a tightly coupled\nUnscented Kalman Filter (UKF) framework that fuses uncertainties from sensor\ndata and estimated human motion based on individual body shape. The UKF\niteratively refines IMU and UWB measurements by aligning them with uncertain\nhuman motion constraints in real-time, producing optimal estimates for each.\nExperiments on both synthetic and real-world datasets demonstrate the\neffectiveness of UMotion in stabilizing sensor data and the improvement over\nstate of the art in pose accuracy.",
      "pdf_url": "http://arxiv.org/pdf/2505.09393v1",
      "published": "2025-05-14T13:48:36+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.09393v1",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "FedSaaS: Class-Consistency Federated Semantic Segmentation via Global Prototype Supervision and Local Adversarial Harmonization",
      "authors": [
        "Xiaoyang Yu",
        "Xiaoming Wu",
        "Xin Wang",
        "Dongrun Li",
        "Ming Yang",
        "Peng Cheng"
      ],
      "abstract": "Federated semantic segmentation enables pixel-level classification in images\nthrough collaborative learning while maintaining data privacy. However,\nexisting research commonly overlooks the fine-grained class relationships\nwithin the semantic space when addressing heterogeneous problems, particularly\ndomain shift. This oversight results in ambiguities between class\nrepresentation. To overcome this challenge, we propose a novel federated\nsegmentation framework that strikes class consistency, termed FedSaaS.\nSpecifically, we introduce class exemplars as a criterion for both local- and\nglobal-level class representations. On the server side, the uploaded class\nexemplars are leveraged to model class prototypes, which supervise global\nbranch of clients, ensuring alignment with global-level representation. On the\nclient side, we incorporate an adversarial mechanism to harmonize contributions\nof global and local branches, leading to consistent output. Moreover,\nmultilevel contrastive losses are employed on both sides to enforce consistency\nbetween two-level representations in the same semantic space. Extensive\nexperiments on several driving scene segmentation datasets demonstrate that our\nframework outperforms state-of-the-art methods, significantly improving average\nsegmentation accuracy and effectively addressing the class-consistency\nrepresentation problem.",
      "pdf_url": "http://arxiv.org/pdf/2505.09385v1",
      "published": "2025-05-14T13:38:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.09385v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "The Voice Timbre Attribute Detection 2025 Challenge Evaluation Plan",
      "authors": [
        "Zhengyan Sheng",
        "Jinghao He",
        "Liping Chen",
        "Kong Aik Lee",
        "Zhen-Hua Ling"
      ],
      "abstract": "Voice timbre refers to the unique quality or character of a person's voice\nthat distinguishes it from others as perceived by human hearing. The Voice\nTimbre Attribute Detection (VtaD) 2025 challenge focuses on explaining the\nvoice timbre attribute in a comparative manner. In this challenge, the human\nimpression of voice timbre is verbalized with a set of sensory descriptors,\nincluding bright, coarse, soft, magnetic, and so on. The timbre is explained\nfrom the comparison between two voices in their intensity within a specific\ndescriptor dimension. The VtaD 2025 challenge starts in May and culminates in a\nspecial proposal at the NCMMSC2025 conference in October 2025 in Zhenjiang,\nChina.",
      "pdf_url": "http://arxiv.org/pdf/2505.09382v1",
      "published": "2025-05-14T13:35:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.09382v1",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ]
    },
    {
      "title": "Examining Deployment and Refinement of the VIOLA-AI Intracranial Hemorrhage Model Using an Interactive NeoMedSys Platform",
      "authors": [
        "Qinghui Liu",
        "Jon Nesvold",
        "Hanna Raaum",
        "Elakkyen Murugesu",
        "Martin Røvang",
        "Bradley J Maclntosh",
        "Atle Bjørnerud",
        "Karoline Skogen"
      ],
      "abstract": "Background: There are many challenges and opportunities in the clinical\ndeployment of AI tools in radiology. The current study describes a radiology\nsoftware platform called NeoMedSys that can enable efficient deployment and\nrefinements of AI models. We evaluated the feasibility and effectiveness of\nrunning NeoMedSys for three months in real-world clinical settings and focused\non improvement performance of an in-house developed AI model (VIOLA-AI)\ndesigned for intracranial hemorrhage (ICH) detection.\n  Methods: NeoMedSys integrates tools for deploying, testing, and optimizing AI\nmodels with a web-based medical image viewer, annotation system, and\nhospital-wide radiology information systems. A pragmatic investigation was\ndeployed using clinical cases of patients presenting to the largest Emergency\nDepartment in Norway (site-1) with suspected traumatic brain injury (TBI) or\npatients with suspected stroke (site-2). We assessed ICH classification\nperformance as VIOLA-AI encountered new data and underwent pre-planned model\nretraining. Performance metrics included sensitivity, specificity, accuracy,\nand the area under the receiver operating characteristic curve (AUC).\n  Results: NeoMedSys facilitated iterative improvements in the AI model,\nsignificantly enhancing its diagnostic accuracy. Automated bleed detection and\nsegmentation were reviewed in near real-time to facilitate re-training\nVIOLA-AI. The iterative refinement process yielded a marked improvement in\nclassification sensitivity, rising to 90.3% (from 79.2%), and specificity that\nreached 89.3% (from 80.7%). The bleed detection ROC analysis for the entire\nsample demonstrated a high area-under-the-curve (AUC) of 0.949 (from 0.873).\nModel refinement stages were associated with notable gains, highlighting the\nvalue of real-time radiologist feedback.",
      "pdf_url": "http://arxiv.org/pdf/2505.09380v1",
      "published": "2025-05-14T13:33:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.09380v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "TensorRL-QAS: Reinforcement learning with tensor networks for scalable quantum architecture search",
      "authors": [
        "Akash Kundu",
        "Stefano Mangini"
      ],
      "abstract": "Variational quantum algorithms hold the promise to address meaningful quantum\nproblems already on noisy intermediate-scale quantum hardware, but they face\nthe challenge of designing quantum circuits that both solve the target problem\nand comply with device limitations. Quantum architecture search (QAS) automates\nthis design process, with reinforcement learning (RL) emerging as a promising\napproach. Yet, RL-based QAS methods encounter significant scalability issues,\nas computational and training costs grow rapidly with the number of qubits,\ncircuit depth, and noise, severely impacting performance. To address these\nchallenges, we introduce $\\textit{TensorRL-QAS}$, a scalable framework that\ncombines tensor network (TN) methods with RL for designing quantum circuits. By\nwarm-starting the architecture search with a matrix product state approximation\nof the target solution, TensorRL-QAS effectively narrows the search space to\nphysically meaningful circuits, accelerating convergence to the desired\nsolution. Tested on several quantum chemistry problems of up to 12-qubit,\nTensorRL-QAS achieves up to a 10-fold reduction in CNOT count and circuit depth\ncompared to baseline methods, while maintaining or surpassing chemical\naccuracy. It reduces function evaluations by up to 100-fold, accelerates\ntraining episodes by up to $98\\%$, and achieves up to $50\\%$ success\nprobability for 10-qubit systems-far exceeding the $<1\\%$ rates of baseline\napproaches. Robustness and versatility are demonstrated both in the noiseless\nand noisy scenarios, where we report a simulation of up to 8-qubit. These\nadvancements establish TensorRL-QAS as a promising candidate for a scalable and\nefficient quantum circuit discovery protocol on near-term quantum hardware.",
      "pdf_url": "http://arxiv.org/pdf/2505.09371v1",
      "published": "2025-05-14T13:23:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.09371v1",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.ET",
        "cs.LG"
      ]
    },
    {
      "title": "GreenFactory: Ensembling Zero-Cost Proxies to Estimate Performance of Neural Networks",
      "authors": [
        "Gabriel Cortês",
        "Nuno Lourenço",
        "Paolo Romano",
        "Penousal Machado"
      ],
      "abstract": "Determining the performance of a Deep Neural Network during Neural\nArchitecture Search processes is essential for identifying optimal\narchitectures and hyperparameters. Traditionally, this process requires\ntraining and evaluation of each network, which is time-consuming and\nresource-intensive. Zero-cost proxies estimate performance without training,\nserving as an alternative to traditional training. However, recent proxies\noften lack generalization across diverse scenarios and provide only relative\nrankings rather than predicted accuracies. To address these limitations, we\npropose GreenFactory, an ensemble of zero-cost proxies that leverages a random\nforest regressor to combine multiple predictors' strengths and directly predict\nmodel test accuracy. We evaluate GreenFactory on NATS-Bench, achieving robust\nresults across multiple datasets. Specifically, GreenFactory achieves high\nKendall correlations on NATS-Bench-SSS, indicating substantial agreement\nbetween its predicted scores and actual performance: 0.907 for CIFAR-10, 0.945\nfor CIFAR-100, and 0.920 for ImageNet-16-120. Similarly, on NATS-Bench-TSS, we\nachieve correlations of 0.921 for CIFAR-10, 0.929 for CIFAR-100, and 0.908 for\nImageNet-16-120, showcasing its reliability in both search spaces.",
      "pdf_url": "http://arxiv.org/pdf/2505.09344v1",
      "published": "2025-05-14T12:40:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.09344v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Insights into DeepSeek-V3: Scaling Challenges and Reflections on Hardware for AI Architectures",
      "authors": [
        "Chenggang Zhao",
        "Chengqi Deng",
        "Chong Ruan",
        "Damai Dai",
        "Huazuo Gao",
        "Jiashi Li",
        "Liyue Zhang",
        "Panpan Huang",
        "Shangyan Zhou",
        "Shirong Ma",
        "Wenfeng Liang",
        "Ying He",
        "Yuqing Wang",
        "Yuxuan Liu",
        "Y. X. Wei"
      ],
      "abstract": "The rapid scaling of large language models (LLMs) has unveiled critical\nlimitations in current hardware architectures, including constraints in memory\ncapacity, computational efficiency, and interconnection bandwidth. DeepSeek-V3,\ntrained on 2,048 NVIDIA H800 GPUs, demonstrates how hardware-aware model\nco-design can effectively address these challenges, enabling cost-efficient\ntraining and inference at scale. This paper presents an in-depth analysis of\nthe DeepSeek-V3/R1 model architecture and its AI infrastructure, highlighting\nkey innovations such as Multi-head Latent Attention (MLA) for enhanced memory\nefficiency, Mixture of Experts (MoE) architectures for optimized\ncomputation-communication trade-offs, FP8 mixed-precision training to unlock\nthe full potential of hardware capabilities, and a Multi-Plane Network Topology\nto minimize cluster-level network overhead. Building on the hardware\nbottlenecks encountered during DeepSeek-V3's development, we engage in a\nbroader discussion with academic and industry peers on potential future\nhardware directions, including precise low-precision computation units,\nscale-up and scale-out convergence, and innovations in low-latency\ncommunication fabrics. These insights underscore the critical role of hardware\nand model co-design in meeting the escalating demands of AI workloads, offering\na practical blueprint for innovation in next-generation AI systems.",
      "pdf_url": "http://arxiv.org/pdf/2505.09343v1",
      "published": "2025-05-14T12:39:03+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.09343v1",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.AR"
      ]
    },
    {
      "title": "Evaluating the Robustness of Adversarial Defenses in Malware Detection Systems",
      "authors": [
        "Mostafa Jafari",
        "Alireza Shameli-Sendi"
      ],
      "abstract": "Machine learning is a key tool for Android malware detection, effectively\nidentifying malicious patterns in apps. However, ML-based detectors are\nvulnerable to evasion attacks, where small, crafted changes bypass detection.\nDespite progress in adversarial defenses, the lack of comprehensive evaluation\nframeworks in binary-constrained domains limits understanding of their\nrobustness. We introduce two key contributions. First, Prioritized Binary\nRounding, a technique to convert continuous perturbations into binary feature\nspaces while preserving high attack success and low perturbation size. Second,\nthe sigma-binary attack, a novel adversarial method for binary domains,\ndesigned to achieve attack goals with minimal feature changes. Experiments on\nthe Malscan dataset show that sigma-binary outperforms existing attacks and\nexposes key vulnerabilities in state-of-the-art defenses. Defenses equipped\nwith adversary detectors, such as KDE, DLA, DNN+, and ICNN, exhibit significant\nbrittleness, with attack success rates exceeding 90% using fewer than 10\nfeature modifications and reaching 100% with just 20. Adversarially trained\ndefenses, including AT-rFGSM-k, AT-MaxMA, improves robustness under small\nbudgets but remains vulnerable to unrestricted perturbations, with attack\nsuccess rates of 99.45% and 96.62%, respectively. Although PAD-SMA demonstrates\nstrong robustness against state-of-the-art gradient-based adversarial attacks\nby maintaining an attack success rate below 16.55%, the sigma-binary attack\nsignificantly outperforms these methods, achieving a 94.56% success rate under\nunrestricted perturbations. These findings highlight the critical need for\nprecise method like sigma-binary to expose hidden vulnerabilities in existing\ndefenses and support the development of more resilient malware detection\nsystems.",
      "pdf_url": "http://arxiv.org/pdf/2505.09342v1",
      "published": "2025-05-14T12:38:43+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.09342v1",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG",
        "68",
        "I.2.1"
      ]
    },
    {
      "title": "Access Controls Will Solve the Dual-Use Dilemma",
      "authors": [
        "Evžen Wybitul"
      ],
      "abstract": "AI safety systems face a dual-use dilemma. Since the same request can be\neither harmless or harmful depending on who made it and why, if the system\nmakes decisions based solely on the request's content, it will refuse some\nlegitimate queries and let pass harmful ones. To address this, we propose a\nconceptual access control framework, based on verified user credentials (such\nas institutional affiliation) and classifiers that assign model outputs to risk\ncategories (such as advanced virology). The system permits responses only when\nthe user's verified credentials match the category's requirements. For\nimplementation of the model output classifiers, we introduce a theoretical\napproach utilizing small, gated expert modules integrated into the generator\nmodel, trained with gradient routing, that enable efficient risk detection\nwithout the capability gap problems of external monitors. While open questions\nremain about the verification mechanisms, risk categories, and the technical\nimplementation, our framework makes the first step toward enabling granular\ngovernance of AI capabilities: verified users gain access to specialized\nknowledge without arbitrary restrictions, while adversaries are blocked from\nit. This contextual approach reconciles model utility with robust safety,\naddressing the dual-use dilemma.",
      "pdf_url": "http://arxiv.org/pdf/2505.09341v1",
      "published": "2025-05-14T12:38:08+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.09341v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "BioVFM-21M: Benchmarking and Scaling Self-Supervised Vision Foundation Models for Biomedical Image Analysis",
      "authors": [
        "Jiarun Liu",
        "Hong-Yu Zhou",
        "Weijian Huang",
        "Hao Yang",
        "Dongning Song",
        "Tao Tan",
        "Yong Liang",
        "Shanshan Wang"
      ],
      "abstract": "Scaling up model and data size have demonstrated impressive performance\nimprovement over a wide range of tasks. Despite extensive studies on scaling\nbehaviors for general-purpose tasks, medical images exhibit substantial\ndifferences from natural data. It remains unclear the key factors in developing\nmedical vision foundation models at scale due to the absence of an extensive\nunderstanding of scaling behavior in the medical domain. In this paper, we\nexplored the scaling behavior across model sizes, training algorithms, data\nsizes, and imaging modalities in developing scalable medical vision foundation\nmodels by self-supervised learning. To support scalable pretraining, we\nintroduce BioVFM-21M, a large-scale biomedical image dataset encompassing a\nwide range of biomedical image modalities and anatomies. We observed that\nscaling up does provide benefits but varies across tasks. Additional analysis\nreveals several factors correlated with scaling benefits. Finally, we propose\nBioVFM, a large-scale medical vision foundation model pretrained on 21 million\nbiomedical images, which outperforms the previous state-of-the-art foundation\nmodels across 12 medical benchmarks. Our results highlight that while scaling\nup is beneficial for pursuing better performance, task characteristics, data\ndiversity, pretraining methods, and computational efficiency remain critical\nconsiderations for developing scalable medical foundation models.",
      "pdf_url": "http://arxiv.org/pdf/2505.09329v1",
      "published": "2025-05-14T12:25:41+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.09329v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Neural Video Compression using 2D Gaussian Splatting",
      "authors": [
        "Lakshya Gupta",
        "Imran N. Junejo"
      ],
      "abstract": "The computer vision and image processing research community has been involved\nin standardizing video data communications for the past many decades, leading\nto standards such as AVC, HEVC, VVC, AV1, AV2, etc. However, recent\ngroundbreaking works have focused on employing deep learning-based techniques\nto replace the traditional video codec pipeline to a greater affect. Neural\nvideo codecs (NVC) create an end-to-end ML-based solution that does not rely on\nany handcrafted features (motion or edge-based) and have the ability to learn\ncontent-aware compression strategies, offering better adaptability and higher\ncompression efficiency than traditional methods. This holds a great potential\nnot only for hardware design, but also for various video streaming platforms\nand applications, especially video conferencing applications such as MS-Teams\nor Zoom that have found extensive usage in classrooms and workplaces. However,\ntheir high computational demands currently limit their use in real-time\napplications like video conferencing. To address this, we propose a\nregion-of-interest (ROI) based neural video compression model that leverages 2D\nGaussian Splatting. Unlike traditional codecs, 2D Gaussian Splatting is capable\nof real-time decoding and can be optimized using fewer data points, requiring\nonly thousands of Gaussians for decent quality outputs as opposed to millions\nin 3D scenes. In this work, we designed a video pipeline that speeds up the\nencoding time of the previous Gaussian splatting-based image codec by 88% by\nusing a content-aware initialization strategy paired with a novel Gaussian\ninter-frame redundancy-reduction mechanism, enabling Gaussian splatting to be\nused for a video-codec solution, the first of its kind solution in this neural\nvideo codec space.",
      "pdf_url": "http://arxiv.org/pdf/2505.09324v1",
      "published": "2025-05-14T12:23:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.09324v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "eess.IV"
      ]
    },
    {
      "title": "Toward Fair Federated Learning under Demographic Disparities and Data Imbalance",
      "authors": [
        "Qiming Wu",
        "Siqi Li",
        "Doudou Zhou",
        "Nan Liu"
      ],
      "abstract": "Ensuring fairness is critical when applying artificial intelligence to\nhigh-stakes domains such as healthcare, where predictive models trained on\nimbalanced and demographically skewed data risk exacerbating existing\ndisparities. Federated learning (FL) enables privacy-preserving collaboration\nacross institutions, but remains vulnerable to both algorithmic bias and\nsubgroup imbalance - particularly when multiple sensitive attributes intersect.\nWe propose FedIDA (Fed erated Learning for Imbalance and D isparity A\nwareness), a framework-agnostic method that combines fairness-aware\nregularization with group-conditional oversampling. FedIDA supports multiple\nsensitive attributes and heterogeneous data distributions without altering the\nconvergence behavior of the underlying FL algorithm. We provide theoretical\nanalysis establishing fairness improvement bounds using Lipschitz continuity\nand concentration inequalities, and show that FedIDA reduces the variance of\nfairness metrics across test sets. Empirical results on both benchmark and\nreal-world clinical datasets confirm that FedIDA consistently improves fairness\nwhile maintaining competitive predictive performance, demonstrating its\neffectiveness for equitable and privacy-preserving modeling in healthcare. The\nsource code is available on GitHub.",
      "pdf_url": "http://arxiv.org/pdf/2505.09295v1",
      "published": "2025-05-14T11:22:54+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.09295v1",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Reproducibility Study of \"Cooperate or Collapse: Emergence of Sustainable Cooperation in a Society of LLM Agents\"",
      "authors": [
        "Pedro M. P. Curvo",
        "Mara Dragomir",
        "Salvador Torpes",
        "Mohammadmahdi Rahimi"
      ],
      "abstract": "This study evaluates and extends the findings made by Piatti et al., who\nintroduced GovSim, a simulation framework designed to assess the cooperative\ndecision-making capabilities of large language models (LLMs) in\nresource-sharing scenarios. By replicating key experiments, we validate claims\nregarding the performance of large models, such as GPT-4-turbo, compared to\nsmaller models. The impact of the universalization principle is also examined,\nwith results showing that large models can achieve sustainable cooperation,\nwith or without the principle, while smaller models fail without it. In\naddition, we provide multiple extensions to explore the applicability of the\nframework to new settings. We evaluate additional models, such as DeepSeek-V3\nand GPT-4o-mini, to test whether cooperative behavior generalizes across\ndifferent architectures and model sizes. Furthermore, we introduce new\nsettings: we create a heterogeneous multi-agent environment, study a scenario\nusing Japanese instructions, and explore an \"inverse environment\" where agents\nmust cooperate to mitigate harmful resource distributions. Our results confirm\nthat the benchmark can be applied to new models, scenarios, and languages,\noffering valuable insights into the adaptability of LLMs in complex cooperative\ntasks. Moreover, the experiment involving heterogeneous multi-agent systems\ndemonstrates that high-performing models can influence lower-performing ones to\nadopt similar behaviors. This finding has significant implications for other\nagent-based applications, potentially enabling more efficient use of\ncomputational resources and contributing to the development of more effective\ncooperative AI systems.",
      "pdf_url": "http://arxiv.org/pdf/2505.09289v1",
      "published": "2025-05-14T11:15:14+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.09289v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "MetaUAS: Universal Anomaly Segmentation with One-Prompt Meta-Learning",
      "authors": [
        "Bin-Bin Gao"
      ],
      "abstract": "Zero- and few-shot visual anomaly segmentation relies on powerful\nvision-language models that detect unseen anomalies using manually designed\ntextual prompts. However, visual representations are inherently independent of\nlanguage. In this paper, we explore the potential of a pure visual foundation\nmodel as an alternative to widely used vision-language models for universal\nvisual anomaly segmentation. We present a novel paradigm that unifies anomaly\nsegmentation into change segmentation. This paradigm enables us to leverage\nlarge-scale synthetic image pairs, featuring object-level and local region\nchanges, derived from existing image datasets, which are independent of target\nanomaly datasets. We propose a one-prompt Meta-learning framework for Universal\nAnomaly Segmentation (MetaUAS) that is trained on this synthetic dataset and\nthen generalizes well to segment any novel or unseen visual anomalies in the\nreal world. To handle geometrical variations between prompt and query images,\nwe propose a soft feature alignment module that bridges paired-image change\nperception and single-image semantic segmentation. This is the first work to\nachieve universal anomaly segmentation using a pure vision model without\nrelying on special anomaly detection datasets and pre-trained visual-language\nmodels. Our method effectively and efficiently segments any anomalies with only\none normal image prompt and enjoys training-free without guidance from\nlanguage. Our MetaUAS significantly outperforms previous zero-shot, few-shot,\nand even full-shot anomaly segmentation methods. The code and pre-trained\nmodels are available at https://github.com/gaobb/MetaUAS.",
      "pdf_url": "http://arxiv.org/pdf/2505.09265v1",
      "published": "2025-05-14T10:25:26+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.09265v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Learning to Detect Multi-class Anomalies with Just One Normal Image Prompt",
      "authors": [
        "Bin-Bin Gao"
      ],
      "abstract": "Unsupervised reconstruction networks using self-attention transformers have\nachieved state-of-the-art performance for multi-class (unified) anomaly\ndetection with a single model. However, these self-attention reconstruction\nmodels primarily operate on target features, which may result in perfect\nreconstruction for both normal and anomaly features due to high consistency\nwith context, leading to failure in detecting anomalies. Additionally, these\nmodels often produce inaccurate anomaly segmentation due to performing\nreconstruction in a low spatial resolution latent space. To enable\nreconstruction models enjoying high efficiency while enhancing their\ngeneralization for unified anomaly detection, we propose a simple yet effective\nmethod that reconstructs normal features and restores anomaly features with\njust One Normal Image Prompt (OneNIP). In contrast to previous work, OneNIP\nallows for the first time to reconstruct or restore anomalies with just one\nnormal image prompt, effectively boosting unified anomaly detection\nperformance. Furthermore, we propose a supervised refiner that regresses\nreconstruction errors by using both real normal and synthesized anomalous\nimages, which significantly improves pixel-level anomaly segmentation. OneNIP\noutperforms previous methods on three industry anomaly detection benchmarks:\nMVTec, BTAD, and VisA. The code and pre-trained models are available at\nhttps://github.com/gaobb/OneNIP.",
      "pdf_url": "http://arxiv.org/pdf/2505.09264v1",
      "published": "2025-05-14T10:25:14+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.09264v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Few-Shot Anomaly-Driven Generation for Anomaly Classification and Segmentation",
      "authors": [
        "Guan Gui",
        "Bin-Bin Gao",
        "Jun Liu",
        "Chengjie Wang",
        "Yunsheng Wu"
      ],
      "abstract": "Anomaly detection is a practical and challenging task due to the scarcity of\nanomaly samples in industrial inspection. Some existing anomaly detection\nmethods address this issue by synthesizing anomalies with noise or external\ndata. However, there is always a large semantic gap between synthetic and\nreal-world anomalies, resulting in weak performance in anomaly detection. To\nsolve the problem, we propose a few-shot Anomaly-driven Generation (AnoGen)\nmethod, which guides the diffusion model to generate realistic and diverse\nanomalies with only a few real anomalies, thereby benefiting training anomaly\ndetection models. Specifically, our work is divided into three stages. In the\nfirst stage, we learn the anomaly distribution based on a few given real\nanomalies and inject the learned knowledge into an embedding. In the second\nstage, we use the embedding and given bounding boxes to guide the diffusion\nmodel to generate realistic and diverse anomalies on specific objects (or\ntextures). In the final stage, we propose a weakly-supervised anomaly detection\nmethod to train a more powerful model with generated anomalies. Our method\nbuilds upon DRAEM and DesTSeg as the foundation model and conducts experiments\non the commonly used industrial anomaly detection dataset, MVTec. The\nexperiments demonstrate that our generated anomalies effectively improve the\nmodel performance of both anomaly classification and segmentation tasks\nsimultaneously, \\eg, DRAEM and DseTSeg achieved a 5.8\\% and 1.5\\% improvement\nin AU-PR metric on segmentation task, respectively. The code and generated\nanomalous data are available at https://github.com/gaobb/AnoGen.",
      "pdf_url": "http://arxiv.org/pdf/2505.09263v1",
      "published": "2025-05-14T10:25:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.09263v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "EDBench: Large-Scale Electron Density Data for Molecular Modeling",
      "authors": [
        "Hongxin Xiang",
        "Ke Li",
        "Mingquan Liu",
        "Zhixiang Cheng",
        "Bin Yao",
        "Wenjie Du",
        "Jun Xia",
        "Li Zeng",
        "Xin Jin",
        "Xiangxiang Zeng"
      ],
      "abstract": "Existing molecular machine learning force fields (MLFFs) generally focus on\nthe learning of atoms, molecules, and simple quantum chemical properties (such\nas energy and force), but ignore the importance of electron density (ED)\n$\\rho(r)$ in accurately understanding molecular force fields (MFFs). ED\ndescribes the probability of finding electrons at specific locations around\natoms or molecules, which uniquely determines all ground state properties (such\nas energy, molecular structure, etc.) of interactive multi-particle systems\naccording to the Hohenberg-Kohn theorem. However, the calculation of ED relies\non the time-consuming first-principles density functional theory (DFT) which\nleads to the lack of large-scale ED data and limits its application in MLFFs.\nIn this paper, we introduce EDBench, a large-scale, high-quality dataset of ED\ndesigned to advance learning-based research at the electronic scale. Built upon\nthe PCQM4Mv2, EDBench provides accurate ED data, covering 3.3 million\nmolecules. To comprehensively evaluate the ability of models to understand and\nutilize electronic information, we design a suite of ED-centric benchmark tasks\nspanning prediction, retrieval, and generation. Our evaluation on several\nstate-of-the-art methods demonstrates that learning from EDBench is not only\nfeasible but also achieves high accuracy. Moreover, we show that learning-based\nmethod can efficiently calculate ED with comparable precision while\nsignificantly reducing the computational cost relative to traditional DFT\ncalculations. All data and benchmarks from EDBench will be freely available,\nlaying a robust foundation for ED-driven drug discovery and materials science.",
      "pdf_url": "http://arxiv.org/pdf/2505.09262v1",
      "published": "2025-05-14T10:23:22+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.09262v1",
      "categories": [
        "physics.chem-ph",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ]
    },
    {
      "title": "Focus, Merge, Rank: Improved Question Answering Based on Semi-structured Knowledge Bases",
      "authors": [
        "Derian Boer",
        "Stephen Roth",
        "Stefan Kramer"
      ],
      "abstract": "In many real-world settings, machine learning models and interactive systems\nhave access to both structured knowledge, e.g., knowledge graphs or tables, and\nunstructured content, e.g., natural language documents. However, most rely on\neither. Semi-Structured Knowledge Bases (SKBs) bridge this gap by linking\nunstructured content to nodes within structured data, thereby enabling new\nstrategies for knowledge access and use. In this work, we present\nFocusedRetriever, a modular SKB-based framework for multi-hop question\nanswering. It integrates components (VSS-based entity search, LLM-based\ngeneration of Cypher queries and pairwise re-ranking) in a way that enables it\nto outperform state-of-the-art methods across all three STaRK benchmark test\nsets, covering diverse domains and multiple performance metrics. The average\nfirst-hit rate exceeds that of the second-best method by 25.7%.\nFocusedRetriever leverages (1) the capacity of Large Language Models (LLMs) to\nextract relational facts and entity attributes from unstructured text, (2) node\nset joins to filter answer candidates based on these extracted triplets and\nconstraints, (3) vector similarity search to retrieve and rank relevant\nunstructured content, and (4) the contextual capabilities of LLMs to finally\nrank the top-k answers. For generality, we only incorporate base LLMs in\nFocusedRetriever in our evaluation. However, our analysis of intermediate\nresults highlights several opportunities for further upgrades including\nfinetuning. The source code is publicly available at\nhttps://github.com/kramerlab/FocusedRetriever .",
      "pdf_url": "http://arxiv.org/pdf/2505.09246v1",
      "published": "2025-05-14T09:35:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.09246v1",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Educational impacts of generative artificial intelligence on learning and performance of engineering students in China",
      "authors": [
        "Lei Fan",
        "Kunyang Deng",
        "Fangxue Liu"
      ],
      "abstract": "With the rapid advancement of generative artificial intelligence(AI), its\npotential applications in higher education have attracted significant\nattention. This study investigated how 148 students from diverse engineering\ndisciplines and regions across China used generative AI, focusing on its impact\non their learning experience and the opportunities and challenges it poses in\nengineering education. Based on the surveyed data, we explored four key areas:\nthe frequency and application scenarios of AI use among engineering students,\nits impact on students' learning and performance, commonly encountered\nchallenges in using generative AI, and future prospects for its adoption in\nengineering education. The results showed that more than half of the\nparticipants reported a positive impact of generative AI on their learning\nefficiency, initiative, and creativity, with nearly half believing it also\nenhanced their independent thinking. However, despite acknowledging improved\nstudy efficiency, many felt their actual academic performance remained largely\nunchanged and expressed concerns about the accuracy and domain-specific\nreliability of generative AI. Our findings provide a first-hand insight into\nthe current benefits and challenges generative AI brings to students,\nparticularly Chinese engineering students, while offering several\nrecommendations, especially from the students' perspective, for effectively\nintegrating generative AI into engineering education.",
      "pdf_url": "http://arxiv.org/pdf/2505.09208v1",
      "published": "2025-05-14T07:52:54+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.09208v1",
      "categories": [
        "cs.HC",
        "cs.AI"
      ]
    },
    {
      "title": "InvDesFlow-AL: Active Learning-based Workflow for Inverse Design of Functional Materials",
      "authors": [
        "Xiao-Qi Han",
        "Peng-Jie Guo",
        "Ze-Feng Gao",
        "Hao Sun",
        "Zhong-Yi Lu"
      ],
      "abstract": "Developing inverse design methods for functional materials with specific\nproperties is critical to advancing fields like renewable energy, catalysis,\nenergy storage, and carbon capture. Generative models based on diffusion\nprinciples can directly produce new materials that meet performance\nconstraints, thereby significantly accelerating the material design process.\nHowever, existing methods for generating and predicting crystal structures\noften remain limited by low success rates. In this work, we propose a novel\ninverse material design generative framework called InvDesFlow-AL, which is\nbased on active learning strategies. This framework can iteratively optimize\nthe material generation process to gradually guide it towards desired\nperformance characteristics. In terms of crystal structure prediction, the\nInvDesFlow-AL model achieves an RMSE of 0.0423 {\\AA}, representing an 32.96%\nimprovement in performance compared to exsisting generative models.\nAdditionally, InvDesFlow-AL has been successfully validated in the design of\nlow-formation-energy and low-Ehull materials. It can systematically generate\nmaterials with progressively lower formation energies while continuously\nexpanding the exploration across diverse chemical spaces. These results fully\ndemonstrate the effectiveness of the proposed active learning-driven generative\nmodel in accelerating material discovery and inverse design. To further prove\nthe effectiveness of this method, we took the search for BCS superconductors\nunder ambient pressure as an example explored by InvDesFlow-AL. As a result, we\nsuccessfully identified Li\\(_2\\)AuH\\(_6\\) as a conventional BCS superconductor\nwith an ultra-high transition temperature of 140 K. This discovery provides\nstrong empirical support for the application of inverse design in materials\nscience.",
      "pdf_url": "http://arxiv.org/pdf/2505.09203v1",
      "published": "2025-05-14T07:29:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.09203v1",
      "categories": [
        "cond-mat.mtrl-sci",
        "cond-mat.supr-con",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "DRRNet: Macro-Micro Feature Fusion and Dual Reverse Refinement for Camouflaged Object Detection",
      "authors": [
        "Jianlin Sun",
        "Xiaolin Fang",
        "Juwei Guan",
        "Dongdong Gui",
        "Teqi Wang",
        "Tongxin Zhu"
      ],
      "abstract": "The core challenge in Camouflage Object Detection (COD) lies in the\nindistinguishable similarity between targets and backgrounds in terms of color,\ntexture, and shape. This causes existing methods to either lose edge details\n(such as hair-like fine structures) due to over-reliance on global semantic\ninformation or be disturbed by similar backgrounds (such as vegetation\npatterns) when relying solely on local features. We propose DRRNet, a\nfour-stage architecture characterized by a \"context-detail-fusion-refinement\"\npipeline to address these issues. Specifically, we introduce an Omni-Context\nFeature Extraction Module to capture global camouflage patterns and a Local\nDetail Extraction Module to supplement microstructural information for the\nfull-scene context module. We then design a module for forming dual\nrepresentations of scene understanding and structural awareness, which fuses\npanoramic features and local features across various scales. In the decoder, we\nalso introduce a reverse refinement module that leverages spatial edge priors\nand frequency-domain noise suppression to perform a two-stage inverse\nrefinement of the output. By applying two successive rounds of inverse\nrefinement, the model effectively suppresses background interference and\nenhances the continuity of object boundaries. Experimental results demonstrate\nthat DRRNet significantly outperforms state-of-the-art methods on benchmark\ndatasets. Our code is available at https://github.com/jerrySunning/DRRNet.",
      "pdf_url": "http://arxiv.org/pdf/2505.09168v1",
      "published": "2025-05-14T06:03:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.09168v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "An Initial Exploration of Default Images in Text-to-Image Generation",
      "authors": [
        "Hannu Simonen",
        "Atte Kiviniemi",
        "Jonas Oppenlaender"
      ],
      "abstract": "In the creative practice of text-to-image generation (TTI), images are\ngenerated from text prompts. However, TTI models are trained to always yield an\noutput, even if the prompt contains unknown terms. In this case, the model may\ngenerate what we call \"default images\": images that closely resemble each other\nacross many unrelated prompts. We argue studying default images is valuable for\ndesigning better solutions for TTI and prompt engineering. In this paper, we\nprovide the first investigation into default images on Midjourney, a popular\nimage generator. We describe our systematic approach to create input prompts\ntriggering default images, and present the results of our initial experiments\nand several small-scale ablation studies. We also report on a survey study\ninvestigating how default images affect user satisfaction. Our work lays the\nfoundation for understanding default images in TTI and highlights challenges\nand future research directions.",
      "pdf_url": "http://arxiv.org/pdf/2505.09166v1",
      "published": "2025-05-14T05:59:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.09166v1",
      "categories": [
        "cs.HC",
        "cs.AI",
        "H.5.m; I.2.m"
      ]
    },
    {
      "title": "A Multi-Task Foundation Model for Wireless Channel Representation Using Contrastive and Masked Autoencoder Learning",
      "authors": [
        "Berkay Guler",
        "Giovanni Geraci",
        "Hamid Jafarkhani"
      ],
      "abstract": "Current applications of self-supervised learning to wireless channel\nrepresentation often borrow paradigms developed for text and image processing,\nwithout fully addressing the unique characteristics and constraints of wireless\ncommunications. Aiming to fill this gap, we first propose WiMAE (Wireless\nMasked Autoencoder), a transformer-based encoder-decoder foundation model\npretrained on a realistic open-source multi-antenna wireless channel dataset.\nBuilding upon this foundation, we develop ContraWiMAE, which enhances WiMAE by\nincorporating a contrastive learning objective alongside the reconstruction\ntask in a unified multi-task framework. By warm-starting from pretrained WiMAE\nweights and generating positive pairs via noise injection, the contrastive\ncomponent enables the model to capture both structural and discriminative\nfeatures, enhancing representation quality beyond what reconstruction alone can\nachieve. Through extensive evaluation on unseen scenarios, we demonstrate the\neffectiveness of both approaches across multiple downstream tasks, with\nContraWiMAE showing further improvements in linear separability and\nadaptability in diverse wireless environments. Comparative evaluations against\na state-of-the-art wireless channel foundation model confirm the superior\nperformance and data efficiency of our models, highlighting their potential as\npowerful baselines for future research in self-supervised wireless channel\nrepresentation learning.",
      "pdf_url": "http://arxiv.org/pdf/2505.09160v1",
      "published": "2025-05-14T05:45:22+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.09160v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ]
    },
    {
      "title": "ELIS: Efficient LLM Iterative Scheduling System with Response Length Predictor",
      "authors": [
        "Seungbeom Choi",
        "Jeonghoe Goo",
        "Eunjoo Jeon",
        "Mingyu Yang",
        "Minsung Jang"
      ],
      "abstract": "We propose ELIS, a serving system for Large Language Models (LLMs) featuring\nan Iterative Shortest Remaining Time First (ISRTF) scheduler designed to\nefficiently manage inference tasks with the shortest remaining tokens. Current\nLLM serving systems often employ a first-come-first-served scheduling strategy,\nwhich can lead to the \"head-of-line blocking\" problem. To overcome this\nlimitation, it is necessary to predict LLM inference times and apply a shortest\njob first scheduling strategy. However, due to the auto-regressive nature of\nLLMs, predicting the inference latency is challenging. ELIS addresses this\nchallenge by training a response length predictor for LLMs using the BGE model,\nan encoder-based state-of-the-art model. Additionally, we have devised the\nISRTF scheduling strategy, an optimization of shortest remaining time first\ntailored to existing LLM iteration batching. To evaluate our work in an\nindustrial setting, we simulate streams of requests based on our study of\nreal-world user LLM serving trace records. Furthermore, we implemented ELIS as\na cloud-native scheduler system on Kubernetes to evaluate its performance in\nproduction environments. Our experimental results demonstrate that ISRTF\nreduces the average job completion time by up to 19.6%.",
      "pdf_url": "http://arxiv.org/pdf/2505.09142v1",
      "published": "2025-05-14T04:50:00+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.09142v1",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Fair Clustering via Alignment",
      "authors": [
        "Kunwoong Kim",
        "Jihu Lee",
        "Sangchul Park",
        "Yongdai Kim"
      ],
      "abstract": "Algorithmic fairness in clustering aims to balance the proportions of\ninstances assigned to each cluster with respect to a given sensitive attribute.\nWhile recently developed fair clustering algorithms optimize clustering\nobjectives under specific fairness constraints, their inherent complexity or\napproximation often results in suboptimal clustering utility or numerical\ninstability in practice. To resolve these limitations, we propose a new fair\nclustering algorithm based on a novel decomposition of the fair K-means\nclustering objective function. The proposed algorithm, called Fair Clustering\nvia Alignment (FCA), operates by alternately (i) finding a joint probability\ndistribution to align the data from different protected groups, and (ii)\noptimizing cluster centers in the aligned space. A key advantage of FCA is that\nit theoretically guarantees approximately optimal clustering utility for any\ngiven fairness level without complex constraints, thereby enabling high-utility\nfair clustering in practice. Experiments show that FCA outperforms existing\nmethods by (i) attaining a superior trade-off between fairness level and\nclustering utility, and (ii) achieving near-perfect fairness without numerical\ninstability.",
      "pdf_url": "http://arxiv.org/pdf/2505.09131v1",
      "published": "2025-05-14T04:29:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.09131v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ]
    },
    {
      "title": "WSCIF: A Weakly-Supervised Color Intelligence Framework for Tactical Anomaly Detection in Surveillance Keyframes",
      "authors": [
        "Wei Meng"
      ],
      "abstract": "The deployment of traditional deep learning models in high-risk security\ntasks in an unlabeled, data-non-exploitable video intelligence environment\nfaces significant challenges. In this paper, we propose a lightweight anomaly\ndetection framework based on color features for surveillance video clips in a\nhigh sensitivity tactical mission, aiming to quickly identify and interpret\npotential threat events under resource-constrained and data-sensitive\nconditions. The method fuses unsupervised KMeans clustering with RGB channel\nhistogram modeling to achieve composite detection of structural anomalies and\ncolor mutation signals in key frames. The experiment takes an operation\nsurveillance video occurring in an African country as a research sample, and\nsuccessfully identifies multiple highly anomalous frames related to high-energy\nlight sources, target presence, and reflective interference under the condition\nof no access to the original data. The results show that this method can be\neffectively used for tactical assassination warning, suspicious object\nscreening and environmental drastic change monitoring with strong deployability\nand tactical interpretation value. The study emphasizes the importance of color\nfeatures as low semantic battlefield signal carriers, and its battlefield\nintelligent perception capability will be further extended by combining graph\nneural networks and temporal modeling in the future.",
      "pdf_url": "http://arxiv.org/pdf/2505.09129v1",
      "published": "2025-05-14T04:24:37+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.09129v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "es: 68T10, 68T05, 62H35, 68U10",
        "I.4.9; I.5.1; I.2.10"
      ]
    },
    {
      "title": "PreCare: Designing AI Assistants for Advance Care Planning (ACP) to Enhance Personal Value Exploration, Patient Knowledge, and Decisional Confidence",
      "authors": [
        "Yu Lun Hsu",
        "Yun-Rung Chou",
        "Chiao-Ju Chang",
        "Yu-Cheng Chang",
        "Zer-Wei Lee",
        "Rokas Gipiškis",
        "Rachel Li",
        "Chih-Yuan Shih",
        "Jen-Kuei Peng",
        "Hsien-Liang Huang",
        "Jaw-Shiun Tsai",
        "Mike Y. Chen"
      ],
      "abstract": "Advance Care Planning (ACP) allows individuals to specify their preferred\nend-of-life life-sustaining treatments before they become incapacitated by\ninjury or terminal illness (e.g., coma, cancer, dementia). While online ACP\noffers high accessibility, it lacks key benefits of clinical consultations,\nincluding personalized value exploration, immediate clarification of decision\nconsequences. To bridge this gap, we conducted two formative studies: 1)\nshadowed and interviewed 3 ACP teams consisting of physicians, nurses, and\nsocial workers (18 patients total), and 2) interviewed 14 users of ACP\nwebsites. Building on these insights, we designed PreCare in collaboration with\n6 ACP professionals. PreCare is a website with 3 AI-driven assistants designed\nto guide users through exploring personal values, gaining ACP knowledge, and\nsupporting informed decision-making. A usability study (n=12) showed that\nPreCare achieved a System Usability Scale (SUS) rating of excellent. A\ncomparative evaluation (n=12) showed that PreCare's AI assistants significantly\nimproved exploration of personal values, knowledge, and decisional confidence,\nand was preferred by 92% of participants.",
      "pdf_url": "http://arxiv.org/pdf/2505.09115v1",
      "published": "2025-05-14T03:53:35+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.09115v1",
      "categories": [
        "cs.HC",
        "cs.AI"
      ]
    }
  ]
}