{
  "last_updated": "2025-02-28T00:44:52.218675",
  "papers": [
    {
      "title": "Hi Robot: Open-Ended Instruction Following with Hierarchical Vision-Language-Action Models",
      "authors": [
        "Lucy Xiaoyang Shi",
        "Brian Ichter",
        "Michael Equi",
        "Liyiming Ke",
        "Karl Pertsch",
        "Quan Vuong",
        "James Tanner",
        "Anna Walling",
        "Haohuan Wang",
        "Niccolo Fusai",
        "Adrian Li-Bell",
        "Danny Driess",
        "Lachy Groom",
        "Sergey Levine",
        "Chelsea Finn"
      ],
      "abstract": "Generalist robots that can perform a range of different tasks in open-world\nsettings must be able to not only reason about the steps needed to accomplish\ntheir goals, but also process complex instructions, prompts, and even feedback\nduring task execution. Intricate instructions (e.g., \"Could you make me a\nvegetarian sandwich?\" or \"I don't like that one\") require not just the ability\nto physically perform the individual steps, but the ability to situate complex\ncommands and feedback in the physical world. In this work, we describe a system\nthat uses vision-language models in a hierarchical structure, first reasoning\nover complex prompts and user feedback to deduce the most appropriate next step\nto fulfill the task, and then performing that step with low-level actions. In\ncontrast to direct instruction following methods that can fulfill simple\ncommands (\"pick up the cup\"), our system can reason through complex prompts and\nincorporate situated feedback during task execution (\"that's not trash\"). We\nevaluate our system across three robotic platforms, including single-arm,\ndual-arm, and dual-arm mobile robots, demonstrating its ability to handle tasks\nsuch as cleaning messy tables, making sandwiches, and grocery shopping.",
      "pdf_url": "http://arxiv.org/pdf/2502.19417v1",
      "published": "2025-02-26T18:58:41+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.19417v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Norm Growth and Stability Challenges in Localized Sequential Knowledge Editing",
      "authors": [
        "Akshat Gupta",
        "Christine Fang",
        "Atahan Ozdemir",
        "Maochuan Lu",
        "Ahmed Alaa",
        "Thomas Hartvigsen",
        "Gopala Anumanchipalli"
      ],
      "abstract": "This study investigates the impact of localized updates to large language\nmodels (LLMs), specifically in the context of knowledge editing - a task aimed\nat incorporating or modifying specific facts without altering broader model\ncapabilities. We first show that across different post-training interventions\nlike continuous pre-training, full fine-tuning and LORA-based fine-tuning, the\nFrobenius norm of the updated matrices always increases. This increasing norm\nis especially detrimental for localized knowledge editing, where only a subset\nof matrices are updated in a model . We reveal a consistent phenomenon across\nvarious editing techniques, including fine-tuning, hypernetwork-based\napproaches, and locate-and-edit methods: the norm of the updated matrix\ninvariably increases with successive updates. Such growth disrupts model\nbalance, particularly when isolated matrices are updated while the rest of the\nmodel remains static, leading to potential instability and degradation of\ndownstream performance. Upon deeper investigations of the intermediate\nactivation vectors, we find that the norm of internal activations decreases and\nis accompanied by shifts in the subspaces occupied by these activations, which\nshows that these activation vectors now occupy completely different regions in\nthe representation space compared to the unedited model. With our paper, we\nhighlight the technical challenges with continuous and localized sequential\nknowledge editing and their implications for maintaining model stability and\nutility.",
      "pdf_url": "http://arxiv.org/pdf/2502.19416v1",
      "published": "2025-02-26T18:58:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.19416v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Project Alexandria: Towards Freeing Scientific Knowledge from Copyright Burdens via LLMs",
      "authors": [
        "Christoph Schuhmann",
        "Gollam Rabby",
        "Ameya Prabhu",
        "Tawsif Ahmed",
        "Andreas Hochlehnert",
        "Huu Nguyen",
        "Nick Akinci Heidrich",
        "Ludwig Schmidt",
        "Robert Kaczmarczyk",
        "Sören Auer",
        "Jenia Jitsev",
        "Matthias Bethge"
      ],
      "abstract": "Paywalls, licenses and copyright rules often restrict the broad dissemination\nand reuse of scientific knowledge. We take the position that it is both legally\nand technically feasible to extract the scientific knowledge in scholarly\ntexts. Current methods, like text embeddings, fail to reliably preserve factual\ncontent, and simple paraphrasing may not be legally sound. We urge the\ncommunity to adopt a new idea: convert scholarly documents into Knowledge Units\nusing LLMs. These units use structured data capturing entities, attributes and\nrelationships without stylistic content. We provide evidence that Knowledge\nUnits: (1) form a legally defensible framework for sharing knowledge from\ncopyrighted research texts, based on legal analyses of German copyright law and\nU.S. Fair Use doctrine, and (2) preserve most (~95%) factual knowledge from\noriginal text, measured by MCQ performance on facts from the original\ncopyrighted text across four research domains. Freeing scientific knowledge\nfrom copyright promises transformative benefits for scientific research and\neducation by allowing language models to reuse important facts from copyrighted\ntext. To support this, we share open-source tools for converting research\ndocuments into Knowledge Units. Overall, our work posits the feasibility of\ndemocratizing access to scientific knowledge while respecting copyright.",
      "pdf_url": "http://arxiv.org/pdf/2502.19413v1",
      "published": "2025-02-26T18:56:52+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.19413v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Code to Think, Think to Code: A Survey on Code-Enhanced Reasoning and Reasoning-Driven Code Intelligence in LLMs",
      "authors": [
        "Dayu Yang",
        "Tianyang Liu",
        "Daoan Zhang",
        "Antoine Simoulin",
        "Xiaoyi Liu",
        "Yuwei Cao",
        "Zhaopu Teng",
        "Xin Qian",
        "Grey Yang",
        "Jiebo Luo",
        "Julian McAuley"
      ],
      "abstract": "In large language models (LLMs), code and reasoning reinforce each other:\ncode offers an abstract, modular, and logic-driven structure that supports\nreasoning, while reasoning translates high-level goals into smaller, executable\nsteps that drive more advanced code intelligence. In this study, we examine how\ncode serves as a structured medium for enhancing reasoning: it provides\nverifiable execution paths, enforces logical decomposition, and enables runtime\nvalidation. We also explore how improvements in reasoning have transformed code\nintelligence from basic completion to advanced capabilities, enabling models to\naddress complex software engineering tasks through planning and debugging.\nFinally, we identify key challenges and propose future research directions to\nstrengthen this synergy, ultimately improving LLM's performance in both areas.",
      "pdf_url": "http://arxiv.org/pdf/2502.19411v1",
      "published": "2025-02-26T18:55:42+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.19411v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.SE"
      ]
    },
    {
      "title": "Less or More: Towards Glanceable Explanations for LLM Recommendations Using Ultra-Small Devices",
      "authors": [
        "Xinru Wang",
        "Mengjie Yu",
        "Hannah Nguyen",
        "Michael Iuzzolino",
        "Tianyi Wang",
        "Peiqi Tang",
        "Natasha Lynova",
        "Co Tran",
        "Ting Zhang",
        "Naveen Sendhilnathan",
        "Hrvoje Benko",
        "Haijun Xia",
        "Tanya Jonker"
      ],
      "abstract": "Large Language Models (LLMs) have shown remarkable potential in recommending\neveryday actions as personal AI assistants, while Explainable AI (XAI)\ntechniques are being increasingly utilized to help users understand why a\nrecommendation is given. Personal AI assistants today are often located on\nultra-small devices such as smartwatches, which have limited screen space. The\nverbosity of LLM-generated explanations, however, makes it challenging to\ndeliver glanceable LLM explanations on such ultra-small devices. To address\nthis, we explored 1) spatially structuring an LLM's explanation text using\ndefined contextual components during prompting and 2) presenting temporally\nadaptive explanations to users based on confidence levels. We conducted a user\nstudy to understand how these approaches impacted user experiences when\ninteracting with LLM recommendations and explanations on ultra-small devices.\nThe results showed that structured explanations reduced users' time to action\nand cognitive load when reading an explanation. Always-on structured\nexplanations increased users' acceptance of AI recommendations. However, users\nwere less satisfied with structured explanations compared to unstructured ones\ndue to their lack of sufficient, readable details. Additionally, adaptively\npresenting structured explanations was less effective at improving user\nperceptions of the AI compared to the always-on structured explanations.\nTogether with users' interview feedback, the results led to design implications\nto be mindful of when personalizing the content and timing of LLM explanations\nthat are displayed on ultra-small devices.",
      "pdf_url": "http://arxiv.org/pdf/2502.19410v1",
      "published": "2025-02-26T18:55:26+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.19410v1",
      "categories": [
        "cs.HC",
        "cs.AI"
      ]
    },
    {
      "title": "TheoremExplainAgent: Towards Multimodal Explanations for LLM Theorem Understanding",
      "authors": [
        "Max Ku",
        "Thomas Chong",
        "Jonathan Leung",
        "Krish Shah",
        "Alvin Yu",
        "Wenhu Chen"
      ],
      "abstract": "Understanding domain-specific theorems often requires more than just\ntext-based reasoning; effective communication through structured visual\nexplanations is crucial for deeper comprehension. While large language models\n(LLMs) demonstrate strong performance in text-based theorem reasoning, their\nability to generate coherent and pedagogically meaningful visual explanations\nremains an open challenge. In this work, we introduce TheoremExplainAgent, an\nagentic approach for generating long-form theorem explanation videos (over 5\nminutes) using Manim animations. To systematically evaluate multimodal theorem\nexplanations, we propose TheoremExplainBench, a benchmark covering 240 theorems\nacross multiple STEM disciplines, along with 5 automated evaluation metrics.\nOur results reveal that agentic planning is essential for generating detailed\nlong-form videos, and the o3-mini agent achieves a success rate of 93.8% and an\noverall score of 0.77. However, our quantitative and qualitative studies show\nthat most of the videos produced exhibit minor issues with visual element\nlayout. Furthermore, multimodal explanations expose deeper reasoning flaws that\ntext-based explanations fail to reveal, highlighting the importance of\nmultimodal explanations.",
      "pdf_url": "http://arxiv.org/pdf/2502.19400v1",
      "published": "2025-02-26T18:50:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.19400v1",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.MM"
      ]
    },
    {
      "title": "Multi-modal Contrastive Learning for Tumor-specific Missing Modality Synthesis",
      "authors": [
        "Minjoo Lim",
        "Bogyeong Kang",
        "Tae-Eui Kam"
      ],
      "abstract": "Multi-modal magnetic resonance imaging (MRI) is essential for providing\ncomplementary information about brain anatomy and pathology, leading to more\naccurate diagnoses. However, obtaining high-quality multi-modal MRI in a\nclinical setting is difficult due to factors such as time constraints, high\ncosts, and patient movement artifacts. To overcome this difficulty, there is\nincreasing interest in developing generative models that can synthesize missing\ntarget modality images from the available source ones. Therefore, we design a\ngenerative model for missing MRI that integrates multi-modal contrastive\nlearning with a focus on critical tumor regions. Specifically, we integrate\nmulti-modal contrastive learning, tailored for multiple source modalities, and\nenhance its effectiveness by selecting features based on entropy during the\ncontrastive learning process. Additionally, our network not only generates the\nmissing target modality images but also predicts segmentation outputs,\nsimultaneously. This approach improves the generator's capability to precisely\ngenerate tumor regions, ultimately improving performance in downstream\nsegmentation tasks. By leveraging a combination of contrastive, segmentation,\nand additional self-representation losses, our model effectively reflects\ntarget-specific information and generate high-quality target images.\nConsequently, our results in the Brain MR Image Synthesis challenge demonstrate\nthat the proposed model excelled in generating the missing modality.",
      "pdf_url": "http://arxiv.org/pdf/2502.19390v1",
      "published": "2025-02-26T18:34:58+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.19390v1",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Efficient 4D fMRI ASD Classification using Spatial-Temporal-Omics-based Learning Framework",
      "authors": [
        "Ziqiao Weng",
        "Weidong Cai",
        "Bo Zhou"
      ],
      "abstract": "Autism Spectrum Disorder (ASD) is a neurodevelopmental disorder impacting\nsocial and behavioral development. Resting-state fMRI, a non-invasive tool for\ncapturing brain connectivity patterns, aids in early ASD diagnosis and\ndifferentiation from typical controls (TC). However, previous methods, which\nrely on either mean time series or full 4D data, are limited by a lack of\nspatial information or by high computational costs. This underscores the need\nfor an efficient solution that preserves both spatial and temporal information.\nIn this paper, we propose a novel, simple, and efficient spatial-temporal-omics\nlearning framework designed to efficiently extract spatio-temporal features\nfrom fMRI for ASD classification. Our approach addresses these limitations by\nutilizing 3D time-domain derivatives as the spatial-temporal inter-voxel omics,\nwhich preserve full spatial resolution while capturing diverse statistical\ncharacteristics of the time series at each voxel. Meanwhile, functional\nconnectivity features serve as the spatial-temporal inter-regional omics,\ncapturing correlations across brain regions. Extensive experiments and ablation\nstudies on the ABIDE dataset demonstrate that our framework significantly\noutperforms previous methods while maintaining computational efficiency. We\nbelieve our research offers valuable insights that will inform and advance\nfuture ASD studies, particularly in the realm of spatial-temporal-omics-based\nlearning.",
      "pdf_url": "http://arxiv.org/pdf/2502.19386v1",
      "published": "2025-02-26T18:31:07+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.19386v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Preference-Based Gradient Estimation for ML-Based Approximate Combinatorial Optimization",
      "authors": [
        "Arman Mielke",
        "Uwe Bauknecht",
        "Thilo Strauss",
        "Mathias Niepert"
      ],
      "abstract": "Combinatorial optimization (CO) problems arise in a wide range of fields from\nmedicine to logistics and manufacturing. While exact solutions are often not\nnecessary, many applications require finding high-quality solutions quickly.\nFor this purpose, we propose a data-driven approach to improve existing\nnon-learned approximation algorithms for CO. We parameterize the approximation\nalgorithm and train a graph neural network (GNN) to predict parameter values\nthat lead to the best possible solutions. Our pipeline is trained end-to-end in\na self-supervised fashion using gradient estimation, treating the approximation\nalgorithm as a black box. We propose a novel gradient estimation scheme for\nthis purpose, which we call preference-based gradient estimation. Our approach\ncombines the benefits of the neural network and the non-learned approximation\nalgorithm: The GNN leverages the information from the dataset to allow the\napproximation algorithm to find better solutions, while the approximation\nalgorithm guarantees that the solution is feasible. We validate our approach on\ntwo well-known combinatorial optimization problems, the travelling salesman\nproblem and the minimum k-cut problem, and show that our method is competitive\nwith state of the art learned CO solvers.",
      "pdf_url": "http://arxiv.org/pdf/2502.19377v1",
      "published": "2025-02-26T18:23:07+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.19377v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "DataMan: Data Manager for Pre-training Large Language Models",
      "authors": [
        "Ru Peng",
        "Kexin Yang",
        "Yawen Zeng",
        "Junyang Lin",
        "Dayiheng Liu",
        "Junbo Zhao"
      ],
      "abstract": "The performance emergence of large language models (LLMs) driven by data\nscaling laws makes the selection of pre-training data increasingly important.\nHowever, existing methods rely on limited heuristics and human intuition,\nlacking comprehensive and clear guidelines. To address this, we are inspired by\n``reverse thinking'' -- prompting LLMs to self-identify which criteria benefit\nits performance. As its pre-training capabilities are related to perplexity\n(PPL), we derive 14 quality criteria from the causes of text perplexity\nanomalies and introduce 15 common application domains to support domain mixing.\nIn this paper, we train a Data Manager (DataMan) to learn quality ratings and\ndomain recognition from pointwise rating, and use it to annotate a 447B token\npre-training corpus with 14 quality ratings and domain type. Our experiments\nvalidate our approach, using DataMan to select 30B tokens to train a\n1.3B-parameter language model, demonstrating significant improvements in\nin-context learning (ICL), perplexity, and instruction-following ability over\nthe state-of-the-art baseline. The best-performing model, based on the Overall\nScore l=5 surpasses a model trained with 50% more data using uniform sampling.\nWe continue pre-training with high-rated, domain-specific data annotated by\nDataMan to enhance domain-specific ICL performance and thus verify DataMan's\ndomain mixing ability. Our findings emphasize the importance of quality\nranking, the complementary nature of quality criteria, and their low\ncorrelation with perplexity, analyzing misalignment between PPL and ICL\nperformance. We also thoroughly analyzed our pre-training dataset, examining\nits composition, the distribution of quality ratings, and the original document\nsources.",
      "pdf_url": "http://arxiv.org/pdf/2502.19363v1",
      "published": "2025-02-26T18:01:19+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.19363v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Physics-Based Hybrid Machine Learning for Critical Heat Flux Prediction with Uncertainty Quantification",
      "authors": [
        "Aidan Furlong",
        "Xingang Zhao",
        "Robert Salko",
        "Xu Wu"
      ],
      "abstract": "Critical heat flux is a key quantity in boiling system modeling due to its\nimpact on heat transfer and component temperature and performance. This study\ninvestigates the development and validation of an uncertainty-aware hybrid\nmodeling approach that combines machine learning with physics-based models in\nthe prediction of critical heat flux in nuclear reactors for cases of dryout.\nTwo empirical correlations, Biasi and Bowring, were employed with three machine\nlearning uncertainty quantification techniques: deep neural network ensembles,\nBayesian neural networks, and deep Gaussian processes. A pure machine learning\nmodel without a base model served as a baseline for comparison. This study\nexamines the performance and uncertainty of the models under both plentiful and\nlimited training data scenarios using parity plots, uncertainty distributions,\nand calibration curves. The results indicate that the Biasi hybrid deep neural\nnetwork ensemble achieved the most favorable performance (with a mean absolute\nrelative error of 1.846% and stable uncertainty estimates), particularly in the\nplentiful data scenario. The Bayesian neural network models showed slightly\nhigher error and uncertainty but superior calibration. By contrast, deep\nGaussian process models underperformed by most metrics. All hybrid models\noutperformed pure machine learning configurations, demonstrating resistance\nagainst data scarcity.",
      "pdf_url": "http://arxiv.org/pdf/2502.19357v1",
      "published": "2025-02-26T17:55:01+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.19357v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Deep Learning-Based Transfer Learning for Classification of Cassava Disease",
      "authors": [
        "Ademir G. Costa Junior",
        "Fábio S. da Silva",
        "Ricardo Rios"
      ],
      "abstract": "This paper presents a performance comparison among four Convolutional Neural\nNetwork architectures (EfficientNet-B3, InceptionV3, ResNet50, and VGG16) for\nclassifying cassava disease images. The images were sourced from an imbalanced\ndataset from a competition. Appropriate metrics were employed to address class\nimbalance. The results indicate that EfficientNet-B3 achieved on this task\naccuracy of 87.7%, precision of 87.8%, revocation of 87.8% and F1-Score of\n87.7%. These findings suggest that EfficientNet-B3 could be a valuable tool to\nsupport Digital Agriculture.",
      "pdf_url": "http://arxiv.org/pdf/2502.19351v1",
      "published": "2025-02-26T17:50:01+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.19351v1",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "I.5.1; I.5.4"
      ]
    },
    {
      "title": "Controlled Diversity: Length-optimized Natural Language Generation",
      "authors": [
        "Diana Marie Schenke",
        "Timo Baumann"
      ],
      "abstract": "LLMs are not generally able to adjust the length of their outputs based on\nstrict length requirements, a capability that would improve their usefulness in\napplications that require adherence to diverse user and system requirements. We\npresent an approach to train LLMs to acquire this capability by augmenting\nexisting data and applying existing fine-tuning techniques, which we compare\nbased on the trained models' adherence to the length requirement and overall\nresponse quality relative to the baseline model. Our results demonstrate that\nthese techniques can be successfully applied to train LLMs to adhere to length\nrequirements, with the trained models generating texts which better align to\nthe length requirements. Our results indicate that our method may change the\nresponse quality when using training data that was not generated by the\nbaseline model. This allows simultaneous alignment to another training\nobjective in certain scenarios, but is undesirable otherwise. Training on a\ndataset containing the model's own responses eliminates this issue.",
      "pdf_url": "http://arxiv.org/pdf/2502.19347v1",
      "published": "2025-02-26T17:38:58+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.19347v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Joint Optimal Transport and Embedding for Network Alignment",
      "authors": [
        "Qi Yu",
        "Zhichen Zeng",
        "Yuchen Yan",
        "Lei Ying",
        "R. Srikant",
        "Hanghang Tong"
      ],
      "abstract": "Network alignment, which aims to find node correspondence across different\nnetworks, is the cornerstone of various downstream multi-network and Web mining\ntasks. Most of the embedding-based methods indirectly model cross-network node\nrelationships by contrasting positive and negative node pairs sampled from\nhand-crafted strategies, which are vulnerable to graph noises and lead to\npotential misalignment of nodes. Another line of work based on the optimal\ntransport (OT) theory directly models cross-network node relationships and\ngenerates noise-reduced alignments. However, OT methods heavily rely on fixed,\npre-defined cost functions that prohibit end-to-end training and are hard to\ngeneralize. In this paper, we aim to unify the embedding and OT-based methods\nin a mutually beneficial manner and propose a joint optimal transport and\nembedding framework for network alignment named JOENA. For one thing (OT for\nembedding), through a simple yet effective transformation, the noise-reduced OT\nmapping serves as an adaptive sampling strategy directly modeling all\ncross-network node pairs for robust embedding learning.For another (embedding\nfor OT), on top of the learned embeddings, the OT cost can be gradually trained\nin an end-to-end fashion, which further enhances the alignment quality. With a\nunified objective, the mutual benefits of both methods can be achieved by an\nalternating optimization schema with guaranteed convergence. Extensive\nexperiments on real-world networks validate the effectiveness and scalability\nof JOENA, achieving up to 16% improvement in MRR and 20x speedup compared with\nthe state-of-the-art alignment methods.",
      "pdf_url": "http://arxiv.org/pdf/2502.19334v1",
      "published": "2025-02-26T17:28:08+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.19334v1",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.SI"
      ]
    },
    {
      "title": "Agentic Reward Modeling: Integrating Human Preferences with Verifiable Correctness Signals for Reliable Reward Systems",
      "authors": [
        "Hao Peng",
        "Yunjia Qi",
        "Xiaozhi Wang",
        "Zijun Yao",
        "Bin Xu",
        "Lei Hou",
        "Juanzi Li"
      ],
      "abstract": "Reward models (RMs) are crucial for the training and inference-time scaling\nup of large language models (LLMs). However, existing reward models primarily\nfocus on human preferences, neglecting verifiable correctness signals which\nhave shown strong potential in training LLMs. In this paper, we propose agentic\nreward modeling, a reward system that combines reward models with verifiable\ncorrectness signals from different aspects to provide reliable rewards. We\nempirically implement a reward agent, named RewardAgent, that combines human\npreference rewards with two verifiable signals: factuality and instruction\nfollowing, to provide more reliable rewards. We conduct comprehensive\nexperiments on existing reward model benchmarks and inference time best-of-n\nsearches on real-world downstream tasks. RewardAgent significantly outperforms\nvanilla reward models, demonstrating its effectiveness. We further construct\ntraining preference pairs using RewardAgent and train an LLM with the DPO\nobjective, achieving superior performance on various NLP benchmarks compared to\nconventional reward models. Our codes are publicly released to facilitate\nfurther research (https://github.com/THU-KEG/Agentic-Reward-Modeling).",
      "pdf_url": "http://arxiv.org/pdf/2502.19328v1",
      "published": "2025-02-26T17:19:12+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.19328v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Partition Tree Weighting for Non-Stationary Stochastic Bandits",
      "authors": [
        "Joel Veness",
        "Marcus Hutter",
        "Andras Gyorgy",
        "Jordi Grau-Moya"
      ],
      "abstract": "This paper considers a generalisation of universal source coding for\ninteraction data, namely data streams that have actions interleaved with\nobservations. Our goal will be to construct a coding distribution that is both\nuniversal \\emph{and} can be used as a control policy. Allowing for action\ngeneration needs careful treatment, as naive approaches which do not\ndistinguish between actions and observations run into the self-delusion problem\nin universal settings. We showcase our perspective in the context of the\nchallenging non-stationary stochastic Bernoulli bandit problem. Our main\ncontribution is an efficient and high performing algorithm for this problem\nthat generalises the Partition Tree Weighting universal source coding technique\nfor passive prediction to the control setting.",
      "pdf_url": "http://arxiv.org/pdf/2502.19325v1",
      "published": "2025-02-26T17:16:33+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.19325v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Shh, don't say that! Domain Certification in LLMs",
      "authors": [
        "Cornelius Emde",
        "Alasdair Paren",
        "Preetham Arvind",
        "Maxime Kayser",
        "Tom Rainforth",
        "Thomas Lukasiewicz",
        "Bernard Ghanem",
        "Philip H. S. Torr",
        "Adel Bibi"
      ],
      "abstract": "Large language models (LLMs) are often deployed to perform constrained tasks,\nwith narrow domains. For example, customer support bots can be built on top of\nLLMs, relying on their broad language understanding and capabilities to enhance\nperformance. However, these LLMs are adversarially susceptible, potentially\ngenerating outputs outside the intended domain. To formalize, assess, and\nmitigate this risk, we introduce domain certification; a guarantee that\naccurately characterizes the out-of-domain behavior of language models. We then\npropose a simple yet effective approach, which we call VALID that provides\nadversarial bounds as a certificate. Finally, we evaluate our method across a\ndiverse set of datasets, demonstrating that it yields meaningful certificates,\nwhich bound the probability of out-of-domain samples tightly with minimum\npenalty to refusal behavior.",
      "pdf_url": "http://arxiv.org/pdf/2502.19320v1",
      "published": "2025-02-26T17:13:19+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.19320v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR",
        "cs.LG",
        "stat.ML"
      ]
    },
    {
      "title": "FSPO: Few-Shot Preference Optimization of Synthetic Preference Data in LLMs Elicits Effective Personalization to Real Users",
      "authors": [
        "Anikait Singh",
        "Sheryl Hsu",
        "Kyle Hsu",
        "Eric Mitchell",
        "Stefano Ermon",
        "Tatsunori Hashimoto",
        "Archit Sharma",
        "Chelsea Finn"
      ],
      "abstract": "Effective personalization of LLMs is critical for a broad range of\nuser-interfacing applications such as virtual assistants and content curation.\nInspired by the strong in-context learning capabilities of LLMs, we propose\nFew-Shot Preference Optimization (FSPO), which reframes reward modeling as a\nmeta-learning problem. Under this framework, an LLM learns to quickly adapt to\na user via a few labeled preferences from that user, constructing a\npersonalized reward function for them. Additionally, since real-world\npreference data is scarce and challenging to collect at scale, we propose\ncareful design choices to construct synthetic preference datasets for\npersonalization, generating over 1M synthetic personalized preferences using\npublicly available LLMs. In particular, to successfully transfer from synthetic\ndata to real users, we find it crucial for the data to exhibit both high\ndiversity and coherent, self-consistent structure. We evaluate FSPO on\npersonalized open-ended generation for up to 1,500 synthetic users across\nacross three domains: movie reviews, pedagogical adaptation based on\neducational background, and general question answering, along with a controlled\nhuman study. Overall, FSPO achieves an 87% Alpaca Eval winrate on average in\ngenerating responses that are personalized to synthetic users and a 72% winrate\nwith real human users in open-ended question answering.",
      "pdf_url": "http://arxiv.org/pdf/2502.19312v1",
      "published": "2025-02-26T17:08:46+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.19312v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "stat.ML"
      ]
    },
    {
      "title": "Faithful Logic Embeddings in HOL -- A recipe to have it all: deep and shallow, automated and interactive, heavy and light, proofs and counterexamples, meta and object level",
      "authors": [
        "Christoph Benzmüller"
      ],
      "abstract": "Deep and shallow embeddings of non-classical logics in classical higher-order\nlogic have been explored, implemented, and used in various automated reasoning\ntools in recent years. This paper presents a recipe for the simultaneous\ndeployment of different forms of deep and shallow embeddings in classical\nhigher-order logic, enabling not only flexible interactive and automated\ntheorem proving and counterexample finding at meta and object level, but also\nautomated faithfulness proofs between the logic embeddings. The approach, which\nis fruitful for logic education, research and application, is deliberately\nillustrated here using simple propositional modal logic. However, the work\npresented is conceptual in nature and not limited to such a simple logic\ncontext.",
      "pdf_url": "http://arxiv.org/pdf/2502.19311v1",
      "published": "2025-02-26T17:08:07+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.19311v1",
      "categories": [
        "cs.LO",
        "cs.AI",
        "cs.MS",
        "math.LO",
        "03Axx, 03Bxx, 03B15, 68T15",
        "F.4; I.2.3; I.2.4"
      ]
    },
    {
      "title": "WOFOSTGym: A Crop Simulator for Learning Annual and Perennial Crop Management Strategies",
      "authors": [
        "William Solow",
        "Sandhya Saisubramanian",
        "Alan Fern"
      ],
      "abstract": "We introduce WOFOSTGym, a novel crop simulation environment designed to train\nreinforcement learning (RL) agents to optimize agromanagement decisions for\nannual and perennial crops in single and multi-farm settings. Effective crop\nmanagement requires optimizing yield and economic returns while minimizing\nenvironmental impact, a complex sequential decision-making problem well suited\nfor RL. However, the lack of simulators for perennial crops in multi-farm\ncontexts has hindered RL applications in this domain. Existing crop simulators\nalso do not support multiple annual crops. WOFOSTGym addresses these gaps by\nsupporting 23 annual crops and two perennial crops, enabling RL agents to learn\ndiverse agromanagement strategies in multi-year, multi-crop, and multi-farm\nsettings. Our simulator offers a suite of challenging tasks for learning under\npartial observability, non-Markovian dynamics, and delayed feedback.\nWOFOSTGym's standard RL interface allows researchers without agricultural\nexpertise to explore a wide range of agromanagement problems. Our experiments\ndemonstrate the learned behaviors across various crop varieties and soil types,\nhighlighting WOFOSTGym's potential for advancing RL-driven decision support in\nagriculture.",
      "pdf_url": "http://arxiv.org/pdf/2502.19308v1",
      "published": "2025-02-26T17:07:11+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.19308v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Anomaly Detection in Complex Dynamical Systems: A Systematic Framework Using Embedding Theory and Physics-Inspired Consistency",
      "authors": [
        "Michael Somma",
        "Thomas Gallien",
        "Branka Stojanovic"
      ],
      "abstract": "Anomaly detection in complex dynamical systems is essential for ensuring\nreliability, safety, and efficiency in industrial and cyber-physical\ninfrastructures. Predictive maintenance helps prevent costly failures, while\ncybersecurity monitoring has become critical as digitized systems face growing\nthreats. Many of these systems exhibit oscillatory behaviors and bounded\nmotion, requiring anomaly detection methods that capture structured temporal\ndependencies while adhering to physical consistency principles. In this work,\nwe propose a system-theoretic approach to anomaly detection, grounded in\nclassical embedding theory and physics-inspired consistency principles. We\nbuild upon the Fractal Whitney Embedding Prevalence Theorem, extending\ntraditional embedding techniques to complex system dynamics. Additionally, we\nintroduce state-derivative pairs as an embedding strategy to capture system\nevolution. To enforce temporal coherence, we develop a Temporal Differential\nConsistency Autoencoder (TDC-AE), incorporating a TDC-Loss that aligns the\napproximated derivatives of latent variables with their dynamic\nrepresentations. We evaluate our method on the C-MAPSS dataset, a benchmark for\nturbofan aeroengine degradation. TDC-AE outperforms LSTMs and Transformers\nwhile achieving a 200x reduction in MAC operations, making it particularly\nsuited for lightweight edge computing. Our findings support the hypothesis that\nanomalies disrupt stable system dynamics, providing a robust, interpretable\nsignal for anomaly detection.",
      "pdf_url": "http://arxiv.org/pdf/2502.19307v1",
      "published": "2025-02-26T17:06:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.19307v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Corporate Fraud Detection in Rich-yet-Noisy Financial Graph",
      "authors": [
        "Shiqi Wang",
        "Zhibo Zhang",
        "Libing Fang",
        "Cam-Tu Nguyen",
        "Wenzhon Li"
      ],
      "abstract": "Corporate fraud detection aims to automatically recognize companies that\nconduct wrongful activities such as fraudulent financial statements or illegal\ninsider trading. Previous learning-based methods fail to effectively integrate\nrich interactions in the company network. To close this gap, we collect 18-year\nfinancial records in China to form three graph datasets with fraud labels. We\nanalyze the characteristics of the financial graphs, highlighting two\npronounced issues: (1) information overload: the dominance of (noisy)\nnon-company nodes over company nodes hinders the message-passing process in\nGraph Convolution Networks (GCN); and (2) hidden fraud: there exists a large\npercentage of possible undetected violations in the collected data. The hidden\nfraud problem will introduce noisy labels in the training dataset and\ncompromise fraud detection results. To handle such challenges, we propose a\nnovel graph-based method, namely, Knowledge-enhanced GCN with Robust Two-stage\nLearning (${\\rm KeGCN}_{R}$), which leverages Knowledge Graph Embeddings to\nmitigate the information overload and effectively learns rich representations.\nThe proposed model adopts a two-stage learning method to enhance robustness\nagainst hidden frauds. Extensive experimental results not only confirm the\nimportance of interactions but also show the superiority of ${\\rm KeGCN}_{R}$\nover a number of strong baselines in terms of fraud detection effectiveness and\nrobustness.",
      "pdf_url": "http://arxiv.org/pdf/2502.19305v1",
      "published": "2025-02-26T17:05:54+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.19305v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-fin.RM",
        "q-fin.ST"
      ]
    },
    {
      "title": "Combining Planning and Reinforcement Learning for Solving Relational Multiagent Domains",
      "authors": [
        "Nikhilesh Prabhakar",
        "Ranveer Singh",
        "Harsha Kokel",
        "Sriraam Natarajan",
        "Prasad Tadepalli"
      ],
      "abstract": "Multiagent Reinforcement Learning (MARL) poses significant challenges due to\nthe exponential growth of state and action spaces and the non-stationary nature\nof multiagent environments. This results in notable sample inefficiency and\nhinders generalization across diverse tasks. The complexity is further\npronounced in relational settings, where domain knowledge is crucial but often\nunderutilized by existing MARL algorithms. To overcome these hurdles, we\npropose integrating relational planners as centralized controllers with\nefficient state abstractions and reinforcement learning. This approach proves\nto be sample-efficient and facilitates effective task transfer and\ngeneralization.",
      "pdf_url": "http://arxiv.org/pdf/2502.19297v1",
      "published": "2025-02-26T16:55:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.19297v1",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Complex LLM Planning via Automated Heuristics Discovery",
      "authors": [
        "Hongyi Ling",
        "Shubham Parashar",
        "Sambhav Khurana",
        "Blake Olson",
        "Anwesha Basu",
        "Gaurangi Sinha",
        "Zhengzhong Tu",
        "James Caverlee",
        "Shuiwang Ji"
      ],
      "abstract": "We consider enhancing large language models (LLMs) for complex planning\ntasks. While existing methods allow LLMs to explore intermediate steps to make\nplans, they either depend on unreliable self-verification or external verifiers\nto evaluate these steps, which demand significant data and computations. Here,\nwe propose automated heuristics discovery (AutoHD), a novel approach that\nenables LLMs to explicitly generate heuristic functions to guide inference-time\nsearch, allowing accurate evaluation of intermediate states. These heuristic\nfunctions are further refined through a heuristic evolution process, improving\ntheir robustness and effectiveness. Our proposed method requires no additional\nmodel training or fine-tuning, and the explicit definition of heuristic\nfunctions generated by the LLMs provides interpretability and insights into the\nreasoning process. Extensive experiments across diverse benchmarks demonstrate\nsignificant gains over multiple baselines, including nearly twice the accuracy\non some datasets, establishing our approach as a reliable and interpretable\nsolution for complex planning tasks.",
      "pdf_url": "http://arxiv.org/pdf/2502.19295v1",
      "published": "2025-02-26T16:52:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.19295v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Integrating Biological and Machine Intelligence: Attention Mechanisms in Brain-Computer Interfaces",
      "authors": [
        "Jiyuan Wang",
        "Weishan Ye",
        "Jialin He",
        "Li Zhang",
        "Gan Huang",
        "Zhuliang Yu",
        "Zhen Liang"
      ],
      "abstract": "With the rapid advancement of deep learning, attention mechanisms have become\nindispensable in electroencephalography (EEG) signal analysis, significantly\nenhancing Brain-Computer Interface (BCI) applications. This paper presents a\ncomprehensive review of traditional and Transformer-based attention mechanisms,\ntheir embedding strategies, and their applications in EEG-based BCI, with a\nparticular emphasis on multimodal data fusion. By capturing EEG variations\nacross time, frequency, and spatial channels, attention mechanisms improve\nfeature extraction, representation learning, and model robustness. These\nmethods can be broadly categorized into traditional attention mechanisms, which\ntypically integrate with convolutional and recurrent networks, and\nTransformer-based multi-head self-attention, which excels in capturing\nlong-range dependencies. Beyond single-modality analysis, attention mechanisms\nalso enhance multimodal EEG applications, facilitating effective fusion between\nEEG and other physiological or sensory data. Finally, we discuss existing\nchallenges and emerging trends in attention-based EEG modeling, highlighting\nfuture directions for advancing BCI technology. This review aims to provide\nvaluable insights for researchers seeking to leverage attention mechanisms for\nimproved EEG interpretation and application.",
      "pdf_url": "http://arxiv.org/pdf/2502.19281v1",
      "published": "2025-02-26T16:38:28+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.19281v1",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Multiview graph dual-attention deep learning and contrastive learning for multi-criteria recommender systems",
      "authors": [
        "Saman Forouzandeh",
        "Pavel N. Krivitsky",
        "Rohitash Chandra"
      ],
      "abstract": "Recommender systems leveraging deep learning models have been crucial for\nassisting users in selecting items aligned with their preferences and\ninterests. However, a significant challenge persists in single-criteria\nrecommender systems, which often overlook the diverse attributes of items that\nhave been addressed by Multi-Criteria Recommender Systems (MCRS). Shared\nembedding vector for multi-criteria item ratings but have struggled to capture\nthe nuanced relationships between users and items based on specific criteria.\nIn this study, we present a novel representation for Multi-Criteria Recommender\nSystems (MCRS) based on a multi-edge bipartite graph, where each edge\nrepresents one criterion rating of items by users, and Multiview Dual Graph\nAttention Networks (MDGAT). Employing MDGAT is beneficial and important for\nadequately considering all relations between users and items, given the\npresence of both local (criterion-based) and global (multi-criteria) relations.\nAdditionally, we define anchor points in each view based on similarity and\nemploy local and global contrastive learning to distinguish between positive\nand negative samples across each view and the entire graph. We evaluate our\nmethod on two real-world datasets and assess its performance based on item\nrating predictions. The results demonstrate that our method achieves higher\naccuracy compared to the baseline method for predicting item ratings on the\nsame datasets. MDGAT effectively capture the local and global impact of\nneighbours and the similarity between nodes.",
      "pdf_url": "http://arxiv.org/pdf/2502.19271v1",
      "published": "2025-02-26T16:25:58+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.19271v1",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ]
    },
    {
      "title": "Drop-Upcycling: Training Sparse Mixture of Experts with Partial Re-initialization",
      "authors": [
        "Taishi Nakamura",
        "Takuya Akiba",
        "Kazuki Fujii",
        "Yusuke Oda",
        "Rio Yokota",
        "Jun Suzuki"
      ],
      "abstract": "The Mixture of Experts (MoE) architecture reduces the training and inference\ncost significantly compared to a dense model of equivalent capacity. Upcycling\nis an approach that initializes and trains an MoE model using a pre-trained\ndense model. While upcycling leads to initial performance gains, the training\nprogresses slower than when trained from scratch, leading to suboptimal\nperformance in the long term. We propose Drop-Upcycling - a method that\neffectively addresses this problem. Drop-Upcycling combines two seemingly\ncontradictory approaches: utilizing the knowledge of pre-trained dense models\nwhile statistically re-initializing some parts of the weights. This approach\nstrategically promotes expert specialization, significantly enhancing the MoE\nmodel's efficiency in knowledge acquisition. Extensive large-scale experiments\ndemonstrate that Drop-Upcycling significantly outperforms previous MoE\nconstruction methods in the long term, specifically when training on hundreds\nof billions of tokens or more. As a result, our MoE model with 5.9B active\nparameters achieves comparable performance to a 13B dense model in the same\nmodel family, while requiring approximately 1/4 of the training FLOPs. All\nexperimental resources, including source code, training data, model checkpoints\nand logs, are publicly available to promote reproducibility and future research\non MoE.",
      "pdf_url": "http://arxiv.org/pdf/2502.19261v1",
      "published": "2025-02-26T16:06:36+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.19261v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "EMT: A Visual Multi-Task Benchmark Dataset for Autonomous Driving in the Arab Gulf Region",
      "authors": [
        "Nadya Abdel Madjid",
        "Murad Mebrahtu",
        "Abdelmoamen Nasser",
        "Bilal Hassan",
        "Naoufel Werghi",
        "Jorge Dias",
        "Majid Khonji"
      ],
      "abstract": "This paper introduces the Emirates Multi-Task (EMT) dataset - the first\npublicly available dataset for autonomous driving collected in the Arab Gulf\nregion. The EMT dataset captures the unique road topology, high traffic\ncongestion, and distinctive characteristics of the Gulf region, including\nvariations in pedestrian clothing and weather conditions. It contains over\n30,000 frames from a dash-camera perspective, along with 570,000 annotated\nbounding boxes, covering approximately 150 kilometers of driving routes. The\nEMT dataset supports three primary tasks: tracking, trajectory forecasting and\nintention prediction. Each benchmark dataset is complemented with corresponding\nevaluations: (1) multi-agent tracking experiments, focusing on multi-class\nscenarios and occlusion handling; (2) trajectory forecasting evaluation using\ndeep sequential and interaction-aware models; and (3) intention benchmark\nexperiments conducted for predicting agents intentions from observed\ntrajectories. The dataset is publicly available at\nhttps://avlab.io/emt-dataset, and pre-processing scripts along with evaluation\nmodels can be accessed at https://github.com/AV-Lab/emt-dataset.",
      "pdf_url": "http://arxiv.org/pdf/2502.19260v1",
      "published": "2025-02-26T16:06:35+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.19260v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Poster: Long PHP webshell files detection based on sliding window attention",
      "authors": [
        "Zhiqiang Wang",
        "Haoyu Wang",
        "Lu Hao"
      ],
      "abstract": "Webshell is a type of backdoor, and web applications are widely exposed to\nwebshell injection attacks. Therefore, it is important to study webshell\ndetection techniques. In this study, we propose a webshell detection method. We\nfirst convert PHP source code to opcodes and then extract Opcode Double-Tuples\n(ODTs). Next, we combine CodeBert and FastText models for feature\nrepresentation and classification. To address the challenge that deep learning\nmethods have difficulty detecting long webshell files, we introduce a sliding\nwindow attention mechanism. This approach effectively captures malicious\nbehavior within long files. Experimental results show that our method reaches\nhigh accuracy in webshell detection, solving the problem of traditional methods\nthat struggle to address new webshell variants and anti-detection techniques.",
      "pdf_url": "http://arxiv.org/pdf/2502.19257v1",
      "published": "2025-02-26T16:04:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.19257v1",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "title": "Can RLHF be More Efficient with Imperfect Reward Models? A Policy Coverage Perspective",
      "authors": [
        "Jiawei Huang",
        "Bingcong Li",
        "Christoph Dann",
        "Niao He"
      ],
      "abstract": "Sample efficiency is critical for online Reinforcement Learning from Human\nFeedback (RLHF). While existing works investigate sample-efficient online\nexploration strategies, the potential of utilizing misspecified yet relevant\nreward models to accelerate learning remains underexplored. This paper studies\nhow to transfer knowledge from those imperfect reward models in online RLHF. We\nstart by identifying a novel property of the KL-regularized RLHF objective:\n\\emph{a policy's ability to cover the optimal policy is captured by its\nsub-optimality}. Building on this insight, we propose a theoretical transfer\nlearning algorithm with provable benefits compared to standard online learning.\nOur approach achieves low regret in the early stage by quickly adapting to the\nbest available source reward models without prior knowledge of their quality,\nand over time, it attains an $\\tilde{O}(\\sqrt{T})$ regret bound\n\\emph{independent} of structural complexity measures. Inspired by our\ntheoretical findings, we develop an empirical algorithm with improved\ncomputational efficiency, and demonstrate its effectiveness empirically in\nsummarization tasks.",
      "pdf_url": "http://arxiv.org/pdf/2502.19255v1",
      "published": "2025-02-26T16:03:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.19255v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ]
    },
    {
      "title": "GraphBridge: Towards Arbitrary Transfer Learning in GNNs",
      "authors": [
        "Li Ju",
        "Xingyi Yang",
        "Qi Li",
        "Xinchao Wang"
      ],
      "abstract": "Graph neural networks (GNNs) are conventionally trained on a per-domain,\nper-task basis. It creates a significant barrier in transferring the acquired\nknowledge to different, heterogeneous data setups. This paper introduces\nGraphBridge, a novel framework to enable knowledge transfer across disparate\ntasks and domains in GNNs, circumventing the need for modifications to task\nconfigurations or graph structures. Specifically, GraphBridge allows for the\naugmentation of any pre-trained GNN with prediction heads and a bridging\nnetwork that connects the input to the output layer. This architecture not only\npreserves the intrinsic knowledge of the original model but also supports\noutputs of arbitrary dimensions. To mitigate the negative transfer problem,\nGraphBridg merges the source model with a concurrently trained model, thereby\nreducing the source bias when applied to the target domain. Our method is\nthoroughly evaluated across diverse transfer learning scenarios, including\nGraph2Graph, Node2Node, Graph2Node, and graph2point-cloud. Empirical\nvalidation, conducted over 16 datasets representative of these scenarios,\nconfirms the framework's capacity for task- and domain-agnostic transfer\nlearning within graph-like data, marking a significant advancement in the field\nof GNNs.",
      "pdf_url": "http://arxiv.org/pdf/2502.19252v1",
      "published": "2025-02-26T15:57:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.19252v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Between Circuits and Chomsky: Pre-pretraining on Formal Languages Imparts Linguistic Biases",
      "authors": [
        "Michael Y. Hu",
        "Jackson Petty",
        "Chuan Shi",
        "William Merrill",
        "Tal Linzen"
      ],
      "abstract": "Pretraining language models on formal languages can improve their acquisition\nof natural language, but it is unclear which features of the formal language\nimpart an inductive bias that leads to effective transfer. Drawing on insights\nfrom linguistics and complexity theory, we hypothesize that effective transfer\noccurs when the formal language both captures dependency structures in natural\nlanguage and remains within the computational limitations of the model\narchitecture. Focusing on transformers, we find that formal languages with both\nthese properties enable language models to achieve lower loss on natural\nlanguage and better linguistic generalization compared to other languages. In\nfact, pre-pretraining, or training on formal-then-natural language, reduces\nloss more efficiently than the same amount of natural language. For a\n1B-parameter language model trained on roughly 1.6B tokens of natural language,\npre-pretraining achieves the same loss and better linguistic generalization\nwith a 33% smaller token budget. We also give mechanistic evidence of\ncross-task transfer from formal to natural language: attention heads acquired\nduring formal language pretraining remain crucial for the model's performance\non syntactic evaluations.",
      "pdf_url": "http://arxiv.org/pdf/2502.19249v1",
      "published": "2025-02-26T15:55:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.19249v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "AI-Powered Bayesian Inference",
      "authors": [
        "Veronika Ročková",
        "Sean O'Hagan"
      ],
      "abstract": "The advent of Generative Artificial Intelligence (GAI) has heralded an\ninflection point that changed how society thinks about knowledge acquisition.\nWhile GAI cannot be fully trusted for decision-making, it may still provide\nvaluable information that can be integrated into a decision pipeline. Rather\nthan seeing the lack of certitude and inherent randomness of GAI as a problem,\nwe view it as an opportunity. Indeed, variable answers to given prompts can be\nleveraged to construct a prior distribution which reflects assuredness of AI\npredictions. This prior distribution may be combined with tailored datasets for\na fully Bayesian analysis with an AI-driven prior. In this paper, we explore\nsuch a possibility within a non-parametric Bayesian framework. The basic idea\nconsists of assigning a Dirichlet process prior distribution on the\ndata-generating distribution with AI generative model as its baseline.\nHyper-parameters of the prior can be tuned out-of-sample to assess the\ninformativeness of the AI prior. Posterior simulation is achieved by computing\na suitably randomized functional on an augmented data that consists of observed\n(labeled) data as well as fake data whose labels have been imputed using AI.\nThis strategy can be parallelized and rapidly produces iid samples from the\nposterior by optimization as opposed to sampling from conditionals. Our method\nenables (predictive) inference and uncertainty quantification leveraging AI\npredictions in a coherent probabilistic manner.",
      "pdf_url": "http://arxiv.org/pdf/2502.19231v1",
      "published": "2025-02-26T15:42:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.19231v1",
      "categories": [
        "stat.ME",
        "cs.AI",
        "stat.ML"
      ]
    },
    {
      "title": "Enhancing the Scalability and Applicability of Kohn-Sham Hamiltonians for Molecular Systems",
      "authors": [
        "Yunyang Li",
        "Zaishuo Xia",
        "Lin Huang",
        "Xinran Wei",
        "Han Yang",
        "Sam Harshe",
        "Zun Wang",
        "Chang Liu",
        "Jia Zhang",
        "Bin Shao",
        "Mark B. Gerstein"
      ],
      "abstract": "Density Functional Theory (DFT) is a pivotal method within quantum chemistry\nand materials science, with its core involving the construction and solution of\nthe Kohn-Sham Hamiltonian. Despite its importance, the application of DFT is\nfrequently limited by the substantial computational resources required to\nconstruct the Kohn-Sham Hamiltonian. In response to these limitations, current\nresearch has employed deep-learning models to efficiently predict molecular and\nsolid Hamiltonians, with roto-translational symmetries encoded in their neural\nnetworks. However, the scalability of prior models may be problematic when\napplied to large molecules, resulting in non-physical predictions of\nground-state properties. In this study, we generate a substantially larger\ntraining set (PubChemQH) than used previously and use it to create a scalable\nmodel for DFT calculations with physical accuracy. For our model, we introduce\na loss function derived from physical principles, which we call Wavefunction\nAlignment Loss (WALoss). WALoss involves performing a basis change on the\npredicted Hamiltonian to align it with the observed one; thus, the resulting\ndifferences can serve as a surrogate for orbital energy differences, allowing\nmodels to make better predictions for molecular orbitals and total energies\nthan previously possible. WALoss also substantially accelerates\nself-consistent-field (SCF) DFT calculations. Here, we show it achieves a\nreduction in total energy prediction error by a factor of 1347 and an SCF\ncalculation speed-up by a factor of 18%. These substantial improvements set new\nbenchmarks for achieving accurate and applicable predictions in larger\nmolecular systems.",
      "pdf_url": "http://arxiv.org/pdf/2502.19227v1",
      "published": "2025-02-26T15:36:25+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.19227v1",
      "categories": [
        "physics.chem-ph",
        "cond-mat.mtrl-sci",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "A Lightweight and Extensible Cell Segmentation and Classification Model for Whole Slide Images",
      "authors": [
        "Nikita Shvetsov",
        "Thomas K. Kilvaer",
        "Masoud Tafavvoghi",
        "Anders Sildnes",
        "Kajsa Møllersen",
        "Lill-Tove Rasmussen Busund",
        "Lars Ailo Bongo"
      ],
      "abstract": "Developing clinically useful cell-level analysis tools in digital pathology\nremains challenging due to limitations in dataset granularity, inconsistent\nannotations, high computational demands, and difficulties integrating new\ntechnologies into workflows. To address these issues, we propose a solution\nthat enhances data quality, model performance, and usability by creating a\nlightweight, extensible cell segmentation and classification model. First, we\nupdate data labels through cross-relabeling to refine annotations of PanNuke\nand MoNuSAC, producing a unified dataset with seven distinct cell types.\nSecond, we leverage the H-Optimus foundation model as a fixed encoder to\nimprove feature representation for simultaneous segmentation and classification\ntasks. Third, to address foundation models' computational demands, we distill\nknowledge to reduce model size and complexity while maintaining comparable\nperformance. Finally, we integrate the distilled model into QuPath, a widely\nused open-source digital pathology platform. Results demonstrate improved\nsegmentation and classification performance using the H-Optimus-based model\ncompared to a CNN-based model. Specifically, average $R^2$ improved from 0.575\nto 0.871, and average $PQ$ score improved from 0.450 to 0.492, indicating\nbetter alignment with actual cell counts and enhanced segmentation quality. The\ndistilled model maintains comparable performance while reducing parameter count\nby a factor of 48. By reducing computational complexity and integrating into\nworkflows, this approach may significantly impact diagnostics, reduce\npathologist workload, and improve outcomes. Although the method shows promise,\nextensive validation is necessary prior to clinical deployment.",
      "pdf_url": "http://arxiv.org/pdf/2502.19217v1",
      "published": "2025-02-26T15:19:52+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.19217v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.4.6; I.4.9; I.2.10"
      ]
    },
    {
      "title": "FaithUn: Toward Faithful Forgetting in Language Models by Investigating the Interconnectedness of Knowledge",
      "authors": [
        "Nakyeong Yang",
        "Minsung Kim",
        "Seunghyun Yoon",
        "Joongbo Shin",
        "Kyomin Jung"
      ],
      "abstract": "Various studies have attempted to remove sensitive or private knowledge from\na language model to prevent its unauthorized exposure. However, prior studies\nhave overlooked the complex and interconnected nature of knowledge, where\nrelated knowledge must be carefully examined. Specifically, they have failed to\nevaluate whether an unlearning method faithfully erases interconnected\nknowledge that should be removed, retaining knowledge that appears relevant but\nexists in a completely different context. To resolve this problem, we first\ndefine a new concept called superficial unlearning, which refers to the\nphenomenon where an unlearning method either fails to erase the interconnected\nknowledge it should remove or unintentionally erases irrelevant knowledge.\nBased on the definition, we introduce a new benchmark, FaithUn, to analyze and\nevaluate the faithfulness of unlearning in real-world knowledge QA settings.\nFurthermore, we propose a novel unlearning method, KLUE, which updates only\nknowledge-related neurons to achieve faithful unlearning. KLUE identifies\nknowledge neurons using an explainability method and updates only those neurons\nusing selected unforgotten samples. Experimental results demonstrate that\nwidely-used unlearning methods fail to ensure faithful unlearning, while our\nmethod shows significant effectiveness in real-world QA unlearning.",
      "pdf_url": "http://arxiv.org/pdf/2502.19207v1",
      "published": "2025-02-26T15:11:03+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.19207v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "EGR-Net: A Novel Embedding Gramian Representation CNN for Intelligent Fault Diagnosis",
      "authors": [
        "Linshan Jia"
      ],
      "abstract": "Feature extraction is crucial in intelligent fault diagnosis of rotating\nmachinery. It is easier for convolutional neural networks(CNNs) to visually\nrecognize and learn fault features by converting the complicated\none-dimensional (1D) vibrational signals into two-dimensional (2D) images with\nsimple textures. However, the existing representation methods for encoding 1D\nsignals as images have two main problems, including complicated computation and\nlow separability. Meanwhile, the existing 2D-CNN fault diagnosis methods taking\n2D images as the only inputs still suffer from the inevitable information loss\nbecause of the conversion process. Considering the above issues, this paper\nproposes a new 1D-to-2D conversion method called Embedding Gramian\nRepresentation (EGR), which is easy to calculate and shows good separability.\nIn EGR, 1D signals are projected in the embedding space and the intrinsic\nperiodicity of vibrational signals is captured enabling the faulty\ncharacteristics contained in raw signals to be uncovered. Second, aiming at the\ninformation loss problem of existing CNN models with the single input of\nconverted images, a double-branch EGR-based CNN, called EGR-Net, is proposed to\nlearn faulty features from both raw signal feature maps and their corresponding\nEGRs. The bridge connection is designed to improve the feature learning\ninteraction between the two branches. Widely used open domain gearbox dataset\nand bearing dataset are used to verify the effectiveness and efficiency of the\nproposed methods. EGR-Net is compared with traditional and state-of-the-art\napproaches, and the results show that the proposed method can deliver enhanced\nperformance.",
      "pdf_url": "http://arxiv.org/pdf/2502.19199v1",
      "published": "2025-02-26T15:05:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.19199v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Simulation of Language Evolution under Regulated Social Media Platforms: A Synergistic Approach of Large Language Models and Genetic Algorithms",
      "authors": [
        "Jinyu Cai",
        "Yusei Ishimizu",
        "Mingyue Zhang",
        "Munan Li",
        "Jialong Li",
        "Kenji Tei"
      ],
      "abstract": "Social media platforms frequently impose restrictive policies to moderate\nuser content, prompting the emergence of creative evasion language strategies.\nThis paper presents a multi-agent framework based on Large Language Models\n(LLMs) to simulate the iterative evolution of language strategies under\nregulatory constraints. In this framework, participant agents, as social media\nusers, continuously evolve their language expression, while supervisory agents\nemulate platform-level regulation by assessing policy violations. To achieve a\nmore faithful simulation, we employ a dual design of language strategies\n(constraint and expression) to differentiate conflicting goals and utilize an\nLLM-driven GA (Genetic Algorithm) for the selection, mutation, and crossover of\nlanguage strategies. The framework is evaluated using two distinct scenarios:\nan abstract password game and a realistic simulated illegal pet trade scenario.\nExperimental results demonstrate that as the number of dialogue rounds\nincreases, both the number of uninterrupted dialogue turns and the accuracy of\ninformation transmission improve significantly. Furthermore, a user study with\n40 participants validates the real-world relevance of the generated dialogues\nand strategies. Moreover, ablation studies validate the importance of the GA,\nemphasizing its contribution to long-term adaptability and improved overall\nresults.",
      "pdf_url": "http://arxiv.org/pdf/2502.19193v1",
      "published": "2025-02-26T14:59:27+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.19193v1",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.NE"
      ]
    },
    {
      "title": "Provocations from the Humanities for Generative AI Research",
      "authors": [
        "Lauren Klein",
        "Meredith Martin",
        "André Brock",
        "Maria Antoniak",
        "Melanie Walsh",
        "Jessica Marie Johnson",
        "Lauren Tilton",
        "David Mimno"
      ],
      "abstract": "This paper presents a set of provocations for considering the uses, impact,\nand harms of generative AI from the perspective of humanities researchers. We\nprovide a working definition of humanities research, summarize some of its most\nsalient theories and methods, and apply these theories and methods to the\ncurrent landscape of AI. Drawing from foundational work in critical data\nstudies, along with relevant humanities scholarship, we elaborate eight claims\nwith broad applicability to current conversations about generative AI: 1)\nModels make words, but people make meaning; 2) Generative AI requires an\nexpanded definition of culture; 3) Generative AI can never be representative;\n4) Bigger models are not always better models; 5) Not all training data is\nequivalent; 6) Openness is not an easy fix; 7) Limited access to compute\nenables corporate capture; and 8) AI universalism creates narrow human\nsubjects. We conclude with a discussion of the importance of resisting the\nextraction of humanities research by computer science and related fields.",
      "pdf_url": "http://arxiv.org/pdf/2502.19190v1",
      "published": "2025-02-26T14:55:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.19190v1",
      "categories": [
        "cs.CY",
        "cs.AI",
        "I.2.0; K.4.0"
      ]
    },
    {
      "title": "AutoML for Multi-Class Anomaly Compensation of Sensor Drift",
      "authors": [
        "Melanie Schaller",
        "Mathis Kruse",
        "Antonio Ortega",
        "Marius Lindauer",
        "Bodo Rosenhahn"
      ],
      "abstract": "Addressing sensor drift is essential in industrial measurement systems, where\nprecise data output is necessary for maintaining accuracy and reliability in\nmonitoring processes, as it progressively degrades the performance of machine\nlearning models over time. Our findings indicate that the standard\ncross-validation method used in existing model training overestimates\nperformance by inadequately accounting for drift. This is primarily because\ntypical cross-validation techniques allow data instances to appear in both\ntraining and testing sets, thereby distorting the accuracy of the predictive\nevaluation. As a result, these models are unable to precisely predict future\ndrift effects, compromising their ability to generalize and adapt to evolving\ndata conditions. This paper presents two solutions: (1) a novel sensor drift\ncompensation learning paradigm for validating models, and (2) automated machine\nlearning (AutoML) techniques to enhance classification performance and\ncompensate sensor drift. By employing strategies such as data balancing,\nmeta-learning, automated ensemble learning, hyperparameter optimization,\nfeature selection, and boosting, our AutoML-DC (Drift Compensation) model\nsignificantly improves classification performance against sensor drift.\nAutoML-DC further adapts effectively to varying drift severities.",
      "pdf_url": "http://arxiv.org/pdf/2502.19180v1",
      "published": "2025-02-26T14:34:53+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.19180v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "MEDDxAgent: A Unified Modular Agent Framework for Explainable Automatic Differential Diagnosis",
      "authors": [
        "Daniel Rose",
        "Chia-Chien Hung",
        "Marco Lepri",
        "Israa Alqassem",
        "Kiril Gashteovski",
        "Carolin Lawrence"
      ],
      "abstract": "Differential Diagnosis (DDx) is a fundamental yet complex aspect of clinical\ndecision-making, in which physicians iteratively refine a ranked list of\npossible diseases based on symptoms, antecedents, and medical knowledge. While\nrecent advances in large language models have shown promise in supporting DDx,\nexisting approaches face key limitations, including single-dataset evaluations,\nisolated optimization of components, unrealistic assumptions about complete\npatient profiles, and single-attempt diagnosis. We introduce a Modular\nExplainable DDx Agent (MEDDxAgent) framework designed for interactive DDx,\nwhere diagnostic reasoning evolves through iterative learning, rather than\nassuming a complete patient profile is accessible. MEDDxAgent integrates three\nmodular components: (1) an orchestrator (DDxDriver), (2) a history taking\nsimulator, and (3) two specialized agents for knowledge retrieval and diagnosis\nstrategy. To ensure robust evaluation, we introduce a comprehensive DDx\nbenchmark covering respiratory, skin, and rare diseases. We analyze single-turn\ndiagnostic approaches and demonstrate the importance of iterative refinement\nwhen patient profiles are not available at the outset. Our broad evaluation\ndemonstrates that MEDDxAgent achieves over 10% accuracy improvements in\ninteractive DDx across both large and small LLMs, while offering critical\nexplainability into its diagnostic reasoning process.",
      "pdf_url": "http://arxiv.org/pdf/2502.19175v1",
      "published": "2025-02-26T14:31:43+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.19175v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "TestNUC: Enhancing Test-Time Computing Approaches through Neighboring Unlabeled Data Consistency",
      "authors": [
        "Henry Peng Zou",
        "Zhengyao Gu",
        "Yue Zhou",
        "Yankai Chen",
        "Weizhi Zhang",
        "Liancheng Fang",
        "Yibo Wang",
        "Yangning Li",
        "Kay Liu",
        "Philip S. Yu"
      ],
      "abstract": "Test-time computing approaches, which leverage additional computational\nresources during inference, have been proven effective in enhancing large\nlanguage model performance. This work introduces a novel, linearly scaling\napproach, TestNUC, that improves test-time predictions by leveraging the local\nconsistency of neighboring unlabeled data-it classifies an input instance by\nconsidering not only the model's prediction on that instance but also on\nneighboring unlabeled instances. We evaluate TestNUC across eight diverse\ndatasets, spanning intent classification, topic mining, domain discovery, and\nemotion detection, demonstrating its consistent superiority over baseline\nmethods such as standard prompting and self-consistency. Furthermore, TestNUC\ncan be seamlessly integrated with existing test-time computing approaches,\nsubstantially boosting their performance. Our analysis reveals that TestNUC\nscales effectively with increasing amounts of unlabeled data and performs\nrobustly across different embedding models, making it practical for real-world\napplications. Our code is available at https://github.com/HenryPengZou/TestNUC.",
      "pdf_url": "http://arxiv.org/pdf/2502.19163v1",
      "published": "2025-02-26T14:17:56+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.19163v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ]
    },
    {
      "title": "Detecting Linguistic Indicators for Stereotype Assessment with Large Language Models",
      "authors": [
        "Rebekka Görge",
        "Michael Mock",
        "Héctor Allende-Cid"
      ],
      "abstract": "Social categories and stereotypes are embedded in language and can introduce\ndata bias into Large Language Models (LLMs). Despite safeguards, these biases\noften persist in model behavior, potentially leading to representational harm\nin outputs. While sociolinguistic research provides valuable insights into the\nformation of stereotypes, NLP approaches for stereotype detection rarely draw\non this foundation and often lack objectivity, precision, and interpretability.\nTo fill this gap, in this work we propose a new approach that detects and\nquantifies the linguistic indicators of stereotypes in a sentence. We derive\nlinguistic indicators from the Social Category and Stereotype Communication\n(SCSC) framework which indicate strong social category formulation and\nstereotyping in language, and use them to build a categorization scheme. To\nautomate this approach, we instruct different LLMs using in-context learning to\napply the approach to a sentence, where the LLM examines the linguistic\nproperties and provides a basis for a fine-grained assessment. Based on an\nempirical evaluation of the importance of different linguistic indicators, we\nlearn a scoring function that measures the linguistic indicators of a\nstereotype. Our annotations of stereotyped sentences show that these indicators\nare present in these sentences and explain the strength of a stereotype. In\nterms of model performance, our results show that the models generally perform\nwell in detecting and classifying linguistic indicators of category labels used\nto denote a category, but sometimes struggle to correctly evaluate the\nassociated behaviors and characteristics. Using more few-shot examples within\nthe prompts, significantly improves performance. Model performance increases\nwith size, as Llama-3.3-70B-Instruct and GPT-4 achieve comparable results that\nsurpass those of Mixtral-8x7B-Instruct, GPT-4-mini and Llama-3.1-8B-Instruct.",
      "pdf_url": "http://arxiv.org/pdf/2502.19160v1",
      "published": "2025-02-26T14:15:28+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.19160v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "When Personalization Meets Reality: A Multi-Faceted Analysis of Personalized Preference Learning",
      "authors": [
        "Yijiang River Dong",
        "Tiancheng Hu",
        "Yinhong Liu",
        "Ahmet Üstün",
        "Nigel Collier"
      ],
      "abstract": "While Reinforcement Learning from Human Feedback (RLHF) is widely used to\nalign Large Language Models (LLMs) with human preferences, it typically assumes\nhomogeneous preferences across users, overlooking diverse human values and\nminority viewpoints. Although personalized preference learning addresses this\nby tailoring separate preferences for individual users, the field lacks\nstandardized methods to assess its effectiveness. We present a multi-faceted\nevaluation framework that measures not only performance but also fairness,\nunintended effects, and adaptability across varying levels of preference\ndivergence. Through extensive experiments comparing eight personalization\nmethods across three preference datasets, we demonstrate that performance\ndifferences between methods could reach 36% when users strongly disagree, and\npersonalization can introduce up to 20% safety misalignment. These findings\nhighlight the critical need for holistic evaluation approaches to advance the\ndevelopment of more effective and inclusive preference learning systems.",
      "pdf_url": "http://arxiv.org/pdf/2502.19158v1",
      "published": "2025-02-26T14:14:58+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.19158v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Multi-Agent Security Tax: Trading Off Security and Collaboration Capabilities in Multi-Agent Systems",
      "authors": [
        "Pierre Peigne-Lefebvre",
        "Mikolaj Kniejski",
        "Filip Sondej",
        "Matthieu David",
        "Jason Hoelscher-Obermaier",
        "Christian Schroeder de Witt",
        "Esben Kran"
      ],
      "abstract": "As AI agents are increasingly adopted to collaborate on complex objectives,\nensuring the security of autonomous multi-agent systems becomes crucial. We\ndevelop simulations of agents collaborating on shared objectives to study these\nsecurity risks and security trade-offs. We focus on scenarios where an attacker\ncompromises one agent, using it to steer the entire system toward misaligned\noutcomes by corrupting other agents. In this context, we observe infectious\nmalicious prompts - the multi-hop spreading of malicious instructions. To\nmitigate this risk, we evaluated several strategies: two \"vaccination\"\napproaches that insert false memories of safely handling malicious input into\nthe agents' memory stream, and two versions of a generic safety instruction\nstrategy. While these defenses reduce the spread and fulfillment of malicious\ninstructions in our experiments, they tend to decrease collaboration capability\nin the agent network. Our findings illustrate potential trade-off between\nsecurity and collaborative efficiency in multi-agent systems, providing\ninsights for designing more secure yet effective AI collaborations.",
      "pdf_url": "http://arxiv.org/pdf/2502.19145v1",
      "published": "2025-02-26T14:00:35+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.19145v1",
      "categories": [
        "cs.AI",
        "cs.MA"
      ]
    },
    {
      "title": "A Temporal Planning Framework for Multi-Agent Systems via LLM-Aided Knowledge Base Management",
      "authors": [
        "Enrico Saccon",
        "Ahmet Tikna",
        "Davide De Martini",
        "Edoardo Lamon",
        "Luigi Palopoli",
        "Marco Roveri"
      ],
      "abstract": "This paper presents a novel framework, called PLANTOR (PLanning with Natural\nlanguage for Task-Oriented Robots), that integrates Large Language Models\n(LLMs) with Prolog-based knowledge management and planning for multi-robot\ntasks. The system employs a two-phase generation of a robot-oriented knowledge\nbase, ensuring reusability and compositional reasoning, as well as a three-step\nplanning procedure that handles temporal dependencies, resource constraints,\nand parallel task execution via mixed-integer linear programming. The final\nplan is converted into a Behaviour Tree for direct use in ROS2. We tested the\nframework in multi-robot assembly tasks within a block world and an\narch-building scenario. Results demonstrate that LLMs can produce accurate\nknowledge bases with modest human feedback, while Prolog guarantees formal\ncorrectness and explainability. This approach underscores the potential of LLM\nintegration for advanced robotics tasks requiring flexible, scalable, and\nhuman-understandable planning.",
      "pdf_url": "http://arxiv.org/pdf/2502.19135v1",
      "published": "2025-02-26T13:51:28+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.19135v1",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.RO"
      ]
    },
    {
      "title": "Voting or Consensus? Decision-Making in Multi-Agent Debate",
      "authors": [
        "Lars Benedikt Kaesberg",
        "Jonas Becker",
        "Jan Philip Wahle",
        "Terry Ruas",
        "Bela Gipp"
      ],
      "abstract": "Much of the success of multi-agent debates depends on carefully choosing the\nright parameters. Among them, the decision-making protocol stands out.\nSystematic comparison of decision protocols is difficult because studies alter\nmultiple discussion parameters beyond the protocol. So far, it has been largely\nunknown how decision-making addresses the challenges of different tasks. This\nwork systematically evaluates the impact of seven decision protocols (e.g.,\nmajority voting, unanimity consensus). We change only one variable at a time\n(i.e., decision protocol) to analyze how different methods affect the\ncollaboration between agents and test different protocols on knowledge (MMLU,\nMMLU-Pro, GPQA) and reasoning datasets (StrategyQA, MuSR, SQuAD 2.0). Our\nresults show that voting protocols improve performance by 13.2% in reasoning\ntasks and consensus protocols by 2.8% in knowledge tasks over the other\ndecision protocol. Increasing the number of agents improves performance, while\nmore discussion rounds before voting reduces it. To improve decision-making by\nincreasing answer diversity, we propose two new methods, All-Agents Drafting\n(AAD) and Collective Improvement (CI). Our methods improve task performance by\nup to 3.3% with AAD and up to 7.4% with CI. This work demonstrates the\nimportance of decision-making in multi-agent debates beyond scaling.",
      "pdf_url": "http://arxiv.org/pdf/2502.19130v1",
      "published": "2025-02-26T13:39:18+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.19130v1",
      "categories": [
        "cs.MA",
        "cs.AI"
      ]
    },
    {
      "title": "From Traditional to Deep Learning Approaches in Whole Slide Image Registration: A Methodological Review",
      "authors": [
        "Behnaz Elhaminia",
        "Abdullah Alsalemi",
        "Esha Nasir",
        "Mostafa Jahanifar",
        "Ruqayya Awan",
        "Lawrence S. Young",
        "Nasir M. Rajpoot",
        "Fayyaz Minhas",
        "Shan E Ahmed Raza"
      ],
      "abstract": "Whole slide image (WSI) registration is an essential task for analysing the\ntumour microenvironment (TME) in histopathology. It involves the alignment of\nspatial information between WSIs of the same section or serial sections of a\ntissue sample. The tissue sections are usually stained with single or multiple\nbiomarkers before imaging, and the goal is to identify neighbouring nuclei\nalong the Z-axis for creating a 3D image or identifying subclasses of cells in\nthe TME. This task is considerably more challenging compared to radiology image\nregistration, such as magnetic resonance imaging or computed tomography, due to\nvarious factors. These include gigapixel size of images, variations in\nappearance between differently stained tissues, changes in structure and\nmorphology between non-consecutive sections, and the presence of artefacts,\ntears, and deformations. Currently, there is a noticeable gap in the literature\nregarding a review of the current approaches and their limitations, as well as\nthe challenges and opportunities they present. We aim to provide a\ncomprehensive understanding of the available approaches and their application\nfor various purposes. Furthermore, we investigate current deep learning methods\nused for WSI registration, emphasising their diverse methodologies. We examine\nthe available datasets and explore tools and software employed in the field.\nFinally, we identify open challenges and potential future trends in this area\nof research.",
      "pdf_url": "http://arxiv.org/pdf/2502.19123v1",
      "published": "2025-02-26T13:24:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.19123v1",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Chemical knowledge-informed framework for privacy-aware retrosynthesis learning",
      "authors": [
        "Guikun Chen",
        "Xu Zhang",
        "Yi Yang",
        "Wenguan Wang"
      ],
      "abstract": "Chemical reaction data is a pivotal asset, driving advances in competitive\nfields such as pharmaceuticals, materials science, and industrial chemistry.\nIts proprietary nature renders it sensitive, as it often includes confidential\ninsights and competitive advantages organizations strive to protect. However,\nin contrast to this need for confidentiality, the current standard training\nparadigm for machine learning-based retrosynthesis gathers reaction data from\nmultiple sources into one single edge to train prediction models. This paradigm\nposes considerable privacy risks as it necessitates broad data availability\nacross organizational boundaries and frequent data transmission between\nentities, potentially exposing proprietary information to unauthorized access\nor interception during storage and transfer. In the present study, we introduce\nthe chemical knowledge-informed framework (CKIF), a privacy-preserving approach\nfor learning retrosynthesis models. CKIF enables distributed training across\nmultiple chemical organizations without compromising the confidentiality of\nproprietary reaction data. Instead of gathering raw reaction data, CKIF learns\nretrosynthesis models through iterative, chemical knowledge-informed\naggregation of model parameters. In particular, the chemical properties of\npredicted reactants are leveraged to quantitatively assess the observable\nbehaviors of individual models, which in turn determines the adaptive weights\nused for model aggregation. On a variety of reaction datasets, CKIF outperforms\nseveral strong baselines by a clear margin (e.g., ~20% performance improvement\nover FedAvg on USPTO-50K), showing its feasibility and superiority to stimulate\nfurther research on privacy-preserving retrosynthesis.",
      "pdf_url": "http://arxiv.org/pdf/2502.19119v1",
      "published": "2025-02-26T13:13:24+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.19119v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Improving customer service with automatic topic detection in user emails",
      "authors": [
        "Bojana Bašaragin",
        "Darija Medvecki",
        "Gorana Gojić",
        "Milena Oparnica",
        "Dragiša Mišković"
      ],
      "abstract": "This study introduces a novel Natural Language Processing pipeline that\nenhances customer service efficiency at Telekom Srbija, a leading Serbian\ntelecommunications company, through automated email topic detection and\nlabelling. Central to the pipeline is BERTopic, a modular architecture that\nallows unsupervised topic modelling. After a series of preprocessing and\npost-processing steps, we assign one of 12 topics and several additional labels\nto incoming emails, allowing customer service to filter and access them through\na custom-made application. The model's performance was evaluated by assessing\nthe speed and correctness of the automatically assigned topics across a test\ndataset of 100 customer emails. The pipeline shows broad applicability across\nlanguages, particularly for those that are low-resourced and morphologically\nrich. The system now operates in the company's production environment,\nstreamlining customer service operations through automated email\nclassification.",
      "pdf_url": "http://arxiv.org/pdf/2502.19115v1",
      "published": "2025-02-26T13:10:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2502.19115v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    }
  ]
}