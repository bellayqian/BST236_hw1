{
  "last_updated": "2025-05-31T00:51:05.457404",
  "papers": [
    {
      "title": "From Chat Logs to Collective Insights: Aggregative Question Answering",
      "authors": [
        "Wentao Zhang",
        "Woojeong Kim",
        "Yuntian Deng"
      ],
      "abstract": "Conversational agents powered by large language models (LLMs) are rapidly\nbecoming integral to our daily interactions, generating unprecedented amounts\nof conversational data. Such datasets offer a powerful lens into societal\ninterests, trending topics, and collective concerns. Yet, existing approaches\ntypically treat these interactions as independent and miss critical insights\nthat could emerge from aggregating and reasoning across large-scale\nconversation logs. In this paper, we introduce Aggregative Question Answering,\na novel task requiring models to reason explicitly over thousands of\nuser-chatbot interactions to answer aggregative queries, such as identifying\nemerging concerns among specific demographics. To enable research in this\ndirection, we construct a benchmark, WildChat-AQA, comprising 6,027 aggregative\nquestions derived from 182,330 real-world chatbot conversations. Experiments\nshow that existing methods either struggle to reason effectively or incur\nprohibitive computational costs, underscoring the need for new approaches\ncapable of extracting collective insights from large-scale conversational data.",
      "pdf_url": "http://arxiv.org/pdf/2505.23765v1",
      "published": "2025-05-29T17:59:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.23765v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "ZeroGUI: Automating Online GUI Learning at Zero Human Cost",
      "authors": [
        "Chenyu Yang",
        "Shiqian Su",
        "Shi Liu",
        "Xuan Dong",
        "Yue Yu",
        "Weijie Su",
        "Xuehui Wang",
        "Zhaoyang Liu",
        "Jinguo Zhu",
        "Hao Li",
        "Wenhai Wang",
        "Yu Qiao",
        "Xizhou Zhu",
        "Jifeng Dai"
      ],
      "abstract": "The rapid advancement of large Vision-Language Models (VLMs) has propelled\nthe development of pure-vision-based GUI Agents, capable of perceiving and\noperating Graphical User Interfaces (GUI) to autonomously fulfill user\ninstructions. However, existing approaches usually adopt an offline learning\nframework, which faces two core limitations: (1) heavy reliance on high-quality\nmanual annotations for element grounding and action supervision, and (2)\nlimited adaptability to dynamic and interactive environments. To address these\nlimitations, we propose ZeroGUI, a scalable, online learning framework for\nautomating GUI Agent training at Zero human cost. Specifically, ZeroGUI\nintegrates (i) VLM-based automatic task generation to produce diverse training\ngoals from the current environment state, (ii) VLM-based automatic reward\nestimation to assess task success without hand-crafted evaluation functions,\nand (iii) two-stage online reinforcement learning to continuously interact with\nand learn from GUI environments. Experiments on two advanced GUI Agents\n(UI-TARS and Aguvis) demonstrate that ZeroGUI significantly boosts performance\nacross OSWorld and AndroidLab environments. The code is available at\nhttps://github.com/OpenGVLab/ZeroGUI.",
      "pdf_url": "http://arxiv.org/pdf/2505.23762v1",
      "published": "2025-05-29T17:59:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.23762v1",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ]
    },
    {
      "title": "Differential Information: An Information-Theoretic Perspective on Preference Optimization",
      "authors": [
        "Yunjae Won",
        "Hyunji Lee",
        "Hyeonbin Hwang",
        "Minjoon Seo"
      ],
      "abstract": "Direct Preference Optimization (DPO) has become a standard technique for\naligning language models with human preferences in a supervised manner. Despite\nits empirical success, the theoretical justification behind its log-ratio\nreward parameterization remains incomplete. In this work, we address this gap\nby utilizing the Differential Information Distribution (DID): a distribution\nover token sequences that captures the information gained during policy\nupdates. First, we show that when preference labels encode the differential\ninformation required to transform a reference policy into a target policy, the\nlog-ratio reward in DPO emerges as the uniquely optimal form for learning the\ntarget policy via preference optimization. This result naturally yields a\nclosed-form expression for the optimal sampling distribution over rejected\nresponses. Second, we find that the condition for preferences to encode\ndifferential information is fundamentally linked to an implicit assumption\nregarding log-margin ordered policies-an inductive bias widely used in\npreference optimization yet previously unrecognized. Finally, by analyzing the\nentropy of the DID, we characterize how learning low-entropy differential\ninformation reinforces the policy distribution, while high-entropy differential\ninformation induces a smoothing effect, which explains the log-likelihood\ndisplacement phenomenon. We validate our theoretical findings in synthetic\nexperiments and extend them to real-world instruction-following datasets. Our\nresults suggest that learning high-entropy differential information is crucial\nfor general instruction-following, while learning low-entropy differential\ninformation benefits knowledge-intensive question answering. Overall, our work\npresents a unifying perspective on the DPO objective, the structure of\npreference data, and resulting policy behaviors through the lens of\ndifferential information.",
      "pdf_url": "http://arxiv.org/pdf/2505.23761v1",
      "published": "2025-05-29T17:59:50+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.23761v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Puzzled by Puzzles: When Vision-Language Models Can't Take a Hint",
      "authors": [
        "Heekyung Lee",
        "Jiaxin Ge",
        "Tsung-Han Wu",
        "Minwoo Kang",
        "Trevor Darrell",
        "David M. Chan"
      ],
      "abstract": "Rebus puzzles, visual riddles that encode language through imagery, spatial\narrangement, and symbolic substitution, pose a unique challenge to current\nvision-language models (VLMs). Unlike traditional image captioning or question\nanswering tasks, rebus solving requires multi-modal abstraction, symbolic\nreasoning, and a grasp of cultural, phonetic and linguistic puns. In this\npaper, we investigate the capacity of contemporary VLMs to interpret and solve\nrebus puzzles by constructing a hand-generated and annotated benchmark of\ndiverse English-language rebus puzzles, ranging from simple pictographic\nsubstitutions to spatially-dependent cues (\"head\" over \"heels\"). We analyze how\ndifferent VLMs perform, and our findings reveal that while VLMs exhibit some\nsurprising capabilities in decoding simple visual clues, they struggle\nsignificantly with tasks requiring abstract reasoning, lateral thinking, and\nunderstanding visual metaphors.",
      "pdf_url": "http://arxiv.org/pdf/2505.23759v1",
      "published": "2025-05-29T17:59:47+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.23759v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ]
    },
    {
      "title": "DeepTheorem: Advancing LLM Reasoning for Theorem Proving Through Natural Language and Reinforcement Learning",
      "authors": [
        "Ziyin Zhang",
        "Jiahao Xu",
        "Zhiwei He",
        "Tian Liang",
        "Qiuzhi Liu",
        "Yansi Li",
        "Linfeng Song",
        "Zhengwen Liang",
        "Zhuosheng Zhang",
        "Rui Wang",
        "Zhaopeng Tu",
        "Haitao Mi",
        "Dong Yu"
      ],
      "abstract": "Theorem proving serves as a major testbed for evaluating complex reasoning\nabilities in large language models (LLMs). However, traditional automated\ntheorem proving (ATP) approaches rely heavily on formal proof systems that\npoorly align with LLMs' strength derived from informal, natural language\nknowledge acquired during pre-training. In this work, we propose DeepTheorem, a\ncomprehensive informal theorem-proving framework exploiting natural language to\nenhance LLM mathematical reasoning. DeepTheorem includes a large-scale\nbenchmark dataset consisting of 121K high-quality IMO-level informal theorems\nand proofs spanning diverse mathematical domains, rigorously annotated for\ncorrectness, difficulty, and topic categories, accompanied by systematically\nconstructed verifiable theorem variants. We devise a novel reinforcement\nlearning strategy (RL-Zero) explicitly tailored to informal theorem proving,\nleveraging the verified theorem variants to incentivize robust mathematical\ninference. Additionally, we propose comprehensive outcome and process\nevaluation metrics examining proof correctness and the quality of reasoning\nsteps. Extensive experimental analyses demonstrate DeepTheorem significantly\nimproves LLM theorem-proving performance compared to existing datasets and\nsupervised fine-tuning protocols, achieving state-of-the-art accuracy and\nreasoning quality. Our findings highlight DeepTheorem's potential to\nfundamentally advance automated informal theorem proving and mathematical\nexploration.",
      "pdf_url": "http://arxiv.org/pdf/2505.23754v1",
      "published": "2025-05-29T17:59:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.23754v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "REOrdering Patches Improves Vision Models",
      "authors": [
        "Declan Kutscher",
        "David M. Chan",
        "Yutong Bai",
        "Trevor Darrell",
        "Ritwik Gupta"
      ],
      "abstract": "Sequence models such as transformers require inputs to be represented as\none-dimensional sequences. In vision, this typically involves flattening images\nusing a fixed row-major (raster-scan) order. While full self-attention is\npermutation-equivariant, modern long-sequence transformers increasingly rely on\narchitectural approximations that break this invariance and introduce\nsensitivity to patch ordering. We show that patch order significantly affects\nmodel performance in such settings, with simple alternatives like column-major\nor Hilbert curves yielding notable accuracy shifts. Motivated by this, we\npropose REOrder, a two-stage framework for discovering task-optimal patch\norderings. First, we derive an information-theoretic prior by evaluating the\ncompressibility of various patch sequences. Then, we learn a policy over\npermutations by optimizing a Plackett-Luce policy using REINFORCE. This\napproach enables efficient learning in a combinatorial permutation space.\nREOrder improves top-1 accuracy over row-major ordering on ImageNet-1K by up to\n3.01% and Functional Map of the World by 13.35%.",
      "pdf_url": "http://arxiv.org/pdf/2505.23751v1",
      "published": "2025-05-29T17:59:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.23751v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Comparative of Genetic Fuzzy regression techniques for aeroacoustic phenomenons",
      "authors": [
        "Hugo Henry",
        "Kelly Cohen"
      ],
      "abstract": "This study investigates the application of Genetic Fuzzy Systems (GFS) to\nmodel the self-noise generated by airfoils, a key issue in aeroaccoustics with\nsignificant implications for aerospace, automotive and drone applications.\nUsing the publicly available Airfoil Self Noise dataset, various Fuzzy\nregression strategies are explored and compared. The paper evaluates a brute\nforce Takagi Sugeno Kang (TSK) fuzzy system with high rule density, a cascading\nGeneti Fuzzy Tree (GFT) architecture and a novel clustered approach based on\nFuzzy C-means (FCM) to reduce the model's complexity. This highlights the\nviability of clustering assisted fuzzy inference as an effective regression\ntool for complex aero accoustic phenomena. Keywords : Fuzzy logic, Regression,\nCascading systems, Clustering and AI.",
      "pdf_url": "http://arxiv.org/pdf/2505.23746v1",
      "published": "2025-05-29T17:59:04+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.23746v1",
      "categories": [
        "cs.AI",
        "cs.NE"
      ]
    },
    {
      "title": "Spatial-MLLM: Boosting MLLM Capabilities in Visual-based Spatial Intelligence",
      "authors": [
        "Diankun Wu",
        "Fangfu Liu",
        "Yi-Hsin Hung",
        "Yueqi Duan"
      ],
      "abstract": "Recent advancements in Multimodal Large Language Models (MLLMs) have\nsignificantly enhanced performance on 2D visual tasks. However, improving their\nspatial intelligence remains a challenge. Existing 3D MLLMs always rely on\nadditional 3D or 2.5D data to incorporate spatial awareness, restricting their\nutility in scenarios with only 2D inputs, such as images or videos. In this\npaper, we present Spatial-MLLM, a novel framework for visual-based spatial\nreasoning from purely 2D observations. Unlike conventional video MLLMs which\nrely on CLIP-based visual encoders optimized for semantic understanding, our\nkey insight is to unleash the strong structure prior from the feed-forward\nvisual geometry foundation model. Specifically, we propose a dual-encoder\narchitecture: a pretrained 2D visual encoder to extract semantic features, and\na spatial encoder-initialized from the backbone of the visual geometry model-to\nextract 3D structure features. A connector then integrates both features into\nunified visual tokens for enhanced spatial understanding. Furthermore, we\npropose a space-aware frame sampling strategy at inference time, which selects\nthe spatially informative frames of a video sequence, ensuring that even under\nlimited token length, the model focuses on frames critical for spatial\nreasoning. Beyond architecture improvements, we construct the Spatial-MLLM-120k\ndataset and train the model on it using supervised fine-tuning and GRPO.\nExtensive experiments on various real-world datasets demonstrate that our\nspatial-MLLM achieves state-of-the-art performance in a wide range of\nvisual-based spatial understanding and reasoning tasks. Project page:\nhttps://diankun-wu.github.io/Spatial-MLLM/.",
      "pdf_url": "http://arxiv.org/pdf/2505.23747v1",
      "published": "2025-05-29T17:59:04+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.23747v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "I.2.6; I.2"
      ]
    },
    {
      "title": "To Trust Or Not To Trust Your Vision-Language Model's Prediction",
      "authors": [
        "Hao Dong",
        "Moru Liu",
        "Jian Liang",
        "Eleni Chatzi",
        "Olga Fink"
      ],
      "abstract": "Vision-Language Models (VLMs) have demonstrated strong capabilities in\naligning visual and textual modalities, enabling a wide range of applications\nin multimodal understanding and generation. While they excel in zero-shot and\ntransfer learning scenarios, VLMs remain susceptible to misclassification,\noften yielding confident yet incorrect predictions. This limitation poses a\nsignificant risk in safety-critical domains, where erroneous predictions can\nlead to severe consequences. In this work, we introduce TrustVLM, a\ntraining-free framework designed to address the critical challenge of\nestimating when VLM's predictions can be trusted. Motivated by the observed\nmodality gap in VLMs and the insight that certain concepts are more distinctly\nrepresented in the image embedding space, we propose a novel confidence-scoring\nfunction that leverages this space to improve misclassification detection. We\nrigorously evaluate our approach across 17 diverse datasets, employing 4\narchitectures and 2 VLMs, and demonstrate state-of-the-art performance, with\nimprovements of up to 51.87% in AURC, 9.14% in AUROC, and 32.42% in FPR95\ncompared to existing baselines. By improving the reliability of the model\nwithout requiring retraining, TrustVLM paves the way for safer deployment of\nVLMs in real-world applications. The code will be available at\nhttps://github.com/EPFL-IMOS/TrustVLM.",
      "pdf_url": "http://arxiv.org/pdf/2505.23745v1",
      "published": "2025-05-29T17:59:01+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.23745v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Boosting Domain Incremental Learning: Selecting the Optimal Parameters is All You Need",
      "authors": [
        "Qiang Wang",
        "Xiang Song",
        "Yuhang He",
        "Jizhou Han",
        "Chenhao Ding",
        "Xinyuan Gao",
        "Yihong Gong"
      ],
      "abstract": "Deep neural networks (DNNs) often underperform in real-world, dynamic\nsettings where data distributions change over time. Domain Incremental Learning\n(DIL) offers a solution by enabling continual model adaptation, with\nParameter-Isolation DIL (PIDIL) emerging as a promising paradigm to reduce\nknowledge conflicts. However, existing PIDIL methods struggle with parameter\nselection accuracy, especially as the number of domains and corresponding\nclasses grows. To address this, we propose SOYO, a lightweight framework that\nimproves domain selection in PIDIL. SOYO introduces a Gaussian Mixture\nCompressor (GMC) and Domain Feature Resampler (DFR) to store and balance prior\ndomain data efficiently, while a Multi-level Domain Feature Fusion Network\n(MDFN) enhances domain feature extraction. Our framework supports multiple\nParameter-Efficient Fine-Tuning (PEFT) methods and is validated across tasks\nsuch as image classification, object detection, and speech enhancement.\nExperimental results on six benchmarks demonstrate SOYO's consistent\nsuperiority over existing baselines, showcasing its robustness and adaptability\nin complex, evolving environments. The codes will be released in\nhttps://github.com/qwangcv/SOYO.",
      "pdf_url": "http://arxiv.org/pdf/2505.23744v1",
      "published": "2025-05-29T17:58:57+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.23744v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "MAGREF: Masked Guidance for Any-Reference Video Generation",
      "authors": [
        "Yufan Deng",
        "Xun Guo",
        "Yuanyang Yin",
        "Jacob Zhiyuan Fang",
        "Yiding Yang",
        "Yizhi Wang",
        "Shenghai Yuan",
        "Angtian Wang",
        "Bo Liu",
        "Haibin Huang",
        "Chongyang Ma"
      ],
      "abstract": "Video generation has made substantial strides with the emergence of deep\ngenerative models, especially diffusion-based approaches. However, video\ngeneration based on multiple reference subjects still faces significant\nchallenges in maintaining multi-subject consistency and ensuring high\ngeneration quality. In this paper, we propose MAGREF, a unified framework for\nany-reference video generation that introduces masked guidance to enable\ncoherent multi-subject video synthesis conditioned on diverse reference images\nand a textual prompt. Specifically, we propose (1) a region-aware dynamic\nmasking mechanism that enables a single model to flexibly handle various\nsubject inference, including humans, objects, and backgrounds, without\narchitectural changes, and (2) a pixel-wise channel concatenation mechanism\nthat operates on the channel dimension to better preserve appearance features.\nOur model delivers state-of-the-art video generation quality, generalizing from\nsingle-subject training to complex multi-subject scenarios with coherent\nsynthesis and precise control over individual subjects, outperforming existing\nopen-source and commercial baselines. To facilitate evaluation, we also\nintroduce a comprehensive multi-subject video benchmark. Extensive experiments\ndemonstrate the effectiveness of our approach, paving the way for scalable,\ncontrollable, and high-fidelity multi-subject video synthesis. Code and model\ncan be found at: https://github.com/MAGREF-Video/MAGREF",
      "pdf_url": "http://arxiv.org/pdf/2505.23742v1",
      "published": "2025-05-29T17:58:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.23742v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "ATLAS: Learning to Optimally Memorize the Context at Test Time",
      "authors": [
        "Ali Behrouz",
        "Zeman Li",
        "Praneeth Kacham",
        "Majid Daliri",
        "Yuan Deng",
        "Peilin Zhong",
        "Meisam Razaviyayn",
        "Vahab Mirrokni"
      ],
      "abstract": "Transformers have been established as the most popular backbones in sequence\nmodeling, mainly due to their effectiveness in in-context retrieval tasks and\nthe ability to learn at scale. Their quadratic memory and time complexity,\nhowever, bound their applicability in longer sequences and so has motivated\nresearchers to explore effective alternative architectures such as modern\nrecurrent neural networks (a.k.a long-term recurrent memory module). Despite\ntheir recent success in diverse downstream tasks, they struggle in tasks that\nrequires long context understanding and extrapolation to longer sequences. We\nobserve that these shortcomings come from three disjoint aspects in their\ndesign: (1) limited memory capacity that is bounded by the architecture of\nmemory and feature mapping of the input; (2) online nature of update, i.e.,\noptimizing the memory only with respect to the last input; and (3) less\nexpressive management of their fixed-size memory. To enhance all these three\naspects, we present ATLAS, a long-term memory module with high capacity that\nlearns to memorize the context by optimizing the memory based on the current\nand past tokens, overcoming the online nature of long-term memory models.\nBuilding on this insight, we present a new family of Transformer-like\narchitectures, called DeepTransformers, that are strict generalizations of the\noriginal Transformer architecture. Our experimental results on language\nmodeling, common-sense reasoning, recall-intensive, and long-context\nunderstanding tasks show that ATLAS surpasses the performance of Transformers\nand recent linear recurrent models. ATLAS further improves the long context\nperformance of Titans, achieving +80\\% accuracy in 10M context length of\nBABILong benchmark.",
      "pdf_url": "http://arxiv.org/pdf/2505.23735v1",
      "published": "2025-05-29T17:57:16+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.23735v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Exposing the Impact of GenAI for Cybercrime: An Investigation into the Dark Side",
      "authors": [
        "Truong",
        "Luu",
        "Binny M. Samuel"
      ],
      "abstract": "In recent years, the rapid advancement and democratization of generative AI\nmodels have sparked significant debate over safety, ethical risks, and dual-use\nconcerns, particularly in the context of cybersecurity. While anecdotally\nknown, this paper provides empirical evidence regarding generative AI's\nassociation with malicious internet-related activities and cybercrime by\nexamining the phenomenon through psychological frameworks of technological\namplification and affordance theory. Using a quasi-experimental design with\ninterrupted time series analysis, we analyze two datasets, one general and one\ncryptocurrency-focused, to empirically assess generative AI's role in\ncybercrime. The findings contribute to ongoing discussions about AI governance\nby balancing control and fostering innovation, underscoring the need for\nstrategies to guide policymakers, inform AI developers and cybersecurity\nprofessionals, and educate the public to maximize AI's benefits while\nmitigating its risks.",
      "pdf_url": "http://arxiv.org/pdf/2505.23733v1",
      "published": "2025-05-29T17:57:01+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.23733v1",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ]
    },
    {
      "title": "Bounded Rationality for LLMs: Satisficing Alignment at Inference-Time",
      "authors": [
        "Mohamad Chehade",
        "Soumya Suvra Ghosal",
        "Souradip Chakraborty",
        "Avinash Reddy",
        "Dinesh Manocha",
        "Hao Zhu",
        "Amrit Singh Bedi"
      ],
      "abstract": "Aligning large language models with humans is challenging due to the\ninherently multifaceted nature of preference feedback. While existing\napproaches typically frame this as a multi-objective optimization problem, they\noften overlook how humans actually make decisions. Research on bounded\nrationality suggests that human decision making follows satisficing\nstrategies-optimizing primary objectives while ensuring others meet acceptable\nthresholds. To bridge this gap and operationalize the notion of satisficing\nalignment, we propose SITAlign: an inference time framework that addresses the\nmultifaceted nature of alignment by maximizing a primary objective while\nsatisfying threshold-based constraints on secondary criteria. We provide\ntheoretical insights by deriving sub-optimality bounds of our satisficing based\ninference alignment approach. We empirically validate SITAlign's performance\nthrough extensive experimentation on multiple benchmarks. For instance, on the\nPKU-SafeRLHF dataset with the primary objective of maximizing helpfulness while\nensuring a threshold on harmlessness, SITAlign outperforms the state-of-the-art\nmulti objective decoding strategy by a margin of 22.3% in terms of GPT-4\nwin-tie rate for helpfulness reward while adhering to the threshold on\nharmlessness.",
      "pdf_url": "http://arxiv.org/pdf/2505.23729v1",
      "published": "2025-05-29T17:56:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.23729v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "SC-LoRA: Balancing Efficient Fine-tuning and Knowledge Preservation via Subspace-Constrained LoRA",
      "authors": [
        "Minrui Luo",
        "Fuhang Kuang",
        "Yu Wang",
        "Zirui Liu",
        "Tianxing He"
      ],
      "abstract": "Parameter-Efficient Fine-Tuning (PEFT) methods, particularly Low-Rank\nAdaptation (LoRA), are indispensable for efficiently customizing Large Language\nModels (LLMs). However, vanilla LoRA suffers from slow convergence speed and\nknowledge forgetting problems. Recent studies have leveraged the power of\ndesigned LoRA initialization, to enhance the fine-tuning efficiency, or to\npreserve knowledge in the pre-trained LLM. However, none of these works can\naddress the two cases at the same time. To this end, we introduce\nSubspace-Constrained LoRA (SC-LoRA), a novel LoRA initialization framework\nengineered to navigate the trade-off between efficient fine-tuning and\nknowledge preservation. We achieve this by constraining the output of trainable\nLoRA adapters in a low-rank subspace, where the context information of\nfine-tuning data is most preserved while the context information of preserved\nknowledge is least retained, in a balanced way. Such constraint enables the\ntrainable weights to primarily focus on the main features of fine-tuning data\nwhile avoiding damaging the preserved knowledge features. We provide\ntheoretical analysis on our method, and conduct extensive experiments including\nsafety preservation and world knowledge preservation, on various downstream\ntasks. In our experiments, SC-LoRA succeeds in delivering superior fine-tuning\nperformance while markedly diminishing knowledge forgetting, surpassing\ncontemporary LoRA initialization methods.",
      "pdf_url": "http://arxiv.org/pdf/2505.23724v1",
      "published": "2025-05-29T17:55:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.23724v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "ML-Agent: Reinforcing LLM Agents for Autonomous Machine Learning Engineering",
      "authors": [
        "Zexi Liu",
        "Jingyi Chai",
        "Xinyu Zhu",
        "Shuo Tang",
        "Rui Ye",
        "Bo Zhang",
        "Lei Bai",
        "Siheng Chen"
      ],
      "abstract": "The emergence of large language model (LLM)-based agents has significantly\nadvanced the development of autonomous machine learning (ML) engineering.\nHowever, most existing approaches rely heavily on manual prompt engineering,\nfailing to adapt and optimize based on diverse experimental experiences.\nFocusing on this, for the first time, we explore the paradigm of learning-based\nagentic ML, where an LLM agent learns through interactive experimentation on ML\ntasks using online reinforcement learning (RL). To realize this, we propose a\nnovel agentic ML training framework with three key components: (1)\nexploration-enriched fine-tuning, which enables LLM agents to generate diverse\nactions for enhanced RL exploration; (2) step-wise RL, which enables training\non a single action step, accelerating experience collection and improving\ntraining efficiency; (3) an agentic ML-specific reward module, which unifies\nvaried ML feedback signals into consistent rewards for RL optimization.\nLeveraging this framework, we train ML-Agent, driven by a 7B-sized Qwen-2.5 LLM\nfor autonomous ML. Remarkably, despite being trained on merely 9 ML tasks, our\n7B-sized ML-Agent outperforms the 671B-sized DeepSeek-R1 agent. Furthermore, it\nachieves continuous performance improvements and demonstrates exceptional\ncross-task generalization capabilities.",
      "pdf_url": "http://arxiv.org/pdf/2505.23723v1",
      "published": "2025-05-29T17:54:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.23723v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "COBRA: Contextual Bandit Algorithm for Ensuring Truthful Strategic Agents",
      "authors": [
        "Arun Verma",
        "Indrajit Saha",
        "Makoto Yokoo",
        "Bryan Kian Hsiang Low"
      ],
      "abstract": "This paper considers a contextual bandit problem involving multiple agents,\nwhere a learner sequentially observes the contexts and the agent's reported\narms, and then selects the arm that maximizes the system's overall reward.\nExisting work in contextual bandits assumes that agents truthfully report their\narms, which is unrealistic in many real-life applications. For instance,\nconsider an online platform with multiple sellers; some sellers may\nmisrepresent product quality to gain an advantage, such as having the platform\npreferentially recommend their products to online users. To address this\nchallenge, we propose an algorithm, COBRA, for contextual bandit problems\ninvolving strategic agents that disincentivize their strategic behavior without\nusing any monetary incentives, while having incentive compatibility and a\nsub-linear regret guarantee. Our experimental results also validate the\ndifferent performance aspects of our proposed algorithm.",
      "pdf_url": "http://arxiv.org/pdf/2505.23720v1",
      "published": "2025-05-29T17:53:12+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.23720v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ]
    },
    {
      "title": "SenWiCh: Sense-Annotation of Low-Resource Languages for WiC using Hybrid Methods",
      "authors": [
        "Roksana Goworek",
        "Harpal Karlcut",
        "Muhammad Shezad",
        "Nijaguna Darshana",
        "Abhishek Mane",
        "Syam Bondada",
        "Raghav Sikka",
        "Ulvi Mammadov",
        "Rauf Allahverdiyev",
        "Sriram Purighella",
        "Paridhi Gupta",
        "Muhinyia Ndegwa",
        "Haim Dubossarsky"
      ],
      "abstract": "This paper addresses the critical need for high-quality evaluation datasets\nin low-resource languages to advance cross-lingual transfer. While\ncross-lingual transfer offers a key strategy for leveraging multilingual\npretraining to expand language technologies to understudied and typologically\ndiverse languages, its effectiveness is dependent on quality and suitable\nbenchmarks. We release new sense-annotated datasets of sentences containing\npolysemous words, spanning nine low-resource languages across diverse language\nfamilies and scripts. To facilitate dataset creation, the paper presents a\ndemonstrably beneficial semi-automatic annotation method. The utility of the\ndatasets is demonstrated through Word-in-Context (WiC) formatted experiments\nthat evaluate transfer on these low-resource languages. Results highlight the\nimportance of targeted dataset creation and evaluation for effective polysemy\ndisambiguation in low-resource settings and transfer studies. The released\ndatasets and code aim to support further research into fair, robust, and truly\nmultilingual NLP.",
      "pdf_url": "http://arxiv.org/pdf/2505.23714v1",
      "published": "2025-05-29T17:48:08+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.23714v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "From Connectivity to Autonomy: The Dawn of Self-Evolving Communication Systems",
      "authors": [
        "Zeinab Nezami",
        "Syed Danial Ali Shah",
        "Maryam Hafeez",
        "Karim Djemame",
        "Syed Ali Raza Zaidi"
      ],
      "abstract": "This paper envisions 6G as a self-evolving telecom ecosystem, where AI-driven\nintelligence enables dynamic adaptation beyond static connectivity. We explore\nthe key enablers of autonomous communication systems, spanning reconfigurable\ninfrastructure, adaptive middleware, and intelligent network functions,\nalongside multi-agent collaboration for distributed decision-making. We explore\nhow these methodologies align with emerging industrial IoT frameworks, ensuring\nseamless integration within digital manufacturing processes. Our findings\nemphasize the potential for improved real-time decision-making, optimizing\nefficiency, and reducing latency in networked control systems. The discussion\naddresses ethical challenges, research directions, and standardization efforts,\nconcluding with a technology stack roadmap to guide future developments. By\nleveraging state-of-the-art 6G network management techniques, this research\ncontributes to the next generation of intelligent automation solutions,\nbridging the gap between theoretical advancements and real-world industrial\napplications.",
      "pdf_url": "http://arxiv.org/pdf/2505.23710v1",
      "published": "2025-05-29T17:45:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.23710v1",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.DC",
        "cs.ET",
        "cs.SY"
      ]
    },
    {
      "title": "Skin Lesion Phenotyping via Nested Multi-modal Contrastive Learning",
      "authors": [
        "Dionysis Christopoulos",
        "Sotiris Spanos",
        "Eirini Baltzi",
        "Valsamis Ntouskos",
        "Konstantinos Karantzalos"
      ],
      "abstract": "We introduce SLIMP (Skin Lesion Image-Metadata Pre-training) for learning\nrich representations of skin lesions through a novel nested contrastive\nlearning approach that captures complex relationships between images and\nmetadata. Melanoma detection and skin lesion classification based solely on\nimages, pose significant challenges due to large variations in imaging\nconditions (lighting, color, resolution, distance, etc.) and lack of clinical\nand phenotypical context. Clinicians typically follow a holistic approach for\nassessing the risk level of the patient and for deciding which lesions may be\nmalignant and need to be excised, by considering the patient's medical history\nas well as the appearance of other lesions of the patient. Inspired by this,\nSLIMP combines the appearance and the metadata of individual skin lesions with\npatient-level metadata relating to their medical record and other clinically\nrelevant information. By fully exploiting all available data modalities\nthroughout the learning process, the proposed pre-training strategy improves\nperformance compared to other pre-training strategies on downstream skin\nlesions classification tasks highlighting the learned representations quality.",
      "pdf_url": "http://arxiv.org/pdf/2505.23709v1",
      "published": "2025-05-29T17:42:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.23709v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Distributed Federated Learning for Vehicular Network Security: Anomaly Detection Benefits and Multi-Domain Attack Threats",
      "authors": [
        "Utku Demir",
        "Yalin E. Sagduyu",
        "Tugba Erpek",
        "Hossein Jafari",
        "Sastry Kompella",
        "Mengran Xue"
      ],
      "abstract": "In connected and autonomous vehicles, machine learning for safety message\nclassification has become critical for detecting malicious or anomalous\nbehavior. However, conventional approaches that rely on centralized data\ncollection or purely local training face limitations due to the large scale,\nhigh mobility, and heterogeneous data distributions inherent in inter-vehicle\nnetworks. To overcome these challenges, this paper explores Distributed\nFederated Learning (DFL), whereby vehicles collaboratively train deep learning\nmodels by exchanging model updates among one-hop neighbors and propagating\nmodels over multiple hops. Using the Vehicular Reference Misbehavior (VeReMi)\nExtension Dataset, we show that DFL can significantly improve classification\naccuracy across all vehicles compared to learning strictly with local data.\nNotably, vehicles with low individual accuracy see substantial accuracy gains\nthrough DFL, illustrating the benefit of knowledge sharing across the network.\nWe further show that local training data size and time-varying network\nconnectivity correlate strongly with the model's overall accuracy. We\ninvestigate DFL's resilience and vulnerabilities under attacks in multiple\ndomains, namely wireless jamming and training data poisoning attacks. Our\nresults reveal important insights into the vulnerabilities of DFL when\nconfronted with multi-domain attacks, underlining the need for more robust\nstrategies to secure DFL in vehicular networks.",
      "pdf_url": "http://arxiv.org/pdf/2505.23706v1",
      "published": "2025-05-29T17:41:02+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.23706v1",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.DC",
        "cs.IT",
        "eess.SP",
        "math.IT"
      ]
    },
    {
      "title": "Let's Reason Formally: Natural-Formal Hybrid Reasoning Enhances LLM's Math Capability",
      "authors": [
        "Ruida Wang",
        "Yuxin Li",
        "Yi R.",
        "Fung",
        "Tong Zhang"
      ],
      "abstract": "Enhancing the mathematical reasoning capabilities of LLMs has garnered\nsignificant attention in both the mathematical and computer science\ncommunities. Recent works have made substantial progress in both Natural\nLanguage (NL) reasoning and Formal Language (FL) reasoning by leveraging the\npotential of pure Reinforcement Learning (RL) methods on base models. However,\nRL approaches struggle to impart new capabilities not presented in the base\nmodel, highlighting the need to integrate more knowledge like FL into NL math\nreasoning effectively. Yet, this integration is challenging due to inherent\ndisparities in problem structure and reasoning format between NL and FL. To\naddress these challenges, we introduce **NL-FL HybridReasoning**, an end-to-end\nframework designed to incorporate the FL expert into NL math problem-solving.\nTo bridge the NL and FL input format gap, we propose the *NL-FL Problem\nAlignment* method, which reformulates the Question-Answering (QA) problems in\nNL as existence theorems in FL. Subsequently, the *Mixed Problem Input*\ntechnique we provide enables the FL reasoner to handle both QA and existence\nproblems concurrently. Lastly, we mitigate the NL and FL output format gap in\nreasoning through an LLM-based *Answer Extraction* mechanism. Comprehensive\nexperiments demonstrate that the **HybridReasoning** framework achieves\n**89.80%** and **84.34%** accuracy rates on the MATH-500 and the AMC\nbenchmarks, surpassing the NL baseline by 4.60% and 4.82%, respectively.\nNotably, some problems resolved by our framework remain unsolved by the NL\nbaseline model even under a larger number of trials.",
      "pdf_url": "http://arxiv.org/pdf/2505.23703v1",
      "published": "2025-05-29T17:39:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.23703v1",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "CLDTracker: A Comprehensive Language Description for Visual Tracking",
      "authors": [
        "Mohamad Alansari",
        "Sajid Javed",
        "Iyyakutti Iyappan Ganapathi",
        "Sara Alansari",
        "Muzammal Naseer"
      ],
      "abstract": "VOT remains a fundamental yet challenging task in computer vision due to\ndynamic appearance changes, occlusions, and background clutter. Traditional\ntrackers, relying primarily on visual cues, often struggle in such complex\nscenarios. Recent advancements in VLMs have shown promise in semantic\nunderstanding for tasks like open-vocabulary detection and image captioning,\nsuggesting their potential for VOT. However, the direct application of VLMs to\nVOT is hindered by critical limitations: the absence of a rich and\ncomprehensive textual representation that semantically captures the target\nobject's nuances, limiting the effective use of language information;\ninefficient fusion mechanisms that fail to optimally integrate visual and\ntextual features, preventing a holistic understanding of the target; and a lack\nof temporal modeling of the target's evolving appearance in the language\ndomain, leading to a disconnect between the initial description and the\nobject's subsequent visual changes. To bridge these gaps and unlock the full\npotential of VLMs for VOT, we propose CLDTracker, a novel Comprehensive\nLanguage Description framework for robust visual Tracking. Our tracker\nintroduces a dual-branch architecture consisting of a textual and a visual\nbranch. In the textual branch, we construct a rich bag of textual descriptions\nderived by harnessing the powerful VLMs such as CLIP and GPT-4V, enriched with\nsemantic and contextual cues to address the lack of rich textual\nrepresentation. Experiments on six standard VOT benchmarks demonstrate that\nCLDTracker achieves SOTA performance, validating the effectiveness of\nleveraging robust and temporally-adaptive vision-language representations for\ntracking. Code and models are publicly available at:\nhttps://github.com/HamadYA/CLDTracker",
      "pdf_url": "http://arxiv.org/pdf/2505.23704v1",
      "published": "2025-05-29T17:39:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.23704v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Data-to-Dashboard: Multi-Agent LLM Framework for Insightful Visualization in Enterprise Analytics",
      "authors": [
        "Ran Zhang",
        "Mohannad Elhamod"
      ],
      "abstract": "The rapid advancement of LLMs has led to the creation of diverse agentic\nsystems in data analysis, utilizing LLMs' capabilities to improve insight\ngeneration and visualization. In this paper, we present an agentic system that\nautomates the data-to-dashboard pipeline through modular LLM agents capable of\ndomain detection, concept extraction, multi-perspective analysis generation,\nand iterative self-reflection. Unlike existing chart QA systems, our framework\nsimulates the analytical reasoning process of business analysts by retrieving\ndomain-relevant knowledge and adapting to diverse datasets without relying on\nclosed ontologies or question templates.\n  We evaluate our system on three datasets across different domains.\nBenchmarked against GPT-4o with a single-prompt baseline, our approach shows\nimproved insightfulness, domain relevance, and analytical depth, as measured by\ntailored evaluation metrics and qualitative human assessment.\n  This work contributes a novel modular pipeline to bridge the path from raw\ndata to visualization, and opens new opportunities for human-in-the-loop\nvalidation by domain experts in business analytics. All code can be found here:\nhttps://github.com/77luvC/D2D_Data2Dashboard",
      "pdf_url": "http://arxiv.org/pdf/2505.23695v1",
      "published": "2025-05-29T17:32:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.23695v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "VF-Eval: Evaluating Multimodal LLMs for Generating Feedback on AIGC Videos",
      "authors": [
        "Tingyu Song",
        "Tongyan Hu",
        "Guo Gan",
        "Yilun Zhao"
      ],
      "abstract": "MLLMs have been widely studied for video question answering recently.\nHowever, most existing assessments focus on natural videos, overlooking\nsynthetic videos, such as AI-generated content (AIGC). Meanwhile, some works in\nvideo generation rely on MLLMs to evaluate the quality of generated videos, but\nthe capabilities of MLLMs on interpreting AIGC videos remain largely\nunderexplored. To address this, we propose a new benchmark, VF-Eval, which\nintroduces four tasks-coherence validation, error awareness, error type\ndetection, and reasoning evaluation-to comprehensively evaluate the abilities\nof MLLMs on AIGC videos. We evaluate 13 frontier MLLMs on VF-Eval and find that\neven the best-performing model, GPT-4.1, struggles to achieve consistently good\nperformance across all tasks. This highlights the challenging nature of our\nbenchmark. Additionally, to investigate the practical applications of VF-Eval\nin improving video generation, we conduct an experiment, RePrompt,\ndemonstrating that aligning MLLMs more closely with human feedback can benefit\nvideo generation.",
      "pdf_url": "http://arxiv.org/pdf/2505.23693v1",
      "published": "2025-05-29T17:31:13+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.23693v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "ROTATE: Regret-driven Open-ended Training for Ad Hoc Teamwork",
      "authors": [
        "Caroline Wang",
        "Arrasy Rahman",
        "Jiaxun Cui",
        "Yoonchang Sung",
        "Peter Stone"
      ],
      "abstract": "Developing AI agents capable of collaborating with previously unseen partners\nis a fundamental generalization challenge in multi-agent learning, known as Ad\nHoc Teamwork (AHT). Existing AHT approaches typically adopt a two-stage\npipeline, where first, a fixed population of teammates is generated with the\nidea that they should be representative of the teammates that will be seen at\ndeployment time, and second, an AHT agent is trained to collaborate well with\nagents in the population. To date, the research community has focused on\ndesigning separate algorithms for each stage. This separation has led to\nalgorithms that generate teammate pools with limited coverage of possible\nbehaviors, and that ignore whether the generated teammates are easy to learn\nfrom for the AHT agent. Furthermore, algorithms for training AHT agents\ntypically treat the set of training teammates as static, thus attempting to\ngeneralize to previously unseen partner agents without assuming any control\nover the distribution of training teammates. In this paper, we present a\nunified framework for AHT by reformulating the problem as an open-ended\nlearning process between an ad hoc agent and an adversarial teammate generator.\nWe introduce ROTATE, a regret-driven, open-ended training algorithm that\nalternates between improving the AHT agent and generating teammates that probe\nits deficiencies. Extensive experiments across diverse AHT environments\ndemonstrate that ROTATE significantly outperforms baselines at generalizing to\nan unseen set of evaluation teammates, thus establishing a new standard for\nrobust and generalizable teamwork.",
      "pdf_url": "http://arxiv.org/pdf/2505.23686v1",
      "published": "2025-05-29T17:24:54+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.23686v1",
      "categories": [
        "cs.AI",
        "cs.MA",
        "I.2.11; I.2.1; I.2.6; I.2.8"
      ]
    },
    {
      "title": "GSO: Challenging Software Optimization Tasks for Evaluating SWE-Agents",
      "authors": [
        "Manish Shetty",
        "Naman Jain",
        "Jinjian Liu",
        "Vijay Kethanaboyina",
        "Koushik Sen",
        "Ion Stoica"
      ],
      "abstract": "Developing high-performance software is a complex task that requires\nspecialized expertise. We introduce GSO, a benchmark for evaluating language\nmodels' capabilities in developing high-performance software. We develop an\nautomated pipeline that generates and executes performance tests to analyze\nrepository commit histories to identify 102 challenging optimization tasks\nacross 10 codebases, spanning diverse domains and programming languages. An\nagent is provided with a codebase and performance test as a precise\nspecification, and tasked to improve the runtime efficiency, which is measured\nagainst the expert developer optimization. Our quantitative evaluation reveals\nthat leading SWE-Agents struggle significantly, achieving less than 5% success\nrate, with limited improvements even with inference-time scaling. Our\nqualitative analysis identifies key failure modes, including difficulties with\nlow-level languages, practicing lazy optimization strategies, and challenges in\naccurately localizing bottlenecks. We release the code and artifacts of our\nbenchmark along with agent trajectories to enable future research.",
      "pdf_url": "http://arxiv.org/pdf/2505.23671v1",
      "published": "2025-05-29T17:14:55+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.23671v1",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    },
    {
      "title": "Fortune: Formula-Driven Reinforcement Learning for Symbolic Table Reasoning in Language Models",
      "authors": [
        "Lang Cao",
        "Jingxian Xu",
        "Hanbing Liu",
        "Jinyu Wang",
        "Mengyu Zhou",
        "Haoyu Dong",
        "Shi Han",
        "Dongmei Zhang"
      ],
      "abstract": "Tables are a fundamental structure for organizing and analyzing data, making\neffective table understanding a critical capability for intelligent systems.\nWhile large language models (LMs) demonstrate strong general reasoning\nabilities, they continue to struggle with accurate numerical or symbolic\nreasoning over tabular data, especially in complex scenarios. Spreadsheet\nformulas provide a powerful and expressive medium for representing executable\nsymbolic operations, encoding rich reasoning patterns that remain largely\nunderutilized. In this paper, we propose Formula Tuning (Fortune), a\nreinforcement learning (RL) framework that trains LMs to generate executable\nspreadsheet formulas for question answering over general tabular data. Formula\nTuning reduces the reliance on supervised formula annotations by using binary\nanswer correctness as a reward signal, guiding the model to learn formula\nderivation through reasoning. We provide a theoretical analysis of its\nadvantages and demonstrate its effectiveness through extensive experiments on\nseven table reasoning benchmarks. Formula Tuning substantially enhances LM\nperformance, particularly on multi-step numerical and symbolic reasoning tasks,\nenabling a 7B model to outperform O1 on table understanding. This highlights\nthe potential of formula-driven RL to advance symbolic table reasoning in LMs.",
      "pdf_url": "http://arxiv.org/pdf/2505.23667v1",
      "published": "2025-05-29T17:13:40+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.23667v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Active Layer-Contrastive Decoding Reduces Hallucination in Large Language Model Generation",
      "authors": [
        "Hongxiang Zhang",
        "Hao Chen",
        "Tianyi Zhang",
        "Muhao Chen"
      ],
      "abstract": "Recent decoding methods improve the factuality of large language\nmodels~(LLMs) by refining how the next token is selected during generation.\nThese methods typically operate at the token level, leveraging internal\nrepresentations to suppress superficial patterns. Nevertheless, LLMs remain\nprone to hallucinations, especially over longer contexts. In this paper, we\npropose Active Layer-Contrastive Decoding (ActLCD), a novel decoding strategy\nthat actively decides when to apply contrasting layers during generation. By\ncasting decoding as a sequential decision-making problem, ActLCD employs a\nreinforcement learning policy guided by a reward-aware classifier to optimize\nfactuality beyond the token level. Our experiments demonstrate that ActLCD\nsurpasses state-of-the-art methods across five benchmarks, showcasing its\neffectiveness in mitigating hallucinations in diverse generation scenarios.",
      "pdf_url": "http://arxiv.org/pdf/2505.23657v1",
      "published": "2025-05-29T17:07:24+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.23657v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Keyed Chaotic Tensor Transformations for Secure And Attributable Neural Inference",
      "authors": [
        "Peter David Fagan"
      ],
      "abstract": "This work introduces a novel framework for secure and privacy-preserving\nneural network inference based on keyed chaotic dynamical transformations. The\nproposed method applies a deterministic, cryptographically seeded chaotic\nsystem to tensors, producing non-invertible, user-specific transformations that\nenable authenticated inference, tensor-level watermarking, and data\nattribution. This framework offers a scalable and lightweight alternative to\nconventional cryptographic techniques, and establishes a new direction for\ntensor-level security in AI systems.",
      "pdf_url": "http://arxiv.org/pdf/2505.23655v1",
      "published": "2025-05-29T17:05:42+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.23655v1",
      "categories": [
        "cs.CR",
        "cs.AI",
        "94A60, 37N25, 68T05",
        "D.4.6"
      ]
    },
    {
      "title": "Securing AI Agents with Information-Flow Control",
      "authors": [
        "Manuel Costa",
        "Boris Köpf",
        "Aashish Kolluri",
        "Andrew Paverd",
        "Mark Russinovich",
        "Ahmed Salem",
        "Shruti Tople",
        "Lukas Wutschitz",
        "Santiago Zanella-Béguelin"
      ],
      "abstract": "As AI agents become increasingly autonomous and capable, ensuring their\nsecurity against vulnerabilities such as prompt injection becomes critical.\nThis paper explores the use of information-flow control (IFC) to provide\nsecurity guarantees for AI agents. We present a formal model to reason about\nthe security and expressiveness of agent planners. Using this model, we\ncharacterize the class of properties enforceable by dynamic taint-tracking and\nconstruct a taxonomy of tasks to evaluate security and utility trade-offs of\nplanner designs. Informed by this exploration, we present Fides, a planner that\ntracks confidentiality and integrity labels, deterministically enforces\nsecurity policies, and introduces novel primitives for selectively hiding\ninformation. Its evaluation in AgentDojo demonstrates that this approach\nbroadens the range of tasks that can be securely accomplished. A tutorial to\nwalk readers through the the concepts introduced in the paper can be found at\nhttps://github.com/microsoft/fides",
      "pdf_url": "http://arxiv.org/pdf/2505.23643v1",
      "published": "2025-05-29T16:50:41+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.23643v1",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "title": "Comparing the Effects of Persistence Barcodes Aggregation and Feature Concatenation on Medical Imaging",
      "authors": [
        "Dashti A. Ali",
        "Richard K. G. Do",
        "William R. Jarnagin",
        "Aras T. Asaad",
        "Amber L. Simpson"
      ],
      "abstract": "In medical image analysis, feature engineering plays an important role in the\ndesign and performance of machine learning models. Persistent homology (PH),\nfrom the field of topological data analysis (TDA), demonstrates robustness and\nstability to data perturbations and addresses the limitation from traditional\nfeature extraction approaches where a small change in input results in a large\nchange in feature representation. Using PH, we store persistent topological and\ngeometrical features in the form of the persistence barcode whereby large bars\nrepresent global topological features and small bars encapsulate geometrical\ninformation of the data. When multiple barcodes are computed from 2D or 3D\nmedical images, two approaches can be used to construct the final topological\nfeature vector in each dimension: aggregating persistence barcodes followed by\nfeaturization or concatenating topological feature vectors derived from each\nbarcode. In this study, we conduct a comprehensive analysis across diverse\nmedical imaging datasets to compare the effects of the two aforementioned\napproaches on the performance of classification models. The results of this\nanalysis indicate that feature concatenation preserves detailed topological\ninformation from individual barcodes, yields better classification performance\nand is therefore a preferred approach when conducting similar experiments.",
      "pdf_url": "http://arxiv.org/pdf/2505.23637v1",
      "published": "2025-05-29T16:45:33+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.23637v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Human Empathy as Encoder: AI-Assisted Depression Assessment in Special Education",
      "authors": [
        "Boning Zhao"
      ],
      "abstract": "Assessing student depression in sensitive environments like special education\nis challenging. Standardized questionnaires may not fully reflect students'\ntrue situations. Furthermore, automated methods often falter with rich student\nnarratives, lacking the crucial, individualized insights stemming from\nteachers' empathetic connections with students. Existing methods often fail to\naddress this ambiguity or effectively integrate educator understanding. To\naddress these limitations by fostering a synergistic human-AI collaboration,\nthis paper introduces Human Empathy as Encoder (HEAE), a novel, human-centered\nAI framework for transparent and socially responsible depression severity\nassessment. Our approach uniquely integrates student narrative text with a\nteacher-derived, 9-dimensional \"Empathy Vector\" (EV), its dimensions guided by\nthe PHQ-9 framework,to explicitly translate tacit empathetic insight into a\nstructured AI input enhancing rather than replacing human judgment. Rigorous\nexperiments optimized the multimodal fusion, text representation, and\nclassification architecture, achieving 82.74% accuracy for 7-level severity\nclassification. This work demonstrates a path toward more responsible and\nethical affective computing by structurally embedding human empathy",
      "pdf_url": "http://arxiv.org/pdf/2505.23631v1",
      "published": "2025-05-29T16:37:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.23631v1",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "AutoSchemaKG: Autonomous Knowledge Graph Construction through Dynamic Schema Induction from Web-Scale Corpora",
      "authors": [
        "Jiaxin Bai",
        "Wei Fan",
        "Qi Hu",
        "Qing Zong",
        "Chunyang Li",
        "Hong Ting Tsang",
        "Hongyu Luo",
        "Yauwai Yim",
        "Haoyu Huang",
        "Xiao Zhou",
        "Feng Qin",
        "Tianshi Zheng",
        "Xi Peng",
        "Xin Yao",
        "Huiwen Yang",
        "Leijie Wu",
        "Yi Ji",
        "Gong Zhang",
        "Renhai Chen",
        "Yangqiu Song"
      ],
      "abstract": "We present AutoSchemaKG, a framework for fully autonomous knowledge graph\nconstruction that eliminates the need for predefined schemas. Our system\nleverages large language models to simultaneously extract knowledge triples and\ninduce comprehensive schemas directly from text, modeling both entities and\nevents while employing conceptualization to organize instances into semantic\ncategories. Processing over 50 million documents, we construct ATLAS (Automated\nTriple Linking And Schema induction), a family of knowledge graphs with 900+\nmillion nodes and 5.9 billion edges. This approach outperforms state-of-the-art\nbaselines on multi-hop QA tasks and enhances LLM factuality. Notably, our\nschema induction achieves 95\\% semantic alignment with human-crafted schemas\nwith zero manual intervention, demonstrating that billion-scale knowledge\ngraphs with dynamically induced schemas can effectively complement parametric\nknowledge in large language models.",
      "pdf_url": "http://arxiv.org/pdf/2505.23628v1",
      "published": "2025-05-29T16:34:58+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.23628v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Towards Explainable Sequential Learning",
      "authors": [
        "Giacomo Bergami",
        "Emma Packer",
        "Kirsty Scott",
        "Silvia Del Din"
      ],
      "abstract": "This paper offers a hybrid explainable temporal data processing pipeline,\nDataFul Explainable MultivariatE coRrelatIonal Temporal Artificial inTElligence\n(EMeriTAte+DF), bridging numerical-driven temporal data classification with an\nevent-based one through verified artificial intelligence principles, enabling\nhuman-explainable results. This was possible through a preliminary a posteriori\nexplainable phase describing the numerical input data in terms of concurrent\nconstituents with numerical payloads. This further required extending the\nevent-based literature to design specification mining algorithms supporting\nconcurrent constituents. Our previous and current solutions outperform\nstate-of-the-art solutions for multivariate time series classifications, thus\nshowcasing the effectiveness of the proposed methodology.",
      "pdf_url": "http://arxiv.org/pdf/2505.23624v1",
      "published": "2025-05-29T16:30:59+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.23624v1",
      "categories": [
        "cs.DB",
        "cs.AI"
      ]
    },
    {
      "title": "One Trajectory, One Token: Grounded Video Tokenization via Panoptic Sub-object Trajectory",
      "authors": [
        "Chenhao Zheng",
        "Jieyu Zhang",
        "Mohammadreza Salehi",
        "Ziqi Gao",
        "Vishnu Iyengar",
        "Norimasa Kobori",
        "Quan Kong",
        "Ranjay Krishna"
      ],
      "abstract": "Effective video tokenization is critical for scaling transformer models for\nlong videos. Current approaches tokenize videos using space-time patches,\nleading to excessive tokens and computational inefficiencies. The best token\nreduction strategies degrade performance and barely reduce the number of tokens\nwhen the camera moves. We introduce grounded video tokenization, a paradigm\nthat organizes tokens based on panoptic sub-object trajectories rather than\nfixed patches. Our method aligns with fundamental perceptual principles,\nensuring that tokenization reflects scene complexity rather than video\nduration. We propose TrajViT, a video encoder that extracts object trajectories\nand converts them into semantically meaningful tokens, significantly reducing\nredundancy while maintaining temporal coherence. Trained with contrastive\nlearning, TrajViT significantly outperforms space-time ViT (ViT3D) across\nmultiple video understanding benchmarks, e.g., TrajViT outperforms ViT3D by a\nlarge margin of 6% top-5 recall in average at video-text retrieval task with\n10x token deduction. We also show TrajViT as a stronger model than ViT3D for\nbeing the video encoder for modern VideoLLM, obtaining an average of 5.2%\nperformance improvement across 6 VideoQA benchmarks while having 4x faster\ntraining time and 18x less inference FLOPs. TrajViT is the first efficient\nencoder to consistently outperform ViT3D across diverse video analysis tasks,\nmaking it a robust and scalable solution.",
      "pdf_url": "http://arxiv.org/pdf/2505.23617v1",
      "published": "2025-05-29T16:25:35+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.23617v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG"
      ]
    },
    {
      "title": "Satori-SWE: Evolutionary Test-Time Scaling for Sample-Efficient Software Engineering",
      "authors": [
        "Guangtao Zeng",
        "Maohao Shen",
        "Delin Chen",
        "Zhenting Qi",
        "Subhro Das",
        "Dan Gutfreund",
        "David Cox",
        "Gregory Wornell",
        "Wei Lu",
        "Zhang-Wei Hong",
        "Chuang Gan"
      ],
      "abstract": "Language models (LMs) perform well on standardized coding benchmarks but\nstruggle with real-world software engineering tasks such as resolving GitHub\nissues in SWE-Bench, especially when model parameters are less than 100B. While\nsmaller models are preferable in practice due to their lower computational\ncost, improving their performance remains challenging. Existing approaches\nprimarily rely on supervised fine-tuning (SFT) with high-quality data, which is\nexpensive to curate at scale. An alternative is test-time scaling: generating\nmultiple outputs, scoring them using a verifier, and selecting the best one.\nAlthough effective, this strategy often requires excessive sampling and costly\nscoring, limiting its practical application. We propose Evolutionary Test-Time\nScaling (EvoScale), a sample-efficient method that treats generation as an\nevolutionary process. By iteratively refining outputs via selection and\nmutation, EvoScale shifts the output distribution toward higher-scoring\nregions, reducing the number of samples needed to find correct solutions. To\nreduce the overhead from repeatedly sampling and selection, we train the model\nto self-evolve using reinforcement learning (RL). Rather than relying on\nexternal verifiers at inference time, the model learns to self-improve the\nscores of its own generations across iterations. Evaluated on\nSWE-Bench-Verified, EvoScale enables our 32B model, Satori-SWE-32B, to match or\nexceed the performance of models with over 100B parameters while using a few\nsamples. Code, data, and models will be fully open-sourced.",
      "pdf_url": "http://arxiv.org/pdf/2505.23604v1",
      "published": "2025-05-29T16:15:36+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.23604v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SE"
      ]
    },
    {
      "title": "MAPLE: A Mobile Assistant with Persistent Finite State Machines for Recovery Reasoning",
      "authors": [
        "Linqiang Guo",
        "Wei Liu",
        "Yi Wen Heng",
        "Tse-Hsun",
        "Chen",
        "Yang Wang"
      ],
      "abstract": "Mobile GUI agents aim to autonomously complete user-instructed tasks across\nmobile apps. Recent advances in Multimodal Large Language Models (MLLMs) enable\nthese agents to interpret UI screens, identify actionable elements, and perform\ninteractions such as tapping or typing. However, existing agents remain\nreactive: they reason only over the current screen and lack a structured model\nof app navigation flow, limiting their ability to understand context, detect\nunexpected outcomes, and recover from errors. We present MAPLE, a state-aware\nmulti-agent framework that abstracts app interactions as a Finite State Machine\n(FSM). We computationally model each UI screen as a discrete state and user\nactions as transitions, allowing the FSM to provide a structured representation\nof the app execution. MAPLE consists of specialized agents responsible for four\nphases of task execution: planning, execution, verification, error recovery,\nand knowledge retention. These agents collaborate to dynamically construct FSMs\nin real time based on perception data extracted from the UI screen, allowing\nthe GUI agents to track navigation progress and flow, validate action outcomes\nthrough pre- and post-conditions of the states, and recover from errors by\nrolling back to previously stable states. Our evaluation results on two\nchallenging cross-app benchmarks, Mobile-Eval-E and SPA-Bench, show that MAPLE\noutperforms the state-of-the-art baseline, improving task success rate by up to\n12%, recovery success by 13.8%, and action accuracy by 6.5%. Our results\nhighlight the importance of structured state modeling in guiding mobile GUI\nagents during task execution. Moreover, our FSM representation can be\nintegrated into future GUI agent architectures as a lightweight, model-agnostic\nmemory layer to support structured planning, execution verification, and error\nrecovery.",
      "pdf_url": "http://arxiv.org/pdf/2505.23596v1",
      "published": "2025-05-29T16:08:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.23596v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "DeepChest: Dynamic Gradient-Free Task Weighting for Effective Multi-Task Learning in Chest X-ray Classification",
      "authors": [
        "Youssef Mohamed",
        "Noran Mohamed",
        "Khaled Abouhashad",
        "Feilong Tang",
        "Sara Atito",
        "Shoaib Jameel",
        "Imran Razzak",
        "Ahmed B. Zaky"
      ],
      "abstract": "While Multi-Task Learning (MTL) offers inherent advantages in complex domains\nsuch as medical imaging by enabling shared representation learning, effectively\nbalancing task contributions remains a significant challenge. This paper\naddresses this critical issue by introducing DeepChest, a novel,\ncomputationally efficient and effective dynamic task-weighting framework\nspecifically designed for multi-label chest X-ray (CXR) classification. Unlike\nexisting heuristic or gradient-based methods that often incur substantial\noverhead, DeepChest leverages a performance-driven weighting mechanism based on\neffective analysis of task-specific loss trends. Given a network architecture\n(e.g., ResNet18), our model-agnostic approach adaptively adjusts task\nimportance without requiring gradient access, thereby significantly reducing\nmemory usage and achieving a threefold increase in training speed. It can be\neasily applied to improve various state-of-the-art methods. Extensive\nexperiments on a large-scale CXR dataset demonstrate that DeepChest not only\noutperforms state-of-the-art MTL methods by 7% in overall accuracy but also\nyields substantial reductions in individual task losses, indicating improved\ngeneralization and effective mitigation of negative transfer. The efficiency\nand performance gains of DeepChest pave the way for more practical and robust\ndeployment of deep learning in critical medical diagnostic applications. The\ncode is publicly available at https://github.com/youssefkhalil320/DeepChest-MTL",
      "pdf_url": "http://arxiv.org/pdf/2505.23595v1",
      "published": "2025-05-29T16:08:26+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.23595v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Jigsaw-R1: A Study of Rule-based Visual Reinforcement Learning with Jigsaw Puzzles",
      "authors": [
        "Zifu Wang",
        "Junyi Zhu",
        "Bo Tang",
        "Zhiyu Li",
        "Feiyu Xiong",
        "Jiaqian Yu",
        "Matthew B. Blaschko"
      ],
      "abstract": "The application of rule-based reinforcement learning (RL) to multimodal large\nlanguage models (MLLMs) introduces unique challenges and potential deviations\nfrom findings in text-only domains, particularly for perception-heavy tasks.\nThis paper provides a comprehensive study of rule-based visual RL using jigsaw\npuzzles as a structured experimental framework, revealing several key findings.\n\\textit{Firstly,} we find that MLLMs, initially performing near to random\nguessing on simple puzzles, achieve near-perfect accuracy and generalize to\ncomplex, unseen configurations through fine-tuning. \\textit{Secondly,} training\non jigsaw puzzles can induce generalization to other visual tasks, with\neffectiveness tied to specific task configurations. \\textit{Thirdly,} MLLMs can\nlearn and generalize with or without explicit reasoning, though open-source\nmodels often favor direct answering. Consequently, even when trained for\nstep-by-step reasoning, they can ignore the thinking process in deriving the\nfinal answer. \\textit{Fourthly,} we observe that complex reasoning patterns\nappear to be pre-existing rather than emergent, with their frequency increasing\nalongside training and task difficulty. \\textit{Finally,} our results\ndemonstrate that RL exhibits more effective generalization than Supervised\nFine-Tuning (SFT), and an initial SFT cold start phase can hinder subsequent RL\noptimization. Although these observations are based on jigsaw puzzles and may\nvary across other visual tasks, this research contributes a valuable piece of\njigsaw to the larger puzzle of collective understanding rule-based visual RL\nand its potential in multimodal learning. The code is available at:\n\\href{https://github.com/zifuwanggg/Jigsaw-R1}{https://github.com/zifuwanggg/Jigsaw-R1}.",
      "pdf_url": "http://arxiv.org/pdf/2505.23590v1",
      "published": "2025-05-29T16:01:22+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.23590v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Collaborative Last-Mile Delivery: A Multi-Platform Vehicle Routing Problem With En-route Charging",
      "authors": [
        "Sumbal Malik",
        "Majid Khonji",
        "Khaled Elbassioni",
        "Jorge Dias"
      ],
      "abstract": "The rapid growth of e-commerce and the increasing demand for timely,\ncost-effective last-mile delivery have increased interest in collaborative\nlogistics. This research introduces a novel collaborative synchronized\nmulti-platform vehicle routing problem with drones and robots (VRP-DR), where a\nfleet of $\\mathcal{M}$ trucks, $\\mathcal{N}$ drones and $\\mathcal{K}$ robots,\ncooperatively delivers parcels. Trucks serve as mobile platforms, enabling the\nlaunching, retrieving, and en-route charging of drones and robots, thereby\naddressing critical limitations such as restricted payload capacities, limited\nrange, and battery constraints. The VRP-DR incorporates five realistic\nfeatures: (1) multi-visit service per trip, (2) multi-trip operations, (3)\nflexible docking, allowing returns to the same or different trucks (4) cyclic\nand acyclic operations, enabling return to the same or different nodes; and (5)\nen-route charging, enabling drones and robots to recharge while being\ntransported on the truck, maximizing operational efficiency by utilizing idle\ntransit time. The VRP-DR is formulated as a mixed-integer linear program (MILP)\nto minimize both operational costs and makespan. To overcome the computational\nchallenges of solving large-scale instances, a scalable heuristic algorithm,\nFINDER (Flexible INtegrated Delivery with Energy Recharge), is developed, to\nprovide efficient, near-optimal solutions. Numerical experiments across various\ninstance sizes evaluate the performance of the MILP and heuristic approaches in\nterms of solution quality and computation time. The results demonstrate\nsignificant time savings of the combined delivery mode over the truck-only mode\nand substantial cost reductions from enabling multi-visits. The study also\nprovides insights into the effects of en-route charging, docking flexibility,\ndrone count, speed, and payload capacity on system performance.",
      "pdf_url": "http://arxiv.org/pdf/2505.23584v1",
      "published": "2025-05-29T15:58:01+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.23584v1",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.RO"
      ]
    },
    {
      "title": "Engineering Serendipity through Recommendations of Items with Atypical Aspects",
      "authors": [
        "Ramit Aditya",
        "Razvan Bunescu",
        "Smita Nannaware",
        "Erfan Al-Hossami"
      ],
      "abstract": "A restaurant dinner or a hotel stay may lead to memorable experiences when\nguests encounter unexpected aspects that also match their interests. For\nexample, an origami-making station in the waiting area of a restaurant may be\nboth surprising and enjoyable for a customer who is passionate about paper\ncrafts. Similarly, an exhibit of 18th century harpsichords would be atypical\nfor a hotel lobby and likely pique the interest of a guest who has a passion\nfor Baroque music. Motivated by this insight, in this paper we introduce the\nnew task of engineering serendipity through recommendations of items with\natypical aspects. We describe an LLM-based system pipeline that extracts\natypical aspects from item reviews, then estimates and aggregates their\nuser-specific utility in a measure of serendipity potential that is used to\nrerank a list of items recommended to the user. To facilitate system\ndevelopment and evaluation, we introduce a dataset of Yelp reviews that are\nmanually annotated with atypical aspects and a dataset of artificially\ngenerated user profiles, together with crowdsourced annotations of user-aspect\nutility values. Furthermore, we introduce a custom procedure for dynamic\nselection of in-context learning examples, which is shown to improve LLM-based\njudgments of atypicality and utility. Experimental evaluations show that\nserendipity-based rankings generated by the system are highly correlated with\nground truth rankings for which serendipity scores are computed from manual\nannotations of atypical aspects and their user-dependent utility. Overall, we\nhope that the new recommendation task and the associated system presented in\nthis paper catalyze further research into recommendation approaches that go\nbeyond accuracy in their pursuit of enhanced user satisfaction.\n  The datasets and the code are made publicly available at\nhttps://github.com/ramituncc49er/ATARS .",
      "pdf_url": "http://arxiv.org/pdf/2505.23580v1",
      "published": "2025-05-29T15:53:21+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.23580v1",
      "categories": [
        "cs.IR",
        "cs.AI"
      ]
    },
    {
      "title": "Cognitive Guardrails for Open-World Decision Making in Autonomous Drone Swarms",
      "authors": [
        "Jane Cleland-Huang",
        "Pedro Antonio Alarcon Granadeno",
        "Arturo Miguel Russell Bernal",
        "Demetrius Hernandez",
        "Michael Murphy",
        "Maureen Petterson",
        "Walter Scheirer"
      ],
      "abstract": "Small Uncrewed Aerial Systems (sUAS) are increasingly deployed as autonomous\nswarms in search-and-rescue and other disaster-response scenarios. In these\nsettings, they use computer vision (CV) to detect objects of interest and\nautonomously adapt their missions. However, traditional CV systems often\nstruggle to recognize unfamiliar objects in open-world environments or to infer\ntheir relevance for mission planning. To address this, we incorporate large\nlanguage models (LLMs) to reason about detected objects and their implications.\nWhile LLMs can offer valuable insights, they are also prone to hallucinations\nand may produce incorrect, misleading, or unsafe recommendations. To ensure\nsafe and sensible decision-making under uncertainty, high-level decisions must\nbe governed by cognitive guardrails. This article presents the design,\nsimulation, and real-world integration of these guardrails for sUAS swarms in\nsearch-and-rescue missions.",
      "pdf_url": "http://arxiv.org/pdf/2505.23576v1",
      "published": "2025-05-29T15:47:49+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.23576v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.HC"
      ]
    },
    {
      "title": "CoT Red-Handed: Stress Testing Chain-of-Thought Monitoring",
      "authors": [
        "Benjamin Arnav",
        "Pablo Bernabeu-Pérez",
        "Nathan Helm-Burger",
        "Tim Kostolansky",
        "Hannes Whittingham",
        "Mary Phuong"
      ],
      "abstract": "As AI models are deployed with increasing autonomy, it is important to ensure\nthey do not take harmful actions unnoticed. As a potential mitigation, we\ninvestigate Chain-of-Thought (CoT) monitoring, wherein a weaker trusted monitor\nmodel continuously oversees the intermediate reasoning steps of a more powerful\nbut untrusted model. We compare CoT monitoring to action-only monitoring, where\nonly final outputs are reviewed, in a red-teaming setup where the untrusted\nmodel is instructed to pursue harmful side tasks while completing a coding\nproblem. We find that CoT monitoring improves detection by up to 27 percentage\npoints in scenarios where action-only monitoring fails to reliably identify\nsabotage. However, CoT traces can also contain misleading rationalizations that\ndeceive the monitor, reducing performance in more obvious sabotage cases. To\naddress this, we introduce a hybrid protocol that independently scores both\nreasoning and final outputs and combines them using a weighted average. This\nhybrid monitor consistently outperforms both CoT and action-only monitors\nacross all tested models and tasks, with detection rates over four times higher\nthan action-only monitoring for subtle deception scenarios.",
      "pdf_url": "http://arxiv.org/pdf/2505.23575v1",
      "published": "2025-05-29T15:47:36+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.23575v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Segment Policy Optimization: Effective Segment-Level Credit Assignment in RL for Large Language Models",
      "authors": [
        "Yiran Guo",
        "Lijie Xu",
        "Jie Liu",
        "Dan Ye",
        "Shuang Qiu"
      ],
      "abstract": "Enhancing the reasoning capabilities of large language models effectively\nusing reinforcement learning (RL) remains a crucial challenge. Existing\napproaches primarily adopt two contrasting advantage estimation granularities:\nToken-level methods (e.g., PPO) aim to provide the fine-grained advantage\nsignals but suffer from inaccurate estimation due to difficulties in training\nan accurate critic model. On the other extreme, trajectory-level methods (e.g.,\nGRPO) solely rely on a coarse-grained advantage signal from the final reward,\nleading to imprecise credit assignment. To address these limitations, we\npropose Segment Policy Optimization (SPO), a novel RL framework that leverages\nsegment-level advantage estimation at an intermediate granularity, achieving a\nbetter balance by offering more precise credit assignment than trajectory-level\nmethods and requiring fewer estimation points than token-level methods,\nenabling accurate advantage estimation based on Monte Carlo (MC) without a\ncritic model. SPO features three components with novel strategies: (1) flexible\nsegment partition; (2) accurate segment advantage estimation; and (3) policy\noptimization using segment advantages, including a novel probability-mask\nstrategy. We further instantiate SPO for two specific scenarios: (1) SPO-chain\nfor short chain-of-thought (CoT), featuring novel cutpoint-based partition and\nchain-based advantage estimation, achieving $6$-$12$ percentage point\nimprovements in accuracy over PPO and GRPO on GSM8K. (2) SPO-tree for long CoT,\nfeaturing novel tree-based advantage estimation, which significantly reduces\nthe cost of MC estimation, achieving $7$-$11$ percentage point improvements\nover GRPO on MATH500 under 2K and 4K context evaluation. We make our code\npublicly available at https://github.com/AIFrameResearch/SPO.",
      "pdf_url": "http://arxiv.org/pdf/2505.23564v1",
      "published": "2025-05-29T15:38:19+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.23564v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "SafeScientist: Toward Risk-Aware Scientific Discoveries by LLM Agents",
      "authors": [
        "Kunlun Zhu",
        "Jiaxun Zhang",
        "Ziheng Qi",
        "Nuoxing Shang",
        "Zijia Liu",
        "Peixuan Han",
        "Yue Su",
        "Haofei Yu",
        "Jiaxuan You"
      ],
      "abstract": "Recent advancements in large language model (LLM) agents have significantly\naccelerated scientific discovery automation, yet concurrently raised critical\nethical and safety concerns. To systematically address these challenges, we\nintroduce \\textbf{SafeScientist}, an innovative AI scientist framework\nexplicitly designed to enhance safety and ethical responsibility in AI-driven\nscientific exploration. SafeScientist proactively refuses ethically\ninappropriate or high-risk tasks and rigorously emphasizes safety throughout\nthe research process. To achieve comprehensive safety oversight, we integrate\nmultiple defensive mechanisms, including prompt monitoring, agent-collaboration\nmonitoring, tool-use monitoring, and an ethical reviewer component.\nComplementing SafeScientist, we propose \\textbf{SciSafetyBench}, a novel\nbenchmark specifically designed to evaluate AI safety in scientific contexts,\ncomprising 240 high-risk scientific tasks across 6 domains, alongside 30\nspecially designed scientific tools and 120 tool-related risk tasks. Extensive\nexperiments demonstrate that SafeScientist significantly improves safety\nperformance by 35\\% compared to traditional AI scientist frameworks, without\ncompromising scientific output quality. Additionally, we rigorously validate\nthe robustness of our safety pipeline against diverse adversarial attack\nmethods, further confirming the effectiveness of our integrated approach. The\ncode and data will be available at https://github.com/ulab-uiuc/SafeScientist.\n\\textcolor{red}{Warning: this paper contains example data that may be offensive\nor harmful.}",
      "pdf_url": "http://arxiv.org/pdf/2505.23559v1",
      "published": "2025-05-29T15:35:58+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.23559v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Sustainable Carbon-Aware and Water-Efficient LLM Scheduling in Geo-Distributed Cloud Datacenters",
      "authors": [
        "Hayden Moore",
        "Sirui Qi",
        "Ninad Hogade",
        "Dejan Milojicic",
        "Cullen Bash",
        "Sudeep Pasricha"
      ],
      "abstract": "In recent years, Large Language Models (LLM) such as ChatGPT, CoPilot, and\nGemini have been widely adopted in different areas. As the use of LLMs\ncontinues to grow, many efforts have focused on reducing the massive training\noverheads of these models. But it is the environmental impact of handling user\nrequests to LLMs that is increasingly becoming a concern. Recent studies\nestimate that the costs of operating LLMs in their inference phase can exceed\ntraining costs by 25x per year. As LLMs are queried incessantly, the cumulative\ncarbon footprint for the operational phase has been shown to far exceed the\nfootprint during the training phase. Further, estimates indicate that 500 ml of\nfresh water is expended for every 20-50 requests to LLMs during inference. To\naddress these important sustainability issues with LLMs, we propose a novel\nframework called SLIT to co-optimize LLM quality of service (time-to-first\ntoken), carbon emissions, water usage, and energy costs. The framework utilizes\na machine learning (ML) based metaheuristic to enhance the sustainability of\nLLM hosting across geo-distributed cloud datacenters. Such a framework will\nbecome increasingly vital as LLMs proliferate.",
      "pdf_url": "http://arxiv.org/pdf/2505.23554v1",
      "published": "2025-05-29T15:31:28+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.23554v1",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "CLaC at SemEval-2025 Task 6: A Multi-Architecture Approach for Corporate Environmental Promise Verification",
      "authors": [
        "Nawar Turk",
        "Eeham Khan",
        "Leila Kosseim"
      ],
      "abstract": "This paper presents our approach to the SemEval-2025 Task~6 (PromiseEval),\nwhich focuses on verifying promises in corporate ESG (Environmental, Social,\nand Governance) reports. We explore three model architectures to address the\nfour subtasks of promise identification, supporting evidence assessment,\nclarity evaluation, and verification timing. Our first model utilizes ESG-BERT\nwith task-specific classifier heads, while our second model enhances this\narchitecture with linguistic features tailored for each subtask. Our third\napproach implements a combined subtask model with attention-based sequence\npooling, transformer representations augmented with document metadata, and\nmulti-objective learning. Experiments on the English portion of the ML-Promise\ndataset demonstrate progressive improvement across our models, with our\ncombined subtask approach achieving a leaderboard score of 0.5268,\noutperforming the provided baseline of 0.5227. Our work highlights the\neffectiveness of linguistic feature extraction, attention pooling, and\nmulti-objective learning in promise verification tasks, despite challenges\nposed by class imbalance and limited training data.",
      "pdf_url": "http://arxiv.org/pdf/2505.23538v1",
      "published": "2025-05-29T15:19:00+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.23538v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Synchronizing Process Model and Event Abstraction for Grounded Process Intelligence (Extended Version)",
      "authors": [
        "Janik-Vasily Benzin",
        "Gyunam Park",
        "Stefanie Rinderle-Ma"
      ],
      "abstract": "Model abstraction (MA) and event abstraction (EA) are means to reduce\ncomplexity of (discovered) models and event data. Imagine a process\nintelligence project that aims to analyze a model discovered from event data\nwhich is further abstracted, possibly multiple times, to reach optimality\ngoals, e.g., reducing model size. So far, after discovering the model, there is\nno technique that enables the synchronized abstraction of the underlying event\nlog. This results in loosing the grounding in the real-world behavior contained\nin the log and, in turn, restricts analysis insights. Hence, in this work, we\nprovide the formal basis for synchronized model and event abstraction, i.e., we\nprove that abstracting a process model by MA and discovering a process model\nfrom an abstracted event log yields an equivalent process model. We prove the\nfeasibility of our approach based on behavioral profile abstraction as\nnon-order preserving MA technique, resulting in a novel EA technique.",
      "pdf_url": "http://arxiv.org/pdf/2505.23536v1",
      "published": "2025-05-29T15:15:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.23536v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Subgraph Gaussian Embedding Contrast for Self-Supervised Graph Representation Learning",
      "authors": [
        "Shifeng Xie",
        "Aref Einizade",
        "Jhony H. Giraldo"
      ],
      "abstract": "Graph Representation Learning (GRL) is a fundamental task in machine\nlearning, aiming to encode high-dimensional graph-structured data into\nlow-dimensional vectors. Self-Supervised Learning (SSL) methods are widely used\nin GRL because they can avoid expensive human annotation. In this work, we\npropose a novel Subgraph Gaussian Embedding Contrast (SubGEC) method. Our\napproach introduces a subgraph Gaussian embedding module, which adaptively maps\nsubgraphs to a structured Gaussian space, ensuring the preservation of input\nsubgraph characteristics while generating subgraphs with a controlled\ndistribution. We then employ optimal transport distances, more precisely the\nWasserstein and Gromov-Wasserstein distances, to effectively measure the\nsimilarity between subgraphs, enhancing the robustness of the contrastive\nlearning process. Extensive experiments across multiple benchmarks demonstrate\nthat \\method~outperforms or presents competitive performance against\nstate-of-the-art approaches. Our findings provide insights into the design of\nSSL methods for GRL, emphasizing the importance of the distribution of the\ngenerated contrastive pairs.",
      "pdf_url": "http://arxiv.org/pdf/2505.23529v1",
      "published": "2025-05-29T15:07:22+00:00",
      "arxiv_url": "http://arxiv.org/abs/2505.23529v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    }
  ]
}