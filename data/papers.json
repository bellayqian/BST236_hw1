{
  "last_updated": "2025-12-03T00:53:23.102882",
  "papers": [
    {
      "title": "EfficientFlow: Efficient Equivariant Flow Policy Learning for Embodied AI",
      "authors": [
        "Jianlei Chang",
        "Ruofeng Mei",
        "Wei Ke",
        "Xiangyu Xu"
      ],
      "abstract": "Generative modeling has recently shown remarkable promise for visuomotor policy learning, enabling flexible and expressive control across diverse embodied AI tasks. However, existing generative policies often struggle with data inefficiency, requiring large-scale demonstrations, and sampling inefficiency, incurring slow action generation during inference. We introduce EfficientFlow, a unified framework for efficient embodied AI with flow-based policy learning. To enhance data efficiency, we bring equivariance into flow matching. We theoretically prove that when using an isotropic Gaussian prior and an equivariant velocity prediction network, the resulting action distribution remains equivariant, leading to improved generalization and substantially reduced data demands. To accelerate sampling, we propose a novel acceleration regularization strategy. As direct computation of acceleration is intractable for marginal flow trajectories, we derive a novel surrogate loss that enables stable and scalable training using only conditional trajectories. Across a wide range of robotic manipulation benchmarks, the proposed algorithm achieves competitive or superior performance under limited data while offering dramatically faster inference. These results highlight EfficientFlow as a powerful and efficient paradigm for high-performance embodied AI.",
      "pdf_url": "https://arxiv.org/pdf/2512.02020v1",
      "published": "2025-12-01T18:59:59+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.02020v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ]
    },
    {
      "title": "A Diffusion Model Framework for Maximum Entropy Reinforcement Learning",
      "authors": [
        "Sebastian Sanokowski",
        "Kaustubh Patil",
        "Alois Knoll"
      ],
      "abstract": "Diffusion models have achieved remarkable success in data-driven learning and in sampling from complex, unnormalized target distributions. Building on this progress, we reinterpret Maximum Entropy Reinforcement Learning (MaxEntRL) as a diffusion model-based sampling problem. We tackle this problem by minimizing the reverse Kullback-Leibler (KL) divergence between the diffusion policy and the optimal policy distribution using a tractable upper bound. By applying the policy gradient theorem to this objective, we derive a modified surrogate objective for MaxEntRL that incorporates diffusion dynamics in a principled way. This leads to simple diffusion-based variants of Soft Actor-Critic (SAC), Proximal Policy Optimization (PPO) and Wasserstein Policy Optimization (WPO), termed DiffSAC, DiffPPO and DiffWPO. All of these methods require only minor implementation changes to their base algorithm. We find that on standard continuous control benchmarks, DiffSAC, DiffPPO and DiffWPO achieve better returns and higher sample efficiency than SAC and PPO.",
      "pdf_url": "https://arxiv.org/pdf/2512.02019v1",
      "published": "2025-12-01T18:59:58+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.02019v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ]
    },
    {
      "title": "Visual Sync: Multi-Camera Synchronization via Cross-View Object Motion",
      "authors": [
        "Shaowei Liu",
        "David Yifan Yao",
        "Saurabh Gupta",
        "Shenlong Wang"
      ],
      "abstract": "Today, people can easily record memorable moments, ranging from concerts, sports events, lectures, family gatherings, and birthday parties with multiple consumer cameras. However, synchronizing these cross-camera streams remains challenging. Existing methods assume controlled settings, specific targets, manual correction, or costly hardware. We present VisualSync, an optimization framework based on multi-view dynamics that aligns unposed, unsynchronized videos at millisecond accuracy. Our key insight is that any moving 3D point, when co-visible in two cameras, obeys epipolar constraints once properly synchronized. To exploit this, VisualSync leverages off-the-shelf 3D reconstruction, feature matching, and dense tracking to extract tracklets, relative poses, and cross-view correspondences. It then jointly minimizes the epipolar error to estimate each camera's time offset. Experiments on four diverse, challenging datasets show that VisualSync outperforms baseline methods, achieving an median synchronization error below 50 ms.",
      "pdf_url": "https://arxiv.org/pdf/2512.02017v1",
      "published": "2025-12-01T18:59:57+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.02017v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ]
    },
    {
      "title": "Learning Sim-to-Real Humanoid Locomotion in 15 Minutes",
      "authors": [
        "Younggyo Seo",
        "Carmelo Sferrazza",
        "Juyue Chen",
        "Guanya Shi",
        "Rocky Duan",
        "Pieter Abbeel"
      ],
      "abstract": "Massively parallel simulation has reduced reinforcement learning (RL) training time for robots from days to minutes. However, achieving fast and reliable sim-to-real RL for humanoid control remains difficult due to the challenges introduced by factors such as high dimensionality and domain randomization. In this work, we introduce a simple and practical recipe based on off-policy RL algorithms, i.e., FastSAC and FastTD3, that enables rapid training of humanoid locomotion policies in just 15 minutes with a single RTX 4090 GPU. Our simple recipe stabilizes off-policy RL algorithms at massive scale with thousands of parallel environments through carefully tuned design choices and minimalist reward functions. We demonstrate rapid end-to-end learning of humanoid locomotion controllers on Unitree G1 and Booster T1 robots under strong domain randomization, e.g., randomized dynamics, rough terrain, and push perturbations, as well as fast training of whole-body human-motion tracking policies. We provide videos and open-source implementation at: https://younggyo.me/fastsac-humanoid.",
      "pdf_url": "https://arxiv.org/pdf/2512.01996v1",
      "published": "2025-12-01T18:55:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.01996v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "RoaD: Rollouts as Demonstrations for Closed-Loop Supervised Fine-Tuning of Autonomous Driving Policies",
      "authors": [
        "Guillermo Garcia-Cobo",
        "Maximilian Igl",
        "Peter Karkus",
        "Zhejun Zhang",
        "Michael Watson",
        "Yuxiao Chen",
        "Boris Ivanovic",
        "Marco Pavone"
      ],
      "abstract": "Autonomous driving policies are typically trained via open-loop behavior cloning of human demonstrations. However, such policies suffer from covariate shift when deployed in closed loop, leading to compounding errors. We introduce Rollouts as Demonstrations (RoaD), a simple and efficient method to mitigate covariate shift by leveraging the policy's own closed-loop rollouts as additional training data. During rollout generation, RoaD incorporates expert guidance to bias trajectories toward high-quality behavior, producing informative yet realistic demonstrations for fine-tuning. This approach enables robust closed-loop adaptation with orders of magnitude less data than reinforcement learning, and avoids restrictive assumptions of prior closed-loop supervised fine-tuning (CL-SFT) methods, allowing broader applications domains including end-to-end driving. We demonstrate the effectiveness of RoaD on WOSAC, a large-scale traffic simulation benchmark, where it performs similar or better than the prior CL-SFT method; and in AlpaSim, a high-fidelity neural reconstruction-based simulator for end-to-end driving, where it improves driving score by 41\\% and reduces collisions by 54\\%.",
      "pdf_url": "https://arxiv.org/pdf/2512.01993v1",
      "published": "2025-12-01T18:52:03+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.01993v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ]
    },
    {
      "title": "LLM CHESS: Benchmarking Reasoning and Instruction-Following in LLMs through Chess",
      "authors": [
        "Sai Kolasani",
        "Maxim Saplin",
        "Nicholas Crispino",
        "Kyle Montgomery",
        "Jared Quincy Davis",
        "Matei Zaharia",
        "Chi Wang",
        "Chenguang Wang"
      ],
      "abstract": "We introduce LLM CHESS, an evaluation framework designed to probe the generalization of reasoning and instruction-following abilities in large language models (LLMs) through extended agentic interaction in the domain of chess. We rank over 50 open and closed source models by playing against a random opponent using a range of behavioral metrics, including win and loss rates, move quality, move legality, hallucinated actions, and game duration. For a subset of top reasoning models, we derive an Elo estimate by playing against a chess engine with variably configured skill, which allows for comparisons between models in an easily understandable way. Despite the simplicity of the instruction-following task and the weakness of the opponent, many state-of-the-art models struggle to complete games or achieve consistent wins. Similar to other benchmarks on complex reasoning tasks, our experiments reveal a clear separation between reasoning and non-reasoning models. However, unlike existing static benchmarks, the stochastic and dynamic nature of LLM CHESS uniquely reduces overfitting and memorization while preventing benchmark saturation, proving difficult even for top reasoning models. To support future work on evaluating reasoning and instruction-following in LLMs, we release our experimental framework, a public leaderboard, and a dataset of associated games.",
      "pdf_url": "https://arxiv.org/pdf/2512.01992v1",
      "published": "2025-12-01T18:51:08+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.01992v1",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Forecasting in Offline Reinforcement Learning for Non-stationary Environments",
      "authors": [
        "Suzan Ece Ada",
        "Georg Martius",
        "Emre Ugur",
        "Erhan Oztop"
      ],
      "abstract": "Offline Reinforcement Learning (RL) provides a promising avenue for training policies from pre-collected datasets when gathering additional interaction data is infeasible. However, existing offline RL methods often assume stationarity or only consider synthetic perturbations at test time, assumptions that often fail in real-world scenarios characterized by abrupt, time-varying offsets. These offsets can lead to partial observability, causing agents to misperceive their true state and degrade performance. To overcome this challenge, we introduce Forecasting in Non-stationary Offline RL (FORL), a framework that unifies (i) conditional diffusion-based candidate state generation, trained without presupposing any specific pattern of future non-stationarity, and (ii) zero-shot time-series foundation models. FORL targets environments prone to unexpected, potentially non-Markovian offsets, requiring robust agent performance from the onset of each episode. Empirical evaluations on offline RL benchmarks, augmented with real-world time-series data to simulate realistic non-stationarity, demonstrate that FORL consistently improves performance compared to competitive baselines. By integrating zero-shot forecasting with the agent's experience, we aim to bridge the gap between offline RL and the complexities of real-world, non-stationary environments.",
      "pdf_url": "https://arxiv.org/pdf/2512.01987v1",
      "published": "2025-12-01T18:45:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.01987v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ]
    },
    {
      "title": "Chain-of-Ground: Improving GUI Grounding via Iterative Reasoning and Reference Feedback",
      "authors": [
        "Aiden Yiliu Li",
        "Bizhi Yu",
        "Daoan Lei",
        "Tianhe Ren",
        "Shilong Liu"
      ],
      "abstract": "GUI grounding aims to align natural language instructions with precise regions in complex user interfaces. Advanced multimodal large language models show strong ability in visual GUI grounding but still struggle with small or visually similar targets and ambiguity in real world layouts. These limitations arise from limited grounding capacity and from underuse of existing reasoning potential. We present Chain of Ground CoG a training free multi step grounding framework that uses multimodal large language models for iterative visual reasoning and refinement. Instead of direct prediction the model progressively reflects and adjusts its hypotheses leading to more accurate and interpretable localization. Our approach achieves 68.4 accuracy on the ScreenSpot Pro benchmark an improvement of 4.8 points. To measure real world generalization we introduce TPanel UI a dataset of 420 labeled industrial control panels with visual distortions such as blur and masking. On TPanel UI Chain of Ground improves over the strong baseline Qwen3 VL 235B by 6.9 points showing the effectiveness of multi step training free grounding across real world and digital interfaces. These results highlight a direction for unlocking grounding potential through structured iterative refinement instead of additional training.",
      "pdf_url": "https://arxiv.org/pdf/2512.01979v1",
      "published": "2025-12-01T18:37:19+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.01979v1",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ]
    },
    {
      "title": "AI-Driven Optimization under Uncertainty for Mineral Processing Operations",
      "authors": [
        "William Xu",
        "Amir Eskanlou",
        "Mansur Arief",
        "David Zhen Yin",
        "Jef K. Caers"
      ],
      "abstract": "The global capacity for mineral processing must expand rapidly to meet the demand for critical minerals, which are essential for building the clean energy technologies necessary to mitigate climate change. However, the efficiency of mineral processing is severely limited by uncertainty, which arises from both the variability of feedstock and the complexity of process dynamics. To optimize mineral processing circuits under uncertainty, we introduce an AI-driven approach that formulates mineral processing as a Partially Observable Markov Decision Process (POMDP). We demonstrate the capabilities of this approach in handling both feedstock uncertainty and process model uncertainty to optimize the operation of a simulated, simplified flotation cell as an example. We show that by integrating the process of information gathering (i.e., uncertainty reduction) and process optimization, this approach has the potential to consistently perform better than traditional approaches at maximizing an overall objective, such as net present value (NPV). Our methodological demonstration of this optimization-under-uncertainty approach for a synthetic case provides a mathematical and computational framework for later real-world application, with the potential to improve both the laboratory-scale design of experiments and industrial-scale operation of mineral processing circuits without any additional hardware.",
      "pdf_url": "https://arxiv.org/pdf/2512.01977v1",
      "published": "2025-12-01T18:35:54+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.01977v1",
      "categories": [
        "eess.SY",
        "cs.AI"
      ]
    },
    {
      "title": "From Atomic to Composite: Reinforcement Learning Enables Generalization in Complementary Reasoning",
      "authors": [
        "Sitao Cheng",
        "Xunjian Yin",
        "Ruiwen Zhou",
        "Yuxuan Li",
        "Xinyi Wang",
        "Liangming Pan",
        "William Yang Wang",
        "Victor Zhong"
      ],
      "abstract": "The mechanism by which RL contributes to reasoning capabilities-whether it incentivizes the synthesis of new skills or merely amplifies existing behaviors-remains a subject of intense debate. In this work, we investigate this question through the lens of Complementary Reasoning, a complex task that requires integrating internal parametric knowledge with external contextual information. Using a controlled synthetic dataset of human biographies, we strictly decouple this ability into two atomic skills: Parametric Reasoning (relying on internal knowledge) and Contextual Reasoning (depending on external information). To rigorously assess capability boundaries, we evaluate generalization across three distinct levels of difficulty: I.I.D., Composition, and Zero-shot settings. We find that while SFT is sufficient for in-distribution performance, it struggles with O.O.D. generalization, particularly in Zero-shot settings where relational combinations are novel. Crucially, we identify the SFT Generalization Paradox: Models supervised solely on the composite task achieve near-perfect in-distribution accuracy but collapse on out-of-distribution generalization, indicating their reliance on rote memorization of path shortcuts. In contrast, we find that RL acts as a reasoning synthesizer rather than a probability amplifier. However, we uncover a strict atomic prerequisite: RL can only synthesize these complex strategies if the base model has first mastered the independent atomic skills (Parametric and Contextual) via SFT. These findings challenge the view of RL as a mere amplifier, suggesting that given sufficient atomic foundations, RL can actively synthesize complex reasoning strategies from learned primitives without explicit supervision on such complex strategies. This indicates that decoupled atomic training followed by RL offers a scalable path to generalization for complex reasoning tasks.",
      "pdf_url": "https://arxiv.org/pdf/2512.01970v1",
      "published": "2025-12-01T18:27:25+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.01970v1",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Learned-Rule-Augmented Large Language Model Evaluators",
      "authors": [
        "Jie Meng",
        "Jin Mao"
      ],
      "abstract": "Large language models (LLMs) are predominantly used as evaluators for natural language generation (NLG) tasks, but their application to broader evaluation scenarios remains limited. In this work, we explore the potential of LLMs as general evaluators across diverse tasks. Although LLM-based evaluators have made progress in different areas, existing methods struggle to generalize due to their reliance on costly, human-designed evaluation principles, which are often misaligned with both annotated data and LLMs' understanding.To address these challenges, we propose a rule-augmented evaluation paradigm. First, we introduce a rule distillation method that automatically extracts scoring rules from data using an LLM-assisted Monte Carlo Tree Search (MCTS), alleviating scalability issues and improving alignment with data. Second, to enable LLMs to effectively apply the learned rules, we propose two strategies: (1) Chain-of-Rule (CoR), which guides LLM to follow distilled rules, and (2) training a rule-augmented LLM evaluator (RuAE) via reinforcement learning, further bridging the gap between rules and LLMs' reasoning. Extensive experiments on diverse tasks demonstrate the effectiveness and generalizability of our approach across various evaluation scenarios.",
      "pdf_url": "https://arxiv.org/pdf/2512.01958v1",
      "published": "2025-12-01T18:08:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.01958v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "GrndCtrl: Grounding World Models via Self-Supervised Reward Alignment",
      "authors": [
        "Haoyang He",
        "Jay Patrikar",
        "Dong-Ki Kim",
        "Max Smith",
        "Daniel McGann",
        "Ali-akbar Agha-mohammadi",
        "Shayegan Omidshafiei",
        "Sebastian Scherer"
      ],
      "abstract": "Recent advances in video world modeling have enabled large-scale generative models to simulate embodied environments with high visual fidelity, providing strong priors for prediction, planning, and control. Yet, despite their realism, these models often lack geometric grounding, limiting their use in navigation tasks that require spatial coherence and long-horizon stability. We introduce Reinforcement Learning with World Grounding (RLWG), a self-supervised post-training framework that aligns pretrained world models with a physically verifiable structure through geometric and perceptual rewards. Analogous to reinforcement learning from verifiable feedback (RLVR) in language models, RLWG can use multiple rewards that measure pose cycle-consistency, depth reprojection, and temporal coherence. We instantiate this framework with GrndCtrl, a reward-aligned adaptation method based on Group Relative Policy Optimization (GRPO), yielding world models that maintain stable trajectories, consistent geometry, and reliable rollouts for embodied navigation. Like post-training alignment in large language models, GrndCtrl leverages verifiable rewards to bridge generative pretraining and grounded behavior, achieving superior spatial coherence and navigation stability over supervised fine-tuning in outdoor environments.",
      "pdf_url": "https://arxiv.org/pdf/2512.01952v1",
      "published": "2025-12-01T18:03:29+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.01952v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ]
    },
    {
      "title": "Agentic Policy Optimization via Instruction-Policy Co-Evolution",
      "authors": [
        "Han Zhou",
        "Xingchen Wan",
        "Ivan Vulić",
        "Anna Korhonen"
      ],
      "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has advanced the reasoning capability of large language models (LLMs), enabling autonomous agents that can conduct effective multi-turn and tool-integrated reasoning. While instructions serve as the primary protocol for defining agents, RLVR typically relies on static and manually designed instructions. However, those instructions may be suboptimal for the base model, and the optimal instruction may change as the agent's policy improves and explores the interaction with the environment. To bridge the gap, we introduce INSPO, a novel Instruction-Policy co-evolution framework that integrates instruction optimization as a dynamic component of the reinforcement learning (RL) loop. INSPO maintains a dynamic population of instruction candidates that are sampled with questions, where reward signals in RL loops are automatically attributed to each instruction, and low performers are periodically pruned. New instructions are generated and verified through an on-policy reflection mechanism, where an LLM-based optimizer analyzes past experience from a replay buffer and evolves more effective strategies given the current policy. We conduct extensive experiments on multi-turn retrieval and reasoning tasks, demonstrating that INSPO substantially outperforms strong baselines relying on static instructions. INSPO discovers innovative instructions that guide the agent toward more strategic reasoning paths, achieving substantial performance gains with only a marginal increase in computational overhead.",
      "pdf_url": "https://arxiv.org/pdf/2512.01945v1",
      "published": "2025-12-01T17:56:29+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.01945v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "An Empirical Study of Agent Developer Practices in AI Agent Frameworks",
      "authors": [
        "Yanlin Wang",
        "Xinyi Xu",
        "Jiachi Chen",
        "Tingting Bi",
        "Wenchao Gu",
        "Zibin Zheng"
      ],
      "abstract": "The rise of large language models (LLMs) has sparked a surge of interest in agents, leading to the rapid growth of agent frameworks. Agent frameworks are software toolkits and libraries that provide standardized components, abstractions, and orchestration mechanisms to simplify agent development. Despite widespread use of agent frameworks, their practical applications and how they influence the agent development process remain underexplored. Different agent frameworks encounter similar problems during use, indicating that these recurring issues deserve greater attention and call for further improvements in agent framework design. Meanwhile, as the number of agent frameworks continues to grow and evolve, more than 80% of developers report difficulties in identifying the frameworks that best meet their specific development requirements. In this paper, we conduct the first empirical study of LLM-based agent frameworks, exploring real-world experiences of developers in building AI agents. To compare how well the agent frameworks meet developer needs, we further collect developer discussions for the ten previously identified agent frameworks, resulting in a total of 11,910 discussions. Finally, by analyzing these discussions, we compare the frameworks across five dimensions: development efficiency, functional abstraction, learning cost, performance optimization, and maintainability, which refers to how easily developers can update and extend both the framework itself and the agents built upon it over time. Our comparative analysis reveals significant differences among frameworks in how they meet the needs of agent developers. Overall, we provide a set of findings and implications for the LLM-driven AI agent framework ecosystem and offer insights for the design of future LLM-based agent frameworks and agent developers.",
      "pdf_url": "https://arxiv.org/pdf/2512.01939v1",
      "published": "2025-12-01T17:52:15+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.01939v1",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "SVRG and Beyond via Posterior Correction",
      "authors": [
        "Nico Daheim",
        "Thomas Möllenhoff",
        "Ming Liang Ang",
        "Mohammad Emtiyaz Khan"
      ],
      "abstract": "Stochastic Variance Reduced Gradient (SVRG) and its variants aim to speed-up training by using gradient corrections, but have seen limited success in deep learning. Here, we show surprising new foundational connections of SVRG to a recently proposed Bayesian method called posterior correction. Specifically, we show that SVRG is recovered as a special case of posterior correction over the isotropic-Gaussian family, while novel extensions are automatically obtained by using more flexible exponential families. We derive two new SVRG variants by using Gaussian families: First, a Newton-like variant that employs novel Hessian corrections, and second, an Adam-like extension that improves pretraining and finetuning of Transformer language models. This is the first work to connect SVRG to Bayes and use it to boost variational training for deep networks.",
      "pdf_url": "https://arxiv.org/pdf/2512.01930v1",
      "published": "2025-12-01T17:45:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.01930v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Rectifying LLM Thought from Lens of Optimization",
      "authors": [
        "Junnan Liu",
        "Hongwei Liu",
        "Songyang Zhang",
        "Kai Chen"
      ],
      "abstract": "Recent advancements in large language models (LLMs) have been driven by their emergent reasoning capabilities, particularly through long chain-of-thought (CoT) prompting, which enables thorough exploration and deliberation. Despite these advances, long-CoT LLMs often exhibit suboptimal reasoning behaviors, such as overthinking and excessively protracted reasoning chains, which can impair performance. In this paper, we analyze reasoning processes through an optimization lens, framing CoT as a gradient descent procedure where each reasoning step constitutes an update toward problem resolution. Building on this perspective, we introduce RePro (Rectifying Process-level Reward), a novel approach to refine LLM reasoning during post-training. RePro defines a surrogate objective function to assess the optimization process underlying CoT, utilizing a dual scoring mechanism to quantify its intensity and stability. These scores are aggregated into a composite process-level reward, seamlessly integrated into reinforcement learning with verifiable rewards (RLVR) pipelines to optimize LLMs. Extensive experiments across multiple reinforcement learning algorithms and diverse LLMs, evaluated on benchmarks spanning mathematics, science, and coding, demonstrate that RePro consistently enhances reasoning performance and mitigates suboptimal reasoning behaviors.",
      "pdf_url": "https://arxiv.org/pdf/2512.01925v1",
      "published": "2025-12-01T17:41:08+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.01925v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Real-World Robot Control by Deep Active Inference With a Temporally Hierarchical World Model",
      "authors": [
        "Kentaro Fujii",
        "Shingo Murata"
      ],
      "abstract": "Robots in uncertain real-world environments must perform both goal-directed and exploratory actions. However, most deep learning-based control methods neglect exploration and struggle under uncertainty. To address this, we adopt deep active inference, a framework that accounts for human goal-directed and exploratory actions. Yet, conventional deep active inference approaches face challenges due to limited environmental representation capacity and high computational cost in action selection. We propose a novel deep active inference framework that consists of a world model, an action model, and an abstract world model. The world model encodes environmental dynamics into hidden state representations at slow and fast timescales. The action model compresses action sequences into abstract actions using vector quantization, and the abstract world model predicts future slow states conditioned on the abstract action, enabling low-cost action selection. We evaluate the framework on object-manipulation tasks with a real-world robot. Results show that it achieves high success rates across diverse manipulation tasks and switches between goal-directed and exploratory actions in uncertain settings, while making action selection computationally tractable. These findings highlight the importance of modeling multiple timescale dynamics and abstracting actions and state transitions.",
      "pdf_url": "https://arxiv.org/pdf/2512.01924v1",
      "published": "2025-12-01T17:41:01+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.01924v1",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Exploring Human Perceptions of AI Responses: Insights from a Mixed-Methods Study on Risk Mitigation in Generative Models",
      "authors": [
        "Heloisa Candello",
        "Muneeza Azmat",
        "Uma Sushmitha Gunturi",
        "Raya Horesh",
        "Rogerio Abreu de Paula",
        "Heloisa Pimentel",
        "Marcelo Carpinette Grave",
        "Aminat Adebiyi",
        "Tiago Machado",
        "Maysa Malfiza Garcia de Macedo"
      ],
      "abstract": "With the rapid uptake of generative AI, investigating human perceptions of generated responses has become crucial. A major challenge is their `aptitude' for hallucinating and generating harmful contents. Despite major efforts for implementing guardrails, human perceptions of these mitigation strategies are largely unknown. We conducted a mixed-method experiment for evaluating the responses of a mitigation strategy across multiple-dimensions: faithfulness, fairness, harm-removal capacity, and relevance. In a within-subject study design, 57 participants assessed the responses under two conditions: harmful response plus its mitigation and solely mitigated response. Results revealed that participants' native language, AI work experience, and annotation familiarity significantly influenced evaluations. Participants showed high sensitivity to linguistic and contextual attributes, penalizing minor grammar errors while rewarding preserved semantic contexts. This contrasts with how language is often treated in the quantitative evaluation of LLMs. We also introduced new metrics for training and evaluating mitigation strategies and insights for human-AI evaluation studies.",
      "pdf_url": "https://arxiv.org/pdf/2512.01892v1",
      "published": "2025-12-01T17:12:28+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.01892v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ]
    },
    {
      "title": "Unifying Sign and Magnitude for Optimizing Deep Vision Networks via ThermoLion",
      "authors": [
        "Ahmed Nebli"
      ],
      "abstract": "The training of deep vision models is fundamentally a signal recovery problem amidst high-dimensional stochastic noise. Current optimization paradigms impose a static compromise on information channel capacity. For instance, magnitude-based methods, such as AdamW, operate on the assumption that gradient norms are high-fidelity curvature signals. While this allows for precision in smooth regimes, it leads to catastrophic noise amplification when applied to rugged, non-convex landscapes. Conversely, sign-based methods (e.g., Lion) perform a radical 1-bit quantization of the gradient, which aims to provide robust regularization at the cost of discarding fine-grained descent information. We propose that optimal convergence requires neither static prior, but rather a dynamic modulation of the update bitrate. We introduce \\textbf{ThermoLion}, a vision-centric framework that utilizes local Signal-to-Noise Ratio (SNR) gating to autonomously transition parameters between a \"low-bit\" exploration phase and a \"high-precision\" exploitation phase. Furthermore, we introduce a Momentum Alignment mechanism that detects constructive interference between historical drift and instantaneous gradients to accelerate convergence during stable trajectories. Empirical benchmarks across 12 diverse vision datasets (including CIFAR, SVHN, and GTSRB) demonstrate that ThermoLion serves as a hyperparameter-free generalist, surpassing both AdamW and Lion in convergence speed and terminal accuracy without architecture-specific tuning.",
      "pdf_url": "https://arxiv.org/pdf/2512.01881v1",
      "published": "2025-12-01T17:04:17+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.01881v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Predicting Human Chess Moves: An AI Assisted Analysis of Chess Games Using Skill-group Specific n-gram Language Models",
      "authors": [
        "Daren Zhong",
        "Dingcheng Huang",
        "Clayton Greenberg"
      ],
      "abstract": "Chess, a deterministic game with perfect information, has long served as a benchmark for studying strategic decision-making and artificial intelligence. Traditional chess engines or tools for analysis primarily focus on calculating optimal moves, often neglecting the variability inherent in human chess playing, particularly across different skill levels.\n  To overcome this limitation, we propose a novel and computationally efficient move prediction framework that approaches chess move prediction as a behavioral analysis task. The framework employs n-gram language models to capture move patterns characteristic of specific player skill levels. By dividing players into seven distinct skill groups, from novice to expert, we trained separate models using data from the open-source chess platform Lichess. The framework dynamically selects the most suitable model for prediction tasks and generates player moves based on preceding sequences.\n  Evaluation on real-world game data demonstrates that the model selector module within the framework can classify skill levels with an accuracy of up to 31.7\\% when utilizing early game information (16 half-moves). The move prediction framework also shows substantial accuracy improvements, with our Selector Assisted Accuracy being up to 39.1\\% more accurate than our benchmark accuracy. The computational efficiency of the framework further enhances its suitability for real-time chess analysis.",
      "pdf_url": "https://arxiv.org/pdf/2512.01880v1",
      "published": "2025-12-01T17:02:07+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.01880v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Graph Distance as Surprise: Free Energy Minimization in Knowledge Graph Reasoning",
      "authors": [
        "Gaganpreet Jhajj",
        "Fuhua Lin"
      ],
      "abstract": "In this work, we propose that reasoning in knowledge graph (KG) networks can be guided by surprise minimization. Entities that are close in graph distance will have lower surprise than those farther apart. This connects the Free Energy Principle (FEP) from neuroscience to KG systems, where the KG serves as the agent's generative model. We formalize surprise using the shortest-path distance in directed graphs and provide a framework for KG-based agents. Graph distance appears in graph neural networks as message passing depth and in model-based reinforcement learning as world model trajectories. This work-in-progress study explores whether distance-based surprise can extend recent work showing that syntax minimizes surprise and free energy via tree structures.",
      "pdf_url": "https://arxiv.org/pdf/2512.01878v1",
      "published": "2025-12-01T16:59:28+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.01878v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Testing Transformer Learnability on the Arithmetic Sequence of Rooted Trees",
      "authors": [
        "Alessandro Breccia",
        "Federica Gerace",
        "Marco Lippi",
        "Gabriele Sicuro",
        "Pierluigi Contucci"
      ],
      "abstract": "We study whether a Large Language Model can learn the deterministic sequence of trees generated by the iterated prime factorization of the natural numbers. Each integer is mapped into a rooted planar tree and the resulting sequence $ \\mathbb{N}\\mathcal{T}$ defines an arithmetic text with measurable statistical structure. A transformer network (the GPT-2 architecture) is trained from scratch on the first $10^{11}$ elements to subsequently test its predictive ability under next-word and masked-word prediction tasks. Our results show that the model partially learns the internal grammar of $\\mathbb{N}\\mathcal{T}$, capturing non-trivial regularities and correlations. This suggests that learnability may extend beyond empirical data to the very structure of arithmetic.",
      "pdf_url": "https://arxiv.org/pdf/2512.01870v1",
      "published": "2025-12-01T16:51:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.01870v1",
      "categories": [
        "cs.AI",
        "cond-mat.dis-nn",
        "math-ph",
        "math.NT"
      ]
    },
    {
      "title": "Cross-Lingual Interleaving for Speech Language Models",
      "authors": [
        "Adel Moumen",
        "Guangzhi Sun",
        "Philip C. Woodland"
      ],
      "abstract": "Spoken Language Models (SLMs) aim to learn linguistic competence directly from speech using discrete units, widening access to Natural Language Processing (NLP) technologies for languages with limited written resources. However, progress has been largely English-centric due to scarce spoken evaluation benchmarks and training data, making cross-lingual learning difficult. We present a cross-lingual interleaving method that mixes speech tokens across languages without textual supervision. We also release an EN-FR training dataset, TinyStories (~42k hours), together with EN-FR spoken StoryCloze and TopicCloze benchmarks for cross-lingual semantic evaluation, both synthetically generated using GPT-4. On 360M and 1B SLMs under matched training-token budgets, interleaving improves monolingual semantic accuracy, enables robust cross-lingual continuation, and strengthens cross-lingual hidden-state alignment. Taken together, these results indicate that cross-lingual interleaving is a simple, scalable route to building multilingual SLMs that understand and converse across languages. All resources will be made open-source to support reproducibility.",
      "pdf_url": "https://arxiv.org/pdf/2512.01865v1",
      "published": "2025-12-01T16:48:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.01865v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Topological Order in Deep State",
      "authors": [
        "Ahmed Abouelkomsan",
        "Max Geier",
        "Liang Fu"
      ],
      "abstract": "Topologically ordered states are among the most interesting quantum phases of matter that host emergent quasi-particles having fractional charge and obeying fractional quantum statistics. Theoretical study of such states is however challenging owing to their strong-coupling nature that prevents conventional mean-field treatment. Here, we demonstrate that an attention-based deep neural network provides an expressive variational wavefunction that discovers fractional Chern insulator ground states purely through energy minimization without prior knowledge and achieves remarkable accuracy. We introduce an efficient method to extract ground state topological degeneracy -- a hallmark of topological order -- from a single optimized real-space wavefunction in translation-invariant systems by decomposing it into different many-body momentum sectors. Our results establish neural network variational Monte Carlo as a versatile tool for discovering strongly correlated topological phases.",
      "pdf_url": "https://arxiv.org/pdf/2512.01863v1",
      "published": "2025-12-01T16:46:39+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.01863v1",
      "categories": [
        "cond-mat.mes-hall",
        "cond-mat.str-el",
        "cs.AI"
      ]
    },
    {
      "title": "BHRAM-IL: A Benchmark for Hallucination Recognition and Assessment in Multiple Indian Languages",
      "authors": [
        "Hrishikesh Terdalkar",
        "Kirtan Bhojani",
        "Aryan Dongare",
        "Omm Aditya Behera"
      ],
      "abstract": "Large language models (LLMs) are increasingly deployed in multilingual applications but often generate plausible yet incorrect or misleading outputs, known as hallucinations. While hallucination detection has been studied extensively in English, under-resourced Indian languages remain largely unexplored. We present BHRAM-IL, a benchmark for hallucination recognition and assessment in multiple Indian languages, covering Hindi, Gujarati, Marathi, Odia, along with English. The benchmark comprises 36,047 curated questions across nine categories spanning factual, numerical, reasoning, and linguistic tasks. We evaluate 14 state-of-the-art multilingual LLMs on a benchmark subset of 10,265 questions, analyzing cross-lingual and factual hallucinations across languages, models, scales, categories, and domains using category-specific metrics normalized to (0,1) range. Aggregation over all categories and models yields a primary score of 0.23 and a language-corrected fuzzy score of 0.385, demonstrating the usefulness of BHRAM-IL for hallucination-focused evaluation. The dataset, and the code for generation and evaluation are available on GitHub (https://github.com/sambhashana/BHRAM-IL/) and HuggingFace (https://huggingface.co/datasets/sambhashana/BHRAM-IL/) to support future research in multilingual hallucination detection and mitigation.",
      "pdf_url": "https://arxiv.org/pdf/2512.01852v1",
      "published": "2025-12-01T16:37:34+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.01852v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.ET"
      ]
    },
    {
      "title": "Mitigating Gender Bias in Depression Detection via Counterfactual Inference",
      "authors": [
        "Mingxuan Hu",
        "Hongbo Ma",
        "Xinlan Wu",
        "Ziqi Liu",
        "Jiaqi Liu",
        "Yangbin Chen"
      ],
      "abstract": "Audio-based depression detection models have demonstrated promising performance but often suffer from gender bias due to imbalanced training data. Epidemiological statistics show a higher prevalence of depression in females, leading models to learn spurious correlations between gender and depression. Consequently, models tend to over-diagnose female patients while underperforming on male patients, raising significant fairness concerns. To address this, we propose a novel Counterfactual Debiasing Framework grounded in causal inference. We construct a causal graph to model the decision-making process and identify gender bias as the direct causal effect of gender on the prediction. During inference, we employ counterfactual inference to estimate and subtract this direct effect, ensuring the model relies primarily on authentic acoustic pathological features. Extensive experiments on the DAIC-WOZ dataset using two advanced acoustic backbones demonstrate that our framework not only significantly reduces gender bias but also improves overall detection performance compared to existing debiasing strategies.",
      "pdf_url": "https://arxiv.org/pdf/2512.01834v1",
      "published": "2025-12-01T16:14:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.01834v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ]
    },
    {
      "title": "Deconstructing Generative Diversity: An Information Bottleneck Analysis of Discrete Latent Generative Models",
      "authors": [
        "Yudi Wu",
        "Wenhao Zhao",
        "Dianbo Liu"
      ],
      "abstract": "Generative diversity varies significantly across discrete latent generative models such as AR, MIM, and Diffusion. We propose a diagnostic framework, grounded in Information Bottleneck (IB) theory, to analyze the underlying strategies resolving this behavior. The framework models generation as a conflict between a 'Compression Pressure' - a drive to minimize overall codebook entropy - and a 'Diversity Pressure' - a drive to maximize conditional entropy given an input. We further decompose this diversity into two primary sources: 'Path Diversity', representing the choice of high-level generative strategies, and 'Execution Diversity', the randomness in executing a chosen strategy. To make this decomposition operational, we introduce three zero-shot, inference-time interventions that directly perturb the latent generative process and reveal how models allocate and express diversity. Application of this probe-based framework to representative AR, MIM, and Diffusion systems reveals three distinct strategies: \"Diversity-Prioritized\" (MIM), \"Compression-Prioritized\" (AR), and \"Decoupled\" (Diffusion). Our analysis provides a principled explanation for their behavioral differences and informs a novel inference-time diversity enhancement technique.",
      "pdf_url": "https://arxiv.org/pdf/2512.01831v1",
      "published": "2025-12-01T16:13:23+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.01831v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "InnoGym: Benchmarking the Innovation Potential of AI Agents",
      "authors": [
        "Jintian Zhang",
        "Kewei Xu",
        "Jingsheng Zheng",
        "Zhuoyun Yu",
        "Yuqi Zhu",
        "Yujie Luo",
        "Lanning Wei",
        "Shuofei Qiao",
        "Lun Du",
        "Da Zheng",
        "Shumin Deng",
        "Huajun Chen",
        "Ningyu Zhang"
      ],
      "abstract": "LLMs and Agents have achieved impressive progress in code generation, mathematical reasoning, and scientific discovery. However, existing benchmarks primarily measure correctness, overlooking the diversity of methods behind solutions. True innovation depends not only on producing correct answers but also on the originality of the approach. We present InnoGym, the first benchmark and framework designed to systematically evaluate the innovation potential of AI agents. InnoGym introduces two complementary metrics: performance gain, which measures improvement over the best-known solutions, and novelty, which captures methodological differences from prior approaches. The benchmark includes 18 carefully curated tasks from real-world engineering and scientific domains, each standardized through resource filtering, evaluator validation, and solution collection. In addition, we provide iGym, a unified execution environment for reproducible and long-horizon evaluations. Extensive experiments show that while some agents produce novel approaches, their lack of robustness limits performance gains. These results highlight a key gap between creativity and effectiveness, underscoring the need for benchmarks that evaluate both.",
      "pdf_url": "https://arxiv.org/pdf/2512.01822v1",
      "published": "2025-12-01T16:03:04+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.01822v1",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.MA"
      ]
    },
    {
      "title": "Envision: Benchmarking Unified Understanding & Generation for Causal World Process Insights",
      "authors": [
        "Juanxi Tian",
        "Siyuan Li",
        "Conghui He",
        "Lijun Wu",
        "Cheng Tan"
      ],
      "abstract": "Current multimodal models aim to transcend the limitations of single-modality representations by unifying understanding and generation, often using text-to-image (T2I) tasks to calibrate semantic consistency. However, their reliance on static, single-image generation in training and evaluation leads to overfitting to static pattern matching and semantic fusion, while fundamentally hindering their ability to model dynamic processes that unfold over time. To address these constraints, we propose Envision-a causal event progression benchmark for chained text-to-multi-image generation. Grounded in world knowledge and structured by spatiotemporal causality, it reorganizes existing evaluation dimensions and includes 1,000 four-stage prompts spanning six scientific and humanities domains. To transition evaluation from single images to sequential frames and assess whether models truly internalize world knowledge while adhering to causal-temporal constraints, we introduce Envision-Score, a holistic metric integrating multi-dimensional consistency, physicality, and aesthetics. Comprehensive evaluation of 15 models (10 specialized T2I models, 5 unified models) uncovers: specialized T2I models demonstrate proficiency in aesthetic rendering yet lack intrinsic world knowledge. Unified multimodal models bridge this gap, consistently outperforming specialized counterparts in causal narrative coherence. However, even these unified architectures remain subordinate to closed-source models and struggle to overcome the core challenge of spatiotemporal consistency. This demonstrates that a focus on causally-isolated single images impedes multi-frame reasoning and generation, promoting static pattern matching over dynamic world modeling-ultimately limiting world knowledge internalization, generation.",
      "pdf_url": "https://arxiv.org/pdf/2512.01816v1",
      "published": "2025-12-01T15:52:31+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.01816v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "H-Neurons: On the Existence, Impact, and Origin of Hallucination-Associated Neurons",
      "authors": [
        "Cheng Gao",
        "Huimin Chen",
        "Chaojun Xiao",
        "Zhiyi Chen",
        "Zhiyuan Liu",
        "Maosong Sun"
      ],
      "abstract": "Large language models (LLMs) frequently generate hallucinations -- plausible but factually incorrect outputs -- undermining their reliability. While prior work has examined hallucinations from macroscopic perspectives such as training data and objectives, the underlying neuron-level mechanisms remain largely unexplored. In this paper, we conduct a systematic investigation into hallucination-associated neurons (H-Neurons) in LLMs from three perspectives: identification, behavioral impact, and origins. Regarding their identification, we demonstrate that a remarkably sparse subset of neurons (less than $0.1\\%$ of total neurons) can reliably predict hallucination occurrences, with strong generalization across diverse scenarios. In terms of behavioral impact, controlled interventions reveal that these neurons are causally linked to over-compliance behaviors. Concerning their origins, we trace these neurons back to the pre-trained base models and find that these neurons remain predictive for hallucination detection, indicating they emerge during pre-training. Our findings bridge macroscopic behavioral patterns with microscopic neural mechanisms, offering insights for developing more reliable LLMs.",
      "pdf_url": "https://arxiv.org/pdf/2512.01797v1",
      "published": "2025-12-01T15:32:14+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.01797v1",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ]
    },
    {
      "title": "Who Judges the Judge? LLM Jury-on-Demand: Building Trustworthy LLM Evaluation Systems",
      "authors": [
        "Xiaochuan Li",
        "Ke Wang",
        "Girija Gouda",
        "Shubham Choudhary",
        "Yaqun Wang",
        "Linwei Hu",
        "Joel Vaughan",
        "Freddy Lecue"
      ],
      "abstract": "As Large Language Models (LLMs) become integrated into high-stakes domains, there is a growing need for evaluation methods that are both scalable for real-time deployment and reliable for critical decision-making. While human evaluation is reliable, it is slow and costly. Single LLM judges are biased, and static juries lack adaptability. To overcome these limitations, we propose LLM Jury-on-Demand - a dynamic, learning-based framework for scalable and context-aware evaluation. Our method trains a set of reliability predictors to assess when LLM judges will agree with human experts, leveraging token distributions, embeddings, and structural input features. This enables a fully adaptive evaluation where, for each data point, an optimal jury of the most reliable judges is dynamically selected, and their scores are aggregated using their reliability as weights. Experiments on summarization and RAG benchmarks show that our dynamic jury system achieves significantly higher correlation with human judgment than both single-judge and static-jury baselines. These results highlight the promise of adaptive, learning-based juries for building scalable, more reliable and trustworthy evaluation systems for modern LLMs in high-stakes domains.",
      "pdf_url": "https://arxiv.org/pdf/2512.01786v1",
      "published": "2025-12-01T15:26:20+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.01786v1",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Dual Randomized Smoothing: Beyond Global Noise Variance",
      "authors": [
        "Chenhao Sun",
        "Yuhao Mao",
        "Martin Vechev"
      ],
      "abstract": "Randomized Smoothing (RS) is a prominent technique for certifying the robustness of neural networks against adversarial perturbations. With RS, achieving high accuracy at small radii requires a small noise variance, while achieving high accuracy at large radii requires a large noise variance. However, the global noise variance used in the standard RS formulation leads to a fundamental limitation: there exists no global noise variance that simultaneously achieves strong performance at both small and large radii. To break through the global variance limitation, we propose a dual RS framework which enables input-dependent noise variances. To achieve that, we first prove that RS remains valid with input-dependent noise variances, provided the variance is locally constant around each input. Building on this result, we introduce two components which form our dual RS framework: (i) a variance estimator first predicts an optimal noise variance for each input, (ii) this estimated variance is then used by a standard RS classifier. The variance estimator is independently smoothed via RS to ensure local constancy, enabling flexible design. We also introduce training strategies to iteratively optimize the two components. Extensive experiments on CIFAR-10 show that our dual RS method provides strong performance for both small and large radii-unattainable with global noise variance-while incurring only a 60% computational overhead at inference. Moreover, it consistently outperforms prior input-dependent noise approaches across most radii, with particularly large gains at radii 0.5, 0.75, and 1.0, achieving relative improvements of 19%, 24%, and 21%, respectively. On ImageNet, dual RS remains effective across all radii. Additionally, the dual RS framework naturally provides a routing perspective for certified robustness, improving the accuracy-robustness trade-off with off-the-shelf expert RS models.",
      "pdf_url": "https://arxiv.org/pdf/2512.01782v1",
      "published": "2025-12-01T15:23:00+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.01782v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Weight Space Representation Learning with Neural Fields",
      "authors": [
        "Zhuoqian Yang",
        "Mathieu Salzmann",
        "Sabine Süsstrunk"
      ],
      "abstract": "In this work, we investigate the potential of weights to serve as effective representations, focusing on neural fields. Our key insight is that constraining the optimization space through a pre-trained base model and low-rank adaptation (LoRA) can induce structure in weight space. Across reconstruction, generation, and analysis tasks on 2D and 3D data, we find that multiplicative LoRA weights achieve high representation quality while exhibiting distinctiveness and semantic structure. When used with latent diffusion models, multiplicative LoRA weights enable higher-quality generation than existing weight-space methods.",
      "pdf_url": "https://arxiv.org/pdf/2512.01759v1",
      "published": "2025-12-01T15:05:01+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.01759v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Probabilistic Neuro-Symbolic Reasoning for Sparse Historical Data: A Framework Integrating Bayesian Inference, Causal Models, and Game-Theoretic Allocation",
      "authors": [
        "Saba Kublashvili"
      ],
      "abstract": "Modeling historical events poses fundamental challenges for machine learning: extreme data scarcity (N << 100), heterogeneous and noisy measurements, missing counterfactuals, and the requirement for human interpretable explanations. We present HistoricalML, a probabilistic neuro-symbolic framework that addresses these challenges through principled integration of (1) Bayesian uncertainty quantification to separate epistemic from aleatoric uncertainty, (2) structural causal models for counterfactual reasoning under confounding, (3) cooperative game theory (Shapley values) for fair allocation modeling, and (4) attention based neural architectures for context dependent factor weighting. We provide theoretical analysis showing that our approach achieves consistent estimation in the sparse data regime when strong priors from domain knowledge are available, and that Shapley based allocation satisfies axiomatic fairness guarantees that pure regression approaches cannot provide. We instantiate the framework on two historical case studies: the 19th century partition of Africa (N = 7 colonial powers) and the Second Punic War (N = 2 factions). Our model identifies Germany's +107.9 percent discrepancy as a quantifiable structural tension preceding World War I, with tension factor 36.43 and 0.79 naval arms race correlation. For the Punic Wars, Monte Carlo battle simulations achieve a 57.3 percent win probability for Carthage at Cannae and 57.8 percent for Rome at Zama, aligning with historical outcomes. Counterfactual analysis reveals that Carthaginian political support (support score 6.4 vs Napoleon's 7.1), rather than military capability, was the decisive factor.",
      "pdf_url": "https://arxiv.org/pdf/2512.01723v1",
      "published": "2025-12-01T14:35:04+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.01723v1",
      "categories": [
        "cs.AI",
        "cs.GT",
        "math.PR"
      ]
    },
    {
      "title": "StreamGaze: Gaze-Guided Temporal Reasoning and Proactive Understanding in Streaming Videos",
      "authors": [
        "Daeun Lee",
        "Subhojyoti Mukherjee",
        "Branislav Kveton",
        "Ryan A. Rossi",
        "Viet Dac Lai",
        "Seunghyun Yoon",
        "Trung Bui",
        "Franck Dernoncourt",
        "Mohit Bansal"
      ],
      "abstract": "Streaming video understanding requires models not only to process temporally incoming frames, but also to anticipate user intention for realistic applications like AR glasses. While prior streaming benchmarks evaluate temporal reasoning, none measure whether MLLMs can interpret or leverage human gaze signals within a streaming setting. To fill this gap, we introduce StreamGaze, the first benchmark designed to evaluate how effectively MLLMs use gaze for temporal and proactive reasoning in streaming videos. StreamGaze introduces gaze-guided past, present, and proactive tasks that comprehensively evaluate streaming video understanding. These tasks assess whether models can use real-time gaze to follow shifting attention and infer user intentions from only past and currently observed frames. To build StreamGaze, we develop a gaze-video QA generation pipeline that aligns egocentric videos with raw gaze trajectories via fixation extraction, region-specific visual prompting, and scanpath construction. This pipeline produces spatio-temporally grounded QA pairs that closely reflect human perceptual dynamics. Across all StreamGaze tasks, we observe substantial performance gaps between state-of-the-art MLLMs and human performance, revealing fundamental limitations in gaze-based temporal reasoning, intention modeling, and proactive prediction. We further provide detailed analyses of gaze-prompting strategies, reasoning behaviors, and task-specific failure modes, offering deeper insight into why current MLLMs struggle and what capabilities future models must develop. All data and code will be publicly released to support continued research in gaze-guided streaming video understanding.",
      "pdf_url": "https://arxiv.org/pdf/2512.01707v1",
      "published": "2025-12-01T14:15:44+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.01707v1",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "ICAD-LLM: One-for-All Anomaly Detection via In-Context Learning with Large Language Models",
      "authors": [
        "Zhongyuan Wu",
        "Jingyuan Wang",
        "Zexuan Cheng",
        "Yilong Zhou",
        "Weizhi Wang",
        "Juhua Pu",
        "Chao Li",
        "Changqing Ma"
      ],
      "abstract": "Anomaly detection (AD) is a fundamental task of critical importance across numerous domains. Current systems increasingly operate in rapidly evolving environments that generate diverse yet interconnected data modalities -- such as time series, system logs, and tabular records -- as exemplified by modern IT systems. Effective AD methods in such environments must therefore possess two critical capabilities: (1) the ability to handle heterogeneous data formats within a unified framework, allowing the model to process and detect multiple modalities in a consistent manner during anomalous events; (2) a strong generalization ability to quickly adapt to new scenarios without extensive retraining. However, most existing methods fall short of these requirements, as they typically focus on single modalities and lack the flexibility to generalize across domains. To address this gap, we introduce a novel paradigm: In-Context Anomaly Detection (ICAD), where anomalies are defined by their dissimilarity to a relevant reference set of normal samples. Under this paradigm, we propose ICAD-LLM, a unified AD framework leveraging Large Language Models' in-context learning abilities to process heterogeneous data within a single model. Extensive experiments demonstrate that ICAD-LLM achieves competitive performance with task-specific AD methods and exhibits strong generalization to previously unseen tasks, which substantially reduces deployment costs and enables rapid adaptation to new environments. To the best of our knowledge, ICAD-LLM is the first model capable of handling anomaly detection tasks across diverse domains and modalities.",
      "pdf_url": "https://arxiv.org/pdf/2512.01672v1",
      "published": "2025-12-01T13:41:30+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.01672v1",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Learning the Boundary of Solvability: Aligning LLMs to Detect Unsolvable Problems",
      "authors": [
        "Dengyun Peng",
        "Qiguang Chen",
        "Bofei Liu",
        "Jiannan Guan",
        "Libo Qin",
        "Zheng Yan",
        "Jinhao Liu",
        "Jianshu Zhang",
        "Wanxiang Che"
      ],
      "abstract": "Ensuring LLM reliability requires not only solving complex problems but also recognizing when a problem is unsolvable. Current models often struggle to distinguish objective unsolvability (inherent contradictions in the problem) from subjective capability limitations (problems beyond the model's competence), which leads to hallucinations and overconfidence. To address this, we propose UnsolvableQA and UnsolvableRL to solve feasible problems, detect inherent contradictions, and prudently refuse tasks beyond capability. Specifically, we construct UnsolvableQA, a dataset of paired solvable and unsolvable instances derived via a dual-track methodology: programmatic generation for logic puzzles and a novel \"Reverse Construction\" method that injects contradictions into valid reasoning chains for mathematics. Building on this dataset, we introduce UnsolvableRL, a reinforcement learning framework with three reward components jointly accounting for accuracy, unsolvability, and difficulty. Empirical results show that our approach achieves near-perfect unsolvability detection while also improving accuracy on solvable tasks. Crucially, we identify Capability Collapse, demonstrating that explicit exposure to unsolvable data is indispensable for preventing models from becoming systematically overconfident. Our code and data are available at https://github.com/sfasfaffa/unsolvableQA.",
      "pdf_url": "https://arxiv.org/pdf/2512.01661v1",
      "published": "2025-12-01T13:32:59+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.01661v1",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "HalluGraph: Auditable Hallucination Detection for Legal RAG Systems via Knowledge Graph Alignment",
      "authors": [
        "Valentin Noël",
        "Elimane Yassine Seidou",
        "Charly Ken Capo-Chichi",
        "Ghanem Amari"
      ],
      "abstract": "Legal AI systems powered by retrieval-augmented generation (RAG) face a critical accountability challenge: when an AI assistant cites case law, statutes, or contractual clauses, practitioners need verifiable guarantees that generated text faithfully represents source documents. Existing hallucination detectors rely on semantic similarity metrics that tolerate entity substitutions, a dangerous failure mode when confusing parties, dates, or legal provisions can have material consequences. We introduce HalluGraph, a graph-theoretic framework that quantifies hallucinations through structural alignment between knowledge graphs extracted from context, query, and response. Our approach produces bounded, interpretable metrics decomposed into \\textit{Entity Grounding} (EG), measuring whether entities in the response appear in source documents, and \\textit{Relation Preservation} (RP), verifying that asserted relationships are supported by context. On structured control documents, HalluGraph achieves near-perfect discrimination ($>$400 words, $>$20 entities), HalluGraph achieves $AUC = 0.979$, while maintaining robust performance ($AUC \\approx 0.89$) on challenging generative legal task, consistently outperforming semantic similarity baselines. The framework provides the transparency and traceability required for high-stakes legal applications, enabling full audit trails from generated assertions back to source passages.",
      "pdf_url": "https://arxiv.org/pdf/2512.01659v1",
      "published": "2025-12-01T13:31:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.01659v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "CLIP-RL: Aligning Language and Policy Representations for Task Transfer in Reinforcement Learning",
      "authors": [
        "Chainesh Gautam",
        "Raghuram Bharadwaj Diddigi"
      ],
      "abstract": "Recently, there has been an increasing need to develop agents capable of solving multiple tasks within the same environment, especially when these tasks are naturally associated with language. In this work, we propose a novel approach that leverages combinations of pre-trained (language, policy) pairs to establish an efficient transfer pipeline. Our algorithm is inspired by the principles of Contrastive Language-Image Pretraining (CLIP) in Computer Vision, which aligns representations across different modalities under the philosophy that ''two modalities representing the same concept should have similar representations.'' The central idea here is that the instruction and corresponding policy of a task represent the same concept, the task itself, in two different modalities. Therefore, by extending the idea of CLIP to RL, our method creates a unified representation space for natural language and policy embeddings. Experimental results demonstrate the utility of our algorithm in achieving faster transfer across tasks.",
      "pdf_url": "https://arxiv.org/pdf/2512.01616v1",
      "published": "2025-12-01T12:37:01+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.01616v1",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "RoleMotion: A Large-Scale Dataset towards Robust Scene-Specific Role-Playing Motion Synthesis with Fine-grained Descriptions",
      "authors": [
        "Junran Peng",
        "Yiheng Huang",
        "Silei Shen",
        "Zeji Wei",
        "Jingwei Yang",
        "Baojie Wang",
        "Yonghao He",
        "Chuanchen Luo",
        "Man Zhang",
        "Xucheng Yin",
        "Wei Sui"
      ],
      "abstract": "In this paper, we introduce RoleMotion, a large-scale human motion dataset that encompasses a wealth of role-playing and functional motion data tailored to fit various specific scenes. Existing text datasets are mainly constructed decentrally as amalgamation of assorted subsets that their data are nonfunctional and isolated to work together to cover social activities in various scenes. Also, the quality of motion data is inconsistent, and textual annotation lacks fine-grained details in these datasets. In contrast, RoleMotion is meticulously designed and collected with a particular focus on scenes and roles. The dataset features 25 classic scenes, 110 functional roles, over 500 behaviors, and 10296 high-quality human motion sequences of body and hands, annotated with 27831 fine-grained text descriptions. We build an evaluator stronger than existing counterparts, prove its reliability, and evaluate various text-to-motion methods on our dataset. Finally, we explore the interplay of motion generation of body and hands. Experimental results demonstrate the high-quality and functionality of our dataset on text-driven whole-body generation.",
      "pdf_url": "https://arxiv.org/pdf/2512.01582v1",
      "published": "2025-12-01T11:59:03+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.01582v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "From Black Hole to Galaxy: Neural Operator: Framework for Accretion and Feedback Dynamics",
      "authors": [
        "Nihaal Bhojwani",
        "Chuwei Wang",
        "Hai-Yang Wang",
        "Chang Sun",
        "Elias R. Most",
        "Anima Anandkumar"
      ],
      "abstract": "Modeling how supermassive black holes co-evolve with their host galaxies is notoriously hard because the relevant physics spans nine orders of magnitude in scale-from milliparsecs to megaparsecs--making end-to-end first-principles simulation infeasible. To characterize the feedback from the small scales, existing methods employ a static subgrid scheme or one based on theoretical guesses, which usually struggle to capture the time variability and derive physically faithful results. Neural operators are a class of machine learning models that achieve significant speed-up in simulating complex dynamics. We introduce a neural-operator-based ''subgrid black hole'' that learns the small-scale local dynamics and embeds it within the direct multi-level simulations. Trained on small-domain (general relativistic) magnetohydrodynamic data, the model predicts the unresolved dynamics needed to supply boundary conditions and fluxes at coarser levels across timesteps, enabling stable long-horizon rollouts without hand-crafted closures. Thanks to the great speedup in fine-scale evolution, our approach for the first time captures intrinsic variability in accretion-driven feedback, allowing dynamic coupling between the central black hole and galaxy-scale gas. This work reframes subgrid modeling in computational astrophysics with scale separation and provides a scalable path toward data-driven closures for a broad class of systems with central accretors.",
      "pdf_url": "https://arxiv.org/pdf/2512.01576v1",
      "published": "2025-12-01T11:47:49+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.01576v1",
      "categories": [
        "astro-ph.HE",
        "astro-ph.GA",
        "cs.AI",
        "gr-qc"
      ]
    },
    {
      "title": "Reconstructing Multi-Scale Physical Fields from Extremely Sparse Measurements with an Autoencoder-Diffusion Cascade",
      "authors": [
        "Letian Yi",
        "Tingpeng Zhang",
        "Mingyuan Zhou",
        "Guannan Wang",
        "Quanke Su",
        "Zhilu Lai"
      ],
      "abstract": "Reconstructing full fields from extremely sparse and random measurements is a longstanding ill-posed inverse problem. A powerful framework for addressing such challenges is hierarchical probabilistic modeling, where uncertainty is represented by intermediate variables and resolved through marginalization during inference. Inspired by this principle, we propose Cascaded Sensing (Cas-Sensing), a hierarchical reconstruction framework that integrates an autoencoder-diffusion cascade. First, a neural operator-based functional autoencoder reconstructs the dominant structures of the original field - including large-scale components and geometric boundaries - from arbitrary sparse inputs, serving as an intermediate variable. Then, a conditional diffusion model, trained with a mask-cascade strategy, generates fine-scale details conditioned on these large-scale structures. To further enhance fidelity, measurement consistency is enforced via the manifold constrained gradient based on Bayesian posterior sampling during the generation process. This cascaded pipeline substantially alleviates ill-posedness, delivering accurate and robust reconstructions. Experiments on both simulation and real-world datasets demonstrate that Cas-Sensing generalizes well across varying sensor configurations and geometric boundaries, making it a promising tool for practical deployment in scientific and engineering applications.",
      "pdf_url": "https://arxiv.org/pdf/2512.01572v1",
      "published": "2025-12-01T11:46:14+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.01572v1",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.app-ph"
      ]
    },
    {
      "title": "Deep FlexQP: Accelerated Nonlinear Programming via Deep Unfolding",
      "authors": [
        "Alex Oshin",
        "Rahul Vodeb Ghosh",
        "Augustinos D. Saravanos",
        "Evangelos A. Theodorou"
      ],
      "abstract": "We propose an always-feasible quadratic programming (QP) optimizer, FlexQP, which is based on an exact relaxation of the QP constraints. If the original constraints are feasible, then the optimizer finds the optimal solution to the original QP. On the other hand, if the constraints are infeasible, the optimizer identifies a solution that minimizes the constraint violation in a sparse manner. FlexQP scales favorably with respect to the problem dimension, is robust to both feasible and infeasible QPs with minimal assumptions on the problem data, and can be effectively warm-started. We subsequently apply deep unfolding to improve our optimizer through data-driven techniques, leading to an accelerated Deep FlexQP. By learning dimension-agnostic feedback policies for the parameters from a small number of training examples, Deep FlexQP generalizes to problems with larger dimensions and can optimize for many more iterations than it was initially trained for. Our approach outperforms two recently proposed state-of-the-art accelerated QP approaches on a suite of benchmark systems including portfolio optimization, classification, and regression problems. We provide guarantees on the expected performance of our deep QP optimizer through probably approximately correct (PAC) Bayes generalization bounds. These certificates are used to design an accelerated sequential quadratic programming solver that solves nonlinear optimal control and predictive safety filter problems faster than traditional approaches. Overall, our approach is very robust and greatly outperforms existing non-learning and learning-based optimizers in terms of both runtime and convergence to the optimal solution across multiple classes of NLPs.",
      "pdf_url": "https://arxiv.org/pdf/2512.01565v1",
      "published": "2025-12-01T11:38:45+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.01565v1",
      "categories": [
        "math.OC",
        "cs.AI"
      ]
    },
    {
      "title": "MasHeNe: A Benchmark for Head and Neck CT Mass Segmentation using Window-Enhanced Mamba with Frequency-Domain Integration",
      "authors": [
        "Thao Thi Phuong Dao",
        "Tan-Cong Nguyen",
        "Nguyen Chi Thanh",
        "Truong Hoang Viet",
        "Trong-Le Do",
        "Mai-Khiem Tran",
        "Minh-Khoi Pham",
        "Trung-Nghia Le",
        "Minh-Triet Tran",
        "Thanh Dinh Le"
      ],
      "abstract": "Head and neck masses are space-occupying lesions that can compress the airway and esophagus and may affect nerves and blood vessels. Available public datasets primarily focus on malignant lesions and often overlook other space-occupying conditions in this region. To address this gap, we introduce MasHeNe, an initial dataset of 3,779 contrast-enhanced CT slices that includes both tumors and cysts with pixel-level annotations. We also establish a benchmark using standard segmentation baselines and report common metrics to enable fair comparison. In addition, we propose the Windowing-Enhanced Mamba with Frequency integration (WEMF) model. WEMF applies tri-window enhancement to enrich the input appearance before feature extraction. It further uses multi-frequency attention to fuse information across skip connections within a U-shaped Mamba backbone. On MasHeNe, WEMF attains the best performance among evaluated methods, with a Dice of 70.45%, IoU of 66.89%, NSD of 72.33%, and HD95 of 5.12 mm. This model indicates stable and strong results on this challenging task. MasHeNe provides a benchmark for head-and-neck mass segmentation beyond malignancy-only datasets. The observed error patterns also suggest that this task remains challenging and requires further research. Our dataset and code are available at https://github.com/drthaodao3101/MasHeNe.git.",
      "pdf_url": "https://arxiv.org/pdf/2512.01563v1",
      "published": "2025-12-01T11:38:05+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.01563v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "LEC: Linear Expectation Constraints for False-Discovery Control in Selective Prediction and Routing Systems",
      "authors": [
        "Zhiyuan Wang",
        "Aniri",
        "Tianlong Chen",
        "Yue Zhang",
        "Heng Tao Shen",
        "Xiaoshuang Shi",
        "Kaidi Xu"
      ],
      "abstract": "Large language models (LLMs) often generate unreliable answers, while heuristic uncertainty methods fail to fully distinguish correct from incorrect predictions, causing users to accept erroneous answers without statistical guarantees. We address this issue through the lens of false discovery rate (FDR) control, ensuring that among all accepted predictions, the proportion of errors does not exceed a target risk level. To achieve this in a principled way, we propose LEC, which reinterprets selective prediction as a constrained decision problem by enforcing a Linear Expectation Constraint over selection and error indicators. Then, we establish a finite-sample sufficient condition, which relies only on a held-out set of exchangeable calibration samples, to compute an FDR-constrained, coverage-maximizing threshold. Furthermore, we extend LEC to a two-model routing mechanism: given a prompt, if the current model's uncertainty exceeds its calibrated threshold, we delegate it to a stronger model, while maintaining a unified FDR guarantee. Evaluations on closed-ended and open-ended question-answering (QA) datasets show that LEC achieves tighter FDR control and substantially improves sample retention over prior methods. Moreover, the two-model routing mechanism achieves lower risk levels while accepting more correct samples than each individual model.",
      "pdf_url": "https://arxiv.org/pdf/2512.01556v1",
      "published": "2025-12-01T11:27:09+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.01556v1",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    },
    {
      "title": "Delta Sum Learning: an approach for fast and global convergence in Gossip Learning",
      "authors": [
        "Tom Goethals",
        "Merlijn Sebrechts",
        "Stijn De Schrijver",
        "Filip De Turck",
        "Bruno Volckaert"
      ],
      "abstract": "Federated Learning is a popular approach for distributed learning due to its security and computational benefits. With the advent of powerful devices in the network edge, Gossip Learning further decentralizes Federated Learning by removing centralized integration and relying fully on peer to peer updates. However, the averaging methods generally used in both Federated and Gossip Learning are not ideal for model accuracy and global convergence. Additionally, there are few options to deploy Learning workloads in the edge as part of a larger application using a declarative approach such as Kubernetes manifests. This paper proposes Delta Sum Learning as a method to improve the basic aggregation operation in Gossip Learning, and implements it in a decentralized orchestration framework based on Open Application Model, which allows for dynamic node discovery and intent-driven deployment of multi-workload applications. Evaluation results show that Delta Sum performance is on par with alternative integration methods for 10 node topologies, but results in a 58% lower global accuracy drop when scaling to 50 nodes. Overall, it shows strong global convergence and a logarithmic loss of accuracy with increasing topology size compared to a linear loss for alternatives under limited connectivity.",
      "pdf_url": "https://arxiv.org/pdf/2512.01549v1",
      "published": "2025-12-01T11:23:51+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.01549v1",
      "categories": [
        "cs.DC",
        "cs.AI"
      ]
    },
    {
      "title": "LPCD: Unified Framework from Layer-Wise to Submodule Quantization",
      "authors": [
        "Yuma Ichikawa",
        "Yudai Fujimoto",
        "Akira Sakai"
      ],
      "abstract": "Post-training quantization (PTQ) aims to preserve model-level behavior; however, most methods focus on individual linear layers. Even recent extensions, such as QEP and LoaQ, which mitigate error propagation or target specific submodules, still rely on layer-wise formulations and fail to capture the behavior of larger submodules. We introduce Layer-Projected Coordinate Descent (LPCD), a unified framework that extends PTQ beyond layers by optimizing relaxed objectives across arbitrary submodules and projecting the solutions with layer-wise quantizers. LPCD generalizes existing methods and provides a principled approach to quantizing complex submodules while maintaining the efficiency and compatibility of layer-wise PTQ pipelines. Across diverse LLM architectures and bit-widths, LPCD-based submodule quantization consistently enhances both layer-wise PTQ methods and existing submodule approaches.",
      "pdf_url": "https://arxiv.org/pdf/2512.01546v1",
      "published": "2025-12-01T11:21:18+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.01546v1",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    },
    {
      "title": "Q2D2: A Geometry-Aware Audio Codec Leveraging Two-Dimensional Quantization",
      "authors": [
        "Tal Shuster",
        "Eliya Nachmani"
      ],
      "abstract": "Recent neural audio codecs have achieved impressive reconstruction quality, typically relying on quantization methods such as Residual Vector Quantization (RVQ), Vector Quantization (VQ) and Finite Scalar Quantization (FSQ). However, these quantization techniques limit the geometric structure of the latent space, make it harder to capture correlations between features leading to inefficiency in representation learning, codebook utilization and token rate. In this paper we introduce Two Dimensional Quantization (Q2D2), a quantization scheme in which feature pairs are projected onto structured 2D grids such as hexagonal, rhombic, or rectangular tiling and quantized to the nearest grid values, yielding an implicit codebook defined by the product of grid levels, with codebook sizes comparable to conventional methods. Despite its simple geometric formulation, Q2D2 improves audio compression efficiency, with low token rates and high codebook utilization while maintaining state of the art reconstruction quality. Specifically, Q2D2 achieves competitive to superior performance in various objective and subjective reconstruction metrics, across extensive experiments in speech domain compared to state of the art models. Comprehensive ablation studies further confirm the effectiveness of our design choices.",
      "pdf_url": "https://arxiv.org/pdf/2512.01537v1",
      "published": "2025-12-01T11:06:38+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.01537v1",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.IT",
        "cs.LG",
        "eess.SP"
      ]
    },
    {
      "title": "Deep Unsupervised Anomaly Detection in Brain Imaging: Large-Scale Benchmarking and Bias Analysis",
      "authors": [
        "Alexander Frotscher",
        "Christian F. Baumgartner",
        "Thomas Wolfers"
      ],
      "abstract": "Deep unsupervised anomaly detection in brain magnetic resonance imaging offers a promising route to identify pathological deviations without requiring lesion-specific annotations. Yet, fragmented evaluations, heterogeneous datasets, and inconsistent metrics have hindered progress toward clinical translation. Here, we present a large-scale, multi-center benchmark of deep unsupervised anomaly detection for brain imaging. The training cohort comprised 2,976 T1 and 2,972 T2-weighted scans from healthy individuals across six scanners, with ages ranging from 6 to 89 years. Validation used 92 scans to tune hyperparameters and estimate unbiased thresholds. Testing encompassed 2,221 T1w and 1,262 T2w scans spanning healthy datasets and diverse clinical cohorts. Across all algorithms, the Dice-based segmentation performance varied between 0.03 and 0.65, indicating substantial variability. To assess robustness, we systematically evaluated the impact of different scanners, lesion types and sizes, as well as demographics (age, sex). Reconstruction-based methods, particularly diffusion-inspired approaches, achieved the strongest lesion segmentation performance, while feature-based methods showed greater robustness under distributional shifts. However, systematic biases, such as scanner-related effects, were observed for the majority of algorithms, including that small and low-contrast lesions were missed more often, and that false positives varied with age and sex. Increasing healthy training data yields only modest gains, underscoring that current unsupervised anomaly detection frameworks are limited algorithmically rather than by data availability. Our benchmark establishes a transparent foundation for future research and highlights priorities for clinical translation, including image native pretraining, principled deviation measures, fairness-aware modeling, and robust domain adaptation.",
      "pdf_url": "https://arxiv.org/pdf/2512.01534v1",
      "published": "2025-12-01T11:03:27+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.01534v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Diffusion Fuzzy System: Fuzzy Rule Guided Latent Multi-Path Diffusion Modeling",
      "authors": [
        "Hailong Yang",
        "Te Zhang",
        "Kup-sze Choi",
        "Zhaohong Deng"
      ],
      "abstract": "Diffusion models have emerged as a leading technique for generating images due to their ability to create high-resolution and realistic images. Despite their strong performance, diffusion models still struggle in managing image collections with significant feature differences. They often fail to capture complex features and produce conflicting results. Research has attempted to address this issue by learning different regions of an image through multiple diffusion paths and then combining them. However, this approach leads to inefficient coordination among multiple paths and high computational costs. To tackle these issues, this paper presents a Diffusion Fuzzy System (DFS), a latent-space multi-path diffusion model guided by fuzzy rules. DFS offers several advantages. First, unlike traditional multi-path diffusion methods, DFS uses multiple diffusion paths, each dedicated to learning a specific class of image features. By assigning each path to a different feature type, DFS overcomes the limitations of multi-path models in capturing heterogeneous image features. Second, DFS employs rule-chain-based reasoning to dynamically steer the diffusion process and enable efficient coordination among multiple paths. Finally, DFS introduces a fuzzy membership-based latent-space compression mechanism to reduce the computational costs of multi-path diffusion effectively. We tested our method on three public datasets: LSUN Bedroom, LSUN Church, and MS COCO. The results show that DFS achieves more stable training and faster convergence than existing single-path and multi-path diffusion models. Additionally, DFS surpasses baseline models in both image quality and alignment between text and images, and also shows improved accuracy when comparing generated images to target references.",
      "pdf_url": "https://arxiv.org/pdf/2512.01533v1",
      "published": "2025-12-01T11:01:06+00:00",
      "arxiv_url": "http://arxiv.org/abs/2512.01533v1",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    }
  ]
}